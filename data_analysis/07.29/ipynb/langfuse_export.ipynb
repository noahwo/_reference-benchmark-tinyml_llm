{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setting up\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ref: https://langfuse.com/docs/query-traces\n",
    "import os\n",
    "import json\n",
    "from langfuse import Langfuse\n",
    "import json\n",
    "import os\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "LOCAL_HOST = True\n",
    "\n",
    "\"\"\"Define session_id\"\"\"\n",
    "# session_id=\"qwen2.5-coder_f4d4_dp_batch\"\n",
    "session_id_list = [\n",
    "    # \"qwen2.5-coder:32b_4e11_tpsg_batch\",\n",
    "    # \"qwen2.5-coder:32b_ae24_tpsg_batch\"\n",
    "    \"qwen2.5-coder:32b_1974_tpusg_batch\",\n",
    "    \"qwen2.5-coder:32b_1974_psg_batch\"\n",
    "]\n",
    "\n",
    "\n",
    "\"\"\"Define paths\"\"\"\n",
    " \n",
    "parent_dir = os.path.dirname(os.getcwd())\n",
    "\n",
    " \n",
    "date = os.path.basename(parent_dir)\n",
    "tex_dir = os.path.join(parent_dir, \"tex\")\n",
    "processed_data_dir = os.path.join(parent_dir, \"processed_data\")\n",
    "raw_export_dir = os.path.join(parent_dir, \"raw_export\")\n",
    "ipynb_dir = os.path.join(parent_dir, \"ipynb\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Export raw data\n",
    "\n",
    "Langfuse added a limit of 20 API invocations per minute. https://langfuse.com/faq/all/api-limits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching traces for session qwen2.5-coder:32b_1974_tpusg_batch...\n",
      "Fetching observation data for time-10-43-05-323896_chatcmpl-0b4bd251-2e97-45f4-9212-34f103c38d72...\n",
      "Fetching observation data for time-10-43-48-595234_chatcmpl-2f24fa79-d8ad-45d6-baee-db65b18f3f76...\n",
      "Fetching observation data for time-10-44-40-545076_chatcmpl-7bee6cd4-919f-46fd-8fc2-c57be44d2064...\n",
      "Fetching observation data for time-10-45-34-760937_chatcmpl-9683905a-b2a3-45dc-961b-673fe4f7704e...\n",
      "Fetching observation data for time-10-38-16-195843_chatcmpl-c6b76df6-6ec9-4a46-b39f-042ee8b12bea...\n",
      "Fetching observation data for time-10-38-59-588764_chatcmpl-f34dd342-0a7d-46ea-a866-8a7f4e6c6c8b...\n",
      "Fetching observation data for time-10-39-50-206830_chatcmpl-e4a4a41c-0a8d-469e-9d08-a8ce8accc97c...\n",
      "Fetching observation data for time-10-40-38-848630_chatcmpl-20edc9cc-c4a0-4a79-97f9-3331d1daea64...\n",
      "Fetching observation data for time-10-41-27-180890_chatcmpl-edf2100a-d184-4e9f-a34f-58e3c760c48d...\n",
      "Fetching observation data for time-10-34-19-595459_chatcmpl-4d1e4f59-8ce1-4880-bc58-af1123590378...\n",
      "Fetching observation data for time-10-35-02-652406_chatcmpl-1668b68e-6d13-40a5-8ea3-b973234f520a...\n",
      "Fetching observation data for time-10-35-53-922243_chatcmpl-210ea055-421b-4e02-beee-8043636810ea...\n",
      "Fetching observation data for time-10-36-38-586966_chatcmpl-76aeb73f-8145-4fa1-a396-61bce16d5eac...\n",
      "Fetching observation data for time-10-30-09-029529_chatcmpl-4814d10a-8893-4cd1-bd8f-14535bf46572...\n",
      "Fetching observation data for time-10-30-52-084897_chatcmpl-c0b88bbb-39b6-4483-a99c-56decb6fe206...\n",
      "Fetching observation data for time-10-31-42-352986_chatcmpl-14544edf-f461-4fba-9fc7-8ac9c505cf28...\n",
      "Fetching observation data for time-10-32-31-914076_chatcmpl-b4b7edd8-801a-4692-b44a-2c515da0bb7f...\n",
      "Fetching observation data for time-10-33-22-798986_chatcmpl-22d2985a-a02f-44aa-8288-3d25186da63d...\n",
      "Fetching observation data for 9df10bb8-4fc6-468c-9bff-6176dbcdfa18...\n",
      "Fetching observation data for time-10-26-14-111723_chatcmpl-b1bbbd2e-9c1a-437f-9878-e7c95ce99267...\n",
      "Fetching observation data for time-10-26-57-479865_chatcmpl-d5cedaa2-deef-470c-ab6e-fe95e083a398...\n",
      "Fetching observation data for time-10-27-46-398455_chatcmpl-730f09ae-13fd-4e0e-892e-09c41fde6d2e...\n",
      "Fetching observation data for time-10-28-30-837256_chatcmpl-4843c6a9-67b4-4e43-8b7e-2b319fd583d0...\n",
      "Fetching observation data for time-10-21-59-470659_chatcmpl-1451859a-3979-4bae-932d-dbd4bbe6b021...\n",
      "Fetching observation data for time-10-22-42-520893_chatcmpl-5f9efe14-38ea-4af2-a419-e521a4df9906...\n",
      "Fetching observation data for time-10-23-34-317936_chatcmpl-38f9e39b-f40c-4c20-9399-2087d2aadb35...\n",
      "Fetching observation data for time-10-24-24-023671_chatcmpl-de34daa5-68d5-4a47-bd9d-bc725f4ff6b6...\n",
      "Fetching observation data for time-10-25-16-073046_chatcmpl-609aa0fe-5b65-4640-8e05-21061b92c166...\n",
      "Fetching observation data for caf78642-4fbd-4cbc-b919-7e318bdcd914...\n",
      "Fetching observation data for time-10-18-06-938485_chatcmpl-8ca10622-ff84-4ee6-8564-f1727ffb26ce...\n",
      "Fetching observation data for time-10-18-50-396655_chatcmpl-a9b2a6a3-6f49-4bae-9405-9211bd9ec0fd...\n",
      "Fetching observation data for time-10-19-37-908988_chatcmpl-4d7554de-0eea-4100-9942-c16c7ca1af7d...\n",
      "Fetching observation data for time-10-20-22-620315_chatcmpl-20ebd6ce-037a-4a7e-b74a-2398680d0cad...\n",
      "Fetching observation data for time-10-13-40-337999_chatcmpl-7e412084-884e-49e4-aaba-52637300a174...\n",
      "Fetching observation data for time-10-14-23-330700_chatcmpl-19c61046-0934-45a5-9839-b3b8efca8f12...\n",
      "Fetching observation data for time-10-15-19-572734_chatcmpl-9c8852f0-0fab-4403-a4a1-274551318f8c...\n",
      "Fetching observation data for time-10-16-14-721801_chatcmpl-c4853523-bfc9-4bd0-b529-9c51e725cd11...\n",
      "Fetching observation data for time-10-17-10-128613_chatcmpl-fc17819c-64d5-4e20-9159-71f40e73ea6c...\n",
      "Fetching observation data for b9e0d378-dd54-41fa-a007-bddcb77155d4...\n",
      "Fetching observation data for time-10-09-31-764851_chatcmpl-f1470d9d-3c25-40a6-8905-be32005f6045...\n",
      "Fetching observation data for time-10-10-14-739015_chatcmpl-e317622d-93d9-47a7-8ee9-930b9e43dccd...\n",
      "Fetching observation data for time-10-11-06-739447_chatcmpl-d173a681-80d1-4bb3-8ff2-bb87a8a9b286...\n",
      "Fetching observation data for time-10-11-56-038082_chatcmpl-89e32da1-8df0-4696-8c21-077a68a8b091...\n",
      "Fetching observation data for time-10-12-45-316330_chatcmpl-c4556752-fd6f-409c-beaa-33f1f54b5b59...\n",
      "Fetching observation data for a456c513-d708-4914-b37e-8892de0dd51e...\n",
      "Fetching observation data for time-10-05-30-159395_chatcmpl-312564a5-f63d-44df-9cdc-93de954cddca...\n",
      "Fetching observation data for time-10-06-13-387932_chatcmpl-96b61f96-d0c4-46de-9682-01be35786511...\n",
      "Fetching observation data for time-10-07-05-682752_chatcmpl-01560f2c-1d4f-4e13-8db7-9d01f0182f7a...\n",
      "Fetching observation data for time-10-07-54-444879_chatcmpl-299f8905-fc6d-4cc3-814c-401bf826fe6c...\n",
      "Fetching observation data for time-10-01-34-585911_chatcmpl-93871f6f-4bea-44eb-83b5-beb708af79a9...\n",
      "Fetching observation data for time-10-02-17-614398_chatcmpl-6e75b522-0892-47f5-99ed-9e0cadc74ebc...\n",
      "Fetching observation data for time-10-03-09-853203_chatcmpl-49665b8f-4421-45a6-9517-5ec621d20b6b...\n",
      "Fetching observation data for time-10-03-55-703132_chatcmpl-21880f6c-2c59-4181-8851-f88e92b07af6...\n",
      "Fetching observation data for time-09-56-54-929262_chatcmpl-3591dfd5-aaa3-494c-9e02-5cd801158f44...\n",
      "Fetching observation data for time-09-57-37-687770_chatcmpl-362bc0ec-b353-4add-9f66-2db8537db489...\n",
      "Fetching observation data for time-09-59-11-574967_chatcmpl-50032d03-ddd9-415f-958d-f51b1b6f3cad...\n",
      "Fetching observation data for time-09-59-56-235021_chatcmpl-07fb8d4c-bd5d-4314-aaa3-9c2f34a86247...\n",
      "Fetching observation data for time-09-51-53-313015_chatcmpl-e3c07af3-f658-4abc-a877-a4f5d2c2e247...\n",
      "Fetching observation data for time-09-52-36-144511_chatcmpl-5091de2b-1acd-41b8-8658-52b2beb1a387...\n",
      "Fetching observation data for time-09-53-27-730541_chatcmpl-3ddd53ea-0ca3-4902-bdc3-d6a59a1578d7...\n",
      "Fetching observation data for time-09-54-22-096645_chatcmpl-8d472687-21d9-4db6-a4cf-102b6690d66d...\n",
      "Fetching observation data for time-09-55-12-573324_chatcmpl-68f4f034-1d15-4cbd-8c36-77fcbdda9a65...\n",
      "Fetching observation data for time-09-47-43-726836_chatcmpl-d58a892a-dd85-4dc9-b3f6-0cee6d34974a...\n",
      "Fetching observation data for time-09-48-26-817979_chatcmpl-9204691f-4d21-4313-b08d-6f38856d0dc0...\n",
      "Fetching observation data for time-09-49-17-622848_chatcmpl-0abcd5d6-0856-460b-b0a3-272e9fac3347...\n",
      "Fetching observation data for time-09-50-09-974779_chatcmpl-ce7293d1-29a8-4197-aba5-c7a0da22f2ba...\n",
      "Fetching observation data for time-09-50-57-617057_chatcmpl-7b750ba3-de0c-4580-9854-993a4ac8c635...\n",
      "Fetching observation data for 4f5aa186-4fe9-4774-b54d-9eb21227b8ae...\n",
      "Fetching observation data for time-09-43-50-116866_chatcmpl-f53c48ac-5be0-4a9f-8776-39f55e26aa33...\n",
      "Fetching observation data for time-09-44-33-921529_chatcmpl-a3dc8c0c-5ce4-4dd7-9723-3e7a82c73498...\n",
      "Fetching observation data for time-09-45-21-517461_chatcmpl-ba1e465f-cc93-428f-ade7-8ae3ddbdb119...\n",
      "Fetching observation data for time-09-46-05-772819_chatcmpl-20462dec-b2d0-4433-8aa0-f3317d482608...\n",
      "Fetching observation data for time-09-39-57-017837_chatcmpl-e295fa30-faba-47d1-9b43-faf8aec70499...\n",
      "Fetching observation data for time-09-40-40-300098_chatcmpl-099f78b4-5269-40b1-ad3e-a769b471aff0...\n",
      "Fetching observation data for time-09-41-27-645475_chatcmpl-c6fa1373-e406-4945-9d9a-a1e0f7ea71b0...\n",
      "Fetching observation data for time-09-42-11-806758_chatcmpl-90eaea11-4537-4f8f-8877-fbf59f18bc55...\n",
      "Fetching observation data for time-09-35-45-485302_chatcmpl-6c780034-b977-4adc-8781-530abe7aaa95...\n",
      "Fetching observation data for time-09-36-28-027106_chatcmpl-a6ca81ff-22da-4760-890a-303de60d2499...\n",
      "Fetching observation data for time-09-37-19-495271_chatcmpl-64804986-717e-4f6d-b10b-bf2de33fecc5...\n",
      "Fetching observation data for time-09-38-10-219071_chatcmpl-5fb41496-62b5-4fbc-901e-1d8c3f00ade3...\n",
      "Fetching observation data for time-09-39-01-067472_chatcmpl-fbb78fd9-7961-4c79-ac43-2e23b33679cd...\n",
      "Fetching observation data for 9824ec3e-1940-42f8-8d2f-e1ec346fa5ce...\n",
      "Fetching observation data for time-09-32-28-864344_chatcmpl-12c28942-2b96-4b55-8be1-dc73731926ed...\n",
      "Fetching observation data for time-09-33-11-683857_chatcmpl-cf3aeb07-d01f-4c71-9140-ad0796b9201d...\n",
      "Fetching observation data for time-09-34-02-467564_chatcmpl-bcd4028f-c6cc-4b56-a138-f6526d872dcf...\n",
      "Fetching observation data for time-09-29-18-330303_chatcmpl-aa6570c6-20c8-4372-a7f2-f247575765af...\n",
      "Fetching observation data for time-09-30-00-907856_chatcmpl-3eb5e419-02d2-45e8-981c-e77a3a612d4d...\n",
      "Fetching observation data for time-09-30-50-304213_chatcmpl-cd3ab1fc-4871-4857-ad72-641c2196b51f...\n",
      "Fetching observation data for time-09-24-38-759297_chatcmpl-3a0388a1-adc1-4a50-a63e-a416222eee64...\n",
      "Fetching observation data for time-09-25-21-523456_chatcmpl-900fab49-47a1-4a8b-b01d-775e804e9602...\n",
      "Fetching observation data for time-09-26-11-532562_chatcmpl-911fbe0d-78e4-4191-bab9-d9364f52b782...\n",
      "Fetching observation data for time-09-27-31-281705_chatcmpl-79237b54-6d2d-444f-9249-2c05c3d2d982...\n",
      "Fetching observation data for time-09-28-22-443817_chatcmpl-d62e03a3-5837-41bc-95db-0986d57c3032...\n",
      "Fetching observation data for 89e38b09-e44c-4cd6-8ae1-bd3ffcdab182...\n",
      "Fetching observation data for time-09-20-29-847194_chatcmpl-e1eab58f-873b-4289-b4f5-25acb1d3b755...\n",
      "Fetching observation data for time-09-21-12-633506_chatcmpl-cb91f02d-b9bc-4414-8c57-e84b26cab126...\n",
      "Fetching observation data for time-09-22-03-097007_chatcmpl-4d1bac71-fa38-4848-9b9a-87336c95bd5b...\n",
      "Fetching observation data for time-09-22-53-631795_chatcmpl-0f7a9922-5a0d-4aa0-9ffe-801577128b58...\n",
      "Fetching observation data for time-09-23-43-058816_chatcmpl-4019640b-a74a-436b-a15e-5c8573bd5874...\n",
      "Fetching observation data for ce28cbc8-809e-4c5d-bb83-3a73e6cd6904...\n",
      "Fetching observation data for time-09-16-41-331068_chatcmpl-c399713c-9404-4457-b32a-41061d26fcd5...\n",
      "Fetching observation data for time-09-17-24-320906_chatcmpl-2af4ebab-1519-4f7b-8ec3-1010c6d6e9a4...\n",
      "Fetching observation data for time-09-18-07-790935_chatcmpl-2cee2ea5-7948-429d-86ee-c95ca3864a22...\n",
      "Fetching observation data for time-09-18-51-687444_chatcmpl-e8ac1c8d-65cd-4c62-9297-fc09d0db27c8...\n",
      "Fetching observation data for time-09-12-48-746915_chatcmpl-0b05186d-a513-4b05-87be-b96207008569...\n",
      "Fetching observation data for time-09-13-31-340449_chatcmpl-5f4dbc03-93b7-4468-a38a-8c982dfbba0e...\n",
      "Fetching observation data for time-09-14-19-112956_chatcmpl-f8c27a37-d59d-42db-808c-6b80ab5f6d4b...\n",
      "Fetching observation data for time-09-15-03-253547_chatcmpl-582f9a79-41ca-4273-8bbc-d25248e0f8cf...\n",
      "Fetching observation data for time-09-08-43-201076_chatcmpl-65767d38-d9a7-4123-b61a-9ded65112a1e...\n",
      "Fetching observation data for time-09-09-25-787317_chatcmpl-64fcf975-4957-4fb1-8802-3cfd1dbe0851...\n",
      "Fetching observation data for time-09-10-15-251159_chatcmpl-41155ade-1409-41a9-a4bf-9f6d6fca7750...\n",
      "Fetching observation data for time-09-11-03-984622_chatcmpl-40cb8810-8aa7-4f8c-a4c7-5288ea772f0f...\n",
      "Fetching observation data for time-09-11-54-366980_chatcmpl-b8440c61-dd3a-41b1-816f-5f287b7dcde8...\n",
      "Fetching observation data for 690934cc-4515-4bfe-9c01-0f53c4dbd2b4...\n",
      "Fetching observation data for time-09-03-57-628572_chatcmpl-455e73d1-a07b-40fc-921b-7e8e09da2d4b...\n",
      "Fetching observation data for time-09-04-40-231791_chatcmpl-0e632bba-046d-49ba-a221-fbe846d542e4...\n",
      "Fetching observation data for time-09-05-33-488987_chatcmpl-819e8def-8af4-4caa-9181-674f8238dc6b...\n",
      "Fetching observation data for time-09-06-25-144452_chatcmpl-4ae7dbfa-61e9-42e4-ae39-637d24a8133c...\n",
      "Fetching observation data for time-09-07-47-804574_chatcmpl-dd720ea2-7b72-4f48-9ed3-58c971909eaa...\n",
      "Fetching observation data for 2cac57bd-a653-407f-959c-fab0d538ac11...\n",
      "Fetching observation data for time-09-00-35-026354_chatcmpl-7a987ae7-47ea-48a9-8eed-55c0e802861e...\n",
      "Fetching observation data for time-09-01-19-382587_chatcmpl-d784f029-0267-4c56-982e-029c8a53acaf...\n",
      "Fetching observation data for time-09-02-10-086103_chatcmpl-44cc81fd-e1cb-4a97-9720-30e8f479c405...\n",
      "Fetching observation data for time-08-57-14-378578_chatcmpl-367e1299-6be5-4fd0-81c7-52d148aaf595...\n",
      "Fetching observation data for time-08-57-57-149855_chatcmpl-7e2b1aad-8fce-4f3e-89d9-ca073cd4513c...\n",
      "Fetching observation data for time-08-58-54-143084_chatcmpl-d4af3ded-4d37-4bc9-9aef-4f0023125e9e...\n",
      "Fetching observation data for time-08-52-31-729069_chatcmpl-4d193cff-92ff-47d4-a57f-327b61de3873...\n",
      "Fetching observation data for time-08-53-14-429912_chatcmpl-766b6c8d-9a68-4f80-8640-8ec6f57a160a...\n",
      "Fetching observation data for time-08-54-04-715423_chatcmpl-b205e297-1bf0-464d-a2e5-9e2b2ae68057...\n",
      "Fetching observation data for time-08-55-24-356806_chatcmpl-21c5aa22-db9e-4b49-9081-76b88cb0ffb4...\n",
      "Fetching observation data for time-08-56-16-234807_chatcmpl-f4cebba9-046d-4f58-a9bb-c5e2b5fa7be7...\n",
      "Fetching observation data for 5c7a3eca-1bc3-4ad6-b411-3d715f5a3ea0...\n",
      "Fetching observation data for time-08-49-13-821670_chatcmpl-6754a09f-c910-4151-a33c-c8a20ddfcb0e...\n",
      "Fetching observation data for time-08-49-57-166860_chatcmpl-c164b72c-2598-4b0b-b722-a63473899815...\n",
      "Fetching observation data for time-08-50-48-433638_chatcmpl-1653815d-6f8d-462f-bdb5-0338fac4bf46...\n",
      "Fetching observation data for time-08-44-27-634644_chatcmpl-7ad138a1-b99c-4d98-9c79-e46768c01297...\n",
      "Fetching observation data for time-08-45-48-274759_chatcmpl-1bff1d0a-8f8a-4743-a0f5-f181f86c8c01...\n",
      "Fetching observation data for time-08-46-38-746417_chatcmpl-efc16674-b72b-4b6e-b4d9-c67cab8fc214...\n",
      "Fetching observation data for time-08-47-31-098029_chatcmpl-9cc744a2-befc-4c6b-868c-7fcc4231cd42...\n",
      "Fetching observation data for time-08-48-19-806223_chatcmpl-12696ac6-a79e-43db-afbb-be5c0c4b3ff9...\n",
      "Fetching observation data for d2032f48-0590-4710-9ae5-d7a669521bf6...\n",
      "Raw JSON saved to: /Users/hann/Projects/reference-benchmark-tinyml_llm/data_analysis/07.29/raw_export/raw_qwen2.5-coder:32b_1974_tpusg_batch.json\n",
      "Fetching traces for session qwen2.5-coder:32b_1974_psg_batch...\n",
      "Fetching observation data for time-12-24-12-589225_chatcmpl-ae1dc834-491f-4ebe-a8d3-045df6af5f73...\n",
      "Fetching observation data for time-12-24-40-880910_chatcmpl-eb09d8cf-d28f-47d3-9beb-83f629e970f3...\n",
      "Fetching observation data for time-12-25-18-313597_chatcmpl-5e9978d2-2ca0-4d16-af9a-33ecc75b8080...\n",
      "Fetching observation data for time-12-25-55-385048_chatcmpl-e580cc6e-3cf6-4060-a982-2119a54296f1...\n",
      "Fetching observation data for time-12-26-40-128430_chatcmpl-e4ab9881-6904-448a-8632-2dd8921f2cc2...\n",
      "Fetching observation data for 1957eddb-75c1-43fe-97df-3b1ca6cb5460...\n",
      "Fetching observation data for time-12-21-04-008069_chatcmpl-50ffa0c3-2005-43aa-bc99-92cb4a2f4b95...\n",
      "Fetching observation data for time-12-21-31-731977_chatcmpl-3274e171-c121-469c-8ff9-643c65998e65...\n",
      "Fetching observation data for time-12-22-09-206806_chatcmpl-504b43f3-8cf9-4799-b9d7-1873b1698d0a...\n",
      "Fetching observation data for time-12-22-43-093582_chatcmpl-4d9570a1-9ca8-4926-a63b-39586ef68e95...\n",
      "Fetching observation data for time-12-23-18-139253_chatcmpl-65c5996a-1294-4bdd-bbd4-4d7bd8fbe595...\n",
      "Fetching observation data for 3d7f7322-08f2-42a8-bb27-143671b5adc1...\n",
      "Fetching observation data for time-12-17-55-475442_chatcmpl-6c3877d1-d811-43b9-a712-4ab6f9dc27eb...\n",
      "Fetching observation data for time-12-18-23-427915_chatcmpl-318e6697-49dc-444b-ac77-1348f7ebfe98...\n",
      "Fetching observation data for time-12-18-59-986206_chatcmpl-2b94008d-361b-4c01-8129-bb0d295b7d82...\n",
      "Fetching observation data for time-12-19-44-067296_chatcmpl-07fcf7b0-98b0-427d-bebc-11a249c68cd9...\n",
      "Fetching observation data for time-12-14-57-906791_chatcmpl-77b6810a-80a7-4e8e-9c66-b3a15e73b2f7...\n",
      "Fetching observation data for time-12-15-25-786119_chatcmpl-5213d7b5-5ad1-4563-aa45-9e5eb3411fb8...\n",
      "Fetching observation data for time-12-15-58-742483_chatcmpl-bcafd9c8-dacb-4e25-b979-f03d0d96888c...\n",
      "Fetching observation data for time-12-16-31-630182_chatcmpl-6be61a5f-33a3-4652-8c5c-05ccd3ec4cb2...\n",
      "Fetching observation data for time-12-17-12-033030_chatcmpl-7301c0a3-95ea-4a9c-9cca-9653a4659c21...\n",
      "Fetching observation data for 00953b3f-2d5f-45b1-8f8d-fc262fcdbf43...\n",
      "Fetching observation data for time-12-12-04-372695_chatcmpl-e1e794d6-574e-4720-bae8-b6f2dddb090d...\n",
      "Fetching observation data for time-12-12-32-237852_chatcmpl-09a00cb0-7290-46d0-8900-811a167d2098...\n",
      "Fetching observation data for time-12-13-05-212571_chatcmpl-ce2466d5-afd8-41e2-a7d5-39bdaeeb9732...\n",
      "Fetching observation data for time-12-13-46-792242_chatcmpl-167036b1-5cc6-40d2-845a-021912900e72...\n",
      "Fetching observation data for time-12-08-56-784985_chatcmpl-60764cba-9a62-4449-884a-5755b452d70a...\n",
      "Fetching observation data for time-12-09-26-508605_chatcmpl-5ddb046c-bb63-45ce-af2d-f12d9d378475...\n",
      "Fetching observation data for time-12-10-06-824698_chatcmpl-1771905b-54e8-434f-b484-bdb7114c8a42...\n",
      "Fetching observation data for time-12-10-46-757654_chatcmpl-54378740-c468-45cd-90ff-4cc124c2a9a4...\n",
      "Fetching observation data for time-12-11-22-679427_chatcmpl-2dab5189-bfe7-4104-b514-d639fd05ac39...\n",
      "Fetching observation data for a030dc4a-48f8-49dc-86a8-648b0405ab0c...\n",
      "Fetching observation data for time-12-05-46-725150_chatcmpl-1ac6e8c8-b160-4d3c-9ab8-1989f9a410ec...\n",
      "Fetching observation data for time-12-06-14-520890_chatcmpl-0b044a2a-1aea-4c97-b7f4-0b0c821261f7...\n",
      "Fetching observation data for time-12-06-52-475541_chatcmpl-5327bbe1-8238-4c9b-b3f3-de6f7430a991...\n",
      "Fetching observation data for time-12-07-27-337996_chatcmpl-b86f3431-7687-499d-8658-903c5f37f27e...\n",
      "Fetching observation data for time-12-08-08-425622_chatcmpl-e18fe2d3-0bb7-4ae4-b08b-3c6dba92ff49...\n",
      "Fetching observation data for 0b1e6574-192f-46bd-8ac2-7a4fc286ed59...\n",
      "Fetching observation data for time-12-01-38-118686_chatcmpl-fc16436a-e382-438b-8a75-4862c672b58c...\n",
      "Fetching observation data for time-12-02-05-844261_chatcmpl-23c47ea7-09ea-46d0-92ce-e9c04006488a...\n",
      "Fetching observation data for time-12-02-42-528274_chatcmpl-04a86263-1257-4a24-ba3b-d913d42353b6...\n",
      "Fetching observation data for time-12-03-23-082203_chatcmpl-5ab52e8d-6be1-4e69-86b2-77ec9feec17e...\n",
      "Fetching observation data for time-12-03-55-764176_chatcmpl-6f6823c2-f698-4356-91b2-4e817f780eb4...\n",
      "Fetching observation data for a87346f9-0350-4386-97b1-8c3ab55309f7...\n",
      "Fetching observation data for time-11-58-19-187784_chatcmpl-04b9244d-635d-4430-893d-4578ccb03120...\n",
      "Fetching observation data for time-11-58-47-027583_chatcmpl-1c2345ca-f2c7-4ab9-be16-a634262fe533...\n",
      "Fetching observation data for time-11-59-23-594251_chatcmpl-f47709e1-f62e-4748-b84a-804f93e443a6...\n",
      "Fetching observation data for time-12-00-07-388600_chatcmpl-94408827-792f-4652-a8d3-f20a5124b5fd...\n",
      "Fetching observation data for time-12-00-50-041477_chatcmpl-62deb9ea-9ca9-4326-9438-f812e823911a...\n",
      "Fetching observation data for daf4bc20-b369-4102-aaa2-bd2e32c03be9...\n",
      "Fetching observation data for time-11-55-25-598389_chatcmpl-bc85f207-61a9-43de-b742-3536021b2598...\n",
      "Fetching observation data for time-11-55-53-478434_chatcmpl-bea6a009-baae-4908-8de5-08628a0a5e59...\n",
      "Fetching observation data for time-11-56-30-267194_chatcmpl-d7b5e142-609c-424d-9387-9c919fbdaae8...\n",
      "Fetching observation data for time-11-57-04-444271_chatcmpl-69e0b870-9ca2-4373-9006-d3765751cec3...\n",
      "Fetching observation data for time-11-57-40-174782_chatcmpl-cb8a4f84-665f-47a0-b00e-76a2388c91f9...\n",
      "Fetching observation data for ddf3b9cd-2041-4ba0-8799-524bb62f5989...\n",
      "Fetching observation data for time-11-52-13-989439_chatcmpl-e85e8e19-71a9-4d9e-adc4-62fd85e614d4...\n",
      "Fetching observation data for time-11-52-41-692413_chatcmpl-98ba831c-af64-4082-8f81-66f8d8077c6f...\n",
      "Fetching observation data for time-11-53-18-294135_chatcmpl-a2dff52c-371a-4449-81d0-dd6c1414bec7...\n",
      "Fetching observation data for time-11-53-54-799270_chatcmpl-46cc03dc-3f52-4469-a7e9-e8daa3fa7f03...\n",
      "Fetching observation data for time-11-54-36-986781_chatcmpl-fd06ccc6-b409-4b5d-9d68-37bc64ae874c...\n",
      "Fetching observation data for 798ef60b-fe63-4bf3-950e-e9d774a6d637...\n",
      "Fetching observation data for time-11-48-42-420192_chatcmpl-105989f7-28b3-4f22-9b01-3d63bee4e0aa...\n",
      "Fetching observation data for time-11-49-10-261231_chatcmpl-d68a8862-b7fd-478f-83ad-6eb2581e0fe5...\n",
      "Fetching observation data for time-11-49-43-213869_chatcmpl-0e873067-c2d6-4b26-9d41-916ee8b66807...\n",
      "Fetching observation data for time-11-50-22-784079_chatcmpl-da11da49-fc53-4131-9213-a150f8350b89...\n",
      "Fetching observation data for time-11-51-03-294137_chatcmpl-b71678e8-d623-412d-b04d-a1b8b8554d5c...\n",
      "Fetching observation data for time-11-45-11-865849_chatcmpl-61e0e9a5-e215-46b3-9429-ab568cb54e3c...\n",
      "Fetching observation data for time-11-45-39-547032_chatcmpl-03993a62-4ba4-480d-9417-7853109a0740...\n",
      "Fetching observation data for time-11-46-13-256610_chatcmpl-2b326386-0a82-4b5b-b9b1-20fe680025d1...\n",
      "Fetching observation data for time-11-46-54-182571_chatcmpl-e6ba6d4d-04c5-432e-a808-0928cd7aa261...\n",
      "Fetching observation data for time-11-47-29-560952_chatcmpl-13750c22-3be3-4001-a51c-53d8001ddfe9...\n",
      "Fetching observation data for time-11-42-17-187314_chatcmpl-dc90bb31-3197-402e-a1cf-70c661c3cada...\n",
      "Fetching observation data for time-11-42-44-808583_chatcmpl-bd587caa-1fab-48d2-a90f-8640a72fa0c1...\n",
      "Fetching observation data for time-11-43-20-652070_chatcmpl-c88a73bb-fe9b-4724-a711-522b72f536d2...\n",
      "Fetching observation data for time-11-43-54-275097_chatcmpl-57e22996-4a57-494c-8ec9-78b4bf13acb4...\n",
      "Fetching observation data for time-11-44-28-971971_chatcmpl-bd3f45ee-cb2f-4cd1-be86-2fb73beabce1...\n",
      "Fetching observation data for f5345885-df68-4c9d-9223-61a77b0c542a...\n",
      "Fetching observation data for time-11-39-15-590431_chatcmpl-14e93b4e-d9cd-45a5-b004-2ec9239411ce...\n",
      "Fetching observation data for time-11-39-43-238853_chatcmpl-acd9330f-8097-4dee-af47-f3df09753d3a...\n",
      "Fetching observation data for time-11-40-19-870199_chatcmpl-097b5981-1cb9-43e8-b7de-a775fbc58cf0...\n",
      "Fetching observation data for time-11-40-53-748816_chatcmpl-1b300a6f-b96b-4d24-93f5-98673d94520f...\n",
      "Fetching observation data for time-11-41-32-946123_chatcmpl-d05c2613-7a88-4653-ad40-a8fe8bc2f558...\n",
      "Fetching observation data for 913ee4de-a3ea-4c34-990c-dc64a2190772...\n",
      "Fetching observation data for time-11-36-03-967475_chatcmpl-3e63d080-8e70-4932-a14e-7a91c918d9f8...\n",
      "Fetching observation data for time-11-36-31-731218_chatcmpl-1abf4181-c2b1-41f2-ab90-8e26c8319292...\n",
      "Fetching observation data for time-11-37-08-395761_chatcmpl-afc7616b-b595-41cf-aa31-3ad6e4c944f4...\n",
      "Fetching observation data for time-11-37-46-022098_chatcmpl-676b908c-a450-437a-8d12-5e4bc1d0c1a5...\n",
      "Fetching observation data for time-11-38-28-750083_chatcmpl-77d2b7ec-0ea1-40ed-8cda-f16b7fe9502d...\n",
      "Fetching observation data for f60b4de8-6bd5-49c4-a8a4-9a6ce76e3ef7...\n",
      "Fetching observation data for time-11-32-29-404608_chatcmpl-c448cf06-8342-4ca8-8379-3d56a9bfcd93...\n",
      "Fetching observation data for time-11-32-57-125463_chatcmpl-defcbc1c-1e12-464a-8938-880bb05ad8f6...\n",
      "Fetching observation data for time-11-33-33-518144_chatcmpl-6970c649-33c7-435d-9a42-f9cb58a5402f...\n",
      "Fetching observation data for time-11-35-21-545132_chatcmpl-eeae8f77-7c61-4277-807b-142d49a57740...\n",
      "Fetching observation data for time-11-29-20-124554_chatcmpl-05cfb618-d009-405a-87d9-b1ded02b8bb4...\n",
      "Fetching observation data for time-11-29-47-691787_chatcmpl-9721e685-7d7d-4871-b769-366bdaf10528...\n",
      "Fetching observation data for time-11-30-20-469506_chatcmpl-0671fd06-c2bb-459e-83f2-3a2709494729...\n",
      "Fetching observation data for time-11-30-57-555359_chatcmpl-ed22882e-51b0-4d94-b934-0804c9b2d72a...\n",
      "Fetching observation data for time-11-31-41-358338_chatcmpl-3cefd176-a3f6-4a16-b0c9-80b0ff131b21...\n",
      "Fetching observation data for 00c8ed04-c46b-4176-8c9e-1b3ceb480fa4...\n",
      "Fetching observation data for time-11-25-34-570947_chatcmpl-1d6db1a9-fca4-4290-a12b-39d68d86c439...\n",
      "Fetching observation data for time-11-26-02-789927_chatcmpl-8e18925f-8a22-430b-872c-c97bc5e62416...\n",
      "Fetching observation data for time-11-26-39-474094_chatcmpl-680f0832-33eb-459b-ab79-91007e90417d...\n",
      "Fetching observation data for time-11-27-22-104136_chatcmpl-401da812-d73e-4664-ad0c-2296db35caee...\n",
      "Fetching observation data for time-11-28-08-209079_chatcmpl-776189bf-c2bc-4607-a7ee-ac811b928df4...\n",
      "Fetching observation data for time-11-22-08-853674_chatcmpl-e7127010-9a9a-46f7-815f-101415ac0d8f...\n",
      "Fetching observation data for time-11-22-36-496133_chatcmpl-9c08e097-97f9-4521-83f2-d3d80b9e04ea...\n",
      "Fetching observation data for time-11-23-09-229646_chatcmpl-8344d191-c92b-4ffe-8bbf-cef1593f1b6f...\n",
      "Fetching observation data for time-11-23-39-835901_chatcmpl-6b598239-de91-4636-9d27-557ea0a48648...\n",
      "Fetching observation data for time-11-24-23-422090_chatcmpl-e7aee2c9-206b-44df-9c8c-22abbce13e7c...\n",
      "Fetching observation data for time-11-17-37-203185_chatcmpl-78bfe30e-84af-4c31-b796-f39571600652...\n",
      "Fetching observation data for time-11-18-04-800185_chatcmpl-cea4b2d8-30da-47ca-bbce-eb4cb41b3b9c...\n",
      "Fetching observation data for time-11-18-44-898999_chatcmpl-6e979098-ebd0-4f95-97fb-f308e4d2b504...\n",
      "Fetching observation data for time-11-20-44-022813_chatcmpl-48c0e885-277e-4151-8e4c-c8715a2a8200...\n",
      "Fetching observation data for time-11-21-22-685215_chatcmpl-9bfa8894-31f9-4635-bd15-3fde266fcb85...\n",
      "Fetching observation data for 105c9d5c-8aac-431f-98f8-5d662827eba9...\n",
      "Fetching observation data for time-11-14-02-125049_chatcmpl-60159d88-c995-4653-96e0-da5424ba445a...\n",
      "Fetching observation data for time-11-14-29-746557_chatcmpl-b919d1ce-d7ae-4790-9d5d-3887f3b7eb01...\n",
      "Fetching observation data for time-11-15-06-332557_chatcmpl-0ae748a0-18e0-473c-b22a-49b20e27d9ec...\n",
      "Fetching observation data for time-11-15-41-543646_chatcmpl-efd088b6-e9f3-4b2b-9434-6a5516a94ddf...\n",
      "Fetching observation data for time-11-16-23-479302_chatcmpl-b29b25a7-a31e-4024-b9d6-00bbbe598547...\n",
      "Fetching observation data for time-11-10-00-519885_chatcmpl-88160416-5187-4f43-8645-cc64222b769c...\n",
      "Fetching observation data for time-11-10-28-249770_chatcmpl-ee717daa-5b22-4644-95c8-11c67a7a3331...\n",
      "Fetching observation data for time-11-11-04-897054_chatcmpl-13f5d786-d6e1-4e9c-ac87-7f497c3c4ff7...\n",
      "Fetching observation data for time-11-12-53-929864_chatcmpl-669b3ce6-d847-4259-849c-1317293569ef...\n",
      "Fetching observation data for time-11-13-26-055341_chatcmpl-d79b8a16-7805-4736-9d59-3759952e706e...\n",
      "Fetching observation data for 70ff5377-de33-4f8e-9bcc-f5501ac1fae3...\n",
      "Fetching observation data for time-11-07-03-927775_chatcmpl-63ffd240-a13d-45ca-8864-587cce4caa15...\n",
      "Fetching observation data for time-11-07-31-524626_chatcmpl-e073c8a4-9f37-42ac-8a47-e2f121f639b0...\n",
      "Fetching observation data for time-11-08-08-185085_chatcmpl-2ad7efde-e905-4000-9f7e-c8405eaeff2b...\n",
      "Fetching observation data for time-11-08-42-844222_chatcmpl-55315418-27c7-4f10-ab19-314da04d3599...\n",
      "Fetching observation data for time-11-03-37-349238_chatcmpl-33b7bc70-041a-4b0a-9ba3-c743fc744de9...\n",
      "Fetching observation data for time-11-04-05-167234_chatcmpl-4f0d3750-0b1b-4084-8239-a503267f5d22...\n",
      "Fetching observation data for time-11-04-41-455102_chatcmpl-f10db152-8fb3-461a-83c7-1edb98fbd9c1...\n",
      "Fetching observation data for time-11-05-16-241762_chatcmpl-a6b335ac-dbcd-48f0-a6eb-6d47413febf9...\n",
      "Fetching observation data for time-11-05-55-322366_chatcmpl-27ba2235-a130-4f82-b5a6-bc73098c2eff...\n",
      "Fetching observation data for time-11-00-20-806951_chatcmpl-b880b0dd-dfb4-47ea-a22c-caf910d57585...\n",
      "Fetching observation data for time-11-00-49-010968_chatcmpl-4a3c7ace-c798-4d83-9de0-22decb5d7096...\n",
      "Fetching observation data for time-11-01-27-048239_chatcmpl-b40cad7b-05f2-4091-8404-ebfa9f4aadbc...\n",
      "Fetching observation data for time-11-02-10-740472_chatcmpl-3d8a4cd2-7c9f-4f3c-9759-4e9bd9f139fd...\n",
      "Fetching observation data for time-11-02-56-357579_chatcmpl-43421bc1-d173-4aa8-97dd-6bba7db13959...\n",
      "Fetching observation data for 7e96817b-57f0-4a41-b943-4f888ddb0d37...\n",
      "Fetching observation data for time-10-57-25-258320_chatcmpl-be7264aa-606e-47d6-8687-fc4b180593af...\n",
      "Fetching observation data for time-10-57-52-913767_chatcmpl-86ab4145-6e8e-43ad-bf1b-11ba04148ea2...\n",
      "Fetching observation data for time-10-58-33-524525_chatcmpl-c9329b42-7f94-448a-8a6a-1576c41cda48...\n",
      "Fetching observation data for time-10-59-05-208922_chatcmpl-87eb2dfb-c8f1-4411-bcb2-5e09b55f5944...\n",
      "Fetching observation data for time-10-59-39-813367_chatcmpl-aaa3cc6b-369c-4aae-b70f-1860b1d8e9ab...\n",
      "Fetching observation data for 8baf7ffe-abf1-44c2-a475-7697de2a0824...\n",
      "Fetching observation data for time-10-54-28-695949_chatcmpl-51e90f07-9011-47cd-9a43-a989dff4a6f4...\n",
      "Fetching observation data for time-10-54-58-380761_chatcmpl-1b9958c2-7b98-480b-81a6-7c624f31ea60...\n",
      "Fetching observation data for time-10-55-34-793969_chatcmpl-8dace88f-fdc0-484d-93d2-532db5e21837...\n",
      "Fetching observation data for time-10-56-15-613872_chatcmpl-d7b3706a-0928-4ba6-853f-c27968192f28...\n",
      "Fetching observation data for time-10-51-32-102209_chatcmpl-c4f55d26-b211-4bd3-9bce-e3b8b2510a9b...\n",
      "Fetching observation data for time-10-51-59-805235_chatcmpl-b6e0b794-c719-45f3-be2f-514ad39e96d1...\n",
      "Fetching observation data for time-10-52-35-795635_chatcmpl-196520a5-e393-481b-b6b2-b628d4854e5e...\n",
      "Fetching observation data for time-10-53-10-810038_chatcmpl-193bcef6-a7a8-4114-bb3b-ba4140cbf8c2...\n",
      "Fetching observation data for time-10-47-15-530016_chatcmpl-8b6d5b63-b756-4e5d-a1fb-03a9dda6008a...\n",
      "Fetching observation data for time-10-47-43-425719_chatcmpl-a6f0c715-3933-47b8-b945-f6124fb847da...\n",
      "Fetching observation data for time-10-48-20-222598_chatcmpl-40b490f8-e026-4fe0-8f6c-fd641407ecf5...\n",
      "Fetching observation data for time-10-48-56-661689_chatcmpl-f02a2571-88bc-4aeb-a192-2b0ae13da04c...\n",
      "Fetching observation data for time-10-50-42-454073_chatcmpl-b3d17a5c-022f-45b0-a567-cfaf392771a1...\n",
      "Raw JSON saved to: /Users/hann/Projects/reference-benchmark-tinyml_llm/data_analysis/07.29/raw_export/raw_qwen2.5-coder:32b_1974_psg_batch.json\n"
     ]
    }
   ],
   "source": [
    "# ALTERNATIVE TO 2.\n",
    "import os\n",
    "import json\n",
    "from time import sleep\n",
    "from langfuse import Langfuse\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "\n",
    "# LANGFUSE_SERVICE_PUBLIC_KEY = \"pk-lf-559a2c0f-ee29-4c32-944c-bf73b5f0ce28\"\n",
    "# LANGFUSE_SERVICE_SECRET_KEY = \"sk-lf-75f8bf7f-a5db-4756-b0dd-d758a2a292c8\"\n",
    "# LANGFUSE_SERVICE_HOST = \"https://langfuse.hann.fi\"\n",
    "\n",
    "\n",
    "if LOCAL_HOST:\n",
    "    langfuse = Langfuse(\n",
    "        secret_key=\"sk-lf-75f8bf7f-a5db-4756-b0dd-d758a2a292c8\",\n",
    "        public_key=\"pk-lf-559a2c0f-ee29-4c32-944c-bf73b5f0ce28\",\n",
    "        host=\"https://langfuse.hann.fi\",\n",
    "    )\n",
    "else:\n",
    "    langfuse = Langfuse(\n",
    "        secret_key=LANGFUSE_SERVICE_SECRET_KEY,\n",
    "        public_key=LANGFUSE_SERVICE_PUBLIC_KEY,\n",
    "        host=LANGFUSE_SERVICE_HOST,\n",
    "    )\n",
    "\n",
    "API_invok_count = 0\n",
    "query_range_num_run = {\"start\": 0, \"end\": 1}\n",
    "\n",
    "\n",
    "class CustomJSONEncoder(json.JSONEncoder):\n",
    "    def __init__(self, *args, LOCAL_HOST=True, **kwargs):\n",
    "        self.LOCAL_HOST = LOCAL_HOST\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "    def default(self, obj):\n",
    "        if isinstance(obj, datetime):\n",
    "            return obj.isoformat()\n",
    "        if hasattr(obj, \"__dict__\"):\n",
    "            data = obj.__dict__.copy()\n",
    "            if \"observations\" in data:\n",
    "                data[\"observations\"] = [\n",
    "                    fetch_observation_data(obs, self.LOCAL_HOST)\n",
    "                    for obs in data[\"observations\"]\n",
    "                ]\n",
    "\n",
    "            return data\n",
    "        return super().default(obj)\n",
    "\n",
    "\n",
    "def fetch_observation_data(observation_id, LOCAL_HOST):\n",
    "    \"\"\"\n",
    "    Fetches observation data from Langfuse and returns its dictionary representation.\n",
    "    \"\"\"\n",
    "    print(f\"Fetching observation data for {observation_id}...\")\n",
    "    global API_invok_count\n",
    "    if API_invok_count >= 0 and not LOCAL_HOST:\n",
    "        print(\"Waiting for 3 seconds to fetch observation data...\")\n",
    "        for _ in tqdm(range(3), desc=\"Progress\", unit=\"s\"):\n",
    "            sleep(1)\n",
    "        API_invok_count = 0\n",
    "\n",
    "    observation_response = langfuse.fetch_observation(observation_id)\n",
    "    API_invok_count += 1\n",
    "\n",
    "    return observation_response.data.dict()\n",
    "\n",
    "\n",
    "def fetch_and_save_complete_data(session_id_list, raw_export_dir, LOCAL_HOST):\n",
    "    \"\"\"\n",
    "    Fetches complete trace data for each session ID and saves it to JSON files.\n",
    "\n",
    "    Parameters:\n",
    "        session_id_list (list): List of session IDs to process.\n",
    "        raw_export_dir (str): Directory path to save raw JSON files.\n",
    "    \"\"\"\n",
    "\n",
    "    def save_complete_data(session_id):\n",
    "        global API_invok_count\n",
    "        if API_invok_count >= 0 and not LOCAL_HOST:\n",
    "            print(\"Waiting for 4 seconds to fetch traces...\")\n",
    "            for _ in tqdm(range(4), desc=\"Progress\", unit=\"s\"):\n",
    "                sleep(1)\n",
    "            API_invok_count = 0\n",
    "\n",
    "        fetch_traces_response = langfuse.fetch_traces(session_id=session_id)\n",
    "        API_invok_count += 1\n",
    "\n",
    "        print(f\"Fetching traces for session {session_id}...\")\n",
    "        # Create directories if they don't exist\n",
    "        os.makedirs(raw_export_dir, exist_ok=True)\n",
    "\n",
    "        # Save complete data to JSON file\n",
    "        # if session_id.startswith(\"da0a\"):\n",
    "        #     session_id = \"phi4_\" + session_id\n",
    "        if \"tpsg\" in session_id:\n",
    "            session_id_ = session_id.replace(\"tpsg\", \"tpusg\")\n",
    "        else:\n",
    "            session_id_ = session_id\n",
    "            \n",
    "        raw_path = os.path.join(raw_export_dir, f\"raw_{session_id_}.json\")\n",
    "        with open(raw_path, \"w\") as f:\n",
    "            json.dump(fetch_traces_response, f, cls=CustomJSONEncoder, indent=2)\n",
    "\n",
    "        print(f\"Raw JSON saved to: {raw_path}\")\n",
    "\n",
    "    for session_id in session_id_list:\n",
    "        save_complete_data(session_id)\n",
    "\n",
    "\n",
    "fetch_and_save_complete_data(session_id_list, raw_export_dir, LOCAL_HOST)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Trim data\n",
    "\n",
    "Here also intercept the runs with fatal errors that need to be excluded from the analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPAN error_cc_tpusg_failure_signal_tpu_sketch_generator: Failed. Last error: Traceback (most recent call last):\n",
      "  File \"script_4606bee4_1753860846.py\", line 67, in <module>\n",
      "    num_detections = int(interpreter.get_tensor(output_details[2]['index'])[0])  # Access the scalar value directly\n",
      "TypeError: only size-1 arrays can be converted to Python scalars\n",
      "SPAN error_1a_tpusg_failure_signal_tpu_sketch_generator: Failed. Last error: Traceback (most recent call last):\n",
      "  File \"script_5eb8ea1b_1753860359.py\", line 66, in <module>\n",
      "    num_detections = int(interpreter.get_tensor(output_details[2]['index']))  # Correctly extract the scalar value\n",
      "TypeError: only size-1 arrays can be converted to Python scalars\n",
      "SPAN error_1e_tpusg_failure_signal_tpu_sketch_generator: Failed. Last error: Traceback (most recent call last):\n",
      "  File \"script_e8eaa798_1753859873.py\", line 66, in <module>\n",
      "    num_detections = int(interpreter.get_tensor(output_details[1]['index']))  # Correctly access the number of detections\n",
      "TypeError: only size-1 arrays can be converted to Python scalars\n",
      "SPAN error_d8_tpusg_failure_signal_tpu_sketch_generator: Failed. Last error: Traceback (most recent call last):\n",
      "  File \"script_7ba23477_1753859606.py\", line 66, in <module>\n",
      "    num_detections = int(interpreter.get_tensor(output_details[2]['index'])[0])  # Extract scalar value from array\n",
      "TypeError: only size-1 arrays can be converted to Python scalars\n",
      "SPAN error_23_tpusg_failure_signal_tpu_sketch_generator: Failed. Last error: Traceback (most recent call last):\n",
      "  File \"script_4e1e0a90_1753858298.py\", line 66, in <module>\n",
      "    num_detections = int(interpreter.get_tensor(output_details[2]['index'])[0])  # Correctly extract the scalar value\n",
      "TypeError: only size-1 arrays can be converted to Python scalars\n",
      "SPAN error_9e_tpusg_failure_signal_tpu_sketch_generator: Failed. Last error: Traceback (most recent call last):\n",
      "  File \"script_8665b9fd_1753857583.py\", line 66, in <module>\n",
      "    num_detections = int(interpreter.get_tensor(output_details[2]['index'])[0])  # Extract scalar value from array\n",
      "TypeError: only size-1 arrays can be converted to Python scalars\n",
      "SPAN error_d5_tpusg_failure_signal_tpu_sketch_generator: Failed. Last error: Traceback (most recent call last):\n",
      "  File \"script_763939cc_1753856944.py\", line 66, in <module>\n",
      "    num_detections = int(interpreter.get_tensor(output_details[2]['index'])[0])  # Extract the single element\n",
      "TypeError: only size-1 arrays can be converted to Python scalars\n",
      "SPAN error_ca_tpusg_failure_signal_tpu_sketch_generator: Failed. Last error: Traceback (most recent call last):\n",
      "  File \"script_82a0d02e_1753856664.py\", line 66, in <module>\n",
      "    num_detections = int(interpreter.get_tensor(output_details[2]['index']))  # Correctly extract the scalar value\n",
      "TypeError: only size-1 arrays can be converted to Python scalars\n",
      "SPAN error_04_tpusg_failure_signal_tpu_sketch_generator: Failed. Last error: Traceback (most recent call last):\n",
      "  File \"script_d0f701b4_1753855954.py\", line 67, in <module>\n",
      "    num_detections = int(interpreter.get_tensor(output_details[2]['index'])[0])  # Access the scalar value directly\n",
      "TypeError: only size-1 arrays can be converted to Python scalars\n",
      "SPAN error_c9_tpusg_failure_signal_tpu_sketch_generator: Failed. Last error: Traceback (most recent call last):\n",
      "  File \"script_212c41ea_1753855708.py\", line 66, in <module>\n",
      "    num_detections = int(interpreter.get_tensor(output_details[2]['index'])[0])  # Extract the scalar value\n",
      "TypeError: only size-1 arrays can be converted to Python scalars\n",
      "SPAN error_c0_tpusg_failure_signal_tpu_sketch_generator: Failed. Last error: Traceback (most recent call last):\n",
      "  File \"script_f91ac5c7_1753855020.py\", line 66, in <module>\n",
      "    num_detections = int(interpreter.get_tensor(output_details[2]['index'])[0])  # Extract the single element\n",
      "TypeError: only size-1 arrays can be converted to Python scalars\n",
      "SPAN error_6f_tpusg_failure_signal_tpu_sketch_generator: Failed. Last error: Traceback (most recent call last):\n",
      "  File \"script_46a346d5_1753854539.py\", line 66, in <module>\n",
      "    num_detections = int(interpreter.get_tensor(output_details[2]['index'])[0])  # Extract the single element\n",
      "TypeError: only size-1 arrays can be converted to Python scalars\n",
      "Successfully processed and saved trimmed data for session qwen2.5-coder:32b_1974_tpusg_batch\n",
      "SPAN error_3c_psg_failure_signal_py_sketch_generator: Failed. Last error: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250730122715_psg_qwen2.5-coder:32b/tmp_20250730122715_psg_qwen2.5-coder:32b.py\", line 66, in <module>\n",
      "    label = labels[i]\n",
      "TypeError: only integer scalar arrays can be converted to a scalar index\n",
      "\n",
      "SPAN error_7d_psg_failure_signal_py_sketch_generator: Failed. Last error: Traceback (most recent call last):\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250730122406_psg_qwen2.5-coder:32b/tmp_20250730122406_psg_qwen2.5-coder:32b.py\", line 21, in <module>\n",
      "    with open(label_path, 'r') as f:\n",
      "FileNotFoundError: [Errno 2] No such file or directory: '/path/to/labelmap.txt'\n",
      "\n",
      "SPAN error_d5_psg_failure_signal_py_sketch_generator: Failed. Last error: Traceback (most recent call last):\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250730121748_psg_qwen2.5-coder:32b/tmp_20250730121748_psg_qwen2.5-coder:32b.py\", line 20, in <module>\n",
      "    with open(label_path, 'r') as f:\n",
      "FileNotFoundError: [Errno 2] No such file or directory: 'path_to_labelmap.txt'\n",
      "\n",
      "SPAN error_fb_psg_failure_signal_py_sketch_generator: Failed. Last error: Traceback (most recent call last):\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250730121157_psg_qwen2.5-coder:32b/tmp_20250730121157_psg_qwen2.5-coder:32b.py\", line 21, in <module>\n",
      "    with open(label_path, 'r') as f:\n",
      "FileNotFoundError: [Errno 2] No such file or directory: 'your_labelmap.txt'\n",
      "\n",
      "SPAN error_3e_psg_failure_signal_py_sketch_generator: Failed. Last error: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250730120850_psg_qwen2.5-coder:32b/tmp_20250730120850_psg_qwen2.5-coder:32b.py\", line 62, in <module>\n",
      "    interpreter.set_tensor(input_details[0]['index'], input_frame)\n",
      "  File \"/home/wuguangh/.conda/envs/tinyml/lib/python3.10/site-packages/tflite_runtime/interpreter.py\", line 720, in set_tensor\n",
      "    self._interpreter.SetTensor(tensor_index, value)\n",
      "ValueError: Cannot set tensor: Got value of type FLOAT32 but expected type UINT8 for input 175, name: normalized_input_image_tensor \n",
      "\n",
      "SPAN error_0e_psg_failure_signal_py_sketch_generator: Failed. Last error: Traceback (most recent call last):\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250730120540_psg_qwen2.5-coder:32b/tmp_20250730120540_psg_qwen2.5-coder:32b.py\", line 140, in <module>\n",
      "    interpreter = tf.lite.Interpreter(model_path=model_path)\n",
      "NameError: name 'tf' is not defined\n",
      "\n",
      "SPAN error_52_psg_failure_signal_py_sketch_generator: Failed. Last error: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250730120131_psg_qwen2.5-coder:32b/tmp_20250730120131_psg_qwen2.5-coder:32b.py\", line 51, in <module>\n",
      "    interpreter.set_tensor(input_details[0]['index'], frame_normalized)\n",
      "  File \"/home/wuguangh/.conda/envs/tinyml/lib/python3.10/site-packages/tflite_runtime/interpreter.py\", line 720, in set_tensor\n",
      "    self._interpreter.SetTensor(tensor_index, value)\n",
      "ValueError: Cannot set tensor: Got value of type FLOAT64 but expected type UINT8 for input 175, name: normalized_input_image_tensor \n",
      "\n",
      "SPAN error_32_psg_failure_signal_py_sketch_generator: Failed. Last error: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "OpenCV: FFMPEG: tag 0x44495658/'XVID' is not supported with codec id 12 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n",
      "OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250730115812_psg_qwen2.5-coder:32b/tmp_20250730115812_psg_qwen2.5-coder:32b.py\", line 62, in <module>\n",
      "    label = labels[top_index]\n",
      "TypeError: only integer scalar arrays can be converted to a scalar index\n",
      "\n",
      "SPAN error_48_psg_failure_signal_py_sketch_generator: Failed. Last error: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "OpenCV: FFMPEG: tag 0x44495658/'XVID' is not supported with codec id 12 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n",
      "OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250730115519_psg_qwen2.5-coder:32b/tmp_20250730115519_psg_qwen2.5-coder:32b.py\", line 70, in <module>\n",
      "    class_index = int(output_data[0])\n",
      "TypeError: only length-1 arrays can be converted to Python scalars\n",
      "\n",
      "SPAN error_23_psg_failure_signal_py_sketch_generator: Failed. Last error: Traceback (most recent call last):\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250730114505_psg_qwen2.5-coder:32b/tmp_20250730114505_psg_qwen2.5-coder:32b.py\", line 20, in <module>\n",
      "    with open(label_path, 'r') as f:\n",
      "FileNotFoundError: [Errno 2] No such file or directory: '/path/to/labelmap.txt'\n",
      "\n",
      "SPAN error_43_psg_failure_signal_py_sketch_generator: Failed. Last error: Traceback (most recent call last):\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250730114210_psg_qwen2.5-coder:32b/tmp_20250730114210_psg_qwen2.5-coder:32b.py\", line 21, in <module>\n",
      "    with open(label_path, 'r') as f:\n",
      "FileNotFoundError: [Errno 2] No such file or directory: '/path/to/labelmap.txt'\n",
      "\n",
      "SPAN error_a5_psg_failure_signal_py_sketch_generator: Failed. Last error: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250730113908_psg_qwen2.5-coder:32b/tmp_20250730113908_psg_qwen2.5-coder:32b.py\", line 62, in <module>\n",
      "    bbox, score, class_id = detection[:4], detection[4], int(detection[5])\n",
      "TypeError: only length-1 arrays can be converted to Python scalars\n",
      "\n",
      "SPAN error_c9_psg_failure_signal_py_sketch_generator: Failed. Last error: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "OpenCV: FFMPEG: tag 0x44495658/'XVID' is not supported with codec id 12 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n",
      "OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250730113222_psg_qwen2.5-coder:32b/tmp_20250730113222_psg_qwen2.5-coder:32b.py\", line 63, in <module>\n",
      "    num_detections = int(output_data[0][0])\n",
      "TypeError: only length-1 arrays can be converted to Python scalars\n",
      "\n",
      "SPAN error_7f_psg_failure_signal_py_sketch_generator: Failed. Last error: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250730112201_psg_qwen2.5-coder:32b/tmp_20250730112201_psg_qwen2.5-coder:32b.py\", line 69, in <module>\n",
      "    confidence_score = scores[predicted_class_index]\n",
      "IndexError: index 19 is out of bounds for axis 0 with size 10\n",
      "\n",
      "SPAN error_7a_psg_failure_signal_py_sketch_generator: Failed. Last error: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "OpenCV: FFMPEG: tag 0x47504a4d/'MJPG' is not supported with codec id 7 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n",
      "OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250730111355_psg_qwen2.5-coder:32b/tmp_20250730111355_psg_qwen2.5-coder:32b.py\", line 57, in <module>\n",
      "    label = labels[i]\n",
      "TypeError: only integer scalar arrays can be converted to a scalar index\n",
      "\n",
      "SPAN error_37_psg_failure_signal_py_sketch_generator: Failed. Last error: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250730110330_psg_qwen2.5-coder:32b/tmp_20250730110330_psg_qwen2.5-coder:32b.py\", line 49, in <module>\n",
      "    interpreter.set_tensor(input_details[0]['index'], input_data)\n",
      "  File \"/home/wuguangh/.conda/envs/tinyml/lib/python3.10/site-packages/tflite_runtime/interpreter.py\", line 720, in set_tensor\n",
      "    self._interpreter.SetTensor(tensor_index, value)\n",
      "ValueError: Cannot set tensor: Got value of type FLOAT32 but expected type UINT8 for input 175, name: normalized_input_image_tensor \n",
      "\n",
      "SPAN error_b7_psg_failure_signal_py_sketch_generator: Failed. Last error: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250730110013_psg_qwen2.5-coder:32b/tmp_20250730110013_psg_qwen2.5-coder:32b.py\", line 49, in <module>\n",
      "    interpreter.set_tensor(input_details[0]['index'], input_data)\n",
      "  File \"/home/wuguangh/.conda/envs/tinyml/lib/python3.10/site-packages/tflite_runtime/interpreter.py\", line 720, in set_tensor\n",
      "    self._interpreter.SetTensor(tensor_index, value)\n",
      "ValueError: Cannot set tensor: Got value of type FLOAT32 but expected type UINT8 for input 175, name: normalized_input_image_tensor \n",
      "\n",
      "Successfully processed and saved trimmed data for session qwen2.5-coder:32b_1974_psg_batch\n",
      "Total 0 traces skipped. They are []\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "skipped_traces = []\n",
    "\n",
    "\n",
    "def process_existing_observation(observation):\n",
    "    \"\"\"\n",
    "    Processes an existing observation dictionary by trimming unwanted keys.\n",
    "    \"\"\"\n",
    "    unwanted_observation_keys = [\n",
    "        \"completionStartTime\",\n",
    "        \"metadata\",\n",
    "        \"timeToFirstToken\",\n",
    "        \"createdAt\",\n",
    "        \"usageDetails\",\n",
    "        \"usage\",\n",
    "        \"projectId\",\n",
    "        \"unit\",\n",
    "        \"updatedAt\",\n",
    "        \"version\",\n",
    "        \"parentObservationId\",\n",
    "        \"promptId\",\n",
    "        \"promptName\",\n",
    "        \"promptVersion\",\n",
    "        \"modelId\",\n",
    "        \"inputPrice\",\n",
    "        \"outputPrice\",\n",
    "        \"totalPrice\",\n",
    "        # \"modelParameters\",\n",
    "        \"input\",\n",
    "        \"output\",\n",
    "    ]\n",
    "\n",
    "    # If observation is a dictionary containing observation data\n",
    "    if isinstance(observation, dict):\n",
    "        trimmed_observation = {\n",
    "            k: v for k, v in observation.items() if k not in unwanted_observation_keys\n",
    "        }\n",
    "        return trimmed_observation\n",
    "    return observation\n",
    "\n",
    "\n",
    "def trim_data(data):\n",
    "    \"\"\"\n",
    "    Recursively trims the data structure.\n",
    "    \"\"\"\n",
    "\n",
    "    if isinstance(data, dict):\n",
    "        # Process the current dictionary\n",
    "        unwanted_trace_keys = [\n",
    "            \"release\",\n",
    "            \"version\",\n",
    "            \"user_id\",\n",
    "            \"public\",\n",
    "            \"html_path\",\n",
    "            \"scores\",\n",
    "            \"bookmarked\",\n",
    "            \"projectId\",\n",
    "            \"externalId\",\n",
    "            \"page\",\n",
    "            \"limit\",\n",
    "            \"total_pages\",\n",
    "        ]\n",
    "\n",
    "        # If this is a trace that contains observations, check for fatal errors\n",
    "        if \"observations\" in data:\n",
    "            # Check for SPAN observations with fatal errors before processing\n",
    "            skip_trace = False\n",
    "            for obs in data[\"observations\"]:\n",
    "                if isinstance(obs, dict) and obs.get(\"name\").startswith(\"error\"):\n",
    "                    status_message = obs.get(\"statusMessage\", \"\")\n",
    "                    ob_name = obs.get(\"name\")\n",
    "                    print(f\"SPAN {ob_name}: {status_message}\")\n",
    "\n",
    "                    if \"Fatal error\" in status_message:\n",
    "                        print(f\"Found Fatal error in SPAN observation, skipping trace\")\n",
    "                        skip_trace = True\n",
    "                        skipped_traces.append(data[\"name\"])\n",
    "                        break\n",
    "\n",
    "            if skip_trace:\n",
    "                return None  # Signal to skip this trace\n",
    "\n",
    "        # Create a new dictionary with wanted keys and recursively process values\n",
    "        trimmed_data = {}\n",
    "        for key, value in data.items():\n",
    "            if key not in unwanted_trace_keys:\n",
    "                if key == \"observations\":\n",
    "                    # Special handling for observations\n",
    "                    trimmed_data[key] = [\n",
    "                        process_existing_observation(obs) for obs in value\n",
    "                    ]\n",
    "                elif isinstance(value, (dict, list)):\n",
    "                    # Recursively process nested structures\n",
    "                    trimmed_data[key] = trim_data(value)\n",
    "                else:\n",
    "                    trimmed_data[key] = value\n",
    "\n",
    "        return trimmed_data\n",
    "\n",
    "    elif isinstance(data, list):\n",
    "        # Recursively process each item in the list\n",
    "        processed_items = []\n",
    "        for item in data:\n",
    "            processed_item = trim_data(item)\n",
    "            if processed_item is not None:  # Only add items that weren't filtered out\n",
    "                processed_items.append(processed_item)\n",
    "        return processed_items\n",
    "\n",
    "    else:\n",
    "        # Return non-dict, non-list values as is\n",
    "        return data\n",
    "\n",
    "\n",
    "def read_and_trim_data(session_id_list, raw_export_dir, trimmed_export_dir):\n",
    "    \"\"\"\n",
    "    Reads complete data from JSON files, trims the data, and saves the trimmed data to new JSON files.\n",
    "    \"\"\"\n",
    "    os.makedirs(trimmed_export_dir, exist_ok=True)\n",
    "\n",
    "    for session_id in session_id_list:\n",
    "        try:\n",
    "            if session_id.startswith(\"da0a\"):\n",
    "                session_id = \"phi4_\" + session_id\n",
    "            # Read raw data\n",
    "            if \"tpsg\" in session_id:\n",
    "                session_id_ = session_id.replace(\"tpsg\", \"tpusg\")\n",
    "            else:\n",
    "                session_id_ = session_id\n",
    "            raw_path = os.path.join(raw_export_dir, f\"raw_{session_id_}.json\")\n",
    "            with open(raw_path, \"r\") as f:\n",
    "                data = json.load(f)\n",
    "\n",
    "            # Process and trim the data\n",
    "            trimmed_data = trim_data(data)\n",
    "\n",
    "            # If the entire data was filtered out (unlikely but possible)\n",
    "            if trimmed_data is None:\n",
    "                print(\n",
    "                    f\"All traces in session {session_id} were filtered due to fatal errors\"\n",
    "                )\n",
    "                continue\n",
    "\n",
    "            # Save trimmed data\n",
    "            if \"tpsg\" in session_id:\n",
    "                session_id_ = session_id.replace(\"tpsg\", \"tpusg\")\n",
    "            else:\n",
    "                session_id_ = session_id\n",
    "            trimmed_path = os.path.join(\n",
    "                trimmed_export_dir, f\"trimmed_{session_id_}.json\"\n",
    "            )\n",
    "            with open(trimmed_path, \"w\") as f:\n",
    "                json.dump(trimmed_data, f, indent=2)\n",
    "\n",
    "            print(\n",
    "                f\"Successfully processed and saved trimmed data for session {session_id}\"\n",
    "            )\n",
    "\n",
    "            # Optional: Verify trimming worked\n",
    "            # print(f\"Verifying trimmed data for session {session_id}...\")\n",
    "            # verify_trimming(trimmed_path)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing session {session_id}: {str(e)}\")\n",
    "\n",
    "\n",
    "def verify_trimming(trimmed_path):\n",
    "    \"\"\"\n",
    "    Verifies that the trimmed data doesn't contain unwanted keys.\n",
    "    \"\"\"\n",
    "    with open(trimmed_path, \"r\") as f:\n",
    "        trimmed_data = json.load(f)\n",
    "\n",
    "    unwanted_keys = [\n",
    "        \"release\",\n",
    "        \"version\",\n",
    "        \"user_id\",\n",
    "        \"public\",\n",
    "        \"html_path\",\n",
    "        \"scores\",\n",
    "        \"bookmarked\",\n",
    "        \"projectId\",\n",
    "        \"externalId\",\n",
    "        \"page\",\n",
    "        \"limit\",\n",
    "        \"total_pages\",\n",
    "        \"completionStartTime\",\n",
    "        \"metadata\",\n",
    "        \"usageDetails\",\n",
    "        \"timeToFirstToken\",\n",
    "        \"createdAt\",\n",
    "        \"completionTokens\",\n",
    "        \"promptTokens\",\n",
    "        \"projectId\",\n",
    "        \"unit\",\n",
    "        \"updatedAt\",\n",
    "        \"version\",\n",
    "        # \"statusMessage\",\n",
    "        \"parentObservationId\",\n",
    "        \"promptId\",\n",
    "        \"promptName\",\n",
    "        \"promptVersion\",\n",
    "        \"modelId\",\n",
    "        \"inputPrice\",\n",
    "        \"outputPrice\",\n",
    "        \"totalPrice\",\n",
    "        \"calculatedInputCost\",\n",
    "        \"calculatedOutputCost\",\n",
    "        \"calculatedTotalCost\",\n",
    "    ]\n",
    "\n",
    "    def check_keys(obj):\n",
    "        if isinstance(obj, dict):\n",
    "            for key in obj.keys():\n",
    "                if key in unwanted_keys:\n",
    "                    print(f\"Warning: Found unwanted key '{key}' in trimmed data\")\n",
    "            for value in obj.values():\n",
    "                check_keys(value)\n",
    "        elif isinstance(obj, list):\n",
    "            for item in obj:\n",
    "                check_keys(item)\n",
    "\n",
    "    check_keys(trimmed_data)\n",
    "    print(\"Verification complete\")\n",
    "\n",
    "\n",
    "# Usage example:\n",
    "read_and_trim_data(session_id_list, raw_export_dir, raw_export_dir)\n",
    "print(f\"Total {len(skipped_traces)} traces skipped. They are {skipped_traces}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Generate CSV files from JSON\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing session qwen2.5-coder:32b_1974_tpusg_batch, simple id qwen2.5-coder:32b_1974. Look for /Users/hann/Projects/reference-benchmark-tinyml_llm/data_analysis/07.29/raw_export/trimmed_qwen2.5-coder:32b_1974_tpusg_batch.json\n",
      "/Users/hann/Projects/reference-benchmark-tinyml_llm/data_analysis/07.29/processed_data/qwen2.5-coder:32b_1974/clean_qwen2.5-coder:32b_1974_tpusg_batch.csv\n",
      "Successfully saved CSV to: /Users/hann/Projects/reference-benchmark-tinyml_llm/data_analysis/07.29/processed_data/qwen2.5-coder:32b_1974/clean_qwen2.5-coder:32b_1974_tpusg_batch.csv\n",
      "Processing session qwen2.5-coder:32b_1974_psg_batch, simple id qwen2.5-coder:32b_1974. Look for /Users/hann/Projects/reference-benchmark-tinyml_llm/data_analysis/07.29/raw_export/trimmed_qwen2.5-coder:32b_1974_psg_batch.json\n",
      "/Users/hann/Projects/reference-benchmark-tinyml_llm/data_analysis/07.29/processed_data/qwen2.5-coder:32b_1974/clean_qwen2.5-coder:32b_1974_psg_batch.csv\n",
      "Successfully saved CSV to: /Users/hann/Projects/reference-benchmark-tinyml_llm/data_analysis/07.29/processed_data/qwen2.5-coder:32b_1974/clean_qwen2.5-coder:32b_1974_psg_batch.csv\n"
     ]
    }
   ],
   "source": [
    "import traceback\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from dateutil import parser\n",
    "\n",
    "\n",
    "def json_to_csv(session_id):\n",
    "    \"\"\"\n",
    "    Convert JSON trace data to CSV format with aggregated metrics.\n",
    "\n",
    "    Args:\n",
    "        session_id (str): Identifier for the session to process\n",
    "    \"\"\"\n",
    "\n",
    "    def extract_observation_details(observations, trace_id):\n",
    "        \"\"\"Extract and aggregate metrics from observations\"\"\"\n",
    "        metrics = {\n",
    "            \"status\": None,\n",
    "            \"latency\": 0,\n",
    "            \"total_tokens\": 0,\n",
    "            \"prompt_tokens\": 0,\n",
    "            \"completion_tokens\": 0,\n",
    "            \"total_cost\": 0,\n",
    "            \"input_cost\": 0,\n",
    "            \"output_cost\": 0,\n",
    "            \"parameters\": set(),\n",
    "        }\n",
    "\n",
    "        # Process GENERATION observations\n",
    "        for obs in (o for o in observations if o[\"type\"] == \"GENERATION\"):\n",
    "            metrics[\"total_tokens\"] += obs[\"totalTokens\"]\n",
    "            metrics[\"prompt_tokens\"] += obs[\"promptTokens\"]\n",
    "            metrics[\"completion_tokens\"] += obs[\"completionTokens\"]\n",
    "            metrics[\"latency\"] += obs[\"latency\"]\n",
    "            for key, value in obs[\"modelParameters\"].items():\n",
    "                metrics[\"parameters\"].add(key + \":\" + value)\n",
    "\n",
    "            # Add costs if present\n",
    "            for cost_type in [\"Total\", \"Input\", \"Output\"]:\n",
    "                key = f\"calculated{cost_type}Cost\"\n",
    "                metric_key = cost_type.lower() + \"_cost\"\n",
    "                if obs.get(key) is not None:\n",
    "                    metrics[metric_key] += obs[key]\n",
    "        if len(metrics[\"parameters\"]) == 0:\n",
    "            metrics[\"parameters\"] = \"N/A\"\n",
    "        # Process SPAN observations for status\n",
    "        status_indicators = [\n",
    "            obs[\"name\"]\n",
    "            for obs in observations\n",
    "            if obs[\"type\"] == \"SPAN\" and \"start_\" not in obs[\"name\"]\n",
    "        ]\n",
    "\n",
    "        #  if later than 2025-05-19, use status_signal_from_output\n",
    "        if datetime.now() > datetime(2025, 5, 19):\n",
    "            pass\n",
    "        else:\n",
    "            # Determine status\n",
    "            success_signals = sum(\"end_\" in name for name in status_indicators)\n",
    "            failure_signals = sum(\n",
    "                \"failure_signal\" in name for name in status_indicators\n",
    "            )\n",
    "\n",
    "            if success_signals + failure_signals > 1:\n",
    "                raise ValueError(\n",
    "                    f\"Multiple status indicators found in trace {trace_id}\"\n",
    "                )\n",
    "\n",
    "            metrics[\"status\"] = (\n",
    "                \"success\"\n",
    "                if success_signals\n",
    "                else \"failure\" if failure_signals else \"unknown\"\n",
    "            )\n",
    "\n",
    "        metrics[\"prompt_cost\"] = metrics.pop(\"input_cost\")\n",
    "        metrics[\"completion_cost\"] = metrics.pop(\"output_cost\")\n",
    "        metrics[\"latency\"] = round(metrics[\"latency\"] / 1000, 2)\n",
    "        return metrics\n",
    "\n",
    "    def cal_time(trace):\n",
    "        time_diff = datetime.fromisoformat(\n",
    "            trace[\"updatedAt\"].replace(\"Z\", \"+00:00\")\n",
    "        ) - datetime.fromisoformat(trace[\"createdAt\"].replace(\"Z\", \"+00:00\"))\n",
    "        seconds_diff = time_diff.total_seconds()\n",
    "        return seconds_diff\n",
    "\n",
    "    try:\n",
    "\n",
    "        if session_id.startswith(\"da0a\"):\n",
    "            session_id = \"phi4_\" + session_id\n",
    "        simple_session_id = session_id.rsplit(\"_\", 2)[0]\n",
    "\n",
    "        \n",
    "        # Load JSON data\n",
    "        if \"tpsg\" in session_id:\n",
    "                session_id_ = session_id.replace(\"tpsg\", \"tpusg\")\n",
    "        else:\n",
    "                session_id_ = session_id\n",
    "        trimmed_path = os.path.join(raw_export_dir, f\"trimmed_{session_id_}.json\")\n",
    "        print(\n",
    "            f\"Processing session {session_id}, simple id {simple_session_id}. Look for {trimmed_path}\"\n",
    "        )\n",
    "        with open(trimmed_path, \"r\") as file:\n",
    "            traces = json.load(file)[\"data\"]\n",
    "\n",
    "        # Process traces\n",
    "        rows = [\n",
    "            {\n",
    "                \"num_run\": trace[\"metadata\"][\"num_run\"],\n",
    "                \"name\": trace[\"name\"],\n",
    "                \"trace_id\": trace[\"id\"],\n",
    "                \"batch_id\": trace[\"session_id\"],\n",
    "                # \"latency\": cal_time(trace),\n",
    "                # \"latency\": round(trace[\"latency\"], 2),\n",
    "                **extract_observation_details(\n",
    "                    trace[\"observations\"],\n",
    "                    trace[\"id\"],\n",
    "                ),\n",
    "                \"status\": (\n",
    "                    \"failure\"\n",
    "                    if trace[\"output\"][\"status\"].lower() == \"failed\"\n",
    "                    else \"success\"\n",
    "                ),\n",
    "                \"tags\": trace[\"tags\"],\n",
    "                \"timestamp\": int(parser.isoparse(trace[\"timestamp\"]).timestamp()),\n",
    "            }\n",
    "            for trace in traces\n",
    "        ]\n",
    "        # print(rows)\n",
    "        # print(rows)\n",
    "        # Create and save DataFrame\n",
    "        df = pd.DataFrame(rows).sort_values(\"num_run\")\n",
    "\n",
    "        output_dir = os.path.join(processed_data_dir, f\"{simple_session_id}\")\n",
    "        if not os.path.exists(output_dir):\n",
    "            os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "        output_path = os.path.join(output_dir, f\"clean_{session_id_}.csv\")\n",
    "\n",
    "        print(output_path)\n",
    "        df.to_csv(output_path, index=False)\n",
    "        print(f\"Successfully saved CSV to: {output_path}\")\n",
    "\n",
    "    except FileNotFoundError as e:\n",
    "        print(\n",
    "            f\"FileNotFoundError: For session {session_id} not found. Looked for {trimmed_path}\\nError info: \\n{e}\\n\\nTraceback: {traceback.format_exc()}\"\n",
    "        )\n",
    "    except json.JSONDecodeError:\n",
    "        print(f\"Error: Invalid JSON format in input file for session {session_id}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing session {session_id}: {str(e)}\")\n",
    "\n",
    "\n",
    "# Example usage\n",
    "for session_id in session_id_list:\n",
    "    json_to_csv(session_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code below is archived\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"\"\"Simply calculate success rate\"\"\"\n",
    "\n",
    "\n",
    "# def cal_success_rate(session_id):\n",
    "\n",
    "#     end_signal_count = 0\n",
    "#     failure_signal_count = 0\n",
    "#     # Function to print the name of each observation\n",
    "#     with open(f\"{raw_export_dir}/trimmed_{session_id}.json\", \"r\") as file:\n",
    "#         data = json.load(file)[\"data\"]\n",
    "#     for i in data:\n",
    "\n",
    "#         observations = i[\"observations\"]\n",
    "\n",
    "#         for observation in observations:\n",
    "#             # print(type(observation))\n",
    "#             for key, value in observation.items():\n",
    "#                 # print(f\"{key}: {value}\")\n",
    "#                 for key, value in value.items():\n",
    "#                     # print(f\"{key}: {value}\")\n",
    "#                     if key == \"name\":\n",
    "#                         if \"end_\" in value:\n",
    "\n",
    "#                             end_signal_count += 1\n",
    "#                         if \"failure_signal\" in value:\n",
    "\n",
    "#                             failure_signal_count += 1\n",
    "\n",
    "#     print(f\"Session ID: {session_id}\")\n",
    "#     total_count = end_signal_count + failure_signal_count\n",
    "#     if total_count > 0:\n",
    "#         success_rate = end_signal_count / total_count\n",
    "#         print(f\"Success rate: {success_rate:.4f}\")\n",
    "#     else:\n",
    "#         print(\"Success rate: N/A (no signals found)\")\n",
    "#     print(f\"Passed:\\t{end_signal_count}\\nFailed:\\t{failure_signal_count}\")\n",
    "#     print(\n",
    "#         \"\"\n",
    "#         if total_count == 30\n",
    "#         else \"Number of ending signals does not match the expected number!\"\n",
    "#     )\n",
    "#     print(\"-\" * 50)\n",
    "\n",
    "\n",
    "# for session_id in session_id_list:\n",
    "#     cal_success_rate(session_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def cal_time(start_time, end_time):\n",
    "#     time_diff = datetime.fromisoformat(\n",
    "#         end_time.replace(\"Z\", \"+00:00\")\n",
    "#     ) - datetime.fromisoformat(start_time.replace(\"Z\", \"+00:00\"))\n",
    "#     seconds_diff = time_diff.total_seconds()\n",
    "#     return seconds_diff\n",
    "\n",
    "\n",
    "# print(cal_time(\"2025-01-15T03:31:56.150000+00:00\", \"2025-01-15T03:32:59.384Z\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"\"\"Print the complete structure of exported json file\"\"\"\n",
    "# def print_keys(d, parent_key=''):\n",
    "#     if isinstance(d, dict):\n",
    "#         for key, value in d.items():\n",
    "#             full_key = f\"{parent_key}.{key}\" if parent_key else key\n",
    "#             print(full_key)\n",
    "#             print_keys(value, full_key)\n",
    "#     elif isinstance(d, list):\n",
    "#         for i, item in enumerate(d):\n",
    "#             full_key = f\"{parent_key}[{i}]\"\n",
    "#             print_keys(item, full_key)\n",
    "\n",
    "# # Load JSON data from a file\n",
    "# with open('fetch_traces_response.json', 'r') as file:\n",
    "#     data = json.load(file)['data'][0]\n",
    "# # Print all keys\n",
    "# print_keys(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1747226053\n",
      "1747226053.1\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "from dateutil import parser\n",
    "\n",
    "timestamp_str = \"2025-05-14T12:34:13.100000+00:00\"\n",
    "dt = parser.isoparse(\n",
    "    timestamp_str\n",
    ")  # Or datetime.fromisoformat(timestamp_str) if no timezone offset\n",
    "unix_ts = int(dt.timestamp())\n",
    "\n",
    "print(unix_ts)  # This will print the integer Unix timestamp\n",
    "print(datetime.fromisoformat(timestamp_str).timestamp())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datasci2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "c4ae8806-be35-44e1-93c7-878eed7f14f3",
      "metadata": {
        "id": "c4ae8806-be35-44e1-93c7-878eed7f14f3"
      },
      "source": [
        "# Exporting LLM Runs and Feedback\n",
        "[![Open In Collab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/langchain-ai/langsmith-cookbook/blob/main/exploratory-data-analysis/exporting-llm-runs-and-feedback/llm_run_etl.ipynb)\n",
        "\n",
        "Understanding how your LLM app interacts with users is crucial. LangSmith offers a number of useful ways to interact with and annotate trace data directly in the app. You can also easily query that trace data so you can process it with your tool of choice.\n",
        "\n",
        "This tutorial guides you through exporting LLM traces and associated feedback from LangSmith for further analysis. By the end, you'll be able to export a flat table of LLM run information that you can analyze, enrich, or use for model training.\n",
        "\n",
        "Before we start, ensure you have a LangChain project with some logged traces. You can generate some using almost any of the other recipes in this cookbook. The overall steps will be:\n",
        "\n",
        "1. Query runs, filtering by time, tags, or other attributes.\n",
        "2. Add in associated feedback metrics (if captured)\n",
        "3. Export to analysis tool.\n",
        "\n",
        "To make things easy, we will be loading the data into a pandas dataframe. We will be doing the ETL on LLM runs logged from LangChain, but you can modify the code below to handle whatever schema is used by your deployed model. Now let's set up our environment!\n",
        "\n",
        "#### Setup\n",
        "\n",
        "First, install langsmith and pandas and set your langsmith API key to connect to your project.\n",
        "We will also install LangChain to use one of its formatting utilities."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "5a6b4974-1f59-4517-bce3-b4836783b3dc",
      "metadata": {
        "id": "5a6b4974-1f59-4517-bce3-b4836783b3dc"
      },
      "outputs": [],
      "source": [
        "# %pip install --upgrade --force-reinstall langchain langsmith pandas seaborn --quiet\n",
        "import os  # Add this line at the beginning of your code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "4c37e579-d044-4d95-8dc5-1763f956f481",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4c37e579-d044-4d95-8dc5-1763f956f481",
        "outputId": "dc591518-8a70-4610-b09d-009e00409459"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "env: LANGCHAIN_API_KEY=\"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\"\n"
          ]
        }
      ],
      "source": [
        "%env LANGCHAIN_API_KEY=\"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\"\n",
        "# %pip install --upgrade pandas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "428695ac-6ca5-4967-8e17-7b0fc6a4df51",
      "metadata": {
        "id": "428695ac-6ca5-4967-8e17-7b0fc6a4df51"
      },
      "outputs": [],
      "source": [
        "from langsmith import Client\n",
        "import pandas as pd\n",
        "\n",
        "client = Client()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d3143554-6a2a-4f42-b6a3-0df9cb521314",
      "metadata": {
        "id": "d3143554-6a2a-4f42-b6a3-0df9cb521314"
      },
      "source": [
        "## 1. Query Runs\n",
        "\n",
        "Now that the environment is ready, we will load the run data from LangSmith. Let's try loading all our LLM runs from the past week. To do so, we will filter for runs with the \"llm\" `run_type` from the past week.\n",
        "\n",
        "Please reference the [docs](https://docs.smith.langchain.com/tracing/faq/querying_traces) for guidance on more complex filters (using metadata, tags, and other attributes).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "d85e089d-d7c1-4f61-bb4f-d6728da98b4e",
      "metadata": {
        "id": "d85e089d-d7c1-4f61-bb4f-d6728da98b4e"
      },
      "outputs": [],
      "source": [
        "from datetime import datetime, timedelta\n",
        "from datetime import timezone\n",
        "\n",
        "UTC = timezone.utc\n",
        "# or\n",
        "\n",
        "\n",
        "start_time = datetime.now(UTC) - timedelta(days=2)\n",
        "# model_converter, data_processor, sketch_generator\n",
        "task_type = \"model_converter\"\n",
        "runs = list(\n",
        "    client.list_runs(\n",
        "        project_name=\"default\",\n",
        "        start_time=start_time,\n",
        "        end_time=datetime.now(UTC),\n",
        "        run_type=\"chain\",\n",
        "        # filter=f\"and(has(tags, 'gpt-4o-mini'),has(tags, {task_type}))\",\n",
        "        filter=f\"and(has(tags, 'gpt-4o'),has(tags, {task_type}),has(tags, 'benchmark'),has(tags, '7248'))\",\n",
        "    )\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "b9898ff5",
      "metadata": {},
      "outputs": [],
      "source": [
        "df = pd.DataFrame(\n",
        "    [\n",
        "        {\n",
        "            \"name\": run.name if run.name == task_type + \"_run\" else None,\n",
        "            # \"id\": str(run.id),  # Convert UUID to string\n",
        "            \"latency\": (\n",
        "                (run.end_time - run.start_time).total_seconds()\n",
        "                if run.end_time\n",
        "                else None\n",
        "            ),\n",
        "            \"time\": run.start_time,\n",
        "            # \"tags\": ', '.join(run.tags) if run.tags else None,  # Join tags into a string\n",
        "            # \"run_type\": run.run_type,\n",
        "            \"num_run\": run.extra[\"metadata\"].get(\n",
        "                \"num_run\", None\n",
        "            ),  # Use .get() with a default value\n",
        "            \"total_tokens\": run.total_tokens,\n",
        "            \"input_tokens\": run.prompt_tokens,\n",
        "            \"output_tokens\": run.completion_tokens,\n",
        "            \"total_cost\": float(run.total_cost) if run.total_cost is not None else None,\n",
        "            \"input_cost\": (\n",
        "                float(run.prompt_cost) if run.prompt_cost is not None else None\n",
        "            ),\n",
        "            \"output_cost\": (\n",
        "                float(run.completion_cost) if run.completion_cost is not None else None\n",
        "            ),\n",
        "            \"pass\": (\n",
        "                \"no\"\n",
        "                if \"An error could not be resolved after 5 retries:\" in str(run.error)\n",
        "                else \"yes\"\n",
        "            ),\n",
        "            \"task\": task_type,\n",
        "        }\n",
        "        for run in runs\n",
        "    ]\n",
        ")\n",
        "\n",
        "# display(df)\n",
        "# print(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "743c0020",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "qpxqEhZ0Tpq3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qpxqEhZ0Tpq3",
        "outputId": "279c14f3-90c3-4477-fc5c-55985388ed36"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "name              0\n",
            "latency          30\n",
            "time             30\n",
            "num_run          30\n",
            "total_tokens     30\n",
            "input_tokens     30\n",
            "output_tokens    30\n",
            "total_cost       30\n",
            "input_cost       30\n",
            "output_cost      30\n",
            "pass             30\n",
            "task             30\n",
            "dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# display(df)\n",
        "print(df.count())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "c0f44bbe",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/home/han/Projects/tinyml-autopilot/dev/test_in_batch/25_oct\n"
          ]
        }
      ],
      "source": [
        "print(os.getcwd())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "u2pJUWQzUteo",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u2pJUWQzUteo",
        "outputId": "2f0b54da-acc4-4a7e-e003-3ab7e62691ef"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data successfully saved to 'model_convert_25_oct.csv'\n"
          ]
        }
      ],
      "source": [
        "import csv\n",
        "\n",
        "\n",
        "def save_to_csv(df, filename=None):\n",
        "    if filename is None:\n",
        "        # Get the name of the current folder\n",
        "        folder_name = os.getcwd().split(\"/\")[-1]\n",
        "\n",
        "    filename = f\"{task_type}_{folder_name}.csv\"\n",
        "    try:\n",
        "        # Convert DataFrame to a list of dictionaries manually\n",
        "        data_to_save = []\n",
        "        for _, row in df.iterrows():\n",
        "            data_to_save.append(row.to_dict())\n",
        "\n",
        "        with open(filename, \"w\", newline=\"\") as csvfile:\n",
        "            fieldnames = df.columns\n",
        "            writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
        "\n",
        "            writer.writeheader()\n",
        "            for row in data_to_save:\n",
        "                writer.writerow(row)\n",
        "\n",
        "        print(f\"Data successfully saved to '{filename}'\")\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred while saving the file: {e}\")\n",
        "\n",
        "\n",
        "# Save the DataFrame\n",
        "save_to_csv(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ae814138-304d-4355-8710-0a3fdf04fb6b",
      "metadata": {
        "id": "ae814138-304d-4355-8710-0a3fdf04fb6b"
      },
      "source": [
        "## 3. Analyze Data\n",
        "\n",
        "Once you have the data in flat form, you can export to many compatible tools, from tabular storage like Airtable and Excel, to annotation tools like [LabelBox](https://docs.labelbox.com/reference/text-file) to other text analysis tools like [Lilac](../lilac/lilac.ipynb) or [Nomic](https://atlas.nomic.ai/).\n",
        "\n",
        "For the purpose of this tutorial, we will wrap things up with a simple token plot. Check out our other recipes for more involved analysis."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "fb6c1f6f",
      "metadata": {},
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name '__file__' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[10], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m date_suffix \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mbasename(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mdirname(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mabspath(\u001b[38;5;18;43m__file__\u001b[39;49m)))\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(date_suffix)\n",
            "\u001b[0;31mNameError\u001b[0m: name '__file__' is not defined"
          ]
        }
      ],
      "source": [
        "date_suffix = os.getcwd().split(\"/\")[-1]\n",
        "print(date_suffix)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "540a44b4",
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.15"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}

{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "c4ae8806-be35-44e1-93c7-878eed7f14f3",
      "metadata": {
        "id": "c4ae8806-be35-44e1-93c7-878eed7f14f3"
      },
      "source": [
        "# Exporting LLM Runs and Feedback\n",
        "\n",
        "[![Open In Collab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/langchain-ai/langsmith-cookbook/blob/main/exploratory-data-analysis/exporting-llm-runs-and-feedback/llm_run_etl.ipynb)\n",
        "\n",
        "Understanding how your LLM app interacts with users is crucial. LangSmith offers a number of useful ways to interact with and annotate trace data directly in the app. You can also easily query that trace data so you can process it with your tool of choice.\n",
        "\n",
        "This tutorial guides you through exporting LLM traces and associated feedback from LangSmith for further analysis. By the end, you'll be able to export a flat table of LLM run information that you can analyze, enrich, or use for model training.\n",
        "\n",
        "Before we start, ensure you have a LangChain project with some logged traces. You can generate some using almost any of the other recipes in this cookbook. The overall steps will be:\n",
        "\n",
        "1. Query runs, filtering by time, tags, or other attributes.\n",
        "2. Add in associated feedback metrics (if captured)\n",
        "3. Export to analysis tool.\n",
        "\n",
        "To make things easy, we will be loading the data into a pandas dataframe. We will be doing the ETL on LLM runs logged from LangChain, but you can modify the code below to handle whatever schema is used by your deployed model. Now let's set up our environment!\n",
        "\n",
        "#### Setup\n",
        "\n",
        "First, install langsmith and pandas and set your langsmith API key to connect to your project.\n",
        "We will also install LangChain to use one of its formatting utilities.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "5a6b4974-1f59-4517-bce3-b4836783b3dc",
      "metadata": {
        "id": "5a6b4974-1f59-4517-bce3-b4836783b3dc"
      },
      "outputs": [],
      "source": [
        "# %pip install --upgrade --force-reinstall langchain langsmith pandas seaborn --quiet\n",
        "import os  # Add this line at the beginning of your code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "4c37e579-d044-4d95-8dc5-1763f956f481",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4c37e579-d044-4d95-8dc5-1763f956f481",
        "outputId": "dc591518-8a70-4610-b09d-009e00409459"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "env: LANGCHAIN_API_KEY='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'\n"
          ]
        }
      ],
      "source": [
        "%env LANGCHAIN_API_KEY='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'\n",
        "parent_dir = os.path.dirname(os.getcwd())\n",
        "# %pip install --upgrade pandas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "428695ac-6ca5-4967-8e17-7b0fc6a4df51",
      "metadata": {
        "id": "428695ac-6ca5-4967-8e17-7b0fc6a4df51"
      },
      "outputs": [],
      "source": [
        "from langsmith import Client\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "client = Client()\n",
        "\n",
        "dp_batch = {\"name\": \"data_processor\", \"batch_id\": \"1128_dp_batch\"}\n",
        "mc_batch = {\"name\": \"model_converter\", \"batch_id\": \"1128_mc_batch\"}\n",
        "sg_batch = {\"name\": \"sketch_generator\", \"batch_id\": \"1128_sg_batch\"}"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d3143554-6a2a-4f42-b6a3-0df9cb521314",
      "metadata": {
        "id": "d3143554-6a2a-4f42-b6a3-0df9cb521314"
      },
      "source": [
        "## 1. Query Runs\n",
        "\n",
        "query and save to json files\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "d85e089d-d7c1-4f61-bb4f-d6728da98b4e",
      "metadata": {
        "id": "d85e089d-d7c1-4f61-bb4f-d6728da98b4e"
      },
      "outputs": [],
      "source": [
        "from datetime import datetime, timedelta\n",
        "from datetime import timezone\n",
        "import json\n",
        "\n",
        "# batch_tests 10.28:\n",
        "#   data_processor: batch_id: 2117_batch\n",
        "#   model_converter: batch_id: 7121_batch\n",
        "#   sketch_generator: batch_id: 1730_batch\n",
        "\n",
        "#   sketch_generato2: batch_id: 2172_batch\n",
        "\n",
        "\n",
        "def run_to_dict(run):\n",
        "    return {\n",
        "        \"id\": str(run.id),\n",
        "        \"name\": run.name,\n",
        "        \"timing\": {\n",
        "            \"start_time\": run.start_time.strftime(\"%Y-%m-%d %H:%M:%S.%f\"),\n",
        "            \"end_time\": run.end_time.strftime(\"%Y-%m-%d %H:%M:%S.%f\"),\n",
        "        },\n",
        "        \"run_type\": run.run_type,\n",
        "        \"metadata\": {\n",
        "            \"trace_id\": run.extra.get(\"metadata\", {}).get(\"trace_id\"),\n",
        "            \"num_run\": run.extra.get(\"metadata\", {}).get(\"num_run\"),\n",
        "            \"batch_id\": run.extra.get(\"metadata\", {}).get(\"batch_id\"),\n",
        "            \"network_latency\": run.extra.get(\"metadata\", {}).get(\"network_latency\"),\n",
        "            \"ls_method\": run.extra.get(\"metadata\", {}).get(\"ls_method\"),\n",
        "            \"revision_id\": run.extra.get(\"metadata\", {}).get(\"revision_id\"),\n",
        "        },\n",
        "        \"runtime\": run.extra.get(\"runtime\", {}),\n",
        "        \"tokens\": {\n",
        "            \"prompt_tokens\": run.prompt_tokens,\n",
        "            \"completion_tokens\": run.completion_tokens,\n",
        "            \"total_tokens\": run.total_tokens,\n",
        "        },\n",
        "        \"cost\": {\n",
        "            \"prompt_cost\": float(run.prompt_cost) if run.prompt_cost else None,\n",
        "            \"completion_cost\": (\n",
        "                float(run.completion_cost) if run.completion_cost else None\n",
        "            ),\n",
        "            \"total_cost\": float(run.total_cost) if run.total_cost else None,\n",
        "        },\n",
        "        \"status\": run.status,\n",
        "        \"session_id\": str(run.session_id) if run.session_id else None,\n",
        "        \"child_run_ids\": (\n",
        "            [str(run_id) for run_id in run.child_run_ids] if run.child_run_ids else []\n",
        "        ),\n",
        "        \"tags\": run.tags,\n",
        "    }\n",
        "\n",
        "\n",
        "def convert_runs_to_json(runs):\n",
        "    # Convert list of Run objects to list of dicts\n",
        "    runs_data = [run_to_dict(run) for run in runs]\n",
        "    return runs_data\n",
        "\n",
        "\n",
        "def save_runs(current_batch):\n",
        "    runs = list(\n",
        "        client.list_runs(\n",
        "            project_name=\"default\",\n",
        "            start_time=datetime.now(timezone.utc) - timedelta(days=2),\n",
        "            run_type=\"llm\",\n",
        "            # filter=f'and(has(tags, \\'gpt-4o-mini\\'),has(tags, {task_type}))',\n",
        "            filter=f\"and(eq(metadata_key, 'batch_id'), eq(metadata_value, '{current_batch['batch_id']}'))\",\n",
        "        )\n",
        "    )\n",
        "\n",
        "    output_file = f\"{parent_dir}/raw_export/js_{current_batch['name']}_{current_batch['batch_id']}.json\"\n",
        "    # if the directory does not exist, create it\n",
        "    if not os.path.exists(os.path.dirname(output_file)):\n",
        "        os.makedirs(os.path.dirname(output_file), exist_ok=True)\n",
        "\n",
        "    runs_data = convert_runs_to_json(runs)\n",
        "    # Write to JSON file\n",
        "    with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
        "        json.dump(runs_data, f, indent=2)\n",
        "\n",
        "\n",
        "# for current_batch in [dp_batch, mc_batch, sg_batch]:\n",
        "#     print(current_batch[\"batch_id\"])\n",
        "#     save_runs(current_batch)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0b9bf6f2",
      "metadata": {},
      "source": [
        "## Start from reading data from saved json files\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "1cfbed3f",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Latency statistics (in seconds):\n",
            "count    218.000000\n",
            "mean       8.716335\n",
            "std       14.000372\n",
            "min        0.000422\n",
            "25%        3.075792\n",
            "50%        4.241238\n",
            "75%        6.081964\n",
            "max       81.175983\n",
            "Name: latency, dtype: float64\n",
            "\n",
            "Sample rows with latency:\n",
            "                         name                 start_time  \\\n",
            "0  cc_dp_operation_code_gen#8 2024-11-28 11:34:55.401254   \n",
            "1  cc_dp_operation_code_gen#7 2024-11-28 11:34:52.035837   \n",
            "2  cc_dp_operation_code_gen#6 2024-11-28 11:34:47.224526   \n",
            "3  cc_dp_operation_code_gen#5 2024-11-28 11:34:42.491760   \n",
            "4  cc_dp_operation_code_gen#4 2024-11-28 11:34:37.091926   \n",
            "\n",
            "                    end_time   latency  \n",
            "0 2024-11-28 11:35:01.524170  6.122916  \n",
            "1 2024-11-28 11:34:55.021401  2.985564  \n",
            "2 2024-11-28 11:34:51.583046  4.358520  \n",
            "3 2024-11-28 11:34:46.491970  4.000210  \n",
            "4 2024-11-28 11:34:41.569732  4.477806  \n",
            "                                     id                        name  \\\n",
            "0  cd7d7009-cd31-4830-9f46-7ce6d56b649f  cc_dp_operation_code_gen#8   \n",
            "1  bd45c550-7f61-459a-a7fb-3c982b0c2e09  cc_dp_operation_code_gen#7   \n",
            "2  0221076c-ca39-42e0-9cc5-e606b83f534d  cc_dp_operation_code_gen#6   \n",
            "3  12a6dbb7-a4b6-4f4e-b074-4da7fae73ae1  cc_dp_operation_code_gen#5   \n",
            "4  804c910d-2607-4722-8895-c235e632a344  cc_dp_operation_code_gen#4   \n",
            "\n",
            "                  start_time                   end_time run_type  trace_id  \\\n",
            "0 2024-11-28 11:34:55.401254 2024-11-28 11:35:01.524170      llm  cccb137a   \n",
            "1 2024-11-28 11:34:52.035837 2024-11-28 11:34:55.021401      llm  cccb137a   \n",
            "2 2024-11-28 11:34:47.224526 2024-11-28 11:34:51.583046      llm  cccb137a   \n",
            "3 2024-11-28 11:34:42.491760 2024-11-28 11:34:46.491970      llm  cccb137a   \n",
            "4 2024-11-28 11:34:37.091926 2024-11-28 11:34:41.569732      llm  cccb137a   \n",
            "\n",
            "   num_run       batch_id  network_latency sdk_version  ... completion_tokens  \\\n",
            "0       19  1128_dp_batch         0.141869     0.1.137  ...               490   \n",
            "1       19  1128_dp_batch         0.208732     0.1.137  ...               287   \n",
            "2       19  1128_dp_batch         0.147121     0.1.137  ...               265   \n",
            "3       19  1128_dp_batch         0.238661     0.1.137  ...               336   \n",
            "4       19  1128_dp_batch         0.218588     0.1.137  ...               247   \n",
            "\n",
            "  total_tokens prompt_cost  completion_cost  total_cost   status  \\\n",
            "0         1423    0.000140         0.000294    0.000434  success   \n",
            "1         1180    0.000134         0.000172    0.000306  success   \n",
            "2         1108    0.000126         0.000159    0.000285  success   \n",
            "3         1086    0.000112         0.000202    0.000314  success   \n",
            "4          972    0.000109         0.000148    0.000257  success   \n",
            "\n",
            "                             session_id                         child_run_ids  \\\n",
            "0  601dc250-34d5-4229-a99b-74074fd8c221  f386560c-154a-4b36-b378-890feac87d13   \n",
            "1  601dc250-34d5-4229-a99b-74074fd8c221  a07226e4-dd8b-4c8c-b610-66f6e374c0f9   \n",
            "2  601dc250-34d5-4229-a99b-74074fd8c221  762e93a2-9471-4404-998e-f23f2cf4e37d   \n",
            "3  601dc250-34d5-4229-a99b-74074fd8c221  f68c15e1-24c3-4416-be9b-9aee6e807a6b   \n",
            "4  601dc250-34d5-4229-a99b-74074fd8c221  6dcbecd5-15c0-4d8b-be62-932395e5e563   \n",
            "\n",
            "                                   tags   latency  \n",
            "0  benchmark,data_processor,gpt-4o-mini  6.122916  \n",
            "1  benchmark,data_processor,gpt-4o-mini  2.985564  \n",
            "2  benchmark,data_processor,gpt-4o-mini  4.358520  \n",
            "3  benchmark,data_processor,gpt-4o-mini  4.000210  \n",
            "4  benchmark,data_processor,gpt-4o-mini  4.477806  \n",
            "\n",
            "[5 rows x 24 columns]\n",
            "\n",
            "DataFrame Info:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 218 entries, 0 to 217\n",
            "Data columns (total 24 columns):\n",
            " #   Column             Non-Null Count  Dtype         \n",
            "---  ------             --------------  -----         \n",
            " 0   id                 218 non-null    object        \n",
            " 1   name               218 non-null    object        \n",
            " 2   start_time         218 non-null    datetime64[ns]\n",
            " 3   end_time           218 non-null    datetime64[ns]\n",
            " 4   run_type           218 non-null    object        \n",
            " 5   trace_id           218 non-null    object        \n",
            " 6   num_run            218 non-null    int64         \n",
            " 7   batch_id           218 non-null    object        \n",
            " 8   network_latency    196 non-null    float64       \n",
            " 9   sdk_version        218 non-null    object        \n",
            " 10  platform           218 non-null    object        \n",
            " 11  python_version     218 non-null    object        \n",
            " 12  langchain_version  218 non-null    object        \n",
            " 13  prompt_tokens      218 non-null    int64         \n",
            " 14  completion_tokens  218 non-null    int64         \n",
            " 15  total_tokens       218 non-null    int64         \n",
            " 16  prompt_cost        216 non-null    float64       \n",
            " 17  completion_cost    216 non-null    float64       \n",
            " 18  total_cost         216 non-null    float64       \n",
            " 19  status             218 non-null    object        \n",
            " 20  session_id         218 non-null    object        \n",
            " 21  child_run_ids      218 non-null    object        \n",
            " 22  tags               218 non-null    object        \n",
            " 23  latency            218 non-null    float64       \n",
            "dtypes: datetime64[ns](2), float64(5), int64(4), object(13)\n",
            "memory usage: 41.0+ KB\n",
            "None\n",
            "\n",
            "Latency statistics (in seconds):\n",
            "count    66.000000\n",
            "mean      4.193494\n",
            "std       1.927055\n",
            "min       0.000474\n",
            "25%       3.513559\n",
            "50%       4.059251\n",
            "75%       4.918961\n",
            "max      11.824604\n",
            "Name: latency, dtype: float64\n",
            "\n",
            "Sample rows with latency:\n",
            "                                   name                 start_time  \\\n",
            "0  98_mc_failure_signal_model_converter 2024-11-28 11:50:42.389957   \n",
            "1                 98_mc_error_handling5 2024-11-28 11:50:34.430733   \n",
            "2                 98_mc_error_handling4 2024-11-28 11:50:25.933296   \n",
            "3                 98_mc_error_handling3 2024-11-28 11:50:17.902021   \n",
            "4                 98_mc_error_handling2 2024-11-28 11:50:07.630758   \n",
            "\n",
            "                    end_time   latency  \n",
            "0 2024-11-28 11:50:42.390431  0.000474  \n",
            "1 2024-11-28 11:50:39.223825  4.793092  \n",
            "2 2024-11-28 11:50:31.095703  5.162407  \n",
            "3 2024-11-28 11:50:22.583091  4.681070  \n",
            "4 2024-11-28 11:50:14.548725  6.917967  \n",
            "                                     id                                  name  \\\n",
            "0  7b9915ed-8f17-4e5b-abb4-b71cc001d25a  98_mc_failure_signal_model_converter   \n",
            "1  6c109e62-70e9-497f-9339-877dd9d7a229                 98_mc_error_handling5   \n",
            "2  2ea54706-2c03-41d4-83d6-a7eaec85ed49                 98_mc_error_handling4   \n",
            "3  19a2a58e-4e4d-4c26-ab80-f304f33cd4be                 98_mc_error_handling3   \n",
            "4  9249d0af-6401-4a4d-9ee1-bc71a932e0cd                 98_mc_error_handling2   \n",
            "\n",
            "                  start_time                   end_time run_type  trace_id  \\\n",
            "0 2024-11-28 11:50:42.389957 2024-11-28 11:50:42.390431      llm  9836a0cb   \n",
            "1 2024-11-28 11:50:34.430733 2024-11-28 11:50:39.223825      llm  9836a0cb   \n",
            "2 2024-11-28 11:50:25.933296 2024-11-28 11:50:31.095703      llm  9836a0cb   \n",
            "3 2024-11-28 11:50:17.902021 2024-11-28 11:50:22.583091      llm  9836a0cb   \n",
            "4 2024-11-28 11:50:07.630758 2024-11-28 11:50:14.548725      llm  9836a0cb   \n",
            "\n",
            "   num_run       batch_id  network_latency sdk_version  ... completion_tokens  \\\n",
            "0       19  1128_mc_batch              NaN     0.1.137  ...                 0   \n",
            "1       19  1128_mc_batch         0.151472     0.1.137  ...               350   \n",
            "2       19  1128_mc_batch         0.206889     0.1.137  ...               340   \n",
            "3       19  1128_mc_batch         0.207495     0.1.137  ...               345   \n",
            "4       19  1128_mc_batch         0.220553     0.1.137  ...               337   \n",
            "\n",
            "  total_tokens prompt_cost  completion_cost  total_cost   status  \\\n",
            "0            0         NaN              NaN         NaN    error   \n",
            "1         2356    0.000301         0.000210    0.000511  success   \n",
            "2         2351    0.000302         0.000204    0.000506  success   \n",
            "3         2344    0.000300         0.000207    0.000507  success   \n",
            "4         2312    0.000296         0.000202    0.000498  success   \n",
            "\n",
            "                             session_id                         child_run_ids  \\\n",
            "0  601dc250-34d5-4229-a99b-74074fd8c221                                         \n",
            "1  601dc250-34d5-4229-a99b-74074fd8c221  86be056d-f904-4ec8-bd90-b65f7f0cac73   \n",
            "2  601dc250-34d5-4229-a99b-74074fd8c221  dc5af4f7-c997-4c3b-a586-ff16ee8d0227   \n",
            "3  601dc250-34d5-4229-a99b-74074fd8c221  bed7c3a6-7825-4c4d-8dc0-d042311f7870   \n",
            "4  601dc250-34d5-4229-a99b-74074fd8c221  6514cdab-368a-415f-9cc9-0eabad3052fb   \n",
            "\n",
            "                                    tags   latency  \n",
            "0  benchmark,gpt-4o-mini,model_converter  0.000474  \n",
            "1  benchmark,gpt-4o-mini,model_converter  4.793092  \n",
            "2  benchmark,gpt-4o-mini,model_converter  5.162407  \n",
            "3  benchmark,gpt-4o-mini,model_converter  4.681070  \n",
            "4  benchmark,gpt-4o-mini,model_converter  6.917967  \n",
            "\n",
            "[5 rows x 24 columns]\n",
            "\n",
            "DataFrame Info:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 66 entries, 0 to 65\n",
            "Data columns (total 24 columns):\n",
            " #   Column             Non-Null Count  Dtype         \n",
            "---  ------             --------------  -----         \n",
            " 0   id                 66 non-null     object        \n",
            " 1   name               66 non-null     object        \n",
            " 2   start_time         66 non-null     datetime64[ns]\n",
            " 3   end_time           66 non-null     datetime64[ns]\n",
            " 4   run_type           66 non-null     object        \n",
            " 5   trace_id           66 non-null     object        \n",
            " 6   num_run            66 non-null     int64         \n",
            " 7   batch_id           66 non-null     object        \n",
            " 8   network_latency    61 non-null     float64       \n",
            " 9   sdk_version        66 non-null     object        \n",
            " 10  platform           66 non-null     object        \n",
            " 11  python_version     66 non-null     object        \n",
            " 12  langchain_version  66 non-null     object        \n",
            " 13  prompt_tokens      66 non-null     int64         \n",
            " 14  completion_tokens  66 non-null     int64         \n",
            " 15  total_tokens       66 non-null     int64         \n",
            " 16  prompt_cost        61 non-null     float64       \n",
            " 17  completion_cost    61 non-null     float64       \n",
            " 18  total_cost         61 non-null     float64       \n",
            " 19  status             66 non-null     object        \n",
            " 20  session_id         66 non-null     object        \n",
            " 21  child_run_ids      66 non-null     object        \n",
            " 22  tags               66 non-null     object        \n",
            " 23  latency            66 non-null     float64       \n",
            "dtypes: datetime64[ns](2), float64(5), int64(4), object(13)\n",
            "memory usage: 12.5+ KB\n",
            "None\n",
            "\n",
            "Latency statistics (in seconds):\n",
            "count    149.000000\n",
            "mean      10.209853\n",
            "std       14.033062\n",
            "min        0.000461\n",
            "25%        4.923774\n",
            "50%        6.095699\n",
            "75%        7.373071\n",
            "max       92.893151\n",
            "Name: latency, dtype: float64\n",
            "\n",
            "Sample rows with latency:\n",
            "                                    name                 start_time  \\\n",
            "0  04_sg_failure_signal_sketch_generator 2024-11-28 12:12:09.826050   \n",
            "1                  04_sg_error_handling5 2024-11-28 12:12:02.563959   \n",
            "2                  04_sg_error_handling4 2024-11-28 12:11:55.578476   \n",
            "3                  04_sg_error_handling3 2024-11-28 12:11:47.438325   \n",
            "4                  04_sg_error_handling2 2024-11-28 12:11:39.505290   \n",
            "\n",
            "                    end_time   latency  \n",
            "0 2024-11-28 12:12:09.826879  0.000829  \n",
            "1 2024-11-28 12:12:08.533000  5.969041  \n",
            "2 2024-11-28 12:12:01.155787  5.577311  \n",
            "3 2024-11-28 12:11:54.124948  6.686623  \n",
            "4 2024-11-28 12:11:46.436457  6.931167  \n",
            "                                     id  \\\n",
            "0  1849a858-968b-4ed8-b0d4-4b202a7ff8ed   \n",
            "1  b63468b1-3c7c-49a0-9a47-c9cda8c0fefb   \n",
            "2  4823387e-6c3f-4f8b-8eab-640af288d7e2   \n",
            "3  ebd21ad5-9a03-424c-a599-7bbd2c955712   \n",
            "4  8dbf3374-2ecc-48fd-8d4c-df5fd89f4471   \n",
            "\n",
            "                                    name                 start_time  \\\n",
            "0  04_sg_failure_signal_sketch_generator 2024-11-28 12:12:09.826050   \n",
            "1                  04_sg_error_handling5 2024-11-28 12:12:02.563959   \n",
            "2                  04_sg_error_handling4 2024-11-28 12:11:55.578476   \n",
            "3                  04_sg_error_handling3 2024-11-28 12:11:47.438325   \n",
            "4                  04_sg_error_handling2 2024-11-28 12:11:39.505290   \n",
            "\n",
            "                    end_time run_type  trace_id  num_run       batch_id  \\\n",
            "0 2024-11-28 12:12:09.826879      llm  04bad66f       19  1128_sg_batch   \n",
            "1 2024-11-28 12:12:08.533000      llm  04bad66f       19  1128_sg_batch   \n",
            "2 2024-11-28 12:12:01.155787      llm  04bad66f       19  1128_sg_batch   \n",
            "3 2024-11-28 12:11:54.124948      llm  04bad66f       19  1128_sg_batch   \n",
            "4 2024-11-28 12:11:46.436457      llm  04bad66f       19  1128_sg_batch   \n",
            "\n",
            "   network_latency sdk_version  ... completion_tokens total_tokens  \\\n",
            "0              NaN     0.1.137  ...                 0            0   \n",
            "1         0.145884     0.1.137  ...               585         2901   \n",
            "2         0.168900     0.1.137  ...               569         2867   \n",
            "3         0.164623     0.1.137  ...               557         2859   \n",
            "4         0.254981     0.1.137  ...               565         2871   \n",
            "\n",
            "  prompt_cost  completion_cost  total_cost   status  \\\n",
            "0         NaN              NaN         NaN    error   \n",
            "1    0.000347         0.000351    0.000698  success   \n",
            "2    0.000345         0.000341    0.000686  success   \n",
            "3    0.000345         0.000334    0.000679  success   \n",
            "4    0.000346         0.000339    0.000685  success   \n",
            "\n",
            "                             session_id                         child_run_ids  \\\n",
            "0  601dc250-34d5-4229-a99b-74074fd8c221                                         \n",
            "1  601dc250-34d5-4229-a99b-74074fd8c221  c0b96ace-6138-4121-970f-a69b7c27511d   \n",
            "2  601dc250-34d5-4229-a99b-74074fd8c221  aa6963a7-b0a7-4879-98b8-ca489cdb0a88   \n",
            "3  601dc250-34d5-4229-a99b-74074fd8c221  ba62d3b6-1255-47b0-9897-58fb43c1224f   \n",
            "4  601dc250-34d5-4229-a99b-74074fd8c221  043a30db-9c67-49db-8088-3dbb34128aeb   \n",
            "\n",
            "                                     tags   latency  \n",
            "0  benchmark,gpt-4o-mini,sketch_generator  0.000829  \n",
            "1  benchmark,gpt-4o-mini,sketch_generator  5.969041  \n",
            "2  benchmark,gpt-4o-mini,sketch_generator  5.577311  \n",
            "3  benchmark,gpt-4o-mini,sketch_generator  6.686623  \n",
            "4  benchmark,gpt-4o-mini,sketch_generator  6.931167  \n",
            "\n",
            "[5 rows x 24 columns]\n",
            "\n",
            "DataFrame Info:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 149 entries, 0 to 148\n",
            "Data columns (total 24 columns):\n",
            " #   Column             Non-Null Count  Dtype         \n",
            "---  ------             --------------  -----         \n",
            " 0   id                 149 non-null    object        \n",
            " 1   name               149 non-null    object        \n",
            " 2   start_time         149 non-null    datetime64[ns]\n",
            " 3   end_time           149 non-null    datetime64[ns]\n",
            " 4   run_type           149 non-null    object        \n",
            " 5   trace_id           149 non-null    object        \n",
            " 6   num_run            149 non-null    int64         \n",
            " 7   batch_id           149 non-null    object        \n",
            " 8   network_latency    111 non-null    float64       \n",
            " 9   sdk_version        149 non-null    object        \n",
            " 10  platform           149 non-null    object        \n",
            " 11  python_version     149 non-null    object        \n",
            " 12  langchain_version  149 non-null    object        \n",
            " 13  prompt_tokens      149 non-null    int64         \n",
            " 14  completion_tokens  149 non-null    int64         \n",
            " 15  total_tokens       149 non-null    int64         \n",
            " 16  prompt_cost        131 non-null    float64       \n",
            " 17  completion_cost    131 non-null    float64       \n",
            " 18  total_cost         131 non-null    float64       \n",
            " 19  status             149 non-null    object        \n",
            " 20  session_id         149 non-null    object        \n",
            " 21  child_run_ids      149 non-null    object        \n",
            " 22  tags               149 non-null    object        \n",
            " 23  latency            149 non-null    float64       \n",
            "dtypes: datetime64[ns](2), float64(5), int64(4), object(13)\n",
            "memory usage: 28.1+ KB\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import json\n",
        "\n",
        "# current_batch = sg_batch\n",
        "\n",
        "\n",
        "# Open json file\n",
        "def load_runs_df(json_path):\n",
        "    # Read JSON file\n",
        "    with open(json_path, \"r\") as f:\n",
        "        data = json.load(f)\n",
        "\n",
        "    # Flatten nested structures\n",
        "    flattened_data = []\n",
        "    for run in data:\n",
        "        flat_run = {\n",
        "            \"id\": run[\"id\"],\n",
        "            \"name\": run[\"name\"],\n",
        "            \"start_time\": run[\"timing\"][\"start_time\"],\n",
        "            \"end_time\": run[\"timing\"][\"end_time\"],\n",
        "            \"run_type\": run[\"run_type\"],\n",
        "            # Metadata\n",
        "            \"trace_id\": run[\"metadata\"][\"trace_id\"],\n",
        "            \"num_run\": run[\"metadata\"][\"num_run\"],\n",
        "            \"batch_id\": run[\"metadata\"][\"batch_id\"],\n",
        "            \"network_latency\": run[\"metadata\"][\"network_latency\"],\n",
        "            # Runtime\n",
        "            \"sdk_version\": run[\"runtime\"][\"sdk_version\"],\n",
        "            \"platform\": run[\"runtime\"][\"platform\"],\n",
        "            \"python_version\": run[\"runtime\"][\"runtime_version\"],\n",
        "            \"langchain_version\": run[\"runtime\"][\"langchain_version\"],\n",
        "            # Tokens\n",
        "            \"prompt_tokens\": run[\"tokens\"][\"prompt_tokens\"],\n",
        "            \"completion_tokens\": run[\"tokens\"][\"completion_tokens\"],\n",
        "            \"total_tokens\": run[\"tokens\"][\"total_tokens\"],\n",
        "            # Cost\n",
        "            \"prompt_cost\": run[\"cost\"][\"prompt_cost\"],\n",
        "            \"completion_cost\": run[\"cost\"][\"completion_cost\"],\n",
        "            \"total_cost\": run[\"cost\"][\"total_cost\"],\n",
        "            \"status\": run[\"status\"],\n",
        "            \"session_id\": run[\"session_id\"],\n",
        "            \"child_run_ids\": \",\".join(run[\"child_run_ids\"]),  # Convert list to string\n",
        "            \"tags\": \",\".join(run[\"tags\"]),  # Convert list to string\n",
        "        }\n",
        "        flattened_data.append(flat_run)\n",
        "\n",
        "    # Create DataFrame\n",
        "    df = pd.DataFrame(flattened_data)\n",
        "\n",
        "    # Convert timestamp strings to datetime\n",
        "    df[\"start_time\"] = pd.to_datetime(df[\"start_time\"])\n",
        "    df[\"end_time\"] = pd.to_datetime(df[\"end_time\"])\n",
        "\n",
        "    return df\n",
        "\n",
        "\n",
        "df_list = []\n",
        "for current_batch in [dp_batch, mc_batch, sg_batch]:\n",
        "    # Usage\n",
        "    json_path = f\"{parent_dir}/raw_export/js_{current_batch['name']}_{current_batch['batch_id']}.json\"\n",
        "    df = load_runs_df(json_path)\n",
        "\n",
        "    # In-place deletion of the duplicateed rows 'ChatOpenAI'\n",
        "    df.drop(df[df[\"name\"] == \"ChatOpenAI\"].index, inplace=True)\n",
        "    df.reset_index(drop=True, inplace=True)\n",
        "\n",
        "    # Add latency column in seconds\n",
        "    df[\"latency\"] = (df[\"end_time\"] - df[\"start_time\"]).dt.total_seconds()\n",
        "\n",
        "    # Show the new column\n",
        "    print(\"\\nLatency statistics (in seconds):\")\n",
        "    print(df[\"latency\"].describe())\n",
        "\n",
        "    # Show sample rows with timestamps and latency\n",
        "    print(\"\\nSample rows with latency:\")\n",
        "    print(df[[\"name\", \"start_time\", \"end_time\", \"latency\"]].head())\n",
        "\n",
        "    # Now you can do analysis\n",
        "    print(df.head())\n",
        "    print(\"\\nDataFrame Info:\")\n",
        "    print(df.info())\n",
        "    df_list.append(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b2f2889f",
      "metadata": {},
      "source": [
        "## Drop the columns that are not needed\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "b9898ff5",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "################## data_processor\n",
            "################## session_id\n",
            "################## child_run_ids\n",
            "################## sdk_version\n",
            "################## start_time\n",
            "################## end_time\n",
            "################## platform\n",
            "################## python_version\n",
            "################## langchain_version\n",
            "################## run_type\n",
            "################## model_converter\n",
            "################## session_id\n",
            "################## child_run_ids\n",
            "################## sdk_version\n",
            "################## start_time\n",
            "################## end_time\n",
            "################## platform\n",
            "################## python_version\n",
            "################## langchain_version\n",
            "################## run_type\n",
            "################## sketch_generator\n",
            "################## session_id\n",
            "################## child_run_ids\n",
            "################## sdk_version\n",
            "################## start_time\n",
            "################## end_time\n",
            "################## platform\n",
            "################## python_version\n",
            "################## langchain_version\n",
            "################## run_type\n"
          ]
        }
      ],
      "source": [
        "# List of columns to drop\n",
        "columns_to_drop = [\n",
        "    \"session_id\",\n",
        "    \"child_run_ids\",\n",
        "    \"sdk_version\",\n",
        "    \"start_time\",\n",
        "    \"end_time\",\n",
        "    \"platform\",\n",
        "    \"python_version\",\n",
        "    \"langchain_version\",\n",
        "    \"run_type\",\n",
        "]\n",
        "# for df in df_list:\n",
        "for df, current_batch in zip(df_list, [dp_batch, mc_batch, sg_batch]):\n",
        "    print(\"##################\", current_batch[\"name\"])\n",
        "    # Drop the columns\n",
        "    for col in columns_to_drop:\n",
        "        print(\"##################\", col)\n",
        "        if col in df.columns:\n",
        "            df = df.drop(columns=[col])\n",
        "    # Show remaining columns\n",
        "    # print(\"Remaining columns:\")\n",
        "    # print(df.columns.tolist())\n",
        "    df_list.append(df)\n",
        "\n",
        "if len(df_list) != 6:\n",
        "    raise ValueError(\n",
        "        \"df_list should contain 6 dataframes, but got {}\".format(len(df_list))\n",
        "    )\n",
        "df_list = df_list[-3:]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3e0f6d65",
      "metadata": {},
      "source": [
        "## Sort the dataframe by num_run\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "5667c32e",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sorted DataFrame by num_run:\n",
            "   num_run                        name  trace_id\n",
            "0        0            5c_dp_task_stack  5c77850d\n",
            "1        0  5c_dp_operation_code_gen#8  5c77850d\n",
            "2        0  5c_dp_operation_code_gen#7  5c77850d\n",
            "3        0  5c_dp_operation_code_gen#6  5c77850d\n",
            "4        0  5c_dp_operation_code_gen#5  5c77850d\n",
            "\n",
            "Range of num_run values:\n",
            "Min: 0, Max: 19\n",
            "Sorted DataFrame by num_run:\n",
            "   num_run                                  name  trace_id\n",
            "0        0             0c_mc_conversion_code_gen  0cda415f\n",
            "1        0  0c_mc_failure_signal_model_converter  0cda415f\n",
            "2        0                 0c_mc_error_handling5  0cda415f\n",
            "3        0                 0c_mc_error_handling2  0cda415f\n",
            "4        0                 0c_mc_error_handling3  0cda415f\n",
            "\n",
            "Range of num_run values:\n",
            "Min: 0, Max: 19\n",
            "Sorted DataFrame by num_run:\n",
            "   num_run                                   name  trace_id\n",
            "0        0                       64_sg_task_stack  6489146f\n",
            "1        0  64_sg_failure_signal_sketch_generator  6489146f\n",
            "2        0                  64_sg_error_handling5  6489146f\n",
            "3        0                  64_sg_error_handling4  6489146f\n",
            "4        0                     64_sg_spec_filling  6489146f\n",
            "\n",
            "Range of num_run values:\n",
            "Min: 0, Max: 19\n"
          ]
        }
      ],
      "source": [
        "for df in df_list:\n",
        "    # Sort DataFrame by num_run\n",
        "    df = df.sort_values(\"num_run\")\n",
        "\n",
        "    # Reset index after sorting\n",
        "    df = df.reset_index(drop=True)\n",
        "\n",
        "    # Display first few rows to verify sorting\n",
        "    print(\"Sorted DataFrame by num_run:\")\n",
        "    print(df[[\"num_run\", \"name\", \"trace_id\"]].head())\n",
        "\n",
        "    # Optional: Display full range of num_run\n",
        "    print(\"\\nRange of num_run values:\")\n",
        "    print(f\"Min: {df['num_run'].min()}, Max: {df['num_run'].max()}\")\n",
        "\n",
        "if len(df_list) != 3:\n",
        "    raise ValueError(\n",
        "        \"df_list should contain 3 dataframes, but got {}\".format(len(df_list))\n",
        "    )\n",
        "# df_list = df_list[-3:]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "91a8e806",
      "metadata": {},
      "source": [
        "## Combine the subtasks into one task (based on the shared trace_id)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "743c0020",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Processed DataFrame Info:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Index: 20 entries, 8 to 15\n",
            "Data columns (total 14 columns):\n",
            " #   Column             Non-Null Count  Dtype  \n",
            "---  ------             --------------  -----  \n",
            " 0   num_run            20 non-null     int64  \n",
            " 1   name               20 non-null     object \n",
            " 2   trace_id           20 non-null     object \n",
            " 3   latency            20 non-null     float64\n",
            " 4   network_latency    20 non-null     float64\n",
            " 5   total_tokens       20 non-null     int64  \n",
            " 6   total_cost         20 non-null     float64\n",
            " 7   status             20 non-null     object \n",
            " 8   batch_id           20 non-null     object \n",
            " 9   tags               20 non-null     object \n",
            " 10  prompt_tokens      20 non-null     int64  \n",
            " 11  completion_tokens  20 non-null     int64  \n",
            " 12  prompt_cost        20 non-null     float64\n",
            " 13  completion_cost    20 non-null     float64\n",
            "dtypes: float64(5), int64(4), object(5)\n",
            "memory usage: 2.3+ KB\n",
            "None\n",
            "\n",
            "First few rows:\n",
            "    num_run   name  trace_id     latency  network_latency  total_tokens  \\\n",
            "8         0  5c_dp  5c77850d   78.025086         1.734907         18586   \n",
            "13        1  a2_dp  a2e9e5f1  117.880463         2.251657         27874   \n",
            "5         2  3d_dp  3d57e52c   96.033112         1.799765         19308   \n",
            "11        3  8c_dp  8cbdc248   86.135508         1.635450         18982   \n",
            "10        4  79_dp  79547eb9   79.343044         1.706554         19126   \n",
            "\n",
            "    total_cost   status       batch_id                                  tags  \\\n",
            "8     0.004834  success  1128_dp_batch  benchmark,data_processor,gpt-4o-mini   \n",
            "13    0.007073  success  1128_dp_batch  benchmark,data_processor,gpt-4o-mini   \n",
            "5     0.005009  success  1128_dp_batch  benchmark,data_processor,gpt-4o-mini   \n",
            "11    0.005083  success  1128_dp_batch  benchmark,data_processor,gpt-4o-mini   \n",
            "10    0.005030  success  1128_dp_batch  benchmark,data_processor,gpt-4o-mini   \n",
            "\n",
            "    prompt_tokens  completion_tokens  prompt_cost  completion_cost  \n",
            "8           14040               4546     0.002106         0.002728  \n",
            "13          21448               6426     0.003217         0.003856  \n",
            "5           14612               4696     0.002192         0.002818  \n",
            "11          14014               4968     0.002102         0.002981  \n",
            "10          14324               4802     0.002149         0.002881  \n",
            "\n",
            "Unique names per trace_id after processing:\n",
            "name\n",
            "1    20\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Processed DataFrame Info:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Index: 20 entries, 1 to 13\n",
            "Data columns (total 14 columns):\n",
            " #   Column             Non-Null Count  Dtype  \n",
            "---  ------             --------------  -----  \n",
            " 0   num_run            20 non-null     int64  \n",
            " 1   name               20 non-null     object \n",
            " 2   trace_id           20 non-null     object \n",
            " 3   latency            20 non-null     float64\n",
            " 4   network_latency    20 non-null     float64\n",
            " 5   total_tokens       20 non-null     int64  \n",
            " 6   total_cost         20 non-null     float64\n",
            " 7   status             20 non-null     object \n",
            " 8   batch_id           20 non-null     object \n",
            " 9   tags               20 non-null     object \n",
            " 10  prompt_tokens      20 non-null     int64  \n",
            " 11  completion_tokens  20 non-null     int64  \n",
            " 12  prompt_cost        20 non-null     float64\n",
            " 13  completion_cost    20 non-null     float64\n",
            "dtypes: float64(5), int64(4), object(5)\n",
            "memory usage: 2.3+ KB\n",
            "None\n",
            "\n",
            "First few rows:\n",
            "    num_run   name  trace_id    latency  network_latency  total_tokens  \\\n",
            "1         0  0c_mc  0cda415f  22.193792         0.966722          9068   \n",
            "5         1  2e_mc  2e36eabc  15.635896         0.812361         11228   \n",
            "11        2  87_mc  8772aab0   9.393618         0.483918          3947   \n",
            "18        3  ef_mc  ef88b426   7.188514         0.396511          2615   \n",
            "16        4  b4_mc  b4da759c   3.546397         0.229117           519   \n",
            "\n",
            "    total_cost   status       batch_id                                   tags  \\\n",
            "1     0.001886    error  1128_mc_batch  benchmark,gpt-4o-mini,model_converter   \n",
            "5     0.002204  success  1128_mc_batch  benchmark,gpt-4o-mini,model_converter   \n",
            "11    0.000819  success  1128_mc_batch  benchmark,gpt-4o-mini,model_converter   \n",
            "18    0.000593  success  1128_mc_batch  benchmark,gpt-4o-mini,model_converter   \n",
            "16    0.000177  success  1128_mc_batch  benchmark,gpt-4o-mini,model_converter   \n",
            "\n",
            "    prompt_tokens  completion_tokens  prompt_cost  completion_cost  \n",
            "1            7900               1168     0.001185         0.000701  \n",
            "5           10073               1155     0.001511         0.000693  \n",
            "11           3442                505     0.000516         0.000303  \n",
            "18           2170                445     0.000325         0.000267  \n",
            "16            299                220     0.000045         0.000132  \n",
            "\n",
            "Unique names per trace_id after processing:\n",
            "name\n",
            "1    20\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Processed DataFrame Info:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Index: 20 entries, 4 to 0\n",
            "Data columns (total 14 columns):\n",
            " #   Column             Non-Null Count  Dtype  \n",
            "---  ------             --------------  -----  \n",
            " 0   num_run            20 non-null     int64  \n",
            " 1   name               20 non-null     object \n",
            " 2   trace_id           20 non-null     object \n",
            " 3   latency            20 non-null     float64\n",
            " 4   network_latency    20 non-null     float64\n",
            " 5   total_tokens       20 non-null     int64  \n",
            " 6   total_cost         20 non-null     float64\n",
            " 7   status             20 non-null     object \n",
            " 8   batch_id           20 non-null     object \n",
            " 9   tags               20 non-null     object \n",
            " 10  prompt_tokens      20 non-null     int64  \n",
            " 11  completion_tokens  20 non-null     int64  \n",
            " 12  prompt_cost        20 non-null     float64\n",
            " 13  completion_cost    20 non-null     float64\n",
            "dtypes: float64(5), int64(4), object(5)\n",
            "memory usage: 2.3+ KB\n",
            "None\n",
            "\n",
            "First few rows:\n",
            "    num_run   name  trace_id     latency  network_latency  total_tokens  \\\n",
            "4         0  64_sg  6489146f   93.519877         1.323120         31982   \n",
            "11        1  95_sg  95368318   72.027652         1.378764         29410   \n",
            "19        2  f1_sg  f10bd938   73.433595         1.025651         29402   \n",
            "5         3  68_sg  68e4fae8   97.477158         1.158438         33098   \n",
            "18        4  eb_sg  eb706d82  104.899247         1.269422         31452   \n",
            "\n",
            "    total_cost status       batch_id                                    tags  \\\n",
            "4     0.008081  error  1128_sg_batch  benchmark,gpt-4o-mini,sketch_generator   \n",
            "11    0.007058  error  1128_sg_batch  benchmark,gpt-4o-mini,sketch_generator   \n",
            "19    0.007030  error  1128_sg_batch  benchmark,gpt-4o-mini,sketch_generator   \n",
            "5     0.008489  error  1128_sg_batch  benchmark,gpt-4o-mini,sketch_generator   \n",
            "18    0.007879  error  1128_sg_batch  benchmark,gpt-4o-mini,sketch_generator   \n",
            "\n",
            "    prompt_tokens  completion_tokens  prompt_cost  completion_cost  \n",
            "4           24684               7298     0.003703         0.004379  \n",
            "11          23528               5882     0.003529         0.003529  \n",
            "19          23580               5822     0.003537         0.003493  \n",
            "5           25266               7832     0.003790         0.004699  \n",
            "18          24428               7024     0.003664         0.004214  \n",
            "\n",
            "Unique names per trace_id after processing:\n",
            "name\n",
            "1    20\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def process_df(df):\n",
        "    # 1. Process names - take first 2 sections\n",
        "    df[\"name\"] = df[\"name\"].apply(lambda x: \"_\".join(x.split(\"_\")[:2]))\n",
        "\n",
        "    # Check name consistency within trace_id groups\n",
        "    name_consistency = df.groupby(\"trace_id\")[\"name\"].nunique()\n",
        "    if not all(name_consistency == 1):\n",
        "        print(\"Warning: Inconsistent names found within trace_id groups:\")\n",
        "        print(name_consistency[name_consistency > 1])\n",
        "\n",
        "    # 2. Remove id column\n",
        "    df = df.drop(columns=[\"id\"])\n",
        "\n",
        "    # Check consistency of num_run, batch_id, tags within trace_id groups\n",
        "    for col in [\"num_run\", \"batch_id\", \"tags\"]:\n",
        "        consistency = df.groupby(\"trace_id\")[col].nunique()\n",
        "        if not all(consistency == 1):\n",
        "            print(f\"Warning: Inconsistent {col} found within trace_id groups:\")\n",
        "            print(consistency[consistency > 1])\n",
        "\n",
        "    # Columns to aggregate\n",
        "    sum_columns = [\n",
        "        \"latency\",\n",
        "        \"network_latency\",\n",
        "        \"prompt_tokens\",\n",
        "        \"completion_tokens\",\n",
        "        \"total_tokens\",\n",
        "        \"prompt_cost\",\n",
        "        \"completion_cost\",\n",
        "        \"total_cost\",\n",
        "    ]\n",
        "\n",
        "    def aggregate_status(x):\n",
        "        if \"error\" in x.values:\n",
        "            return \"error\"\n",
        "        return \"success\" if all(x == \"success\") else \"error\"\n",
        "\n",
        "    # Aggregate by trace_id\n",
        "    agg_dict = {\n",
        "        \"name\": \"first\",\n",
        "        \"num_run\": \"first\",\n",
        "        \"batch_id\": \"first\",\n",
        "        \"tags\": \"first\",\n",
        "        \"status\": aggregate_status,\n",
        "    }\n",
        "\n",
        "    # Add sum aggregation for numeric columns\n",
        "    for col in sum_columns:\n",
        "        agg_dict[col] = lambda x: x[x.notna()].sum()\n",
        "\n",
        "    # Perform groupby and aggregation\n",
        "    df_combined = df.groupby(\"trace_id\").agg(agg_dict).reset_index()\n",
        "\n",
        "    # 7. Reorder columns\n",
        "    column_order = [\n",
        "        \"num_run\",\n",
        "        \"name\",\n",
        "        \"trace_id\",\n",
        "        \"latency\",\n",
        "        \"network_latency\",\n",
        "        \"total_tokens\",\n",
        "        \"total_cost\",\n",
        "        \"status\",\n",
        "        \"batch_id\",\n",
        "        \"tags\",\n",
        "        \"prompt_tokens\",\n",
        "        \"completion_tokens\",\n",
        "        \"prompt_cost\",\n",
        "        \"completion_cost\",\n",
        "    ]\n",
        "    df_combined = df_combined[column_order]\n",
        "\n",
        "    # 8. Sort by num_run\n",
        "    df_combined = df_combined.sort_values(\"num_run\")\n",
        "\n",
        "    return df_combined\n",
        "\n",
        "\n",
        "df_processed_list = []\n",
        "if len(df_list) != 3:\n",
        "    raise ValueError(\n",
        "        \"df_list should contain 3 dataframes, but got {}\".format(len(df_list))\n",
        "    )\n",
        "\n",
        "for df in df_list:\n",
        "    # Apply the processing\n",
        "    df_processed = process_df(df)\n",
        "    df_processed_list.append(df_processed)\n",
        "\n",
        "    # Display results\n",
        "    print(\"\\nProcessed DataFrame Info:\")\n",
        "    print(df_processed.info())\n",
        "    print(\"\\nFirst few rows:\")\n",
        "    print(df_processed.head())\n",
        "\n",
        "    # Additional verification\n",
        "    print(\"\\nUnique names per trace_id after processing:\")\n",
        "    print(df_processed.groupby(\"trace_id\")[\"name\"].nunique().value_counts())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "09739400",
      "metadata": {},
      "source": [
        "## Calculate clean latency\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "4be66738",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "After calculation:\n",
            "       latency  network_latency\n",
            "8    74.555273         1.734907\n",
            "13  113.377148         2.251657\n",
            "5    92.433582         1.799765\n",
            "11   82.864608         1.635450\n",
            "10   75.929935         1.706554\n",
            "\n",
            "After calculation:\n",
            "      latency  network_latency\n",
            "1   20.260347         0.966722\n",
            "5   14.011174         0.812361\n",
            "11   8.425783         0.483918\n",
            "18   6.395492         0.396511\n",
            "16   3.088163         0.229117\n",
            "\n",
            "After calculation:\n",
            "       latency  network_latency\n",
            "4    90.873637         1.323120\n",
            "11   69.270124         1.378764\n",
            "19   71.382294         1.025651\n",
            "5    95.160282         1.158438\n",
            "18  102.360403         1.269422\n"
          ]
        }
      ],
      "source": [
        "for df_processed in df_processed_list[-3:]:\n",
        "    # Calculate new latency\n",
        "    df_processed[\"latency\"] = df_processed[\"latency\"] - (\n",
        "        2 * df_processed[\"network_latency\"]\n",
        "    )\n",
        "\n",
        "    # Show results\n",
        "    print(\"\\nAfter calculation:\")\n",
        "    print(df_processed[[\"latency\", \"network_latency\"]].head())\n",
        "\n",
        "    # Check for any negative values (which might indicate issues)\n",
        "    negative_latency = df_processed[df_processed[\"latency\"] < 0]\n",
        "    if len(negative_latency) > 0:\n",
        "        print(\"\\nWarning: Found negative latency values:\")\n",
        "        print(negative_latency[[\"trace_id\", \"latency\", \"network_latency\"]])\n",
        "\n",
        "    # Remove network_latency column\n",
        "    df_processed = df_processed.drop(columns=[\"network_latency\"])\n",
        "\n",
        "    # Reorder columns\n",
        "    column_order = [\n",
        "        \"num_run\",\n",
        "        \"name\",\n",
        "        \"trace_id\",\n",
        "        \"latency\",\n",
        "        \"total_tokens\",\n",
        "        \"total_cost\",\n",
        "        \"status\",\n",
        "        \"batch_id\",\n",
        "        \"tags\",\n",
        "        \"prompt_tokens\",\n",
        "        \"completion_tokens\",\n",
        "        \"prompt_cost\",\n",
        "        \"completion_cost\",\n",
        "    ]\n",
        "    df_processed = df_processed[column_order]\n",
        "\n",
        "    df_processed_list.append(df_processed)\n",
        "\n",
        "if len(df_processed_list) != 6:\n",
        "    raise ValueError(\n",
        "        \"df_processed_list should contain 6 dataframes, but got {}\".format(\n",
        "            len(df_processed_list)\n",
        "        )\n",
        "    )\n",
        "df_processed_list = df_processed_list[-3:]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f54feca7",
      "metadata": {},
      "source": [
        "## Save to csv\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "c0f44bbe",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DataFrame saved to: /Users/hann/Projects/reference-benchmark-tinyml_llm/data_analysis/11.28/processed_data/clean_data_processor_1128_dp_batch.csv\n",
            "File size: 3170 bytes\n",
            "\n",
            "First few lines of saved file:\n",
            "num_run,name,trace_id,latency,total_tokens,total_cost,status,batch_id,tags,prompt_tokens,completion_tokens,prompt_cost,completion_cost\n",
            "0,5c_dp,5c77850d,74.5552726531372,18586,0.0048336,success,1128_dp_batch,\"benchmark,data_processor,gpt-4o-mini\",14040,4546,0.002106,0.0027276\n",
            "DataFrame saved to: /Users/hann/Projects/reference-benchmark-tinyml_llm/data_analysis/11.28/processed_data/clean_model_converter_1128_mc_batch.csv\n",
            "File size: 3160 bytes\n",
            "\n",
            "First few lines of saved file:\n",
            "num_run,name,trace_id,latency,total_tokens,total_cost,status,batch_id,tags,prompt_tokens,completion_tokens,prompt_cost,completion_cost\n",
            "0,0c_mc,0cda415f,20.260347023193358,9068,0.0018858,error,1128_mc_batch,\"benchmark,gpt-4o-mini,model_converter\",7900,1168,0.0011849999999999999,0.0007008\n",
            "DataFrame saved to: /Users/hann/Projects/reference-benchmark-tinyml_llm/data_analysis/11.28/processed_data/clean_sketch_generator_1128_sg_batch.csv\n",
            "File size: 3220 bytes\n",
            "\n",
            "First few lines of saved file:\n",
            "num_run,name,trace_id,latency,total_tokens,total_cost,status,batch_id,tags,prompt_tokens,completion_tokens,prompt_cost,completion_cost\n",
            "0,64_sg,6489146f,90.87363676562501,31982,0.008081399999999999,error,1128_sg_batch,\"benchmark,gpt-4o-mini,sketch_generator\",24684,7298,0.0037026000000000003,0.0043788\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "for df_processed, current_batch in zip(\n",
        "    df_processed_list, [dp_batch, mc_batch, sg_batch]\n",
        "):\n",
        "\n",
        "    # Create the filename\n",
        "    filename = f\"{parent_dir}/processed_data/clean_{current_batch['name']}_{current_batch['batch_id']}.csv\"\n",
        "\n",
        "    # Save to CSV\n",
        "    df_processed.to_csv(filename, index=False)\n",
        "\n",
        "    print(f\"DataFrame saved to: {filename}\")\n",
        "\n",
        "    # Verify the file was created\n",
        "    if os.path.exists(filename):\n",
        "        print(f\"File size: {os.path.getsize(filename)} bytes\")\n",
        "        # Show first few lines of saved file\n",
        "        print(\"\\nFirst few lines of saved file:\")\n",
        "        with open(filename, \"r\") as f:\n",
        "            print(f.readline().strip())  # Headers\n",
        "            print(f.readline().strip())  # First data row"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "766b584e",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Error processing data_processor: [Errno 2] No such file or directory: 'processed_data//Users/hann/Projects/reference-benchmark-tinyml_llm/data_analysis/11.28/clean_data_processor_1128_dp_batch.csv'\n",
            "\n",
            "Error processing model_converter: [Errno 2] No such file or directory: 'processed_data//Users/hann/Projects/reference-benchmark-tinyml_llm/data_analysis/11.28/clean_model_converter_1128_mc_batch.csv'\n",
            "\n",
            "Error processing sketch_generator: [Errno 2] No such file or directory: 'processed_data//Users/hann/Projects/reference-benchmark-tinyml_llm/data_analysis/11.28/clean_sketch_generator_1128_sg_batch.csv'\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def validate_data(df, task_name):\n",
        "    print(f\"\\n{'='*50}\")\n",
        "    print(f\"Validation for {task_name}\")\n",
        "    print(f\"{'='*50}\")\n",
        "\n",
        "    # Cost Validation\n",
        "    print(\"\\n=== Cost Validation ===\")\n",
        "    df[\"calculated_total_cost\"] = df[\"prompt_cost\"] + df[\"completion_cost\"]\n",
        "    df[\"cost_difference\"] = (df[\"total_cost\"] - df[\"calculated_total_cost\"]).abs()\n",
        "\n",
        "    # Token Validation\n",
        "    print(\"\\n=== Token Validation ===\")\n",
        "    df[\"calculated_total_tokens\"] = df[\"prompt_tokens\"] + df[\"completion_tokens\"]\n",
        "    df[\"token_difference\"] = (df[\"total_tokens\"] - df[\"calculated_total_tokens\"]).abs()\n",
        "\n",
        "    # Check for mismatches\n",
        "    cost_threshold = 0.0001\n",
        "    cost_mismatches = df[df[\"cost_difference\"] > cost_threshold]\n",
        "    token_mismatches = df[df[\"token_difference\"] > 0]  # Tokens should match exactly\n",
        "\n",
        "    # Print results\n",
        "    print(\"\\nCost Analysis:\")\n",
        "    print(f\"Total rows: {len(df)}\")\n",
        "    print(f\"Rows with cost mismatches: {len(cost_mismatches)}\")\n",
        "    if len(cost_mismatches) > 0:\n",
        "        print(\"\\nSample of cost mismatches:\")\n",
        "        print(\n",
        "            cost_mismatches[\n",
        "                [\n",
        "                    \"prompt_cost\",\n",
        "                    \"completion_cost\",\n",
        "                    \"calculated_total_cost\",\n",
        "                    \"total_cost\",\n",
        "                    \"cost_difference\",\n",
        "                ]\n",
        "            ]\n",
        "            .head()\n",
        "            .to_string()\n",
        "        )\n",
        "\n",
        "    print(\"\\nToken Analysis:\")\n",
        "    print(f\"Total rows: {len(df)}\")\n",
        "    print(f\"Rows with token mismatches: {len(token_mismatches)}\")\n",
        "    if len(token_mismatches) > 0:\n",
        "        print(\"\\nSample of token mismatches:\")\n",
        "        print(\n",
        "            token_mismatches[\n",
        "                [\n",
        "                    \"prompt_tokens\",\n",
        "                    \"completion_tokens\",\n",
        "                    \"calculated_total_tokens\",\n",
        "                    \"total_tokens\",\n",
        "                    \"token_difference\",\n",
        "                ]\n",
        "            ]\n",
        "            .head()\n",
        "            .to_string()\n",
        "        )\n",
        "\n",
        "    # Statistics\n",
        "    print(\"\\nStatistics:\")\n",
        "    print(\"Costs:\")\n",
        "    print(f\"Mean difference: {df['cost_difference'].mean():.6f}\")\n",
        "    print(f\"Max difference: {df['cost_difference'].max():.6f}\")\n",
        "    print(\"\\nTokens:\")\n",
        "    print(f\"Mean difference: {df['token_difference'].mean():.1f}\")\n",
        "    print(f\"Max difference: {df['token_difference'].max():.1f}\")\n",
        "\n",
        "\n",
        "# # Define batches\n",
        "# batches = {\n",
        "#     \"Data Processor\": {\"name\": \"data_processor\", \"batch_id\": \"2117_batch\"},\n",
        "#     \"Model Converter\": {\"name\": \"model_converter\", \"batch_id\": \"7121_batch\"},\n",
        "#     \"Sketch Generator\": {\"name\": \"sketch_generator\", \"batch_id\": \"1730_batch\"},\n",
        "# }\n",
        "\n",
        "# Load and validate each dataset\n",
        "data_dir = \"processed_data\"\n",
        "for current_batch in [dp_batch, mc_batch, sg_batch]:\n",
        "    try:\n",
        "        input_csv = f\"{parent_dir}/clean_{current_batch['name']}_{current_batch['batch_id']}.csv\"\n",
        "        df = pd.read_csv(f\"{data_dir}/{input_csv}\")\n",
        "        validate_data(df, current_batch[\"name\"])\n",
        "    except Exception as e:\n",
        "        print(f\"\\nError processing {current_batch['name']}: {str(e)}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}

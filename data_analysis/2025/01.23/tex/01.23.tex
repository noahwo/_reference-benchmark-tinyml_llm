\newpage
\subsection{2025.01.23, qwen2.5-coder:14b}
\FloatBarrier
\input{data_analysis/2025/01.23/tex/tab_token_details_qwen2.5-coder:14b_01.23}
\input{data_analysis/2025/01.23/tex/tab_performance_metrics_qwen2.5-coder:14b_01.23}
\input{data_analysis/2025/01.23/tex/tab_cost_details_qwen2.5-coder:14b_01.23}
\input{data_analysis/2025/01.23/tex/tab_performance_metrics_ave_qwen2.5-coder:14b_01.23}
\input{data_analysis/2025/01.23/tex/tab_time_qwen2.5-coder:14b_01.23}
\newpage
\begin{figure}[!h]
    \centering
    \includegraphics[width=0.75\linewidth]{data_analysis/2025/01.23/tex/scatter_plot_qwen2.5-coder:14b_01.23.pdf}
    \caption{Distribution of time and token consumption in three tasks. Model: qwen2.5-coder:14b, Date: 01.23.}
    \label{fig:scatter_qwen2.5-coder:14b_01.23}
\end{figure}

\begin{figure}[!h]
    \centering
    \includegraphics[width=0.75\linewidth]{data_analysis/2025/01.23/tex/bar_plot_qwen2.5-coder:14b_01.23.pdf}
    \caption{Average Time and Token Consumption by Task Status. Model: qwen2.5-coder:14b, Date: 01.23. \\ \textit{The average time (top) and token consumption (bottom) are compared across three stages, broken down by overall performance (considering all runs), performance of only successful runs, and of only the failed runs.}}
    \label{fig:bar_qwen2.5-coder:14b_01.23}
\end{figure}



\newpage
\subsection{ 2025.01.23, Model: deepseek-r1:14b}
In this test, we used Deepseek's \texttt{deepseek-r1:14b}, which is a reasoning LLM in their reasoning series of LLMs. Similar to OpenAI's \texttt{o1} series, it trades off speed for more powerful reasoning ability. It also outputs the reasoning process before the real answer to the question. A typical output is shown below \ref{fig:deepseekr1_example}. Although the model is powerful at its reasoning capability according to recent studies and tests, our own test results that are based on using its direct output as engineering code are not outstanding. Perhaps the reasoning model series can be excellent for providing helpful insights into human-in-the-loop engineering tasks instead.
\begin{figure}[!h]
    \centering
\includegraphics[width=0.75\linewidth]{data_analysis/2025/01.23/tex/deepseekr1_example.png}
\caption{An example output of \texttt{deepseek-r1:14b}.}
\label{fig:deepseekr1_example}
\end{figure}
\input{data_analysis/2025/01.23/tex/tab_token_details_deepseek-r1:14b_01.23}
\input{data_analysis/2025/01.23/tex/tab_performance_metrics_deepseek-r1:14b_01.23}
\input{data_analysis/2025/01.23/tex/tab_cost_details_deepseek-r1:14b_01.23}
\input{data_analysis/2025/01.23/tex/tab_performance_metrics_ave_deepseek-r1:14b_01.23}
\input{data_analysis/2025/01.23/tex/tab_time_deepseek-r1:14b_01.23}
\newpage
\begin{figure}[!h]
    \centering
    \includegraphics[width=0.75\linewidth]{data_analysis/2025/01.23/tex/scatter_plot_deepseek-r1:14b_01.23.pdf}
    \caption{Distribution of time and token consumption in three tasks. Model: deepseek-r1:14b, Date: 01.23.}
    \label{fig:scatter_deepseek-r1:14b_01.23}
\end{figure}

\begin{figure}[!h]
    \centering
    \includegraphics[width=0.75\linewidth]{data_analysis/2025/01.23/tex/bar_plot_deepseek-r1:14b_01.23.pdf}
    \caption{Average Time and Token Consumption by Task Status. Model: deepseek-r1:14b, Date: 01.23. \\ \textit{The average time (top) and token consumption (bottom) are compared across three stages, broken down by overall performance (considering all runs), performance of only successful runs, and of only the failed runs.}}
    \label{fig:bar_deepseek-r1:14b_01.23}
\end{figure}


{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setting up\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ref: https://langfuse.com/docs/query-traces\n",
    "import os\n",
    "import json\n",
    "from langfuse import Langfuse\n",
    "import json\n",
    "import os\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "\n",
    "LANGFUSE_SERVICE_PUBLIC_KEY = \"pk-lf-559a2c0f-ee29-4c32-944c-bf73b5f0ce28\"\n",
    "LANGFUSE_SERVICE_SECRET_KEY = \"sk-lf-75f8bf7f-a5db-4756-b0dd-d758a2a292c8\"\n",
    "LANGFUSE_SERVICE_HOST = \"https://langfuse.hann.fi\"\n",
    "\n",
    "LOCAL_HOST = True\n",
    "\n",
    "\n",
    "\"\"\"Define paths\"\"\"\n",
    "# print(os.getcwd())\n",
    "parent_dir = os.path.dirname(os.getcwd())\n",
    "\n",
    "# date = \"03.18\"\n",
    "date = os.path.basename(parent_dir)\n",
    "tex_dir = os.path.join(parent_dir, \"tex\")\n",
    "processed_data_dir = os.path.join(parent_dir, \"processed_data\")\n",
    "raw_export_dir = os.path.join(parent_dir, \"raw_export\")\n",
    "ipynb_dir = os.path.join(parent_dir, \"ipynb\")\n",
    "\n",
    "\"\"\"Define session_id\"\"\"\n",
    "# session_id=\"qwen2.5-coder_f4d4_dp_batch\"\n",
    "session_id_list = [\n",
    "    # \"qwen2.5-coder:32b_4e11_tpsg_batch\",\n",
    "    # \"qwen2.5-coder:32b_ae24_tpsg_batch\"\n",
    "    \"codestral_c8f6_tpusg_batch\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Export raw data\n",
    "\n",
    "Langfuse added a limit of 20 API invocations per minute. https://langfuse.com/faq/all/api-limits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching traces for session codestral_c8f6_tpusg_batch...\n",
      "Fetching observation data for time-18-09-45-499622_chatcmpl-7ad913a3-3ed0-4407-98f8-3e1aab6a0485...\n",
      "Fetching observation data for time-18-10-10-406436_chatcmpl-dc1d73e7-5187-4224-97d1-36f54d8da6ca...\n",
      "Fetching observation data for time-18-10-42-554396_chatcmpl-ffb344da-21d0-44c4-b95d-195163dd6abc...\n",
      "Fetching observation data for time-18-11-18-359024_chatcmpl-0543d934-0341-48cd-911c-75666577ab3a...\n",
      "Fetching observation data for time-18-11-58-465070_chatcmpl-dcde08e9-cbb1-461d-a8f1-1edc26651e37...\n",
      "Fetching observation data for eab18326-9f78-4f74-93e5-b4fa515669a4...\n",
      "Fetching observation data for time-18-07-03-411970_chatcmpl-6d716bff-c39d-47bb-b450-1a843ddf9e80...\n",
      "Fetching observation data for time-18-07-36-343073_chatcmpl-15d04ba9-3436-4753-9a0a-7dca60861077...\n",
      "Fetching observation data for time-18-08-16-414315_chatcmpl-06dfeaef-124d-4170-96a8-6e15e8e4d6a2...\n",
      "Fetching observation data for time-18-05-20-820874_chatcmpl-4a49009c-c3b2-4c38-91f4-7d3f0e9a0f10...\n",
      "Fetching observation data for time-18-06-03-136783_chatcmpl-62ec6609-778f-4739-951e-9d79630ed1bb...\n",
      "Fetching observation data for time-18-06-10-828115_chatcmpl-bb54be12-79ea-47f3-bcc3-7ec422589b72...\n",
      "Fetching observation data for time-18-06-47-334934_chatcmpl-e2a587db-1269-4e44-83e7-e9338d0346a7...\n",
      "Fetching observation data for time-18-06-51-447239_chatcmpl-17df6492-0881-4e92-8dda-459a5245043d...\n",
      "Fetching observation data for 7d9e1b87-7054-4a62-a2ab-344acfec75c6...\n",
      "Fetching observation data for time-18-02-29-270461_chatcmpl-1a2cbc7b-90e5-42fc-930a-da621f6f4a2e...\n",
      "Fetching observation data for time-18-03-08-956995_chatcmpl-8a79bb6e-0aee-475e-b039-eec0d706a8e8...\n",
      "Fetching observation data for time-18-03-15-395205_chatcmpl-edbb4eaf-5573-4cbd-987c-708542be090a...\n",
      "Fetching observation data for time-18-03-56-073480_chatcmpl-43808379-6b9c-4be8-8d79-73ecc5176624...\n",
      "Fetching observation data for time-18-04-33-254342_chatcmpl-f51c603c-b021-4410-9042-66e0d5d41ddf...\n",
      "Fetching observation data for 86ea111b-99e6-4b95-ac16-de8a73532477...\n",
      "Fetching observation data for time-17-59-35-718090_chatcmpl-4315adf9-7474-4bd5-bf42-86f3245d9b05...\n",
      "Fetching observation data for time-18-00-24-289720_chatcmpl-c6ab2454-5871-4810-afb0-295b14a9ab24...\n",
      "Fetching observation data for time-18-01-14-138570_chatcmpl-51500137-7268-4865-b752-aadff4cb3d36...\n",
      "Fetching observation data for time-18-01-56-766827_chatcmpl-d4060efd-fab9-4a99-96b3-e654cec1c204...\n",
      "Fetching observation data for time-18-02-11-566718_chatcmpl-ba016a19-9318-47a4-abc3-8b280ee5a5cb...\n",
      "Fetching observation data for db18516d-e27b-4588-b554-41e6600ea4a9...\n",
      "Fetching observation data for time-17-57-34-845607_chatcmpl-22703d58-6a0b-4f61-930c-ee2f322faf13...\n",
      "Fetching observation data for time-17-58-00-032440_chatcmpl-ef8432ca-1cba-40e9-86c3-530603d0ffa4...\n",
      "Fetching observation data for time-17-58-08-525053_chatcmpl-e8c1696e-ccfc-46b7-8474-2b8850b23671...\n",
      "Fetching observation data for time-17-58-35-143296_chatcmpl-d9a78913-dcb2-44d2-975a-4c878fdb2b42...\n",
      "Fetching observation data for time-17-58-59-373035_chatcmpl-55e1d5db-ed0c-4a06-b46f-d5b8b7489706...\n",
      "Fetching observation data for 5286ee42-3355-4f8c-a19a-6fb2f9aa2ffd...\n",
      "Fetching observation data for time-17-56-16-271409_chatcmpl-b841aec3-87f1-4145-bf6c-895eb2560e15...\n",
      "Fetching observation data for time-17-56-52-259010_chatcmpl-932a44b4-6a60-4cce-837a-b8f2059e9908...\n",
      "Fetching observation data for time-17-57-02-954152_chatcmpl-f22f16e0-f3de-445e-b43d-15970554136a...\n",
      "Fetching observation data for time-17-57-16-382881_chatcmpl-889df9be-f4de-402a-8eed-fa80cd0340bb...\n",
      "Fetching observation data for time-17-57-21-534277_chatcmpl-9b84528e-9cca-4b86-ae9d-76796eb95318...\n",
      "Fetching observation data for 5497fa5b-aa53-404f-a204-a11423c3b40a...\n",
      "Fetching observation data for time-17-53-59-647360_chatcmpl-bd037f31-0fad-4640-b25b-4d2cd540c59d...\n",
      "Fetching observation data for time-17-54-21-605698_chatcmpl-6b3a1185-ad0c-4eb1-b990-fbb91c5d0ce5...\n",
      "Fetching observation data for time-17-54-34-074342_chatcmpl-af0fb7f1-8f22-450a-9bc4-4e208798b615...\n",
      "Fetching observation data for time-17-55-04-441663_chatcmpl-f3fe6d69-a744-41fd-baea-beb7a1d0c40d...\n",
      "Fetching observation data for time-17-55-36-603031_chatcmpl-50473e65-3e15-41ee-87d6-d8ea75d48429...\n",
      "Fetching observation data for 4c85066d-51b1-43f0-bfe9-efb40476e0cf...\n",
      "Fetching observation data for time-17-51-30-151349_chatcmpl-4163aab1-94b4-4b28-b03c-1cf4bcf54636...\n",
      "Fetching observation data for time-17-51-56-178515_chatcmpl-306cfdf9-3d3e-49a7-ba09-065d7a616482...\n",
      "Fetching observation data for time-17-52-04-606320_chatcmpl-03c74431-fffd-4e32-a5f4-215caa7b127c...\n",
      "Fetching observation data for time-17-52-41-506180_chatcmpl-45d9928f-1103-443f-b9fe-2f484f4fcde8...\n",
      "Fetching observation data for time-17-53-17-038001_chatcmpl-b3819625-ca3e-4b42-9fea-6615d9bd6cdb...\n",
      "Fetching observation data for 951239b7-564b-41d7-a4ef-32c7dc2c416f...\n",
      "Fetching observation data for time-17-50-11-640234_chatcmpl-485b560a-8a34-4f7b-9d55-d3955f5d3116...\n",
      "Fetching observation data for time-17-50-21-183788_chatcmpl-42a0278b-07e0-4847-ba59-fafe672db504...\n",
      "Fetching observation data for time-17-51-04-780757_chatcmpl-7c7a3429-7f98-4fac-aa5b-e81922d7c34f...\n",
      "Fetching observation data for time-17-47-23-074711_chatcmpl-77bbb05c-87b5-4937-b0c5-694117fe7adb...\n",
      "Fetching observation data for time-17-48-04-029771_chatcmpl-bca5d8bb-fd15-41ef-acc0-969e0bf92e4f...\n",
      "Fetching observation data for time-17-48-16-200074_chatcmpl-cb0cab0a-10d9-4a16-b1c9-0abd26630f8e...\n",
      "Fetching observation data for time-17-48-52-797725_chatcmpl-af6a13f7-4508-404a-aec0-e58d773c4c9a...\n",
      "Fetching observation data for time-17-49-30-106367_chatcmpl-f37259a6-aa65-4895-ba03-3817975480ff...\n",
      "Fetching observation data for 9f3ca678-8082-4e0a-9dc8-2aa6ce5970ec...\n",
      "Fetching observation data for time-17-44-17-559018_chatcmpl-917a8da7-913e-4679-be9f-351c85195c87...\n",
      "Fetching observation data for time-17-44-48-897415_chatcmpl-7a70480d-43df-4522-93b6-5b125a81d192...\n",
      "Fetching observation data for time-17-45-25-202277_chatcmpl-01371c2d-3588-42b3-b1cb-422e2d9f59f1...\n",
      "Fetching observation data for time-17-46-00-274780_chatcmpl-071d2f63-e9b3-47e3-a5eb-d380f6443322...\n",
      "Fetching observation data for time-17-46-37-849264_chatcmpl-2fe7c2a1-6274-43ea-b5d6-2b2d8ab019f6...\n",
      "Fetching observation data for a9dfc70b-895f-413e-ac48-fa5db4bc785f...\n",
      "Fetching observation data for time-17-41-39-023510_chatcmpl-b63eb99d-7758-40f1-baf3-134934e17282...\n",
      "Fetching observation data for time-17-42-10-366203_chatcmpl-83f808cb-edc5-496f-9a3d-90bcd1ec0cfd...\n",
      "Fetching observation data for time-17-42-45-383723_chatcmpl-1d64f41f-212d-4054-bba9-c762fd78fc09...\n",
      "Fetching observation data for time-17-43-21-992510_chatcmpl-575952c8-f75a-4d3a-afc1-487fc70c425c...\n",
      "Fetching observation data for time-17-43-50-390029_chatcmpl-d7d36567-8f3d-44a8-b5a9-4b2540b89ea0...\n",
      "Fetching observation data for fa34c52f-1deb-42fd-9a4b-f0d137ec02ae...\n",
      "Fetching observation data for time-17-39-43-543874_chatcmpl-a266e951-9118-444b-a55b-6931dc3a3b65...\n",
      "Fetching observation data for time-17-40-13-444565_chatcmpl-b806f8e8-cbdf-4ff4-b30b-91e4b3f49a32...\n",
      "Fetching observation data for time-17-40-21-103841_chatcmpl-1a54fe5a-de01-45b5-b746-b703c2d9ed7f...\n",
      "Fetching observation data for time-17-40-50-885169_chatcmpl-79901d44-4366-4557-854d-273bd3c71c48...\n",
      "Fetching observation data for time-17-41-24-313546_chatcmpl-9bb1ab69-502a-4713-bb16-146347d756db...\n",
      "Fetching observation data for 040e536b-b160-4218-9688-c02f4495b40a...\n",
      "Fetching observation data for time-17-37-22-449154_chatcmpl-da861c0c-5291-46d0-9b5b-4a2cee70f288...\n",
      "Fetching observation data for time-17-37-58-099999_chatcmpl-37bf6499-d3db-4ee8-a574-6c1cb4442afa...\n",
      "Fetching observation data for time-17-38-31-477849_chatcmpl-6b8a0d63-b04b-41ba-91d1-1615b92e76a0...\n",
      "Fetching observation data for time-17-38-59-592731_chatcmpl-cb5cdda8-2ccd-402c-8aa8-a1263c73de40...\n",
      "Fetching observation data for time-17-39-09-373044_chatcmpl-e31e3120-f48f-412b-b6eb-3db9762dce3c...\n",
      "Fetching observation data for 2157739a-379a-41fd-8991-54743234fb99...\n",
      "Fetching observation data for time-17-33-57-866777_chatcmpl-95b597ea-d630-4826-9f26-dcfd043024d6...\n",
      "Fetching observation data for time-17-34-30-852206_chatcmpl-ec9d2fea-a86b-4b77-a57f-97b0fb5243c1...\n",
      "Fetching observation data for time-17-35-10-324228_chatcmpl-b2973bb0-30b1-45cc-984c-9fc8d1807409...\n",
      "Fetching observation data for time-17-35-51-589202_chatcmpl-8c350dab-7f04-4c9e-9b80-80ae371d300d...\n",
      "Fetching observation data for time-17-31-51-330627_chatcmpl-0b57f145-6ffb-49a8-bfa0-96b82e265060...\n",
      "Fetching observation data for time-17-32-27-912540_chatcmpl-0d63e3c2-1a0b-4d11-a561-bd334a1672ab...\n",
      "Fetching observation data for time-17-32-44-082785_chatcmpl-64cb532c-b1a9-41ec-bf8a-9b9df2a0e82b...\n",
      "Fetching observation data for time-17-33-32-149162_chatcmpl-6d0cb003-5772-4ce6-a96e-6e4729febce9...\n",
      "Fetching observation data for time-17-33-38-375359_chatcmpl-1abaafa3-a808-4aba-abbe-7983b640a0d9...\n",
      "Fetching observation data for d61cc4b0-d636-4134-b0ab-b3c5611f5985...\n",
      "Fetching observation data for time-17-29-29-809776_chatcmpl-0f8dc2ea-2981-45a1-aab2-0cb0d4d211b4...\n",
      "Fetching observation data for time-17-30-08-885120_chatcmpl-9d256703-9e9f-48b0-a98c-6637e54d15f6...\n",
      "Fetching observation data for time-17-30-24-814937_chatcmpl-99fa6147-24aa-4d6d-9090-c37acd77059f...\n",
      "Fetching observation data for time-17-30-49-193753_chatcmpl-42d193d9-b4ff-4d7e-9e09-f562c3474274...\n",
      "Fetching observation data for time-17-31-18-588809_chatcmpl-80687bc7-1e2d-47f4-9876-e5da31a16a1d...\n",
      "Fetching observation data for f4042faf-a603-4bae-bb91-aa3bc2a4108e...\n",
      "Fetching observation data for time-17-26-30-238963_chatcmpl-582f5533-1009-49d5-b7b3-9b992f15523c...\n",
      "Fetching observation data for time-17-26-55-405580_chatcmpl-1e70a410-9dca-4880-9ffe-3312dc61340a...\n",
      "Fetching observation data for time-17-27-28-612630_chatcmpl-b5000bf3-6043-4f25-955c-93548dbeea1d...\n",
      "Fetching observation data for time-17-28-07-538297_chatcmpl-c9e0bd4e-5231-44c8-a71b-a9ebbae40cf7...\n",
      "Fetching observation data for time-17-28-42-724161_chatcmpl-0e1873da-b0a7-4e75-8062-f0766040a6c7...\n",
      "Fetching observation data for dd76dfdb-9638-45e6-8cb1-42c39523548b...\n",
      "Fetching observation data for time-17-23-06-724560_chatcmpl-75ef9077-80b3-4c15-895c-19a8460dde0e...\n",
      "Fetching observation data for time-17-23-50-389038_chatcmpl-1ad10f6b-92b8-45a9-8672-c3d08e72d3b7...\n",
      "Fetching observation data for time-17-24-28-257116_chatcmpl-75e8842d-af52-41cf-9e61-676fd335202a...\n",
      "Fetching observation data for time-17-25-05-376597_chatcmpl-ae32ef3e-4557-4a17-84d0-2dcb15f925cd...\n",
      "Fetching observation data for time-17-19-17-140993_chatcmpl-bf6042e9-ffc5-4a35-b0fb-c86912949058...\n",
      "Fetching observation data for time-17-19-49-566490_chatcmpl-fb9af05a-e466-43db-be7a-a5e56d9a69c8...\n",
      "Fetching observation data for time-17-20-22-863106_chatcmpl-46ac909f-661d-48cf-b297-46067c26b30b...\n",
      "Fetching observation data for time-17-20-59-700369_chatcmpl-01f0094d-853e-4327-9682-9a487599b551...\n",
      "Fetching observation data for time-17-21-35-522774_chatcmpl-2c47278e-35f9-4c55-9260-e0bc2434ba54...\n",
      "Fetching observation data for time-17-17-50-639226_chatcmpl-b437f040-303d-4028-a30e-744ae28bccde...\n",
      "Fetching observation data for time-17-17-58-569330_chatcmpl-fcd4de15-01ea-4a4c-958f-38fbfaac3365...\n",
      "Fetching observation data for time-17-18-23-043704_chatcmpl-214341db-2cd0-43d1-b990-e570caf3dfbd...\n",
      "Fetching observation data for time-17-18-42-961818_chatcmpl-65f5a46d-ef28-4540-84b8-cee90a2c5656...\n",
      "Fetching observation data for time-17-14-27-087721_chatcmpl-01eac8a2-b4bc-47f9-99f4-4801622a0497...\n",
      "Fetching observation data for time-17-15-08-292315_chatcmpl-53988640-d822-4b73-8ad3-5f1125778afa...\n",
      "Fetching observation data for time-17-15-48-845895_chatcmpl-44c2e4c7-7fd1-4bc0-a2e9-f54769bcf935...\n",
      "Fetching observation data for time-17-16-27-288939_chatcmpl-cf807c17-ce3d-464f-a40d-75db8dad0052...\n",
      "Fetching observation data for time-17-13-06-537980_chatcmpl-81fcfa07-3522-44cc-b1d6-3ef58d1f0d39...\n",
      "Fetching observation data for time-17-10-35-005420_chatcmpl-19324b9d-7e97-46d5-a3b0-5ea7d1b7c0fd...\n",
      "Fetching observation data for time-17-11-07-902625_chatcmpl-f51c9ab4-0206-4997-b5eb-223fb17f6426...\n",
      "Fetching observation data for time-17-11-41-256673_chatcmpl-3bd6f746-dbc9-4567-859d-7ae3b5007212...\n",
      "Fetching observation data for time-17-12-17-562367_chatcmpl-b22ff7e7-d137-4902-9d5e-c51b3c4f3e73...\n",
      "Fetching observation data for time-17-12-52-001413_chatcmpl-ab21ad62-1c40-4be2-8fdc-331fd05a22ec...\n",
      "Fetching observation data for 23d2a1e2-f474-4602-a15f-ff61169a8677...\n",
      "Fetching observation data for time-17-08-27-388099_chatcmpl-daed50b4-b9fe-4c8c-9040-3b31d34794eb...\n",
      "Fetching observation data for time-17-08-42-181429_chatcmpl-5b1884da-7946-4479-8cae-5b020d297703...\n",
      "Fetching observation data for time-17-09-11-775565_chatcmpl-8b04dd98-dcdb-427b-9f49-bb5e0381cedb...\n",
      "Fetching observation data for time-17-07-06-880088_chatcmpl-663f6d84-fbae-43b3-b707-0779f1faef16...\n",
      "Fetching observation data for time-17-07-43-981507_chatcmpl-6becc3be-c9db-4452-86c2-629ce93dade8...\n",
      "Fetching observation data for time-17-07-50-082516_chatcmpl-380e6d71-ce0f-4e0e-87b3-0ffd25e870ca...\n",
      "Fetching observation data for time-17-07-57-174894_chatcmpl-2843adba-e1fb-4004-a217-9b858933c2a8...\n",
      "Fetching observation data for time-17-08-06-806939_chatcmpl-3614aead-2399-4412-8b55-ce25d2d05630...\n",
      "Fetching observation data for 267af003-4dd5-43de-8221-e5f852d6d638...\n",
      "Fetching observation data for time-17-03-30-339722_chatcmpl-c0811721-d65d-4075-b3fb-e0a5ae4787e3...\n",
      "Fetching observation data for time-17-04-08-513555_chatcmpl-bfa3297f-d53c-400a-a5ce-c68c740e05a2...\n",
      "Fetching observation data for time-17-04-50-287534_chatcmpl-d330fa89-9b35-46ec-b1e4-cb4ce5e47ec9...\n",
      "Fetching observation data for time-17-05-36-645689_chatcmpl-06f23ae4-d9a5-496f-8871-d2c1d6181d76...\n",
      "Fetching observation data for time-16-58-59-747355_chatcmpl-1af41f3e-43b7-4101-a11a-9df5f047763a...\n",
      "Fetching observation data for time-16-59-33-826530_chatcmpl-d9e19e60-5113-4aee-bd8b-d1ce2cc71853...\n",
      "Fetching observation data for time-17-00-09-827993_chatcmpl-8692eb04-da68-4ee7-970d-a77b46239904...\n",
      "Fetching observation data for time-17-02-11-960200_chatcmpl-5f7403a0-a798-4a44-9858-fcbe38ac335b...\n",
      "Fetching observation data for time-17-02-42-769809_chatcmpl-1cba6552-09ce-4e51-b7d8-c6ca3bc9fe28...\n",
      "Fetching observation data for 6c44e65f-2ca1-4384-b40f-2210ef78777a...\n",
      "Fetching observation data for time-16-56-35-227178_chatcmpl-2697130b-462b-460d-b152-1b56d1de5b13...\n",
      "Fetching observation data for time-16-57-12-435525_chatcmpl-f6b307bf-1f66-4178-ac03-2534e8e2235f...\n",
      "Fetching observation data for time-16-57-22-780404_chatcmpl-f3538bf3-eba0-41e2-97c3-a64e4c41bc3a...\n",
      "Fetching observation data for time-16-57-50-905311_chatcmpl-f2e88aec-915b-4cea-8795-2124b6f4ecd1...\n",
      "Fetching observation data for time-16-58-21-264358_chatcmpl-9593fa8a-097d-46a9-bfd9-98601fd9e004...\n",
      "Fetching observation data for cb5bbd77-740d-465b-9a6b-4301c61b75bc...\n",
      "Raw JSON saved to: /Users/hann/Projects/reference-benchmark-tinyml_llm/data_analysis/07.29/raw_export/raw_codestral_c8f6_tpusg_batch.json\n"
     ]
    }
   ],
   "source": [
    "# ALTERNATIVE TO 2.\n",
    "import os\n",
    "import json\n",
    "from time import sleep\n",
    "from langfuse import Langfuse\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "\n",
    "if LOCAL_HOST:\n",
    "    langfuse = Langfuse(\n",
    "        secret_key=\"sk-lf-75f8bf7f-a5db-4756-b0dd-d758a2a292c8\",\n",
    "        public_key=\"pk-lf-559a2c0f-ee29-4c32-944c-bf73b5f0ce28\",\n",
    "        host=\"https://langfuse.hann.fi\",\n",
    "    )\n",
    "else:\n",
    "    langfuse = Langfuse(\n",
    "        secret_key=LANGFUSE_SERVICE_SECRET_KEY,\n",
    "        public_key=LANGFUSE_SERVICE_PUBLIC_KEY,\n",
    "        host=LANGFUSE_SERVICE_HOST,\n",
    "    )\n",
    "\n",
    "API_invok_count = 0\n",
    "query_range_num_run = {\"start\": 0, \"end\": 1}\n",
    "\n",
    "\n",
    "class CustomJSONEncoder(json.JSONEncoder):\n",
    "    def __init__(self, *args, LOCAL_HOST=True, **kwargs):\n",
    "        self.LOCAL_HOST = LOCAL_HOST\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "    def default(self, obj):\n",
    "        if isinstance(obj, datetime):\n",
    "            return obj.isoformat()\n",
    "        if hasattr(obj, \"__dict__\"):\n",
    "            data = obj.__dict__.copy()\n",
    "            if \"observations\" in data:\n",
    "                data[\"observations\"] = [\n",
    "                    fetch_observation_data(obs, self.LOCAL_HOST)\n",
    "                    for obs in data[\"observations\"]\n",
    "                ]\n",
    "\n",
    "            return data\n",
    "        return super().default(obj)\n",
    "\n",
    "\n",
    "def fetch_observation_data(observation_id, LOCAL_HOST):\n",
    "    \"\"\"\n",
    "    Fetches observation data from Langfuse and returns its dictionary representation.\n",
    "    \"\"\"\n",
    "    print(f\"Fetching observation data for {observation_id}...\")\n",
    "    global API_invok_count\n",
    "    if API_invok_count >= 0 and not LOCAL_HOST:\n",
    "        print(\"Waiting for 3 seconds to fetch observation data...\")\n",
    "        for _ in tqdm(range(3), desc=\"Progress\", unit=\"s\"):\n",
    "            sleep(1)\n",
    "        API_invok_count = 0\n",
    "\n",
    "    observation_response = langfuse.fetch_observation(observation_id)\n",
    "    API_invok_count += 1\n",
    "\n",
    "    return observation_response.data.dict()\n",
    "\n",
    "\n",
    "def fetch_and_save_complete_data(session_id_list, raw_export_dir, LOCAL_HOST):\n",
    "    \"\"\"\n",
    "    Fetches complete trace data for each session ID and saves it to JSON files.\n",
    "\n",
    "    Parameters:\n",
    "        session_id_list (list): List of session IDs to process.\n",
    "        raw_export_dir (str): Directory path to save raw JSON files.\n",
    "    \"\"\"\n",
    "\n",
    "    def save_complete_data(session_id):\n",
    "        global API_invok_count\n",
    "        if API_invok_count >= 0 and not LOCAL_HOST:\n",
    "            print(\"Waiting for 4 seconds to fetch traces...\")\n",
    "            for _ in tqdm(range(4), desc=\"Progress\", unit=\"s\"):\n",
    "                sleep(1)\n",
    "            API_invok_count = 0\n",
    "\n",
    "        fetch_traces_response = langfuse.fetch_traces(session_id=session_id)\n",
    "        API_invok_count += 1\n",
    "\n",
    "        print(f\"Fetching traces for session {session_id}...\")\n",
    "        # Create directories if they don't exist\n",
    "        os.makedirs(raw_export_dir, exist_ok=True)\n",
    "\n",
    "        # Save complete data to JSON file\n",
    "        # if session_id.startswith(\"da0a\"):\n",
    "        #     session_id = \"phi4_\" + session_id\n",
    "        if \"tpsg\" in session_id:\n",
    "            session_id_ = session_id.replace(\"tpsg\", \"tpusg\")\n",
    "        else:\n",
    "            session_id_ = session_id\n",
    "        raw_path = os.path.join(raw_export_dir, f\"raw_{session_id_}.json\")\n",
    "        with open(raw_path, \"w\") as f:\n",
    "            json.dump(fetch_traces_response, f, cls=CustomJSONEncoder, indent=2)\n",
    "\n",
    "        print(f\"Raw JSON saved to: {raw_path}\")\n",
    "\n",
    "    for session_id in session_id_list:\n",
    "        save_complete_data(session_id)\n",
    "\n",
    "\n",
    "fetch_and_save_complete_data(session_id_list, raw_export_dir, LOCAL_HOST)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Trim data\n",
    "\n",
    "Here also intercept the runs with fatal errors that need to be excluded from the analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPAN error_56_tpusg_failure_signal_tpu_sketch_generator: Failed. Last error: Traceback (most recent call last):\n",
      "  File \"script_4ba536c1_1753801949.py\", line 74, in <module>\n",
      "    predicted_label = labels[label_id]\n",
      "TypeError: only integer scalar arrays can be converted to a scalar index\n",
      "SPAN error_fe_tpusg_failure_signal_tpu_sketch_generator: Failed. Last error: Unexpected error during generation: The output is not a valid code block. Follow the instructions in the prompt return a complete, correct Python script enclosed in a single ```python\n",
      "<generated_code>\n",
      "``` block.\n",
      "SPAN error_5f_tpusg_failure_signal_tpu_sketch_generator: Failed. Last error: Traceback (most recent call last):\n",
      "  File \"script_e3245015_1753801506.py\", line 11, in <module>\n",
      "    interpreter.allocate_tensors()\n",
      "  File \"/home/mendel/tinyml_autopilot/tinyml-env/lib/python3.7/site-packages/tflite_runtime/interpreter.py\", line 408, in allocate_tensors\n",
      "    return self._interpreter.AllocateTensors()\n",
      "RuntimeError: Encountered unresolved custom op: edgetpu-custom-op.Node number 0 (edgetpu-custom-op) failed to prepare.\n",
      "\n",
      "SPAN error_25_tpusg_failure_signal_tpu_sketch_generator: Failed. Last error: Unexpected error during generation: The output is not a valid code block. Follow the instructions in the prompt return a complete, correct Python script enclosed in a single ```python\n",
      "<generated_code>\n",
      "``` block.\n",
      "SPAN error_03_tpusg_failure_signal_tpu_sketch_generator: Failed. Last error: OpenCV Error: Assertion failed (ssize.width > 0 && ssize.height > 0) in resize, file /build/opencv-tragD2/opencv-3.2.0+dfsg/modules/imgproc/src/imgwarp.cpp, line 3492\n",
      "Traceback (most recent call last):\n",
      "  File \"script_0f33c544_1753801161.py\", line 20, in <module>\n",
      "    resized_image = cv2.resize(image, (width, height)) # Resize to model's expected input shape\n",
      "cv2.error: /build/opencv-tragD2/opencv-3.2.0+dfsg/modules/imgproc/src/imgwarp.cpp:3492: error: (-215) ssize.width > 0 && ssize.height > 0 in function resize\n",
      "\n",
      "SPAN error_2d_tpusg_failure_signal_tpu_sketch_generator: Failed. Last error: Unexpected error during generation: The output is not a valid code block. Follow the instructions in the prompt return a complete, correct Python script enclosed in a single ```python\n",
      "<generated_code>\n",
      "``` block.\n",
      "SPAN error_1c_tpusg_failure_signal_tpu_sketch_generator: Failed. Last error: Traceback (most recent call last):\n",
      "  File \"script_3c109637_1753800961.py\", line 55, in <module>\n",
      "    main()\n",
      "  File \"script_3c109637_1753800961.py\", line 45, in main\n",
      "    labels = load_labels(label_path)\n",
      "  File \"script_3c109637_1753800961.py\", line 11, in load_labels\n",
      "    with open(path, 'r') as f:\n",
      "FileNotFoundError: [Errno 2] No such file or directory: '<your_labels_path>'\n",
      "SPAN error_97_tpusg_failure_signal_tpu_sketch_generator: Failed. Last error: Traceback (most recent call last):\n",
      "  File \"script_b89edd0a_1753800824.py\", line 48, in <module>\n",
      "    if scores[category_id] > threshold:\n",
      "ValueError: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()\n",
      "SPAN error_c1_tpusg_failure_signal_tpu_sketch_generator: Failed. Last error: WARNING:root:From script_aca71d01_1753800596.py:42: The name DetectWithImage will be deprecated. Please use detect_with_image instead.\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"script_aca71d01_1753800596.py\", line 42, in <module>\n",
      "    results = engine.DetectWithImage(rgb_frame, threshold=THRESHOLD, top_k=10)\n",
      "  File \"/home/mendel/.local/lib/python3.7/site-packages/edgetpu/utils/warning.py\", line 44, in new_func\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/mendel/.local/lib/python3.7/site-packages/edgetpu/detection/engine.py\", line 187, in DetectWithImage\n",
      "    relative_coord, resample)\n",
      "  File \"/home/mendel/.local/lib/python3.7/site-packages/edgetpu/detection/engine.py\", line 134, in detect_with_image\n",
      "    resized_img = img.resize((width, height), resample)\n",
      "TypeError: 'tuple' object cannot be interpreted as an integer\n",
      "SPAN error_c5_tpusg_failure_signal_tpu_sketch_generator: Failed. Last error: Traceback (most recent call last):\n",
      "  File \"script_8241e8c3_1753800428.py\", line 48, in <module>\n",
      "    scores = output_data[:,5]\n",
      "IndexError: index 5 is out of bounds for axis 1 with size 4\n",
      "SPAN error_75_tpusg_failure_signal_tpu_sketch_generator: Failed. Last error: Traceback (most recent call last):\n",
      "  File \"script_89ba92cf_1753800246.py\", line 21, in <module>\n",
      "    image = Image.open(image_path)\n",
      "  File \"/usr/lib/python3/dist-packages/PIL/Image.py\", line 2634, in open\n",
      "    fp = builtins.open(filename, \"rb\")\n",
      "FileNotFoundError: [Errno 2] No such file or directory: 'path/to/your/image.jpg'\n",
      "SPAN error_fa_tpusg_failure_signal_tpu_sketch_generator: Failed. Last error: Unexpected error during generation: Generated script is not complete. Please ensure to generate a complete Python script.\n",
      "SPAN error_16_tpusg_failure_signal_tpu_sketch_generator: Failed. Last error: Traceback (most recent call last):\n",
      "  File \"script_603dc640_1753799968.py\", line 3, in <module>\n",
      "    from tensorflow import lite\n",
      "ModuleNotFoundError: No module named 'tensorflow'\n",
      "SPAN error_b1_tpusg_failure_signal_tpu_sketch_generator: Failed. Last error: Unexpected error during generation: Generated script is not complete. Please ensure to generate a complete Python script.\n",
      "SPAN error_22_tpusg_failure_signal_tpu_sketch_generator: Failed. Last error: Traceback (most recent call last):\n",
      "  File \"script_fad69de2_1753799500.py\", line 3, in <module>\n",
      "    from tensorflow.lite.python.interpreter import Interpreter, load_delegate\n",
      "ModuleNotFoundError: No module named 'tensorflow'\n",
      "SPAN error_f0_tpusg_failure_signal_tpu_sketch_generator: Failed. Last error: Traceback (most recent call last):\n",
      "  File \"script_f3991632_1753799356.py\", line 3, in <module>\n",
      "    from tqdm import tqdm\n",
      "ModuleNotFoundError: No module named 'tqdm'\n",
      "SPAN error_3a_tpusg_failure_signal_tpu_sketch_generator: Failed. Last error: Unexpected error during generation: Generated script is not complete. Please ensure to generate a complete Python script.\n",
      "SPAN error_87_tpusg_failure_signal_tpu_sketch_generator: Failed. Last error: Unexpected error during generation: The output is not a valid code block. Follow the instructions in the prompt return a complete, correct Python script enclosed in a single ```python\n",
      "<generated_code>\n",
      "``` block.\n",
      "SPAN error_77_tpusg_failure_signal_tpu_sketch_generator: Failed. Last error: Traceback (most recent call last):\n",
      "  File \"script_20055e8d_1753797794.py\", line 12, in <module>\n",
      "    with open('/path/to/your/label/file', 'r') as f:\n",
      "FileNotFoundError: [Errno 2] No such file or directory: '/path/to/your/label/file'\n",
      "SPAN error_52_tpusg_failure_signal_tpu_sketch_generator: Failed. Last error: Traceback (most recent call last):\n",
      "  File \"script_1beaa3f4_1753797526.py\", line 3, in <module>\n",
      "    from tensorflow.lite.experimental.load_delegate import load_delegate, LoadDelegateError\n",
      "ModuleNotFoundError: No module named 'tensorflow'\n",
      "Successfully processed and saved trimmed data for session codestral_c8f6_tpusg_batch\n",
      "Total 0 traces skipped. They are []\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "skipped_traces = []\n",
    "\n",
    "\n",
    "def process_existing_observation(observation):\n",
    "    \"\"\"\n",
    "    Processes an existing observation dictionary by trimming unwanted keys.\n",
    "    \"\"\"\n",
    "    unwanted_observation_keys = [\n",
    "        \"completionStartTime\",\n",
    "        \"metadata\",\n",
    "        \"timeToFirstToken\",\n",
    "        \"createdAt\",\n",
    "        \"usageDetails\",\n",
    "        \"usage\",\n",
    "        \"projectId\",\n",
    "        \"unit\",\n",
    "        \"updatedAt\",\n",
    "        \"version\",\n",
    "        \"parentObservationId\",\n",
    "        \"promptId\",\n",
    "        \"promptName\",\n",
    "        \"promptVersion\",\n",
    "        \"modelId\",\n",
    "        \"inputPrice\",\n",
    "        \"outputPrice\",\n",
    "        \"totalPrice\",\n",
    "        # \"modelParameters\",\n",
    "        \"input\",\n",
    "        \"output\",\n",
    "    ]\n",
    "\n",
    "    # If observation is a dictionary containing observation data\n",
    "    if isinstance(observation, dict):\n",
    "        trimmed_observation = {\n",
    "            k: v for k, v in observation.items() if k not in unwanted_observation_keys\n",
    "        }\n",
    "        return trimmed_observation\n",
    "    return observation\n",
    "\n",
    "\n",
    "def trim_data(data):\n",
    "    \"\"\"\n",
    "    Recursively trims the data structure.\n",
    "    \"\"\"\n",
    "\n",
    "    if isinstance(data, dict):\n",
    "        # Process the current dictionary\n",
    "        unwanted_trace_keys = [\n",
    "            \"release\",\n",
    "            \"version\",\n",
    "            \"user_id\",\n",
    "            \"public\",\n",
    "            \"html_path\",\n",
    "            \"scores\",\n",
    "            \"bookmarked\",\n",
    "            \"projectId\",\n",
    "            \"externalId\",\n",
    "            \"page\",\n",
    "            \"limit\",\n",
    "            \"total_pages\",\n",
    "        ]\n",
    "\n",
    "        # If this is a trace that contains observations, check for fatal errors\n",
    "        if \"observations\" in data:\n",
    "            # Check for SPAN observations with fatal errors before processing\n",
    "            skip_trace = False\n",
    "            for obs in data[\"observations\"]:\n",
    "                if isinstance(obs, dict) and obs.get(\"name\").startswith(\"error\"):\n",
    "                    status_message = obs.get(\"statusMessage\", \"\")\n",
    "                    ob_name = obs.get(\"name\")\n",
    "                    print(f\"SPAN {ob_name}: {status_message}\")\n",
    "\n",
    "                    if \"Fatal error\" in status_message:\n",
    "                        print(f\"Found Fatal error in SPAN observation, skipping trace\")\n",
    "                        skip_trace = True\n",
    "                        skipped_traces.append(data[\"name\"])\n",
    "                        break\n",
    "\n",
    "            if skip_trace:\n",
    "                return None  # Signal to skip this trace\n",
    "\n",
    "        # Create a new dictionary with wanted keys and recursively process values\n",
    "        trimmed_data = {}\n",
    "        for key, value in data.items():\n",
    "            if key not in unwanted_trace_keys:\n",
    "                if key == \"observations\":\n",
    "                    # Special handling for observations\n",
    "                    trimmed_data[key] = [\n",
    "                        process_existing_observation(obs) for obs in value\n",
    "                    ]\n",
    "                elif isinstance(value, (dict, list)):\n",
    "                    # Recursively process nested structures\n",
    "                    trimmed_data[key] = trim_data(value)\n",
    "                else:\n",
    "                    trimmed_data[key] = value\n",
    "\n",
    "        return trimmed_data\n",
    "\n",
    "    elif isinstance(data, list):\n",
    "        # Recursively process each item in the list\n",
    "        processed_items = []\n",
    "        for item in data:\n",
    "            processed_item = trim_data(item)\n",
    "            if processed_item is not None:  # Only add items that weren't filtered out\n",
    "                processed_items.append(processed_item)\n",
    "        return processed_items\n",
    "\n",
    "    else:\n",
    "        # Return non-dict, non-list values as is\n",
    "        return data\n",
    "\n",
    "\n",
    "def read_and_trim_data(session_id_list, raw_export_dir, trimmed_export_dir):\n",
    "    \"\"\"\n",
    "    Reads complete data from JSON files, trims the data, and saves the trimmed data to new JSON files.\n",
    "    \"\"\"\n",
    "    os.makedirs(trimmed_export_dir, exist_ok=True)\n",
    "\n",
    "    for session_id in session_id_list:\n",
    "        try:\n",
    "            if session_id.startswith(\"da0a\"):\n",
    "                session_id = \"phi4_\" + session_id\n",
    "            # Read raw data\n",
    "            if \"tpsg\" in session_id:\n",
    "                session_id_ = session_id.replace(\"tpsg\", \"tpusg\")\n",
    "            else:\n",
    "                session_id_ = session_id\n",
    "            raw_path = os.path.join(raw_export_dir, f\"raw_{session_id_}.json\")\n",
    "            with open(raw_path, \"r\") as f:\n",
    "                data = json.load(f)\n",
    "\n",
    "            # Process and trim the data\n",
    "            trimmed_data = trim_data(data)\n",
    "\n",
    "            # If the entire data was filtered out (unlikely but possible)\n",
    "            if trimmed_data is None:\n",
    "                print(\n",
    "                    f\"All traces in session {session_id} were filtered due to fatal errors\"\n",
    "                )\n",
    "                continue\n",
    "\n",
    "            # Save trimmed data\n",
    "            if \"tpsg\" in session_id:\n",
    "                session_id_ = session_id.replace(\"tpsg\", \"tpusg\")\n",
    "            else:\n",
    "                session_id_ = session_id\n",
    "            trimmed_path = os.path.join(\n",
    "                trimmed_export_dir, f\"trimmed_{session_id_}.json\"\n",
    "            )\n",
    "            with open(trimmed_path, \"w\") as f:\n",
    "                json.dump(trimmed_data, f, indent=2)\n",
    "\n",
    "            print(\n",
    "                f\"Successfully processed and saved trimmed data for session {session_id}\"\n",
    "            )\n",
    "\n",
    "            # Optional: Verify trimming worked\n",
    "            # print(f\"Verifying trimmed data for session {session_id}...\")\n",
    "            # verify_trimming(trimmed_path)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing session {session_id}: {str(e)}\")\n",
    "\n",
    "\n",
    "def verify_trimming(trimmed_path):\n",
    "    \"\"\"\n",
    "    Verifies that the trimmed data doesn't contain unwanted keys.\n",
    "    \"\"\"\n",
    "    with open(trimmed_path, \"r\") as f:\n",
    "        trimmed_data = json.load(f)\n",
    "\n",
    "    unwanted_keys = [\n",
    "        \"release\",\n",
    "        \"version\",\n",
    "        \"user_id\",\n",
    "        \"public\",\n",
    "        \"html_path\",\n",
    "        \"scores\",\n",
    "        \"bookmarked\",\n",
    "        \"projectId\",\n",
    "        \"externalId\",\n",
    "        \"page\",\n",
    "        \"limit\",\n",
    "        \"total_pages\",\n",
    "        \"completionStartTime\",\n",
    "        \"metadata\",\n",
    "        \"usageDetails\",\n",
    "        \"timeToFirstToken\",\n",
    "        \"createdAt\",\n",
    "        \"completionTokens\",\n",
    "        \"promptTokens\",\n",
    "        \"projectId\",\n",
    "        \"unit\",\n",
    "        \"updatedAt\",\n",
    "        \"version\",\n",
    "        # \"statusMessage\",\n",
    "        \"parentObservationId\",\n",
    "        \"promptId\",\n",
    "        \"promptName\",\n",
    "        \"promptVersion\",\n",
    "        \"modelId\",\n",
    "        \"inputPrice\",\n",
    "        \"outputPrice\",\n",
    "        \"totalPrice\",\n",
    "        \"calculatedInputCost\",\n",
    "        \"calculatedOutputCost\",\n",
    "        \"calculatedTotalCost\",\n",
    "    ]\n",
    "\n",
    "    def check_keys(obj):\n",
    "        if isinstance(obj, dict):\n",
    "            for key in obj.keys():\n",
    "                if key in unwanted_keys:\n",
    "                    print(f\"Warning: Found unwanted key '{key}' in trimmed data\")\n",
    "            for value in obj.values():\n",
    "                check_keys(value)\n",
    "        elif isinstance(obj, list):\n",
    "            for item in obj:\n",
    "                check_keys(item)\n",
    "\n",
    "    check_keys(trimmed_data)\n",
    "    print(\"Verification complete\")\n",
    "\n",
    "\n",
    "# Usage example:\n",
    "read_and_trim_data(session_id_list, raw_export_dir, raw_export_dir)\n",
    "print(f\"Total {len(skipped_traces)} traces skipped. They are {skipped_traces}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Generate CSV files from JSON\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing session codestral_c8f6_tpusg_batch, simple id codestral_c8f6. Look for /Users/hann/Projects/reference-benchmark-tinyml_llm/data_analysis/07.29/raw_export/trimmed_codestral_c8f6_tpusg_batch.json\n",
      "/Users/hann/Projects/reference-benchmark-tinyml_llm/data_analysis/07.29/processed_data/codestral_c8f6/clean_codestral_c8f6_tpusg_batch.csv\n",
      "Successfully saved CSV to: /Users/hann/Projects/reference-benchmark-tinyml_llm/data_analysis/07.29/processed_data/codestral_c8f6/clean_codestral_c8f6_tpusg_batch.csv\n"
     ]
    }
   ],
   "source": [
    "import traceback\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from dateutil import parser\n",
    "\n",
    "\n",
    "def json_to_csv(session_id):\n",
    "    \"\"\"\n",
    "    Convert JSON trace data to CSV format with aggregated metrics.\n",
    "\n",
    "    Args:\n",
    "        session_id (str): Identifier for the session to process\n",
    "    \"\"\"\n",
    "\n",
    "    def extract_observation_details(observations, trace_id):\n",
    "        \"\"\"Extract and aggregate metrics from observations\"\"\"\n",
    "        metrics = {\n",
    "            \"status\": None,\n",
    "            \"latency\": 0,\n",
    "            \"total_tokens\": 0,\n",
    "            \"prompt_tokens\": 0,\n",
    "            \"completion_tokens\": 0,\n",
    "            \"total_cost\": 0,\n",
    "            \"input_cost\": 0,\n",
    "            \"output_cost\": 0,\n",
    "            \"parameters\": set(),\n",
    "        }\n",
    "\n",
    "        # Process GENERATION observations\n",
    "        for obs in (o for o in observations if o[\"type\"] == \"GENERATION\"):\n",
    "            metrics[\"total_tokens\"] += obs[\"totalTokens\"]\n",
    "            metrics[\"prompt_tokens\"] += obs[\"promptTokens\"]\n",
    "            metrics[\"completion_tokens\"] += obs[\"completionTokens\"]\n",
    "            metrics[\"latency\"] += obs[\"latency\"]\n",
    "            for key, value in obs[\"modelParameters\"].items():\n",
    "                metrics[\"parameters\"].add(key + \":\" + value)\n",
    "\n",
    "            # Add costs if present\n",
    "            for cost_type in [\"Total\", \"Input\", \"Output\"]:\n",
    "                key = f\"calculated{cost_type}Cost\"\n",
    "                metric_key = cost_type.lower() + \"_cost\"\n",
    "                if obs.get(key) is not None:\n",
    "                    metrics[metric_key] += obs[key]\n",
    "        if len(metrics[\"parameters\"]) == 0:\n",
    "            metrics[\"parameters\"] = \"N/A\"\n",
    "        # Process SPAN observations for status\n",
    "        status_indicators = [\n",
    "            obs[\"name\"]\n",
    "            for obs in observations\n",
    "            if obs[\"type\"] == \"SPAN\" and \"start_\" not in obs[\"name\"]\n",
    "        ]\n",
    "\n",
    "        #  if later than 2025-05-19, use status_signal_from_output\n",
    "        if datetime.now() > datetime(2025, 5, 19):\n",
    "            pass\n",
    "        else:\n",
    "            # Determine status\n",
    "            success_signals = sum(\"end_\" in name for name in status_indicators)\n",
    "            failure_signals = sum(\n",
    "                \"failure_signal\" in name for name in status_indicators\n",
    "            )\n",
    "\n",
    "            if success_signals + failure_signals > 1:\n",
    "                raise ValueError(\n",
    "                    f\"Multiple status indicators found in trace {trace_id}\"\n",
    "                )\n",
    "\n",
    "            metrics[\"status\"] = (\n",
    "                \"success\"\n",
    "                if success_signals\n",
    "                else \"failure\" if failure_signals else \"unknown\"\n",
    "            )\n",
    "\n",
    "        metrics[\"prompt_cost\"] = metrics.pop(\"input_cost\")\n",
    "        metrics[\"completion_cost\"] = metrics.pop(\"output_cost\")\n",
    "        metrics[\"latency\"] = round(metrics[\"latency\"] / 1000, 2)\n",
    "        return metrics\n",
    "\n",
    "    def cal_time(trace):\n",
    "        time_diff = datetime.fromisoformat(\n",
    "            trace[\"updatedAt\"].replace(\"Z\", \"+00:00\")\n",
    "        ) - datetime.fromisoformat(trace[\"createdAt\"].replace(\"Z\", \"+00:00\"))\n",
    "        seconds_diff = time_diff.total_seconds()\n",
    "        return seconds_diff\n",
    "\n",
    "    try:\n",
    "\n",
    "        if session_id.startswith(\"da0a\"):\n",
    "            session_id = \"phi4_\" + session_id\n",
    "        simple_session_id = session_id.rsplit(\"_\", 2)[0]\n",
    "\n",
    "        \n",
    "        # Load JSON data\n",
    "        if \"tpsg\" in session_id:\n",
    "                session_id_ = session_id.replace(\"tpsg\", \"tpusg\")\n",
    "        else:\n",
    "                session_id_ = session_id\n",
    "        trimmed_path = os.path.join(raw_export_dir, f\"trimmed_{session_id_}.json\")\n",
    "        print(\n",
    "            f\"Processing session {session_id}, simple id {simple_session_id}. Look for {trimmed_path}\"\n",
    "        )\n",
    "        with open(trimmed_path, \"r\") as file:\n",
    "            traces = json.load(file)[\"data\"]\n",
    "\n",
    "        # Process traces\n",
    "        rows = [\n",
    "            {\n",
    "                \"num_run\": trace[\"metadata\"][\"num_run\"],\n",
    "                \"name\": trace[\"name\"],\n",
    "                \"trace_id\": trace[\"id\"],\n",
    "                \"batch_id\": trace[\"session_id\"],\n",
    "                # \"latency\": cal_time(trace),\n",
    "                # \"latency\": round(trace[\"latency\"], 2),\n",
    "                **extract_observation_details(\n",
    "                    trace[\"observations\"],\n",
    "                    trace[\"id\"],\n",
    "                ),\n",
    "                \"status\": (\n",
    "                    \"failure\"\n",
    "                    if trace[\"output\"][\"status\"].lower() == \"failed\"\n",
    "                    else \"success\"\n",
    "                ),\n",
    "                \"tags\": trace[\"tags\"],\n",
    "                \"timestamp\": int(parser.isoparse(trace[\"timestamp\"]).timestamp()),\n",
    "            }\n",
    "            for trace in traces\n",
    "        ]\n",
    "        # print(rows)\n",
    "        # print(rows)\n",
    "        # Create and save DataFrame\n",
    "        df = pd.DataFrame(rows).sort_values(\"num_run\")\n",
    "\n",
    "        output_dir = os.path.join(processed_data_dir, f\"{simple_session_id}\")\n",
    "        if not os.path.exists(output_dir):\n",
    "            os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "        output_path = os.path.join(output_dir, f\"clean_{session_id_}.csv\")\n",
    "\n",
    "        print(output_path)\n",
    "        df.to_csv(output_path, index=False)\n",
    "        print(f\"Successfully saved CSV to: {output_path}\")\n",
    "\n",
    "    except FileNotFoundError as e:\n",
    "        print(\n",
    "            f\"FileNotFoundError: For session {session_id} not found. Looked for {trimmed_path}\\nError info: \\n{e}\\n\\nTraceback: {traceback.format_exc()}\"\n",
    "        )\n",
    "    except json.JSONDecodeError:\n",
    "        print(f\"Error: Invalid JSON format in input file for session {session_id}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing session {session_id}: {str(e)}\")\n",
    "\n",
    "\n",
    "# Example usage\n",
    "for session_id in session_id_list:\n",
    "    json_to_csv(session_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code below is archived\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"\"\"Simply calculate success rate\"\"\"\n",
    "\n",
    "\n",
    "# def cal_success_rate(session_id):\n",
    "\n",
    "#     end_signal_count = 0\n",
    "#     failure_signal_count = 0\n",
    "#     # Function to print the name of each observation\n",
    "#     with open(f\"{raw_export_dir}/trimmed_{session_id}.json\", \"r\") as file:\n",
    "#         data = json.load(file)[\"data\"]\n",
    "#     for i in data:\n",
    "\n",
    "#         observations = i[\"observations\"]\n",
    "\n",
    "#         for observation in observations:\n",
    "#             # print(type(observation))\n",
    "#             for key, value in observation.items():\n",
    "#                 # print(f\"{key}: {value}\")\n",
    "#                 for key, value in value.items():\n",
    "#                     # print(f\"{key}: {value}\")\n",
    "#                     if key == \"name\":\n",
    "#                         if \"end_\" in value:\n",
    "\n",
    "#                             end_signal_count += 1\n",
    "#                         if \"failure_signal\" in value:\n",
    "\n",
    "#                             failure_signal_count += 1\n",
    "\n",
    "#     print(f\"Session ID: {session_id}\")\n",
    "#     total_count = end_signal_count + failure_signal_count\n",
    "#     if total_count > 0:\n",
    "#         success_rate = end_signal_count / total_count\n",
    "#         print(f\"Success rate: {success_rate:.4f}\")\n",
    "#     else:\n",
    "#         print(\"Success rate: N/A (no signals found)\")\n",
    "#     print(f\"Passed:\\t{end_signal_count}\\nFailed:\\t{failure_signal_count}\")\n",
    "#     print(\n",
    "#         \"\"\n",
    "#         if total_count == 30\n",
    "#         else \"Number of ending signals does not match the expected number!\"\n",
    "#     )\n",
    "#     print(\"-\" * 50)\n",
    "\n",
    "\n",
    "# for session_id in session_id_list:\n",
    "#     cal_success_rate(session_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def cal_time(start_time, end_time):\n",
    "#     time_diff = datetime.fromisoformat(\n",
    "#         end_time.replace(\"Z\", \"+00:00\")\n",
    "#     ) - datetime.fromisoformat(start_time.replace(\"Z\", \"+00:00\"))\n",
    "#     seconds_diff = time_diff.total_seconds()\n",
    "#     return seconds_diff\n",
    "\n",
    "\n",
    "# print(cal_time(\"2025-01-15T03:31:56.150000+00:00\", \"2025-01-15T03:32:59.384Z\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"\"\"Print the complete structure of exported json file\"\"\"\n",
    "# def print_keys(d, parent_key=''):\n",
    "#     if isinstance(d, dict):\n",
    "#         for key, value in d.items():\n",
    "#             full_key = f\"{parent_key}.{key}\" if parent_key else key\n",
    "#             print(full_key)\n",
    "#             print_keys(value, full_key)\n",
    "#     elif isinstance(d, list):\n",
    "#         for i, item in enumerate(d):\n",
    "#             full_key = f\"{parent_key}[{i}]\"\n",
    "#             print_keys(item, full_key)\n",
    "\n",
    "# # Load JSON data from a file\n",
    "# with open('fetch_traces_response.json', 'r') as file:\n",
    "#     data = json.load(file)['data'][0]\n",
    "# # Print all keys\n",
    "# print_keys(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1747226053\n",
      "1747226053.1\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "from dateutil import parser\n",
    "\n",
    "timestamp_str = \"2025-05-14T12:34:13.100000+00:00\"\n",
    "dt = parser.isoparse(\n",
    "    timestamp_str\n",
    ")  # Or datetime.fromisoformat(timestamp_str) if no timezone offset\n",
    "unix_ts = int(dt.timestamp())\n",
    "\n",
    "print(unix_ts)  # This will print the integer Unix timestamp\n",
    "print(datetime.fromisoformat(timestamp_str).timestamp())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datasci2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

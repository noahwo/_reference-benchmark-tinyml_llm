{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dec7f3c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "import re\n",
    "from typing import Dict, List, Tuple\n",
    "\n",
    "parent_dir = os.path.dirname(os.getcwd())\n",
    "# date = \"10.28\"\n",
    "date_in_filename = os.path.basename(parent_dir)\n",
    "date=date_in_filename.split(\"_\")[0]\n",
    "\n",
    "extracted_code_dir = os.path.join(parent_dir, \"extracted_code\")\n",
    "results_records_path=os.path.join(parent_dir, \"full_execution_results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "deb4e53f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìù Skipped 18 files already succeeded in previous runs.\n",
      "üìÅ Found 0 Python files in /Users/hann/Projects/reference-benchmark-tinyml_llm/data_analysis/2025/07.29/extracted_code (to execute)\n",
      "‚ùå No Python files found to execute\n",
      "Expected directory: /Users/hann/Projects/reference-benchmark-tinyml_llm/data_analysis/2025/07.29/extracted_code\n",
      "Make sure you've run the extraction process first.\n"
     ]
    }
   ],
   "source": [
    "# Find all extracted Python files\n",
    "import pandas as pd\n",
    "\n",
    "def get_extracted_python_files():\n",
    "    \"\"\"Get list of all Python files in the extracted_code directory, skipping those already succeeded in full_execution_results.csv if present.\"\"\"\n",
    "    if not os.path.exists(extracted_code_dir):\n",
    "        print(f\"‚ùå Extracted code directory not found: {extracted_code_dir}\")\n",
    "        return []\n",
    "    \n",
    "    python_files = glob.glob(os.path.join(extracted_code_dir, \"*tpusg*.py\"))\n",
    "    python_files.sort()  # Sort for consistent processing order\n",
    "\n",
    "    # Filter out files that already succeeded in full_execution_results.csv\n",
    "    results_csv = os.path.join(parent_dir, \"full_execution_results.csv\")\n",
    "    if os.path.exists(results_csv) and os.path.getsize(results_csv) > 0:\n",
    "        try:\n",
    "            df = pd.read_csv(results_csv)\n",
    "            succeeded = set(df[df['success'] == True]['filename'])\n",
    "            before_count = len(python_files)\n",
    "            python_files = [f for f in python_files if os.path.basename(f) not in succeeded]\n",
    "            after_count = len(python_files)\n",
    "            print(f\"üìù Skipped {before_count - after_count} files already succeeded in previous runs.\")\n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è  Could not filter succeeded files: {e}\")\n",
    "\n",
    "    print(f\"üìÅ Found {len(python_files)} Python files in {extracted_code_dir} (to execute)\")\n",
    "    return python_files\n",
    "\n",
    "# Get the list of files to execute\n",
    "python_files = get_extracted_python_files()\n",
    "\n",
    "# Show first few files as preview\n",
    "if python_files:\n",
    "    print(\"\\nüìã First 5 Python files to execute:\")\n",
    "    for i, file_path in enumerate(python_files[:5]):\n",
    "        filename = os.path.basename(file_path)\n",
    "        print(f\"  {i+1}. {filename}\")\n",
    "    \n",
    "    if len(python_files) > 5:\n",
    "        print(f\"  ... and {len(python_files) - 5} more files\")\n",
    "else:\n",
    "    print(\"‚ùå No Python files found to execute\")\n",
    "    print(f\"Expected directory: {extracted_code_dir}\")\n",
    "    print(\"Make sure you've run the extraction process first.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b1229004",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîß Remote TPU Executor initialized\n",
      "   Remote Host: coral\n",
      "   Remote Path: /home/mendel/tinyml_autopilot/tmp\n",
      "   Remote Python: /home/mendel/tinyml_autopilot/tinyml-env/bin/python\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "import tempfile\n",
    "import shutil\n",
    "import uuid\n",
    "import time\n",
    "import threading\n",
    "import queue\n",
    "import logging\n",
    "from datetime import datetime\n",
    "\n",
    "class RemoteTPUExecutor:\n",
    "    \"\"\"Execute Python scripts on remote TPU device (Coral Dev Board)\"\"\"\n",
    "    \n",
    "    def __init__(self, remote_host='coral', remote_path='/home/mendel/tinyml_autopilot/tmp', \n",
    "                 remote_python='/home/mendel/tinyml_autopilot/tinyml-env/bin/python'):\n",
    "        self.remote_host = remote_host\n",
    "        self.remote_path = remote_path  \n",
    "        self.remote_python = remote_python\n",
    "        self.session_id = f\"exec_{int(time.time())}\"\n",
    "        \n",
    "        # Setup basic logging\n",
    "        logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "        self.logger = logging.getLogger(__name__)\n",
    "        \n",
    "    def get_session_id(self):\n",
    "        return f\"[{self.session_id}] \"\n",
    "    \n",
    "    def execute_code_remotely(self, code, script_name=\"unnamed_script\"):\n",
    "        \"\"\"\n",
    "        Execute code remotely via direct SSH file transfer and execution.\n",
    "        \n",
    "        Args:\n",
    "            code (str): The Python code to execute remotely\n",
    "            script_name (str): Name identifier for the script\n",
    "            \n",
    "        Returns:\n",
    "            dict: Execution result with status, output, and error info\n",
    "        \"\"\"\n",
    "        # Generate unique script name with timestamp\n",
    "        script_id = f\"script_{uuid.uuid4().hex[:8]}_{int(time.time())}\"\n",
    "        script_filename = f\"{script_id}.py\"\n",
    "        remote_script_path = f\"{self.remote_path}/{script_filename}\"\n",
    "        \n",
    "        result = {\n",
    "            'script_id': script_id,\n",
    "            'script_name': script_name,\n",
    "            'success': False,\n",
    "            'output': '',\n",
    "            'error': '',\n",
    "            'execution_time': 0\n",
    "        }\n",
    "        \n",
    "        start_time = time.time()\n",
    "        \n",
    "        try:\n",
    "            # Check and kill any TPU device owner processes\n",
    "            self._cleanup_tpu_device()\n",
    "            \n",
    "            # Create temporary local file with the code\n",
    "            with tempfile.NamedTemporaryFile(mode='w', suffix='.py', delete=False) as temp_file:\n",
    "                temp_file.write(code)\n",
    "                local_script_path = temp_file.name\n",
    "            \n",
    "            # Save a copy for analysis\n",
    "            analysis_dir = os.path.join(\"tmp\")\n",
    "            os.makedirs(analysis_dir, exist_ok=True)\n",
    "            analysis_file_path = os.path.join(analysis_dir, f\"{script_id}.py\")\n",
    "            shutil.copy2(local_script_path, analysis_file_path)\n",
    "            \n",
    "            # Commands for remote execution\n",
    "            mkdir_command = ['ssh', self.remote_host, f'mkdir -p {self.remote_path}']\n",
    "            scp_command = ['scp', local_script_path, f'{self.remote_host}:{remote_script_path}']\n",
    "            ssh_command = ['ssh', self.remote_host, f'cd {self.remote_path} && {self.remote_python} {script_filename}']\n",
    "            cleanup_command = ['ssh', self.remote_host, f'rm -f {remote_script_path}']\n",
    "            kill_command = ['ssh', self.remote_host, f'pkill -f {script_id} || true']\n",
    "            \n",
    "            # Step 1: Create remote directory\n",
    "            self.logger.info(self.get_session_id() + f\"Creating remote directory: {self.remote_path}\")\n",
    "            mkdir_result = subprocess.run(mkdir_command, capture_output=True, text=True, timeout=30)\n",
    "            \n",
    "            if mkdir_result.returncode != 0:\n",
    "                result['error'] = f\"Failed to create remote directory: {mkdir_result.stderr}\"\n",
    "                return result\n",
    "            \n",
    "            # Step 2: Transfer script to remote machine\n",
    "            self.logger.info(self.get_session_id() + f\"Transferring script to remote: {remote_script_path}\")\n",
    "            scp_result = subprocess.run(scp_command, capture_output=True, text=True, timeout=60)\n",
    "            \n",
    "            if scp_result.returncode != 0:\n",
    "                result['error'] = f\"Failed to transfer script: {scp_result.stderr}\"\n",
    "                return result\n",
    "            \n",
    "            # Step 3: Execute script remotely\n",
    "            self.logger.info(self.get_session_id() + f\"Executing script remotely: {script_filename}\")\n",
    "            execution_error = self._stream_remote_execution(ssh_command, script_id)\n",
    "            \n",
    "            # Step 4: Cleanup\n",
    "            self.logger.info(self.get_session_id() + f\"Cleaning up remote script: {remote_script_path}\")\n",
    "            subprocess.run(kill_command, capture_output=True, text=True, timeout=30)\n",
    "            cleanup_result = subprocess.run(cleanup_command, capture_output=True, text=True, timeout=30)\n",
    "            \n",
    "            if cleanup_result.returncode != 0:\n",
    "                self.logger.warning(self.get_session_id() + f\"Failed to cleanup remote file: {cleanup_result.stderr}\")\n",
    "            \n",
    "            # Process results\n",
    "            if execution_error is None:\n",
    "                result['success'] = True\n",
    "                result['output'] = \"Execution completed successfully\"\n",
    "            else:\n",
    "                result['error'] = execution_error\n",
    "                \n",
    "        except subprocess.TimeoutExpired as e:\n",
    "            result['error'] = f\"Remote execution timeout: {e}\"\n",
    "        except Exception as e:\n",
    "            result['error'] = f\"Remote execution failed: {e}\"\n",
    "        finally:\n",
    "            # Cleanup local temporary file\n",
    "            try:\n",
    "                if 'local_script_path' in locals():\n",
    "                    os.unlink(local_script_path)\n",
    "            except Exception as cleanup_error:\n",
    "                self.logger.warning(self.get_session_id() + f\"Failed to cleanup local temp file: {cleanup_error}\")\n",
    "        \n",
    "        result['execution_time'] = time.time() - start_time\n",
    "        return result\n",
    "    \n",
    "    def _cleanup_tpu_device(self):\n",
    "        \"\"\"Kill any processes that might be using the TPU device\"\"\"\n",
    "        try:\n",
    "            check_result = subprocess.run(\n",
    "                ['ssh', self.remote_host, \"cat /sys/class/apex/apex_0/device_owner\"], \n",
    "                capture_output=True, text=True, timeout=10\n",
    "            )\n",
    "            if check_result.returncode == 0:\n",
    "                owner_pid = check_result.stdout.strip()\n",
    "                if owner_pid and owner_pid != \"0\":\n",
    "                    self.logger.warning(self.get_session_id() + f\"TPU Device owned by PID {owner_pid}, killing process\")\n",
    "                    kill_cmd = ['ssh', self.remote_host, f'kill {owner_pid} || true']\n",
    "                    subprocess.run(kill_cmd, capture_output=True, text=True, timeout=10)\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    def _stream_remote_execution(self, ssh_command, script_id):\n",
    "        \"\"\"\n",
    "        Execute SSH command with real-time output streaming.\n",
    "        \n",
    "        Args:\n",
    "            ssh_command (list): SSH command to execute\n",
    "            script_id (str): Unique script identifier for logging\n",
    "            \n",
    "        Returns:\n",
    "            str: Error message if execution failed, None if successful\n",
    "        \"\"\"\n",
    "        try:\n",
    "            process = subprocess.Popen(\n",
    "                ssh_command,\n",
    "                stdout=subprocess.PIPE,\n",
    "                stderr=subprocess.PIPE,\n",
    "                text=True,\n",
    "                bufsize=0,\n",
    "                universal_newlines=True\n",
    "            )\n",
    "            \n",
    "            self.logger.info(self.get_session_id() + f\"üöÄ Remote execution started for {script_id}\")\n",
    "            \n",
    "            stdout_lines = []\n",
    "            stderr_lines = []\n",
    "            \n",
    "            def read_stdout():\n",
    "                try:\n",
    "                    for line in iter(process.stdout.readline, ''):\n",
    "                        if line:\n",
    "                            line = line.rstrip('\\n')\n",
    "                            stdout_lines.append(line)\n",
    "                    if stdout_lines:\n",
    "                        if any('Error' in line for line in stdout_lines):\n",
    "                            stderr_lines.extend(stdout_lines)\n",
    "                        else:\n",
    "                            self.logger.info(self.get_session_id() + f\"[STDOUT] {stdout_lines}\")\n",
    "                except:\n",
    "                    pass\n",
    "            \n",
    "            def read_stderr():\n",
    "                try:\n",
    "                    for line in iter(process.stderr.readline, ''):\n",
    "                        if line:\n",
    "                            line = line.rstrip('\\n')\n",
    "                            stderr_lines.append(line)\n",
    "                    if stderr_lines and 'Traceback (most recent call last)' not in ' '.join(stderr_lines):\n",
    "                        self.logger.error(self.get_session_id() + f\"[STDERR] {stderr_lines}\")\n",
    "                except:\n",
    "                    pass\n",
    "            \n",
    "            # Start reader threads\n",
    "            stdout_thread = threading.Thread(target=read_stdout)\n",
    "            stderr_thread = threading.Thread(target=read_stderr)\n",
    "            stdout_thread.daemon = True\n",
    "            stderr_thread.daemon = True\n",
    "            \n",
    "            stdout_thread.start()\n",
    "            stderr_thread.start()\n",
    "            \n",
    "            # Wait for process completion with timeout\n",
    "            timeout_seconds = 60\n",
    "            start_time = time.time()\n",
    "            \n",
    "            while True:\n",
    "                if process.poll() is not None:\n",
    "                    break\n",
    "                \n",
    "                current_time = time.time()\n",
    "                if current_time - start_time > timeout_seconds:\n",
    "                    self.logger.error(self.get_session_id() + f\"Remote execution timeout after {timeout_seconds} seconds\")\n",
    "                    process.terminate()\n",
    "                    time.sleep(2)\n",
    "                    if process.poll() is None:\n",
    "                        process.kill()\n",
    "                    return f\"Remote execution timeout after {timeout_seconds} seconds\"\n",
    "                \n",
    "                time.sleep(0.1)\n",
    "            \n",
    "            # Wait for threads to finish\n",
    "            stdout_thread.join(timeout=5)\n",
    "            stderr_thread.join(timeout=5)\n",
    "            \n",
    "            exit_code = process.returncode\n",
    "            full_stdout = '\\n'.join(stdout_lines)\n",
    "            full_stderr = '\\n'.join(stderr_lines)\n",
    "            \n",
    "            combined_output = \"\"\n",
    "            if full_stdout:\n",
    "                combined_output += full_stdout\n",
    "            if full_stderr:\n",
    "                if combined_output:\n",
    "                    combined_output += \"\\n\"\n",
    "                combined_output += full_stderr\n",
    "            \n",
    "            if exit_code == 0:\n",
    "                self.logger.info(self.get_session_id() + f\"‚úÖ Remote execution completed successfully for {script_id}\")\n",
    "                return None\n",
    "            else:\n",
    "                error_msg = f\"‚ùå Remote execution failed with exit code {exit_code}\"\n",
    "                if full_stderr and 'Traceback' in full_stderr:\n",
    "                    self.logger.error(self.get_session_id() + \"Python traceback detected in remote execution:\")\n",
    "                    self.logger.error(self.get_session_id() + f\"üîç [REMOTE TRACEBACK] \\n{full_stderr}\")\n",
    "                \n",
    "                self.logger.error(self.get_session_id() + error_msg)\n",
    "                return combined_output if combined_output else error_msg\n",
    "                \n",
    "        except Exception as e:\n",
    "            error_msg = f\"Failed to stream remote execution: {e}\"\n",
    "            self.logger.error(self.get_session_id() + error_msg)\n",
    "            return error_msg\n",
    "\n",
    "# Initialize the executor\n",
    "executor = RemoteTPUExecutor()\n",
    "print(\"üîß Remote TPU Executor initialized\")\n",
    "print(f\"   Remote Host: {executor.remote_host}\")\n",
    "print(f\"   Remote Path: {executor.remote_path}\")\n",
    "print(f\"   Remote Python: {executor.remote_python}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6e0e482c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîß Batch execution functions ready\n",
      "   Use execute_all_python_files() to start batch execution\n",
      "   Use save_execution_results() to save results to CSV\n"
     ]
    }
   ],
   "source": [
    "def execute_all_python_files(python_files, max_files=None, start_from=0, update_csv=True):\n",
    "    \"\"\"\n",
    "    Execute all Python files in the extracted_code directory one by one\n",
    "    \n",
    "    Args:\n",
    "        python_files (list): List of Python file paths to execute\n",
    "        max_files (int): Maximum number of files to execute (None for all)\n",
    "        start_from (int): Index to start execution from\n",
    "        update_csv (bool): If True, update full_execution_results.csv after each execution\n",
    "    \n",
    "    Returns:\n",
    "        dict: Summary of execution results\n",
    "    \"\"\"\n",
    "    if not python_files:\n",
    "        print(\"‚ùå No Python files to execute\")\n",
    "        return {}\n",
    "    \n",
    "    # Limit the number of files if specified\n",
    "    files_to_execute = python_files[start_from:]\n",
    "    if max_files:\n",
    "        files_to_execute = files_to_execute[:max_files]\n",
    "    \n",
    "    print(f\"üöÄ Starting batch execution of {len(files_to_execute)} Python files\")\n",
    "    print(f\"   Starting from index: {start_from}\")\n",
    "    if max_files:\n",
    "        print(f\"   Max files to execute: {max_files}\")\n",
    "    print(f\"   Total files available: {len(python_files)}\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    execution_results = []\n",
    "    successful_executions = 0\n",
    "    failed_executions = 0\n",
    "    # Path for results CSV\n",
    "    results_csv = os.path.join(parent_dir, \"full_execution_results.csv\")\n",
    "    \n",
    "    for i, file_path in enumerate(files_to_execute):\n",
    "        actual_index = start_from + i\n",
    "        filename = os.path.basename(file_path)\n",
    "        \n",
    "        print(f\"\\nüìÑ [{actual_index + 1}/{len(python_files)}] Executing: {filename}\")\n",
    "        print(\"-\" * 40)\n",
    "        \n",
    "        try:\n",
    "            # Read the Python file content\n",
    "            with open(file_path, 'r', encoding='utf-8') as f:\n",
    "                code_content = f.read()\n",
    "            \n",
    "            # Extract metadata from the header comment\n",
    "            metadata = extract_metadata_from_file(code_content)\n",
    "            \n",
    "            print(f\"   üìä Metadata:\")\n",
    "            print(f\"      Entry ID: {metadata.get('entry_id', 'Unknown')}\")\n",
    "            print(f\"      Session: {metadata.get('session_id', 'Unknown')}\")\n",
    "            print(f\"      Source: {metadata.get('source_file', 'Unknown')}\")\n",
    "            \n",
    "            # Execute the code remotely\n",
    "            print(f\"   üöÄ Starting remote execution...\")\n",
    "            result = executor.execute_code_remotely(code_content, filename)\n",
    "            \n",
    "            # Process results\n",
    "            result['file_path'] = file_path\n",
    "            result['filename'] = filename\n",
    "            result['metadata'] = metadata\n",
    "            result['index'] = actual_index\n",
    "            \n",
    "            if result['success']:\n",
    "                print(f\"   ‚úÖ SUCCESS - Execution completed in {result['execution_time']:.2f}s\")\n",
    "                successful_executions += 1\n",
    "            else:\n",
    "                print(f\"   ‚ùå FAILED - {result['error'][:100]}...\")\n",
    "                failed_executions += 1\n",
    "            \n",
    "            execution_results.append(result)\n",
    "            if update_csv:\n",
    "                update_execution_result_csv(result, results_csv, parent_dir)\n",
    "            \n",
    "            # Brief pause between executions to avoid overwhelming the remote system\n",
    "            time.sleep(2)\n",
    "            \n",
    "        except Exception as e:\n",
    "            error_result = {\n",
    "                'script_id': f\"failed_{actual_index}\",\n",
    "                'script_name': filename,\n",
    "                'file_path': file_path,\n",
    "                'filename': filename,\n",
    "                'success': False,\n",
    "                'output': '',\n",
    "                'error': f\"Local execution setup failed: {e}\",\n",
    "                'execution_time': 0,\n",
    "                'metadata': {},\n",
    "                'index': actual_index\n",
    "            }\n",
    "            execution_results.append(error_result)\n",
    "            failed_executions += 1\n",
    "            print(f\"   üí• SETUP FAILED - {e}\")\n",
    "            if update_csv:\n",
    "                update_execution_result_csv(error_result, results_csv, parent_dir)\n",
    "    \n",
    "    # Print summary\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"üìä BATCH EXECUTION SUMMARY\")\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"   Total files processed: {len(execution_results)}\")\n",
    "    print(f\"   ‚úÖ Successful executions: {successful_executions}\")\n",
    "    print(f\"   ‚ùå Failed executions: {failed_executions}\")\n",
    "    print(f\"   üìà Success rate: {successful_executions/len(execution_results):.1%}\")\n",
    "    \n",
    "    return {\n",
    "        'results': execution_results,\n",
    "        'total_processed': len(execution_results),\n",
    "        'successful': successful_executions,\n",
    "        'failed': failed_executions,\n",
    "        'success_rate': successful_executions/len(execution_results) if execution_results else 0\n",
    "    }\n",
    "\n",
    "def extract_metadata_from_file(code_content):\n",
    "    \"\"\"Extract metadata from the file header comment\"\"\"\n",
    "    metadata = {}\n",
    "    lines = code_content.split('\\n')\n",
    "    \n",
    "    # Look for metadata in the header comment\n",
    "    in_header = False\n",
    "    for line in lines:\n",
    "        line = line.strip()\n",
    "        if line.startswith('\"\"\"'):\n",
    "            in_header = not in_header\n",
    "            continue\n",
    "        \n",
    "        if in_header and ':' in line:\n",
    "            parts = line.split(':', 1)\n",
    "            if len(parts) == 2:\n",
    "                key = parts[0].strip()\n",
    "                value = parts[1].strip()\n",
    "                metadata[key.lower().replace(' ', '_')] = value\n",
    "    \n",
    "    return metadata\n",
    "\n",
    "def save_execution_results(batch_results, output_filename=None):\n",
    "    \"\"\"Save execution results to a CSV file for analysis\"\"\"\n",
    "    if not batch_results or not batch_results['results']:\n",
    "        print(\"‚ùå No results to save\")\n",
    "        return\n",
    "    \n",
    "    if output_filename is None:\n",
    "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "        output_filename = f\"execution_results_{timestamp}.csv\"\n",
    "    \n",
    "    # Prepare data for CSV\n",
    "    csv_data = []\n",
    "    for result in batch_results['results']:\n",
    "        metadata = result.get('metadata', {})\n",
    "        csv_row = {\n",
    "            'index': result.get('index', 0),\n",
    "            'filename': result.get('filename', ''),\n",
    "            'script_id': result.get('script_id', ''),\n",
    "            'success': result.get('success', False),\n",
    "            'execution_time': result.get('execution_time', 0),\n",
    "            'error': result.get('error', '')[:500],  # Limit error message length\n",
    "            'entry_id': metadata.get('entry_id', ''),\n",
    "            'session_id': metadata.get('session_id', ''),\n",
    "            'source_file': metadata.get('extracted_from', ''),\n",
    "            'timestamp': metadata.get('timestamp', '')\n",
    "        }\n",
    "        csv_data.append(csv_row)\n",
    "    \n",
    "    # Save to CSV\n",
    "    df = pd.DataFrame(csv_data)\n",
    "    output_path = os.path.join(parent_dir, output_filename)\n",
    "    df.to_csv(output_path, index=False)\n",
    "    \n",
    "    print(f\"üíæ Execution results saved to: {output_path}\")\n",
    "    print(f\"   üìä {len(csv_data)} records saved\")\n",
    "    \n",
    "    return output_path\n",
    "\n",
    "def update_execution_result_csv(result, csv_path, parent_dir):\n",
    "    \"\"\"\n",
    "    Update or append the execution result for a single file in the CSV.\n",
    "    If the file already exists (by filename), update the row; otherwise, append.\n",
    "    \"\"\"\n",
    "    import pandas as pd\n",
    "    import os\n",
    "    # Prepare row for CSV\n",
    "    metadata = result.get('metadata', {})\n",
    "    csv_row = {\n",
    "        'index': result.get('index', 0),\n",
    "        'filename': result.get('filename', ''),\n",
    "        'script_id': result.get('script_id', ''),\n",
    "        'success': result.get('success', False),\n",
    "        'execution_time': result.get('execution_time', 0),\n",
    "        'error': result.get('error', '')[:500],\n",
    "        'entry_id': metadata.get('entry_id', ''),\n",
    "        'session_id': metadata.get('session_id', ''),\n",
    "        'source_file': metadata.get('extracted_from', ''),\n",
    "        'timestamp': metadata.get('timestamp', '')\n",
    "    }\n",
    "    # If file exists, update or append\n",
    "    if os.path.exists(csv_path) and os.path.getsize(csv_path) > 0:\n",
    "        df = pd.read_csv(csv_path)\n",
    "        # Remove any existing row for this filename\n",
    "        df = df[df['filename'] != csv_row['filename']]\n",
    "        df = pd.concat([df, pd.DataFrame([csv_row])], ignore_index=True)\n",
    "    else:\n",
    "        df = pd.DataFrame([csv_row])\n",
    "    df.to_csv(csv_path, index=False)\n",
    "    print(f\"[CSV] Registered result for {csv_row['filename']} in {csv_path}\")\n",
    "\n",
    "print(\"üîß Batch execution functions ready\")\n",
    "print(\"   Use execute_all_python_files() to start batch execution\")\n",
    "print(\"   Use save_execution_results() to save results to CSV\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4178570f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute_all_files():\n",
    "    \"\"\"Execute ALL extracted Python files, or only previously failed ones if results_records_path exists with failures.\"\"\"\n",
    "    import pandas as pd\n",
    "    if not python_files:\n",
    "        print(\"‚ùå No Python files found. Run the file discovery cell first.\")\n",
    "        return\n",
    "    # Check for existing results and failed files\n",
    "    if os.path.exists(results_records_path) and os.path.getsize(results_records_path) > 0:\n",
    "        df = pd.read_csv(results_records_path)\n",
    "        failed = df[df['success'] == False]\n",
    "        if not failed.empty:\n",
    "            print(f\"üîÑ Found {len(failed)} previously failed files. Will only re-execute those.\")\n",
    "            # Build list of file paths for failed files\n",
    "            failed_files = []\n",
    "            for fname in failed['filename']:\n",
    "                fpath = fname if os.path.isabs(fname) else os.path.join(extracted_code_dir, fname)\n",
    "                if os.path.exists(fpath):\n",
    "                    failed_files.append(fpath)\n",
    "                else:\n",
    "                    print(f\"[SKIP] File not found: {fpath}\")\n",
    "            if not failed_files:\n",
    "                print(\"No failed files found on disk. Nothing to execute.\")\n",
    "                return\n",
    "            # Only execute failed files, update results in place\n",
    "            batch_results = execute_all_python_files(failed_files, update_csv=True)\n",
    "            print(\"‚úÖ Only failed files were executed and results updated.\")\n",
    "            return batch_results\n",
    "    # Otherwise, execute all files as usual\n",
    "    print(f\"‚ö†Ô∏è  WARNING: About to execute ALL {len(python_files)} Python files!\")\n",
    "    print(\"   This could take a very long time...\")\n",
    "    print(\"üöÄ Starting full batch execution...\")\n",
    "    batch_results = execute_all_python_files(python_files, update_csv=True)\n",
    "    if batch_results:\n",
    "        save_execution_results(batch_results, \"full_execution_results.csv\")\n",
    "    return batch_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ea5dc7d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ùå No Python files found. Run the file discovery cell first.\n"
     ]
    }
   ],
   "source": [
    "execute_all_files()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "74713942",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Retry Failed Executions ---\n",
    "import pandas as pd\n",
    "import time\n",
    "import os\n",
    "\n",
    "\n",
    "def retry_failed_executions( executor,  max_retries=1, delay=2, output_csv_path=None):\n",
    "    \"\"\"\n",
    "    Retry execution for failed Python files recorded in the results CSV.\n",
    "    Args:\n",
    "        executor (RemoteTPUExecutor): The executor instance to use for remote execution.\n",
    "        max_retries (int): Number of times to retry each failed file.\n",
    "        delay (int): Seconds to wait between retries.\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame of retry results.\n",
    "    \"\"\"\n",
    "    results_records_path = os.path.join(parent_dir, \"full_execution_results.csv\")\n",
    "    print(f'Loading results from: {results_records_path}')\n",
    "    df = pd.read_csv(results_records_path)\n",
    "    # In full_execution_results.csv, 'success' is a boolean column\n",
    "    failed = df[df['success'] == False]\n",
    "    if failed.empty:\n",
    "        print('No failed executions to retry.')\n",
    "        return None\n",
    "\n",
    "    extracted_code_dir = os.path.join(parent_dir, \"extracted_code\")\n",
    "\n",
    "\n",
    "    print(f'Retrying {len(failed)} failed files...')\n",
    "    retry_results = []\n",
    "    for idx, row in failed.iterrows():\n",
    "        py_file = row['filename']\n",
    "        py_path = py_file if os.path.isabs(py_file) else os.path.join(extracted_code_dir, py_file)\n",
    "        if not os.path.exists(py_path):\n",
    "            print(f'  [SKIP] File not found: {py_path}')\n",
    "            continue\n",
    "        print(f'\\nRetrying: {py_path}')\n",
    "        for attempt in range(1, max_retries+1):\n",
    "            print(f'  Attempt {attempt}...')\n",
    "            try:\n",
    "                with open(py_path, 'r', encoding='utf-8') as f:\n",
    "                    code_content = f.read()\n",
    "                result = executor.execute_code_remotely(code_content, py_file)\n",
    "            except Exception as e:\n",
    "                result = {'success': False, 'error': f'Local file read/exec error: {e}', 'execution_time': 0}\n",
    "            retry_results.append({\n",
    "                'filename': py_file,\n",
    "                'attempt': attempt,\n",
    "                'success': result.get('success', False),\n",
    "                'execution_time': result.get('execution_time', None),\n",
    "                'error': result.get('error', ''),\n",
    "                'script_id': result.get('script_id', ''),\n",
    "                'output': result.get('output', ''),\n",
    "                'entry_id': row.get('entry_id', ''),\n",
    "                'session_id': row.get('session_id', ''),\n",
    "                'source_file': row.get('source_file', ''),\n",
    "                'timestamp': row.get('timestamp', ''),\n",
    "            })\n",
    "            if result.get('success'):\n",
    "                print('  Success!')\n",
    "                break\n",
    "            else:\n",
    "                print('  Failed.')\n",
    "                time.sleep(delay)\n",
    "\n",
    "    retry_df = pd.DataFrame(retry_results)\n",
    "    if output_csv_path is None:\n",
    "        output_csv_path = results_csv_path.replace('.csv', '_retry.csv')\n",
    "    retry_df.to_csv(output_csv_path, index=False)\n",
    "    print(f'\\nRetry results saved to: {output_csv_path}')\n",
    "    return retry_df\n",
    "\n",
    "# Example usage:\n",
    "# retry_failed_executions(executor)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datasci2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
  "data": [
    {
      "id": "efe335ee",
      "timestamp": "2025-07-30T07:43:05.321000+00:00",
      "name": "efe3_tpu_sketch_generator",
      "input": null,
      "output": {
        "status": "success",
        "sketch": "import numpy as np\nfrom tflite_runtime.interpreter import Interpreter, load_delegate\nimport cv2\n\n# Phase 1: Setup\nmodel_path  = \"/home/mendel/tinyml_autopilot/models/edgetpu_detect.tflite\"\nlabel_path  = \"/home/mendel/tinyml_autopilot/models/labelmap.txt\"\ninput_path  = \"/home/mendel/tinyml_autopilot/data//sheeps.mp4\"\noutput_path  = \"/home/mendel/tinyml_autopilot/results/sheeps_detections.mp4\"\nconfidence_threshold  = 0.5\n\n# Load labels\nwith open(label_path, 'r') as f:\n    labels = [line.strip() for line in f.readlines()]\n\n# Load Interpreter with EdgeTPU\ntry:\n    interpreter = Interpreter(model_path=model_path,\n                              experimental_delegates=[load_delegate('libedgetpu.so.1.0')])\nexcept Exception as e:\n    print(f\"Failed to load libedgetpu.so.1.0: {e}\")\n    try:\n        interpreter = Interpreter(model_path=model_path,\n                                  experimental_delegates=[load_delegate('/usr/lib/aarch64-linux-gnu/libedgetpu.so.1.0')])\n    except Exception as e:\n        print(f\"Failed to load /usr/lib/aarch64-linux-gnu/libedgetpu.so.1.0: {e}\")\n        raise\n\ninterpreter.allocate_tensors()\n\n# Get Model Details\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\n\nfloating_model = (input_details[0]['dtype'] == np.float32)\n\nprint(\"Input details:\", input_details)\nprint(\"Output details:\", output_details)\n\n# Phase 2: Input Acquisition & Preprocessing Loop\ncap = cv2.VideoCapture(input_path)\nif not cap.isOpened():\n    raise IOError(\"Cannot open video file\")\n\nframe_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\nframe_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\nfps = cap.get(cv2.CAP_PROP_FPS)\n\nout = cv2.VideoWriter(output_path, cv2.VideoWriter_fourcc(*'mp4v'), fps, (frame_width, frame_height))\n\nwhile True:\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    # Preprocess Data\n    input_data = cv2.resize(frame, (input_details[0]['shape'][1], input_details[0]['shape'][2]))\n    input_data = np.expand_dims(input_data, axis=0)\n\n    if floating_model:\n        input_data = (np.float32(input_data) - 127.5) / 127.5\n\n    # Phase 3: Inference\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n    interpreter.invoke()\n\n    # Phase 4: Output Interpretation & Handling Loop\n    boxes = interpreter.get_tensor(output_details[0]['index'])[0]\n    classes = interpreter.get_tensor(output_details[1]['index'])[0]\n    scores = interpreter.get_tensor(output_details[2]['index'])[0]\n    num_detections = int(interpreter.get_tensor(output_details[3]['index']))  # Corrected index\n\n    for i in range(num_detections):\n        confidence = float(scores[i])\n        if confidence > confidence_threshold:\n            ymin, xmin, ymax, xmax = boxes[i]\n            (left, right, top, bottom) = (xmin * frame_width, xmax * frame_width,\n                                          ymin * frame_height, ymax * frame_height)\n\n            cv2.rectangle(frame, (int(left), int(top)), (int(right), int(bottom)), (0, 255, 0), 2)\n            label = f\"{labels[int(classes[i])]}: {confidence:.2f}\"\n            cv2.putText(frame, label, (int(left), int(top) - 10),\n                        cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n\n    # Handle Output\n    out.write(frame)\n\n# Phase 5: Cleanup\ncap.release()\nout.release()\ncv2.destroyAllWindows()"
      },
      "session_id": "qwen2.5-coder:32b_1974_tpusg_batch",
      "metadata": {
        "num_run": 30
      },
      "tags": [
        "benchmark",
        "qwen2.5-coder:32b",
        "tpu_sketch_generator"
      ],
      "latency": 190.776,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-10-43-05-323896_chatcmpl-0b4bd251-2e97-45f4-9212-34f103c38d72",
          "traceId": "efe335ee",
          "type": "GENERATION",
          "name": "efe3_tpusg_gen_attempt#1",
          "startTime": "2025-07-30T07:43:05.323000+00:00",
          "endTime": "2025-07-30T07:43:40.322000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 34999.0,
          "environment": "default",
          "promptTokens": 1833,
          "completionTokens": 822,
          "totalTokens": 2655,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-10-43-48-595234_chatcmpl-2f24fa79-d8ad-45d6-baee-db65b18f3f76",
          "traceId": "efe335ee",
          "type": "GENERATION",
          "name": "efe3_tpusg_gen_attempt#2",
          "startTime": "2025-07-30T07:43:48.595000+00:00",
          "endTime": "2025-07-30T07:44:32.291000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 43696.0,
          "environment": "default",
          "promptTokens": 2048,
          "completionTokens": 1055,
          "totalTokens": 3103,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-10-44-40-545076_chatcmpl-7bee6cd4-919f-46fd-8fc2-c57be44d2064",
          "traceId": "efe335ee",
          "type": "GENERATION",
          "name": "efe3_tpusg_gen_attempt#3",
          "startTime": "2025-07-30T07:44:40.545000+00:00",
          "endTime": "2025-07-30T07:45:26.489000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 45944.0,
          "environment": "default",
          "promptTokens": 2048,
          "completionTokens": 1108,
          "totalTokens": 3156,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-10-45-34-760937_chatcmpl-9683905a-b2a3-45dc-961b-673fe4f7704e",
          "traceId": "efe335ee",
          "type": "GENERATION",
          "name": "efe3_tpusg_gen_attempt#4",
          "startTime": "2025-07-30T07:45:34.760000+00:00",
          "endTime": "2025-07-30T07:46:16.099000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 41339.0,
          "environment": "default",
          "promptTokens": 2048,
          "completionTokens": 989,
          "totalTokens": 3037,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        }
      ],
      "createdAt": "2025-07-30T07:43:05.842Z",
      "updatedAt": "2025-07-30T07:47:14.234Z",
      "environment": "default"
    },
    {
      "id": "d4ef2e0a",
      "timestamp": "2025-07-30T07:38:16.194000+00:00",
      "name": "d4ef_tpu_sketch_generator",
      "input": null,
      "output": {
        "status": "success",
        "sketch": "import numpy as np\nfrom tflite_runtime.interpreter import Interpreter, load_delegate\n\n# Phase 1: Setup\nmodel_path  = \"/home/mendel/tinyml_autopilot/models/edgetpu_detect.tflite\"\nlabel_path  = \"/home/mendel/tinyml_autopilot/models/labelmap.txt\"\ninput_path  = \"/home/mendel/tinyml_autopilot/data//sheeps.mp4\"\noutput_path  = \"/home/mendel/tinyml_autopilot/results/sheeps_detections.mp4\"\nconfidence_threshold  = 0.5\n\n# Load labels\nwith open(label_path, 'r') as f:\n    labels = [line.strip() for line in f.readlines()]\n\n# Load Interpreter with EdgeTPU\ntry:\n    interpreter = Interpreter(model_path=model_path,\n                              experimental_delegates=[load_delegate('libedgetpu.so.1.0')])\nexcept Exception as e:\n    print(f\"Failed to load libedgetpu.so.1.0: {e}\")\n    try:\n        interpreter = Interpreter(model_path=model_path,\n                                  experimental_delegates=[load_delegate('/usr/lib/aarch64-linux-gnu/libedgetpu.so.1.0')])\n    except Exception as e:\n        print(f\"Failed to load /usr/lib/aarch64-linux-gnu/libedgetpu.so.1.0: {e}\")\n        raise\n\ninterpreter.allocate_tensors()\n\n# Get Model Details\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\n\nfloating_model = (input_details[0]['dtype'] == np.float32)\n\n# Phase 2: Input Acquisition & Preprocessing Loop\nimport cv2\n\ncap = cv2.VideoCapture(input_path)\nif not cap.isOpened():\n    raise IOError(\"Cannot open video file\")\n\nframe_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\nframe_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\nfps = cap.get(cv2.CAP_PROP_FPS)\n\nout = cv2.VideoWriter(output_path, cv2.VideoWriter_fourcc(*'mp4v'), fps, (frame_width, frame_height))\n\nwhile True:\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    # Preprocess Data\n    input_data = cv2.resize(frame, (input_details[0]['shape'][1], input_details[0]['shape'][2]))\n    input_data = np.expand_dims(input_data, axis=0)\n\n    if floating_model:\n        input_data = (np.float32(input_data) - 127.5) / 127.5\n\n    # Phase 3: Inference\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n    interpreter.invoke()\n\n    # Phase 4: Output Interpretation & Handling Loop\n    output_data = interpreter.get_tensor(output_details[0]['index'])\n    num_detections_tensor = interpreter.get_tensor(output_details[2]['index'])\n\n    # Ensure the tensor is a single scalar value\n    if num_detections_tensor.size == 1:\n        num_detections = int(np.squeeze(num_detections_tensor))\n    else:\n        print(\"Unexpected shape for number of detections:\", num_detections_tensor.shape)\n        continue\n\n    for i in range(num_detections):\n        confidence = float(output_data[0][i][15])\n        if confidence > confidence_threshold:\n            ymin, xmin, ymax, xmax = output_data[0][i][:4]\n            (left, right, top, bottom) = (xmin * frame_width, xmax * frame_width,\n                                          ymin * frame_height, ymax * frame_height)\n\n            cv2.rectangle(frame, (int(left), int(top)), (int(right), int(bottom)), (0, 255, 0), 2)\n            label = f\"{labels[int(output_data[0][i][14])]}: {confidence:.2f}\"\n            cv2.putText(frame, label, (int(left), int(top) - 10),\n                        cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n\n    # Handle Output\n    out.write(frame)\n\n# Phase 5: Cleanup\ncap.release()\nout.release()\ncv2.destroyAllWindows()"
      },
      "session_id": "qwen2.5-coder:32b_1974_tpusg_batch",
      "metadata": {
        "num_run": 29
      },
      "tags": [
        "benchmark",
        "qwen2.5-coder:32b",
        "tpu_sketch_generator"
      ],
      "latency": 236.081,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-10-38-16-195843_chatcmpl-c6b76df6-6ec9-4a46-b39f-042ee8b12bea",
          "traceId": "d4ef2e0a",
          "type": "GENERATION",
          "name": "d4ef_tpusg_gen_attempt#1",
          "startTime": "2025-07-30T07:38:16.195000+00:00",
          "endTime": "2025-07-30T07:38:51.270000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 35075.0,
          "environment": "default",
          "promptTokens": 1833,
          "completionTokens": 822,
          "totalTokens": 2655,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-10-38-59-588764_chatcmpl-f34dd342-0a7d-46ea-a866-8a7f4e6c6c8b",
          "traceId": "d4ef2e0a",
          "type": "GENERATION",
          "name": "d4ef_tpusg_gen_attempt#2",
          "startTime": "2025-07-30T07:38:59.588000+00:00",
          "endTime": "2025-07-30T07:39:41.839000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 42251.0,
          "environment": "default",
          "promptTokens": 2048,
          "completionTokens": 1001,
          "totalTokens": 3049,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-10-39-50-206830_chatcmpl-e4a4a41c-0a8d-469e-9d08-a8ce8accc97c",
          "traceId": "d4ef2e0a",
          "type": "GENERATION",
          "name": "d4ef_tpusg_gen_attempt#3",
          "startTime": "2025-07-30T07:39:50.206000+00:00",
          "endTime": "2025-07-30T07:40:30.527000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 40321.0,
          "environment": "default",
          "promptTokens": 2048,
          "completionTokens": 974,
          "totalTokens": 3022,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-10-40-38-848630_chatcmpl-20edc9cc-c4a0-4a79-97f9-3331d1daea64",
          "traceId": "d4ef2e0a",
          "type": "GENERATION",
          "name": "d4ef_tpusg_gen_attempt#4",
          "startTime": "2025-07-30T07:40:38.848000+00:00",
          "endTime": "2025-07-30T07:41:18.925000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 40077.0,
          "environment": "default",
          "promptTokens": 2048,
          "completionTokens": 970,
          "totalTokens": 3018,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-10-41-27-180890_chatcmpl-edf2100a-d184-4e9f-a34f-58e3c760c48d",
          "traceId": "d4ef2e0a",
          "type": "GENERATION",
          "name": "d4ef_tpusg_gen_attempt#5",
          "startTime": "2025-07-30T07:41:27.180000+00:00",
          "endTime": "2025-07-30T07:42:12.276000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 45096.0,
          "environment": "default",
          "promptTokens": 2048,
          "completionTokens": 1079,
          "totalTokens": 3127,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        }
      ],
      "createdAt": "2025-07-30T07:38:16.716Z",
      "updatedAt": "2025-07-30T07:43:05.450Z",
      "environment": "default"
    },
    {
      "id": "abc065b1",
      "timestamp": "2025-07-30T07:34:19.594000+00:00",
      "name": "abc0_tpu_sketch_generator",
      "input": null,
      "output": {
        "status": "success",
        "sketch": "import numpy as np\nfrom PIL import Image\nimport cv2\n\n# Phase 1: Setup\ntry:\n    from tflite_runtime.interpreter import Interpreter, load_delegate\nexcept ImportError:\n    from tensorflow.lite import Interpreter\n    from tensorflow.lite.experimental import load_delegate\n\n# Paths/Parameters\nmodel_path  = \"/home/mendel/tinyml_autopilot/models/edgetpu_detect.tflite\"\ninput_path  = \"/home/mendel/tinyml_autopilot/data//sheeps.mp4\"\nlabel_path  = \"/home/mendel/tinyml_autopilot/models/labelmap.txt\"\noutput_path  = \"/home/mendel/tinyml_autopilot/results/sheeps_detections.mp4\"\n\n# Load Labels (Conditional)\nwith open(label_path, 'r') as f:\n    labels = [line.strip() for line in f.readlines()]\n\n# Load Interpreter with EdgeTPU\ntry:\n    interpreter = Interpreter(model_path=model_path, experimental_delegates=[load_delegate('libedgetpu.so.1.0')])\nexcept Exception as e:\n    interpreter = Interpreter(model_path=model_path, experimental_delegates=[load_delegate('/usr/lib/aarch64-linux-gnu/libedgetpu.so.1.0')])\n\ninterpreter.allocate_tensors()\n\n# Get Model Details\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\n\n# Phase 2: Input Acquisition & Preprocessing Loop\ncap = cv2.VideoCapture(input_path)\nwidth = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\nheight = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\nfps = cap.get(cv2.CAP_PROP_FPS)\n\nfourcc = cv2.VideoWriter_fourcc(*'mp4v')\nout = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n\nwhile cap.isOpened():\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    # Preprocess Data\n    input_data = cv2.resize(frame, (input_details[0]['shape'][1], input_details[0]['shape'][2]))\n    input_data = np.expand_dims(input_data, axis=0)\n\n    # Quantization Handling\n    floating_model = (input_details[0]['dtype'] == np.float32)\n    if floating_model:\n        input_data = (np.float32(input_data) - 127.5) / 127.5\n\n    # Phase 3: Inference\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n    interpreter.invoke()\n\n    # Phase 4: Output Interpretation & Handling Loop\n    boxes = interpreter.get_tensor(output_details[0]['index'])[0]\n    classes = interpreter.get_tensor(output_details[1]['index'])[0]\n    scores = interpreter.get_tensor(output_details[2]['index'])[0]\n    num_detections = int(interpreter.get_tensor(output_details[3]['index']))\n\n    # Interpret Results\n    for i in range(num_detections):\n        if scores[i] > 0.5:\n            ymin, xmin, ymax, xmax = boxes[i]\n            (left, right, top, bottom) = (xmin * width, xmax * width,\n                                          ymin * height, ymax * height)\n            cv2.rectangle(frame, (int(left), int(top)), (int(right), int(bottom)), (0, 255, 0), 2)\n            label = f'{labels[int(classes[i])]}: {scores[i]:.2f}'\n            cv2.putText(frame, label, (int(left), int(top) - 10),\n                        cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n\n    # Handle Output\n    out.write(frame)\n\n# Phase 5: Cleanup\ncap.release()\nout.release()\ncv2.destroyAllWindows()"
      },
      "session_id": "qwen2.5-coder:32b_1974_tpusg_batch",
      "metadata": {
        "num_run": 28
      },
      "tags": [
        "benchmark",
        "qwen2.5-coder:32b",
        "tpu_sketch_generator"
      ],
      "latency": 178.02,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-10-34-19-595459_chatcmpl-4d1e4f59-8ce1-4880-bc58-af1123590378",
          "traceId": "abc065b1",
          "type": "GENERATION",
          "name": "abc0_tpusg_gen_attempt#1",
          "startTime": "2025-07-30T07:34:19.595000+00:00",
          "endTime": "2025-07-30T07:34:54.412000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 34817.0,
          "environment": "default",
          "promptTokens": 1833,
          "completionTokens": 822,
          "totalTokens": 2655,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-10-35-02-652406_chatcmpl-1668b68e-6d13-40a5-8ea3-b973234f520a",
          "traceId": "abc065b1",
          "type": "GENERATION",
          "name": "abc0_tpusg_gen_attempt#2",
          "startTime": "2025-07-30T07:35:02.652000+00:00",
          "endTime": "2025-07-30T07:35:53.914000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 51262.0,
          "environment": "default",
          "promptTokens": 2048,
          "completionTokens": 1239,
          "totalTokens": 3287,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-10-35-53-922243_chatcmpl-210ea055-421b-4e02-beee-8043636810ea",
          "traceId": "abc065b1",
          "type": "GENERATION",
          "name": "abc0_tpusg_gen_attempt#3",
          "startTime": "2025-07-30T07:35:53.922000+00:00",
          "endTime": "2025-07-30T07:36:30.724000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 36802.0,
          "environment": "default",
          "promptTokens": 1990,
          "completionTokens": 868,
          "totalTokens": 2858,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-10-36-38-586966_chatcmpl-76aeb73f-8145-4fa1-a396-61bce16d5eac",
          "traceId": "abc065b1",
          "type": "GENERATION",
          "name": "abc0_tpusg_gen_attempt#4",
          "startTime": "2025-07-30T07:36:38.586000+00:00",
          "endTime": "2025-07-30T07:37:17.615000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 39029.0,
          "environment": "default",
          "promptTokens": 2048,
          "completionTokens": 927,
          "totalTokens": 2975,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        }
      ],
      "createdAt": "2025-07-30T07:34:20.116Z",
      "updatedAt": "2025-07-30T07:38:15.322Z",
      "environment": "default"
    },
    {
      "id": "cc081285",
      "timestamp": "2025-07-30T07:30:09.028000+00:00",
      "name": "cc08_tpu_sketch_generator",
      "input": null,
      "output": {
        "status": "failed",
        "last_code": "import numpy as np\nfrom tflite_runtime.interpreter import Interpreter, load_delegate\n\n# Phase 1: Setup\nmodel_path  = \"/home/mendel/tinyml_autopilot/models/edgetpu_detect.tflite\"\nlabel_path  = \"/home/mendel/tinyml_autopilot/models/labelmap.txt\"\ninput_path  = \"/home/mendel/tinyml_autopilot/data//sheeps.mp4\"\noutput_path  = \"/home/mendel/tinyml_autopilot/results/sheeps_detections.mp4\"\nconfidence_threshold  = 0.5\n\n# Load labels\nwith open(label_path, 'r') as f:\n    labels = [line.strip() for line in f.readlines()]\n\n# Load Interpreter with EdgeTPU\ntry:\n    interpreter = Interpreter(model_path=model_path,\n                              experimental_delegates=[load_delegate('libedgetpu.so.1.0')])\nexcept Exception as e:\n    print(f\"Failed to load libedgetpu.so.1.0: {e}\")\n    try:\n        interpreter = Interpreter(model_path=model_path,\n                                  experimental_delegates=[load_delegate('/usr/lib/aarch64-linux-gnu/libedgetpu.so.1.0')])\n    except Exception as e:\n        print(f\"Failed to load /usr/lib/aarch64-linux-gnu/libedgetpu.so.1.0: {e}\")\n        raise\n\ninterpreter.allocate_tensors()\n\n# Get Model Details\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\n\nfloating_model = (input_details[0]['dtype'] == np.float32)\n\n# Phase 2: Input Acquisition & Preprocessing Loop\nimport cv2\n\ncap = cv2.VideoCapture(input_path)\nif not cap.isOpened():\n    raise IOError(\"Cannot open video file\")\n\nframe_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\nframe_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\nfps = cap.get(cv2.CAP_PROP_FPS)\n\nout = cv2.VideoWriter(output_path, cv2.VideoWriter_fourcc(*'mp4v'), fps, (frame_width, frame_height))\n\nwhile True:\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    # Preprocess Data\n    input_data = cv2.resize(frame, (input_details[0]['shape'][1], input_details[0]['shape'][2]))\n    input_data = np.expand_dims(input_data, axis=0)\n\n    if floating_model:\n        input_data = (np.float32(input_data) - 127.5) / 127.5\n\n    # Phase 3: Inference\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n    interpreter.invoke()\n\n    # Phase 4: Output Interpretation & Handling Loop\n    output_data = interpreter.get_tensor(output_details[0]['index'])\n    num_detections = int(interpreter.get_tensor(output_details[2]['index'])[0])  # Access the scalar value directly\n\n    for i in range(num_detections):\n        confidence = float(output_data[0][i][15])\n        if confidence > confidence_threshold:\n            ymin, xmin, ymax, xmax = output_data[0][i][:4]\n            (left, right, top, bottom) = (xmin * frame_width, xmax * frame_width,\n                                          ymin * frame_height, ymax * frame_height)\n\n            cv2.rectangle(frame, (int(left), int(top)), (int(right), int(bottom)), (0, 255, 0), 2)\n            label = f\"{labels[int(output_data[0][i][14])]}: {confidence:.2f}\"\n            cv2.putText(frame, label, (int(left), int(top) - 10),\n                        cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n\n    # Handle Output\n    out.write(frame)\n\n# Phase 5: Cleanup\ncap.release()\nout.release()\ncv2.destroyAllWindows()",
        "last_error": "Traceback (most recent call last):\n  File \"script_4606bee4_1753860846.py\", line 67, in <module>\n    num_detections = int(interpreter.get_tensor(output_details[2]['index'])[0])  # Access the scalar value directly\nTypeError: only size-1 arrays can be converted to Python scalars"
      },
      "session_id": "qwen2.5-coder:32b_1974_tpusg_batch",
      "metadata": {
        "num_run": 27
      },
      "tags": [
        "benchmark",
        "qwen2.5-coder:32b",
        "tpu_sketch_generator"
      ],
      "latency": 245.274,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-10-30-09-029529_chatcmpl-4814d10a-8893-4cd1-bd8f-14535bf46572",
          "traceId": "cc081285",
          "type": "GENERATION",
          "name": "cc08_tpusg_gen_attempt#1",
          "startTime": "2025-07-30T07:30:09.029000+00:00",
          "endTime": "2025-07-30T07:30:43.733000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 34704.0,
          "environment": "default",
          "promptTokens": 1833,
          "completionTokens": 822,
          "totalTokens": 2655,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-10-30-52-084897_chatcmpl-c0b88bbb-39b6-4483-a99c-56decb6fe206",
          "traceId": "cc081285",
          "type": "GENERATION",
          "name": "cc08_tpusg_gen_attempt#2",
          "startTime": "2025-07-30T07:30:52.084000+00:00",
          "endTime": "2025-07-30T07:31:34.092000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 42008.0,
          "environment": "default",
          "promptTokens": 2048,
          "completionTokens": 1001,
          "totalTokens": 3049,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-10-31-42-352986_chatcmpl-14544edf-f461-4fba-9fc7-8ac9c505cf28",
          "traceId": "cc081285",
          "type": "GENERATION",
          "name": "cc08_tpusg_gen_attempt#3",
          "startTime": "2025-07-30T07:31:42.352000+00:00",
          "endTime": "2025-07-30T07:32:23.609000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 41257.0,
          "environment": "default",
          "promptTokens": 2048,
          "completionTokens": 991,
          "totalTokens": 3039,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-10-32-31-914076_chatcmpl-b4b7edd8-801a-4692-b44a-2c515da0bb7f",
          "traceId": "cc081285",
          "type": "GENERATION",
          "name": "cc08_tpusg_gen_attempt#4",
          "startTime": "2025-07-30T07:32:31.914000+00:00",
          "endTime": "2025-07-30T07:33:14.570000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 42656.0,
          "environment": "default",
          "promptTokens": 2048,
          "completionTokens": 1023,
          "totalTokens": 3071,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-10-33-22-798986_chatcmpl-22d2985a-a02f-44aa-8288-3d25186da63d",
          "traceId": "cc081285",
          "type": "GENERATION",
          "name": "cc08_tpusg_gen_attempt#5",
          "startTime": "2025-07-30T07:33:22.798000+00:00",
          "endTime": "2025-07-30T07:34:06.127000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 43329.0,
          "environment": "default",
          "promptTokens": 2048,
          "completionTokens": 1041,
          "totalTokens": 3089,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "9df10bb8-4fc6-468c-9bff-6176dbcdfa18",
          "traceId": "cc081285",
          "type": "SPAN",
          "name": "error_cc_tpusg_failure_signal_tpu_sketch_generator",
          "startTime": "2025-07-30T07:34:14.303000+00:00",
          "level": "ERROR",
          "statusMessage": "Failed. Last error: Traceback (most recent call last):\n  File \"script_4606bee4_1753860846.py\", line 67, in <module>\n    num_detections = int(interpreter.get_tensor(output_details[2]['index'])[0])  # Access the scalar value directly\nTypeError: only size-1 arrays can be converted to Python scalars",
          "calculatedTotalCost": 0.0,
          "environment": "default",
          "promptTokens": 0,
          "completionTokens": 0,
          "totalTokens": 0,
          "costDetails": {},
          "endTime": null,
          "model": null,
          "modelParameters": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null,
          "latency": null
        }
      ],
      "createdAt": "2025-07-30T07:30:09.549Z",
      "updatedAt": "2025-07-30T07:34:19.916Z",
      "environment": "default"
    },
    {
      "id": "8a4d3f5d",
      "timestamp": "2025-07-30T07:26:14.110000+00:00",
      "name": "8a4d_tpu_sketch_generator",
      "input": null,
      "output": {
        "status": "success",
        "sketch": "import numpy as np\nfrom PIL import Image\nimport cv2\n\n# Phase 1: Setup\ntry:\n    from tflite_runtime.interpreter import Interpreter, load_delegate\nexcept ImportError:\n    from tensorflow.lite import Interpreter\n    from tensorflow.lite.experimental import load_delegate\n\n# Paths/Parameters\nmodel_path  = \"/home/mendel/tinyml_autopilot/models/edgetpu_detect.tflite\"\ninput_path  = \"/home/mendel/tinyml_autopilot/data//sheeps.mp4\"\nlabel_path  = \"/home/mendel/tinyml_autopilot/models/labelmap.txt\"\noutput_path  = \"/home/mendel/tinyml_autopilot/results/sheeps_detections.mp4\"\n\n# Load Labels (Conditional)\nwith open(label_path, 'r') as f:\n    labels = [line.strip() for line in f.readlines()]\n\n# Load Interpreter with EdgeTPU\ntry:\n    interpreter = Interpreter(model_path=model_path, experimental_delegates=[load_delegate('libedgetpu.so.1.0')])\nexcept Exception as e:\n    interpreter = Interpreter(model_path=model_path, experimental_delegates=[load_delegate('/usr/lib/aarch64-linux-gnu/libedgetpu.so.1.0')])\n\ninterpreter.allocate_tensors()\n\n# Get Model Details\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\n\n# Phase 2: Input Acquisition & Preprocessing Loop\ncap = cv2.VideoCapture(input_path)\nwidth = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\nheight = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\nfps = cap.get(cv2.CAP_PROP_FPS)\n\nfourcc = cv2.VideoWriter_fourcc(*'mp4v')\nout = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n\nwhile cap.isOpened():\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    # Preprocess Data\n    input_data = cv2.resize(frame, (input_details[0]['shape'][1], input_details[0]['shape'][2]))\n    input_data = np.expand_dims(input_data, axis=0)\n\n    # Quantization Handling\n    floating_model = (input_details[0]['dtype'] == np.float32)\n    if floating_model:\n        input_data = (np.float32(input_data) - 127.5) / 127.5\n\n    # Phase 3: Inference\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n    interpreter.invoke()\n\n    # Phase 4: Output Interpretation & Handling Loop\n    boxes = interpreter.get_tensor(output_details[0]['index'])[0]\n    classes = interpreter.get_tensor(output_details[1]['index'])[0]\n    scores = interpreter.get_tensor(output_details[2]['index'])[0]\n    num_detections = int(interpreter.get_tensor(output_details[3]['index']))\n\n    # Interpret Results\n    for i in range(num_detections):\n        if scores[i] > 0.5:\n            ymin, xmin, ymax, xmax = boxes[i]\n            (left, right, top, bottom) = (xmin * width, xmax * width,\n                                          ymin * height, ymax * height)\n            cv2.rectangle(frame, (int(left), int(top)), (int(right), int(bottom)), (0, 255, 0), 2)\n            label = f'{labels[int(classes[i])]}: {scores[i]:.2f}'\n            cv2.putText(frame, label, (int(left), int(top) - 10),\n                        cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n\n    # Handle Output\n    out.write(frame)\n\n# Phase 5: Cleanup\ncap.release()\nout.release()\ncv2.destroyAllWindows()"
      },
      "session_id": "qwen2.5-coder:32b_1974_tpusg_batch",
      "metadata": {
        "num_run": 26
      },
      "tags": [
        "benchmark",
        "qwen2.5-coder:32b",
        "tpu_sketch_generator"
      ],
      "latency": 176.649,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-10-26-14-111723_chatcmpl-b1bbbd2e-9c1a-437f-9878-e7c95ce99267",
          "traceId": "8a4d3f5d",
          "type": "GENERATION",
          "name": "8a4d_tpusg_gen_attempt#1",
          "startTime": "2025-07-30T07:26:14.111000+00:00",
          "endTime": "2025-07-30T07:26:48.967000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 34856.0,
          "environment": "default",
          "promptTokens": 1833,
          "completionTokens": 822,
          "totalTokens": 2655,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-10-26-57-479865_chatcmpl-d5cedaa2-deef-470c-ab6e-fe95e083a398",
          "traceId": "8a4d3f5d",
          "type": "GENERATION",
          "name": "8a4d_tpusg_gen_attempt#2",
          "startTime": "2025-07-30T07:26:57.479000+00:00",
          "endTime": "2025-07-30T07:27:46.392000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 48913.0,
          "environment": "default",
          "promptTokens": 2048,
          "completionTokens": 1193,
          "totalTokens": 3241,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-10-27-46-398455_chatcmpl-730f09ae-13fd-4e0e-892e-09c41fde6d2e",
          "traceId": "8a4d3f5d",
          "type": "GENERATION",
          "name": "8a4d_tpusg_gen_attempt#3",
          "startTime": "2025-07-30T07:27:46.398000+00:00",
          "endTime": "2025-07-30T07:28:22.799000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 36401.0,
          "environment": "default",
          "promptTokens": 1990,
          "completionTokens": 868,
          "totalTokens": 2858,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-10-28-30-837256_chatcmpl-4843c6a9-67b4-4e43-8b7e-2b319fd583d0",
          "traceId": "8a4d3f5d",
          "type": "GENERATION",
          "name": "8a4d_tpusg_gen_attempt#4",
          "startTime": "2025-07-30T07:28:30.837000+00:00",
          "endTime": "2025-07-30T07:29:10.760000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 39923.0,
          "environment": "default",
          "promptTokens": 2048,
          "completionTokens": 958,
          "totalTokens": 3006,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        }
      ],
      "createdAt": "2025-07-30T07:26:14.631Z",
      "updatedAt": "2025-07-30T07:30:08.380Z",
      "environment": "default"
    },
    {
      "id": "1a156bdc",
      "timestamp": "2025-07-30T07:21:59.469000+00:00",
      "name": "1a15_tpu_sketch_generator",
      "input": null,
      "output": {
        "status": "failed",
        "last_code": "import numpy as np\nfrom tflite_runtime.interpreter import Interpreter, load_delegate\nimport cv2\n\n# Phase 1: Setup\nmodel_path  = \"/home/mendel/tinyml_autopilot/models/edgetpu_detect.tflite\"\nlabel_path  = \"/home/mendel/tinyml_autopilot/models/labelmap.txt\"\ninput_path  = \"/home/mendel/tinyml_autopilot/data//sheeps.mp4\"\noutput_path  = \"/home/mendel/tinyml_autopilot/results/sheeps_detections.mp4\"\nconfidence_threshold  = 0.5\n\n# Load labels\nwith open(label_path, 'r') as f:\n    labels = [line.strip() for line in f.readlines()]\n\n# Load Interpreter with EdgeTPU\ntry:\n    interpreter = Interpreter(model_path=model_path,\n                              experimental_delegates=[load_delegate('libedgetpu.so.1.0')])\nexcept Exception as e:\n    print(f\"Failed to load libedgetpu.so.1.0: {e}\")\n    try:\n        interpreter = Interpreter(model_path=model_path,\n                                  experimental_delegates=[load_delegate('/usr/lib/aarch64-linux-gnu/libedgetpu.so.1.0')])\n    except Exception as e:\n        print(f\"Failed to load /usr/lib/aarch64-linux-gnu/libedgetpu.so.1.0: {e}\")\n        raise\n\ninterpreter.allocate_tensors()\n\n# Get Model Details\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\n\nfloating_model = (input_details[0]['dtype'] == np.float32)\n\n# Phase 2: Input Acquisition & Preprocessing Loop\ncap = cv2.VideoCapture(input_path)\nif not cap.isOpened():\n    raise IOError(\"Cannot open video file\")\n\nframe_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\nframe_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\nfps = cap.get(cv2.CAP_PROP_FPS)\n\nout = cv2.VideoWriter(output_path, cv2.VideoWriter_fourcc(*'mp4v'), fps, (frame_width, frame_height))\n\nwhile True:\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    # Preprocess Data\n    input_data = cv2.resize(frame, (input_details[0]['shape'][1], input_details[0]['shape'][2]))\n    input_data = np.expand_dims(input_data, axis=0)\n\n    if floating_model:\n        input_data = (np.float32(input_data) - 127.5) / 127.5\n\n    # Phase 3: Inference\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n    interpreter.invoke()\n\n    # Phase 4: Output Interpretation & Handling Loop\n    output_data = interpreter.get_tensor(output_details[0]['index'])\n    num_detections = int(interpreter.get_tensor(output_details[2]['index']))  # Correctly extract the scalar value\n\n    for i in range(num_detections):\n        confidence = float(output_data[0][i][15])\n        if confidence > confidence_threshold:\n            class_id = int(output_data[0][i][14])\n            label = labels[class_id]\n            box = output_data[0][i][:4] * np.array([frame_height, frame_width, frame_height, frame_width])\n\n            y_min, x_min, y_max, x_max = box.astype(int)\n            cv2.rectangle(frame, (x_min, y_min), (x_max, y_max), (10, 255, 0), 2)\n            label_text = f'{label}: {confidence:.2f}'\n            cv2.putText(frame, label_text, (x_min, y_min - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (36, 255, 12), 2)\n\n    # Handle Output\n    out.write(frame)\n\n# Phase 5: Cleanup\ncap.release()\nout.release()\ncv2.destroyAllWindows()",
        "last_error": "Traceback (most recent call last):\n  File \"script_5eb8ea1b_1753860359.py\", line 66, in <module>\n    num_detections = int(interpreter.get_tensor(output_details[2]['index']))  # Correctly extract the scalar value\nTypeError: only size-1 arrays can be converted to Python scalars"
      },
      "session_id": "qwen2.5-coder:32b_1974_tpusg_batch",
      "metadata": {
        "num_run": 25
      },
      "tags": [
        "benchmark",
        "qwen2.5-coder:32b",
        "tpu_sketch_generator"
      ],
      "latency": 248.502,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-10-21-59-470659_chatcmpl-1451859a-3979-4bae-932d-dbd4bbe6b021",
          "traceId": "1a156bdc",
          "type": "GENERATION",
          "name": "1a15_tpusg_gen_attempt#1",
          "startTime": "2025-07-30T07:21:59.470000+00:00",
          "endTime": "2025-07-30T07:22:34.276000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 34806.0,
          "environment": "default",
          "promptTokens": 1833,
          "completionTokens": 829,
          "totalTokens": 2662,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-10-22-42-520893_chatcmpl-5f9efe14-38ea-4af2-a419-e521a4df9906",
          "traceId": "1a156bdc",
          "type": "GENERATION",
          "name": "1a15_tpusg_gen_attempt#2",
          "startTime": "2025-07-30T07:22:42.520000+00:00",
          "endTime": "2025-07-30T07:23:26.128000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 43608.0,
          "environment": "default",
          "promptTokens": 2048,
          "completionTokens": 1060,
          "totalTokens": 3108,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-10-23-34-317936_chatcmpl-38f9e39b-f40c-4c20-9399-2087d2aadb35",
          "traceId": "1a156bdc",
          "type": "GENERATION",
          "name": "1a15_tpusg_gen_attempt#3",
          "startTime": "2025-07-30T07:23:34.317000+00:00",
          "endTime": "2025-07-30T07:24:15.780000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 41463.0,
          "environment": "default",
          "promptTokens": 2048,
          "completionTokens": 1002,
          "totalTokens": 3050,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-10-24-24-023671_chatcmpl-de34daa5-68d5-4a47-bd9d-bc725f4ff6b6",
          "traceId": "1a156bdc",
          "type": "GENERATION",
          "name": "1a15_tpusg_gen_attempt#4",
          "startTime": "2025-07-30T07:24:24.023000+00:00",
          "endTime": "2025-07-30T07:25:07.845000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 43822.0,
          "environment": "default",
          "promptTokens": 2048,
          "completionTokens": 1060,
          "totalTokens": 3108,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-10-25-16-073046_chatcmpl-609aa0fe-5b65-4640-8e05-21061b92c166",
          "traceId": "1a156bdc",
          "type": "GENERATION",
          "name": "1a15_tpusg_gen_attempt#5",
          "startTime": "2025-07-30T07:25:16.073000+00:00",
          "endTime": "2025-07-30T07:25:59.551000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 43478.0,
          "environment": "default",
          "promptTokens": 2048,
          "completionTokens": 1044,
          "totalTokens": 3092,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "caf78642-4fbd-4cbc-b919-7e318bdcd914",
          "traceId": "1a156bdc",
          "type": "SPAN",
          "name": "error_1a_tpusg_failure_signal_tpu_sketch_generator",
          "startTime": "2025-07-30T07:26:07.972000+00:00",
          "level": "ERROR",
          "statusMessage": "Failed. Last error: Traceback (most recent call last):\n  File \"script_5eb8ea1b_1753860359.py\", line 66, in <module>\n    num_detections = int(interpreter.get_tensor(output_details[2]['index']))  # Correctly extract the scalar value\nTypeError: only size-1 arrays can be converted to Python scalars",
          "calculatedTotalCost": 0.0,
          "environment": "default",
          "promptTokens": 0,
          "completionTokens": 0,
          "totalTokens": 0,
          "costDetails": {},
          "endTime": null,
          "model": null,
          "modelParameters": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null,
          "latency": null
        }
      ],
      "createdAt": "2025-07-30T07:21:59.987Z",
      "updatedAt": "2025-07-30T07:26:13.207Z",
      "environment": "default"
    },
    {
      "id": "65092f21",
      "timestamp": "2025-07-30T07:18:06.936000+00:00",
      "name": "6509_tpu_sketch_generator",
      "input": null,
      "output": {
        "status": "success",
        "sketch": "import numpy as np\nfrom PIL import Image\nimport cv2\n\n# Phase 1: Setup\ntry:\n    from tflite_runtime.interpreter import Interpreter, load_delegate\nexcept ImportError:\n    from tensorflow.lite import Interpreter\n    from tensorflow.lite.experimental import load_delegate\n\n# Paths/Parameters\nmodel_path  = \"/home/mendel/tinyml_autopilot/models/edgetpu_detect.tflite\"\ninput_path  = \"/home/mendel/tinyml_autopilot/data//sheeps.mp4\"\nlabel_path  = \"/home/mendel/tinyml_autopilot/models/labelmap.txt\"\noutput_path  = \"/home/mendel/tinyml_autopilot/results/sheeps_detections.mp4\"\n\n# Load Labels (Conditional)\nwith open(label_path, 'r') as f:\n    labels = [line.strip() for line in f.readlines()]\n\n# Load Interpreter with EdgeTPU\ntry:\n    interpreter = Interpreter(model_path=model_path, experimental_delegates=[load_delegate('libedgetpu.so.1.0')])\nexcept Exception as e:\n    interpreter = Interpreter(model_path=model_path, experimental_delegates=[load_delegate('/usr/lib/aarch64-linux-gnu/libedgetpu.so.1.0')])\n\ninterpreter.allocate_tensors()\n\n# Get Model Details\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\n\n# Phase 2: Input Acquisition & Preprocessing Loop\ncap = cv2.VideoCapture(input_path)\nwidth = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\nheight = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\nfps = cap.get(cv2.CAP_PROP_FPS)\n\nfourcc = cv2.VideoWriter_fourcc(*'mp4v')\nout = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n\nwhile cap.isOpened():\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    # Preprocess Data\n    input_data = cv2.resize(frame, (input_details[0]['shape'][1], input_details[0]['shape'][2]))\n    input_data = np.expand_dims(input_data, axis=0)\n\n    # Quantization Handling\n    floating_model = (input_details[0]['dtype'] == np.float32)\n    if floating_model:\n        input_data = (np.float32(input_data) - 127.5) / 127.5\n\n    # Phase 3: Inference\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n    interpreter.invoke()\n\n    # Phase 4: Output Interpretation & Handling Loop\n    boxes = interpreter.get_tensor(output_details[0]['index'])[0]\n    classes = interpreter.get_tensor(output_details[1]['index'])[0]\n    scores = interpreter.get_tensor(output_details[2]['index'])[0]\n    num_detections = int(interpreter.get_tensor(output_details[3]['index']))\n\n    # Interpret Results\n    for i in range(num_detections):\n        if scores[i] > 0.5:\n            ymin, xmin, ymax, xmax = boxes[i]\n            (left, right, top, bottom) = (xmin * width, xmax * width,\n                                          ymin * height, ymax * height)\n            cv2.rectangle(frame, (int(left), int(top)), (int(right), int(bottom)), (0, 255, 0), 2)\n            label = f'{labels[int(classes[i])]}: {scores[i]:.2f}'\n            cv2.putText(frame, label, (int(left), int(top) - 10),\n                        cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n\n    # Handle Output\n    out.write(frame)\n\n# Phase 5: Cleanup\ncap.release()\nout.release()\ncv2.destroyAllWindows()"
      },
      "session_id": "qwen2.5-coder:32b_1974_tpusg_batch",
      "metadata": {
        "num_run": 24
      },
      "tags": [
        "benchmark",
        "qwen2.5-coder:32b",
        "tpu_sketch_generator"
      ],
      "latency": 174.193,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-10-18-06-938485_chatcmpl-8ca10622-ff84-4ee6-8564-f1727ffb26ce",
          "traceId": "65092f21",
          "type": "GENERATION",
          "name": "6509_tpusg_gen_attempt#1",
          "startTime": "2025-07-30T07:18:06.938000+00:00",
          "endTime": "2025-07-30T07:18:41.748000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 34810.0,
          "environment": "default",
          "promptTokens": 1833,
          "completionTokens": 822,
          "totalTokens": 2655,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-10-18-50-396655_chatcmpl-a9b2a6a3-6f49-4bae-9405-9211bd9ec0fd",
          "traceId": "65092f21",
          "type": "GENERATION",
          "name": "6509_tpusg_gen_attempt#2",
          "startTime": "2025-07-30T07:18:50.396000+00:00",
          "endTime": "2025-07-30T07:19:37.904000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 47508.0,
          "environment": "default",
          "promptTokens": 2048,
          "completionTokens": 1157,
          "totalTokens": 3205,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-10-19-37-908988_chatcmpl-4d7554de-0eea-4100-9942-c16c7ca1af7d",
          "traceId": "65092f21",
          "type": "GENERATION",
          "name": "6509_tpusg_gen_attempt#3",
          "startTime": "2025-07-30T07:19:37.908000+00:00",
          "endTime": "2025-07-30T07:20:14.582000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 36674.0,
          "environment": "default",
          "promptTokens": 1990,
          "completionTokens": 868,
          "totalTokens": 2858,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-10-20-22-620315_chatcmpl-20ebd6ce-037a-4a7e-b74a-2398680d0cad",
          "traceId": "65092f21",
          "type": "GENERATION",
          "name": "6509_tpusg_gen_attempt#4",
          "startTime": "2025-07-30T07:20:22.620000+00:00",
          "endTime": "2025-07-30T07:21:01.131000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 38511.0,
          "environment": "default",
          "promptTokens": 2048,
          "completionTokens": 927,
          "totalTokens": 2975,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        }
      ],
      "createdAt": "2025-07-30T07:18:07.499Z",
      "updatedAt": "2025-07-30T07:21:59.215Z",
      "environment": "default"
    },
    {
      "id": "1e3c0f22",
      "timestamp": "2025-07-30T07:13:40.336000+00:00",
      "name": "1e3c_tpu_sketch_generator",
      "input": null,
      "output": {
        "status": "failed",
        "last_code": "import numpy as np\nfrom tflite_runtime.interpreter import Interpreter, load_delegate\nimport cv2\n\n# Phase 1: Setup\nmodel_path  = \"/home/mendel/tinyml_autopilot/models/edgetpu_detect.tflite\"\nlabel_path  = \"/home/mendel/tinyml_autopilot/models/labelmap.txt\"\ninput_path  = \"/home/mendel/tinyml_autopilot/data//sheeps.mp4\"\noutput_path  = \"/home/mendel/tinyml_autopilot/results/sheeps_detections.mp4\"\nconfidence_threshold  = 0.5\n\n# Load labels\nwith open(label_path, 'r') as f:\n    labels = [line.strip() for line in f.readlines()]\n\n# Load Interpreter with EdgeTPU\ntry:\n    interpreter = Interpreter(model_path=model_path,\n                              experimental_delegates=[load_delegate('libedgetpu.so.1.0')])\nexcept Exception as e:\n    print(f\"Failed to load libedgetpu.so.1.0: {e}\")\n    try:\n        interpreter = Interpreter(model_path=model_path,\n                                  experimental_delegates=[load_delegate('/usr/lib/aarch64-linux-gnu/libedgetpu.so.1.0')])\n    except Exception as e:\n        print(f\"Failed to load /usr/lib/aarch64-linux-gnu/libedgetpu.so.1.0: {e}\")\n        raise\n\ninterpreter.allocate_tensors()\n\n# Get Model Details\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\n\nfloating_model = (input_details[0]['dtype'] == np.float32)\n\n# Phase 2: Input Acquisition & Preprocessing Loop\ncap = cv2.VideoCapture(input_path)\nif not cap.isOpened():\n    raise IOError(\"Cannot open video file\")\n\nframe_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\nframe_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\nfps = cap.get(cv2.CAP_PROP_FPS)\n\nout = cv2.VideoWriter(output_path, cv2.VideoWriter_fourcc(*'mp4v'), fps, (frame_width, frame_height))\n\nwhile True:\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    # Preprocess Data\n    input_data = cv2.resize(frame, (input_details[0]['shape'][1], input_details[0]['shape'][2]))\n    input_data = np.expand_dims(input_data, axis=0)\n\n    if floating_model:\n        input_data = (np.float32(input_data) - 127.5) / 127.5\n\n    # Phase 3: Inference\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n    interpreter.invoke()\n\n    # Phase 4: Output Interpretation & Handling Loop\n    output_data = interpreter.get_tensor(output_details[0]['index'])\n    num_detections = int(interpreter.get_tensor(output_details[1]['index']))  # Correctly access the number of detections\n\n    print(f\"Output Data Shape: {output_data.shape}\")\n    print(f\"Num Detections Tensor Shape: {interpreter.get_tensor(output_details[1]['index']).shape}\")\n\n    for i in range(num_detections):\n        confidence = float(output_data[i][2])  # Assuming confidence is at index 2\n        if confidence > confidence_threshold:\n            ymin, xmin, ymax, xmax = output_data[i][:4]\n            (left, right, top, bottom) = (xmin * frame_width, xmax * frame_width,\n                                          ymin * frame_height, ymax * frame_height)\n\n            cv2.rectangle(frame, (int(left), int(top)), (int(right), int(bottom)), (0, 255, 0), 2)\n            label = f\"{labels[int(output_data[i][1])]}: {confidence:.2f}\"  # Assuming class ID is at index 1\n            cv2.putText(frame, label, (int(left), int(top) - 10),\n                        cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n\n    # Handle Output\n    out.write(frame)\n\n# Phase 5: Cleanup\ncap.release()\nout.release()\ncv2.destroyAllWindows()",
        "last_error": "Traceback (most recent call last):\n  File \"script_e8eaa798_1753859873.py\", line 66, in <module>\n    num_detections = int(interpreter.get_tensor(output_details[1]['index']))  # Correctly access the number of detections\nTypeError: only size-1 arrays can be converted to Python scalars"
      },
      "session_id": "qwen2.5-coder:32b_1974_tpusg_batch",
      "metadata": {
        "num_run": 23
      },
      "tags": [
        "benchmark",
        "qwen2.5-coder:32b",
        "tpu_sketch_generator"
      ],
      "latency": 261.971,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-10-13-40-337999_chatcmpl-7e412084-884e-49e4-aaba-52637300a174",
          "traceId": "1e3c0f22",
          "type": "GENERATION",
          "name": "1e3c_tpusg_gen_attempt#1",
          "startTime": "2025-07-30T07:13:40.337000+00:00",
          "endTime": "2025-07-30T07:14:14.813000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 34476.0,
          "environment": "default",
          "promptTokens": 1833,
          "completionTokens": 822,
          "totalTokens": 2655,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-10-14-23-330700_chatcmpl-19c61046-0934-45a5-9839-b3b8efca8f12",
          "traceId": "1e3c0f22",
          "type": "GENERATION",
          "name": "1e3c_tpusg_gen_attempt#2",
          "startTime": "2025-07-30T07:14:23.330000+00:00",
          "endTime": "2025-07-30T07:15:11.037000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 47707.0,
          "environment": "default",
          "promptTokens": 2048,
          "completionTokens": 1165,
          "totalTokens": 3213,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-10-15-19-572734_chatcmpl-9c8852f0-0fab-4403-a4a1-274551318f8c",
          "traceId": "1e3c0f22",
          "type": "GENERATION",
          "name": "1e3c_tpusg_gen_attempt#3",
          "startTime": "2025-07-30T07:15:19.572000+00:00",
          "endTime": "2025-07-30T07:16:06.183000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 46611.0,
          "environment": "default",
          "promptTokens": 2048,
          "completionTokens": 1140,
          "totalTokens": 3188,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-10-16-14-721801_chatcmpl-c4853523-bfc9-4bd0-b529-9c51e725cd11",
          "traceId": "1e3c0f22",
          "type": "GENERATION",
          "name": "1e3c_tpusg_gen_attempt#4",
          "startTime": "2025-07-30T07:16:14.721000+00:00",
          "endTime": "2025-07-30T07:17:01.529000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 46808.0,
          "environment": "default",
          "promptTokens": 2048,
          "completionTokens": 1145,
          "totalTokens": 3193,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-10-17-10-128613_chatcmpl-fc17819c-64d5-4e20-9159-71f40e73ea6c",
          "traceId": "1e3c0f22",
          "type": "GENERATION",
          "name": "1e3c_tpusg_gen_attempt#5",
          "startTime": "2025-07-30T07:17:10.128000+00:00",
          "endTime": "2025-07-30T07:17:53.845000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 43717.0,
          "environment": "default",
          "promptTokens": 2048,
          "completionTokens": 1042,
          "totalTokens": 3090,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "b9e0d378-dd54-41fa-a007-bddcb77155d4",
          "traceId": "1e3c0f22",
          "type": "SPAN",
          "name": "error_1e_tpusg_failure_signal_tpu_sketch_generator",
          "startTime": "2025-07-30T07:18:02.308000+00:00",
          "level": "ERROR",
          "statusMessage": "Failed. Last error: Traceback (most recent call last):\n  File \"script_e8eaa798_1753859873.py\", line 66, in <module>\n    num_detections = int(interpreter.get_tensor(output_details[1]['index']))  # Correctly access the number of detections\nTypeError: only size-1 arrays can be converted to Python scalars",
          "calculatedTotalCost": 0.0,
          "environment": "default",
          "promptTokens": 0,
          "completionTokens": 0,
          "totalTokens": 0,
          "costDetails": {},
          "endTime": null,
          "model": null,
          "modelParameters": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null,
          "latency": null
        }
      ],
      "createdAt": "2025-07-30T07:13:40.856Z",
      "updatedAt": "2025-07-30T07:18:07.608Z",
      "environment": "default"
    },
    {
      "id": "d8268468",
      "timestamp": "2025-07-30T07:09:31.763000+00:00",
      "name": "d826_tpu_sketch_generator",
      "input": null,
      "output": {
        "status": "failed",
        "last_code": "import numpy as np\nfrom tflite_runtime.interpreter import Interpreter, load_delegate\nimport cv2\n\n# Phase 1: Setup\nmodel_path  = \"/home/mendel/tinyml_autopilot/models/edgetpu_detect.tflite\"\nlabel_path  = \"/home/mendel/tinyml_autopilot/models/labelmap.txt\"\ninput_path  = \"/home/mendel/tinyml_autopilot/data//sheeps.mp4\"\noutput_path  = \"/home/mendel/tinyml_autopilot/results/sheeps_detections.mp4\"\nconfidence_threshold  = 0.5\n\n# Load labels\nwith open(label_path, 'r') as f:\n    labels = [line.strip() for line in f.readlines()]\n\n# Load Interpreter with EdgeTPU\ntry:\n    interpreter = Interpreter(model_path=model_path,\n                              experimental_delegates=[load_delegate('libedgetpu.so.1.0')])\nexcept Exception as e:\n    print(f\"Failed to load libedgetpu.so.1.0: {e}\")\n    try:\n        interpreter = Interpreter(model_path=model_path,\n                                  experimental_delegates=[load_delegate('/usr/lib/aarch64-linux-gnu/libedgetpu.so.1.0')])\n    except Exception as e:\n        print(f\"Failed to load /usr/lib/aarch64-linux-gnu/libedgetpu.so.1.0: {e}\")\n        raise\n\ninterpreter.allocate_tensors()\n\n# Get Model Details\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\n\nfloating_model = (input_details[0]['dtype'] == np.float32)\n\n# Phase 2: Input Acquisition & Preprocessing Loop\ncap = cv2.VideoCapture(input_path)\nif not cap.isOpened():\n    raise IOError(\"Cannot open video file\")\n\nframe_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\nframe_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\nfps = cap.get(cv2.CAP_PROP_FPS)\n\nout = cv2.VideoWriter(output_path, cv2.VideoWriter_fourcc(*'mp4v'), fps, (frame_width, frame_height))\n\nwhile True:\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    # Preprocess Data\n    input_data = cv2.resize(frame, (input_details[0]['shape'][1], input_details[0]['shape'][2]))\n    input_data = np.expand_dims(input_data, axis=0)\n\n    if floating_model:\n        input_data = (np.float32(input_data) - 127.5) / 127.5\n\n    # Phase 3: Inference\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n    interpreter.invoke()\n\n    # Phase 4: Output Interpretation & Handling Loop\n    output_data = interpreter.get_tensor(output_details[0]['index'])\n    num_detections = int(interpreter.get_tensor(output_details[2]['index'])[0])  # Extract scalar value from array\n\n    for i in range(num_detections):\n        confidence = float(output_data[0][i][15])\n        if confidence > confidence_threshold:\n            ymin, xmin, ymax, xmax = output_data[0][i][:4]\n            (left, right, top, bottom) = (xmin * frame_width, xmax * frame_width,\n                                          ymin * frame_height, ymax * frame_height)\n\n            cv2.rectangle(frame, (int(left), int(top)), (int(right), int(bottom)), (0, 255, 0), 2)\n            label = f\"{labels[int(output_data[0][i][14])]}: {confidence:.2f}\"\n            cv2.putText(frame, label, (int(left), int(top) - 10),\n                        cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n\n    # Handle Output\n    out.write(frame)\n\n# Phase 5: Cleanup\ncap.release()\nout.release()\ncv2.destroyAllWindows()",
        "last_error": "Traceback (most recent call last):\n  File \"script_7ba23477_1753859606.py\", line 66, in <module>\n    num_detections = int(interpreter.get_tensor(output_details[2]['index'])[0])  # Extract scalar value from array\nTypeError: only size-1 arrays can be converted to Python scalars"
      },
      "session_id": "qwen2.5-coder:32b_1974_tpusg_batch",
      "metadata": {
        "num_run": 22
      },
      "tags": [
        "benchmark",
        "qwen2.5-coder:32b",
        "tpu_sketch_generator"
      ],
      "latency": 242.924,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-10-09-31-764851_chatcmpl-f1470d9d-3c25-40a6-8905-be32005f6045",
          "traceId": "d8268468",
          "type": "GENERATION",
          "name": "d826_tpusg_gen_attempt#1",
          "startTime": "2025-07-30T07:09:31.764000+00:00",
          "endTime": "2025-07-30T07:10:06.196000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 34432.0,
          "environment": "default",
          "promptTokens": 1833,
          "completionTokens": 822,
          "totalTokens": 2655,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-10-10-14-739015_chatcmpl-e317622d-93d9-47a7-8ee9-930b9e43dccd",
          "traceId": "d8268468",
          "type": "GENERATION",
          "name": "d826_tpusg_gen_attempt#2",
          "startTime": "2025-07-30T07:10:14.739000+00:00",
          "endTime": "2025-07-30T07:10:58.093000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 43354.0,
          "environment": "default",
          "promptTokens": 2048,
          "completionTokens": 1054,
          "totalTokens": 3102,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-10-11-06-739447_chatcmpl-d173a681-80d1-4bb3-8ff2-bb87a8a9b286",
          "traceId": "d8268468",
          "type": "GENERATION",
          "name": "d826_tpusg_gen_attempt#3",
          "startTime": "2025-07-30T07:11:06.739000+00:00",
          "endTime": "2025-07-30T07:11:47.553000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 40814.0,
          "environment": "default",
          "promptTokens": 2048,
          "completionTokens": 985,
          "totalTokens": 3033,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-10-11-56-038082_chatcmpl-89e32da1-8df0-4696-8c21-077a68a8b091",
          "traceId": "d8268468",
          "type": "GENERATION",
          "name": "d826_tpusg_gen_attempt#4",
          "startTime": "2025-07-30T07:11:56.038000+00:00",
          "endTime": "2025-07-30T07:12:36.740000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 40702.0,
          "environment": "default",
          "promptTokens": 2048,
          "completionTokens": 984,
          "totalTokens": 3032,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-10-12-45-316330_chatcmpl-c4556752-fd6f-409c-beaa-33f1f54b5b59",
          "traceId": "d8268468",
          "type": "GENERATION",
          "name": "d826_tpusg_gen_attempt#5",
          "startTime": "2025-07-30T07:12:45.316000+00:00",
          "endTime": "2025-07-30T07:13:26.005000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 40689.0,
          "environment": "default",
          "promptTokens": 2048,
          "completionTokens": 984,
          "totalTokens": 3032,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "a456c513-d708-4914-b37e-8892de0dd51e",
          "traceId": "d8268468",
          "type": "SPAN",
          "name": "error_d8_tpusg_failure_signal_tpu_sketch_generator",
          "startTime": "2025-07-30T07:13:34.688000+00:00",
          "level": "ERROR",
          "statusMessage": "Failed. Last error: Traceback (most recent call last):\n  File \"script_7ba23477_1753859606.py\", line 66, in <module>\n    num_detections = int(interpreter.get_tensor(output_details[2]['index'])[0])  # Extract scalar value from array\nTypeError: only size-1 arrays can be converted to Python scalars",
          "calculatedTotalCost": 0.0,
          "environment": "default",
          "promptTokens": 0,
          "completionTokens": 0,
          "totalTokens": 0,
          "costDetails": {},
          "endTime": null,
          "model": null,
          "modelParameters": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null,
          "latency": null
        }
      ],
      "createdAt": "2025-07-30T07:09:32.283Z",
      "updatedAt": "2025-07-30T07:13:39.984Z",
      "environment": "default"
    },
    {
      "id": "0ba74e4d",
      "timestamp": "2025-07-30T07:05:30.157000+00:00",
      "name": "0ba7_tpu_sketch_generator",
      "input": null,
      "output": {
        "status": "success",
        "sketch": "import numpy as np\nfrom tflite_runtime.interpreter import Interpreter, load_delegate\nimport cv2\n\n# Phase 1: Setup\nmodel_path  = \"/home/mendel/tinyml_autopilot/models/edgetpu_detect.tflite\"\nlabel_path  = \"/home/mendel/tinyml_autopilot/models/labelmap.txt\"\ninput_path  = \"/home/mendel/tinyml_autopilot/data//sheeps.mp4\"\noutput_path  = \"/home/mendel/tinyml_autopilot/results/sheeps_detections.mp4\"\nconfidence_threshold  = 0.5\n\n# Load labels\nwith open(label_path, 'r') as f:\n    labels = [line.strip() for line in f.readlines()]\n\n# Load Interpreter with EdgeTPU\ntry:\n    interpreter = Interpreter(model_path=model_path,\n                              experimental_delegates=[load_delegate('libedgetpu.so.1.0')])\nexcept Exception as e:\n    print(f\"Failed to load libedgetpu.so.1.0: {e}\")\n    try:\n        interpreter = Interpreter(model_path=model_path,\n                                  experimental_delegates=[load_delegate('/usr/lib/aarch64-linux-gnu/libedgetpu.so.1.0')])\n    except Exception as e:\n        print(f\"Failed to load /usr/lib/aarch64-linux-gnu/libedgetpu.so.1.0: {e}\")\n        raise\n\ninterpreter.allocate_tensors()\n\n# Get Model Details\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\n\nfloating_model = (input_details[0]['dtype'] == np.float32)\n\n# Phase 2: Input Acquisition & Preprocessing Loop\ncap = cv2.VideoCapture(input_path)\nif not cap.isOpened():\n    raise IOError(\"Cannot open video file\")\n\nframe_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\nframe_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\nfps = cap.get(cv2.CAP_PROP_FPS)\n\nout = cv2.VideoWriter(output_path, cv2.VideoWriter_fourcc(*'mp4v'), fps, (frame_width, frame_height))\n\nwhile True:\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    # Preprocess Data\n    input_data = cv2.resize(frame, (input_details[0]['shape'][1], input_details[0]['shape'][2]))\n    input_data = np.expand_dims(input_data, axis=0)\n\n    if floating_model:\n        input_data = (np.float32(input_data) - 127.5) / 127.5\n\n    # Phase 3: Inference\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n    interpreter.invoke()\n\n    # Phase 4: Output Interpretation & Handling Loop\n    output_data = interpreter.get_tensor(output_details[0]['index'])\n    num_detections_tensor = interpreter.get_tensor(output_details[2]['index'])\n\n    # Ensure the tensor is a single scalar value\n    if num_detections_tensor.size == 1:\n        num_detections = int(np.squeeze(num_detections_tensor))\n    else:\n        print(\"Unexpected size of num_detections tensor:\", num_detections_tensor.shape)\n        continue\n\n    for i in range(num_detections):\n        confidence = float(output_data[0][i][15])\n        if confidence > confidence_threshold:\n            ymin, xmin, ymax, xmax = output_data[0][i][:4]\n            (left, right, top, bottom) = (xmin * frame_width, xmax * frame_width,\n                                          ymin * frame_height, ymax * frame_height)\n\n            cv2.rectangle(frame, (int(left), int(top)), (int(right), int(bottom)), (0, 255, 0), 2)\n            label = f\"{labels[int(output_data[0][i][14])]}: {confidence:.2f}\"\n            cv2.putText(frame, label, (int(left), int(top) - 10),\n                        cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n\n    # Handle Output\n    out.write(frame)\n\n# Phase 5: Cleanup\ncap.release()\nout.release()\ncv2.destroyAllWindows()"
      },
      "session_id": "qwen2.5-coder:32b_1974_tpusg_batch",
      "metadata": {
        "num_run": 21
      },
      "tags": [
        "benchmark",
        "qwen2.5-coder:32b",
        "tpu_sketch_generator"
      ],
      "latency": 188.608,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-10-05-30-159395_chatcmpl-312564a5-f63d-44df-9cdc-93de954cddca",
          "traceId": "0ba74e4d",
          "type": "GENERATION",
          "name": "0ba7_tpusg_gen_attempt#1",
          "startTime": "2025-07-30T07:05:30.159000+00:00",
          "endTime": "2025-07-30T07:06:04.635000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 34476.0,
          "environment": "default",
          "promptTokens": 1833,
          "completionTokens": 822,
          "totalTokens": 2655,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-10-06-13-387932_chatcmpl-96b61f96-d0c4-46de-9682-01be35786511",
          "traceId": "0ba74e4d",
          "type": "GENERATION",
          "name": "0ba7_tpusg_gen_attempt#2",
          "startTime": "2025-07-30T07:06:13.387000+00:00",
          "endTime": "2025-07-30T07:06:56.917000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 43530.0,
          "environment": "default",
          "promptTokens": 2048,
          "completionTokens": 1056,
          "totalTokens": 3104,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-10-07-05-682752_chatcmpl-01560f2c-1d4f-4e13-8db7-9d01f0182f7a",
          "traceId": "0ba74e4d",
          "type": "GENERATION",
          "name": "0ba7_tpusg_gen_attempt#3",
          "startTime": "2025-07-30T07:07:05.682000+00:00",
          "endTime": "2025-07-30T07:07:45.849000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 40167.0,
          "environment": "default",
          "promptTokens": 2048,
          "completionTokens": 970,
          "totalTokens": 3018,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-10-07-54-444879_chatcmpl-299f8905-fc6d-4cc3-814c-401bf826fe6c",
          "traceId": "0ba74e4d",
          "type": "GENERATION",
          "name": "0ba7_tpusg_gen_attempt#4",
          "startTime": "2025-07-30T07:07:54.444000+00:00",
          "endTime": "2025-07-30T07:08:38.767000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 44323.0,
          "environment": "default",
          "promptTokens": 2048,
          "completionTokens": 1077,
          "totalTokens": 3125,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        }
      ],
      "createdAt": "2025-07-30T07:05:30.678Z",
      "updatedAt": "2025-07-30T07:09:31.909Z",
      "environment": "default"
    },
    {
      "id": "508535c3",
      "timestamp": "2025-07-30T07:01:34.584000+00:00",
      "name": "5085_tpu_sketch_generator",
      "input": null,
      "output": {
        "status": "success",
        "sketch": "import numpy as np\nfrom PIL import Image\nimport cv2\n\n# Phase 1: Setup and Initialization\ntry:\n    from tflite_runtime.interpreter import Interpreter, load_delegate\nexcept ImportError:\n    from tensorflow.lite import Interpreter\n    from tensorflow.lite.experimental import load_delegate\n\n# Paths/Parameters\nmodel_path  = \"/home/mendel/tinyml_autopilot/models/edgetpu_detect.tflite\"\ninput_path  = \"/home/mendel/tinyml_autopilot/data//sheeps.mp4\"\nlabel_path  = \"/home/mendel/tinyml_autopilot/models/labelmap.txt\"\noutput_path  = \"/home/mendel/tinyml_autopilot/results/sheeps_detections.mp4\"\n\n# Load Labels (Conditional)\nwith open(label_path, 'r') as f:\n    labels = [line.strip() for line in f.readlines()]\n\n# Load Interpreter with EdgeTPU\ntry:\n    interpreter = Interpreter(model_path=model_path, experimental_delegates=[load_delegate('libedgetpu.so.1.0')])\nexcept Exception as e:\n    interpreter = Interpreter(model_path=model_path, experimental_delegates=[load_delegate('/usr/lib/aarch64-linux-gnu/libedgetpu.so.1.0')])\n\ninterpreter.allocate_tensors()\n\n# Get Model Details\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\n\n# Phase 2: Input Acquisition & Preprocessing Loop\ncap = cv2.VideoCapture(input_path)\nfourcc = cv2.VideoWriter_fourcc(*'mp4v')\nout = cv2.VideoWriter(output_path, fourcc, 30.0, (int(cap.get(3)), int(cap.get(4))))\n\nwhile cap.isOpened():\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    # Preprocess Data\n    input_shape = input_details[0]['shape']\n    image_resized = cv2.resize(frame, (input_shape[1], input_shape[2]))\n    input_data = np.expand_dims(image_resized, axis=0)\n\n    # Quantization Handling\n    floating_model = (input_details[0]['dtype'] == np.float32)\n    if floating_model:\n        input_data = (np.float32(input_data) - 127.5) / 127.5\n\n    # Phase 3: Inference\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n    interpreter.invoke()\n\n    # Phase 4: Output Interpretation & Handling Loop\n    boxes = interpreter.get_tensor(output_details[0]['index'])[0]\n    classes = interpreter.get_tensor(output_details[1]['index'])[0]\n    scores = interpreter.get_tensor(output_details[2]['index'])[0]\n    num_detections = int(interpreter.get_tensor(output_details[3]['index']))\n\n    # Interpret Results\n    for i in range(num_detections):\n        if scores[i] > 0.5:\n            ymin, xmin, ymax, xmax = boxes[i]\n            (left, right, top, bottom) = (xmin * cap.get(3), xmax * cap.get(3),\n                                          ymin * cap.get(4), ymax * cap.get(4))\n            cv2.rectangle(frame, (int(left), int(top)), (int(right), int(bottom)), (0, 255, 0), 2)\n            label = f'{labels[int(classes[i])]}: {scores[i]:.2f}'\n            cv2.putText(frame, label, (int(left), int(top) - 10),\n                        cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n\n    # Handle Output\n    out.write(frame)\n\n# Phase 5: Cleanup\ncap.release()\nout.release()\ncv2.destroyAllWindows()"
      },
      "session_id": "qwen2.5-coder:32b_1974_tpusg_batch",
      "metadata": {
        "num_run": 20
      },
      "tags": [
        "benchmark",
        "qwen2.5-coder:32b",
        "tpu_sketch_generator"
      ],
      "latency": 176.442,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-10-01-34-585911_chatcmpl-93871f6f-4bea-44eb-83b5-beb708af79a9",
          "traceId": "508535c3",
          "type": "GENERATION",
          "name": "5085_tpusg_gen_attempt#1",
          "startTime": "2025-07-30T07:01:34.585000+00:00",
          "endTime": "2025-07-30T07:02:09.145000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 34560.0,
          "environment": "default",
          "promptTokens": 1833,
          "completionTokens": 822,
          "totalTokens": 2655,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-10-02-17-614398_chatcmpl-6e75b522-0892-47f5-99ed-9e0cadc74ebc",
          "traceId": "508535c3",
          "type": "GENERATION",
          "name": "5085_tpusg_gen_attempt#2",
          "startTime": "2025-07-30T07:02:17.614000+00:00",
          "endTime": "2025-07-30T07:03:01.249000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 43635.0,
          "environment": "default",
          "promptTokens": 2048,
          "completionTokens": 1051,
          "totalTokens": 3099,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-10-03-09-853203_chatcmpl-49665b8f-4421-45a6-9517-5ec621d20b6b",
          "traceId": "508535c3",
          "type": "GENERATION",
          "name": "5085_tpusg_gen_attempt#3",
          "startTime": "2025-07-30T07:03:09.853000+00:00",
          "endTime": "2025-07-30T07:03:55.694000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 45841.0,
          "environment": "default",
          "promptTokens": 2048,
          "completionTokens": 1117,
          "totalTokens": 3165,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-10-03-55-703132_chatcmpl-21880f6c-2c59-4181-8851-f88e92b07af6",
          "traceId": "508535c3",
          "type": "GENERATION",
          "name": "5085_tpusg_gen_attempt#4",
          "startTime": "2025-07-30T07:03:55.703000+00:00",
          "endTime": "2025-07-30T07:04:31.027000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 35324.0,
          "environment": "default",
          "promptTokens": 1999,
          "completionTokens": 843,
          "totalTokens": 2842,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        }
      ],
      "createdAt": "2025-07-30T07:01:35.104Z",
      "updatedAt": "2025-07-30T07:05:29.371Z",
      "environment": "default"
    },
    {
      "id": "c6f8a481",
      "timestamp": "2025-07-30T06:56:54.927000+00:00",
      "name": "c6f8_tpu_sketch_generator",
      "input": null,
      "output": {
        "status": "success",
        "sketch": "import numpy as np\nfrom PIL import Image\nimport cv2\n\n# Phase 1: Setup\ntry:\n    from tflite_runtime.interpreter import Interpreter, load_delegate\nexcept ImportError:\n    from tensorflow.lite import Interpreter\n    from tensorflow.lite.experimental import load_delegate\n\n# Paths/Parameters\nmodel_path  = \"/home/mendel/tinyml_autopilot/models/edgetpu_detect.tflite\"\ninput_path  = \"/home/mendel/tinyml_autopilot/data//sheeps.mp4\"\nlabel_path  = \"/home/mendel/tinyml_autopilot/models/labelmap.txt\"\noutput_path  = \"/home/mendel/tinyml_autopilot/results/sheeps_detections.mp4\"\n\n# Load Labels (Conditional)\nwith open(label_path, 'r') as f:\n    labels = [line.strip() for line in f.readlines()]\n\n# Load Interpreter with EdgeTPU\ntry:\n    interpreter = Interpreter(model_path=model_path, experimental_delegates=[load_delegate('libedgetpu.so.1.0')])\nexcept Exception as e:\n    interpreter = Interpreter(model_path=model_path, experimental_delegates=[load_delegate('/usr/lib/aarch64-linux-gnu/libedgetpu.so.1.0')])\n\ninterpreter.allocate_tensors()\n\n# Get Model Details\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\n\n# Phase 2: Input Acquisition & Preprocessing Loop\ncap = cv2.VideoCapture(input_path)\nwidth = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\nheight = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\nfps = cap.get(cv2.CAP_PROP_FPS)\n\nfourcc = cv2.VideoWriter_fourcc(*'mp4v')\nout = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n\nwhile cap.isOpened():\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    # Preprocess Data\n    input_data = cv2.resize(frame, (input_details[0]['shape'][1], input_details[0]['shape'][2]))\n    input_data = np.expand_dims(input_data, axis=0)\n\n    # Quantization Handling\n    floating_model = (input_details[0]['dtype'] == np.float32)\n    if floating_model:\n        input_data = (np.float32(input_data) - 127.5) / 127.5\n\n    # Phase 3: Inference\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n    interpreter.invoke()\n\n    # Phase 4: Output Interpretation & Handling Loop\n    boxes = interpreter.get_tensor(output_details[0]['index'])[0]\n    classes = interpreter.get_tensor(output_details[1]['index'])[0]\n    scores = interpreter.get_tensor(output_details[2]['index'])[0]\n    num_detections = int(interpreter.get_tensor(output_details[3]['index']))\n\n    # Interpret Results\n    for i in range(num_detections):\n        if scores[i] > 0.5:\n            ymin, xmin, ymax, xmax = boxes[i]\n            (left, right, top, bottom) = (xmin * width, xmax * width,\n                                          ymin * height, ymax * height)\n            cv2.rectangle(frame, (int(left), int(top)), (int(right), int(bottom)), (0, 255, 0), 2)\n            label = f'{labels[int(classes[i])]}: {scores[i]:.2f}'\n            cv2.putText(frame, label, (int(left), int(top) - 10),\n                        cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n\n    # Handle Output\n    out.write(frame)\n\n# Phase 5: Cleanup\ncap.release()\nout.release()\ncv2.destroyAllWindows()"
      },
      "session_id": "qwen2.5-coder:32b_1974_tpusg_batch",
      "metadata": {
        "num_run": 19
      },
      "tags": [
        "benchmark",
        "qwen2.5-coder:32b",
        "tpu_sketch_generator"
      ],
      "latency": 220.909,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-09-56-54-929262_chatcmpl-3591dfd5-aaa3-494c-9e02-5cd801158f44",
          "traceId": "c6f8a481",
          "type": "GENERATION",
          "name": "c6f8_tpusg_gen_attempt#1",
          "startTime": "2025-07-30T06:56:54.929000+00:00",
          "endTime": "2025-07-30T06:57:28.956000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 34027.0,
          "environment": "default",
          "promptTokens": 1833,
          "completionTokens": 822,
          "totalTokens": 2655,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-09-57-37-687770_chatcmpl-362bc0ec-b353-4add-9f66-2db8537db489",
          "traceId": "c6f8a481",
          "type": "GENERATION",
          "name": "c6f8_tpusg_gen_attempt#2",
          "startTime": "2025-07-30T06:57:37.687000+00:00",
          "endTime": "2025-07-30T06:59:11.567000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 93880.0,
          "environment": "default",
          "promptTokens": 2048,
          "completionTokens": 2394,
          "totalTokens": 4442,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-09-59-11-574967_chatcmpl-50032d03-ddd9-415f-958d-f51b1b6f3cad",
          "traceId": "c6f8a481",
          "type": "GENERATION",
          "name": "c6f8_tpusg_gen_attempt#3",
          "startTime": "2025-07-30T06:59:11.574000+00:00",
          "endTime": "2025-07-30T06:59:47.958000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 36384.0,
          "environment": "default",
          "promptTokens": 1990,
          "completionTokens": 868,
          "totalTokens": 2858,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-09-59-56-235021_chatcmpl-07fb8d4c-bd5d-4314-aaa3-9c2f34a86247",
          "traceId": "c6f8a481",
          "type": "GENERATION",
          "name": "c6f8_tpusg_gen_attempt#4",
          "startTime": "2025-07-30T06:59:56.235000+00:00",
          "endTime": "2025-07-30T07:00:35.838000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 39603.0,
          "environment": "default",
          "promptTokens": 2048,
          "completionTokens": 958,
          "totalTokens": 3006,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        }
      ],
      "createdAt": "2025-07-30T06:56:55.447Z",
      "updatedAt": "2025-07-30T07:01:34.338Z",
      "environment": "default"
    },
    {
      "id": "fcff55f9",
      "timestamp": "2025-07-30T06:51:53.311000+00:00",
      "name": "fcff_tpu_sketch_generator",
      "input": null,
      "output": {
        "status": "success",
        "sketch": "import numpy as np\nfrom tflite_runtime.interpreter import Interpreter, load_delegate\nimport cv2\n\n# Phase 1: Setup\nmodel_path  = \"/home/mendel/tinyml_autopilot/models/edgetpu_detect.tflite\"\nlabel_path  = \"/home/mendel/tinyml_autopilot/models/labelmap.txt\"\ninput_path  = \"/home/mendel/tinyml_autopilot/data//sheeps.mp4\"\noutput_path  = \"/home/mendel/tinyml_autopilot/results/sheeps_detections.mp4\"\nconfidence_threshold  = 0.5\n\n# Load labels\nwith open(label_path, 'r') as f:\n    labels = [line.strip() for line in f.readlines()]\n\n# Load Interpreter with EdgeTPU\ntry:\n    interpreter = Interpreter(model_path=model_path,\n                              experimental_delegates=[load_delegate('libedgetpu.so.1.0')])\nexcept Exception as e:\n    print(f\"Failed to load libedgetpu.so.1.0: {e}\")\n    try:\n        interpreter = Interpreter(model_path=model_path,\n                                  experimental_delegates=[load_delegate('/usr/lib/aarch64-linux-gnu/libedgetpu.so.1.0')])\n    except Exception as e:\n        print(f\"Failed to load /usr/lib/aarch64-linux-gnu/libedgetpu.so.1.0: {e}\")\n        raise\n\ninterpreter.allocate_tensors()\n\n# Get Model Details\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\n\nfloating_model = (input_details[0]['dtype'] == np.float32)\n\n# Phase 2: Input Acquisition & Preprocessing Loop\ncap = cv2.VideoCapture(input_path)\nif not cap.isOpened():\n    raise IOError(\"Cannot open video file\")\n\nframe_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\nframe_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\nfps = cap.get(cv2.CAP_PROP_FPS)\n\nout = cv2.VideoWriter(output_path, cv2.VideoWriter_fourcc(*'mp4v'), fps, (frame_width, frame_height))\n\nwhile True:\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    # Preprocess Data\n    input_data = cv2.resize(frame, (input_details[0]['shape'][1], input_details[0]['shape'][2]))\n    input_data = np.expand_dims(input_data, axis=0)\n\n    if floating_model:\n        input_data = (np.float32(input_data) - 127.5) / 127.5\n\n    # Phase 3: Inference\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n    interpreter.invoke()\n\n    # Phase 4: Output Interpretation & Handling Loop\n    boxes = interpreter.get_tensor(output_details[0]['index'])[0]  # Shape (10, 4)\n    class_ids = interpreter.get_tensor(output_details[1]['index'])[0]  # Assuming this is the class indices\n    scores = interpreter.get_tensor(output_details[2]['index'])[0]  # Assuming this is the confidence scores\n\n    for i in range(len(scores)):\n        if scores[i] > confidence_threshold:\n            ymin, xmin, ymax, xmax = boxes[i]\n            (left, right, top, bottom) = (xmin * frame_width, xmax * frame_width,\n                                          ymin * frame_height, ymax * frame_height)\n\n            cv2.rectangle(frame, (int(left), int(top)), (int(right), int(bottom)), (0, 255, 0), 2)\n            label = f\"{labels[int(class_ids[i])]}: {scores[i]:.2f}\"\n            cv2.putText(frame, label, (int(left), int(top) - 10),\n                        cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n\n    # Handle Output\n    out.write(frame)\n\n# Phase 5: Cleanup\ncap.release()\nout.release()\ncv2.destroyAllWindows()"
      },
      "session_id": "qwen2.5-coder:32b_1974_tpusg_batch",
      "metadata": {
        "num_run": 18
      },
      "tags": [
        "benchmark",
        "qwen2.5-coder:32b",
        "tpu_sketch_generator"
      ],
      "latency": 243.959,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-09-51-53-313015_chatcmpl-e3c07af3-f658-4abc-a877-a4f5d2c2e247",
          "traceId": "fcff55f9",
          "type": "GENERATION",
          "name": "fcff_tpusg_gen_attempt#1",
          "startTime": "2025-07-30T06:51:53.313000+00:00",
          "endTime": "2025-07-30T06:52:27.406000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 34093.0,
          "environment": "default",
          "promptTokens": 1833,
          "completionTokens": 822,
          "totalTokens": 2655,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-09-52-36-144511_chatcmpl-5091de2b-1acd-41b8-8658-52b2beb1a387",
          "traceId": "fcff55f9",
          "type": "GENERATION",
          "name": "fcff_tpusg_gen_attempt#2",
          "startTime": "2025-07-30T06:52:36.144000+00:00",
          "endTime": "2025-07-30T06:53:19.144000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 43000.0,
          "environment": "default",
          "promptTokens": 2048,
          "completionTokens": 1055,
          "totalTokens": 3103,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-09-53-27-730541_chatcmpl-3ddd53ea-0ca3-4902-bdc3-d6a59a1578d7",
          "traceId": "fcff55f9",
          "type": "GENERATION",
          "name": "fcff_tpusg_gen_attempt#3",
          "startTime": "2025-07-30T06:53:27.730000+00:00",
          "endTime": "2025-07-30T06:54:13.633000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 45903.0,
          "environment": "default",
          "promptTokens": 2048,
          "completionTokens": 1133,
          "totalTokens": 3181,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-09-54-22-096645_chatcmpl-8d472687-21d9-4db6-a4cf-102b6690d66d",
          "traceId": "fcff55f9",
          "type": "GENERATION",
          "name": "fcff_tpusg_gen_attempt#4",
          "startTime": "2025-07-30T06:54:22.096000+00:00",
          "endTime": "2025-07-30T06:55:03.993000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 41897.0,
          "environment": "default",
          "promptTokens": 2048,
          "completionTokens": 1027,
          "totalTokens": 3075,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-09-55-12-573324_chatcmpl-68f4f034-1d15-4cbd-8c36-77fcbdda9a65",
          "traceId": "fcff55f9",
          "type": "GENERATION",
          "name": "fcff_tpusg_gen_attempt#5",
          "startTime": "2025-07-30T06:55:12.573000+00:00",
          "endTime": "2025-07-30T06:55:57.272000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 44699.0,
          "environment": "default",
          "promptTokens": 2048,
          "completionTokens": 1100,
          "totalTokens": 3148,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        }
      ],
      "createdAt": "2025-07-30T06:51:53.832Z",
      "updatedAt": "2025-07-30T06:56:55.375Z",
      "environment": "default"
    },
    {
      "id": "239c7a0b",
      "timestamp": "2025-07-30T06:47:43.725000+00:00",
      "name": "239c_tpu_sketch_generator",
      "input": null,
      "output": {
        "status": "failed",
        "last_code": "import numpy as np\nfrom tflite_runtime.interpreter import Interpreter, load_delegate\nimport cv2\n\n# Phase 1: Setup\nmodel_path  = \"/home/mendel/tinyml_autopilot/models/edgetpu_detect.tflite\"\nlabel_path  = \"/home/mendel/tinyml_autopilot/models/labelmap.txt\"\ninput_path  = \"/home/mendel/tinyml_autopilot/data//sheeps.mp4\"\noutput_path  = \"/home/mendel/tinyml_autopilot/results/sheeps_detections.mp4\"\nconfidence_threshold  = 0.5\n\n# Load labels\nwith open(label_path, 'r') as f:\n    labels = [line.strip() for line in f.readlines()]\n\n# Load Interpreter with EdgeTPU\ntry:\n    interpreter = Interpreter(model_path=model_path,\n                              experimental_delegates=[load_delegate('libedgetpu.so.1.0')])\nexcept Exception as e:\n    print(f\"Failed to load libedgetpu.so.1.0: {e}\")\n    try:\n        interpreter = Interpreter(model_path=model_path,\n                                  experimental_delegates=[load_delegate('/usr/lib/aarch64-linux-gnu/libedgetpu.so.1.0')])\n    except Exception as e:\n        print(f\"Failed to load /usr/lib/aarch64-linux-gnu/libedgetpu.so.1.0: {e}\")\n        raise\n\ninterpreter.allocate_tensors()\n\n# Get Model Details\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\n\nfloating_model = (input_details[0]['dtype'] == np.float32)\n\n# Phase 2: Input Acquisition & Preprocessing Loop\ncap = cv2.VideoCapture(input_path)\nif not cap.isOpened():\n    raise IOError(\"Cannot open video file\")\n\nframe_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\nframe_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\nfps = cap.get(cv2.CAP_PROP_FPS)\n\nout = cv2.VideoWriter(output_path, cv2.VideoWriter_fourcc(*'mp4v'), fps, (frame_width, frame_height))\n\nwhile True:\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    # Preprocess Data\n    input_data = cv2.resize(frame, (input_details[0]['shape'][1], input_details[0]['shape'][2]))\n    input_data = np.expand_dims(input_data, axis=0)\n\n    if floating_model:\n        input_data = (np.float32(input_data) - 127.5) / 127.5\n\n    # Phase 3: Inference\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n    interpreter.invoke()\n\n    # Phase 4: Output Interpretation & Handling Loop\n    output_data = interpreter.get_tensor(output_details[0]['index'])\n    num_detections = int(interpreter.get_tensor(output_details[2]['index'])[0])  # Correctly extract the scalar value\n\n    for i in range(num_detections):\n        confidence = float(output_data[0][i][15])\n        if confidence > confidence_threshold:\n            ymin, xmin, ymax, xmax = output_data[0][i][:4]\n            (left, right, top, bottom) = (xmin * frame_width, xmax * frame_width,\n                                          ymin * frame_height, ymax * frame_height)\n\n            cv2.rectangle(frame, (int(left), int(top)), (int(right), int(bottom)), (0, 255, 0), 2)\n            label = f\"{labels[int(output_data[0][i][14])]}: {confidence:.2f}\"\n            cv2.putText(frame, label, (int(left), int(top) - 10),\n                        cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n\n    # Handle Output\n    out.write(frame)\n\n# Phase 5: Cleanup\ncap.release()\nout.release()\ncv2.destroyAllWindows()",
        "last_error": "Traceback (most recent call last):\n  File \"script_4e1e0a90_1753858298.py\", line 66, in <module>\n    num_detections = int(interpreter.get_tensor(output_details[2]['index'])[0])  # Correctly extract the scalar value\nTypeError: only size-1 arrays can be converted to Python scalars"
      },
      "session_id": "qwen2.5-coder:32b_1974_tpusg_batch",
      "metadata": {
        "num_run": 17
      },
      "tags": [
        "benchmark",
        "qwen2.5-coder:32b",
        "tpu_sketch_generator"
      ],
      "latency": 243.5,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-09-47-43-726836_chatcmpl-d58a892a-dd85-4dc9-b3f6-0cee6d34974a",
          "traceId": "239c7a0b",
          "type": "GENERATION",
          "name": "239c_tpusg_gen_attempt#1",
          "startTime": "2025-07-30T06:47:43.726000+00:00",
          "endTime": "2025-07-30T06:48:18.093000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 34367.0,
          "environment": "default",
          "promptTokens": 1833,
          "completionTokens": 822,
          "totalTokens": 2655,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-09-48-26-817979_chatcmpl-9204691f-4d21-4313-b08d-6f38856d0dc0",
          "traceId": "239c7a0b",
          "type": "GENERATION",
          "name": "239c_tpusg_gen_attempt#2",
          "startTime": "2025-07-30T06:48:26.817000+00:00",
          "endTime": "2025-07-30T06:49:08.982000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 42165.0,
          "environment": "default",
          "promptTokens": 2048,
          "completionTokens": 1022,
          "totalTokens": 3070,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-09-49-17-622848_chatcmpl-0abcd5d6-0856-460b-b0a3-272e9fac3347",
          "traceId": "239c7a0b",
          "type": "GENERATION",
          "name": "239c_tpusg_gen_attempt#3",
          "startTime": "2025-07-30T06:49:17.622000+00:00",
          "endTime": "2025-07-30T06:50:01.248000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 43626.0,
          "environment": "default",
          "promptTokens": 2048,
          "completionTokens": 1068,
          "totalTokens": 3116,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-09-50-09-974779_chatcmpl-ce7293d1-29a8-4197-aba5-c7a0da22f2ba",
          "traceId": "239c7a0b",
          "type": "GENERATION",
          "name": "239c_tpusg_gen_attempt#4",
          "startTime": "2025-07-30T06:50:09.974000+00:00",
          "endTime": "2025-07-30T06:50:49.012000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 39038.0,
          "environment": "default",
          "promptTokens": 2048,
          "completionTokens": 952,
          "totalTokens": 3000,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-09-50-57-617057_chatcmpl-7b750ba3-de0c-4580-9854-993a4ac8c635",
          "traceId": "239c7a0b",
          "type": "GENERATION",
          "name": "239c_tpusg_gen_attempt#5",
          "startTime": "2025-07-30T06:50:57.617000+00:00",
          "endTime": "2025-07-30T06:51:38.768000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 41151.0,
          "environment": "default",
          "promptTokens": 2048,
          "completionTokens": 1004,
          "totalTokens": 3052,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "4f5aa186-4fe9-4774-b54d-9eb21227b8ae",
          "traceId": "239c7a0b",
          "type": "SPAN",
          "name": "error_23_tpusg_failure_signal_tpu_sketch_generator",
          "startTime": "2025-07-30T06:51:47.226000+00:00",
          "level": "ERROR",
          "statusMessage": "Failed. Last error: Traceback (most recent call last):\n  File \"script_4e1e0a90_1753858298.py\", line 66, in <module>\n    num_detections = int(interpreter.get_tensor(output_details[2]['index'])[0])  # Correctly extract the scalar value\nTypeError: only size-1 arrays can be converted to Python scalars",
          "calculatedTotalCost": 0.0,
          "environment": "default",
          "promptTokens": 0,
          "completionTokens": 0,
          "totalTokens": 0,
          "costDetails": {},
          "endTime": null,
          "model": null,
          "modelParameters": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null,
          "latency": null
        }
      ],
      "createdAt": "2025-07-30T06:47:44.248Z",
      "updatedAt": "2025-07-30T06:51:52.501Z",
      "environment": "default"
    },
    {
      "id": "f5ea1dbd",
      "timestamp": "2025-07-30T06:43:50.115000+00:00",
      "name": "f5ea_tpu_sketch_generator",
      "input": null,
      "output": {
        "status": "success",
        "sketch": "import numpy as np\nfrom PIL import Image\nimport cv2\n\n# Phase 1: Setup\ntry:\n    from tflite_runtime.interpreter import Interpreter, load_delegate\nexcept ImportError:\n    from tensorflow.lite import Interpreter\n    from tensorflow.lite.experimental import load_delegate\n\n# Paths/Parameters\nmodel_path  = \"/home/mendel/tinyml_autopilot/models/edgetpu_detect.tflite\"\ninput_path  = \"/home/mendel/tinyml_autopilot/data//sheeps.mp4\"\nlabel_path  = \"/home/mendel/tinyml_autopilot/models/labelmap.txt\"\noutput_path  = \"/home/mendel/tinyml_autopilot/results/sheeps_detections.mp4\"\n\n# Load Labels (Conditional)\nwith open(label_path, 'r') as f:\n    labels = [line.strip() for line in f.readlines()]\n\n# Load Interpreter with EdgeTPU\ntry:\n    interpreter = Interpreter(model_path=model_path, experimental_delegates=[load_delegate('libedgetpu.so.1.0')])\nexcept Exception as e:\n    interpreter = Interpreter(model_path=model_path, experimental_delegates=[load_delegate('/usr/lib/aarch64-linux-gnu/libedgetpu.so.1.0')])\n\ninterpreter.allocate_tensors()\n\n# Get Model Details\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\n\n# Phase 2: Input Acquisition & Preprocessing Loop\ncap = cv2.VideoCapture(input_path)\nwidth = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\nheight = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\nfps = cap.get(cv2.CAP_PROP_FPS)\n\nfourcc = cv2.VideoWriter_fourcc(*'mp4v')\nout = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n\nwhile cap.isOpened():\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    # Preprocess Data\n    input_data = cv2.resize(frame, (input_details[0]['shape'][1], input_details[0]['shape'][2]))\n    input_data = np.expand_dims(input_data, axis=0)\n\n    # Quantization Handling\n    floating_model = (input_details[0]['dtype'] == np.float32)\n    if floating_model:\n        input_data = (np.float32(input_data) - 127.5) / 127.5\n\n    # Phase 3: Inference\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n    interpreter.invoke()\n\n    # Phase 4: Output Interpretation & Handling Loop\n    boxes = interpreter.get_tensor(output_details[0]['index'])[0]\n    classes = interpreter.get_tensor(output_details[1]['index'])[0]\n    scores = interpreter.get_tensor(output_details[2]['index'])[0]\n    num_detections = int(interpreter.get_tensor(output_details[3]['index']))\n\n    # Interpret Results\n    for i in range(num_detections):\n        if scores[i] > 0.5:\n            ymin, xmin, ymax, xmax = boxes[i]\n            (left, right, top, bottom) = (xmin * width, xmax * width,\n                                          ymin * height, ymax * height)\n            cv2.rectangle(frame, (int(left), int(top)), (int(right), int(bottom)), (0, 255, 0), 2)\n            label = f'{labels[int(classes[i])]}: {scores[i]:.2f}'\n            cv2.putText(frame, label, (int(left), int(top) - 10),\n                        cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n\n    # Handle Output\n    out.write(frame)\n\n# Phase 5: Cleanup\ncap.release()\nout.release()\ncv2.destroyAllWindows()"
      },
      "session_id": "qwen2.5-coder:32b_1974_tpusg_batch",
      "metadata": {
        "num_run": 16
      },
      "tags": [
        "benchmark",
        "qwen2.5-coder:32b",
        "tpu_sketch_generator"
      ],
      "latency": 174.929,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-09-43-50-116866_chatcmpl-f53c48ac-5be0-4a9f-8776-39f55e26aa33",
          "traceId": "f5ea1dbd",
          "type": "GENERATION",
          "name": "f5ea_tpusg_gen_attempt#1",
          "startTime": "2025-07-30T06:43:50.116000+00:00",
          "endTime": "2025-07-30T06:44:25.221000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 35105.0,
          "environment": "default",
          "promptTokens": 1833,
          "completionTokens": 822,
          "totalTokens": 2655,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-09-44-33-921529_chatcmpl-a3dc8c0c-5ce4-4dd7-9723-3e7a82c73498",
          "traceId": "f5ea1dbd",
          "type": "GENERATION",
          "name": "f5ea_tpusg_gen_attempt#2",
          "startTime": "2025-07-30T06:44:33.921000+00:00",
          "endTime": "2025-07-30T06:45:21.509000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 47588.0,
          "environment": "default",
          "promptTokens": 2048,
          "completionTokens": 1178,
          "totalTokens": 3226,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-09-45-21-517461_chatcmpl-ba1e465f-cc93-428f-ade7-8ae3ddbdb119",
          "traceId": "f5ea1dbd",
          "type": "GENERATION",
          "name": "f5ea_tpusg_gen_attempt#3",
          "startTime": "2025-07-30T06:45:21.517000+00:00",
          "endTime": "2025-07-30T06:45:57.452000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 35935.0,
          "environment": "default",
          "promptTokens": 1990,
          "completionTokens": 868,
          "totalTokens": 2858,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-09-46-05-772819_chatcmpl-20462dec-b2d0-4433-8aa0-f3317d482608",
          "traceId": "f5ea1dbd",
          "type": "GENERATION",
          "name": "f5ea_tpusg_gen_attempt#4",
          "startTime": "2025-07-30T06:46:05.772000+00:00",
          "endTime": "2025-07-30T06:46:45.045000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 39273.0,
          "environment": "default",
          "promptTokens": 2048,
          "completionTokens": 958,
          "totalTokens": 3006,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        }
      ],
      "createdAt": "2025-07-30T06:43:50.635Z",
      "updatedAt": "2025-07-30T06:47:42.815Z",
      "environment": "default"
    },
    {
      "id": "ed940fff",
      "timestamp": "2025-07-30T06:39:57.016000+00:00",
      "name": "ed94_tpu_sketch_generator",
      "input": null,
      "output": {
        "status": "success",
        "sketch": "import numpy as np\nfrom PIL import Image\nimport cv2\n\n# Phase 1: Setup\ntry:\n    from tflite_runtime.interpreter import Interpreter, load_delegate\nexcept ImportError:\n    from tensorflow.lite import Interpreter\n    from tensorflow.lite.experimental import load_delegate\n\n# Paths/Parameters\nmodel_path  = \"/home/mendel/tinyml_autopilot/models/edgetpu_detect.tflite\"\ninput_path  = \"/home/mendel/tinyml_autopilot/data//sheeps.mp4\"\nlabel_path  = \"/home/mendel/tinyml_autopilot/models/labelmap.txt\"\noutput_path  = \"/home/mendel/tinyml_autopilot/results/sheeps_detections.mp4\"\n\n# Load Labels (Conditional)\nwith open(label_path, 'r') as f:\n    labels = [line.strip() for line in f.readlines()]\n\n# Load Interpreter with EdgeTPU\ntry:\n    interpreter = Interpreter(model_path=model_path, experimental_delegates=[load_delegate('libedgetpu.so.1.0')])\nexcept Exception as e:\n    interpreter = Interpreter(model_path=model_path, experimental_delegates=[load_delegate('/usr/lib/aarch64-linux-gnu/libedgetpu.so.1.0')])\n\ninterpreter.allocate_tensors()\n\n# Get Model Details\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\n\n# Phase 2: Input Acquisition & Preprocessing Loop\ncap = cv2.VideoCapture(input_path)\nwidth = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\nheight = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\nfps = cap.get(cv2.CAP_PROP_FPS)\n\nfourcc = cv2.VideoWriter_fourcc(*'mp4v')\nout = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n\nwhile cap.isOpened():\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    # Preprocess Data\n    input_data = cv2.resize(frame, (input_details[0]['shape'][1], input_details[0]['shape'][2]))\n    input_data = np.expand_dims(input_data, axis=0)\n\n    # Quantization Handling\n    floating_model = (input_details[0]['dtype'] == np.float32)\n    if floating_model:\n        input_data = (np.float32(input_data) - 127.5) / 127.5\n\n    # Phase 3: Inference\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n    interpreter.invoke()\n\n    # Phase 4: Output Interpretation & Handling Loop\n    boxes = interpreter.get_tensor(output_details[0]['index'])[0]\n    classes = interpreter.get_tensor(output_details[1]['index'])[0]\n    scores = interpreter.get_tensor(output_details[2]['index'])[0]\n    num_detections = int(interpreter.get_tensor(output_details[3]['index']))\n\n    # Interpret Results\n    for i in range(num_detections):\n        if scores[i] > 0.5:\n            ymin, xmin, ymax, xmax = boxes[i]\n            (left, right, top, bottom) = (xmin * width, xmax * width,\n                                          ymin * height, ymax * height)\n            cv2.rectangle(frame, (int(left), int(top)), (int(right), int(bottom)), (0, 255, 0), 2)\n            label = f'{labels[int(classes[i])]}: {scores[i]:.2f}'\n            cv2.putText(frame, label, (int(left), int(top) - 10),\n                        cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n\n    # Handle Output\n    out.write(frame)\n\n# Phase 5: Cleanup\ncap.release()\nout.release()\ncv2.destroyAllWindows()"
      },
      "session_id": "qwen2.5-coder:32b_1974_tpusg_batch",
      "metadata": {
        "num_run": 15
      },
      "tags": [
        "benchmark",
        "qwen2.5-coder:32b",
        "tpu_sketch_generator"
      ],
      "latency": 174.049,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-09-39-57-017837_chatcmpl-e295fa30-faba-47d1-9b43-faf8aec70499",
          "traceId": "ed940fff",
          "type": "GENERATION",
          "name": "ed94_tpusg_gen_attempt#1",
          "startTime": "2025-07-30T06:39:57.017000+00:00",
          "endTime": "2025-07-30T06:40:31.132000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 34115.0,
          "environment": "default",
          "promptTokens": 1833,
          "completionTokens": 822,
          "totalTokens": 2655,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-09-40-40-300098_chatcmpl-099f78b4-5269-40b1-ad3e-a769b471aff0",
          "traceId": "ed940fff",
          "type": "GENERATION",
          "name": "ed94_tpusg_gen_attempt#2",
          "startTime": "2025-07-30T06:40:40.300000+00:00",
          "endTime": "2025-07-30T06:41:27.639000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 47339.0,
          "environment": "default",
          "promptTokens": 2048,
          "completionTokens": 1167,
          "totalTokens": 3215,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-09-41-27-645475_chatcmpl-c6fa1373-e406-4945-9d9a-a1e0f7ea71b0",
          "traceId": "ed940fff",
          "type": "GENERATION",
          "name": "ed94_tpusg_gen_attempt#3",
          "startTime": "2025-07-30T06:41:27.645000+00:00",
          "endTime": "2025-07-30T06:42:03.447000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 35802.0,
          "environment": "default",
          "promptTokens": 1990,
          "completionTokens": 868,
          "totalTokens": 2858,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-09-42-11-806758_chatcmpl-90eaea11-4537-4f8f-8877-fbf59f18bc55",
          "traceId": "ed940fff",
          "type": "GENERATION",
          "name": "ed94_tpusg_gen_attempt#4",
          "startTime": "2025-07-30T06:42:11.806000+00:00",
          "endTime": "2025-07-30T06:42:51.066000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 39260.0,
          "environment": "default",
          "promptTokens": 2048,
          "completionTokens": 958,
          "totalTokens": 3006,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        }
      ],
      "createdAt": "2025-07-30T06:39:57.539Z",
      "updatedAt": "2025-07-30T06:43:49.280Z",
      "environment": "default"
    },
    {
      "id": "9ed3c1c8",
      "timestamp": "2025-07-30T06:35:45.483000+00:00",
      "name": "9ed3_tpu_sketch_generator",
      "input": null,
      "output": {
        "status": "failed",
        "last_code": "import numpy as np\nfrom tflite_runtime.interpreter import Interpreter, load_delegate\nimport cv2\n\n# Phase 1: Setup\nmodel_path  = \"/home/mendel/tinyml_autopilot/models/edgetpu_detect.tflite\"\nlabel_path  = \"/home/mendel/tinyml_autopilot/models/labelmap.txt\"\ninput_path  = \"/home/mendel/tinyml_autopilot/data//sheeps.mp4\"\noutput_path  = \"/home/mendel/tinyml_autopilot/results/sheeps_detections.mp4\"\nconfidence_threshold  = 0.5\n\n# Load labels\nwith open(label_path, 'r') as f:\n    labels = [line.strip() for line in f.readlines()]\n\n# Load Interpreter with EdgeTPU\ntry:\n    interpreter = Interpreter(model_path=model_path,\n                              experimental_delegates=[load_delegate('libedgetpu.so.1.0')])\nexcept Exception as e:\n    print(f\"Failed to load libedgetpu.so.1.0: {e}\")\n    try:\n        interpreter = Interpreter(model_path=model_path,\n                                  experimental_delegates=[load_delegate('/usr/lib/aarch64-linux-gnu/libedgetpu.so.1.0')])\n    except Exception as e:\n        print(f\"Failed to load /usr/lib/aarch64-linux-gnu/libedgetpu.so.1.0: {e}\")\n        raise\n\ninterpreter.allocate_tensors()\n\n# Get Model Details\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\n\nfloating_model = (input_details[0]['dtype'] == np.float32)\n\n# Phase 2: Input Acquisition & Preprocessing Loop\ncap = cv2.VideoCapture(input_path)\nif not cap.isOpened():\n    raise IOError(\"Cannot open video file\")\n\nframe_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\nframe_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\nfps = cap.get(cv2.CAP_PROP_FPS)\n\nout = cv2.VideoWriter(output_path, cv2.VideoWriter_fourcc(*'mp4v'), fps, (frame_width, frame_height))\n\nwhile True:\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    # Preprocess Data\n    input_data = cv2.resize(frame, (input_details[0]['shape'][1], input_details[0]['shape'][2]))\n    input_data = np.expand_dims(input_data, axis=0)\n\n    if floating_model:\n        input_data = (np.float32(input_data) - 127.5) / 127.5\n\n    # Phase 3: Inference\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n    interpreter.invoke()\n\n    # Phase 4: Output Interpretation & Handling Loop\n    output_data = interpreter.get_tensor(output_details[0]['index'])\n    num_detections = int(interpreter.get_tensor(output_details[2]['index'])[0])  # Extract scalar value from array\n\n    for i in range(num_detections):\n        confidence = float(output_data[0][i][15])\n        if confidence > confidence_threshold:\n            ymin, xmin, ymax, xmax = output_data[0][i][:4]\n            (left, right, top, bottom) = (xmin * frame_width, xmax * frame_width,\n                                          ymin * frame_height, ymax * frame_height)\n\n            cv2.rectangle(frame, (int(left), int(top)), (int(right), int(bottom)), (0, 255, 0), 2)\n            label = f\"{labels[int(output_data[0][i][14])]}: {confidence:.2f}\"\n            cv2.putText(frame, label, (int(left), int(top) - 10),\n                        cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n\n    # Handle Output\n    out.write(frame)\n\n# Phase 5: Cleanup\ncap.release()\nout.release()\ncv2.destroyAllWindows()",
        "last_error": "Traceback (most recent call last):\n  File \"script_8665b9fd_1753857583.py\", line 66, in <module>\n    num_detections = int(interpreter.get_tensor(output_details[2]['index'])[0])  # Extract scalar value from array\nTypeError: only size-1 arrays can be converted to Python scalars"
      },
      "session_id": "qwen2.5-coder:32b_1974_tpusg_batch",
      "metadata": {
        "num_run": 14
      },
      "tags": [
        "benchmark",
        "qwen2.5-coder:32b",
        "tpu_sketch_generator"
      ],
      "latency": 246.363,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-09-35-45-485302_chatcmpl-6c780034-b977-4adc-8781-530abe7aaa95",
          "traceId": "9ed3c1c8",
          "type": "GENERATION",
          "name": "9ed3_tpusg_gen_attempt#1",
          "startTime": "2025-07-30T06:35:45.485000+00:00",
          "endTime": "2025-07-30T06:36:19.548000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 34063.0,
          "environment": "default",
          "promptTokens": 1833,
          "completionTokens": 822,
          "totalTokens": 2655,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-09-36-28-027106_chatcmpl-a6ca81ff-22da-4760-890a-303de60d2499",
          "traceId": "9ed3c1c8",
          "type": "GENERATION",
          "name": "9ed3_tpusg_gen_attempt#2",
          "startTime": "2025-07-30T06:36:28.027000+00:00",
          "endTime": "2025-07-30T06:37:10.992000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 42965.0,
          "environment": "default",
          "promptTokens": 2048,
          "completionTokens": 1054,
          "totalTokens": 3102,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-09-37-19-495271_chatcmpl-64804986-717e-4f6d-b10b-bf2de33fecc5",
          "traceId": "9ed3c1c8",
          "type": "GENERATION",
          "name": "9ed3_tpusg_gen_attempt#3",
          "startTime": "2025-07-30T06:37:19.495000+00:00",
          "endTime": "2025-07-30T06:38:01.781000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 42286.0,
          "environment": "default",
          "promptTokens": 2048,
          "completionTokens": 1038,
          "totalTokens": 3086,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-09-38-10-219071_chatcmpl-5fb41496-62b5-4fbc-901e-1d8c3f00ade3",
          "traceId": "9ed3c1c8",
          "type": "GENERATION",
          "name": "9ed3_tpusg_gen_attempt#4",
          "startTime": "2025-07-30T06:38:10.219000+00:00",
          "endTime": "2025-07-30T06:38:52.615000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 42396.0,
          "environment": "default",
          "promptTokens": 2048,
          "completionTokens": 1040,
          "totalTokens": 3088,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-09-39-01-067472_chatcmpl-fbb78fd9-7961-4c79-ac43-2e23b33679cd",
          "traceId": "9ed3c1c8",
          "type": "GENERATION",
          "name": "9ed3_tpusg_gen_attempt#5",
          "startTime": "2025-07-30T06:39:01.067000+00:00",
          "endTime": "2025-07-30T06:39:43.380000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 42313.0,
          "environment": "default",
          "promptTokens": 2048,
          "completionTokens": 1038,
          "totalTokens": 3086,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "9824ec3e-1940-42f8-8d2f-e1ec346fa5ce",
          "traceId": "9ed3c1c8",
          "type": "SPAN",
          "name": "error_9e_tpusg_failure_signal_tpu_sketch_generator",
          "startTime": "2025-07-30T06:39:51.848000+00:00",
          "level": "ERROR",
          "statusMessage": "Failed. Last error: Traceback (most recent call last):\n  File \"script_8665b9fd_1753857583.py\", line 66, in <module>\n    num_detections = int(interpreter.get_tensor(output_details[2]['index'])[0])  # Extract scalar value from array\nTypeError: only size-1 arrays can be converted to Python scalars",
          "calculatedTotalCost": 0.0,
          "environment": "default",
          "promptTokens": 0,
          "completionTokens": 0,
          "totalTokens": 0,
          "costDetails": {},
          "endTime": null,
          "model": null,
          "modelParameters": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null,
          "latency": null
        }
      ],
      "createdAt": "2025-07-30T06:35:46.005Z",
      "updatedAt": "2025-07-30T06:39:57.258Z",
      "environment": "default"
    },
    {
      "id": "24640f14",
      "timestamp": "2025-07-30T06:32:28.862000+00:00",
      "name": "2464_tpu_sketch_generator",
      "input": null,
      "output": {
        "status": "success",
        "sketch": "import numpy as np\nfrom tflite_runtime.interpreter import Interpreter, load_delegate\nimport cv2\n\n# Phase 1: Setup\nmodel_path  = \"/home/mendel/tinyml_autopilot/models/edgetpu_detect.tflite\"\nlabel_path  = \"/home/mendel/tinyml_autopilot/models/labelmap.txt\"\ninput_path  = \"/home/mendel/tinyml_autopilot/data//sheeps.mp4\"\noutput_path  = \"/home/mendel/tinyml_autopilot/results/sheeps_detections.mp4\"\nconfidence_threshold  = 0.5\n\n# Load labels\nwith open(label_path, 'r') as f:\n    labels = [line.strip() for line in f.readlines()]\n\n# Load Interpreter with EdgeTPU\ntry:\n    interpreter = Interpreter(model_path=model_path,\n                              experimental_delegates=[load_delegate('libedgetpu.so.1.0')])\nexcept Exception as e:\n    print(f\"Failed to load libedgetpu.so.1.0: {e}\")\n    try:\n        interpreter = Interpreter(model_path=model_path,\n                                  experimental_delegates=[load_delegate('/usr/lib/aarch64-linux-gnu/libedgetpu.so.1.0')])\n    except Exception as e:\n        print(f\"Failed to load /usr/lib/aarch64-linux-gnu/libedgetpu.so.1.0: {e}\")\n        raise\n\ninterpreter.allocate_tensors()\n\n# Get Model Details\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\n\nfloating_model = (input_details[0]['dtype'] == np.float32)\n\n# Phase 2: Input Acquisition & Preprocessing Loop\ncap = cv2.VideoCapture(input_path)\nif not cap.isOpened():\n    raise IOError(\"Cannot open video file\")\n\nframe_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\nframe_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\nfps = cap.get(cv2.CAP_PROP_FPS)\n\nout = cv2.VideoWriter(output_path, cv2.VideoWriter_fourcc(*'mp4v'), fps, (frame_width, frame_height))\n\nwhile True:\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    # Preprocess Data\n    input_data = cv2.resize(frame, (input_details[0]['shape'][1], input_details[0]['shape'][2]))\n    input_data = np.expand_dims(input_data, axis=0)\n\n    if floating_model:\n        input_data = (np.float32(input_data) - 127.5) / 127.5\n\n    # Phase 3: Inference\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n    interpreter.invoke()\n\n    # Phase 4: Output Interpretation & Handling Loop\n    boxes = interpreter.get_tensor(output_details[0]['index'])[0]\n    classes = interpreter.get_tensor(output_details[1]['index'])[0]\n    scores = interpreter.get_tensor(output_details[2]['index'])[0]\n\n    for i in range(len(scores)):\n        confidence = float(scores[i])\n        if confidence > confidence_threshold:\n            ymin, xmin, ymax, xmax = boxes[i]\n            (left, right, top, bottom) = (xmin * frame_width, xmax * frame_width,\n                                          ymin * frame_height, ymax * frame_height)\n\n            cv2.rectangle(frame, (int(left), int(top)), (int(right), int(bottom)), (0, 255, 0), 2)\n            label = f\"{labels[int(classes[i])]}: {confidence:.2f}\"\n            cv2.putText(frame, label, (int(left), int(top) - 10),\n                        cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n\n    # Handle Output\n    out.write(frame)\n\n# Phase 5: Cleanup\ncap.release()\nout.release()\ncv2.destroyAllWindows()"
      },
      "session_id": "qwen2.5-coder:32b_1974_tpusg_batch",
      "metadata": {
        "num_run": 13
      },
      "tags": [
        "benchmark",
        "qwen2.5-coder:32b",
        "tpu_sketch_generator"
      ],
      "latency": 137.685,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-09-32-28-864344_chatcmpl-12c28942-2b96-4b55-8be1-dc73731926ed",
          "traceId": "24640f14",
          "type": "GENERATION",
          "name": "2464_tpusg_gen_attempt#1",
          "startTime": "2025-07-30T06:32:28.864000+00:00",
          "endTime": "2025-07-30T06:33:03.249000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 34385.0,
          "environment": "default",
          "promptTokens": 1833,
          "completionTokens": 822,
          "totalTokens": 2655,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-09-33-11-683857_chatcmpl-cf3aeb07-d01f-4c71-9140-ad0796b9201d",
          "traceId": "24640f14",
          "type": "GENERATION",
          "name": "2464_tpusg_gen_attempt#2",
          "startTime": "2025-07-30T06:33:11.683000+00:00",
          "endTime": "2025-07-30T06:33:53.827000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 42144.0,
          "environment": "default",
          "promptTokens": 2048,
          "completionTokens": 1033,
          "totalTokens": 3081,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-09-34-02-467564_chatcmpl-bcd4028f-c6cc-4b56-a138-f6526d872dcf",
          "traceId": "24640f14",
          "type": "GENERATION",
          "name": "2464_tpusg_gen_attempt#3",
          "startTime": "2025-07-30T06:34:02.467000+00:00",
          "endTime": "2025-07-30T06:34:46.549000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 44082.0,
          "environment": "default",
          "promptTokens": 2048,
          "completionTokens": 1085,
          "totalTokens": 3133,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        }
      ],
      "createdAt": "2025-07-30T06:32:29.384Z",
      "updatedAt": "2025-07-30T06:35:44.566Z",
      "environment": "default"
    },
    {
      "id": "c34b4de7",
      "timestamp": "2025-07-30T06:29:18.328000+00:00",
      "name": "c34b_tpu_sketch_generator",
      "input": null,
      "output": {
        "status": "success",
        "sketch": "import numpy as np\nfrom tflite_runtime.interpreter import Interpreter, load_delegate\n\n# Phase 1: Setup\nmodel_path  = \"/home/mendel/tinyml_autopilot/models/edgetpu_detect.tflite\"\nlabel_path  = \"/home/mendel/tinyml_autopilot/models/labelmap.txt\"\ninput_path  = \"/home/mendel/tinyml_autopilot/data//sheeps.mp4\"\noutput_path  = \"/home/mendel/tinyml_autopilot/results/sheeps_detections.mp4\"\nconfidence_threshold  = 0.5\n\n# Load labels\nwith open(label_path, 'r') as f:\n    labels = [line.strip() for line in f.readlines()]\n\n# Load Interpreter with EdgeTPU\ntry:\n    interpreter = Interpreter(model_path=model_path,\n                              experimental_delegates=[load_delegate('libedgetpu.so.1.0')])\nexcept Exception as e:\n    print(f\"Failed to load libedgetpu.so.1.0: {e}\")\n    try:\n        interpreter = Interpreter(model_path=model_path,\n                                  experimental_delegates=[load_delegate('/usr/lib/aarch64-linux-gnu/libedgetpu.so.1.0')])\n    except Exception as e:\n        print(f\"Failed to load /usr/lib/aarch64-linux-gnu/libedgetpu.so.1.0: {e}\")\n        raise\n\ninterpreter.allocate_tensors()\n\n# Get Model Details\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\n\nfloating_model = (input_details[0]['dtype'] == np.float32)\n\n# Phase 2: Input Acquisition & Preprocessing Loop\nimport cv2\n\ncap = cv2.VideoCapture(input_path)\nif not cap.isOpened():\n    raise IOError(\"Cannot open video file\")\n\nframe_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\nframe_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\nfps = cap.get(cv2.CAP_PROP_FPS)\n\nout = cv2.VideoWriter(output_path, cv2.VideoWriter_fourcc(*'mp4v'), fps, (frame_width, frame_height))\n\nwhile True:\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    # Preprocess Data\n    input_data = cv2.resize(frame, (input_details[0]['shape'][1], input_details[0]['shape'][2]))\n    input_data = np.expand_dims(input_data, axis=0)\n\n    if floating_model:\n        input_data = (np.float32(input_data) - 127.5) / 127.5\n\n    # Phase 3: Inference\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n    interpreter.invoke()\n\n    # Phase 4: Output Interpretation & Handling Loop\n    output_data = interpreter.get_tensor(output_details[0]['index'])\n    num_detections = int(interpreter.get_tensor(output_details[2]['index'])[0][0])  # Corrected indexing\n\n    for i in range(num_detections):\n        confidence = float(output_data[0][i][15])\n        if confidence > confidence_threshold:\n            ymin, xmin, ymax, xmax = output_data[0][i][:4]\n            (left, right, top, bottom) = (xmin * frame_width, xmax * frame_width,\n                                          ymin * frame_height, ymax * frame_height)\n\n            cv2.rectangle(frame, (int(left), int(top)), (int(right), int(bottom)), (0, 255, 0), 2)\n            label = f\"{labels[int(output_data[0][i][14])]}: {confidence:.2f}\"\n            cv2.putText(frame, label, (int(left), int(top) - 10),\n                        cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n\n    # Handle Output\n    out.write(frame)\n\n# Phase 5: Cleanup\ncap.release()\nout.release()\ncv2.destroyAllWindows()"
      },
      "session_id": "qwen2.5-coder:32b_1974_tpusg_batch",
      "metadata": {
        "num_run": 12
      },
      "tags": [
        "benchmark",
        "qwen2.5-coder:32b",
        "tpu_sketch_generator"
      ],
      "latency": 132.608,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-09-29-18-330303_chatcmpl-aa6570c6-20c8-4372-a7f2-f247575765af",
          "traceId": "c34b4de7",
          "type": "GENERATION",
          "name": "c34b_tpusg_gen_attempt#1",
          "startTime": "2025-07-30T06:29:18.330000+00:00",
          "endTime": "2025-07-30T06:29:52.551000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 34221.0,
          "environment": "default",
          "promptTokens": 1833,
          "completionTokens": 822,
          "totalTokens": 2655,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-09-30-00-907856_chatcmpl-3eb5e419-02d2-45e8-981c-e77a3a612d4d",
          "traceId": "c34b4de7",
          "type": "GENERATION",
          "name": "c34b_tpusg_gen_attempt#2",
          "startTime": "2025-07-30T06:30:00.907000+00:00",
          "endTime": "2025-07-30T06:30:41.860000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 40953.0,
          "environment": "default",
          "promptTokens": 2048,
          "completionTokens": 1001,
          "totalTokens": 3049,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-09-30-50-304213_chatcmpl-cd3ab1fc-4871-4857-ad72-641c2196b51f",
          "traceId": "c34b4de7",
          "type": "GENERATION",
          "name": "c34b_tpusg_gen_attempt#3",
          "startTime": "2025-07-30T06:30:50.304000+00:00",
          "endTime": "2025-07-30T06:31:30.938000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 40634.0,
          "environment": "default",
          "promptTokens": 2048,
          "completionTokens": 994,
          "totalTokens": 3042,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        }
      ],
      "createdAt": "2025-07-30T06:29:18.849Z",
      "updatedAt": "2025-07-30T06:32:27.566Z",
      "environment": "default"
    },
    {
      "id": "d560756c",
      "timestamp": "2025-07-30T06:24:38.757000+00:00",
      "name": "d560_tpu_sketch_generator",
      "input": null,
      "output": {
        "status": "failed",
        "last_code": "import numpy as np\nfrom tflite_runtime.interpreter import Interpreter, load_delegate\nimport cv2\n\n# Phase 1: Setup\nmodel_path  = \"/home/mendel/tinyml_autopilot/models/edgetpu_detect.tflite\"\nlabel_path  = \"/home/mendel/tinyml_autopilot/models/labelmap.txt\"\ninput_path  = \"/home/mendel/tinyml_autopilot/data//sheeps.mp4\"\noutput_path  = \"/home/mendel/tinyml_autopilot/results/sheeps_detections.mp4\"\nconfidence_threshold  = 0.5\n\n# Load labels\nwith open(label_path, 'r') as f:\n    labels = [line.strip() for line in f.readlines()]\n\n# Load Interpreter with EdgeTPU\ntry:\n    interpreter = Interpreter(model_path=model_path,\n                              experimental_delegates=[load_delegate('libedgetpu.so.1.0')])\nexcept Exception as e:\n    print(f\"Failed to load libedgetpu.so.1.0: {e}\")\n    try:\n        interpreter = Interpreter(model_path=model_path,\n                                  experimental_delegates=[load_delegate('/usr/lib/aarch64-linux-gnu/libedgetpu.so.1.0')])\n    except Exception as e:\n        print(f\"Failed to load /usr/lib/aarch64-linux-gnu/libedgetpu.so.1.0: {e}\")\n        raise\n\ninterpreter.allocate_tensors()\n\n# Get Model Details\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\n\nfloating_model = (input_details[0]['dtype'] == np.float32)\n\n# Phase 2: Input Acquisition & Preprocessing Loop\ncap = cv2.VideoCapture(input_path)\nif not cap.isOpened():\n    raise IOError(\"Cannot open video file\")\n\nframe_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\nframe_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\nfps = cap.get(cv2.CAP_PROP_FPS)\n\nout = cv2.VideoWriter(output_path, cv2.VideoWriter_fourcc(*'mp4v'), fps, (frame_width, frame_height))\n\nwhile True:\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    # Preprocess Data\n    input_data = cv2.resize(frame, (input_details[0]['shape'][1], input_details[0]['shape'][2]))\n    input_data = np.expand_dims(input_data, axis=0)\n\n    if floating_model:\n        input_data = (np.float32(input_data) - 127.5) / 127.5\n\n    # Phase 3: Inference\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n    interpreter.invoke()\n\n    # Phase 4: Output Interpretation & Handling Loop\n    output_data = interpreter.get_tensor(output_details[0]['index'])\n    num_detections = int(interpreter.get_tensor(output_details[2]['index'])[0])  # Extract the single element\n\n    for i in range(num_detections):\n        confidence = float(output_data[0][i][15])\n        if confidence > confidence_threshold:\n            ymin, xmin, ymax, xmax = output_data[0][i][:4]\n            (left, right, top, bottom) = (xmin * frame_width, xmax * frame_width,\n                                          ymin * frame_height, ymax * frame_height)\n\n            cv2.rectangle(frame, (int(left), int(top)), (int(right), int(bottom)), (0, 255, 0), 2)\n            label = f\"{labels[int(output_data[0][i][14])]}: {confidence:.2f}\"\n            cv2.putText(frame, label, (int(left), int(top) - 10),\n                        cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n\n    # Handle Output\n    out.write(frame)\n\n# Phase 5: Cleanup\ncap.release()\nout.release()\ncv2.destroyAllWindows()",
        "last_error": "Traceback (most recent call last):\n  File \"script_763939cc_1753856944.py\", line 66, in <module>\n    num_detections = int(interpreter.get_tensor(output_details[2]['index'])[0])  # Extract the single element\nTypeError: only size-1 arrays can be converted to Python scalars"
      },
      "session_id": "qwen2.5-coder:32b_1974_tpusg_batch",
      "metadata": {
        "num_run": 11
      },
      "tags": [
        "benchmark",
        "qwen2.5-coder:32b",
        "tpu_sketch_generator"
      ],
      "latency": 274.71,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-09-24-38-759297_chatcmpl-3a0388a1-adc1-4a50-a63e-a416222eee64",
          "traceId": "d560756c",
          "type": "GENERATION",
          "name": "d560_tpusg_gen_attempt#1",
          "startTime": "2025-07-30T06:24:38.759000+00:00",
          "endTime": "2025-07-30T06:25:12.808000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 34049.0,
          "environment": "default",
          "promptTokens": 1833,
          "completionTokens": 822,
          "totalTokens": 2655,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-09-25-21-523456_chatcmpl-900fab49-47a1-4a8b-b01d-775e804e9602",
          "traceId": "d560756c",
          "type": "GENERATION",
          "name": "d560_tpusg_gen_attempt#2",
          "startTime": "2025-07-30T06:25:21.523000+00:00",
          "endTime": "2025-07-30T06:26:03.152000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 41629.0,
          "environment": "default",
          "promptTokens": 2048,
          "completionTokens": 1021,
          "totalTokens": 3069,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-09-26-11-532562_chatcmpl-911fbe0d-78e4-4191-bab9-d9364f52b782",
          "traceId": "d560756c",
          "type": "GENERATION",
          "name": "d560_tpusg_gen_attempt#3",
          "startTime": "2025-07-30T06:26:11.532000+00:00",
          "endTime": "2025-07-30T06:27:22.777000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 71245.0,
          "environment": "default",
          "promptTokens": 2048,
          "completionTokens": 1810,
          "totalTokens": 3858,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-09-27-31-281705_chatcmpl-79237b54-6d2d-444f-9249-2c05c3d2d982",
          "traceId": "d560756c",
          "type": "GENERATION",
          "name": "d560_tpusg_gen_attempt#4",
          "startTime": "2025-07-30T06:27:31.281000+00:00",
          "endTime": "2025-07-30T06:28:13.941000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 42660.0,
          "environment": "default",
          "promptTokens": 2048,
          "completionTokens": 1047,
          "totalTokens": 3095,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-09-28-22-443817_chatcmpl-d62e03a3-5837-41bc-95db-0986d57c3032",
          "traceId": "d560756c",
          "type": "GENERATION",
          "name": "d560_tpusg_gen_attempt#5",
          "startTime": "2025-07-30T06:28:22.443000+00:00",
          "endTime": "2025-07-30T06:29:04.924000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 42481.0,
          "environment": "default",
          "promptTokens": 2048,
          "completionTokens": 1035,
          "totalTokens": 3083,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "89e38b09-e44c-4cd6-8ae1-bd3ffcdab182",
          "traceId": "d560756c",
          "type": "SPAN",
          "name": "error_d5_tpusg_failure_signal_tpu_sketch_generator",
          "startTime": "2025-07-30T06:29:13.469000+00:00",
          "level": "ERROR",
          "statusMessage": "Failed. Last error: Traceback (most recent call last):\n  File \"script_763939cc_1753856944.py\", line 66, in <module>\n    num_detections = int(interpreter.get_tensor(output_details[2]['index'])[0])  # Extract the single element\nTypeError: only size-1 arrays can be converted to Python scalars",
          "calculatedTotalCost": 0.0,
          "environment": "default",
          "promptTokens": 0,
          "completionTokens": 0,
          "totalTokens": 0,
          "costDetails": {},
          "endTime": null,
          "model": null,
          "modelParameters": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null,
          "latency": null
        }
      ],
      "createdAt": "2025-07-30T06:24:39.278Z",
      "updatedAt": "2025-07-30T06:29:18.998Z",
      "environment": "default"
    },
    {
      "id": "ca78fb05",
      "timestamp": "2025-07-30T06:20:29.845000+00:00",
      "name": "ca78_tpu_sketch_generator",
      "input": null,
      "output": {
        "status": "failed",
        "last_code": "import numpy as np\nfrom tflite_runtime.interpreter import Interpreter, load_delegate\nimport cv2\n\n# Phase 1: Setup\nmodel_path  = \"/home/mendel/tinyml_autopilot/models/edgetpu_detect.tflite\"\nlabel_path  = \"/home/mendel/tinyml_autopilot/models/labelmap.txt\"\ninput_path  = \"/home/mendel/tinyml_autopilot/data//sheeps.mp4\"\noutput_path  = \"/home/mendel/tinyml_autopilot/results/sheeps_detections.mp4\"\nconfidence_threshold  = 0.5\n\n# Load labels\nwith open(label_path, 'r') as f:\n    labels = [line.strip() for line in f.readlines()]\n\n# Load Interpreter with EdgeTPU\ntry:\n    interpreter = Interpreter(model_path=model_path,\n                              experimental_delegates=[load_delegate('libedgetpu.so.1.0')])\nexcept Exception as e:\n    print(f\"Failed to load libedgetpu.so.1.0: {e}\")\n    try:\n        interpreter = Interpreter(model_path=model_path,\n                                  experimental_delegates=[load_delegate('/usr/lib/aarch64-linux-gnu/libedgetpu.so.1.0')])\n    except Exception as e:\n        print(f\"Failed to load /usr/lib/aarch64-linux-gnu/libedgetpu.so.1.0: {e}\")\n        raise\n\ninterpreter.allocate_tensors()\n\n# Get Model Details\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\n\nfloating_model = (input_details[0]['dtype'] == np.float32)\n\n# Phase 2: Input Acquisition & Preprocessing Loop\ncap = cv2.VideoCapture(input_path)\nif not cap.isOpened():\n    raise IOError(\"Cannot open video file\")\n\nframe_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\nframe_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\nfps = cap.get(cv2.CAP_PROP_FPS)\n\nout = cv2.VideoWriter(output_path, cv2.VideoWriter_fourcc(*'mp4v'), fps, (frame_width, frame_height))\n\nwhile True:\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    # Preprocess Data\n    input_data = cv2.resize(frame, (input_details[0]['shape'][1], input_details[0]['shape'][2]))\n    input_data = np.expand_dims(input_data, axis=0)\n\n    if floating_model:\n        input_data = (np.float32(input_data) - 127.5) / 127.5\n\n    # Phase 3: Inference\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n    interpreter.invoke()\n\n    # Phase 4: Output Interpretation & Handling Loop\n    output_data = interpreter.get_tensor(output_details[0]['index'])\n    num_detections = int(interpreter.get_tensor(output_details[2]['index']))  # Correctly extract the scalar value\n\n    for i in range(num_detections):\n        confidence = float(output_data[0][i][15])\n        if confidence > confidence_threshold:\n            class_id = int(output_data[0][i][14])\n            label = labels[class_id]\n            box = output_data[0][i][:4] * np.array([frame_height, frame_width, frame_height, frame_width])\n\n            y_min, x_min, y_max, x_max = box.astype(int)\n            cv2.rectangle(frame, (x_min, y_min), (x_max, y_max), (10, 255, 0), 2)\n            label_text = f'{label}: {confidence:.2f}'\n            cv2.putText(frame, label_text, (x_min, y_min - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (36, 255, 12), 2)\n\n    # Handle Output\n    out.write(frame)\n\n# Phase 5: Cleanup\ncap.release()\nout.release()\ncv2.destroyAllWindows()",
        "last_error": "Traceback (most recent call last):\n  File \"script_82a0d02e_1753856664.py\", line 66, in <module>\n    num_detections = int(interpreter.get_tensor(output_details[2]['index']))  # Correctly extract the scalar value\nTypeError: only size-1 arrays can be converted to Python scalars"
      },
      "session_id": "qwen2.5-coder:32b_1974_tpusg_batch",
      "metadata": {
        "num_run": 10
      },
      "tags": [
        "benchmark",
        "qwen2.5-coder:32b",
        "tpu_sketch_generator"
      ],
      "latency": 242.697,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-09-20-29-847194_chatcmpl-e1eab58f-873b-4289-b4f5-25acb1d3b755",
          "traceId": "ca78fb05",
          "type": "GENERATION",
          "name": "ca78_tpusg_gen_attempt#1",
          "startTime": "2025-07-30T06:20:29.847000+00:00",
          "endTime": "2025-07-30T06:21:04.192000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 34345.0,
          "environment": "default",
          "promptTokens": 1833,
          "completionTokens": 829,
          "totalTokens": 2662,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-09-21-12-633506_chatcmpl-cb91f02d-b9bc-4414-8c57-e84b26cab126",
          "traceId": "ca78fb05",
          "type": "GENERATION",
          "name": "ca78_tpusg_gen_attempt#2",
          "startTime": "2025-07-30T06:21:12.633000+00:00",
          "endTime": "2025-07-30T06:21:54.678000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 42045.0,
          "environment": "default",
          "promptTokens": 2048,
          "completionTokens": 1028,
          "totalTokens": 3076,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-09-22-03-097007_chatcmpl-4d1bac71-fa38-4848-9b9a-87336c95bd5b",
          "traceId": "ca78fb05",
          "type": "GENERATION",
          "name": "ca78_tpusg_gen_attempt#3",
          "startTime": "2025-07-30T06:22:03.097000+00:00",
          "endTime": "2025-07-30T06:22:45.229000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 42132.0,
          "environment": "default",
          "promptTokens": 2048,
          "completionTokens": 1034,
          "totalTokens": 3082,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-09-22-53-631795_chatcmpl-0f7a9922-5a0d-4aa0-9ffe-801577128b58",
          "traceId": "ca78fb05",
          "type": "GENERATION",
          "name": "ca78_tpusg_gen_attempt#4",
          "startTime": "2025-07-30T06:22:53.631000+00:00",
          "endTime": "2025-07-30T06:23:34.597000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 40966.0,
          "environment": "default",
          "promptTokens": 2048,
          "completionTokens": 1001,
          "totalTokens": 3049,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-09-23-43-058816_chatcmpl-4019640b-a74a-436b-a15e-5c8573bd5874",
          "traceId": "ca78fb05",
          "type": "GENERATION",
          "name": "ca78_tpusg_gen_attempt#5",
          "startTime": "2025-07-30T06:23:43.058000+00:00",
          "endTime": "2025-07-30T06:24:24.141000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 41083.0,
          "environment": "default",
          "promptTokens": 2048,
          "completionTokens": 1002,
          "totalTokens": 3050,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "ce28cbc8-809e-4c5d-bb83-3a73e6cd6904",
          "traceId": "ca78fb05",
          "type": "SPAN",
          "name": "error_ca_tpusg_failure_signal_tpu_sketch_generator",
          "startTime": "2025-07-30T06:24:32.544000+00:00",
          "level": "ERROR",
          "statusMessage": "Failed. Last error: Traceback (most recent call last):\n  File \"script_82a0d02e_1753856664.py\", line 66, in <module>\n    num_detections = int(interpreter.get_tensor(output_details[2]['index']))  # Correctly extract the scalar value\nTypeError: only size-1 arrays can be converted to Python scalars",
          "calculatedTotalCost": 0.0,
          "environment": "default",
          "promptTokens": 0,
          "completionTokens": 0,
          "totalTokens": 0,
          "costDetails": {},
          "endTime": null,
          "model": null,
          "modelParameters": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null,
          "latency": null
        }
      ],
      "createdAt": "2025-07-30T06:20:30.365Z",
      "updatedAt": "2025-07-30T06:24:38.106Z",
      "environment": "default"
    },
    {
      "id": "18296e38",
      "timestamp": "2025-07-30T06:16:41.329000+00:00",
      "name": "1829_tpu_sketch_generator",
      "input": null,
      "output": {
        "status": "success",
        "sketch": "import numpy as np\nfrom PIL import Image\nimport cv2\n\n# Phase 1: Setup\ntry:\n    from tflite_runtime.interpreter import Interpreter, load_delegate\nexcept ImportError:\n    from tensorflow.lite import Interpreter\n    from tensorflow.lite.experimental import load_delegate\n\n# Paths/Parameters\nmodel_path  = \"/home/mendel/tinyml_autopilot/models/edgetpu_detect.tflite\"\ninput_path  = \"/home/mendel/tinyml_autopilot/data//sheeps.mp4\"\nlabel_path  = \"/home/mendel/tinyml_autopilot/models/labelmap.txt\"\noutput_path  = \"/home/mendel/tinyml_autopilot/results/sheeps_detections.mp4\"\n\n# Load Labels (Conditional)\nwith open(label_path, 'r') as f:\n    labels = [line.strip() for line in f.readlines()]\n\n# Load Interpreter with EdgeTPU\ntry:\n    interpreter = Interpreter(model_path=model_path, experimental_delegates=[load_delegate('libedgetpu.so.1.0')])\nexcept Exception as e:\n    interpreter = Interpreter(model_path=model_path, experimental_delegates=[load_delegate('/usr/lib/aarch64-linux-gnu/libedgetpu.so.1.0')])\n\ninterpreter.allocate_tensors()\n\n# Get Model Details\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\n\n# Phase 2: Input Acquisition & Preprocessing Loop\ncap = cv2.VideoCapture(input_path)\nwidth = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\nheight = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\nfps = cap.get(cv2.CAP_PROP_FPS)\n\nfourcc = cv2.VideoWriter_fourcc(*'mp4v')\nout = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n\nwhile cap.isOpened():\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    # Preprocess Data\n    input_data = cv2.resize(frame, (input_details[0]['shape'][1], input_details[0]['shape'][2]))\n    input_data = np.expand_dims(input_data, axis=0)\n\n    # Quantization Handling\n    floating_model = (input_details[0]['dtype'] == np.float32)\n    if floating_model:\n        input_data = (np.float32(input_data) - 127.5) / 127.5\n\n    # Phase 3: Inference\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n    interpreter.invoke()\n\n    # Phase 4: Output Interpretation & Handling Loop\n    boxes = interpreter.get_tensor(output_details[0]['index'])[0]\n    classes = interpreter.get_tensor(output_details[1]['index'])[0]\n    scores = interpreter.get_tensor(output_details[2]['index'])[0]\n    num_detections = int(interpreter.get_tensor(output_details[3]['index']))\n\n    # Interpret Results\n    for i in range(num_detections):\n        if scores[i] > 0.5:\n            ymin, xmin, ymax, xmax = boxes[i]\n            (left, right, top, bottom) = (xmin * width, xmax * width,\n                                          ymin * height, ymax * height)\n            cv2.rectangle(frame, (int(left), int(top)), (int(right), int(bottom)), (0, 255, 0), 2)\n            label = f'{labels[int(classes[i])]}: {scores[i]:.2f}'\n            cv2.putText(frame, label, (int(left), int(top) - 10),\n                        cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n\n    # Handle Output\n    out.write(frame)\n\n# Phase 5: Cleanup\ncap.release()\nout.release()\ncv2.destroyAllWindows()"
      },
      "session_id": "qwen2.5-coder:32b_1974_tpusg_batch",
      "metadata": {
        "num_run": 9
      },
      "tags": [
        "benchmark",
        "qwen2.5-coder:32b",
        "tpu_sketch_generator"
      ],
      "latency": 169.631,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-09-16-41-331068_chatcmpl-c399713c-9404-4457-b32a-41061d26fcd5",
          "traceId": "18296e38",
          "type": "GENERATION",
          "name": "1829_tpusg_gen_attempt#1",
          "startTime": "2025-07-30T06:16:41.331000+00:00",
          "endTime": "2025-07-30T06:17:15.977000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 34646.0,
          "environment": "default",
          "promptTokens": 1833,
          "completionTokens": 822,
          "totalTokens": 2655,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-09-17-24-320906_chatcmpl-2af4ebab-1519-4f7b-8ec3-1010c6d6e9a4",
          "traceId": "18296e38",
          "type": "GENERATION",
          "name": "1829_tpusg_gen_attempt#2",
          "startTime": "2025-07-30T06:17:24.320000+00:00",
          "endTime": "2025-07-30T06:18:07.783000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 43463.0,
          "environment": "default",
          "promptTokens": 2048,
          "completionTokens": 1065,
          "totalTokens": 3113,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-09-18-07-790935_chatcmpl-2cee2ea5-7948-429d-86ee-c95ca3864a22",
          "traceId": "18296e38",
          "type": "GENERATION",
          "name": "1829_tpusg_gen_attempt#3",
          "startTime": "2025-07-30T06:18:07.790000+00:00",
          "endTime": "2025-07-30T06:18:43.654000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 35864.0,
          "environment": "default",
          "promptTokens": 1990,
          "completionTokens": 868,
          "totalTokens": 2858,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-09-18-51-687444_chatcmpl-e8ac1c8d-65cd-4c62-9297-fc09d0db27c8",
          "traceId": "18296e38",
          "type": "GENERATION",
          "name": "1829_tpusg_gen_attempt#4",
          "startTime": "2025-07-30T06:18:51.687000+00:00",
          "endTime": "2025-07-30T06:19:30.962000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 39275.0,
          "environment": "default",
          "promptTokens": 2048,
          "completionTokens": 958,
          "totalTokens": 3006,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        }
      ],
      "createdAt": "2025-07-30T06:16:41.847Z",
      "updatedAt": "2025-07-30T06:20:29.123Z",
      "environment": "default"
    },
    {
      "id": "eb354546",
      "timestamp": "2025-07-30T06:12:48.745000+00:00",
      "name": "eb35_tpu_sketch_generator",
      "input": null,
      "output": {
        "status": "success",
        "sketch": "import numpy as np\nfrom PIL import Image\nimport cv2\n\n# Phase 1: Setup\ntry:\n    from tflite_runtime.interpreter import Interpreter, load_delegate\nexcept ImportError:\n    from tensorflow.lite import Interpreter\n    from tensorflow.lite.experimental import load_delegate\n\n# Paths/Parameters\nmodel_path  = \"/home/mendel/tinyml_autopilot/models/edgetpu_detect.tflite\"\ninput_path  = \"/home/mendel/tinyml_autopilot/data//sheeps.mp4\"\nlabel_path  = \"/home/mendel/tinyml_autopilot/models/labelmap.txt\"\noutput_path  = \"/home/mendel/tinyml_autopilot/results/sheeps_detections.mp4\"\n\n# Load Labels (Conditional)\nwith open(label_path, 'r') as f:\n    labels = [line.strip() for line in f.readlines()]\n\n# Load Interpreter with EdgeTPU\ntry:\n    interpreter = Interpreter(model_path=model_path, experimental_delegates=[load_delegate('libedgetpu.so.1.0')])\nexcept Exception as e:\n    interpreter = Interpreter(model_path=model_path, experimental_delegates=[load_delegate('/usr/lib/aarch64-linux-gnu/libedgetpu.so.1.0')])\n\ninterpreter.allocate_tensors()\n\n# Get Model Details\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\n\n# Phase 2: Input Acquisition & Preprocessing Loop\ncap = cv2.VideoCapture(input_path)\nwidth = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\nheight = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\nfps = cap.get(cv2.CAP_PROP_FPS)\n\nfourcc = cv2.VideoWriter_fourcc(*'mp4v')\nout = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n\nwhile cap.isOpened():\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    # Preprocess Data\n    input_data = cv2.resize(frame, (input_details[0]['shape'][1], input_details[0]['shape'][2]))\n    input_data = np.expand_dims(input_data, axis=0)\n\n    # Quantization Handling\n    floating_model = (input_details[0]['dtype'] == np.float32)\n    if floating_model:\n        input_data = (np.float32(input_data) - 127.5) / 127.5\n\n    # Phase 3: Inference\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n    interpreter.invoke()\n\n    # Phase 4: Output Interpretation & Handling Loop\n    boxes = interpreter.get_tensor(output_details[0]['index'])[0]\n    classes = interpreter.get_tensor(output_details[1]['index'])[0]\n    scores = interpreter.get_tensor(output_details[2]['index'])[0]\n    num_detections = int(interpreter.get_tensor(output_details[3]['index']))\n\n    # Interpret Results\n    for i in range(num_detections):\n        if scores[i] > 0.5:\n            ymin, xmin, ymax, xmax = boxes[i]\n            (left, right, top, bottom) = (xmin * width, xmax * width,\n                                          ymin * height, ymax * height)\n            cv2.rectangle(frame, (int(left), int(top)), (int(right), int(bottom)), (0, 255, 0), 2)\n            label = f'{labels[int(classes[i])]}: {scores[i]:.2f}'\n            cv2.putText(frame, label, (int(left), int(top) - 10),\n                        cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n\n    # Handle Output\n    out.write(frame)\n\n# Phase 5: Cleanup\ncap.release()\nout.release()\ncv2.destroyAllWindows()"
      },
      "session_id": "qwen2.5-coder:32b_1974_tpusg_batch",
      "metadata": {
        "num_run": 8
      },
      "tags": [
        "benchmark",
        "qwen2.5-coder:32b",
        "tpu_sketch_generator"
      ],
      "latency": 173.902,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-09-12-48-746915_chatcmpl-0b05186d-a513-4b05-87be-b96207008569",
          "traceId": "eb354546",
          "type": "GENERATION",
          "name": "eb35_tpusg_gen_attempt#1",
          "startTime": "2025-07-30T06:12:48.746000+00:00",
          "endTime": "2025-07-30T06:13:22.835000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 34089.0,
          "environment": "default",
          "promptTokens": 1833,
          "completionTokens": 822,
          "totalTokens": 2655,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-09-13-31-340449_chatcmpl-5f4dbc03-93b7-4468-a38a-8c982dfbba0e",
          "traceId": "eb354546",
          "type": "GENERATION",
          "name": "eb35_tpusg_gen_attempt#2",
          "startTime": "2025-07-30T06:13:31.340000+00:00",
          "endTime": "2025-07-30T06:14:19.106000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 47766.0,
          "environment": "default",
          "promptTokens": 2048,
          "completionTokens": 1172,
          "totalTokens": 3220,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-09-14-19-112956_chatcmpl-f8c27a37-d59d-42db-808c-6b80ab5f6d4b",
          "traceId": "eb354546",
          "type": "GENERATION",
          "name": "eb35_tpusg_gen_attempt#3",
          "startTime": "2025-07-30T06:14:19.112000+00:00",
          "endTime": "2025-07-30T06:14:55.201000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 36089.0,
          "environment": "default",
          "promptTokens": 1990,
          "completionTokens": 868,
          "totalTokens": 2858,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-09-15-03-253547_chatcmpl-582f9a79-41ca-4273-8bbc-d25248e0f8cf",
          "traceId": "eb354546",
          "type": "GENERATION",
          "name": "eb35_tpusg_gen_attempt#4",
          "startTime": "2025-07-30T06:15:03.253000+00:00",
          "endTime": "2025-07-30T06:15:42.648000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 39395.0,
          "environment": "default",
          "promptTokens": 2048,
          "completionTokens": 958,
          "totalTokens": 3006,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        }
      ],
      "createdAt": "2025-07-30T06:12:49.265Z",
      "updatedAt": "2025-07-30T06:16:40.520Z",
      "environment": "default"
    },
    {
      "id": "0410ae45",
      "timestamp": "2025-07-30T06:08:43.199000+00:00",
      "name": "0410_tpu_sketch_generator",
      "input": null,
      "output": {
        "status": "failed",
        "last_code": "import numpy as np\nfrom tflite_runtime.interpreter import Interpreter, load_delegate\n\n# Phase 1: Setup\nmodel_path  = \"/home/mendel/tinyml_autopilot/models/edgetpu_detect.tflite\"\nlabel_path  = \"/home/mendel/tinyml_autopilot/models/labelmap.txt\"\ninput_path  = \"/home/mendel/tinyml_autopilot/data//sheeps.mp4\"\noutput_path  = \"/home/mendel/tinyml_autopilot/results/sheeps_detections.mp4\"\nconfidence_threshold  = 0.5\n\n# Load labels\nwith open(label_path, 'r') as f:\n    labels = [line.strip() for line in f.readlines()]\n\n# Load Interpreter with EdgeTPU\ntry:\n    interpreter = Interpreter(model_path=model_path,\n                              experimental_delegates=[load_delegate('libedgetpu.so.1.0')])\nexcept Exception as e:\n    print(f\"Failed to load libedgetpu.so.1.0: {e}\")\n    try:\n        interpreter = Interpreter(model_path=model_path,\n                                  experimental_delegates=[load_delegate('/usr/lib/aarch64-linux-gnu/libedgetpu.so.1.0')])\n    except Exception as e:\n        print(f\"Failed to load /usr/lib/aarch64-linux-gnu/libedgetpu.so.1.0: {e}\")\n        raise\n\ninterpreter.allocate_tensors()\n\n# Get Model Details\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\n\nfloating_model = (input_details[0]['dtype'] == np.float32)\n\n# Phase 2: Input Acquisition & Preprocessing Loop\nimport cv2\n\ncap = cv2.VideoCapture(input_path)\nif not cap.isOpened():\n    raise IOError(\"Cannot open video file\")\n\nframe_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\nframe_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\nfps = cap.get(cv2.CAP_PROP_FPS)\n\nout = cv2.VideoWriter(output_path, cv2.VideoWriter_fourcc(*'mp4v'), fps, (frame_width, frame_height))\n\nwhile True:\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    # Preprocess Data\n    input_data = cv2.resize(frame, (input_details[0]['shape'][1], input_details[0]['shape'][2]))\n    input_data = np.expand_dims(input_data, axis=0)\n\n    if floating_model:\n        input_data = (np.float32(input_data) - 127.5) / 127.5\n\n    # Phase 3: Inference\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n    interpreter.invoke()\n\n    # Phase 4: Output Interpretation & Handling Loop\n    output_data = interpreter.get_tensor(output_details[0]['index'])\n    num_detections = int(interpreter.get_tensor(output_details[2]['index'])[0])  # Access the scalar value directly\n\n    for i in range(num_detections):\n        confidence = float(output_data[0][i][15])\n        if confidence > confidence_threshold:\n            ymin, xmin, ymax, xmax = output_data[0][i][:4]\n            (left, right, top, bottom) = (xmin * frame_width, xmax * frame_width,\n                                          ymin * frame_height, ymax * frame_height)\n\n            cv2.rectangle(frame, (int(left), int(top)), (int(right), int(bottom)), (0, 255, 0), 2)\n            label = f\"{labels[int(output_data[0][i][14])]}: {confidence:.2f}\"\n            cv2.putText(frame, label, (int(left), int(top) - 10),\n                        cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n\n    # Handle Output\n    out.write(frame)\n\n# Phase 5: Cleanup\ncap.release()\nout.release()\ncv2.destroyAllWindows()",
        "last_error": "Traceback (most recent call last):\n  File \"script_d0f701b4_1753855954.py\", line 67, in <module>\n    num_detections = int(interpreter.get_tensor(output_details[2]['index'])[0])  # Access the scalar value directly\nTypeError: only size-1 arrays can be converted to Python scalars"
      },
      "session_id": "qwen2.5-coder:32b_1974_tpusg_batch",
      "metadata": {
        "num_run": 7
      },
      "tags": [
        "benchmark",
        "qwen2.5-coder:32b",
        "tpu_sketch_generator"
      ],
      "latency": 239.343,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-09-08-43-201076_chatcmpl-65767d38-d9a7-4123-b61a-9ded65112a1e",
          "traceId": "0410ae45",
          "type": "GENERATION",
          "name": "0410_tpusg_gen_attempt#1",
          "startTime": "2025-07-30T06:08:43.201000+00:00",
          "endTime": "2025-07-30T06:09:17.277000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 34076.0,
          "environment": "default",
          "promptTokens": 1833,
          "completionTokens": 822,
          "totalTokens": 2655,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-09-09-25-787317_chatcmpl-64fcf975-4957-4fb1-8802-3cfd1dbe0851",
          "traceId": "0410ae45",
          "type": "GENERATION",
          "name": "0410_tpusg_gen_attempt#2",
          "startTime": "2025-07-30T06:09:25.787000+00:00",
          "endTime": "2025-07-30T06:10:06.754000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 40967.0,
          "environment": "default",
          "promptTokens": 2048,
          "completionTokens": 1001,
          "totalTokens": 3049,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-09-10-15-251159_chatcmpl-41155ade-1409-41a9-a4bf-9f6d6fca7750",
          "traceId": "0410ae45",
          "type": "GENERATION",
          "name": "0410_tpusg_gen_attempt#3",
          "startTime": "2025-07-30T06:10:15.251000+00:00",
          "endTime": "2025-07-30T06:10:55.359000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 40108.0,
          "environment": "default",
          "promptTokens": 2048,
          "completionTokens": 977,
          "totalTokens": 3025,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-09-11-03-984622_chatcmpl-40cb8810-8aa7-4f8c-a4c7-5288ea772f0f",
          "traceId": "0410ae45",
          "type": "GENERATION",
          "name": "0410_tpusg_gen_attempt#4",
          "startTime": "2025-07-30T06:11:03.984000+00:00",
          "endTime": "2025-07-30T06:11:45.923000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 41939.0,
          "environment": "default",
          "promptTokens": 2048,
          "completionTokens": 1027,
          "totalTokens": 3075,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-09-11-54-366980_chatcmpl-b8440c61-dd3a-41b1-816f-5f287b7dcde8",
          "traceId": "0410ae45",
          "type": "GENERATION",
          "name": "0410_tpusg_gen_attempt#5",
          "startTime": "2025-07-30T06:11:54.366000+00:00",
          "endTime": "2025-07-30T06:12:34.090000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 39724.0,
          "environment": "default",
          "promptTokens": 2048,
          "completionTokens": 970,
          "totalTokens": 3018,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "690934cc-4515-4bfe-9c01-0f53c4dbd2b4",
          "traceId": "0410ae45",
          "type": "SPAN",
          "name": "error_04_tpusg_failure_signal_tpu_sketch_generator",
          "startTime": "2025-07-30T06:12:42.544000+00:00",
          "level": "ERROR",
          "statusMessage": "Failed. Last error: Traceback (most recent call last):\n  File \"script_d0f701b4_1753855954.py\", line 67, in <module>\n    num_detections = int(interpreter.get_tensor(output_details[2]['index'])[0])  # Access the scalar value directly\nTypeError: only size-1 arrays can be converted to Python scalars",
          "calculatedTotalCost": 0.0,
          "environment": "default",
          "promptTokens": 0,
          "completionTokens": 0,
          "totalTokens": 0,
          "costDetails": {},
          "endTime": null,
          "model": null,
          "modelParameters": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null,
          "latency": null
        }
      ],
      "createdAt": "2025-07-30T06:08:43.719Z",
      "updatedAt": "2025-07-30T06:12:47.914Z",
      "environment": "default"
    },
    {
      "id": "c9bd32c6",
      "timestamp": "2025-07-30T06:03:57.627000+00:00",
      "name": "c9bd_tpu_sketch_generator",
      "input": null,
      "output": {
        "status": "failed",
        "last_code": "import numpy as np\nfrom tflite_runtime.interpreter import Interpreter, load_delegate\nimport cv2\n\n# Phase 1: Setup\nmodel_path  = \"/home/mendel/tinyml_autopilot/models/edgetpu_detect.tflite\"\nlabel_path  = \"/home/mendel/tinyml_autopilot/models/labelmap.txt\"\ninput_path  = \"/home/mendel/tinyml_autopilot/data//sheeps.mp4\"\noutput_path  = \"/home/mendel/tinyml_autopilot/results/sheeps_detections.mp4\"\nconfidence_threshold  = 0.5\n\n# Load labels\nwith open(label_path, 'r') as f:\n    labels = [line.strip() for line in f.readlines()]\n\n# Load Interpreter with EdgeTPU\ntry:\n    interpreter = Interpreter(model_path=model_path,\n                              experimental_delegates=[load_delegate('libedgetpu.so.1.0')])\nexcept Exception as e:\n    print(f\"Failed to load libedgetpu.so.1.0: {e}\")\n    try:\n        interpreter = Interpreter(model_path=model_path,\n                                  experimental_delegates=[load_delegate('/usr/lib/aarch64-linux-gnu/libedgetpu.so.1.0')])\n    except Exception as e:\n        print(f\"Failed to load /usr/lib/aarch64-linux-gnu/libedgetpu.so.1.0: {e}\")\n        raise\n\ninterpreter.allocate_tensors()\n\n# Get Model Details\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\n\nfloating_model = (input_details[0]['dtype'] == np.float32)\n\n# Phase 2: Input Acquisition & Preprocessing Loop\ncap = cv2.VideoCapture(input_path)\nif not cap.isOpened():\n    raise IOError(\"Cannot open video file\")\n\nframe_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\nframe_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\nfps = cap.get(cv2.CAP_PROP_FPS)\n\nout = cv2.VideoWriter(output_path, cv2.VideoWriter_fourcc(*'mp4v'), fps, (frame_width, frame_height))\n\nwhile True:\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    # Preprocess Data\n    input_data = cv2.resize(frame, (input_details[0]['shape'][1], input_details[0]['shape'][2]))\n    input_data = np.expand_dims(input_data, axis=0)\n\n    if floating_model:\n        input_data = (np.float32(input_data) - 127.5) / 127.5\n\n    # Phase 3: Inference\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n    interpreter.invoke()\n\n    # Phase 4: Output Interpretation & Handling Loop\n    output_data = interpreter.get_tensor(output_details[0]['index'])\n    num_detections = int(interpreter.get_tensor(output_details[2]['index'])[0])  # Extract the scalar value\n\n    print(f\"Output Data Shape: {output_data.shape}\")\n    print(f\"Number of Detections Tensor Shape: {interpreter.get_tensor(output_details[2]['index']).shape}\")\n\n    for i in range(num_detections):\n        confidence = float(output_data[0][i][15])\n        if confidence > confidence_threshold:\n            ymin, xmin, ymax, xmax = output_data[0][i][:4]\n            (left, right, top, bottom) = (xmin * frame_width, xmax * frame_width,\n                                          ymin * frame_height, ymax * frame_height)\n\n            cv2.rectangle(frame, (int(left), int(top)), (int(right), int(bottom)), (0, 255, 0), 2)\n            label = f\"{labels[int(output_data[0][i][14])]}: {confidence:.2f}\"\n            cv2.putText(frame, label, (int(left), int(top) - 10),\n                        cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n\n    # Handle Output\n    out.write(frame)\n\n# Phase 5: Cleanup\ncap.release()\nout.release()\ncv2.destroyAllWindows()",
        "last_error": "Traceback (most recent call last):\n  File \"script_212c41ea_1753855708.py\", line 66, in <module>\n    num_detections = int(interpreter.get_tensor(output_details[2]['index'])[0])  # Extract the scalar value\nTypeError: only size-1 arrays can be converted to Python scalars"
      },
      "session_id": "qwen2.5-coder:32b_1974_tpusg_batch",
      "metadata": {
        "num_run": 6
      },
      "tags": [
        "benchmark",
        "qwen2.5-coder:32b",
        "tpu_sketch_generator"
      ],
      "latency": 279.462,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-09-03-57-628572_chatcmpl-455e73d1-a07b-40fc-921b-7e8e09da2d4b",
          "traceId": "c9bd32c6",
          "type": "GENERATION",
          "name": "c9bd_tpusg_gen_attempt#1",
          "startTime": "2025-07-30T06:03:57.628000+00:00",
          "endTime": "2025-07-30T06:04:31.713000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 34085.0,
          "environment": "default",
          "promptTokens": 1833,
          "completionTokens": 822,
          "totalTokens": 2655,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-09-04-40-231791_chatcmpl-0e632bba-046d-49ba-a221-fbe846d542e4",
          "traceId": "c9bd32c6",
          "type": "GENERATION",
          "name": "c9bd_tpusg_gen_attempt#2",
          "startTime": "2025-07-30T06:04:40.231000+00:00",
          "endTime": "2025-07-30T06:05:25.016000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 44785.0,
          "environment": "default",
          "promptTokens": 2048,
          "completionTokens": 1104,
          "totalTokens": 3152,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-09-05-33-488987_chatcmpl-819e8def-8af4-4caa-9181-674f8238dc6b",
          "traceId": "c9bd32c6",
          "type": "GENERATION",
          "name": "c9bd_tpusg_gen_attempt#3",
          "startTime": "2025-07-30T06:05:33.488000+00:00",
          "endTime": "2025-07-30T06:06:16.601000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 43113.0,
          "environment": "default",
          "promptTokens": 2048,
          "completionTokens": 1059,
          "totalTokens": 3107,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-09-06-25-144452_chatcmpl-4ae7dbfa-61e9-42e4-ae39-637d24a8133c",
          "traceId": "c9bd32c6",
          "type": "GENERATION",
          "name": "c9bd_tpusg_gen_attempt#4",
          "startTime": "2025-07-30T06:06:25.144000+00:00",
          "endTime": "2025-07-30T06:07:39.336000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 74192.0,
          "environment": "default",
          "promptTokens": 2048,
          "completionTokens": 1891,
          "totalTokens": 3939,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-09-07-47-804574_chatcmpl-dd720ea2-7b72-4f48-9ed3-58c971909eaa",
          "traceId": "c9bd32c6",
          "type": "GENERATION",
          "name": "c9bd_tpusg_gen_attempt#5",
          "startTime": "2025-07-30T06:07:47.804000+00:00",
          "endTime": "2025-07-30T06:08:28.569000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 40765.0,
          "environment": "default",
          "promptTokens": 2048,
          "completionTokens": 997,
          "totalTokens": 3045,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "2cac57bd-a653-407f-959c-fab0d538ac11",
          "traceId": "c9bd32c6",
          "type": "SPAN",
          "name": "error_c9_tpusg_failure_signal_tpu_sketch_generator",
          "startTime": "2025-07-30T06:08:37.090000+00:00",
          "level": "ERROR",
          "statusMessage": "Failed. Last error: Traceback (most recent call last):\n  File \"script_212c41ea_1753855708.py\", line 66, in <module>\n    num_detections = int(interpreter.get_tensor(output_details[2]['index'])[0])  # Extract the scalar value\nTypeError: only size-1 arrays can be converted to Python scalars",
          "calculatedTotalCost": 0.0,
          "environment": "default",
          "promptTokens": 0,
          "completionTokens": 0,
          "totalTokens": 0,
          "costDetails": {},
          "endTime": null,
          "model": null,
          "modelParameters": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null,
          "latency": null
        }
      ],
      "createdAt": "2025-07-30T06:03:58.147Z",
      "updatedAt": "2025-07-30T06:08:42.339Z",
      "environment": "default"
    },
    {
      "id": "987e6621",
      "timestamp": "2025-07-30T06:00:35.024000+00:00",
      "name": "987e_tpu_sketch_generator",
      "input": null,
      "output": {
        "status": "success",
        "sketch": "import numpy as np\nfrom tflite_runtime.interpreter import Interpreter, load_delegate\nimport cv2\n\n# Phase 1: Setup\nmodel_path  = \"/home/mendel/tinyml_autopilot/models/edgetpu_detect.tflite\"\nlabel_path  = \"/home/mendel/tinyml_autopilot/models/labelmap.txt\"\ninput_path  = \"/home/mendel/tinyml_autopilot/data//sheeps.mp4\"\noutput_path  = \"/home/mendel/tinyml_autopilot/results/sheeps_detections.mp4\"\nconfidence_threshold  = 0.5\n\n# Load labels\nwith open(label_path, 'r') as f:\n    labels = [line.strip() for line in f.readlines()]\n\n# Load Interpreter with EdgeTPU\ntry:\n    interpreter = Interpreter(model_path=model_path,\n                              experimental_delegates=[load_delegate('libedgetpu.so.1.0')])\nexcept Exception as e:\n    print(f\"Failed to load libedgetpu.so.1.0: {e}\")\n    try:\n        interpreter = Interpreter(model_path=model_path,\n                                  experimental_delegates=[load_delegate('/usr/lib/aarch64-linux-gnu/libedgetpu.so.1.0')])\n    except Exception as e:\n        print(f\"Failed to load /usr/lib/aarch64-linux-gnu/libedgetpu.so.1.0: {e}\")\n        raise\n\ninterpreter.allocate_tensors()\n\n# Get Model Details\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\n\nfloating_model = (input_details[0]['dtype'] == np.float32)\n\n# Phase 2: Input Acquisition & Preprocessing Loop\ncap = cv2.VideoCapture(input_path)\nif not cap.isOpened():\n    raise IOError(\"Cannot open video file\")\n\nframe_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\nframe_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\nfps = cap.get(cv2.CAP_PROP_FPS)\n\nout = cv2.VideoWriter(output_path, cv2.VideoWriter_fourcc(*'mp4v'), fps, (frame_width, frame_height))\n\nwhile True:\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    # Preprocess Data\n    input_data = cv2.resize(frame, (input_details[0]['shape'][1], input_details[0]['shape'][2]))\n    input_data = np.expand_dims(input_data, axis=0)\n\n    if floating_model:\n        input_data = (np.float32(input_data) - 127.5) / 127.5\n\n    # Phase 3: Inference\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n    interpreter.invoke()\n\n    # Phase 4: Output Interpretation & Handling Loop\n    boxes = interpreter.get_tensor(output_details[0]['index'])[0]\n    class_ids = interpreter.get_tensor(output_details[1]['index'])[0]\n    scores = interpreter.get_tensor(output_details[2]['index'])[0]\n    num_detections = int(interpreter.get_tensor(output_details[3]['index']))  # Correctly access the number of detections\n\n    for i in range(num_detections):\n        confidence = float(scores[i])\n        if confidence > confidence_threshold:\n            ymin, xmin, ymax, xmax = boxes[i]\n            (left, right, top, bottom) = (xmin * frame_width, xmax * frame_width,\n                                          ymin * frame_height, ymax * frame_height)\n\n            cv2.rectangle(frame, (int(left), int(top)), (int(right), int(bottom)), (0, 255, 0), 2)\n            label = f\"{labels[int(class_ids[i])]}: {confidence:.2f}\"\n            cv2.putText(frame, label, (int(left), int(top) - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (36, 255, 12), 2)\n\n    # Write the frame to the output video\n    out.write(frame)\n\n# Release resources\ncap.release()\nout.release()\ncv2.destroyAllWindows()"
      },
      "session_id": "qwen2.5-coder:32b_1974_tpusg_batch",
      "metadata": {
        "num_run": 5
      },
      "tags": [
        "benchmark",
        "qwen2.5-coder:32b",
        "tpu_sketch_generator"
      ],
      "latency": 144.106,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-09-00-35-026354_chatcmpl-7a987ae7-47ea-48a9-8eed-55c0e802861e",
          "traceId": "987e6621",
          "type": "GENERATION",
          "name": "987e_tpusg_gen_attempt#1",
          "startTime": "2025-07-30T06:00:35.026000+00:00",
          "endTime": "2025-07-30T06:01:10.823000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 35797.0,
          "environment": "default",
          "promptTokens": 1833,
          "completionTokens": 822,
          "totalTokens": 2655,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-09-01-19-382587_chatcmpl-d784f029-0267-4c56-982e-029c8a53acaf",
          "traceId": "987e6621",
          "type": "GENERATION",
          "name": "987e_tpusg_gen_attempt#2",
          "startTime": "2025-07-30T06:01:19.382000+00:00",
          "endTime": "2025-07-30T06:02:01.655000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 42273.0,
          "environment": "default",
          "promptTokens": 2048,
          "completionTokens": 1035,
          "totalTokens": 3083,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-09-02-10-086103_chatcmpl-44cc81fd-e1cb-4a97-9720-30e8f479c405",
          "traceId": "987e6621",
          "type": "GENERATION",
          "name": "987e_tpusg_gen_attempt#3",
          "startTime": "2025-07-30T06:02:10.086000+00:00",
          "endTime": "2025-07-30T06:02:59.132000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 49046.0,
          "environment": "default",
          "promptTokens": 2048,
          "completionTokens": 1219,
          "totalTokens": 3267,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        }
      ],
      "createdAt": "2025-07-30T06:00:35.544Z",
      "updatedAt": "2025-07-30T06:03:56.825Z",
      "environment": "default"
    },
    {
      "id": "bf2bc90f",
      "timestamp": "2025-07-30T05:57:14.377000+00:00",
      "name": "bf2b_tpu_sketch_generator",
      "input": null,
      "output": {
        "status": "success",
        "sketch": "import numpy as np\nfrom tflite_runtime.interpreter import Interpreter, load_delegate\nimport cv2\n\n# Phase 1: Setup\nmodel_path  = \"/home/mendel/tinyml_autopilot/models/edgetpu_detect.tflite\"\nlabel_path  = \"/home/mendel/tinyml_autopilot/models/labelmap.txt\"\ninput_path  = \"/home/mendel/tinyml_autopilot/data//sheeps.mp4\"\noutput_path  = \"/home/mendel/tinyml_autopilot/results/sheeps_detections.mp4\"\nconfidence_threshold  = 0.5\n\n# Load labels\nwith open(label_path, 'r') as f:\n    labels = [line.strip() for line in f.readlines()]\n\n# Load Interpreter with EdgeTPU\ntry:\n    interpreter = Interpreter(model_path=model_path,\n                              experimental_delegates=[load_delegate('libedgetpu.so.1.0')])\nexcept Exception as e:\n    print(f\"Failed to load libedgetpu.so.1.0: {e}\")\n    try:\n        interpreter = Interpreter(model_path=model_path,\n                                  experimental_delegates=[load_delegate('/usr/lib/aarch64-linux-gnu/libedgetpu.so.1.0')])\n    except Exception as e:\n        print(f\"Failed to load /usr/lib/aarch64-linux-gnu/libedgetpu.so.1.0: {e}\")\n        raise\n\ninterpreter.allocate_tensors()\n\n# Get Model Details\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\n\nfloating_model = (input_details[0]['dtype'] == np.float32)\n\n# Phase 2: Input Acquisition & Preprocessing Loop\ncap = cv2.VideoCapture(input_path)\nif not cap.isOpened():\n    raise IOError(\"Cannot open video file\")\n\nframe_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\nframe_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\nfps = cap.get(cv2.CAP_PROP_FPS)\n\nout = cv2.VideoWriter(output_path, cv2.VideoWriter_fourcc(*'mp4v'), fps, (frame_width, frame_height))\n\nwhile True:\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    # Preprocess Data\n    input_data = cv2.resize(frame, (input_details[0]['shape'][1], input_details[0]['shape'][2]))\n    input_data = np.expand_dims(input_data, axis=0)\n\n    if floating_model:\n        input_data = (np.float32(input_data) - 127.5) / 127.5\n\n    # Phase 3: Inference\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n    interpreter.invoke()\n\n    # Phase 4: Output Interpretation & Handling Loop\n    boxes = interpreter.get_tensor(output_details[0]['index'])\n    classes = interpreter.get_tensor(output_details[1]['index'])\n    scores = interpreter.get_tensor(output_details[2]['index'])\n    num_detections = int(interpreter.get_tensor(output_details[3]['index']))\n\n    for i in range(num_detections):\n        confidence = float(scores[0][i])\n        if confidence > confidence_threshold:\n            class_id = int(classes[0][i])\n            label = labels[class_id]\n            box = boxes[0][i] * np.array([frame_height, frame_width, frame_height, frame_width])\n\n            y_min, x_min, y_max, x_max = box.astype(int)\n            cv2.rectangle(frame, (x_min, y_min), (x_max, y_max), (10, 255, 0), 2)\n            label_text = f'{label}: {confidence:.2f}'\n            cv2.putText(frame, label_text, (x_min, y_min - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (36, 255, 12), 2)\n\n    # Handle Output\n    out.write(frame)\n\n# Phase 5: Cleanup\ncap.release()\nout.release()\ncv2.destroyAllWindows()"
      },
      "session_id": "qwen2.5-coder:32b_1974_tpusg_batch",
      "metadata": {
        "num_run": 4
      },
      "tags": [
        "benchmark",
        "qwen2.5-coder:32b",
        "tpu_sketch_generator"
      ],
      "latency": 142.377,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-08-57-14-378578_chatcmpl-367e1299-6be5-4fd0-81c7-52d148aaf595",
          "traceId": "bf2bc90f",
          "type": "GENERATION",
          "name": "bf2b_tpusg_gen_attempt#1",
          "startTime": "2025-07-30T05:57:14.378000+00:00",
          "endTime": "2025-07-30T05:57:48.684000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 34306.0,
          "environment": "default",
          "promptTokens": 1833,
          "completionTokens": 829,
          "totalTokens": 2662,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-08-57-57-149855_chatcmpl-7e2b1aad-8fce-4f3e-89d9-ca073cd4513c",
          "traceId": "bf2bc90f",
          "type": "GENERATION",
          "name": "bf2b_tpusg_gen_attempt#2",
          "startTime": "2025-07-30T05:57:57.149000+00:00",
          "endTime": "2025-07-30T05:58:45.323000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 48174.0,
          "environment": "default",
          "promptTokens": 2048,
          "completionTokens": 1156,
          "totalTokens": 3204,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-08-58-54-143084_chatcmpl-d4af3ded-4d37-4bc9-9aef-4f0023125e9e",
          "traceId": "bf2bc90f",
          "type": "GENERATION",
          "name": "bf2b_tpusg_gen_attempt#3",
          "startTime": "2025-07-30T05:58:54.143000+00:00",
          "endTime": "2025-07-30T05:59:36.755000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 42612.0,
          "environment": "default",
          "promptTokens": 2048,
          "completionTokens": 1033,
          "totalTokens": 3081,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        }
      ],
      "createdAt": "2025-07-30T05:57:14.896Z",
      "updatedAt": "2025-07-30T06:00:34.715Z",
      "environment": "default"
    },
    {
      "id": "c0698d45",
      "timestamp": "2025-07-30T05:52:31.727000+00:00",
      "name": "c069_tpu_sketch_generator",
      "input": null,
      "output": {
        "status": "failed",
        "last_code": "import numpy as np\nfrom tflite_runtime.interpreter import Interpreter, load_delegate\nimport cv2\n\n# Phase 1: Setup\nmodel_path  = \"/home/mendel/tinyml_autopilot/models/edgetpu_detect.tflite\"\nlabel_path  = \"/home/mendel/tinyml_autopilot/models/labelmap.txt\"\ninput_path  = \"/home/mendel/tinyml_autopilot/data//sheeps.mp4\"\noutput_path  = \"/home/mendel/tinyml_autopilot/results/sheeps_detections.mp4\"\nconfidence_threshold  = 0.5\n\n# Load labels\nwith open(label_path, 'r') as f:\n    labels = [line.strip() for line in f.readlines()]\n\n# Load Interpreter with EdgeTPU\ntry:\n    interpreter = Interpreter(model_path=model_path,\n                              experimental_delegates=[load_delegate('libedgetpu.so.1.0')])\nexcept Exception as e:\n    print(f\"Failed to load libedgetpu.so.1.0: {e}\")\n    try:\n        interpreter = Interpreter(model_path=model_path,\n                                  experimental_delegates=[load_delegate('/usr/lib/aarch64-linux-gnu/libedgetpu.so.1.0')])\n    except Exception as e:\n        print(f\"Failed to load /usr/lib/aarch64-linux-gnu/libedgetpu.so.1.0: {e}\")\n        raise\n\ninterpreter.allocate_tensors()\n\n# Get Model Details\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\n\nfloating_model = (input_details[0]['dtype'] == np.float32)\n\n# Phase 2: Input Acquisition & Preprocessing Loop\ncap = cv2.VideoCapture(input_path)\nif not cap.isOpened():\n    raise IOError(\"Cannot open video file\")\n\nframe_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\nframe_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\nfps = cap.get(cv2.CAP_PROP_FPS)\n\nout = cv2.VideoWriter(output_path, cv2.VideoWriter_fourcc(*'mp4v'), fps, (frame_width, frame_height))\n\nwhile True:\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    # Preprocess Data\n    input_data = cv2.resize(frame, (input_details[0]['shape'][1], input_details[0]['shape'][2]))\n    input_data = np.expand_dims(input_data, axis=0)\n\n    if floating_model:\n        input_data = (np.float32(input_data) - 127.5) / 127.5\n\n    # Phase 3: Inference\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n    interpreter.invoke()\n\n    # Phase 4: Output Interpretation & Handling Loop\n    output_data = interpreter.get_tensor(output_details[0]['index'])\n    num_detections = int(interpreter.get_tensor(output_details[2]['index'])[0])  # Extract the single element\n\n    for i in range(num_detections):\n        confidence = float(output_data[0][i][15])\n        if confidence > confidence_threshold:\n            ymin, xmin, ymax, xmax = output_data[0][i][:4]\n            (left, right, top, bottom) = (xmin * frame_width, xmax * frame_width,\n                                          ymin * frame_height, ymax * frame_height)\n\n            cv2.rectangle(frame, (int(left), int(top)), (int(right), int(bottom)), (0, 255, 0), 2)\n            label = f\"{labels[int(output_data[0][i][14])]}: {confidence:.2f}\"\n            cv2.putText(frame, label, (int(left), int(top) - 10),\n                        cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n\n    # Handle Output\n    out.write(frame)\n\n# Phase 5: Cleanup\ncap.release()\nout.release()\ncv2.destroyAllWindows()",
        "last_error": "Traceback (most recent call last):\n  File \"script_f91ac5c7_1753855020.py\", line 66, in <module>\n    num_detections = int(interpreter.get_tensor(output_details[2]['index'])[0])  # Extract the single element\nTypeError: only size-1 arrays can be converted to Python scalars"
      },
      "session_id": "qwen2.5-coder:32b_1974_tpusg_batch",
      "metadata": {
        "num_run": 3
      },
      "tags": [
        "benchmark",
        "qwen2.5-coder:32b",
        "tpu_sketch_generator"
      ],
      "latency": 277.011,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-08-52-31-729069_chatcmpl-4d193cff-92ff-47d4-a57f-327b61de3873",
          "traceId": "c0698d45",
          "type": "GENERATION",
          "name": "c069_tpusg_gen_attempt#1",
          "startTime": "2025-07-30T05:52:31.729000+00:00",
          "endTime": "2025-07-30T05:53:05.828000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 34099.0,
          "environment": "default",
          "promptTokens": 1833,
          "completionTokens": 822,
          "totalTokens": 2655,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-08-53-14-429912_chatcmpl-766b6c8d-9a68-4f80-8640-8ec6f57a160a",
          "traceId": "c0698d45",
          "type": "GENERATION",
          "name": "c069_tpusg_gen_attempt#2",
          "startTime": "2025-07-30T05:53:14.429000+00:00",
          "endTime": "2025-07-30T05:53:56.082000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 41653.0,
          "environment": "default",
          "promptTokens": 2048,
          "completionTokens": 1021,
          "totalTokens": 3069,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-08-54-04-715423_chatcmpl-b205e297-1bf0-464d-a2e5-9e2b2ae68057",
          "traceId": "c0698d45",
          "type": "GENERATION",
          "name": "c069_tpusg_gen_attempt#3",
          "startTime": "2025-07-30T05:54:04.715000+00:00",
          "endTime": "2025-07-30T05:55:15.805000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 71090.0,
          "environment": "default",
          "promptTokens": 2048,
          "completionTokens": 1810,
          "totalTokens": 3858,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-08-55-24-356806_chatcmpl-21c5aa22-db9e-4b49-9081-76b88cb0ffb4",
          "traceId": "c0698d45",
          "type": "GENERATION",
          "name": "c069_tpusg_gen_attempt#4",
          "startTime": "2025-07-30T05:55:24.356000+00:00",
          "endTime": "2025-07-30T05:56:07.690000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 43334.0,
          "environment": "default",
          "promptTokens": 2048,
          "completionTokens": 1067,
          "totalTokens": 3115,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-08-56-16-234807_chatcmpl-f4cebba9-046d-4f58-a9bb-c5e2b5fa7be7",
          "traceId": "c0698d45",
          "type": "GENERATION",
          "name": "c069_tpusg_gen_attempt#5",
          "startTime": "2025-07-30T05:56:16.234000+00:00",
          "endTime": "2025-07-30T05:57:00.174000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 43940.0,
          "environment": "default",
          "promptTokens": 2048,
          "completionTokens": 1082,
          "totalTokens": 3130,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "5c7a3eca-1bc3-4ad6-b411-3d715f5a3ea0",
          "traceId": "c0698d45",
          "type": "SPAN",
          "name": "error_c0_tpusg_failure_signal_tpu_sketch_generator",
          "startTime": "2025-07-30T05:57:08.740000+00:00",
          "level": "ERROR",
          "statusMessage": "Failed. Last error: Traceback (most recent call last):\n  File \"script_f91ac5c7_1753855020.py\", line 66, in <module>\n    num_detections = int(interpreter.get_tensor(output_details[2]['index'])[0])  # Extract the single element\nTypeError: only size-1 arrays can be converted to Python scalars",
          "calculatedTotalCost": 0.0,
          "environment": "default",
          "promptTokens": 0,
          "completionTokens": 0,
          "totalTokens": 0,
          "costDetails": {},
          "endTime": null,
          "model": null,
          "modelParameters": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null,
          "latency": null
        }
      ],
      "createdAt": "2025-07-30T05:52:32.246Z",
      "updatedAt": "2025-07-30T05:57:14.007Z",
      "environment": "default"
    },
    {
      "id": "c017cb4c",
      "timestamp": "2025-07-30T05:49:13.820000+00:00",
      "name": "c017_tpu_sketch_generator",
      "input": null,
      "output": {
        "status": "success",
        "sketch": "import numpy as np\nfrom tflite_runtime.interpreter import Interpreter, load_delegate\nimport cv2\n\n# Phase 1: Setup\nmodel_path  = \"/home/mendel/tinyml_autopilot/models/edgetpu_detect.tflite\"\nlabel_path  = \"/home/mendel/tinyml_autopilot/models/labelmap.txt\"\ninput_path  = \"/home/mendel/tinyml_autopilot/data//sheeps.mp4\"\noutput_path  = \"/home/mendel/tinyml_autopilot/results/sheeps_detections.mp4\"\nconfidence_threshold  = 0.5\n\n# Load labels\nwith open(label_path, 'r') as f:\n    labels = [line.strip() for line in f.readlines()]\n\n# Load Interpreter with EdgeTPU\ntry:\n    interpreter = Interpreter(model_path=model_path,\n                              experimental_delegates=[load_delegate('libedgetpu.so.1.0')])\nexcept Exception as e:\n    print(f\"Failed to load libedgetpu.so.1.0: {e}\")\n    try:\n        interpreter = Interpreter(model_path=model_path,\n                                  experimental_delegates=[load_delegate('/usr/lib/aarch64-linux-gnu/libedgetpu.so.1.0')])\n    except Exception as e:\n        print(f\"Failed to load /usr/lib/aarch64-linux-gnu/libedgetpu.so.1.0: {e}\")\n        raise\n\ninterpreter.allocate_tensors()\n\n# Get Model Details\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\n\nfloating_model = (input_details[0]['dtype'] == np.float32)\n\n# Phase 2: Input Acquisition & Preprocessing Loop\ncap = cv2.VideoCapture(input_path)\nif not cap.isOpened():\n    raise IOError(\"Cannot open video file\")\n\nframe_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\nframe_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\nfps = cap.get(cv2.CAP_PROP_FPS)\n\nout = cv2.VideoWriter(output_path, cv2.VideoWriter_fourcc(*'mp4v'), fps, (frame_width, frame_height))\n\nwhile True:\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    # Preprocess Data\n    input_data = cv2.resize(frame, (input_details[0]['shape'][1], input_details[0]['shape'][2]))\n    input_data = np.expand_dims(input_data, axis=0)\n\n    if floating_model:\n        input_data = (np.float32(input_data) - 127.5) / 127.5\n\n    # Phase 3: Inference\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n    interpreter.invoke()\n\n    # Phase 4: Output Interpretation & Handling Loop\n    boxes = interpreter.get_tensor(output_details[0]['index'])[0]\n    classes = interpreter.get_tensor(output_details[1]['index'])[0]\n    scores = interpreter.get_tensor(output_details[2]['index'])[0]\n\n    for i in range(len(scores)):\n        confidence = float(scores[i])\n        if confidence > confidence_threshold:\n            ymin, xmin, ymax, xmax = boxes[i]\n            (left, right, top, bottom) = (xmin * frame_width, xmax * frame_width,\n                                          ymin * frame_height, ymax * frame_height)\n\n            cv2.rectangle(frame, (int(left), int(top)), (int(right), int(bottom)), (0, 255, 0), 2)\n            label = f\"{labels[int(classes[i])]}: {confidence:.2f}\"\n            cv2.putText(frame, label, (int(left), int(top) - 10),\n                        cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n\n    # Handle Output\n    out.write(frame)\n\n# Phase 5: Cleanup\ncap.release()\nout.release()\ncv2.destroyAllWindows()"
      },
      "session_id": "qwen2.5-coder:32b_1974_tpusg_batch",
      "metadata": {
        "num_run": 2
      },
      "tags": [
        "benchmark",
        "qwen2.5-coder:32b",
        "tpu_sketch_generator"
      ],
      "latency": 138.561,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-08-49-13-821670_chatcmpl-6754a09f-c910-4151-a33c-c8a20ddfcb0e",
          "traceId": "c017cb4c",
          "type": "GENERATION",
          "name": "c017_tpusg_gen_attempt#1",
          "startTime": "2025-07-30T05:49:13.821000+00:00",
          "endTime": "2025-07-30T05:49:48.123000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 34302.0,
          "environment": "default",
          "promptTokens": 1833,
          "completionTokens": 822,
          "totalTokens": 2655,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-08-49-57-166860_chatcmpl-c164b72c-2598-4b0b-b722-a63473899815",
          "traceId": "c017cb4c",
          "type": "GENERATION",
          "name": "c017_tpusg_gen_attempt#2",
          "startTime": "2025-07-30T05:49:57.166000+00:00",
          "endTime": "2025-07-30T05:50:39.374000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 42208.0,
          "environment": "default",
          "promptTokens": 2048,
          "completionTokens": 1033,
          "totalTokens": 3081,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-08-50-48-433638_chatcmpl-1653815d-6f8d-462f-bdb5-0338fac4bf46",
          "traceId": "c017cb4c",
          "type": "GENERATION",
          "name": "c017_tpusg_gen_attempt#3",
          "startTime": "2025-07-30T05:50:48.433000+00:00",
          "endTime": "2025-07-30T05:51:32.382000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 43949.0,
          "environment": "default",
          "promptTokens": 2048,
          "completionTokens": 1082,
          "totalTokens": 3130,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        }
      ],
      "createdAt": "2025-07-30T05:49:14.340Z",
      "updatedAt": "2025-07-30T05:52:30.604Z",
      "environment": "default"
    },
    {
      "id": "6f6d9769",
      "timestamp": "2025-07-30T05:44:27.633000+00:00",
      "name": "6f6d_tpu_sketch_generator",
      "input": null,
      "output": {
        "status": "failed",
        "last_code": "import numpy as np\nfrom tflite_runtime.interpreter import Interpreter, load_delegate\nimport cv2\n\n# Phase 1: Setup\nmodel_path  = \"/home/mendel/tinyml_autopilot/models/edgetpu_detect.tflite\"\nlabel_path  = \"/home/mendel/tinyml_autopilot/models/labelmap.txt\"\ninput_path  = \"/home/mendel/tinyml_autopilot/data//sheeps.mp4\"\noutput_path  = \"/home/mendel/tinyml_autopilot/results/sheeps_detections.mp4\"\nconfidence_threshold  = 0.5\n\n# Load labels\nwith open(label_path, 'r') as f:\n    labels = [line.strip() for line in f.readlines()]\n\n# Load Interpreter with EdgeTPU\ntry:\n    interpreter = Interpreter(model_path=model_path,\n                              experimental_delegates=[load_delegate('libedgetpu.so.1.0')])\nexcept Exception as e:\n    print(f\"Failed to load libedgetpu.so.1.0: {e}\")\n    try:\n        interpreter = Interpreter(model_path=model_path,\n                                  experimental_delegates=[load_delegate('/usr/lib/aarch64-linux-gnu/libedgetpu.so.1.0')])\n    except Exception as e:\n        print(f\"Failed to load /usr/lib/aarch64-linux-gnu/libedgetpu.so.1.0: {e}\")\n        raise\n\ninterpreter.allocate_tensors()\n\n# Get Model Details\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\n\nfloating_model = (input_details[0]['dtype'] == np.float32)\n\n# Phase 2: Input Acquisition & Preprocessing Loop\ncap = cv2.VideoCapture(input_path)\nif not cap.isOpened():\n    raise IOError(\"Cannot open video file\")\n\nframe_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\nframe_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\nfps = cap.get(cv2.CAP_PROP_FPS)\n\nout = cv2.VideoWriter(output_path, cv2.VideoWriter_fourcc(*'mp4v'), fps, (frame_width, frame_height))\n\nwhile True:\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    # Preprocess Data\n    input_data = cv2.resize(frame, (input_details[0]['shape'][1], input_details[0]['shape'][2]))\n    input_data = np.expand_dims(input_data, axis=0)\n\n    if floating_model:\n        input_data = (np.float32(input_data) - 127.5) / 127.5\n\n    # Phase 3: Inference\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n    interpreter.invoke()\n\n    # Phase 4: Output Interpretation & Handling Loop\n    output_data = interpreter.get_tensor(output_details[0]['index'])\n    num_detections = int(interpreter.get_tensor(output_details[2]['index'])[0])  # Extract the single element\n\n    for i in range(num_detections):\n        confidence = float(output_data[0][i][15])\n        if confidence > confidence_threshold:\n            ymin, xmin, ymax, xmax = output_data[0][i][:4]\n            (left, right, top, bottom) = (xmin * frame_width, xmax * frame_width,\n                                          ymin * frame_height, ymax * frame_height)\n\n            cv2.rectangle(frame, (int(left), int(top)), (int(right), int(bottom)), (0, 255, 0), 2)\n            label = f\"{labels[int(output_data[0][i][14])]}: {confidence:.2f}\"\n            cv2.putText(frame, label, (int(left), int(top) - 10),\n                        cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n\n    # Handle Output\n    out.write(frame)\n\n# Phase 5: Cleanup\ncap.release()\nout.release()\ncv2.destroyAllWindows()",
        "last_error": "Traceback (most recent call last):\n  File \"script_46a346d5_1753854539.py\", line 66, in <module>\n    num_detections = int(interpreter.get_tensor(output_details[2]['index'])[0])  # Extract the single element\nTypeError: only size-1 arrays can be converted to Python scalars"
      },
      "session_id": "qwen2.5-coder:32b_1974_tpusg_batch",
      "metadata": {
        "num_run": 1
      },
      "tags": [
        "benchmark",
        "qwen2.5-coder:32b",
        "tpu_sketch_generator"
      ],
      "latency": 280.805,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-08-44-27-634644_chatcmpl-7ad138a1-b99c-4d98-9c79-e46768c01297",
          "traceId": "6f6d9769",
          "type": "GENERATION",
          "name": "6f6d_tpusg_gen_attempt#1",
          "startTime": "2025-07-30T05:44:27.634000+00:00",
          "endTime": "2025-07-30T05:45:39.554000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 71920.0,
          "environment": "default",
          "promptTokens": 1833,
          "completionTokens": 822,
          "totalTokens": 2655,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-08-45-48-274759_chatcmpl-1bff1d0a-8f8a-4743-a0f5-f181f86c8c01",
          "traceId": "6f6d9769",
          "type": "GENERATION",
          "name": "6f6d_tpusg_gen_attempt#2",
          "startTime": "2025-07-30T05:45:48.274000+00:00",
          "endTime": "2025-07-30T05:46:29.925000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 41651.0,
          "environment": "default",
          "promptTokens": 2048,
          "completionTokens": 1021,
          "totalTokens": 3069,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-08-46-38-746417_chatcmpl-efc16674-b72b-4b6e-b4d9-c67cab8fc214",
          "traceId": "6f6d9769",
          "type": "GENERATION",
          "name": "6f6d_tpusg_gen_attempt#3",
          "startTime": "2025-07-30T05:46:38.746000+00:00",
          "endTime": "2025-07-30T05:47:22.120000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 43374.0,
          "environment": "default",
          "promptTokens": 2048,
          "completionTokens": 1067,
          "totalTokens": 3115,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-08-47-31-098029_chatcmpl-9cc744a2-befc-4c6b-868c-7fcc4231cd42",
          "traceId": "6f6d9769",
          "type": "GENERATION",
          "name": "6f6d_tpusg_gen_attempt#4",
          "startTime": "2025-07-30T05:47:31.098000+00:00",
          "endTime": "2025-07-30T05:48:10.916000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 39818.0,
          "environment": "default",
          "promptTokens": 2048,
          "completionTokens": 971,
          "totalTokens": 3019,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-08-48-19-806223_chatcmpl-12696ac6-a79e-43db-afbb-be5c0c4b3ff9",
          "traceId": "6f6d9769",
          "type": "GENERATION",
          "name": "6f6d_tpusg_gen_attempt#5",
          "startTime": "2025-07-30T05:48:19.806000+00:00",
          "endTime": "2025-07-30T05:48:59.566000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 39760.0,
          "environment": "default",
          "promptTokens": 2048,
          "completionTokens": 971,
          "totalTokens": 3019,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "d2032f48-0590-4710-9ae5-d7a669521bf6",
          "traceId": "6f6d9769",
          "type": "SPAN",
          "name": "error_6f_tpusg_failure_signal_tpu_sketch_generator",
          "startTime": "2025-07-30T05:49:08.439000+00:00",
          "level": "ERROR",
          "statusMessage": "Failed. Last error: Traceback (most recent call last):\n  File \"script_46a346d5_1753854539.py\", line 66, in <module>\n    num_detections = int(interpreter.get_tensor(output_details[2]['index'])[0])  # Extract the single element\nTypeError: only size-1 arrays can be converted to Python scalars",
          "calculatedTotalCost": 0.0,
          "environment": "default",
          "promptTokens": 0,
          "completionTokens": 0,
          "totalTokens": 0,
          "costDetails": {},
          "endTime": null,
          "model": null,
          "modelParameters": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null,
          "latency": null
        }
      ],
      "createdAt": "2025-07-30T05:44:28.152Z",
      "updatedAt": "2025-07-30T05:49:13.911Z",
      "environment": "default"
    }
  ],
  "meta": {
    "total_items": 30
  }
}
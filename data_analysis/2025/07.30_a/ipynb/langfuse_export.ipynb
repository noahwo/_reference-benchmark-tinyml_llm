{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setting up\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ref: https://langfuse.com/docs/query-traces\n",
    "import os\n",
    "import json\n",
    "from langfuse import Langfuse\n",
    "import json\n",
    "import os\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "LOCAL_HOST = True\n",
    "\n",
    "\"\"\"Define session_id\"\"\"\n",
    "# session_id=\"qwen2.5-coder_f4d4_dp_batch\"\n",
    "session_id_list = [\n",
    "    # \"qwen2.5-coder:32b_4e11_tpsg_batch\",\n",
    "    # \"qwen2.5-coder:32b_ae24_tpsg_batch\"\n",
    "    \"qwen2.5-coder:14b_85a9_tpusg_batch\",\n",
    "    \"qwen2.5-coder:14b_85a9_psg_batch\"\n",
    "]\n",
    "\n",
    "\n",
    "\"\"\"Define paths\"\"\"\n",
    " \n",
    "parent_dir = os.path.dirname(os.getcwd())\n",
    "\n",
    " \n",
    "# date = os.path.basename(parent_dir)\n",
    "tex_dir = os.path.join(parent_dir, \"tex\")\n",
    "processed_data_dir = os.path.join(parent_dir, \"processed_data\")\n",
    "raw_export_dir = os.path.join(parent_dir, \"raw_export\")\n",
    "ipynb_dir = os.path.join(parent_dir, \"ipynb\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Export raw data\n",
    "\n",
    "Langfuse added a limit of 20 API invocations per minute. https://langfuse.com/faq/all/api-limits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching traces for session qwen2.5-coder:14b_85a9_tpusg_batch...\n",
      "Fetching observation data for time-18-46-29-691709_chatcmpl-45838e77-f685-4705-95d7-a8de40a2b290...\n",
      "Fetching observation data for time-18-44-37-156139_chatcmpl-1ef5e061-01a1-432f-8080-f276a900da74...\n",
      "Fetching observation data for time-18-45-05-484561_chatcmpl-78837052-3ce5-46a9-89aa-2334e4f3b763...\n",
      "Fetching observation data for time-18-43-19-619447_chatcmpl-4cba1fe1-ee8b-42c8-9bb0-3b266e7cda7b...\n",
      "Fetching observation data for time-18-41-01-055237_chatcmpl-9ad6e67a-f2ac-4f65-bafd-76fc6221eaee...\n",
      "Fetching observation data for time-18-41-28-109778_chatcmpl-63db544b-705c-4d73-b4f4-9dcc06b80f5a...\n",
      "Fetching observation data for time-18-41-58-710098_chatcmpl-166e5d70-a778-4c04-b997-d27e20ba157e...\n",
      "Fetching observation data for time-18-39-11-541985_chatcmpl-8bf6a755-24d1-4cce-81b5-fee518e48c73...\n",
      "Fetching observation data for time-18-39-40-178007_chatcmpl-7aa4e3cc-168c-479f-b263-581595958251...\n",
      "Fetching observation data for time-18-37-52-489176_chatcmpl-595456d8-d3f2-45cb-8b63-a90a077eae64...\n",
      "Fetching observation data for time-18-36-04-987520_chatcmpl-7aa81455-77d7-4d42-8210-a3ad3b53a6ed...\n",
      "Fetching observation data for time-18-36-32-884449_chatcmpl-cd23986f-9d6a-4634-b840-1099956b3b08...\n",
      "Fetching observation data for time-18-34-14-380181_chatcmpl-633361cc-e7cd-49be-921c-8f88807b681d...\n",
      "Fetching observation data for time-18-34-42-821264_chatcmpl-0521a7eb-7c99-4bca-956a-b19db40ae602...\n",
      "Fetching observation data for time-18-31-39-840040_chatcmpl-068ea04c-7c02-4470-9370-2a975eae5c10...\n",
      "Fetching observation data for time-18-32-04-361572_chatcmpl-7ae7d916-91fc-4a3d-b6fc-c9e48e2c6947...\n",
      "Fetching observation data for time-18-32-41-114288_chatcmpl-823404e2-1b23-4d0c-a6a4-81eee0ab29f2...\n",
      "Fetching observation data for time-18-33-08-201671_chatcmpl-12305fa5-602e-49e8-a44f-267b5e9084dd...\n",
      "Fetching observation data for time-18-33-37-812541_chatcmpl-70e346aa-4049-4545-b90f-0e64221ca289...\n",
      "Fetching observation data for f49198a1-d3b3-4e6b-a7e6-481a3c2d78c3...\n",
      "Fetching observation data for time-18-30-24-860481_chatcmpl-978738ba-b911-4587-9a80-e3859cef0e13...\n",
      "Fetching observation data for time-18-29-09-286195_chatcmpl-de5e7974-6ecc-40e8-aaa0-0f96d714e513...\n",
      "Fetching observation data for time-18-27-47-777570_chatcmpl-ea6af001-d120-436e-a0f6-04cf51189c85...\n",
      "Fetching observation data for time-18-25-54-257502_chatcmpl-2e4b199d-c04e-4a0c-8e09-6378aa90c547...\n",
      "Fetching observation data for time-18-26-24-108938_chatcmpl-275fd583-d915-4f33-9d36-22845a2132b0...\n",
      "Fetching observation data for time-18-23-18-736314_chatcmpl-428f400d-27f7-4f94-8b8f-a0f3b9608fa1...\n",
      "Fetching observation data for time-18-23-45-684283_chatcmpl-ed865c50-e98c-4b76-9bec-cf11b7149118...\n",
      "Fetching observation data for time-18-24-15-033886_chatcmpl-bf923a7c-122e-45a6-9f14-b22ffc7fafb9...\n",
      "Fetching observation data for time-18-24-45-341850_chatcmpl-40df46d2-b864-4a69-9733-e9adb2c21f5d...\n",
      "Fetching observation data for time-18-25-16-818223_chatcmpl-5dd58976-9ef4-4ecc-87d9-5e0d144d9e26...\n",
      "Fetching observation data for 9af30348-cb8d-45b6-a8df-606dca8c1f53...\n",
      "Fetching observation data for time-18-21-58-184701_chatcmpl-d4abcc4d-10e4-4063-8575-090fedf1fdbe...\n",
      "Fetching observation data for time-18-19-10-451608_chatcmpl-56e73516-ee51-40b0-9e3d-b5175e59dcd1...\n",
      "Fetching observation data for time-18-20-01-691886_chatcmpl-d6cc7bea-12bd-44fe-b2f0-677799b2e957...\n",
      "Fetching observation data for time-18-20-35-533645_chatcmpl-1c592ecf-583d-4977-8557-05a8f2074a76...\n",
      "Fetching observation data for a19bb9aa-7e96-45f0-a03e-d6975f5de022...\n",
      "Fetching observation data for d3904792-6b1d-4c61-80f7-35aa38737ea4...\n",
      "Fetching observation data for 5b2466a6-7831-47d8-be1b-d0ca3ae9f22b...\n",
      "Fetching observation data for d135a782-5156-4b9d-ac1c-25a1a1fd03d9...\n",
      "Fetching observation data for b66e2b8e-acf6-4f66-b260-a4661eee2127...\n",
      "Fetching observation data for a227dd3e-36ac-4928-aa7d-90d13b507f25...\n",
      "Fetching observation data for a221f67f-a427-44ec-a674-7952e8ab6318...\n",
      "Fetching observation data for dc01f79c-a687-4e0f-a992-0a9151f01cfe...\n",
      "Fetching observation data for 91c12b3e-3d58-4c46-a0c5-a451dbd7a27c...\n",
      "Fetching observation data for 476da73c-777e-4a78-b35e-be2bb6563eed...\n",
      "Fetching observation data for c8e42544-ba72-47de-8860-ff25dbe428b4...\n",
      "Fetching observation data for 5c65bace-33b6-4a89-ab6c-1951b8a0026f...\n",
      "Fetching observation data for 5acb6134-c7af-4725-86a9-bc5d9cb708f3...\n",
      "Fetching observation data for ce260d12-a730-470a-8d43-5fc77ae544ea...\n",
      "Raw JSON saved to: /Users/hann/Projects/reference-benchmark-tinyml_llm/data_analysis/07.30_a/raw_export/raw_qwen2.5-coder:14b_85a9_tpusg_batch.json\n",
      "Fetching traces for session qwen2.5-coder:14b_85a9_psg_batch...\n",
      "Fetching observation data for time-19-22-46-050785_chatcmpl-882d6e1d-c67e-44e8-9061-795aeb837f35...\n",
      "Fetching observation data for time-19-23-00-914714_chatcmpl-a1012ba0-4917-4080-ae87-19f0ecef1d2a...\n",
      "Fetching observation data for time-19-23-10-966285_chatcmpl-71541781-eec5-40ea-9221-89549ee409e4...\n",
      "Fetching observation data for time-19-23-20-134840_chatcmpl-8db82f0b-47fe-4542-8169-9bd3d2c3aac8...\n",
      "Fetching observation data for time-19-23-35-542646_chatcmpl-58853374-fb90-413a-a187-9baaf6376587...\n",
      "Fetching observation data for 6c5147e6-e45f-4b42-bfd2-68c1b429041a...\n",
      "Fetching observation data for time-19-21-20-023351_chatcmpl-f8835944-1db4-40d9-8e23-94cc4a39c818...\n",
      "Fetching observation data for time-19-21-34-630916_chatcmpl-086e00f7-6b23-4e65-b4ce-def8f1fb0006...\n",
      "Fetching observation data for time-19-21-48-929082_chatcmpl-b5f5b20f-71ba-4d4d-88ee-c8c4f02d156a...\n",
      "Fetching observation data for time-19-22-04-732236_chatcmpl-d737fc39-962d-42af-b184-107136c36bdf...\n",
      "Fetching observation data for time-19-22-23-077362_chatcmpl-afad86ce-5cce-441c-be32-c995d132b124...\n",
      "Fetching observation data for 577bcc09-4c2e-44d7-8fa6-a272853fee36...\n",
      "Fetching observation data for time-19-20-01-437738_chatcmpl-b12192e6-1836-4b81-8714-331ef5982e10...\n",
      "Fetching observation data for time-19-20-16-812922_chatcmpl-f61eb098-cd9f-440a-a51d-2d4bae121ef1...\n",
      "Fetching observation data for time-19-20-31-200040_chatcmpl-8d28c7e7-2475-47fd-a2de-73e48a9a70c9...\n",
      "Fetching observation data for time-19-20-45-488126_chatcmpl-a2fb5b7a-9871-4acd-a2d4-770766b18958...\n",
      "Fetching observation data for time-19-21-02-147172_chatcmpl-dcaae6cb-379b-4dc8-8dd5-f4bdfa912dbd...\n",
      "Fetching observation data for 72c45b12-456c-49f9-ac21-a6a2138ced7d...\n",
      "Fetching observation data for time-19-18-40-883001_chatcmpl-e28c6721-87fc-4e0a-aa51-949ff8f45f99...\n",
      "Fetching observation data for time-19-18-58-356680_chatcmpl-8dfbb70c-0a9c-45cf-862a-1044a6a5e217...\n",
      "Fetching observation data for time-19-19-15-667510_chatcmpl-889cdab4-7c09-4238-bd45-a2d497e7c545...\n",
      "Fetching observation data for time-19-19-30-260610_chatcmpl-43dfb328-a019-4d22-95d9-d047f6bd5c69...\n",
      "Fetching observation data for time-19-19-40-311308_chatcmpl-fa03848f-b9a2-420c-8d76-3507acc03542...\n",
      "Fetching observation data for 3b8e58d4-8765-44e5-ba63-158718dd2d6d...\n",
      "Fetching observation data for time-19-17-26-261845_chatcmpl-1ec74de4-0499-4a32-a16e-a8763fca8b03...\n",
      "Fetching observation data for time-19-17-43-757742_chatcmpl-526a2d7e-21e1-4476-8ec1-0d6791e43a73...\n",
      "Fetching observation data for time-19-17-55-310427_chatcmpl-66dad086-f81e-4a05-923a-434e97611d62...\n",
      "Fetching observation data for time-19-18-07-411081_chatcmpl-2a3386e9-6354-4851-95c1-5e8a59a1c5fd...\n",
      "Fetching observation data for time-19-18-19-347140_chatcmpl-e68994ad-c755-4086-a9e2-33339039a9dc...\n",
      "Fetching observation data for 7dde1c66-4e9e-40c2-9589-c4a64df5ff75...\n",
      "Fetching observation data for time-19-16-09-611047_chatcmpl-f48c7b37-d0dc-46e4-bdd6-892979dc93ea...\n",
      "Fetching observation data for time-19-16-25-569555_chatcmpl-8cac55e8-74a8-480e-a8ba-4731d3e6cd06...\n",
      "Fetching observation data for time-19-16-38-351883_chatcmpl-761b6874-2b46-4ad3-9818-dd2d19e9f71e...\n",
      "Fetching observation data for time-19-16-52-232886_chatcmpl-f53a4759-bf5b-469d-ae4d-bcd831d8400a...\n",
      "Fetching observation data for time-19-17-04-548810_chatcmpl-bf60fbf0-90e3-4729-b97c-7b2205c88ade...\n",
      "Fetching observation data for 07bffde6-f319-4e65-9061-e2acffb25b4d...\n",
      "Fetching observation data for time-19-15-14-725790_chatcmpl-f1fd3f8e-ffc3-46a9-a9a7-d39108100678...\n",
      "Fetching observation data for time-19-13-57-575792_chatcmpl-f61fe286-c927-4978-a96d-0a2e52c8c289...\n",
      "Fetching observation data for time-19-14-12-472523_chatcmpl-368a9913-2e86-4308-882f-831f864fa333...\n",
      "Fetching observation data for time-19-14-25-657491_chatcmpl-53df7311-3b2e-432b-a0e2-aa562b5a3fd8...\n",
      "Fetching observation data for time-19-14-37-515228_chatcmpl-eb14a7dd-f863-4522-9116-7e61a8bf8401...\n",
      "Fetching observation data for time-19-14-51-396428_chatcmpl-e91ab278-564d-4f95-8651-af29103e476f...\n",
      "Fetching observation data for time-19-12-38-305716_chatcmpl-52f6c149-b12e-4808-b47c-2f87759b70ec...\n",
      "Fetching observation data for time-19-12-58-957547_chatcmpl-f507c8bd-ea1f-4cdb-aa30-f7e81b7208b2...\n",
      "Fetching observation data for time-19-13-08-784898_chatcmpl-d3da3160-203e-4816-8078-c37bc5e6bcd1...\n",
      "Fetching observation data for time-19-13-24-600162_chatcmpl-ac414fda-29a9-4e0d-b7c2-ac3d2d653351...\n",
      "Fetching observation data for time-19-13-38-956502_chatcmpl-9366b877-aed4-4104-9511-0c52bce86648...\n",
      "Fetching observation data for 58593237-efa5-4e53-8bb4-c4ab2707b7f3...\n",
      "Fetching observation data for time-19-11-22-816955_chatcmpl-186f5bb2-8e29-468a-85fc-85bc8cc8ec65...\n",
      "Fetching observation data for time-19-11-39-757108_chatcmpl-e9f67291-50cb-4830-8a99-b5de65f1b706...\n",
      "Fetching observation data for time-19-11-54-647738_chatcmpl-189e7e1f-d316-416b-9655-2cd12b74a08b...\n",
      "Fetching observation data for time-19-12-04-630139_chatcmpl-2d7378b1-755b-49aa-bb25-236c4224c1d0...\n",
      "Fetching observation data for time-19-12-14-129913_chatcmpl-af0b9b9c-8590-48d7-850f-05de1739eb8d...\n",
      "Fetching observation data for 03a9fae8-81aa-4aeb-91a5-ed0c43d7d591...\n",
      "Fetching observation data for time-19-10-16-238651_chatcmpl-7ccb8adc-f08e-46e6-a62c-bc541a3deef6...\n",
      "Fetching observation data for time-19-10-33-155839_chatcmpl-8a10ac63-88fa-4a42-a916-2258f64baddb...\n",
      "Fetching observation data for time-19-10-44-300534_chatcmpl-b3f4a289-278e-4462-aedf-38cbc974758e...\n",
      "Fetching observation data for time-19-10-54-132217_chatcmpl-9df4209a-2bee-4c20-acd7-646d31431a1a...\n",
      "Fetching observation data for time-19-11-07-378306_chatcmpl-de594a62-da45-4508-a87e-ec38809a62eb...\n",
      "Fetching observation data for dec6d68e-38ff-4a77-9fc2-f9e12b02faa6...\n",
      "Fetching observation data for time-19-08-54-712909_chatcmpl-196e806e-5b9c-4ac6-a7f5-069c4ef4503f...\n",
      "Fetching observation data for time-19-09-09-991207_chatcmpl-9fb89644-0965-4965-b012-7a63531856ba...\n",
      "Fetching observation data for time-19-09-22-120030_chatcmpl-9f78927a-c75a-484a-9626-297e4955f1a6...\n",
      "Fetching observation data for time-19-09-36-374919_chatcmpl-0c6d8a1a-1a2a-43c2-8d73-d2ee0e1c1ccd...\n",
      "Fetching observation data for time-19-09-51-791311_chatcmpl-7b15220c-585b-424a-a5b5-dcbe8b1ea614...\n",
      "Fetching observation data for 299eee22-7ca8-4380-8a92-7c5485d1cfab...\n",
      "Fetching observation data for time-19-07-33-193922_chatcmpl-69ad5311-3541-4c1f-a9d8-a136d4d104dd...\n",
      "Fetching observation data for time-19-07-52-461287_chatcmpl-70b9788b-8b86-4018-a8db-4847d2c72e78...\n",
      "Fetching observation data for time-19-08-06-889517_chatcmpl-1bce1caf-1b85-40b2-bd28-9f71f451ffd3...\n",
      "Fetching observation data for time-19-08-23-292368_chatcmpl-56ce5e88-dbf1-42da-a470-1927b4609021...\n",
      "Fetching observation data for time-19-08-36-518093_chatcmpl-b7437fe6-32a0-4270-94e2-042db514c745...\n",
      "Fetching observation data for 6f3921cd-406d-473b-a47b-5b7b61be632e...\n",
      "Fetching observation data for time-19-06-13-687663_chatcmpl-a45d5d14-ef0e-429f-8c7d-5a47922995a7...\n",
      "Fetching observation data for time-19-06-29-719669_chatcmpl-6f9cbf44-f6a5-4d6a-b447-be986de0c5be...\n",
      "Fetching observation data for time-19-06-39-720507_chatcmpl-37d4831a-9d72-4097-928e-88aa3e811e4a...\n",
      "Fetching observation data for time-19-05-20-222812_chatcmpl-69eef354-cc1f-47ce-9bf9-345172be0efe...\n",
      "Fetching observation data for time-19-04-09-677395_chatcmpl-93eadba8-480d-483a-87f2-15c714ef4e39...\n",
      "Fetching observation data for time-19-04-26-074680_chatcmpl-785ab46f-3bd2-4fe1-b5a4-def67bbd7ff4...\n",
      "Fetching observation data for time-19-04-39-025960_chatcmpl-22974876-e9ff-477c-a30a-f5165f0bd745...\n",
      "Fetching observation data for time-19-04-49-720850_chatcmpl-0832389a-12b4-43d5-8d76-3752da64f1a2...\n",
      "Fetching observation data for time-19-05-02-549833_chatcmpl-a92d8a87-140a-4fb3-9bf0-9f661953f31b...\n",
      "Fetching observation data for d7f9e603-8b0f-44d5-97a6-42ece4367e55...\n",
      "Fetching observation data for time-19-02-51-202476_chatcmpl-bf533948-5b50-42de-86a3-2c826739eb79...\n",
      "Fetching observation data for time-19-03-07-008856_chatcmpl-b685f26c-e057-49dc-9363-0d99cbb86e41...\n",
      "Fetching observation data for time-19-03-16-629016_chatcmpl-ed330345-6e5f-4c7f-a11e-cda5be38fd56...\n",
      "Fetching observation data for time-19-03-30-970993_chatcmpl-67b44c3d-ac5c-403f-b082-6bf90005d511...\n",
      "Fetching observation data for time-19-03-48-193159_chatcmpl-07496c7f-cac7-4341-8784-9c612fd25896...\n",
      "Fetching observation data for 75725491-a5e3-4794-8322-5bba7869dbb1...\n",
      "Fetching observation data for time-19-01-43-086991_chatcmpl-0a102ec4-6210-44e3-a532-ab7d1b0c6638...\n",
      "Fetching observation data for time-19-01-58-875924_chatcmpl-061f4e95-2148-418a-8cf4-81097ab7cddb...\n",
      "Fetching observation data for time-19-02-10-087963_chatcmpl-d65afd48-2842-457e-8580-2edcc2047080...\n",
      "Fetching observation data for time-19-02-19-472534_chatcmpl-0ab3998c-8041-454e-a25f-e77523f38153...\n",
      "Fetching observation data for time-19-02-31-453976_chatcmpl-88a53d9b-556e-4d35-a548-aeb54dee7867...\n",
      "Fetching observation data for 687f03f9-4e98-48ac-99d3-b1debc875b0f...\n",
      "Fetching observation data for time-19-00-28-573822_chatcmpl-7b91eba7-7641-4ab2-8665-140d27c7947e...\n",
      "Fetching observation data for time-19-00-45-937594_chatcmpl-e60f1e6e-89a2-484f-bd16-87ace1c72809...\n",
      "Fetching observation data for time-19-00-56-829834_chatcmpl-4c970371-b1b8-43cf-90ef-96826c472638...\n",
      "Fetching observation data for time-19-01-10-267985_chatcmpl-69a30345-b303-49cf-94e1-86011fbadfaa...\n",
      "Fetching observation data for time-19-01-25-765478_chatcmpl-bbb30bd3-7768-4951-8331-67a04fd5b06c...\n",
      "Fetching observation data for 41c42885-cc8f-4217-987e-29d8dde3dd6f...\n",
      "Fetching observation data for time-18-59-24-088985_chatcmpl-50390f58-3260-466a-8c66-72228a0b6649...\n",
      "Fetching observation data for time-18-59-39-940929_chatcmpl-c9d6ba2e-5f61-4e90-aa79-b594578e0c09...\n",
      "Fetching observation data for time-18-59-51-646280_chatcmpl-a180dc8b-ed91-4910-bf05-34e50311b325...\n",
      "Fetching observation data for time-19-00-00-471293_chatcmpl-83f48e56-0598-40f1-b325-092a552ecf34...\n",
      "Fetching observation data for time-19-00-10-443211_chatcmpl-5878c09f-240f-40e9-9498-6bf21dd24641...\n",
      "Fetching observation data for f98dc077-33af-4b8b-9697-d3e49cdb8ac0...\n",
      "Fetching observation data for time-18-58-29-606739_chatcmpl-c22acf5b-ff32-400f-aa31-273ed3d51b33...\n",
      "Fetching observation data for time-18-57-20-100735_chatcmpl-7efdefa9-178f-4a87-9b86-29857be6d15c...\n",
      "Fetching observation data for time-18-57-35-919313_chatcmpl-e54608a8-c80c-4689-9bac-7f1afb3f9077...\n",
      "Fetching observation data for time-18-57-45-276072_chatcmpl-85f15487-0cec-4f89-84e2-5ef24f5c7e66...\n",
      "Fetching observation data for time-18-57-58-377804_chatcmpl-685ed306-3e7f-4d00-ab1a-88d30f91eb57...\n",
      "Fetching observation data for time-18-58-08-281123_chatcmpl-157fc0a4-fa35-429f-91de-479e30c0f7da...\n",
      "Fetching observation data for adea4513-2656-4a0d-a463-491deac0dd34...\n",
      "Fetching observation data for time-18-56-03-119085_chatcmpl-0b54b4e1-ef4f-46dc-baf8-7cf90211218d...\n",
      "Fetching observation data for time-18-56-18-695144_chatcmpl-117fa9c6-237a-4146-ba21-f910c8509c28...\n",
      "Fetching observation data for time-18-56-33-689569_chatcmpl-2f9c2528-89e0-4b7a-b420-627c104c2c49...\n",
      "Fetching observation data for time-18-56-44-362351_chatcmpl-dd56f67d-f049-4bda-bcdb-fa65c9dae054...\n",
      "Fetching observation data for time-18-56-55-378584_chatcmpl-1c28ca93-cbab-41c6-9730-300e47e10687...\n",
      "Fetching observation data for cf3cee6e-46b1-4b00-bdfa-075410370c69...\n",
      "Fetching observation data for time-18-54-50-410275_chatcmpl-dfde7509-7697-4758-8fcd-4d8ddf625099...\n",
      "Fetching observation data for time-18-55-06-668395_chatcmpl-da02e023-b350-421e-93a1-369ebdb5d0e1...\n",
      "Fetching observation data for time-18-55-17-187617_chatcmpl-43baf456-61e5-443a-834d-e5886be45c6a...\n",
      "Fetching observation data for time-18-55-28-675753_chatcmpl-094b340a-1857-42ad-99b6-3a5b630cc8d0...\n",
      "Fetching observation data for time-18-55-39-322455_chatcmpl-69fccecf-0962-49d3-b5f1-bf3b05e507b3...\n",
      "Fetching observation data for time-18-53-29-773328_chatcmpl-8f71c354-7e18-4e5d-b8c3-f4a5c214e65c...\n",
      "Fetching observation data for time-18-53-45-963587_chatcmpl-eeb55cc0-2f9a-4250-8c39-fab7166d6d58...\n",
      "Fetching observation data for time-18-53-58-533932_chatcmpl-96a56648-a248-4e62-bb1d-0905e17078bf...\n",
      "Fetching observation data for time-18-54-13-847609_chatcmpl-2ab69d9d-a1b5-4c6e-aa8e-c8239681d2d4...\n",
      "Fetching observation data for time-18-54-28-561480_chatcmpl-92a68909-d880-439f-8144-3035ad17c1c8...\n",
      "Fetching observation data for fb587733-e607-4bb8-a08e-334f3f6e18e8...\n",
      "Fetching observation data for time-18-52-13-280106_chatcmpl-db26e8e1-6419-428c-9195-98fa5ef78862...\n",
      "Fetching observation data for time-18-52-29-869940_chatcmpl-5ee4a7ea-c67f-4e2b-a8d7-94af20730d72...\n",
      "Fetching observation data for time-18-52-42-627890_chatcmpl-c6177617-ed9b-45b0-b543-3967d5680e8b...\n",
      "Fetching observation data for time-18-52-53-638796_chatcmpl-17bd2ef1-9656-4bc0-89d9-812519bd38f8...\n",
      "Fetching observation data for time-18-53-07-442167_chatcmpl-af675d68-f36a-4328-9c7f-a6e2a2c4c784...\n",
      "Fetching observation data for d1d6b5d8-a020-43dd-bd81-13cefea8005d...\n",
      "Fetching observation data for time-18-51-21-781915_chatcmpl-4496f6f1-50af-40f9-81de-a729d82527ef...\n",
      "Fetching observation data for time-18-51-37-532067_chatcmpl-e71e4daf-0eb1-46dd-bc0f-7c475d428c2a...\n",
      "Fetching observation data for time-18-51-46-773583_chatcmpl-0fbf71c2-edf2-4644-bec1-6b146ce93154...\n",
      "Fetching observation data for time-18-50-29-294530_chatcmpl-b32b807a-382e-41b1-856e-d53591b20640...\n",
      "Fetching observation data for time-18-49-08-813141_chatcmpl-7fc60215-6a6b-4d01-a5d4-ee4c7de555d8...\n",
      "Fetching observation data for time-18-49-23-690581_chatcmpl-903252e4-8c98-4c0d-b636-4433534830e2...\n",
      "Fetching observation data for time-18-49-38-295133_chatcmpl-f01d5292-eb6d-4c33-816a-9073d3430f83...\n",
      "Fetching observation data for time-18-49-54-431917_chatcmpl-a26547de-1b6e-4c9b-b95f-51950850df81...\n",
      "Fetching observation data for time-18-50-10-293137_chatcmpl-d579a31a-be45-47cb-8635-94dd7e9cf339...\n",
      "Fetching observation data for 9e37aa51-54f2-4d22-beca-389cbb88b84a...\n",
      "Fetching observation data for time-18-47-50-205242_chatcmpl-d19e7984-9cf6-4c2e-8850-a0430c6012eb...\n",
      "Fetching observation data for time-18-48-09-363405_chatcmpl-3196e864-7712-48cd-b4d8-70a7efb2cdae...\n",
      "Fetching observation data for time-18-48-22-953095_chatcmpl-c0f16bf6-3535-4121-a9c4-c5fcee63e540...\n",
      "Fetching observation data for time-18-48-35-440164_chatcmpl-357232c7-14f4-4e9e-ba77-62831d23c4ec...\n",
      "Fetching observation data for time-18-48-47-345552_chatcmpl-ed376ce9-31ac-48f1-8a21-78c3c236ee0b...\n",
      "Fetching observation data for 60393b85-ae77-40cd-a61d-a634df5e9c50...\n",
      "Raw JSON saved to: /Users/hann/Projects/reference-benchmark-tinyml_llm/data_analysis/07.30_a/raw_export/raw_qwen2.5-coder:14b_85a9_psg_batch.json\n"
     ]
    }
   ],
   "source": [
    "# ALTERNATIVE TO 2.\n",
    "import os\n",
    "import json\n",
    "from time import sleep\n",
    "from langfuse import Langfuse\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "\n",
    "# LANGFUSE_SERVICE_PUBLIC_KEY = \"pk-lf-559a2c0f-ee29-4c32-944c-bf73b5f0ce28\"\n",
    "# LANGFUSE_SERVICE_SECRET_KEY = \"sk-lf-75f8bf7f-a5db-4756-b0dd-d758a2a292c8\"\n",
    "# LANGFUSE_SERVICE_HOST = \"https://langfuse.hann.fi\"\n",
    "\n",
    "\n",
    "if LOCAL_HOST:\n",
    "    langfuse = Langfuse(\n",
    "        secret_key=\"sk-lf-75f8bf7f-a5db-4756-b0dd-d758a2a292c8\",\n",
    "        public_key=\"pk-lf-559a2c0f-ee29-4c32-944c-bf73b5f0ce28\",\n",
    "        host=\"https://langfuse.hann.fi\",\n",
    "    )\n",
    "else:\n",
    "    langfuse = Langfuse(\n",
    "        secret_key=LANGFUSE_SERVICE_SECRET_KEY,\n",
    "        public_key=LANGFUSE_SERVICE_PUBLIC_KEY,\n",
    "        host=LANGFUSE_SERVICE_HOST,\n",
    "    )\n",
    "\n",
    "API_invok_count = 0\n",
    "query_range_num_run = {\"start\": 0, \"end\": 1}\n",
    "\n",
    "\n",
    "class CustomJSONEncoder(json.JSONEncoder):\n",
    "    def __init__(self, *args, LOCAL_HOST=True, **kwargs):\n",
    "        self.LOCAL_HOST = LOCAL_HOST\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "    def default(self, obj):\n",
    "        if isinstance(obj, datetime):\n",
    "            return obj.isoformat()\n",
    "        if hasattr(obj, \"__dict__\"):\n",
    "            data = obj.__dict__.copy()\n",
    "            if \"observations\" in data:\n",
    "                data[\"observations\"] = [\n",
    "                    fetch_observation_data(obs, self.LOCAL_HOST)\n",
    "                    for obs in data[\"observations\"]\n",
    "                ]\n",
    "\n",
    "            return data\n",
    "        return super().default(obj)\n",
    "\n",
    "\n",
    "def fetch_observation_data(observation_id, LOCAL_HOST):\n",
    "    \"\"\"\n",
    "    Fetches observation data from Langfuse and returns its dictionary representation.\n",
    "    \"\"\"\n",
    "    print(f\"Fetching observation data for {observation_id}...\")\n",
    "    global API_invok_count\n",
    "    if API_invok_count >= 0 and not LOCAL_HOST:\n",
    "        print(\"Waiting for 3 seconds to fetch observation data...\")\n",
    "        for _ in tqdm(range(3), desc=\"Progress\", unit=\"s\"):\n",
    "            sleep(1)\n",
    "        API_invok_count = 0\n",
    "\n",
    "    observation_response = langfuse.fetch_observation(observation_id)\n",
    "    API_invok_count += 1\n",
    "\n",
    "    return observation_response.data.dict()\n",
    "\n",
    "\n",
    "def fetch_and_save_complete_data(session_id_list, raw_export_dir, LOCAL_HOST):\n",
    "    \"\"\"\n",
    "    Fetches complete trace data for each session ID and saves it to JSON files.\n",
    "\n",
    "    Parameters:\n",
    "        session_id_list (list): List of session IDs to process.\n",
    "        raw_export_dir (str): Directory path to save raw JSON files.\n",
    "    \"\"\"\n",
    "\n",
    "    def save_complete_data(session_id):\n",
    "        global API_invok_count\n",
    "        if API_invok_count >= 0 and not LOCAL_HOST:\n",
    "            print(\"Waiting for 4 seconds to fetch traces...\")\n",
    "            for _ in tqdm(range(4), desc=\"Progress\", unit=\"s\"):\n",
    "                sleep(1)\n",
    "            API_invok_count = 0\n",
    "\n",
    "        fetch_traces_response = langfuse.fetch_traces(session_id=session_id)\n",
    "        API_invok_count += 1\n",
    "\n",
    "        print(f\"Fetching traces for session {session_id}...\")\n",
    "        # Create directories if they don't exist\n",
    "        os.makedirs(raw_export_dir, exist_ok=True)\n",
    "\n",
    "        # Save complete data to JSON file\n",
    "        # if session_id.startswith(\"da0a\"):\n",
    "        #     session_id = \"phi4_\" + session_id\n",
    "        if \"tpsg\" in session_id:\n",
    "            session_id_ = session_id.replace(\"tpsg\", \"tpusg\")\n",
    "        else:\n",
    "            session_id_ = session_id\n",
    "            \n",
    "        raw_path = os.path.join(raw_export_dir, f\"raw_{session_id_}.json\")\n",
    "        with open(raw_path, \"w\") as f:\n",
    "            json.dump(fetch_traces_response, f, cls=CustomJSONEncoder, indent=2)\n",
    "\n",
    "        print(f\"Raw JSON saved to: {raw_path}\")\n",
    "\n",
    "    for session_id in session_id_list:\n",
    "        save_complete_data(session_id)\n",
    "\n",
    "\n",
    "fetch_and_save_complete_data(session_id_list, raw_export_dir, LOCAL_HOST)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Trim data\n",
    "\n",
    "Here also intercept the runs with fatal errors that need to be excluded from the analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPAN error_51_tpusg_failure_signal_tpu_sketch_generator: Failed. Last error: OpenCV: FFMPEG: tag 0x44495658/'XVID' is not supported with codec id 12 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n",
      "OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n",
      "Traceback (most recent call last):\n",
      "  File \"script_13ea7ccf_1753889639.py\", line 66, in <module>\n",
      "    if scores[i] > 0.5:  # Confidence threshold\n",
      "ValueError: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()\n",
      "SPAN error_b5_tpusg_failure_signal_tpu_sketch_generator: Failed. Last error: OpenCV: FFMPEG: tag 0x44495658/'XVID' is not supported with codec id 12 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n",
      "OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n",
      "Traceback (most recent call last):\n",
      "  File \"script_6b23d452_1753889139.py\", line 72, in <module>\n",
      "    if scores[i] > confidence_threshold:\n",
      "ValueError: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()\n",
      "SPAN error_91_tpusg_failure_signal_tpu_sketch_generator: Failed. Last error: Unexpected error during generation: litellm.APIConnectionError: OllamaException - {\"error\":\"llama runner process has terminated: CUDA error\"}\n",
      "SPAN error_44_tpusg_failure_signal_tpu_sketch_generator: Failed. Last error: Unexpected error during generation: litellm.APIConnectionError: OllamaException - {\"error\":\"llama runner process has terminated: CUDA error\"}\n",
      "SPAN error_ce_tpusg_failure_signal_tpu_sketch_generator: Failed. Last error: Unexpected error during generation: litellm.APIConnectionError: OllamaException - {\"error\":\"llama runner process has terminated: CUDA error\"}\n",
      "SPAN error_fb_tpusg_failure_signal_tpu_sketch_generator: Failed. Last error: Unexpected error during generation: litellm.APIConnectionError: OllamaException - {\"error\":\"llama runner process has terminated: CUDA error\"}\n",
      "SPAN error_05_tpusg_failure_signal_tpu_sketch_generator: Failed. Last error: Unexpected error during generation: litellm.APIConnectionError: OllamaException - {\"error\":\"llama runner process has terminated: CUDA error\"}\n",
      "SPAN error_b0_tpusg_failure_signal_tpu_sketch_generator: Failed. Last error: Unexpected error during generation: litellm.APIConnectionError: OllamaException - {\"error\":\"llama runner process has terminated: CUDA error\"}\n",
      "SPAN error_36_tpusg_failure_signal_tpu_sketch_generator: Failed. Last error: Unexpected error during generation: litellm.APIConnectionError: OllamaException - {\"error\":\"llama runner process has terminated: CUDA error\"}\n",
      "SPAN error_90_tpusg_failure_signal_tpu_sketch_generator: Failed. Last error: Unexpected error during generation: litellm.APIConnectionError: OllamaException - {\"error\":\"llama runner process has terminated: CUDA error: all CUDA-capable devices are busy or unavailable\\n  current device: 0, in function ggml_backend_cuda_device_get_memory at //ml/backend/ggml/ggml/src/ggml-cuda/ggml-cuda.cu:2898\\n  cudaMemGetInfo(free, total)\\n//ml/backend/ggml/ggml/src/ggml-cuda/ggml-cuda.cu:73: CUDA error\"}\n",
      "SPAN error_90_tpusg_failure_signal_tpu_sketch_generator: Failed. Last error: Unexpected error during generation: litellm.APIConnectionError: OllamaException - {\"error\":\"llama runner process has terminated: CUDA error\"}\n",
      "SPAN error_a4_tpusg_failure_signal_tpu_sketch_generator: Failed. Last error: Unexpected error during generation: litellm.APIConnectionError: OllamaException - {\"error\":\"llama runner process has terminated: CUDA error\"}\n",
      "SPAN error_b5_tpusg_failure_signal_tpu_sketch_generator: Failed. Last error: Unexpected error during generation: litellm.APIConnectionError: OllamaException - {\"error\":\"llama runner process has terminated: CUDA error\"}\n",
      "SPAN error_f2_tpusg_failure_signal_tpu_sketch_generator: Failed. Last error: Unexpected error during generation: litellm.APIConnectionError: OllamaException - {\"error\":\"llama runner process has terminated: CUDA error\"}\n",
      "SPAN error_97_tpusg_failure_signal_tpu_sketch_generator: Failed. Last error: Unexpected error during generation: litellm.APIConnectionError: OllamaException - {\"error\":\"llama runner process has terminated: CUDA error\"}\n",
      "SPAN error_c5_tpusg_failure_signal_tpu_sketch_generator: Failed. Last error: Unexpected error during generation: litellm.APIConnectionError: OllamaException - {\"error\":\"llama runner process has terminated: CUDA error\"}\n",
      "Successfully processed and saved trimmed data for session qwen2.5-coder:14b_85a9_tpusg_batch\n",
      "SPAN error_48_psg_failure_signal_py_sketch_generator: Failed. Last error: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250730192349_psg_qwen2.5-coder:14b/tmp_20250730192349_psg_qwen2.5-coder:14b.py\", line 29, in <module>\n",
      "    input_data = np.load(input_path)  # Use the input path variable if it was provided and is relevant to the described input method.\n",
      "  File \"/home/wuguangh/.conda/envs/tinyml/lib/python3.10/site-packages/numpy/lib/npyio.py\", line 462, in load\n",
      "    raise ValueError(\"Cannot load file containing pickled data \"\n",
      "ValueError: Cannot load file containing pickled data when allow_pickle=False\n",
      "\n",
      "SPAN error_fd_psg_failure_signal_py_sketch_generator: Failed. Last error: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250730192238_psg_qwen2.5-coder:14b/tmp_20250730192238_psg_qwen2.5-coder:14b.py\", line 53, in <module>\n",
      "    class_id = int(detection[1])\n",
      "TypeError: only length-1 arrays can be converted to Python scalars\n",
      "\n",
      "SPAN error_07_psg_failure_signal_py_sketch_generator: Failed. Last error: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250730192113_psg_qwen2.5-coder:14b/tmp_20250730192113_psg_qwen2.5-coder:14b.py\", line 33, in <module>\n",
      "    input_data = np.expand_dims(resized_frame, axis=0)\n",
      "NameError: name 'np' is not defined\n",
      "\n",
      "SPAN error_1f_psg_failure_signal_py_sketch_generator: Failed. Last error: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "OpenCV: FFMPEG: tag 0x44495658/'XVID' is not supported with codec id 12 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n",
      "OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250730191954_psg_qwen2.5-coder:14b/tmp_20250730191954_psg_qwen2.5-coder:14b.py\", line 56, in <module>\n",
      "    label = labels[class_id]\n",
      "TypeError: only integer scalar arrays can be converted to a scalar index\n",
      "\n",
      "SPAN error_b2_psg_failure_signal_py_sketch_generator: Failed. Last error: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "qt.qpa.xcb: could not connect to display \n",
      "qt.qpa.plugin: Could not load the Qt platform plugin \"xcb\" in \"/home/wuguangh/.conda/envs/tinyml/lib/python3.10/site-packages/cv2/qt/plugins\" even though it was found.\n",
      "This application failed to start because no Qt platform plugin could be initialized. Reinstalling the application may fix this problem.\n",
      "\n",
      "Available platform plugins are: xcb.\n",
      "\n",
      "\n",
      "SPAN error_8c_psg_failure_signal_py_sketch_generator: Failed. Last error: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250730191719_psg_qwen2.5-coder:14b/tmp_20250730191719_psg_qwen2.5-coder:14b.py\", line 30, in <module>\n",
      "    input_data = np.load(input_path).astype(input_dtype)\n",
      "  File \"/home/wuguangh/.conda/envs/tinyml/lib/python3.10/site-packages/numpy/lib/npyio.py\", line 462, in load\n",
      "    raise ValueError(\"Cannot load file containing pickled data \"\n",
      "ValueError: Cannot load file containing pickled data when allow_pickle=False\n",
      "\n",
      "SPAN error_65_psg_failure_signal_py_sketch_generator: Failed. Last error: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250730191350_psg_qwen2.5-coder:14b/tmp_20250730191350_psg_qwen2.5-coder:14b.py\", line 52, in <module>\n",
      "    predicted_class_index = np.argmax(output_data, axis=1)[0]\n",
      "NameError: name 'np' is not defined\n",
      "\n",
      "SPAN error_55_psg_failure_signal_py_sketch_generator: Failed. Last error: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250730191231_psg_qwen2.5-coder:14b/tmp_20250730191231_psg_qwen2.5-coder:14b.py\", line 30, in <module>\n",
      "    raw_data = np.load(input_path)  # Assuming the input data is in a numpy format\n",
      "  File \"/home/wuguangh/.conda/envs/tinyml/lib/python3.10/site-packages/numpy/lib/npyio.py\", line 462, in load\n",
      "    raise ValueError(\"Cannot load file containing pickled data \"\n",
      "ValueError: Cannot load file containing pickled data when allow_pickle=False\n",
      "\n",
      "SPAN error_4b_psg_failure_signal_py_sketch_generator: Failed. Last error: Traceback (most recent call last):\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250730191116_psg_qwen2.5-coder:14b/tmp_20250730191116_psg_qwen2.5-coder:14b.py\", line 15, in <module>\n",
      "    interpreter = Interpreter(model_path=model_path)\n",
      "NameError: name 'Interpreter' is not defined\n",
      "\n",
      "SPAN error_96_psg_failure_signal_py_sketch_generator: Failed. Last error: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250730191010_psg_qwen2.5-coder:14b/tmp_20250730191010_psg_qwen2.5-coder:14b.py\", line 33, in <module>\n",
      "    image_resized = cv2.resize(image, input_size)\n",
      "cv2.error: OpenCV(4.10.0) /io/opencv/modules/imgproc/src/resize.cpp:4152: error: (-215:Assertion failed) !ssize.empty() in function 'resize'\n",
      "\n",
      "\n",
      "SPAN error_65_psg_failure_signal_py_sketch_generator: Failed. Last error: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250730190848_psg_qwen2.5-coder:14b/tmp_20250730190848_psg_qwen2.5-coder:14b.py\", line 41, in <module>\n",
      "    input_data = np.expand_dims(input_data, axis=0)\n",
      "NameError: name 'np' is not defined\n",
      "\n",
      "SPAN error_22_psg_failure_signal_py_sketch_generator: Failed. Last error: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250730190513_psg_qwen2.5-coder:14b/tmp_20250730190513_psg_qwen2.5-coder:14b.py\", line 28, in <module>\n",
      "    img = cv2.resize(img, (input_details[0]['shape'][1], input_details[0]['shape'][2]))\n",
      "cv2.error: OpenCV(4.10.0) /io/opencv/modules/imgproc/src/resize.cpp:4152: error: (-215:Assertion failed) !ssize.empty() in function 'resize'\n",
      "\n",
      "\n",
      "SPAN error_8c_psg_failure_signal_py_sketch_generator: Failed. Last error: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250730190403_psg_qwen2.5-coder:14b/tmp_20250730190403_psg_qwen2.5-coder:14b.py\", line 52, in <module>\n",
      "    class_id = int(detection[1])\n",
      "TypeError: only length-1 arrays can be converted to Python scalars\n",
      "\n",
      "SPAN error_2d_psg_failure_signal_py_sketch_generator: Failed. Last error: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250730190244_psg_qwen2.5-coder:14b/tmp_20250730190244_psg_qwen2.5-coder:14b.py\", line 44, in <module>\n",
      "    class_id = np.argmax(output_data)\n",
      "NameError: name 'np' is not defined\n",
      "\n",
      "SPAN error_32_psg_failure_signal_py_sketch_generator: Failed. Last error: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250730190136_psg_qwen2.5-coder:14b/tmp_20250730190136_psg_qwen2.5-coder:14b.py\", line 30, in <module>\n",
      "    input_data = np.load(input_path).astype(input_dtype)\n",
      "  File \"/home/wuguangh/.conda/envs/tinyml/lib/python3.10/site-packages/numpy/lib/npyio.py\", line 462, in load\n",
      "    raise ValueError(\"Cannot load file containing pickled data \"\n",
      "ValueError: Cannot load file containing pickled data when allow_pickle=False\n",
      "\n",
      "SPAN error_2e_psg_failure_signal_py_sketch_generator: Failed. Last error: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250730190021_psg_qwen2.5-coder:14b/tmp_20250730190021_psg_qwen2.5-coder:14b.py\", line 50, in <module>\n",
      "    print(f\"Predicted Class: {predicted_label}, Confidence: {output_data[0][predicted_class_id]:.2f}\")\n",
      "IndexError: index 31 is out of bounds for axis 0 with size 10\n",
      "\n",
      "SPAN error_41_psg_failure_signal_py_sketch_generator: Failed. Last error: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250730185823_psg_qwen2.5-coder:14b/tmp_20250730185823_psg_qwen2.5-coder:14b.py\", line 50, in <module>\n",
      "    score = float(detection[2])\n",
      "TypeError: only length-1 arrays can be converted to Python scalars\n",
      "\n",
      "SPAN error_4e_psg_failure_signal_py_sketch_generator: Failed. Last error: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250730185712_psg_qwen2.5-coder:14b/tmp_20250730185712_psg_qwen2.5-coder:14b.py\", line 45, in <module>\n",
      "    input_data = np.expand_dims(frame_rgb, axis=0).astype(np.float32) / 127.5 - 1.0\n",
      "NameError: name 'np' is not defined\n",
      "\n",
      "SPAN error_cc_psg_failure_signal_py_sketch_generator: Failed. Last error: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "OpenCV: FFMPEG: tag 0x44495658/'XVID' is not supported with codec id 12 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n",
      "OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250730185443_psg_qwen2.5-coder:14b/tmp_20250730185443_psg_qwen2.5-coder:14b.py\", line 50, in <module>\n",
      "    interpreter.set_tensor(input_details[0]['index'], input_tensor)\n",
      "  File \"/home/wuguangh/.conda/envs/tinyml/lib/python3.10/site-packages/ai_edge_litert/interpreter.py\", line 764, in set_tensor\n",
      "    self._interpreter.SetTensor(tensor_index, value)\n",
      "ValueError: Cannot set tensor: Got value of type FLOAT32 but expected type UINT8 for input 175, name: normalized_input_image_tensor \n",
      "\n",
      "SPAN error_34_psg_failure_signal_py_sketch_generator: Failed. Last error: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250730185323_psg_qwen2.5-coder:14b/tmp_20250730185323_psg_qwen2.5-coder:14b.py\", line 42, in <module>\n",
      "    interpreter.set_tensor(input_details[0]['index'], input_data)\n",
      "  File \"/home/wuguangh/.conda/envs/tinyml/lib/python3.10/site-packages/tflite_runtime/interpreter.py\", line 720, in set_tensor\n",
      "    self._interpreter.SetTensor(tensor_index, value)\n",
      "ValueError: Cannot set tensor: Got value of type FLOAT32 but expected type UINT8 for input 175, name: normalized_input_image_tensor \n",
      "\n",
      "SPAN error_67_psg_failure_signal_py_sketch_generator: Failed. Last error: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250730185022_psg_qwen2.5-coder:14b/tmp_20250730185022_psg_qwen2.5-coder:14b.py\", line 28, in <module>\n",
      "    image = Image.open(input_path).resize((224, 224))  # Resize image to match model input size\n",
      "  File \"/home/wuguangh/.conda/envs/tinyml/lib/python3.10/site-packages/PIL/Image.py\", line 3536, in open\n",
      "    raise UnidentifiedImageError(msg)\n",
      "PIL.UnidentifiedImageError: cannot identify image file '/home/wuguangh/Projects/tinyml-autopilot/data/object_detection/sheeps.mp4'\n",
      "\n",
      "SPAN error_20_psg_failure_signal_py_sketch_generator: Failed. Last error: Traceback (most recent call last):\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250730184901_psg_qwen2.5-coder:14b/tmp_20250730184901_psg_qwen2.5-coder:14b.py\", line 18, in <module>\n",
      "    with open(label_path, 'r') as f:\n",
      "FileNotFoundError: [Errno 2] No such file or directory: 'path_to_label_map.txt'\n",
      "\n",
      "Successfully processed and saved trimmed data for session qwen2.5-coder:14b_85a9_psg_batch\n",
      "Total 0 traces skipped. They are []\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "skipped_traces = []\n",
    "\n",
    "\n",
    "def process_existing_observation(observation):\n",
    "    \"\"\"\n",
    "    Processes an existing observation dictionary by trimming unwanted keys.\n",
    "    \"\"\"\n",
    "    unwanted_observation_keys = [\n",
    "        \"completionStartTime\",\n",
    "        \"metadata\",\n",
    "        \"timeToFirstToken\",\n",
    "        \"createdAt\",\n",
    "        \"usageDetails\",\n",
    "        \"usage\",\n",
    "        \"projectId\",\n",
    "        \"unit\",\n",
    "        \"updatedAt\",\n",
    "        \"version\",\n",
    "        \"parentObservationId\",\n",
    "        \"promptId\",\n",
    "        \"promptName\",\n",
    "        \"promptVersion\",\n",
    "        \"modelId\",\n",
    "        \"inputPrice\",\n",
    "        \"outputPrice\",\n",
    "        \"totalPrice\",\n",
    "        # \"modelParameters\",\n",
    "        \"input\",\n",
    "        \"output\",\n",
    "    ]\n",
    "\n",
    "    # If observation is a dictionary containing observation data\n",
    "    if isinstance(observation, dict):\n",
    "        trimmed_observation = {\n",
    "            k: v for k, v in observation.items() if k not in unwanted_observation_keys\n",
    "        }\n",
    "        return trimmed_observation\n",
    "    return observation\n",
    "\n",
    "\n",
    "def trim_data(data):\n",
    "    \"\"\"\n",
    "    Recursively trims the data structure.\n",
    "    \"\"\"\n",
    "\n",
    "    if isinstance(data, dict):\n",
    "        # Process the current dictionary\n",
    "        unwanted_trace_keys = [\n",
    "            \"release\",\n",
    "            \"version\",\n",
    "            \"user_id\",\n",
    "            \"public\",\n",
    "            \"html_path\",\n",
    "            \"scores\",\n",
    "            \"bookmarked\",\n",
    "            \"projectId\",\n",
    "            \"externalId\",\n",
    "            \"page\",\n",
    "            \"limit\",\n",
    "            \"total_pages\",\n",
    "        ]\n",
    "\n",
    "        # If this is a trace that contains observations, check for fatal errors\n",
    "        if \"observations\" in data:\n",
    "            # Check for SPAN observations with fatal errors before processing\n",
    "            skip_trace = False\n",
    "            for obs in data[\"observations\"]:\n",
    "                if isinstance(obs, dict) and obs.get(\"name\").startswith(\"error\"):\n",
    "                    status_message = obs.get(\"statusMessage\", \"\")\n",
    "                    ob_name = obs.get(\"name\")\n",
    "                    print(f\"SPAN {ob_name}: {status_message}\")\n",
    "\n",
    "                    if \"Fatal error\" in status_message:\n",
    "                        print(f\"Found Fatal error in SPAN observation, skipping trace\")\n",
    "                        skip_trace = True\n",
    "                        skipped_traces.append(data[\"name\"])\n",
    "                        break\n",
    "\n",
    "            if skip_trace:\n",
    "                return None  # Signal to skip this trace\n",
    "\n",
    "        # Create a new dictionary with wanted keys and recursively process values\n",
    "        trimmed_data = {}\n",
    "        for key, value in data.items():\n",
    "            if key not in unwanted_trace_keys:\n",
    "                if key == \"observations\":\n",
    "                    # Special handling for observations\n",
    "                    trimmed_data[key] = [\n",
    "                        process_existing_observation(obs) for obs in value\n",
    "                    ]\n",
    "                elif isinstance(value, (dict, list)):\n",
    "                    # Recursively process nested structures\n",
    "                    trimmed_data[key] = trim_data(value)\n",
    "                else:\n",
    "                    trimmed_data[key] = value\n",
    "\n",
    "        return trimmed_data\n",
    "\n",
    "    elif isinstance(data, list):\n",
    "        # Recursively process each item in the list\n",
    "        processed_items = []\n",
    "        for item in data:\n",
    "            processed_item = trim_data(item)\n",
    "            if processed_item is not None:  # Only add items that weren't filtered out\n",
    "                processed_items.append(processed_item)\n",
    "        return processed_items\n",
    "\n",
    "    else:\n",
    "        # Return non-dict, non-list values as is\n",
    "        return data\n",
    "\n",
    "\n",
    "def read_and_trim_data(session_id_list, raw_export_dir, trimmed_export_dir):\n",
    "    \"\"\"\n",
    "    Reads complete data from JSON files, trims the data, and saves the trimmed data to new JSON files.\n",
    "    \"\"\"\n",
    "    os.makedirs(trimmed_export_dir, exist_ok=True)\n",
    "\n",
    "    for session_id in session_id_list:\n",
    "        try:\n",
    "            if session_id.startswith(\"da0a\"):\n",
    "                session_id = \"phi4_\" + session_id\n",
    "            # Read raw data\n",
    "            if \"tpsg\" in session_id:\n",
    "                session_id_ = session_id.replace(\"tpsg\", \"tpusg\")\n",
    "            else:\n",
    "                session_id_ = session_id\n",
    "            raw_path = os.path.join(raw_export_dir, f\"raw_{session_id_}.json\")\n",
    "            with open(raw_path, \"r\") as f:\n",
    "                data = json.load(f)\n",
    "\n",
    "            # Process and trim the data\n",
    "            trimmed_data = trim_data(data)\n",
    "\n",
    "            # If the entire data was filtered out (unlikely but possible)\n",
    "            if trimmed_data is None:\n",
    "                print(\n",
    "                    f\"All traces in session {session_id} were filtered due to fatal errors\"\n",
    "                )\n",
    "                continue\n",
    "\n",
    "            # Save trimmed data\n",
    "            if \"tpsg\" in session_id:\n",
    "                session_id_ = session_id.replace(\"tpsg\", \"tpusg\")\n",
    "            else:\n",
    "                session_id_ = session_id\n",
    "            trimmed_path = os.path.join(\n",
    "                trimmed_export_dir, f\"trimmed_{session_id_}.json\"\n",
    "            )\n",
    "            with open(trimmed_path, \"w\") as f:\n",
    "                json.dump(trimmed_data, f, indent=2)\n",
    "\n",
    "            print(\n",
    "                f\"Successfully processed and saved trimmed data for session {session_id}\"\n",
    "            )\n",
    "\n",
    "            # Optional: Verify trimming worked\n",
    "            # print(f\"Verifying trimmed data for session {session_id}...\")\n",
    "            # verify_trimming(trimmed_path)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing session {session_id}: {str(e)}\")\n",
    "\n",
    "\n",
    "def verify_trimming(trimmed_path):\n",
    "    \"\"\"\n",
    "    Verifies that the trimmed data doesn't contain unwanted keys.\n",
    "    \"\"\"\n",
    "    with open(trimmed_path, \"r\") as f:\n",
    "        trimmed_data = json.load(f)\n",
    "\n",
    "    unwanted_keys = [\n",
    "        \"release\",\n",
    "        \"version\",\n",
    "        \"user_id\",\n",
    "        \"public\",\n",
    "        \"html_path\",\n",
    "        \"scores\",\n",
    "        \"bookmarked\",\n",
    "        \"projectId\",\n",
    "        \"externalId\",\n",
    "        \"page\",\n",
    "        \"limit\",\n",
    "        \"total_pages\",\n",
    "        \"completionStartTime\",\n",
    "        \"metadata\",\n",
    "        \"usageDetails\",\n",
    "        \"timeToFirstToken\",\n",
    "        \"createdAt\",\n",
    "        \"completionTokens\",\n",
    "        \"promptTokens\",\n",
    "        \"projectId\",\n",
    "        \"unit\",\n",
    "        \"updatedAt\",\n",
    "        \"version\",\n",
    "        # \"statusMessage\",\n",
    "        \"parentObservationId\",\n",
    "        \"promptId\",\n",
    "        \"promptName\",\n",
    "        \"promptVersion\",\n",
    "        \"modelId\",\n",
    "        \"inputPrice\",\n",
    "        \"outputPrice\",\n",
    "        \"totalPrice\",\n",
    "        \"calculatedInputCost\",\n",
    "        \"calculatedOutputCost\",\n",
    "        \"calculatedTotalCost\",\n",
    "    ]\n",
    "\n",
    "    def check_keys(obj):\n",
    "        if isinstance(obj, dict):\n",
    "            for key in obj.keys():\n",
    "                if key in unwanted_keys:\n",
    "                    print(f\"Warning: Found unwanted key '{key}' in trimmed data\")\n",
    "            for value in obj.values():\n",
    "                check_keys(value)\n",
    "        elif isinstance(obj, list):\n",
    "            for item in obj:\n",
    "                check_keys(item)\n",
    "\n",
    "    check_keys(trimmed_data)\n",
    "    print(\"Verification complete\")\n",
    "\n",
    "\n",
    "# Usage example:\n",
    "read_and_trim_data(session_id_list, raw_export_dir, raw_export_dir)\n",
    "print(f\"Total {len(skipped_traces)} traces skipped. They are {skipped_traces}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Generate CSV files from JSON\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing session qwen2.5-coder:14b_85a9_tpusg_batch, simple id qwen2.5-coder:14b_85a9. Look for /Users/hann/Projects/reference-benchmark-tinyml_llm/data_analysis/2025/07.30_a/raw_export/trimmed_qwen2.5-coder:14b_85a9_tpusg_batch.json\n",
      "/Users/hann/Projects/reference-benchmark-tinyml_llm/data_analysis/2025/07.30_a/processed_data/qwen2.5-coder:14b_85a9/clean_qwen2.5-coder:14b_85a9_tpusg_batch.csv\n",
      "Successfully saved CSV to: /Users/hann/Projects/reference-benchmark-tinyml_llm/data_analysis/2025/07.30_a/processed_data/qwen2.5-coder:14b_85a9/clean_qwen2.5-coder:14b_85a9_tpusg_batch.csv\n",
      "Processing session qwen2.5-coder:14b_85a9_psg_batch, simple id qwen2.5-coder:14b_85a9. Look for /Users/hann/Projects/reference-benchmark-tinyml_llm/data_analysis/2025/07.30_a/raw_export/trimmed_qwen2.5-coder:14b_85a9_psg_batch.json\n",
      "/Users/hann/Projects/reference-benchmark-tinyml_llm/data_analysis/2025/07.30_a/processed_data/qwen2.5-coder:14b_85a9/clean_qwen2.5-coder:14b_85a9_psg_batch.csv\n",
      "Successfully saved CSV to: /Users/hann/Projects/reference-benchmark-tinyml_llm/data_analysis/2025/07.30_a/processed_data/qwen2.5-coder:14b_85a9/clean_qwen2.5-coder:14b_85a9_psg_batch.csv\n"
     ]
    }
   ],
   "source": [
    "import traceback\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from dateutil import parser\n",
    "\n",
    "\n",
    "def json_to_csv(session_id):\n",
    "    \"\"\"\n",
    "    Convert JSON trace data to CSV format with aggregated metrics.\n",
    "\n",
    "    Args:\n",
    "        session_id (str): Identifier for the session to process\n",
    "    \"\"\"\n",
    "\n",
    "    def extract_observation_details(observations, trace_id):\n",
    "        \"\"\"Extract and aggregate metrics from observations\"\"\"\n",
    "        metrics = {\n",
    "            \"status\": None,\n",
    "            \"latency\": 0,\n",
    "            \"total_tokens\": 0,\n",
    "            \"prompt_tokens\": 0,\n",
    "            \"completion_tokens\": 0,\n",
    "            \"total_cost\": 0,\n",
    "            \"input_cost\": 0,\n",
    "            \"output_cost\": 0,\n",
    "            \"parameters\": set(),\n",
    "        }\n",
    "\n",
    "        # Process GENERATION observations\n",
    "        for obs in (o for o in observations if o[\"type\"] == \"GENERATION\"):\n",
    "            metrics[\"total_tokens\"] += obs[\"totalTokens\"]\n",
    "            metrics[\"prompt_tokens\"] += obs[\"promptTokens\"]\n",
    "            metrics[\"completion_tokens\"] += obs[\"completionTokens\"]\n",
    "            metrics[\"latency\"] += obs[\"latency\"]\n",
    "            for key, value in obs[\"modelParameters\"].items():\n",
    "                metrics[\"parameters\"].add(key + \":\" + value)\n",
    "\n",
    "            # Add costs if present\n",
    "            for cost_type in [\"Total\", \"Input\", \"Output\"]:\n",
    "                key = f\"calculated{cost_type}Cost\"\n",
    "                metric_key = cost_type.lower() + \"_cost\"\n",
    "                if obs.get(key) is not None:\n",
    "                    metrics[metric_key] += obs[key]\n",
    "        if len(metrics[\"parameters\"]) == 0:\n",
    "            metrics[\"parameters\"] = \"N/A\"\n",
    "        # Process SPAN observations for status\n",
    "        status_indicators = [\n",
    "            obs[\"name\"]\n",
    "            for obs in observations\n",
    "            if obs[\"type\"] == \"SPAN\" and \"start_\" not in obs[\"name\"]\n",
    "        ]\n",
    "\n",
    "        #  if later than 2025-05-19, use status_signal_from_output\n",
    "        if datetime.now() > datetime(2025, 5, 19):\n",
    "            pass\n",
    "        else:\n",
    "            # Determine status\n",
    "            success_signals = sum(\"end_\" in name for name in status_indicators)\n",
    "            failure_signals = sum(\n",
    "                \"failure_signal\" in name for name in status_indicators\n",
    "            )\n",
    "\n",
    "            if success_signals + failure_signals > 1:\n",
    "                raise ValueError(\n",
    "                    f\"Multiple status indicators found in trace {trace_id}\"\n",
    "                )\n",
    "\n",
    "            metrics[\"status\"] = (\n",
    "                \"success\"\n",
    "                if success_signals\n",
    "                else \"failure\" if failure_signals else \"unknown\"\n",
    "            )\n",
    "\n",
    "        metrics[\"prompt_cost\"] = metrics.pop(\"input_cost\")\n",
    "        metrics[\"completion_cost\"] = metrics.pop(\"output_cost\")\n",
    "        metrics[\"latency\"] = round(metrics[\"latency\"] / 1000, 2)\n",
    "        return metrics\n",
    "\n",
    "    def cal_time(trace):\n",
    "        time_diff = datetime.fromisoformat(\n",
    "            trace[\"updatedAt\"].replace(\"Z\", \"+00:00\")\n",
    "        ) - datetime.fromisoformat(trace[\"createdAt\"].replace(\"Z\", \"+00:00\"))\n",
    "        seconds_diff = time_diff.total_seconds()\n",
    "        return seconds_diff\n",
    "\n",
    "    try:\n",
    "\n",
    "        if session_id.startswith(\"da0a\"):\n",
    "            session_id = \"phi4_\" + session_id\n",
    "        simple_session_id = session_id.rsplit(\"_\", 2)[0]\n",
    "\n",
    "        \n",
    "        # Load JSON data\n",
    "        if \"tpsg\" in session_id:\n",
    "                session_id_ = session_id.replace(\"tpsg\", \"tpusg\")\n",
    "        else:\n",
    "                session_id_ = session_id\n",
    "        trimmed_path = os.path.join(raw_export_dir, f\"trimmed_{session_id_}.json\")\n",
    "        print(\n",
    "            f\"Processing session {session_id}, simple id {simple_session_id}. Look for {trimmed_path}\"\n",
    "        )\n",
    "        with open(trimmed_path, \"r\") as file:\n",
    "            traces = json.load(file)[\"data\"]\n",
    "\n",
    "        # Process traces\n",
    "        rows = [\n",
    "            {\n",
    "                \"num_run\": trace[\"metadata\"][\"num_run\"],\n",
    "                \"name\": trace[\"name\"],\n",
    "                \"trace_id\": trace[\"id\"],\n",
    "                \"batch_id\": trace[\"session_id\"],\n",
    "                # \"latency\": cal_time(trace),\n",
    "                # \"latency\": round(trace[\"latency\"], 2),\n",
    "                **extract_observation_details(\n",
    "                    trace[\"observations\"],\n",
    "                    trace[\"id\"],\n",
    "                ),\n",
    "                \"status\": (\n",
    "                    \"failure\"\n",
    "                    if trace[\"output\"][\"status\"].lower() == \"failed\"\n",
    "                    else \"success\"\n",
    "                ),\n",
    "                \"tags\": trace[\"tags\"],\n",
    "                \"timestamp\": int(parser.isoparse(trace[\"timestamp\"]).timestamp()),\n",
    "            }\n",
    "            for trace in traces\n",
    "        ]\n",
    "        # print(rows)\n",
    "        # print(rows)\n",
    "        # Create and save DataFrame\n",
    "        df = pd.DataFrame(rows).sort_values(\"num_run\")\n",
    "\n",
    "        output_dir = os.path.join(processed_data_dir, f\"{simple_session_id}\")\n",
    "        if not os.path.exists(output_dir):\n",
    "            os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "        output_path = os.path.join(output_dir, f\"clean_{session_id_}.csv\")\n",
    "\n",
    "        print(output_path)\n",
    "        df.to_csv(output_path, index=False)\n",
    "        print(f\"Successfully saved CSV to: {output_path}\")\n",
    "\n",
    "    except FileNotFoundError as e:\n",
    "        print(\n",
    "            f\"FileNotFoundError: For session {session_id} not found. Looked for {trimmed_path}\\nError info: \\n{e}\\n\\nTraceback: {traceback.format_exc()}\"\n",
    "        )\n",
    "    except json.JSONDecodeError:\n",
    "        print(f\"Error: Invalid JSON format in input file for session {session_id}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing session {session_id}: {str(e)}\")\n",
    "\n",
    "\n",
    "# Example usage\n",
    "for session_id in session_id_list:\n",
    "    json_to_csv(session_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code below is archived\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"\"\"Simply calculate success rate\"\"\"\n",
    "\n",
    "\n",
    "# def cal_success_rate(session_id):\n",
    "\n",
    "#     end_signal_count = 0\n",
    "#     failure_signal_count = 0\n",
    "#     # Function to print the name of each observation\n",
    "#     with open(f\"{raw_export_dir}/trimmed_{session_id}.json\", \"r\") as file:\n",
    "#         data = json.load(file)[\"data\"]\n",
    "#     for i in data:\n",
    "\n",
    "#         observations = i[\"observations\"]\n",
    "\n",
    "#         for observation in observations:\n",
    "#             # print(type(observation))\n",
    "#             for key, value in observation.items():\n",
    "#                 # print(f\"{key}: {value}\")\n",
    "#                 for key, value in value.items():\n",
    "#                     # print(f\"{key}: {value}\")\n",
    "#                     if key == \"name\":\n",
    "#                         if \"end_\" in value:\n",
    "\n",
    "#                             end_signal_count += 1\n",
    "#                         if \"failure_signal\" in value:\n",
    "\n",
    "#                             failure_signal_count += 1\n",
    "\n",
    "#     print(f\"Session ID: {session_id}\")\n",
    "#     total_count = end_signal_count + failure_signal_count\n",
    "#     if total_count > 0:\n",
    "#         success_rate = end_signal_count / total_count\n",
    "#         print(f\"Success rate: {success_rate:.4f}\")\n",
    "#     else:\n",
    "#         print(\"Success rate: N/A (no signals found)\")\n",
    "#     print(f\"Passed:\\t{end_signal_count}\\nFailed:\\t{failure_signal_count}\")\n",
    "#     print(\n",
    "#         \"\"\n",
    "#         if total_count == 30\n",
    "#         else \"Number of ending signals does not match the expected number!\"\n",
    "#     )\n",
    "#     print(\"-\" * 50)\n",
    "\n",
    "\n",
    "# for session_id in session_id_list:\n",
    "#     cal_success_rate(session_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def cal_time(start_time, end_time):\n",
    "#     time_diff = datetime.fromisoformat(\n",
    "#         end_time.replace(\"Z\", \"+00:00\")\n",
    "#     ) - datetime.fromisoformat(start_time.replace(\"Z\", \"+00:00\"))\n",
    "#     seconds_diff = time_diff.total_seconds()\n",
    "#     return seconds_diff\n",
    "\n",
    "\n",
    "# print(cal_time(\"2025-01-15T03:31:56.150000+00:00\", \"2025-01-15T03:32:59.384Z\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"\"\"Print the complete structure of exported json file\"\"\"\n",
    "# def print_keys(d, parent_key=''):\n",
    "#     if isinstance(d, dict):\n",
    "#         for key, value in d.items():\n",
    "#             full_key = f\"{parent_key}.{key}\" if parent_key else key\n",
    "#             print(full_key)\n",
    "#             print_keys(value, full_key)\n",
    "#     elif isinstance(d, list):\n",
    "#         for i, item in enumerate(d):\n",
    "#             full_key = f\"{parent_key}[{i}]\"\n",
    "#             print_keys(item, full_key)\n",
    "\n",
    "# # Load JSON data from a file\n",
    "# with open('fetch_traces_response.json', 'r') as file:\n",
    "#     data = json.load(file)['data'][0]\n",
    "# # Print all keys\n",
    "# print_keys(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1747226053\n",
      "1747226053.1\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "from dateutil import parser\n",
    "\n",
    "timestamp_str = \"2025-05-14T12:34:13.100000+00:00\"\n",
    "dt = parser.isoparse(\n",
    "    timestamp_str\n",
    ")  # Or datetime.fromisoformat(timestamp_str) if no timezone offset\n",
    "unix_ts = int(dt.timestamp())\n",
    "\n",
    "print(unix_ts)  # This will print the integer Unix timestamp\n",
    "print(datetime.fromisoformat(timestamp_str).timestamp())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datasci2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

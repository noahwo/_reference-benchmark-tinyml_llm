{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setting up\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ref: https://langfuse.com/docs/query-traces\n",
    "import os\n",
    "import json\n",
    "from langfuse import Langfuse\n",
    "import json\n",
    "import os\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "LOCAL_HOST = True\n",
    "\n",
    "\"\"\"Define session_id\"\"\"\n",
    "# session_id=\"qwen2.5-coder_f4d4_dp_batch\"\n",
    "session_id_list = [\n",
    "    # \"qwen2.5-coder:32b_4e11_tpsg_batch\",\n",
    "    # \"qwen2.5-coder:32b_ae24_tpsg_batch\"\n",
    "    \"gemma3:27b_85a9_psg_batch\",\n",
    "    \"gemma3:27b_85a9_tpusg_batch\"\n",
    "]\n",
    "\n",
    "\n",
    "\"\"\"Define paths\"\"\"\n",
    " \n",
    "parent_dir = os.path.dirname(os.getcwd())\n",
    "\n",
    " \n",
    "# date = os.path.basename(parent_dir)\n",
    "tex_dir = os.path.join(parent_dir, \"tex\")\n",
    "processed_data_dir = os.path.join(parent_dir, \"processed_data\")\n",
    "raw_export_dir = os.path.join(parent_dir, \"raw_export\")\n",
    "ipynb_dir = os.path.join(parent_dir, \"ipynb\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Export raw data\n",
    "\n",
    "Langfuse added a limit of 20 API invocations per minute. https://langfuse.com/faq/all/api-limits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching traces for session gemma3:27b_85a9_psg_batch...\n",
      "Fetching observation data for time-21-14-48-974131_chatcmpl-6864a4a0-7549-4513-8812-bfa3f5a55365...\n",
      "Fetching observation data for time-21-13-52-357924_chatcmpl-040d9bd6-78eb-41c8-b617-151a53850b88...\n",
      "Fetching observation data for time-21-14-23-698574_chatcmpl-acfa81a2-55dd-4359-ba0f-73bf888a72f3...\n",
      "Fetching observation data for time-21-12-46-699577_chatcmpl-14a621fc-ecd6-40bf-b575-c43e919c4cf5...\n",
      "Fetching observation data for time-21-13-16-163740_chatcmpl-daf45f50-bd82-41ef-bd8d-4c87fc4ab69c...\n",
      "Fetching observation data for time-21-11-12-018098_chatcmpl-f578b261-70be-404e-b46f-f881aa68af15...\n",
      "Fetching observation data for time-21-11-45-151450_chatcmpl-3affb71c-9ff3-4934-83b6-ad1e8225e8a0...\n",
      "Fetching observation data for time-21-12-16-904890_chatcmpl-e25d7507-6016-4f0e-8e84-23e382b25b5d...\n",
      "Fetching observation data for time-21-09-33-311276_chatcmpl-6ccc7500-ea97-49d7-a5c6-4a50fb42da62...\n",
      "Fetching observation data for time-21-10-01-366849_chatcmpl-063e0b13-0905-45a3-a888-2f97b37cc624...\n",
      "Fetching observation data for time-21-10-35-991784_chatcmpl-74b8ef5b-3168-4da8-8c6d-fff9854100b8...\n",
      "Fetching observation data for time-21-08-06-676540_chatcmpl-926ef9ce-b635-4118-99df-af1f0af886df...\n",
      "Fetching observation data for time-21-08-39-208480_chatcmpl-dd52d3e5-42d3-443e-a77d-882f8e43a4db...\n",
      "Fetching observation data for time-21-09-04-947546_chatcmpl-6c725a01-2a9d-4ec4-8c2b-8ecaf7637554...\n",
      "Fetching observation data for time-21-05-49-936979_chatcmpl-d4af78b1-632c-43ea-95b4-1fbb94dd1f17...\n",
      "Fetching observation data for time-21-06-19-172689_chatcmpl-5cd6247c-3f9c-4a45-bc28-fb2a24ac63d7...\n",
      "Fetching observation data for time-21-06-42-922486_chatcmpl-81d08937-bbd9-4a3b-b25a-0813d98553ce...\n",
      "Fetching observation data for time-21-07-08-597913_chatcmpl-b53b399a-def9-4938-9f92-d390db27badf...\n",
      "Fetching observation data for time-21-07-36-202575_chatcmpl-702e7b92-ad43-4349-9d40-b52706f16dac...\n",
      "Fetching observation data for 7b620457-eb6a-465e-bf4d-ad707748631c...\n",
      "Fetching observation data for time-21-04-40-198322_chatcmpl-e5c8ad7e-12c0-4cd7-b387-14a37954a00d...\n",
      "Fetching observation data for time-21-05-09-146186_chatcmpl-62694d8c-305a-46a9-8d00-ecbd387f613e...\n",
      "Fetching observation data for time-21-03-00-411917_chatcmpl-15795084-1469-49b1-af9a-f34f8cd65cfd...\n",
      "Fetching observation data for time-21-03-32-664613_chatcmpl-494b5fa7-3455-48ba-8ae1-2bf0154af3a5...\n",
      "Fetching observation data for time-21-03-55-033116_chatcmpl-5ed6cb36-b4c0-4ae4-944e-3f088a0f8a0d...\n",
      "Fetching observation data for time-21-00-51-693973_chatcmpl-0a44003b-f615-4591-9ee6-34048dece15f...\n",
      "Fetching observation data for time-21-01-26-161966_chatcmpl-3fd2bc03-2074-45af-bf59-9b76e72b8ca7...\n",
      "Fetching observation data for time-21-01-46-021953_chatcmpl-d7be534b-eece-4229-bc2d-06e4bcfaeda4...\n",
      "Fetching observation data for time-20-58-48-036994_chatcmpl-8080f906-b967-4434-9327-ef59dfbeb2ed...\n",
      "Fetching observation data for time-20-59-20-694559_chatcmpl-8e2612e4-45c3-42f7-a71e-c766d008ac07...\n",
      "Fetching observation data for time-20-59-48-540610_chatcmpl-b96e1fd5-3406-44b7-bafe-c8ba71728e6d...\n",
      "Fetching observation data for time-21-00-16-012899_chatcmpl-2b37fab3-6e91-4b2b-95d5-de5f3220cdca...\n",
      "Fetching observation data for time-20-57-26-410913_chatcmpl-9dc03156-55bb-48ae-9273-e8a4461babe3...\n",
      "Fetching observation data for time-20-57-54-717540_chatcmpl-5775119a-aad6-4d73-a226-0dc10bc6fa35...\n",
      "Fetching observation data for time-20-58-19-994115_chatcmpl-99a4c33b-81fa-4009-95fa-d4ad71e96a82...\n",
      "Fetching observation data for time-20-54-43-751183_chatcmpl-e3770c60-c5b4-4447-b6b1-294f93e2ad26...\n",
      "Fetching observation data for time-20-55-15-735896_chatcmpl-b68a72a0-9aae-4afd-b1c9-f84d4a18117f...\n",
      "Fetching observation data for time-20-55-49-590087_chatcmpl-ed82f637-4de2-46b8-a1df-081d40651010...\n",
      "Fetching observation data for time-20-56-25-224561_chatcmpl-e2ab51c0-54aa-4dfd-bc96-8caf71284d39...\n",
      "Fetching observation data for time-20-56-53-973747_chatcmpl-625171b5-c8e9-479c-8722-b97844a09962...\n",
      "Fetching observation data for 7dedce77-9f69-4a86-a36b-25fb0331e363...\n",
      "Fetching observation data for time-20-54-07-080965_chatcmpl-b5159376-fa95-4a4f-bbda-39a002d9b93c...\n",
      "Fetching observation data for time-20-52-16-331425_chatcmpl-0b93cc6a-7ef5-4a89-b9ac-336fcee1f622...\n",
      "Fetching observation data for time-20-52-46-291799_chatcmpl-b9d4502c-c7c1-45ad-83fa-83e32f29356d...\n",
      "Fetching observation data for time-20-53-18-026265_chatcmpl-4152cc58-17e5-4415-a551-1e30b05f6eb9...\n",
      "Fetching observation data for time-20-53-42-717591_chatcmpl-7812fa90-ca6c-4160-bb89-0b5623aa824e...\n",
      "Fetching observation data for time-20-51-35-438631_chatcmpl-69ac48a4-53ee-4f63-8b13-7370d3084440...\n",
      "Fetching observation data for time-20-50-57-670849_chatcmpl-d2a80287-04dc-4b05-b032-d96a66451335...\n",
      "Fetching observation data for time-20-48-26-731328_chatcmpl-a196a286-11b8-44a6-8f9f-e1a12c90aa71...\n",
      "Fetching observation data for time-20-49-00-259450_chatcmpl-7aa0082a-6f44-4c4e-abbe-1aab9b256397...\n",
      "Fetching observation data for time-20-49-28-213879_chatcmpl-41b424e3-9292-4afc-8372-d32de1dbb5eb...\n",
      "Fetching observation data for time-20-49-48-662901_chatcmpl-ca4d3892-40f7-4a6c-a56f-cd13a70ae70c...\n",
      "Fetching observation data for time-20-50-17-078778_chatcmpl-398d5e4f-e65f-4664-bab6-93bec720ad8d...\n",
      "Fetching observation data for 3bdf0d72-4a6b-4775-9356-59eaa8db60bb...\n",
      "Fetching observation data for time-20-46-00-097375_chatcmpl-5acc6865-d000-4840-af99-cb42eb5303df...\n",
      "Fetching observation data for time-20-46-35-634922_chatcmpl-83dffeac-dd02-429c-97ce-f81b592a03b7...\n",
      "Fetching observation data for time-20-47-01-999920_chatcmpl-93d90527-6433-4422-a8f9-0c4304bcc53b...\n",
      "Fetching observation data for time-20-47-32-386531_chatcmpl-243f4917-07d7-4651-9db2-0f9577c752ad...\n",
      "Fetching observation data for time-20-47-52-577526_chatcmpl-d1ba87d4-7d9e-42a9-836d-73fe9d0c8ac9...\n",
      "Fetching observation data for 8d834401-f168-4b72-a81f-c3aae3c74277...\n",
      "Fetching observation data for time-20-43-18-540392_chatcmpl-6d9544d1-f77e-4cab-b77c-8ca55b815473...\n",
      "Fetching observation data for time-20-43-53-958366_chatcmpl-5020a607-4227-45a4-a543-f385f3c578df...\n",
      "Fetching observation data for time-20-44-21-415786_chatcmpl-e8b999cc-884f-4e77-b761-3744b9c67869...\n",
      "Fetching observation data for time-20-44-47-930898_chatcmpl-f4a2e7bf-130c-4165-aa21-f3e72d36f49c...\n",
      "Fetching observation data for time-20-45-24-554149_chatcmpl-f617d049-f797-4bb7-b70b-5e55f3ff2477...\n",
      "Fetching observation data for 45ea666f-4341-4d65-8aee-7ba4884390cb...\n",
      "Fetching observation data for time-20-42-18-022892_chatcmpl-833f56c2-8fdf-4a4c-8080-cbc2781b715c...\n",
      "Fetching observation data for time-20-42-45-270978_chatcmpl-5f723d54-a923-4156-ac3d-f696dc830fe4...\n",
      "Fetching observation data for time-20-39-56-335683_chatcmpl-319faeab-b134-4057-b746-9d76c89a8adf...\n",
      "Fetching observation data for time-20-40-26-817686_chatcmpl-e9e8ab36-9983-49e6-9867-ad0359ceaad9...\n",
      "Fetching observation data for time-20-40-51-937324_chatcmpl-32858c3d-0acb-431b-9ab5-de471d64731a...\n",
      "Fetching observation data for time-20-41-16-068671_chatcmpl-5f341634-4e40-4a4f-882e-81ca1d84dad8...\n",
      "Fetching observation data for time-20-41-43-454202_chatcmpl-0f8bd6b7-363d-47f3-9800-c54d6de1b809...\n",
      "Fetching observation data for ef208943-8b03-46e2-b3ce-131a0542ae2f...\n",
      "Fetching observation data for time-20-38-57-802159_chatcmpl-4f8aa00a-8af5-4dcd-9797-4aa9ed5452d0...\n",
      "Fetching observation data for time-20-39-27-993040_chatcmpl-494351c3-ab44-4021-a6ca-d80e4725dcf0...\n",
      "Fetching observation data for time-20-37-03-211245_chatcmpl-97e2f326-717f-4467-a96a-ef62601db66f...\n",
      "Fetching observation data for time-20-37-33-374541_chatcmpl-1c3ae197-242b-44d6-a1b4-809872fb2175...\n",
      "Fetching observation data for time-20-38-01-388847_chatcmpl-86b6b08d-77ae-4c57-94cc-59386366a2c2...\n",
      "Fetching observation data for time-20-38-37-669837_chatcmpl-453d319d-45c9-442e-9e6f-ef15ef481fb0...\n",
      "Fetching observation data for time-20-36-06-231237_chatcmpl-d21ec5d3-b190-4fe3-a862-8b98ffbdf15c...\n",
      "Fetching observation data for time-20-36-39-508404_chatcmpl-8d1210c6-a21f-4ec0-8fd1-061f11484652...\n",
      "Fetching observation data for time-20-34-44-623226_chatcmpl-ae9674c9-68dc-4c97-8bd4-f853aed78f0c...\n",
      "Fetching observation data for time-20-35-20-187844_chatcmpl-14a2bf15-effb-4aae-8480-09d83995c906...\n",
      "Fetching observation data for time-20-35-44-883801_chatcmpl-41724c0d-e7b0-4dbd-bfcd-652018d81e78...\n",
      "Fetching observation data for time-20-33-39-031997_chatcmpl-7667ebeb-a78c-4a3d-81e5-223c19da8f44...\n",
      "Fetching observation data for time-20-34-09-928777_chatcmpl-edfcd368-78b0-476c-af6e-1f20e2663810...\n",
      "Fetching observation data for time-20-31-34-441037_chatcmpl-a331c8fd-afc5-44ae-8c6e-16fbe4c2d841...\n",
      "Fetching observation data for time-20-32-07-270604_chatcmpl-2cbe4203-65c0-4c0a-8768-3beabb2785c1...\n",
      "Fetching observation data for time-20-32-35-382349_chatcmpl-48272266-d1d1-4416-aa00-4de0c778ad72...\n",
      "Fetching observation data for time-20-33-02-301731_chatcmpl-804d20fb-1b1d-4711-ba4e-802fefcf059f...\n",
      "Fetching observation data for time-20-31-00-567450_chatcmpl-bf16dfb1-63b9-438f-a3aa-269fb49c9851...\n",
      "Fetching observation data for time-20-30-23-655817_chatcmpl-9f21e070-15a4-4ddc-9401-af4abc5558b5...\n",
      "Raw JSON saved to: /Users/hann/Projects/reference-benchmark-tinyml_llm/data_analysis/07.30_b/raw_export/raw_gemma3:27b_85a9_psg_batch.json\n",
      "Fetching traces for session gemma3:27b_85a9_tpusg_batch...\n",
      "Fetching observation data for time-20-26-17-588894_chatcmpl-0ed49918-c6fe-4a61-92f2-f036c4b727ef...\n",
      "Fetching observation data for time-20-27-00-872840_chatcmpl-bf1b8163-938c-4cc0-b8af-629d42a2534f...\n",
      "Fetching observation data for time-20-27-49-043834_chatcmpl-8719ea5d-5b98-4412-a645-e075a0e85956...\n",
      "Fetching observation data for time-20-28-37-621240_chatcmpl-a46928b9-4df7-4b16-8a20-5907836ef7a2...\n",
      "Fetching observation data for time-20-29-29-077963_chatcmpl-b4322766-fdba-42c3-8048-4963367d7195...\n",
      "Fetching observation data for 4c7fe3f5-a6f3-4336-87e9-b5c890a56a7d...\n",
      "Fetching observation data for time-20-22-11-723511_chatcmpl-3e61c133-bee2-4f6d-85db-70b92a00fd66...\n",
      "Fetching observation data for time-20-22-55-402566_chatcmpl-40a638bf-60bf-45b8-97d8-c7077bea99d3...\n",
      "Fetching observation data for time-20-23-43-465433_chatcmpl-d42d55a0-1f34-46c4-bb0b-2e1cea67f908...\n",
      "Fetching observation data for time-20-24-32-235300_chatcmpl-8d54c163-6c7f-4d4c-9b0f-61fde70d9e72...\n",
      "Fetching observation data for time-20-25-23-205175_chatcmpl-a8ac1090-1637-4a11-96a5-1802b8b8fd9a...\n",
      "Fetching observation data for ecbc3d1a-5a94-4565-a3a3-94a9fd1b4076...\n",
      "Fetching observation data for time-20-18-09-126235_chatcmpl-ce058be3-656b-454f-98a8-c118ddebb232...\n",
      "Fetching observation data for time-20-18-51-307597_chatcmpl-cc84cb65-b41e-4cb1-b017-47f4aafb1f6b...\n",
      "Fetching observation data for time-20-19-37-731705_chatcmpl-4ae27a82-5401-4104-af60-929236e23302...\n",
      "Fetching observation data for time-20-20-29-169579_chatcmpl-1271da4b-208a-4d59-a643-2af492376d43...\n",
      "Fetching observation data for time-20-21-17-944999_chatcmpl-4444981e-e4ff-43d2-a77e-34e8ad7bdee7...\n",
      "Fetching observation data for 4e9d7455-8bc6-40e3-844a-09e699a72b05...\n",
      "Fetching observation data for time-20-13-59-212154_chatcmpl-6670fc43-4c53-41b6-b647-4a4478643141...\n",
      "Fetching observation data for time-20-14-41-942333_chatcmpl-630d787e-4b4f-4606-b5e2-2b2292b21165...\n",
      "Fetching observation data for time-20-15-32-614550_chatcmpl-02b3f25a-3af3-45da-85c4-4533fa9534ec...\n",
      "Fetching observation data for time-20-16-21-955608_chatcmpl-cca83b8c-039a-476a-814f-53c212f4c388...\n",
      "Fetching observation data for time-20-17-11-126365_chatcmpl-6e857e32-7253-473d-833f-5ebc16adfef5...\n",
      "Fetching observation data for dfd157a6-2606-4c39-9ee0-c0fa6408fffa...\n",
      "Fetching observation data for time-20-09-54-489027_chatcmpl-b2370dbc-1714-4413-95ce-11c9c9431134...\n",
      "Fetching observation data for time-20-10-34-799263_chatcmpl-13e3fd0f-4f84-486e-ad30-364e4903fb94...\n",
      "Fetching observation data for time-20-11-27-962567_chatcmpl-1e2cade0-56d6-4b2e-b3dc-1189d0c0effb...\n",
      "Fetching observation data for time-20-12-17-526252_chatcmpl-07afdf48-9f44-4e8b-bf48-918a6c236350...\n",
      "Fetching observation data for time-20-13-05-670981_chatcmpl-44547877-acb0-4866-bda2-4126d06ab164...\n",
      "Fetching observation data for fb70c2ac-e3e0-4ef3-99fb-aae84711bc3d...\n",
      "Fetching observation data for time-20-08-12-739398_chatcmpl-f3e29d25-2917-4edc-a7a2-2b00d8794faa...\n",
      "Fetching observation data for time-20-04-11-961246_chatcmpl-5e55f626-ebc9-42c2-b049-a50065b1aebb...\n",
      "Fetching observation data for time-20-04-54-241930_chatcmpl-5d0e60c5-edd8-4123-9cbe-0ddd4d0cc433...\n",
      "Fetching observation data for time-20-05-42-179496_chatcmpl-9d01f9c4-14f1-41ee-8634-76fed915a3b3...\n",
      "Fetching observation data for time-20-06-31-949354_chatcmpl-59677556-32a7-442f-adf3-0b87ea0fccff...\n",
      "Fetching observation data for time-20-07-18-716785_chatcmpl-548f8593-43c1-4387-8806-bbac866910dc...\n",
      "Fetching observation data for 2d0218bf-8f63-4abd-b17c-11171339bfb0...\n",
      "Fetching observation data for time-19-59-54-281334_chatcmpl-b362c042-5f03-4377-b94d-3d1c848e9aab...\n",
      "Fetching observation data for time-20-00-38-511489_chatcmpl-62a2a08c-4875-483c-8629-71ac56704e92...\n",
      "Fetching observation data for time-20-01-30-015547_chatcmpl-df1ff3ae-86f0-4f56-8960-02b495f68da8...\n",
      "Fetching observation data for time-20-02-21-712451_chatcmpl-94e704c5-207f-4d8a-802a-1b7edd393fa9...\n",
      "Fetching observation data for time-20-03-14-807723_chatcmpl-1bdbf9ea-b11d-4411-93e0-f40e38b72c47...\n",
      "Fetching observation data for 37e2ebef-2ae8-4540-944f-f516749039fa...\n",
      "Fetching observation data for time-19-55-55-702968_chatcmpl-31430011-ca29-48d3-a34a-2be7cc640a8e...\n",
      "Fetching observation data for time-19-56-36-378938_chatcmpl-c0cd1b3b-3522-4f7a-b28a-4de46ba9cc2c...\n",
      "Fetching observation data for time-19-57-22-416254_chatcmpl-978ee3dc-b4ed-4684-a128-b5a7fc952c4a...\n",
      "Fetching observation data for time-19-58-08-477627_chatcmpl-8e806586-becb-490b-be81-5c554a9b4936...\n",
      "Fetching observation data for time-19-58-59-598304_chatcmpl-8054b18d-1468-4dc6-b157-33763e7c76a8...\n",
      "Fetching observation data for 83b6d0e6-ae39-450b-8749-718cdfc726da...\n",
      "Fetching observation data for time-19-51-45-925051_chatcmpl-dded838a-b6e5-49c6-a68b-20507013d334...\n",
      "Fetching observation data for time-19-52-28-059843_chatcmpl-7f3a178a-7da2-4550-b69a-8f26cf2d9335...\n",
      "Fetching observation data for time-19-53-19-769788_chatcmpl-e1ae579b-579a-4281-9763-93ad534b585e...\n",
      "Fetching observation data for time-19-54-10-530094_chatcmpl-a2f08748-4d42-4a44-aa31-d716ae03fbec...\n",
      "Fetching observation data for time-19-55-01-853055_chatcmpl-d2a59470-7c65-4303-9952-7ec6130519e0...\n",
      "Fetching observation data for f47915a8-808d-449e-9e28-512270a064c9...\n",
      "Fetching observation data for time-19-47-37-304093_chatcmpl-7400e452-fdf7-4f12-a335-4445881f86cd...\n",
      "Fetching observation data for time-19-48-24-468357_chatcmpl-96359e96-9ef0-478e-83fa-a8dae7b7bfde...\n",
      "Fetching observation data for time-19-49-08-646771_chatcmpl-5bdc6b47-3c03-4b55-b013-76f7f7b7e07a...\n",
      "Fetching observation data for time-19-50-02-313505_chatcmpl-5f235f62-579d-4ee3-8468-3a938dc43385...\n",
      "Fetching observation data for time-19-50-51-352951_chatcmpl-f2d99fae-9146-4146-b187-ca74f62443d3...\n",
      "Fetching observation data for d2fa861f-0e59-41e0-9182-0adbda58536d...\n",
      "Fetching observation data for time-19-43-33-263315_chatcmpl-f47f1d10-f80a-438d-af2b-0bb26546513d...\n",
      "Fetching observation data for time-19-44-16-253504_chatcmpl-696f93a2-1930-4378-8a6a-494581657c0d...\n",
      "Fetching observation data for time-19-45-05-308463_chatcmpl-2795e045-c8a3-4f32-adcd-e615a6d7be5d...\n",
      "Fetching observation data for time-19-45-53-257680_chatcmpl-23c733a5-2ea7-4cb5-8750-5f5e92ea68d7...\n",
      "Fetching observation data for time-19-46-40-313664_chatcmpl-21ca1b98-053d-4338-83ef-84191c107023...\n",
      "Fetching observation data for c7011209-1449-4782-8c27-363b9d68c41f...\n",
      "Fetching observation data for time-19-39-31-565232_chatcmpl-5cdc9513-b581-43bd-8e5c-58efd6be11c1...\n",
      "Fetching observation data for time-19-40-12-896444_chatcmpl-d1965c40-392a-42cd-b828-3f045ce01879...\n",
      "Fetching observation data for time-19-41-00-917780_chatcmpl-f511fee9-127b-48f7-86d3-c387f019c66e...\n",
      "Fetching observation data for time-19-41-51-562441_chatcmpl-d1ea46d6-01b1-4a5f-a91d-bf4e16f06dae...\n",
      "Fetching observation data for time-19-42-38-503886_chatcmpl-79ab53e7-dc72-431d-a5a8-b750171c9e2d...\n",
      "Fetching observation data for 848ae6d1-86b7-4b6d-807b-c402214d4e6c...\n",
      "Fetching observation data for time-19-35-08-706765_chatcmpl-dc9003b6-63d2-455a-b760-cb57301e847a...\n",
      "Fetching observation data for time-19-35-53-039948_chatcmpl-4927de3f-dd30-480a-aa5f-a40543136028...\n",
      "Fetching observation data for time-19-36-45-103570_chatcmpl-1f7a3f8f-7fd8-44c2-ab93-cb7c0ac765ba...\n",
      "Fetching observation data for time-19-37-36-415548_chatcmpl-42085d5c-b78b-438e-94ae-51c11b5d9c85...\n",
      "Fetching observation data for time-19-38-37-062328_chatcmpl-54fe003a-4bc0-4c82-90f7-57a56f373ce2...\n",
      "Fetching observation data for d5538a62-9622-42f4-a891-fc69238de310...\n",
      "Fetching observation data for time-19-30-21-813520_chatcmpl-4555305d-08ab-4604-b52d-5f22db455166...\n",
      "Fetching observation data for time-19-31-36-907600_chatcmpl-10e4e6ac-d250-490f-8338-b9b85df87952...\n",
      "Fetching observation data for time-19-32-26-825022_chatcmpl-17ec252e-20d8-4085-ab4d-6e82620f638b...\n",
      "Fetching observation data for time-19-33-19-015144_chatcmpl-4c59b373-c759-4a43-b820-14115e13cf0e...\n",
      "Fetching observation data for time-19-34-09-764479_chatcmpl-3ab8f3ba-cdd6-4d2e-9c36-7993b45bb3e8...\n",
      "Fetching observation data for 5fb4bd8f-c5e2-4f9d-a096-9b94a79f2b17...\n",
      "Fetching observation data for c85a6918-26e6-44fe-86b3-4fe9f68aac7f...\n",
      "Fetching observation data for 57e4c596-d1a5-455d-9404-ce8730abd95a...\n",
      "Fetching observation data for 68e0b461-1430-47e4-a3f7-cfca1399fc09...\n",
      "Fetching observation data for 04c74fde-d7c6-4ec0-a387-7788f100e572...\n",
      "Fetching observation data for 14536dee-894b-48df-a484-efa55de8cca0...\n",
      "Fetching observation data for 4ca23000-8f9a-4168-b93c-9671d9bed3c1...\n",
      "Fetching observation data for 8d986505-9fd2-4f06-af3d-002a5b87ec39...\n",
      "Fetching observation data for 313669e6-2765-4200-91a3-8ae5f1cf7b58...\n",
      "Fetching observation data for e7b4ef5f-d70f-49c5-857b-9561eb4b0f58...\n",
      "Fetching observation data for 2dbe24be-6587-44de-b214-2f736366e123...\n",
      "Fetching observation data for da182fa7-784c-46b9-b3e0-f12967d282b5...\n",
      "Fetching observation data for e95b6979-d85e-4787-ab3d-8cd62987bb2c...\n",
      "Fetching observation data for 51757002-d1c3-4618-b928-4d85f538017d...\n",
      "Fetching observation data for fe0919c1-f0c4-40e7-b3bd-a85652d38e9b...\n",
      "Fetching observation data for 522643a0-f7dd-405b-86f5-691c3ca680f2...\n",
      "Raw JSON saved to: /Users/hann/Projects/reference-benchmark-tinyml_llm/data_analysis/07.30_b/raw_export/raw_gemma3:27b_85a9_tpusg_batch.json\n"
     ]
    }
   ],
   "source": [
    "# ALTERNATIVE TO 2.\n",
    "import os\n",
    "import json\n",
    "from time import sleep\n",
    "from langfuse import Langfuse\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "\n",
    "# LANGFUSE_SERVICE_PUBLIC_KEY = \"pk-lf-559a2c0f-ee29-4c32-944c-bf73b5f0ce28\"\n",
    "# LANGFUSE_SERVICE_SECRET_KEY = \"sk-lf-75f8bf7f-a5db-4756-b0dd-d758a2a292c8\"\n",
    "# LANGFUSE_SERVICE_HOST = \"https://langfuse.hann.fi\"\n",
    "\n",
    "\n",
    "if LOCAL_HOST:\n",
    "    langfuse = Langfuse(\n",
    "        secret_key=\"sk-lf-75f8bf7f-a5db-4756-b0dd-d758a2a292c8\",\n",
    "        public_key=\"pk-lf-559a2c0f-ee29-4c32-944c-bf73b5f0ce28\",\n",
    "        host=\"https://langfuse.hann.fi\",\n",
    "    )\n",
    "else:\n",
    "    langfuse = Langfuse(\n",
    "        secret_key=LANGFUSE_SERVICE_SECRET_KEY,\n",
    "        public_key=LANGFUSE_SERVICE_PUBLIC_KEY,\n",
    "        host=LANGFUSE_SERVICE_HOST,\n",
    "    )\n",
    "\n",
    "API_invok_count = 0\n",
    "query_range_num_run = {\"start\": 0, \"end\": 1}\n",
    "\n",
    "\n",
    "class CustomJSONEncoder(json.JSONEncoder):\n",
    "    def __init__(self, *args, LOCAL_HOST=True, **kwargs):\n",
    "        self.LOCAL_HOST = LOCAL_HOST\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "    def default(self, obj):\n",
    "        if isinstance(obj, datetime):\n",
    "            return obj.isoformat()\n",
    "        if hasattr(obj, \"__dict__\"):\n",
    "            data = obj.__dict__.copy()\n",
    "            if \"observations\" in data:\n",
    "                data[\"observations\"] = [\n",
    "                    fetch_observation_data(obs, self.LOCAL_HOST)\n",
    "                    for obs in data[\"observations\"]\n",
    "                ]\n",
    "\n",
    "            return data\n",
    "        return super().default(obj)\n",
    "\n",
    "\n",
    "def fetch_observation_data(observation_id, LOCAL_HOST):\n",
    "    \"\"\"\n",
    "    Fetches observation data from Langfuse and returns its dictionary representation.\n",
    "    \"\"\"\n",
    "    print(f\"Fetching observation data for {observation_id}...\")\n",
    "    global API_invok_count\n",
    "    if API_invok_count >= 0 and not LOCAL_HOST:\n",
    "        print(\"Waiting for 3 seconds to fetch observation data...\")\n",
    "        for _ in tqdm(range(3), desc=\"Progress\", unit=\"s\"):\n",
    "            sleep(1)\n",
    "        API_invok_count = 0\n",
    "\n",
    "    observation_response = langfuse.fetch_observation(observation_id)\n",
    "    API_invok_count += 1\n",
    "\n",
    "    return observation_response.data.dict()\n",
    "\n",
    "\n",
    "def fetch_and_save_complete_data(session_id_list, raw_export_dir, LOCAL_HOST):\n",
    "    \"\"\"\n",
    "    Fetches complete trace data for each session ID and saves it to JSON files.\n",
    "\n",
    "    Parameters:\n",
    "        session_id_list (list): List of session IDs to process.\n",
    "        raw_export_dir (str): Directory path to save raw JSON files.\n",
    "    \"\"\"\n",
    "\n",
    "    def save_complete_data(session_id):\n",
    "        global API_invok_count\n",
    "        if API_invok_count >= 0 and not LOCAL_HOST:\n",
    "            print(\"Waiting for 4 seconds to fetch traces...\")\n",
    "            for _ in tqdm(range(4), desc=\"Progress\", unit=\"s\"):\n",
    "                sleep(1)\n",
    "            API_invok_count = 0\n",
    "\n",
    "        fetch_traces_response = langfuse.fetch_traces(session_id=session_id)\n",
    "        API_invok_count += 1\n",
    "\n",
    "        print(f\"Fetching traces for session {session_id}...\")\n",
    "        # Create directories if they don't exist\n",
    "        os.makedirs(raw_export_dir, exist_ok=True)\n",
    "\n",
    "        # Save complete data to JSON file\n",
    "        # if session_id.startswith(\"da0a\"):\n",
    "        #     session_id = \"phi4_\" + session_id\n",
    "        if \"tpsg\" in session_id:\n",
    "            session_id_ = session_id.replace(\"tpsg\", \"tpusg\")\n",
    "        else:\n",
    "            session_id_ = session_id\n",
    "            \n",
    "        raw_path = os.path.join(raw_export_dir, f\"raw_{session_id_}.json\")\n",
    "        with open(raw_path, \"w\") as f:\n",
    "            json.dump(fetch_traces_response, f, cls=CustomJSONEncoder, indent=2)\n",
    "\n",
    "        print(f\"Raw JSON saved to: {raw_path}\")\n",
    "\n",
    "    for session_id in session_id_list:\n",
    "        save_complete_data(session_id)\n",
    "\n",
    "\n",
    "fetch_and_save_complete_data(session_id_list, raw_export_dir, LOCAL_HOST)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Trim data\n",
    "\n",
    "Here also intercept the runs with fatal errors that need to be excluded from the analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPAN error_50_psg_failure_signal_py_sketch_generator: Failed. Last error: Traceback (most recent call last):\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250730210800_psg_gemma3:27b/tmp_20250730210800_psg_gemma3:27b.py\", line 29, in <module>\n",
      "    net = cv2.dnn.readNet(model_path)\n",
      "cv2.error: OpenCV(4.10.0) /io/opencv/modules/dnn/src/tflite/tflite_importer.cpp:118: error: (-213:The function/feature is not implemented) Parse tensor with type UINT8 in function 'parseTensor'\n",
      "\n",
      "\n",
      "SPAN error_74_psg_failure_signal_py_sketch_generator: Failed. Last error: Traceback (most recent call last):\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250730205719_psg_gemma3:27b/tmp_20250730205719_psg_gemma3:27b.py\", line 21, in <module>\n",
      "    interpreter.allocate_tensor()\n",
      "AttributeError: 'Interpreter' object has no attribute 'allocate_tensor'. Did you mean: 'allocate_tensors'?\n",
      "\n",
      "SPAN error_d5_psg_failure_signal_py_sketch_generator: Failed. Last error: Traceback (most recent call last):\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250730205050_psg_gemma3:27b/tmp_20250730205050_psg_gemma3:27b.py\", line 21, in <module>\n",
      "    net = cv2.dnn.readNet(model_path)\n",
      "cv2.error: OpenCV(4.10.0) /io/opencv/modules/dnn/src/tflite/tflite_importer.cpp:118: error: (-213:The function/feature is not implemented) Parse tensor with type UINT8 in function 'parseTensor'\n",
      "\n",
      "\n",
      "SPAN error_b2_psg_failure_signal_py_sketch_generator: Failed. Last error: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250730204819_psg_gemma3:27b/tmp_20250730204819_psg_gemma3:27b.py\", line 45, in <module>\n",
      "    interpreter.set_tensor(input_details[0]['index'], input_data)\n",
      "  File \"/home/wuguangh/.conda/envs/tinyml/lib/python3.10/site-packages/ai_edge_litert/interpreter.py\", line 764, in set_tensor\n",
      "    self._interpreter.SetTensor(tensor_index, value)\n",
      "ValueError: Cannot set tensor: Got value of type FLOAT32 but expected type UINT8 for input 175, name: normalized_input_image_tensor \n",
      "\n",
      "SPAN error_60_psg_failure_signal_py_sketch_generator: Failed. Last error: Traceback (most recent call last):\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250730204553_psg_gemma3:27b/tmp_20250730204553_psg_gemma3:27b.py\", line 15, in <module>\n",
      "    interpreter.allocate_tensor()\n",
      "AttributeError: 'Interpreter' object has no attribute 'allocate_tensor'. Did you mean: 'allocate_tensors'?\n",
      "\n",
      "SPAN error_be_psg_failure_signal_py_sketch_generator: Failed. Last error: Traceback (most recent call last):\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250730204210_psg_gemma3:27b/tmp_20250730204210_psg_gemma3:27b.py\", line 14, in <module>\n",
      "    net = cv2.dnn.readNet(model_path)\n",
      "cv2.error: OpenCV(4.10.0) /io/opencv/modules/dnn/src/tflite/tflite_importer.cpp:118: error: (-213:The function/feature is not implemented) Parse tensor with type UINT8 in function 'parseTensor'\n",
      "\n",
      "\n",
      "Successfully processed and saved trimmed data for session gemma3:27b_85a9_psg_batch\n",
      "SPAN error_1a_tpusg_failure_signal_tpu_sketch_generator: Failed. Last error: Traceback (most recent call last):\n",
      "  File \"script_a1892503_1753896608.py\", line 63, in <module>\n",
      "    if scores > confidence_threshold:\n",
      "ValueError: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()\n",
      "SPAN error_c0_tpusg_failure_signal_tpu_sketch_generator: Failed. Last error: Traceback (most recent call last):\n",
      "  File \"script_bff71d51_1753896363.py\", line 59, in <module>\n",
      "    if scores > 0.5:\n",
      "ValueError: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()\n",
      "SPAN error_89_tpusg_failure_signal_tpu_sketch_generator: Failed. Last error: Traceback (most recent call last):\n",
      "  File \"script_e6556542_1753896116.py\", line 59, in <module>\n",
      "    if scores > confidence_threshold:\n",
      "ValueError: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()\n",
      "SPAN error_e6_tpusg_failure_signal_tpu_sketch_generator: Failed. Last error: Traceback (most recent call last):\n",
      "  File \"script_568a8a56_1753895874.py\", line 64, in <module>\n",
      "    if confidence > 0.5:\n",
      "ValueError: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()\n",
      "SPAN error_1d_tpusg_failure_signal_tpu_sketch_generator: Failed. Last error: Traceback (most recent call last):\n",
      "  File \"script_c6ff16a5_1753895625.py\", line 55, in <module>\n",
      "    interpreter.set_tensor(input_details[0]['index'], input_data)\n",
      "  File \"/home/mendel/tinyml_autopilot/tinyml-env/lib/python3.7/site-packages/tflite_runtime/interpreter.py\", line 572, in set_tensor\n",
      "    self._interpreter.SetTensor(tensor_index, value)\n",
      "ValueError: Cannot set tensor: Got value of type FLOAT32 but expected type UINT8 for input 175, name: normalized_input_image_tensor \n",
      "SPAN error_47_tpusg_failure_signal_tpu_sketch_generator: Failed. Last error: Traceback (most recent call last):\n",
      "  File \"script_76645b10_1753895278.py\", line 63, in <module>\n",
      "    if scores > 0.5:\n",
      "ValueError: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()\n",
      "SPAN error_69_tpusg_failure_signal_tpu_sketch_generator: Failed. Last error: Traceback (most recent call last):\n",
      "  File \"script_57bfe6cc_1753895036.py\", line 66, in <module>\n",
      "    if scores > confidence_threshold:\n",
      "ValueError: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()\n",
      "SPAN error_eb_tpusg_failure_signal_tpu_sketch_generator: Failed. Last error: Traceback (most recent call last):\n",
      "  File \"script_1f389844_1753894779.py\", line 62, in <module>\n",
      "    if scores > 0.5:\n",
      "ValueError: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()\n",
      "SPAN error_50_tpusg_failure_signal_tpu_sketch_generator: Failed. Last error: Traceback (most recent call last):\n",
      "  File \"script_a6dc0deb_1753894541.py\", line 73, in <module>\n",
      "    if scores > confidence_threshold:\n",
      "ValueError: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()\n",
      "SPAN error_db_tpusg_failure_signal_tpu_sketch_generator: Failed. Last error: Traceback (most recent call last):\n",
      "  File \"script_82567684_1753894292.py\", line 13, in <module>\n",
      "    input_shape = input_details[0]['shape']\n",
      "TypeError: string indices must be integers\n",
      "SPAN error_9d_tpusg_failure_signal_tpu_sketch_generator: Failed. Last error: Traceback (most recent call last):\n",
      "  File \"script_e6132835_1753894042.py\", line 61, in <module>\n",
      "    if scores > confidence_threshold:\n",
      "ValueError: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()\n",
      "SPAN error_94_tpusg_failure_signal_tpu_sketch_generator: Failed. Last error: Traceback (most recent call last):\n",
      "  File \"script_94741fcb_1753893798.py\", line 58, in <module>\n",
      "    if confidence > 0.5:\n",
      "ValueError: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()\n",
      "SPAN error_8f_tpusg_failure_signal_tpu_sketch_generator: Failed. Last error: Traceback (most recent call last):\n",
      "  File \"script_9343285f_1753893558.py\", line 65, in <module>\n",
      "    classes = output_data[0, ..., 5]\n",
      "IndexError: index 5 is out of bounds for axis 2 with size 4\n",
      "SPAN error_c0_tpusg_failure_signal_tpu_sketch_generator: Failed. Last error: Traceback (most recent call last):\n",
      "  File \"script_d03ea379_1753893294.py\", line 3, in <module>\n",
      "    import tensorflow as tf\n",
      "ModuleNotFoundError: No module named 'tensorflow'\n",
      "SPAN error_70_tpusg_failure_signal_tpu_sketch_generator: Failed. Last error: Unexpected error during generation: litellm.APIConnectionError: OllamaException - {\"error\":\"llama runner process has terminated: CUDA error: all CUDA-capable devices are busy or unavailable\\n  current device: 0, in function ggml_backend_cuda_device_get_memory at //ml/backend/ggml/ggml/src/ggml-cuda/ggml-cuda.cu:2898\\n  cudaMemGetInfo(free, total)\\n//ml/backend/ggml/ggml/src/ggml-cuda/ggml-cuda.cu:73: CUDA error\"}\n",
      "SPAN error_50_tpusg_failure_signal_tpu_sketch_generator: Failed. Last error: Unexpected error during generation: litellm.APIConnectionError: OllamaException - {\"error\":\"llama runner process has terminated: CUDA error\"}\n",
      "SPAN error_cb_tpusg_failure_signal_tpu_sketch_generator: Failed. Last error: Unexpected error during generation: litellm.APIConnectionError: OllamaException - {\"error\":\"llama runner process has terminated: CUDA error: all CUDA-capable devices are busy or unavailable\\n  current device: 0, in function ggml_backend_cuda_device_get_memory at //ml/backend/ggml/ggml/src/ggml-cuda/ggml-cuda.cu:2898\\n  cudaMemGetInfo(free, total)\\n//ml/backend/ggml/ggml/src/ggml-cuda/ggml-cuda.cu:73: CUDA error\"}\n",
      "SPAN error_83_tpusg_failure_signal_tpu_sketch_generator: Failed. Last error: Unexpected error during generation: litellm.APIConnectionError: OllamaException - {\"error\":\"llama runner process has terminated: CUDA error: all CUDA-capable devices are busy or unavailable\\n  current device: 0, in function ggml_backend_cuda_device_get_memory at //ml/backend/ggml/ggml/src/ggml-cuda/ggml-cuda.cu:2898\\n  cudaMemGetInfo(free, total)\\n//ml/backend/ggml/ggml/src/ggml-cuda/ggml-cuda.cu:73: CUDA error\"}\n",
      "SPAN error_70_tpusg_failure_signal_tpu_sketch_generator: Failed. Last error: Unexpected error during generation: litellm.APIConnectionError: OllamaException - {\"error\":\"llama runner process has terminated: CUDA error\"}\n",
      "SPAN error_e8_tpusg_failure_signal_tpu_sketch_generator: Failed. Last error: Unexpected error during generation: litellm.APIConnectionError: OllamaException - {\"error\":\"llama runner process has terminated: CUDA error\"}\n",
      "SPAN error_3d_tpusg_failure_signal_tpu_sketch_generator: Failed. Last error: Unexpected error during generation: litellm.APIConnectionError: OllamaException - {\"error\":\"llama runner process has terminated: CUDA error\"}\n",
      "SPAN error_b2_tpusg_failure_signal_tpu_sketch_generator: Failed. Last error: Unexpected error during generation: litellm.APIConnectionError: OllamaException - {\"error\":\"llama runner process has terminated: CUDA error\"}\n",
      "SPAN error_4b_tpusg_failure_signal_tpu_sketch_generator: Failed. Last error: Unexpected error during generation: litellm.APIConnectionError: OllamaException - {\"error\":\"llama runner process has terminated: CUDA error\"}\n",
      "SPAN error_b3_tpusg_failure_signal_tpu_sketch_generator: Failed. Last error: Unexpected error during generation: litellm.APIConnectionError: OllamaException - {\"error\":\"llama runner process has terminated: CUDA error\"}\n",
      "SPAN error_0f_tpusg_failure_signal_tpu_sketch_generator: Failed. Last error: Unexpected error during generation: litellm.APIConnectionError: OllamaException - {\"error\":\"llama runner process has terminated: CUDA error\"}\n",
      "SPAN error_6d_tpusg_failure_signal_tpu_sketch_generator: Failed. Last error: Unexpected error during generation: litellm.APIConnectionError: OllamaException - {\"error\":\"llama runner process has terminated: CUDA error\"}\n",
      "SPAN error_5c_tpusg_failure_signal_tpu_sketch_generator: Failed. Last error: Unexpected error during generation: litellm.APIConnectionError: OllamaException - {\"error\":\"llama runner process has terminated: CUDA error\"}\n",
      "SPAN error_1e_tpusg_failure_signal_tpu_sketch_generator: Failed. Last error: Unexpected error during generation: litellm.APIConnectionError: OllamaException - {\"error\":\"llama runner process has terminated: CUDA error\"}\n",
      "SPAN error_8c_tpusg_failure_signal_tpu_sketch_generator: Failed. Last error: Unexpected error during generation: litellm.APIConnectionError: OllamaException - {\"error\":\"llama runner process has terminated: CUDA error\"}\n",
      "Successfully processed and saved trimmed data for session gemma3:27b_85a9_tpusg_batch\n",
      "Total 0 traces skipped. They are []\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "skipped_traces = []\n",
    "\n",
    "\n",
    "def process_existing_observation(observation):\n",
    "    \"\"\"\n",
    "    Processes an existing observation dictionary by trimming unwanted keys.\n",
    "    \"\"\"\n",
    "    unwanted_observation_keys = [\n",
    "        \"completionStartTime\",\n",
    "        \"metadata\",\n",
    "        \"timeToFirstToken\",\n",
    "        \"createdAt\",\n",
    "        \"usageDetails\",\n",
    "        \"usage\",\n",
    "        \"projectId\",\n",
    "        \"unit\",\n",
    "        \"updatedAt\",\n",
    "        \"version\",\n",
    "        \"parentObservationId\",\n",
    "        \"promptId\",\n",
    "        \"promptName\",\n",
    "        \"promptVersion\",\n",
    "        \"modelId\",\n",
    "        \"inputPrice\",\n",
    "        \"outputPrice\",\n",
    "        \"totalPrice\",\n",
    "        # \"modelParameters\",\n",
    "        \"input\",\n",
    "        \"output\",\n",
    "    ]\n",
    "\n",
    "    # If observation is a dictionary containing observation data\n",
    "    if isinstance(observation, dict):\n",
    "        trimmed_observation = {\n",
    "            k: v for k, v in observation.items() if k not in unwanted_observation_keys\n",
    "        }\n",
    "        return trimmed_observation\n",
    "    return observation\n",
    "\n",
    "\n",
    "def trim_data(data):\n",
    "    \"\"\"\n",
    "    Recursively trims the data structure.\n",
    "    \"\"\"\n",
    "\n",
    "    if isinstance(data, dict):\n",
    "        # Process the current dictionary\n",
    "        unwanted_trace_keys = [\n",
    "            \"release\",\n",
    "            \"version\",\n",
    "            \"user_id\",\n",
    "            \"public\",\n",
    "            \"html_path\",\n",
    "            \"scores\",\n",
    "            \"bookmarked\",\n",
    "            \"projectId\",\n",
    "            \"externalId\",\n",
    "            \"page\",\n",
    "            \"limit\",\n",
    "            \"total_pages\",\n",
    "        ]\n",
    "\n",
    "        # If this is a trace that contains observations, check for fatal errors\n",
    "        if \"observations\" in data:\n",
    "            # Check for SPAN observations with fatal errors before processing\n",
    "            skip_trace = False\n",
    "            for obs in data[\"observations\"]:\n",
    "                if isinstance(obs, dict) and obs.get(\"name\").startswith(\"error\"):\n",
    "                    status_message = obs.get(\"statusMessage\", \"\")\n",
    "                    ob_name = obs.get(\"name\")\n",
    "                    print(f\"SPAN {ob_name}: {status_message}\")\n",
    "\n",
    "                    if \"Fatal error\" in status_message:\n",
    "                        print(f\"Found Fatal error in SPAN observation, skipping trace\")\n",
    "                        skip_trace = True\n",
    "                        skipped_traces.append(data[\"name\"])\n",
    "                        break\n",
    "\n",
    "            if skip_trace:\n",
    "                return None  # Signal to skip this trace\n",
    "\n",
    "        # Create a new dictionary with wanted keys and recursively process values\n",
    "        trimmed_data = {}\n",
    "        for key, value in data.items():\n",
    "            if key not in unwanted_trace_keys:\n",
    "                if key == \"observations\":\n",
    "                    # Special handling for observations\n",
    "                    trimmed_data[key] = [\n",
    "                        process_existing_observation(obs) for obs in value\n",
    "                    ]\n",
    "                elif isinstance(value, (dict, list)):\n",
    "                    # Recursively process nested structures\n",
    "                    trimmed_data[key] = trim_data(value)\n",
    "                else:\n",
    "                    trimmed_data[key] = value\n",
    "\n",
    "        return trimmed_data\n",
    "\n",
    "    elif isinstance(data, list):\n",
    "        # Recursively process each item in the list\n",
    "        processed_items = []\n",
    "        for item in data:\n",
    "            processed_item = trim_data(item)\n",
    "            if processed_item is not None:  # Only add items that weren't filtered out\n",
    "                processed_items.append(processed_item)\n",
    "        return processed_items\n",
    "\n",
    "    else:\n",
    "        # Return non-dict, non-list values as is\n",
    "        return data\n",
    "\n",
    "\n",
    "def read_and_trim_data(session_id_list, raw_export_dir, trimmed_export_dir):\n",
    "    \"\"\"\n",
    "    Reads complete data from JSON files, trims the data, and saves the trimmed data to new JSON files.\n",
    "    \"\"\"\n",
    "    os.makedirs(trimmed_export_dir, exist_ok=True)\n",
    "\n",
    "    for session_id in session_id_list:\n",
    "        try:\n",
    "            if session_id.startswith(\"da0a\"):\n",
    "                session_id = \"phi4_\" + session_id\n",
    "            # Read raw data\n",
    "            if \"tpsg\" in session_id:\n",
    "                session_id_ = session_id.replace(\"tpsg\", \"tpusg\")\n",
    "            else:\n",
    "                session_id_ = session_id\n",
    "            raw_path = os.path.join(raw_export_dir, f\"raw_{session_id_}.json\")\n",
    "            with open(raw_path, \"r\") as f:\n",
    "                data = json.load(f)\n",
    "\n",
    "            # Process and trim the data\n",
    "            trimmed_data = trim_data(data)\n",
    "\n",
    "            # If the entire data was filtered out (unlikely but possible)\n",
    "            if trimmed_data is None:\n",
    "                print(\n",
    "                    f\"All traces in session {session_id} were filtered due to fatal errors\"\n",
    "                )\n",
    "                continue\n",
    "\n",
    "            # Save trimmed data\n",
    "            if \"tpsg\" in session_id:\n",
    "                session_id_ = session_id.replace(\"tpsg\", \"tpusg\")\n",
    "            else:\n",
    "                session_id_ = session_id\n",
    "            trimmed_path = os.path.join(\n",
    "                trimmed_export_dir, f\"trimmed_{session_id_}.json\"\n",
    "            )\n",
    "            with open(trimmed_path, \"w\") as f:\n",
    "                json.dump(trimmed_data, f, indent=2)\n",
    "\n",
    "            print(\n",
    "                f\"Successfully processed and saved trimmed data for session {session_id}\"\n",
    "            )\n",
    "\n",
    "            # Optional: Verify trimming worked\n",
    "            # print(f\"Verifying trimmed data for session {session_id}...\")\n",
    "            # verify_trimming(trimmed_path)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing session {session_id}: {str(e)}\")\n",
    "\n",
    "\n",
    "def verify_trimming(trimmed_path):\n",
    "    \"\"\"\n",
    "    Verifies that the trimmed data doesn't contain unwanted keys.\n",
    "    \"\"\"\n",
    "    with open(trimmed_path, \"r\") as f:\n",
    "        trimmed_data = json.load(f)\n",
    "\n",
    "    unwanted_keys = [\n",
    "        \"release\",\n",
    "        \"version\",\n",
    "        \"user_id\",\n",
    "        \"public\",\n",
    "        \"html_path\",\n",
    "        \"scores\",\n",
    "        \"bookmarked\",\n",
    "        \"projectId\",\n",
    "        \"externalId\",\n",
    "        \"page\",\n",
    "        \"limit\",\n",
    "        \"total_pages\",\n",
    "        \"completionStartTime\",\n",
    "        \"metadata\",\n",
    "        \"usageDetails\",\n",
    "        \"timeToFirstToken\",\n",
    "        \"createdAt\",\n",
    "        \"completionTokens\",\n",
    "        \"promptTokens\",\n",
    "        \"projectId\",\n",
    "        \"unit\",\n",
    "        \"updatedAt\",\n",
    "        \"version\",\n",
    "        # \"statusMessage\",\n",
    "        \"parentObservationId\",\n",
    "        \"promptId\",\n",
    "        \"promptName\",\n",
    "        \"promptVersion\",\n",
    "        \"modelId\",\n",
    "        \"inputPrice\",\n",
    "        \"outputPrice\",\n",
    "        \"totalPrice\",\n",
    "        \"calculatedInputCost\",\n",
    "        \"calculatedOutputCost\",\n",
    "        \"calculatedTotalCost\",\n",
    "    ]\n",
    "\n",
    "    def check_keys(obj):\n",
    "        if isinstance(obj, dict):\n",
    "            for key in obj.keys():\n",
    "                if key in unwanted_keys:\n",
    "                    print(f\"Warning: Found unwanted key '{key}' in trimmed data\")\n",
    "            for value in obj.values():\n",
    "                check_keys(value)\n",
    "        elif isinstance(obj, list):\n",
    "            for item in obj:\n",
    "                check_keys(item)\n",
    "\n",
    "    check_keys(trimmed_data)\n",
    "    print(\"Verification complete\")\n",
    "\n",
    "\n",
    "# Usage example:\n",
    "read_and_trim_data(session_id_list, raw_export_dir, raw_export_dir)\n",
    "print(f\"Total {len(skipped_traces)} traces skipped. They are {skipped_traces}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Generate CSV files from JSON\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing session gemma3:27b_85a9_psg_batch, simple id gemma3:27b_85a9. Look for /Users/hann/Projects/reference-benchmark-tinyml_llm/data_analysis/07.30_b/raw_export/trimmed_gemma3:27b_85a9_psg_batch.json\n",
      "/Users/hann/Projects/reference-benchmark-tinyml_llm/data_analysis/07.30_b/processed_data/gemma3:27b_85a9/clean_gemma3:27b_85a9_psg_batch.csv\n",
      "Successfully saved CSV to: /Users/hann/Projects/reference-benchmark-tinyml_llm/data_analysis/07.30_b/processed_data/gemma3:27b_85a9/clean_gemma3:27b_85a9_psg_batch.csv\n",
      "Processing session gemma3:27b_85a9_tpusg_batch, simple id gemma3:27b_85a9. Look for /Users/hann/Projects/reference-benchmark-tinyml_llm/data_analysis/07.30_b/raw_export/trimmed_gemma3:27b_85a9_tpusg_batch.json\n",
      "/Users/hann/Projects/reference-benchmark-tinyml_llm/data_analysis/07.30_b/processed_data/gemma3:27b_85a9/clean_gemma3:27b_85a9_tpusg_batch.csv\n",
      "Successfully saved CSV to: /Users/hann/Projects/reference-benchmark-tinyml_llm/data_analysis/07.30_b/processed_data/gemma3:27b_85a9/clean_gemma3:27b_85a9_tpusg_batch.csv\n"
     ]
    }
   ],
   "source": [
    "import traceback\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from dateutil import parser\n",
    "\n",
    "\n",
    "def json_to_csv(session_id):\n",
    "    \"\"\"\n",
    "    Convert JSON trace data to CSV format with aggregated metrics.\n",
    "\n",
    "    Args:\n",
    "        session_id (str): Identifier for the session to process\n",
    "    \"\"\"\n",
    "\n",
    "    def extract_observation_details(observations, trace_id):\n",
    "        \"\"\"Extract and aggregate metrics from observations\"\"\"\n",
    "        metrics = {\n",
    "            \"status\": None,\n",
    "            \"latency\": 0,\n",
    "            \"total_tokens\": 0,\n",
    "            \"prompt_tokens\": 0,\n",
    "            \"completion_tokens\": 0,\n",
    "            \"total_cost\": 0,\n",
    "            \"input_cost\": 0,\n",
    "            \"output_cost\": 0,\n",
    "            \"parameters\": set(),\n",
    "        }\n",
    "\n",
    "        # Process GENERATION observations\n",
    "        for obs in (o for o in observations if o[\"type\"] == \"GENERATION\"):\n",
    "            metrics[\"total_tokens\"] += obs[\"totalTokens\"]\n",
    "            metrics[\"prompt_tokens\"] += obs[\"promptTokens\"]\n",
    "            metrics[\"completion_tokens\"] += obs[\"completionTokens\"]\n",
    "            metrics[\"latency\"] += obs[\"latency\"]\n",
    "            for key, value in obs[\"modelParameters\"].items():\n",
    "                metrics[\"parameters\"].add(key + \":\" + value)\n",
    "\n",
    "            # Add costs if present\n",
    "            for cost_type in [\"Total\", \"Input\", \"Output\"]:\n",
    "                key = f\"calculated{cost_type}Cost\"\n",
    "                metric_key = cost_type.lower() + \"_cost\"\n",
    "                if obs.get(key) is not None:\n",
    "                    metrics[metric_key] += obs[key]\n",
    "        if len(metrics[\"parameters\"]) == 0:\n",
    "            metrics[\"parameters\"] = \"N/A\"\n",
    "        # Process SPAN observations for status\n",
    "        status_indicators = [\n",
    "            obs[\"name\"]\n",
    "            for obs in observations\n",
    "            if obs[\"type\"] == \"SPAN\" and \"start_\" not in obs[\"name\"]\n",
    "        ]\n",
    "\n",
    "        #  if later than 2025-05-19, use status_signal_from_output\n",
    "        if datetime.now() > datetime(2025, 5, 19):\n",
    "            pass\n",
    "        else:\n",
    "            # Determine status\n",
    "            success_signals = sum(\"end_\" in name for name in status_indicators)\n",
    "            failure_signals = sum(\n",
    "                \"failure_signal\" in name for name in status_indicators\n",
    "            )\n",
    "\n",
    "            if success_signals + failure_signals > 1:\n",
    "                raise ValueError(\n",
    "                    f\"Multiple status indicators found in trace {trace_id}\"\n",
    "                )\n",
    "\n",
    "            metrics[\"status\"] = (\n",
    "                \"success\"\n",
    "                if success_signals\n",
    "                else \"failure\" if failure_signals else \"unknown\"\n",
    "            )\n",
    "\n",
    "        metrics[\"prompt_cost\"] = metrics.pop(\"input_cost\")\n",
    "        metrics[\"completion_cost\"] = metrics.pop(\"output_cost\")\n",
    "        metrics[\"latency\"] = round(metrics[\"latency\"] / 1000, 2)\n",
    "        return metrics\n",
    "\n",
    "    def cal_time(trace):\n",
    "        time_diff = datetime.fromisoformat(\n",
    "            trace[\"updatedAt\"].replace(\"Z\", \"+00:00\")\n",
    "        ) - datetime.fromisoformat(trace[\"createdAt\"].replace(\"Z\", \"+00:00\"))\n",
    "        seconds_diff = time_diff.total_seconds()\n",
    "        return seconds_diff\n",
    "\n",
    "    try:\n",
    "\n",
    "        if session_id.startswith(\"da0a\"):\n",
    "            session_id = \"phi4_\" + session_id\n",
    "        simple_session_id = session_id.rsplit(\"_\", 2)[0]\n",
    "\n",
    "        \n",
    "        # Load JSON data\n",
    "        if \"tpsg\" in session_id:\n",
    "                session_id_ = session_id.replace(\"tpsg\", \"tpusg\")\n",
    "        else:\n",
    "                session_id_ = session_id\n",
    "        trimmed_path = os.path.join(raw_export_dir, f\"trimmed_{session_id_}.json\")\n",
    "        print(\n",
    "            f\"Processing session {session_id}, simple id {simple_session_id}. Look for {trimmed_path}\"\n",
    "        )\n",
    "        with open(trimmed_path, \"r\") as file:\n",
    "            traces = json.load(file)[\"data\"]\n",
    "\n",
    "        # Process traces\n",
    "        rows = [\n",
    "            {\n",
    "                \"num_run\": trace[\"metadata\"][\"num_run\"],\n",
    "                \"name\": trace[\"name\"],\n",
    "                \"trace_id\": trace[\"id\"],\n",
    "                \"batch_id\": trace[\"session_id\"],\n",
    "                # \"latency\": cal_time(trace),\n",
    "                # \"latency\": round(trace[\"latency\"], 2),\n",
    "                **extract_observation_details(\n",
    "                    trace[\"observations\"],\n",
    "                    trace[\"id\"],\n",
    "                ),\n",
    "                \"status\": (\n",
    "                    \"failure\"\n",
    "                    if trace[\"output\"][\"status\"].lower() == \"failed\"\n",
    "                    else \"success\"\n",
    "                ),\n",
    "                \"tags\": trace[\"tags\"],\n",
    "                \"timestamp\": int(parser.isoparse(trace[\"timestamp\"]).timestamp()),\n",
    "            }\n",
    "            for trace in traces\n",
    "        ]\n",
    "        # print(rows)\n",
    "        # print(rows)\n",
    "        # Create and save DataFrame\n",
    "        df = pd.DataFrame(rows).sort_values(\"num_run\")\n",
    "\n",
    "        output_dir = os.path.join(processed_data_dir, f\"{simple_session_id}\")\n",
    "        if not os.path.exists(output_dir):\n",
    "            os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "        output_path = os.path.join(output_dir, f\"clean_{session_id_}.csv\")\n",
    "\n",
    "        print(output_path)\n",
    "        df.to_csv(output_path, index=False)\n",
    "        print(f\"Successfully saved CSV to: {output_path}\")\n",
    "\n",
    "    except FileNotFoundError as e:\n",
    "        print(\n",
    "            f\"FileNotFoundError: For session {session_id} not found. Looked for {trimmed_path}\\nError info: \\n{e}\\n\\nTraceback: {traceback.format_exc()}\"\n",
    "        )\n",
    "    except json.JSONDecodeError:\n",
    "        print(f\"Error: Invalid JSON format in input file for session {session_id}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing session {session_id}: {str(e)}\")\n",
    "\n",
    "\n",
    "# Example usage\n",
    "for session_id in session_id_list:\n",
    "    json_to_csv(session_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code below is archived\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"\"\"Simply calculate success rate\"\"\"\n",
    "\n",
    "\n",
    "# def cal_success_rate(session_id):\n",
    "\n",
    "#     end_signal_count = 0\n",
    "#     failure_signal_count = 0\n",
    "#     # Function to print the name of each observation\n",
    "#     with open(f\"{raw_export_dir}/trimmed_{session_id}.json\", \"r\") as file:\n",
    "#         data = json.load(file)[\"data\"]\n",
    "#     for i in data:\n",
    "\n",
    "#         observations = i[\"observations\"]\n",
    "\n",
    "#         for observation in observations:\n",
    "#             # print(type(observation))\n",
    "#             for key, value in observation.items():\n",
    "#                 # print(f\"{key}: {value}\")\n",
    "#                 for key, value in value.items():\n",
    "#                     # print(f\"{key}: {value}\")\n",
    "#                     if key == \"name\":\n",
    "#                         if \"end_\" in value:\n",
    "\n",
    "#                             end_signal_count += 1\n",
    "#                         if \"failure_signal\" in value:\n",
    "\n",
    "#                             failure_signal_count += 1\n",
    "\n",
    "#     print(f\"Session ID: {session_id}\")\n",
    "#     total_count = end_signal_count + failure_signal_count\n",
    "#     if total_count > 0:\n",
    "#         success_rate = end_signal_count / total_count\n",
    "#         print(f\"Success rate: {success_rate:.4f}\")\n",
    "#     else:\n",
    "#         print(\"Success rate: N/A (no signals found)\")\n",
    "#     print(f\"Passed:\\t{end_signal_count}\\nFailed:\\t{failure_signal_count}\")\n",
    "#     print(\n",
    "#         \"\"\n",
    "#         if total_count == 30\n",
    "#         else \"Number of ending signals does not match the expected number!\"\n",
    "#     )\n",
    "#     print(\"-\" * 50)\n",
    "\n",
    "\n",
    "# for session_id in session_id_list:\n",
    "#     cal_success_rate(session_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def cal_time(start_time, end_time):\n",
    "#     time_diff = datetime.fromisoformat(\n",
    "#         end_time.replace(\"Z\", \"+00:00\")\n",
    "#     ) - datetime.fromisoformat(start_time.replace(\"Z\", \"+00:00\"))\n",
    "#     seconds_diff = time_diff.total_seconds()\n",
    "#     return seconds_diff\n",
    "\n",
    "\n",
    "# print(cal_time(\"2025-01-15T03:31:56.150000+00:00\", \"2025-01-15T03:32:59.384Z\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"\"\"Print the complete structure of exported json file\"\"\"\n",
    "# def print_keys(d, parent_key=''):\n",
    "#     if isinstance(d, dict):\n",
    "#         for key, value in d.items():\n",
    "#             full_key = f\"{parent_key}.{key}\" if parent_key else key\n",
    "#             print(full_key)\n",
    "#             print_keys(value, full_key)\n",
    "#     elif isinstance(d, list):\n",
    "#         for i, item in enumerate(d):\n",
    "#             full_key = f\"{parent_key}[{i}]\"\n",
    "#             print_keys(item, full_key)\n",
    "\n",
    "# # Load JSON data from a file\n",
    "# with open('fetch_traces_response.json', 'r') as file:\n",
    "#     data = json.load(file)['data'][0]\n",
    "# # Print all keys\n",
    "# print_keys(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1747226053\n",
      "1747226053.1\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "from dateutil import parser\n",
    "\n",
    "timestamp_str = \"2025-05-14T12:34:13.100000+00:00\"\n",
    "dt = parser.isoparse(\n",
    "    timestamp_str\n",
    ")  # Or datetime.fromisoformat(timestamp_str) if no timezone offset\n",
    "unix_ts = int(dt.timestamp())\n",
    "\n",
    "print(unix_ts)  # This will print the integer Unix timestamp\n",
    "print(datetime.fromisoformat(timestamp_str).timestamp())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datasci2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

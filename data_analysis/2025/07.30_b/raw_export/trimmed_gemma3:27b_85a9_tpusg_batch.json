{
  "data": [
    {
      "id": "1a38d526",
      "timestamp": "2025-07-30T17:26:17.587000+00:00",
      "name": "1a38_tpu_sketch_generator",
      "input": null,
      "output": {
        "status": "failed",
        "last_code": "import numpy as np\nimport cv2\nfrom tflite_runtime.interpreter import Interpreter, load_delegate\n\n# Configuration Parameters\nmodel_path  = \"/home/mendel/tinyml_autopilot/models/edgetpu_detect.tflite\"\nlabel_path  = \"/home/mendel/tinyml_autopilot/models/labelmap.txt\"\ninput_video_path  = \"/home/mendel/tinyml_autopilot/data//sheeps.mp4\"\noutput_video_path  = \"/home/mendel/tinyml_autopilot/results/sheeps_detections.mp4\"\nconfidence_threshold  = 0.5\n\n# Load Labels\nwith open(label_path, 'r') as f:\n   labels = [line.strip() for line in f.readlines()]\n\n# Load Interpreter with EdgeTPU\ntry:\n   interpreter = Interpreter(model_path=model_path,\n                             experimental_delegates=[load_delegate('libedgetpu.so.1')])\nexcept:\n   interpreter = Interpreter(model_path=model_path,\n                             experimental_delegates=[load_delegate('/usr/lib/aarch64-linux-gnu/libedgetpu.so.1')])\n\ninterpreter.allocate_tensors()\n\n# Get Model Details\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\ninput_shape = input_details[0]['shape']\nfloating_model = (input_details[0]['dtype'] == np.float32)\n\n# Input Acquisition & Preprocessing Loop\ncap = cv2.VideoCapture(input_video_path)\nif not cap.isOpened():\n   print(\"Error opening video stream or file\")\n   exit()\n\nfourcc = cv2.VideoWriter_fourcc(*'mp4v')\nout = cv2.VideoWriter(output_video_path, fourcc, 30.0, (int(cap.get(3)), int(cap.get(4))))\n\nwhile True:\n   ret, frame = cap.read()\n   if not ret:\n       break\n\n   # Preprocess Data\n   resized_frame = cv2.resize(frame, (input_shape[1], input_shape[2]))\n   input_data = np.expand_dims(resized_frame, axis=0)\n   if floating_model:\n       input_data = (np.float32(input_data) - 127.5) / 127.5\n\n   # Inference\n   interpreter.set_tensor(input_details[0]['index'], input_data)\n   interpreter.invoke()\n\n   # Output Interpretation & Handling\n   output_data = interpreter.get_tensor(output_details[0]['index'])\n   boxes = output_data[0][0:4]\n   classes = output_data[0][4]\n   scores = output_data[0][5]\n\n   # Apply confidence threshold\n   if scores > confidence_threshold:\n       # Scale the bounding box\n       height, width, _ = frame.shape\n       x_min = int(boxes[0] * width)\n       y_min = int(boxes[1] * height)\n       x_max = int(boxes[2] * width)\n       y_max = int(boxes[3] * height)\n\n       # Draw bounding box and label\n       label = labels[int(classes)]\n       cv2.rectangle(frame, (x_min, y_min), (x_max, y_max), (0, 255, 0), 2)\n       cv2.putText(frame, f\"{label}: {scores:.2f}\", (x_min, y_min - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n\n   out.write(frame)\n\ncap.release()\nout.release()\ncv2.destroyAllWindows()",
        "last_error": "Traceback (most recent call last):\n  File \"script_a1892503_1753896608.py\", line 63, in <module>\n    if scores > confidence_threshold:\nValueError: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()"
      },
      "session_id": "gemma3:27b_85a9_tpusg_batch",
      "metadata": {
        "num_run": 30
      },
      "tags": [
        "benchmark",
        "gemma3:27b",
        "tpu_sketch_generator"
      ],
      "latency": 239.709,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-20-26-17-588894_chatcmpl-0ed49918-c6fe-4a61-92f2-f036c4b727ef",
          "traceId": "1a38d526",
          "type": "GENERATION",
          "name": "1a38_tpusg_gen_attempt#1",
          "startTime": "2025-07-30T17:26:17.588000+00:00",
          "endTime": "2025-07-30T17:26:52.452000+00:00",
          "model": "gemma3:27b",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 34864.0,
          "completionTokens": 900,
          "environment": "default",
          "totalTokens": 2866,
          "costDetails": {},
          "promptTokens": 1966,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-20-27-00-872840_chatcmpl-bf1b8163-938c-4cc0-b8af-629d42a2534f",
          "traceId": "1a38d526",
          "type": "GENERATION",
          "name": "1a38_tpusg_gen_attempt#2",
          "startTime": "2025-07-30T17:27:00.872000+00:00",
          "endTime": "2025-07-30T17:27:40.656000+00:00",
          "model": "gemma3:27b",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 39784.0,
          "completionTokens": 1040,
          "environment": "default",
          "totalTokens": 3088,
          "costDetails": {},
          "promptTokens": 2048,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-20-27-49-043834_chatcmpl-8719ea5d-5b98-4412-a645-e075a0e85956",
          "traceId": "1a38d526",
          "type": "GENERATION",
          "name": "1a38_tpusg_gen_attempt#3",
          "startTime": "2025-07-30T17:27:49.043000+00:00",
          "endTime": "2025-07-30T17:28:29.207000+00:00",
          "model": "gemma3:27b",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 40164.0,
          "completionTokens": 1053,
          "environment": "default",
          "totalTokens": 3101,
          "costDetails": {},
          "promptTokens": 2048,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-20-28-37-621240_chatcmpl-a46928b9-4df7-4b16-8a20-5907836ef7a2",
          "traceId": "1a38d526",
          "type": "GENERATION",
          "name": "1a38_tpusg_gen_attempt#4",
          "startTime": "2025-07-30T17:28:37.621000+00:00",
          "endTime": "2025-07-30T17:29:20.331000+00:00",
          "model": "gemma3:27b",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 42710.0,
          "completionTokens": 1126,
          "environment": "default",
          "totalTokens": 3174,
          "costDetails": {},
          "promptTokens": 2048,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-20-29-29-077963_chatcmpl-b4322766-fdba-42c3-8048-4963367d7195",
          "traceId": "1a38d526",
          "type": "GENERATION",
          "name": "1a38_tpusg_gen_attempt#5",
          "startTime": "2025-07-30T17:29:29.077000+00:00",
          "endTime": "2025-07-30T17:30:08.872000+00:00",
          "model": "gemma3:27b",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 39795.0,
          "completionTokens": 1042,
          "environment": "default",
          "totalTokens": 3090,
          "costDetails": {},
          "promptTokens": 2048,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "4c7fe3f5-a6f3-4336-87e9-b5c890a56a7d",
          "traceId": "1a38d526",
          "type": "SPAN",
          "name": "error_1a_tpusg_failure_signal_tpu_sketch_generator",
          "startTime": "2025-07-30T17:30:17.297000+00:00",
          "level": "ERROR",
          "statusMessage": "Failed. Last error: Traceback (most recent call last):\n  File \"script_a1892503_1753896608.py\", line 63, in <module>\n    if scores > confidence_threshold:\nValueError: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()",
          "calculatedTotalCost": 0.0,
          "completionTokens": 0,
          "environment": "default",
          "totalTokens": 0,
          "costDetails": {},
          "promptTokens": 0,
          "endTime": null,
          "model": null,
          "modelParameters": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null,
          "latency": null
        }
      ],
      "updatedAt": "2025-07-30T17:30:22.876Z",
      "createdAt": "2025-07-30T17:26:18.109Z",
      "environment": "default"
    },
    {
      "id": "c077f7a4",
      "timestamp": "2025-07-30T17:22:11.722000+00:00",
      "name": "c077_tpu_sketch_generator",
      "input": null,
      "output": {
        "status": "failed",
        "last_code": "import numpy as np\nimport cv2\nfrom tflite_runtime.interpreter import Interpreter, load_delegate\n\n# Configuration Parameters\nmodel_path  = \"/home/mendel/tinyml_autopilot/models/edgetpu_detect.tflite\"\nlabel_path  = \"/home/mendel/tinyml_autopilot/models/labelmap.txt\"\ninput_video_path  = \"/home/mendel/tinyml_autopilot/data//sheeps.mp4\"\noutput_video_path  = \"/home/mendel/tinyml_autopilot/results/sheeps_detections.mp4\"\n\n# Load Labels\nwith open(label_path, 'r') as f:\n   labels = [line.strip() for line in f.readlines()]\n\n# Load Interpreter with EdgeTPU\ntry:\n   interpreter = Interpreter(model_path=model_path, experimental_delegates=[load_delegate('libedgetpu.so.1.0')])\nexcept:\n   interpreter = Interpreter(model_path=model_path, experimental_delegates=[load_delegate('/usr/lib/aarch64-linux-gnu/libedgetpu.so.1.0')])\n\ninterpreter.allocate_tensors()\n\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\ninput_shape = input_details[0]['shape']\nfloating_model = (input_details[0]['dtype'] == np.float32)\n\n# Video Capture\ncap = cv2.VideoCapture(input_video_path)\nif not cap.isOpened():\n   print(\"Error opening video stream or file\")\n   exit()\n\n# Video Writer\nfourcc = cv2.VideoWriter_fourcc(*'mp4v')\nout = cv2.VideoWriter(output_video_path, fourcc, 20.0, (int(cap.get(3)), int(cap.get(4))))\n\nwhile(cap.isOpened()):\n   ret, frame = cap.read()\n   if not ret:\n       break\n\n   # Preprocessing\n   resized_frame = cv2.resize(frame, (input_shape[1], input_shape[2]))\n   input_data = np.expand_dims(resized_frame, axis=0)\n   if floating_model:\n       input_data = (np.float32(input_data) - 127.5) / 127.5\n\n   # Inference\n   interpreter.set_tensor(input_details[0]['index'], input_data)\n   interpreter.invoke()\n\n   # Output Interpretation\n   output_data = interpreter.get_tensor(output_details[0]['index'])\n   boxes = output_data[0][0:4]\n   classes = output_data[0][4]\n   scores = output_data[0][5]\n\n   if scores > 0.5:\n       xmin = int(boxes[0] * frame.shape[1])\n       ymin = int(boxes[1] * frame.shape[0])\n       xmax = int(boxes[2] * frame.shape[1])\n       ymax = int(boxes[3] * frame.shape[0])\n\n       cv2.rectangle(frame, (xmin, ymin), (xmax, ymax), (0, 255, 0), 2)\n       cv2.putText(frame, f\"{labels[int(classes)]}: {scores:.2f}\", (xmin, ymin - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n\n   # Write the output frame\n   out.write(frame)\n\n   # Display the resulting frame\n   cv2.imshow('Frame', frame)\n   if cv2.waitKey(1) & 0xFF == ord('q'):\n       break\n\n# When everything done, release the capture and writer\ncap.release()\nout.release()\ncv2.destroyAllWindows()",
        "last_error": "Traceback (most recent call last):\n  File \"script_bff71d51_1753896363.py\", line 59, in <module>\n    if scores > 0.5:\nValueError: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()"
      },
      "session_id": "gemma3:27b_85a9_tpusg_batch",
      "metadata": {
        "num_run": 29
      },
      "tags": [
        "benchmark",
        "gemma3:27b",
        "tpu_sketch_generator"
      ],
      "latency": 240.027,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-20-22-11-723511_chatcmpl-3e61c133-bee2-4f6d-85db-70b92a00fd66",
          "traceId": "c077f7a4",
          "type": "GENERATION",
          "name": "c077_tpusg_gen_attempt#1",
          "startTime": "2025-07-30T17:22:11.723000+00:00",
          "endTime": "2025-07-30T17:22:46.992000+00:00",
          "model": "gemma3:27b",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 35269.0,
          "completionTokens": 912,
          "environment": "default",
          "totalTokens": 2878,
          "costDetails": {},
          "promptTokens": 1966,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-20-22-55-402566_chatcmpl-40a638bf-60bf-45b8-97d8-c7077bea99d3",
          "traceId": "c077f7a4",
          "type": "GENERATION",
          "name": "c077_tpusg_gen_attempt#2",
          "startTime": "2025-07-30T17:22:55.402000+00:00",
          "endTime": "2025-07-30T17:23:35.053000+00:00",
          "model": "gemma3:27b",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 39651.0,
          "completionTokens": 1034,
          "environment": "default",
          "totalTokens": 3082,
          "costDetails": {},
          "promptTokens": 2048,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-20-23-43-465433_chatcmpl-d42d55a0-1f34-46c4-bb0b-2e1cea67f908",
          "traceId": "c077f7a4",
          "type": "GENERATION",
          "name": "c077_tpusg_gen_attempt#3",
          "startTime": "2025-07-30T17:23:43.465000+00:00",
          "endTime": "2025-07-30T17:24:23.926000+00:00",
          "model": "gemma3:27b",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 40461.0,
          "completionTokens": 1060,
          "environment": "default",
          "totalTokens": 3108,
          "costDetails": {},
          "promptTokens": 2048,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-20-24-32-235300_chatcmpl-8d54c163-6c7f-4d4c-9b0f-61fde70d9e72",
          "traceId": "c077f7a4",
          "type": "GENERATION",
          "name": "c077_tpusg_gen_attempt#4",
          "startTime": "2025-07-30T17:24:32.235000+00:00",
          "endTime": "2025-07-30T17:25:14.938000+00:00",
          "model": "gemma3:27b",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 42703.0,
          "completionTokens": 1122,
          "environment": "default",
          "totalTokens": 3170,
          "costDetails": {},
          "promptTokens": 2048,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-20-25-23-205175_chatcmpl-a8ac1090-1637-4a11-96a5-1802b8b8fd9a",
          "traceId": "c077f7a4",
          "type": "GENERATION",
          "name": "c077_tpusg_gen_attempt#5",
          "startTime": "2025-07-30T17:25:23.205000+00:00",
          "endTime": "2025-07-30T17:26:03.499000+00:00",
          "model": "gemma3:27b",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 40294.0,
          "completionTokens": 1051,
          "environment": "default",
          "totalTokens": 3099,
          "costDetails": {},
          "promptTokens": 2048,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "ecbc3d1a-5a94-4565-a3a3-94a9fd1b4076",
          "traceId": "c077f7a4",
          "type": "SPAN",
          "name": "error_c0_tpusg_failure_signal_tpu_sketch_generator",
          "startTime": "2025-07-30T17:26:11.750000+00:00",
          "level": "ERROR",
          "statusMessage": "Failed. Last error: Traceback (most recent call last):\n  File \"script_bff71d51_1753896363.py\", line 59, in <module>\n    if scores > 0.5:\nValueError: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()",
          "calculatedTotalCost": 0.0,
          "completionTokens": 0,
          "environment": "default",
          "totalTokens": 0,
          "costDetails": {},
          "promptTokens": 0,
          "endTime": null,
          "model": null,
          "modelParameters": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null,
          "latency": null
        }
      ],
      "updatedAt": "2025-07-30T17:26:17.006Z",
      "createdAt": "2025-07-30T17:22:12.243Z",
      "environment": "default"
    },
    {
      "id": "89140ba9",
      "timestamp": "2025-07-30T17:18:09.124000+00:00",
      "name": "8914_tpu_sketch_generator",
      "input": null,
      "output": {
        "status": "failed",
        "last_code": "import numpy as np\nimport cv2\nfrom tflite_runtime.interpreter import Interpreter, load_delegate\n\n# Configuration Parameters\nmodel_path  = \"/home/mendel/tinyml_autopilot/models/edgetpu_detect.tflite\"\nlabel_path  = \"/home/mendel/tinyml_autopilot/models/labelmap.txt\"\ninput_video_path  = \"/home/mendel/tinyml_autopilot/data//sheeps.mp4\"\noutput_video_path  = \"/home/mendel/tinyml_autopilot/results/sheeps_detections.mp4\"\n\n# Load Labels\nwith open(label_path, 'r') as f:\n   labels = [line.strip() for line in f.readlines()]\n\n# Load Interpreter with EdgeTPU\ntry:\n   interpreter = Interpreter(model_path=model_path,\n                             experimental_delegates=[load_delegate('libedgetpu.so.1.0')])\nexcept:\n   interpreter = Interpreter(model_path=model_path,\n                             experimental_delegates=[load_delegate('/usr/lib/aarch64-linux-gnu/libedgetpu.so.1.0')])\n\ninterpreter.allocate_tensors()\n\n# Get Model Details\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\ninput_shape = input_details[0]['shape']\nfloating_model = (input_details[0]['dtype'] == np.float32)\n\n# Input Acquisition & Preprocessing Loop\ncap = cv2.VideoCapture(input_video_path)\nfourcc = cv2.VideoWriter_fourcc(*'mp4v')\nout = cv2.VideoWriter(output_video_path, fourcc, 30.0, (int(cap.get(3)), int(cap.get(4))))\n\nwhile(cap.isOpened()):\n   ret, frame = cap.read()\n   if not ret:\n       break\n\n   # Resize and Preprocess Frame\n   resized_frame = cv2.resize(frame, (input_shape[1], input_shape[2]))\n   input_data = np.expand_dims(resized_frame, axis=0)\n\n   if floating_model:\n       input_data = (np.float32(input_data) - 127.5) / 127.5\n\n   # Inference\n   interpreter.set_tensor(input_details[0]['index'], input_data)\n   interpreter.invoke()\n\n   # Output Interpretation & Handling\n   output_data = interpreter.get_tensor(output_details[0]['index'])\n   boxes = output_data[0][0:4]\n   classes = output_data[0][4]\n   scores = output_data[0][5]\n\n   confidence_threshold = 0.5\n   if scores > confidence_threshold:\n       x1, y1, x2, y2 = boxes\n       x1, y1, x2, y2 = int(x1 * frame.shape[1]), int(y1 * frame.shape[0]), int(x2 * frame.shape[1]), int(y2 * frame.shape[0])\n       class_id = int(classes)\n       label = labels[class_id]\n       confidence = scores\n       cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n       cv2.putText(frame, f'{label}: {confidence:.2f}', (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n\n   out.write(frame)\n\ncap.release()\nout.release()\ncv2.destroyAllWindows()",
        "last_error": "Traceback (most recent call last):\n  File \"script_e6556542_1753896116.py\", line 59, in <module>\n    if scores > confidence_threshold:\nValueError: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()"
      },
      "session_id": "gemma3:27b_85a9_tpusg_batch",
      "metadata": {
        "num_run": 28
      },
      "tags": [
        "benchmark",
        "gemma3:27b",
        "tpu_sketch_generator"
      ],
      "latency": 236.155,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-20-18-09-126235_chatcmpl-ce058be3-656b-454f-98a8-c118ddebb232",
          "traceId": "89140ba9",
          "type": "GENERATION",
          "name": "8914_tpusg_gen_attempt#1",
          "startTime": "2025-07-30T17:18:09.126000+00:00",
          "endTime": "2025-07-30T17:18:42.905000+00:00",
          "model": "gemma3:27b",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 33779.0,
          "completionTokens": 865,
          "environment": "default",
          "totalTokens": 2831,
          "costDetails": {},
          "promptTokens": 1966,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-20-18-51-307597_chatcmpl-cc84cb65-b41e-4cb1-b017-47f4aafb1f6b",
          "traceId": "89140ba9",
          "type": "GENERATION",
          "name": "8914_tpusg_gen_attempt#2",
          "startTime": "2025-07-30T17:18:51.307000+00:00",
          "endTime": "2025-07-30T17:19:29.286000+00:00",
          "model": "gemma3:27b",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 37979.0,
          "completionTokens": 985,
          "environment": "default",
          "totalTokens": 3033,
          "costDetails": {},
          "promptTokens": 2048,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-20-19-37-731705_chatcmpl-4ae27a82-5401-4104-af60-929236e23302",
          "traceId": "89140ba9",
          "type": "GENERATION",
          "name": "8914_tpusg_gen_attempt#3",
          "startTime": "2025-07-30T17:19:37.731000+00:00",
          "endTime": "2025-07-30T17:20:20.792000+00:00",
          "model": "gemma3:27b",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 43061.0,
          "completionTokens": 1133,
          "environment": "default",
          "totalTokens": 3181,
          "costDetails": {},
          "promptTokens": 2048,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-20-20-29-169579_chatcmpl-1271da4b-208a-4d59-a643-2af492376d43",
          "traceId": "89140ba9",
          "type": "GENERATION",
          "name": "8914_tpusg_gen_attempt#4",
          "startTime": "2025-07-30T17:20:29.169000+00:00",
          "endTime": "2025-07-30T17:21:09.529000+00:00",
          "model": "gemma3:27b",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 40360.0,
          "completionTokens": 1058,
          "environment": "default",
          "totalTokens": 3106,
          "costDetails": {},
          "promptTokens": 2048,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-20-21-17-944999_chatcmpl-4444981e-e4ff-43d2-a77e-34e8ad7bdee7",
          "traceId": "89140ba9",
          "type": "GENERATION",
          "name": "8914_tpusg_gen_attempt#5",
          "startTime": "2025-07-30T17:21:17.944000+00:00",
          "endTime": "2025-07-30T17:21:56.904000+00:00",
          "model": "gemma3:27b",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 38960.0,
          "completionTokens": 1019,
          "environment": "default",
          "totalTokens": 3067,
          "costDetails": {},
          "promptTokens": 2048,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "4e9d7455-8bc6-40e3-844a-09e699a72b05",
          "traceId": "89140ba9",
          "type": "SPAN",
          "name": "error_89_tpusg_failure_signal_tpu_sketch_generator",
          "startTime": "2025-07-30T17:22:05.281000+00:00",
          "level": "ERROR",
          "statusMessage": "Failed. Last error: Traceback (most recent call last):\n  File \"script_e6556542_1753896116.py\", line 59, in <module>\n    if scores > confidence_threshold:\nValueError: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()",
          "calculatedTotalCost": 0.0,
          "completionTokens": 0,
          "environment": "default",
          "totalTokens": 0,
          "costDetails": {},
          "promptTokens": 0,
          "endTime": null,
          "model": null,
          "modelParameters": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null,
          "latency": null
        }
      ],
      "updatedAt": "2025-07-30T17:22:11.044Z",
      "createdAt": "2025-07-30T17:18:09.646Z",
      "environment": "default"
    },
    {
      "id": "e6f97a5c",
      "timestamp": "2025-07-30T17:13:59.210000+00:00",
      "name": "e6f9_tpu_sketch_generator",
      "input": null,
      "output": {
        "status": "failed",
        "last_code": "import numpy as np\nimport cv2\nfrom tflite_runtime.interpreter import Interpreter, load_delegate\n\n# Configuration Parameters\nmodel_path  = \"/home/mendel/tinyml_autopilot/models/edgetpu_detect.tflite\"\nlabel_path  = \"/home/mendel/tinyml_autopilot/models/labelmap.txt\"\ninput_video_path  = \"/home/mendel/tinyml_autopilot/data//sheeps.mp4\"\noutput_video_path  = \"/home/mendel/tinyml_autopilot/results/sheeps_detections.mp4\"\n\n# Load Labels\nwith open(label_path, 'r') as f:\n   labels = [line.strip() for line in f.readlines()]\n\n# Load Interpreter with EdgeTPU\ntry:\n   interpreter = Interpreter(model_path=model_path,\n                             experimental_delegates=[load_delegate('libedgetpu.so.1.0')])\nexcept:\n   interpreter = Interpreter(model_path=model_path,\n                             experimental_delegates=[load_delegate('/usr/lib/aarch64-linux-gnu/libedgetpu.so.1.0')])\n\ninterpreter.allocate_tensors()\n\n# Get Model Details\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\ninput_shape = input_details[0]['shape']\ninput_dtype = input_details[0]['dtype']\n\n# Video Setup\ncap = cv2.VideoCapture(input_video_path)\nif not cap.isOpened():\n   print(\"Error opening video file\")\n   exit()\n\nframe_width = int(cap.get(3))\nframe_height = int(cap.get(4))\nfourcc = cv2.VideoWriter_fourcc(*'mp4v')\nout = cv2.VideoWriter(output_video_path, fourcc, 20.0, (frame_width, frame_height))\n\n# Inference Loop\nwhile True:\n   ret, frame = cap.read()\n   if not ret:\n       break\n\n   # Preprocessing\n   resized_frame = cv2.resize(frame, (input_shape[1], input_shape[2]))\n   input_data = np.expand_dims(resized_frame, axis=0)\n   if input_dtype == np.float32:\n       input_data = (np.float32(input_data) - 127.5) / 127.5\n\n   # Inference\n   interpreter.set_tensor(input_details[0]['index'], input_data)\n   interpreter.invoke()\n\n   # Post-processing\n   output_data = interpreter.get_tensor(output_details[0]['index'])\n   boxes = output_data[0][0:4]\n   classes = output_data[0][4]\n   confidence = output_data[0][5]\n\n   if confidence > 0.5:\n       x1, y1, x2, y2 = boxes\n       x1 = int(x1 * frame_width)\n       y1 = int(y1 * frame_height)\n       x2 = int(x2 * frame_width)\n       y2 = int(y2 * frame_height)\n       class_id = int(classes)\n       label = labels[class_id]\n       confidence_text = f\"{confidence:.2f}\"\n       cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n       cv2.putText(frame, f\"{label}: {confidence_text}\", (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n\n   out.write(frame)\n\ncap.release()\nout.release()\ncv2.destroyAllWindows()",
        "last_error": "Traceback (most recent call last):\n  File \"script_568a8a56_1753895874.py\", line 64, in <module>\n    if confidence > 0.5:\nValueError: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()"
      },
      "session_id": "gemma3:27b_85a9_tpusg_batch",
      "metadata": {
        "num_run": 27
      },
      "tags": [
        "benchmark",
        "gemma3:27b",
        "tpu_sketch_generator"
      ],
      "latency": 243.685,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-20-13-59-212154_chatcmpl-6670fc43-4c53-41b6-b647-4a4478643141",
          "traceId": "e6f97a5c",
          "type": "GENERATION",
          "name": "e6f9_tpusg_gen_attempt#1",
          "startTime": "2025-07-30T17:13:59.212000+00:00",
          "endTime": "2025-07-30T17:14:33.692000+00:00",
          "model": "gemma3:27b",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 34480.0,
          "completionTokens": 888,
          "environment": "default",
          "totalTokens": 2854,
          "costDetails": {},
          "promptTokens": 1966,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-20-14-41-942333_chatcmpl-630d787e-4b4f-4606-b5e2-2b2292b21165",
          "traceId": "e6f97a5c",
          "type": "GENERATION",
          "name": "e6f9_tpusg_gen_attempt#2",
          "startTime": "2025-07-30T17:14:41.942000+00:00",
          "endTime": "2025-07-30T17:15:24.250000+00:00",
          "model": "gemma3:27b",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 42308.0,
          "completionTokens": 1107,
          "environment": "default",
          "totalTokens": 3155,
          "costDetails": {},
          "promptTokens": 2048,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-20-15-32-614550_chatcmpl-02b3f25a-3af3-45da-85c4-4533fa9534ec",
          "traceId": "e6f97a5c",
          "type": "GENERATION",
          "name": "e6f9_tpusg_gen_attempt#3",
          "startTime": "2025-07-30T17:15:32.614000+00:00",
          "endTime": "2025-07-30T17:16:13.580000+00:00",
          "model": "gemma3:27b",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 40966.0,
          "completionTokens": 1072,
          "environment": "default",
          "totalTokens": 3120,
          "costDetails": {},
          "promptTokens": 2048,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-20-16-21-955608_chatcmpl-cca83b8c-039a-476a-814f-53c212f4c388",
          "traceId": "e6f97a5c",
          "type": "GENERATION",
          "name": "e6f9_tpusg_gen_attempt#4",
          "startTime": "2025-07-30T17:16:21.955000+00:00",
          "endTime": "2025-07-30T17:17:02.721000+00:00",
          "model": "gemma3:27b",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 40766.0,
          "completionTokens": 1068,
          "environment": "default",
          "totalTokens": 3116,
          "costDetails": {},
          "promptTokens": 2048,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-20-17-11-126365_chatcmpl-6e857e32-7253-473d-833f-5ebc16adfef5",
          "traceId": "e6f97a5c",
          "type": "GENERATION",
          "name": "e6f9_tpusg_gen_attempt#5",
          "startTime": "2025-07-30T17:17:11.126000+00:00",
          "endTime": "2025-07-30T17:17:54.521000+00:00",
          "model": "gemma3:27b",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 43395.0,
          "completionTokens": 1139,
          "environment": "default",
          "totalTokens": 3187,
          "costDetails": {},
          "promptTokens": 2048,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "dfd157a6-2606-4c39-9ee0-c0fa6408fffa",
          "traceId": "e6f97a5c",
          "type": "SPAN",
          "name": "error_e6_tpusg_failure_signal_tpu_sketch_generator",
          "startTime": "2025-07-30T17:18:02.897000+00:00",
          "level": "ERROR",
          "statusMessage": "Failed. Last error: Traceback (most recent call last):\n  File \"script_568a8a56_1753895874.py\", line 64, in <module>\n    if confidence > 0.5:\nValueError: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()",
          "calculatedTotalCost": 0.0,
          "completionTokens": 0,
          "environment": "default",
          "totalTokens": 0,
          "costDetails": {},
          "promptTokens": 0,
          "endTime": null,
          "model": null,
          "modelParameters": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null,
          "latency": null
        }
      ],
      "updatedAt": "2025-07-30T17:18:08.485Z",
      "createdAt": "2025-07-30T17:13:59.732Z",
      "environment": "default"
    },
    {
      "id": "1d55aeb9",
      "timestamp": "2025-07-30T17:09:54.487000+00:00",
      "name": "1d55_tpu_sketch_generator",
      "input": null,
      "output": {
        "status": "failed",
        "last_code": "import numpy as np\nimport cv2\nfrom tflite_runtime.interpreter import Interpreter, load_delegate\n\n# Configuration Parameters\nmodel_path  = \"/home/mendel/tinyml_autopilot/models/edgetpu_detect.tflite\"\nlabel_path  = \"/home/mendel/tinyml_autopilot/models/labelmap.txt\"\ninput_video_path  = \"/home/mendel/tinyml_autopilot/data//sheeps.mp4\"\noutput_video_path  = \"/home/mendel/tinyml_autopilot/results/sheeps_detections.mp4\"\n\n# Load Labels\nwith open(label_path, 'r') as f:\n   labels = [line.strip() for line in f.readlines()]\n\n# Load Interpreter with EdgeTPU\ntry:\n   interpreter = Interpreter(model_path=model_path, experimental_delegates=[load_delegate('libedgetpu.so.1.0')])\nexcept:\n   interpreter = Interpreter(model_path=model_path, experimental_delegates=[load_delegate('/usr/lib/aarch64-linux-gnu/libedgetpu.so.1.0')])\n\ninterpreter.allocate_tensors()\n\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\n\ninput_shape = input_details[0]['shape']\n\n# Video setup\ncap = cv2.VideoCapture(input_video_path)\nif not cap.isOpened():\n   print(\"Error opening video file\")\n   exit()\n\nframe_width = int(cap.get(3))\nframe_height = int(cap.get(4))\n\nfourcc = cv2.VideoWriter_fourcc(*'mp4v')\nout = cv2.VideoWriter(output_video_path, fourcc, 20.0, (frame_width, frame_height))\n\n# Inference loop\nwhile(cap.isOpened()):\n   ret, frame = cap.read()\n   if not ret:\n       break\n\n   # Preprocessing\n   resized_frame = cv2.resize(frame, (input_shape[1], input_shape[2]))\n   input_data = resized_frame.astype(np.uint8)\n   input_data = np.expand_dims(input_data, axis=0)\n   # Normalize input image\n   input_data = input_data.astype(np.float32)  # Convert to float32 before normalization\n   input_data = input_data / 255.0\n\n   # Inference\n   interpreter.set_tensor(input_details[0]['index'], input_data)\n   interpreter.invoke()\n\n   # Post-processing\n   output_data = interpreter.get_tensor(output_details[0]['index'])\n   boxes = output_data[0][0:4]\n   classes = output_data[0][4]\n   scores = output_data[0][5]\n\n   if scores > 0.5:\n       xmin = int(boxes[0] * frame_width)\n       ymin = int(boxes[1] * frame_height)\n       xmax = int(boxes[2] * frame_width)\n       ymax = int(boxes[3] * frame_height)\n\n       cv2.rectangle(frame, (xmin, ymin), (xmax, ymax), (0, 255, 0), 2)\n       cv2.putText(frame, labels[int(classes)], (xmin, ymin - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n\n   out.write(frame)\n\ncap.release()\nout.release()\ncv2.destroyAllWindows()",
        "last_error": "Traceback (most recent call last):\n  File \"script_c6ff16a5_1753895625.py\", line 55, in <module>\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n  File \"/home/mendel/tinyml_autopilot/tinyml-env/lib/python3.7/site-packages/tflite_runtime/interpreter.py\", line 572, in set_tensor\n    self._interpreter.SetTensor(tensor_index, value)\nValueError: Cannot set tensor: Got value of type FLOAT32 but expected type UINT8 for input 175, name: normalized_input_image_tensor "
      },
      "session_id": "gemma3:27b_85a9_tpusg_batch",
      "metadata": {
        "num_run": 26
      },
      "tags": [
        "benchmark",
        "gemma3:27b",
        "tpu_sketch_generator"
      ],
      "latency": 238.595,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-20-09-54-489027_chatcmpl-b2370dbc-1714-4413-95ce-11c9c9431134",
          "traceId": "1d55aeb9",
          "type": "GENERATION",
          "name": "1d55_tpusg_gen_attempt#1",
          "startTime": "2025-07-30T17:09:54.489000+00:00",
          "endTime": "2025-07-30T17:10:26.733000+00:00",
          "model": "gemma3:27b",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 32244.0,
          "completionTokens": 824,
          "environment": "default",
          "totalTokens": 2790,
          "costDetails": {},
          "promptTokens": 1966,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-20-10-34-799263_chatcmpl-13e3fd0f-4f84-486e-ad30-364e4903fb94",
          "traceId": "1d55aeb9",
          "type": "GENERATION",
          "name": "1d55_tpusg_gen_attempt#2",
          "startTime": "2025-07-30T17:10:34.799000+00:00",
          "endTime": "2025-07-30T17:11:19.927000+00:00",
          "model": "gemma3:27b",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 45128.0,
          "completionTokens": 1185,
          "environment": "default",
          "totalTokens": 3233,
          "costDetails": {},
          "promptTokens": 2048,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-20-11-27-962567_chatcmpl-1e2cade0-56d6-4b2e-b3dc-1189d0c0effb",
          "traceId": "1d55aeb9",
          "type": "GENERATION",
          "name": "1d55_tpusg_gen_attempt#3",
          "startTime": "2025-07-30T17:11:27.962000+00:00",
          "endTime": "2025-07-30T17:12:09.472000+00:00",
          "model": "gemma3:27b",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 41510.0,
          "completionTokens": 1089,
          "environment": "default",
          "totalTokens": 3137,
          "costDetails": {},
          "promptTokens": 2048,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-20-12-17-526252_chatcmpl-07afdf48-9f44-4e8b-bf48-918a6c236350",
          "traceId": "1d55aeb9",
          "type": "GENERATION",
          "name": "1d55_tpusg_gen_attempt#4",
          "startTime": "2025-07-30T17:12:17.526000+00:00",
          "endTime": "2025-07-30T17:12:57.553000+00:00",
          "model": "gemma3:27b",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 40027.0,
          "completionTokens": 1049,
          "environment": "default",
          "totalTokens": 3097,
          "costDetails": {},
          "promptTokens": 2048,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-20-13-05-670981_chatcmpl-44547877-acb0-4866-bda2-4126d06ab164",
          "traceId": "1d55aeb9",
          "type": "GENERATION",
          "name": "1d55_tpusg_gen_attempt#5",
          "startTime": "2025-07-30T17:13:05.670000+00:00",
          "endTime": "2025-07-30T17:13:45.034000+00:00",
          "model": "gemma3:27b",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 39364.0,
          "completionTokens": 1030,
          "environment": "default",
          "totalTokens": 3078,
          "costDetails": {},
          "promptTokens": 2048,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "fb70c2ac-e3e0-4ef3-99fb-aae84711bc3d",
          "traceId": "1d55aeb9",
          "type": "SPAN",
          "name": "error_1d_tpusg_failure_signal_tpu_sketch_generator",
          "startTime": "2025-07-30T17:13:53.084000+00:00",
          "level": "ERROR",
          "statusMessage": "Failed. Last error: Traceback (most recent call last):\n  File \"script_c6ff16a5_1753895625.py\", line 55, in <module>\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n  File \"/home/mendel/tinyml_autopilot/tinyml-env/lib/python3.7/site-packages/tflite_runtime/interpreter.py\", line 572, in set_tensor\n    self._interpreter.SetTensor(tensor_index, value)\nValueError: Cannot set tensor: Got value of type FLOAT32 but expected type UINT8 for input 175, name: normalized_input_image_tensor ",
          "calculatedTotalCost": 0.0,
          "completionTokens": 0,
          "environment": "default",
          "totalTokens": 0,
          "costDetails": {},
          "promptTokens": 0,
          "endTime": null,
          "model": null,
          "modelParameters": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null,
          "latency": null
        }
      ],
      "updatedAt": "2025-07-30T17:13:58.202Z",
      "createdAt": "2025-07-30T17:09:55.008Z",
      "environment": "default"
    },
    {
      "id": "2962b4b0",
      "timestamp": "2025-07-30T17:08:12.737000+00:00",
      "name": "2962_tpu_sketch_generator",
      "input": null,
      "output": {
        "status": "success",
        "sketch": "import numpy as np\nimport cv2\nfrom tflite_runtime.interpreter import Interpreter, load_delegate\n\n# Configuration Parameters\nmodel_path  = \"/home/mendel/tinyml_autopilot/models/edgetpu_detect.tflite\"\nlabel_path  = \"/home/mendel/tinyml_autopilot/models/labelmap.txt\"\ninput_video_path  = \"/home/mendel/tinyml_autopilot/data//sheeps.mp4\"\noutput_video_path  = \"/home/mendel/tinyml_autopilot/results/sheeps_detections.mp4\"\nconfidence_threshold  = 0.5\n\n# Load Labels\nwith open(label_path, 'r') as f:\n    labels = [line.strip() for line in f.readlines()]\n\n# Load Interpreter with EdgeTPU\ntry:\n    interpreter = Interpreter(model_path=model_path, \n                              experimental_delegates=[load_delegate('libedgetpu.so.1.0')])\nexcept:\n    interpreter = Interpreter(model_path=model_path, \n                              experimental_delegates=[load_delegate('/usr/lib/aarch64-linux-gnu/libedgetpu.so.1.0')])\n\ninterpreter.allocate_tensors()\n\n# Get Model Details\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\n\ninput_shape = input_details[0]['shape']\nfloating_model = (input_details[0]['dtype'] == np.float32)\n\n# Video Capture\ncap = cv2.VideoCapture(input_video_path)\nif not cap.isOpened():\n    print(\"Error opening video stream or file\")\n    exit()\n\n# Video Writer\nframe_width = int(cap.get(3))\nframe_height = int(cap.get(4))\nfourcc = cv2.VideoWriter_fourcc(*'mp4v')\nout = cv2.VideoWriter(output_video_path, fourcc, 20.0, (frame_width, frame_height))\n\n# Inference Loop\nwhile(cap.isOpened()):\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    # Preprocessing\n    resized_frame = cv2.resize(frame, (input_shape[1], input_shape[2]))\n    input_data = np.expand_dims(resized_frame, axis=0)\n\n    if floating_model:\n        input_data = (np.float32(input_data) - 127.5) / 127.5\n\n    # Inference\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n    interpreter.invoke()\n\n    # Post-processing\n    output_data = interpreter.get_tensor(output_details[0]['index'])\n    boxes = output_data[0][0:4]\n    classes = output_data[0][4]\n    scores = output_data[0][5]\n\n    # Filtering bounding boxes based on confidence score\n    valid_boxes = []\n    valid_classes = []\n    valid_scores = []\n\n    for i in range(len(scores)):\n        if scores[i] > confidence_threshold:\n            valid_boxes.append(boxes[i])\n            valid_classes.append(classes[i])\n            valid_scores.append(scores[i])\n\n    # Draw bounding boxes on the frame\n    for i in range(len(valid_boxes)):\n        box = valid_boxes[i]\n        class_id = int(valid_classes[i])\n        score = valid_scores[i]\n        label = labels[class_id]\n        \n        x1 = int(box[0] * frame_width)\n        y1 = int(box[1] * frame_height)\n        x2 = int(box[2] * frame_width)\n        y2 = int(box[3] * frame_height)\n        \n        cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n        cv2.putText(frame, f\"{label}: {score:.2f}\", (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n\n    # Write the frame to the output video\n    out.write(frame)\n\n    # Display the resulting frame (optional)\n    cv2.imshow('frame', frame)\n    if cv2.waitKey(1) & 0xFF == ord('q'):\n        break\n\n# When everything done, release the capture and writer\ncap.release()\nout.release()\ncv2.destroyAllWindows()"
      },
      "session_id": "gemma3:27b_85a9_tpusg_batch",
      "metadata": {
        "num_run": 25
      },
      "tags": [
        "benchmark",
        "gemma3:27b",
        "tpu_sketch_generator"
      ],
      "latency": 42.333,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-20-08-12-739398_chatcmpl-f3e29d25-2917-4edc-a7a2-2b00d8794faa",
          "traceId": "2962b4b0",
          "type": "GENERATION",
          "name": "2962_tpusg_gen_attempt#1",
          "startTime": "2025-07-30T17:08:12.739000+00:00",
          "endTime": "2025-07-30T17:08:55.072000+00:00",
          "model": "gemma3:27b",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 42333.0,
          "completionTokens": 1104,
          "environment": "default",
          "totalTokens": 3070,
          "costDetails": {},
          "promptTokens": 1966,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        }
      ],
      "updatedAt": "2025-07-30T17:09:52.930Z",
      "createdAt": "2025-07-30T17:08:13.258Z",
      "environment": "default"
    },
    {
      "id": "47d390bb",
      "timestamp": "2025-07-30T17:04:11.959000+00:00",
      "name": "47d3_tpu_sketch_generator",
      "input": null,
      "output": {
        "status": "failed",
        "last_code": "import numpy as np\nimport cv2\nfrom tflite_runtime.interpreter import Interpreter, load_delegate\n\n# Configuration Parameters\nmodel_path  = \"/home/mendel/tinyml_autopilot/models/edgetpu_detect.tflite\"\nlabel_path  = \"/home/mendel/tinyml_autopilot/models/labelmap.txt\"\ninput_video_path  = \"/home/mendel/tinyml_autopilot/data//sheeps.mp4\"\noutput_video_path  = \"/home/mendel/tinyml_autopilot/results/sheeps_detections.mp4\"\n\n# Load Labels\nwith open(label_path, 'r') as f:\n   labels = [line.strip() for line in f]\n\n# Load Interpreter with EdgeTPU\ntry:\n   interpreter = Interpreter(model_path=model_path,\n                             experimental_delegates=[load_delegate('libedgetpu.so.1.0')])\nexcept:\n   interpreter = Interpreter(model_path=model_path,\n                             experimental_delegates=[load_delegate('/usr/lib/aarch64-linux-gnu/libedgetpu.so.1.0')])\n\ninterpreter.allocate_tensors()\n\n# Get Model Details\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\ninput_shape = input_details[0]['shape']\ninput_data_type = input_details[0]['dtype']\n\n# Video Capture\ncap = cv2.VideoCapture(input_video_path)\nif not cap.isOpened():\n   print(\"Error opening video file\")\n   exit()\n\n# Video Writer\nfourcc = cv2.VideoWriter_fourcc(*'mp4v')\nout = cv2.VideoWriter(output_video_path, fourcc, 20.0, (int(cap.get(3)), int(cap.get(4))))\n\n# Inference Loop\nwhile True:\n   ret, frame = cap.read()\n   if not ret:\n       break\n\n   # Preprocessing\n   resized_frame = cv2.resize(frame, (input_shape[1], input_shape[2]))\n   input_data = np.expand_dims(resized_frame, axis=0)\n   if input_data_type == np.float32:\n       input_data = (np.float32(input_data) - 127.5) / 127.5\n\n   # Inference\n   interpreter.set_tensor(input_details[0]['index'], input_data)\n   interpreter.invoke()\n   output_data = interpreter.get_tensor(output_details[0]['index'])\n\n   # Post-processing\n   boxes = output_data[0][0:4]\n   classes = output_data[0][4]\n   scores = output_data[0][5]\n\n   if scores > 0.5:\n       xmin = int(boxes[0])\n       ymin = int(boxes[1])\n       xmax = int(boxes[2])\n       ymax = int(boxes[3])\n       class_id = int(classes)\n       label = labels[class_id]\n       confidence = scores\n\n       cv2.rectangle(frame, (xmin, ymin), (xmax, ymax), (0, 255, 0), 2)\n       cv2.putText(frame, f\"{label}: {confidence:.2f}\", (xmin, ymin - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n\n   # Write output\n   out.write(frame)\n\n# Release resources\ncap.release()\nout.release()\ncv2.destroyAllWindows()",
        "last_error": "Traceback (most recent call last):\n  File \"script_76645b10_1753895278.py\", line 63, in <module>\n    if scores > 0.5:\nValueError: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()"
      },
      "session_id": "gemma3:27b_85a9_tpusg_batch",
      "metadata": {
        "num_run": 24
      },
      "tags": [
        "benchmark",
        "gemma3:27b",
        "tpu_sketch_generator"
      ],
      "latency": 234.916,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-20-04-11-961246_chatcmpl-5e55f626-ebc9-42c2-b049-a50065b1aebb",
          "traceId": "47d390bb",
          "type": "GENERATION",
          "name": "47d3_tpusg_gen_attempt#1",
          "startTime": "2025-07-30T17:04:11.961000+00:00",
          "endTime": "2025-07-30T17:04:45.662000+00:00",
          "model": "gemma3:27b",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 33701.0,
          "completionTokens": 866,
          "environment": "default",
          "totalTokens": 2832,
          "costDetails": {},
          "promptTokens": 1966,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-20-04-54-241930_chatcmpl-5d0e60c5-edd8-4123-9cbe-0ddd4d0cc433",
          "traceId": "47d390bb",
          "type": "GENERATION",
          "name": "47d3_tpusg_gen_attempt#2",
          "startTime": "2025-07-30T17:04:54.241000+00:00",
          "endTime": "2025-07-30T17:05:33.829000+00:00",
          "model": "gemma3:27b",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 39588.0,
          "completionTokens": 1033,
          "environment": "default",
          "totalTokens": 3081,
          "costDetails": {},
          "promptTokens": 2048,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-20-05-42-179496_chatcmpl-9d01f9c4-14f1-41ee-8634-76fed915a3b3",
          "traceId": "47d390bb",
          "type": "GENERATION",
          "name": "47d3_tpusg_gen_attempt#3",
          "startTime": "2025-07-30T17:05:42.179000+00:00",
          "endTime": "2025-07-30T17:06:23.611000+00:00",
          "model": "gemma3:27b",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 41432.0,
          "completionTokens": 1089,
          "environment": "default",
          "totalTokens": 3137,
          "costDetails": {},
          "promptTokens": 2048,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-20-06-31-949354_chatcmpl-59677556-32a7-442f-adf3-0b87ea0fccff",
          "traceId": "47d390bb",
          "type": "GENERATION",
          "name": "47d3_tpusg_gen_attempt#4",
          "startTime": "2025-07-30T17:06:31.949000+00:00",
          "endTime": "2025-07-30T17:07:10.280000+00:00",
          "model": "gemma3:27b",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 38331.0,
          "completionTokens": 999,
          "environment": "default",
          "totalTokens": 3047,
          "costDetails": {},
          "promptTokens": 2048,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-20-07-18-716785_chatcmpl-548f8593-43c1-4387-8806-bbac866910dc",
          "traceId": "47d390bb",
          "type": "GENERATION",
          "name": "47d3_tpusg_gen_attempt#5",
          "startTime": "2025-07-30T17:07:18.716000+00:00",
          "endTime": "2025-07-30T17:07:58.528000+00:00",
          "model": "gemma3:27b",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 39812.0,
          "completionTokens": 1043,
          "environment": "default",
          "totalTokens": 3091,
          "costDetails": {},
          "promptTokens": 2048,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "2d0218bf-8f63-4abd-b17c-11171339bfb0",
          "traceId": "47d390bb",
          "type": "SPAN",
          "name": "error_47_tpusg_failure_signal_tpu_sketch_generator",
          "startTime": "2025-07-30T17:08:06.877000+00:00",
          "level": "ERROR",
          "statusMessage": "Failed. Last error: Traceback (most recent call last):\n  File \"script_76645b10_1753895278.py\", line 63, in <module>\n    if scores > 0.5:\nValueError: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()",
          "calculatedTotalCost": 0.0,
          "completionTokens": 0,
          "environment": "default",
          "totalTokens": 0,
          "costDetails": {},
          "promptTokens": 0,
          "endTime": null,
          "model": null,
          "modelParameters": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null,
          "latency": null
        }
      ],
      "updatedAt": "2025-07-30T17:08:12.187Z",
      "createdAt": "2025-07-30T17:04:12.478Z",
      "environment": "default"
    },
    {
      "id": "69660530",
      "timestamp": "2025-07-30T16:59:54.279000+00:00",
      "name": "6966_tpu_sketch_generator",
      "input": null,
      "output": {
        "status": "failed",
        "last_code": "import numpy as np\nimport cv2\nfrom tflite_runtime.interpreter import Interpreter, load_delegate\n\n# Configuration Parameters\nmodel_path  = \"/home/mendel/tinyml_autopilot/models/edgetpu_detect.tflite\"\nlabel_path  = \"/home/mendel/tinyml_autopilot/models/labelmap.txt\"\ninput_video_path  = \"/home/mendel/tinyml_autopilot/data//sheeps.mp4\"\noutput_video_path  = \"/home/mendel/tinyml_autopilot/results/sheeps_detections.mp4\"\n\n# Load Labels\nwith open(label_path, 'r') as f:\n   labels = [line.strip() for line in f.readlines()]\n\n# Load Interpreter with EdgeTPU\ntry:\n   interpreter = Interpreter(model_path=model_path,\n                             experimental_delegates=[load_delegate('libedgetpu.so.1.0')])\nexcept:\n   interpreter = Interpreter(model_path=model_path,\n                             experimental_delegates=[load_delegate('/usr/lib/aarch64-linux-gnu/libedgetpu.so.1.0')])\ninterpreter.allocate_tensors()\n\n# Get Model Details\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\ninput_shape = input_details[0]['shape']\nfloating_model = (input_details[0]['dtype'] == np.float32)\n\n# Video Setup\ncap = cv2.VideoCapture(input_video_path)\nif not cap.isOpened():\n   print(\"Error opening video file\")\n   exit()\n\nframe_width = int(cap.get(3))\nframe_height = int(cap.get(4))\nfourcc = cv2.VideoWriter_fourcc(*'mp4v')\nout = cv2.VideoWriter(output_video_path, fourcc, 20.0, (frame_width, frame_height))\n\n# Input Acquisition & Preprocessing Loop\nwhile True:\n   ret, frame = cap.read()\n   if not ret:\n       break\n\n   # Resize and Preprocess\n   resized_frame = cv2.resize(frame, (input_shape[1], input_shape[2]))\n   input_data = np.expand_dims(resized_frame, axis=0)\n\n   if floating_model:\n       input_data = (np.float32(input_data) - 127.5) / 127.5\n\n   # Inference\n   interpreter.set_tensor(input_details[0]['index'], input_data)\n   interpreter.invoke()\n\n   # Get Output\n   output_data = interpreter.get_tensor(output_details[0]['index'])\n   boxes = output_data[0][0:4]\n   classes = output_data[0][4]\n   scores = output_data[0][5]\n\n   # Interpret Results & Post-processing\n   confidence_threshold = 0.5\n   if scores > confidence_threshold:\n       # Scale bounding box coordinates\n       x0 = int(boxes[0] * frame_width)\n       y0 = int(boxes[1] * frame_height)\n       x1 = int(boxes[2] * frame_width)\n       y1 = int(boxes[3] * frame_height)\n\n       # Get class label\n       class_id = int(classes)\n       label = labels[class_id]\n\n       # Draw bounding box and label\n       cv2.rectangle(frame, (x0, y0), (x1, y1), (0, 255, 0), 2)\n       cv2.putText(frame, f\"{label}: {scores:.2f}\", (x0, y0 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n\n   # Write to output video\n   out.write(frame)\n\n# Cleanup\ncap.release()\nout.release()\ncv2.destroyAllWindows()",
        "last_error": "Traceback (most recent call last):\n  File \"script_57bfe6cc_1753895036.py\", line 66, in <module>\n    if scores > confidence_threshold:\nValueError: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()"
      },
      "session_id": "gemma3:27b_85a9_tpusg_batch",
      "metadata": {
        "num_run": 23
      },
      "tags": [
        "benchmark",
        "gemma3:27b",
        "tpu_sketch_generator"
      ],
      "latency": 250.405,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-19-59-54-281334_chatcmpl-b362c042-5f03-4377-b94d-3d1c848e9aab",
          "traceId": "69660530",
          "type": "GENERATION",
          "name": "6966_tpusg_gen_attempt#1",
          "startTime": "2025-07-30T16:59:54.281000+00:00",
          "endTime": "2025-07-30T17:00:30.181000+00:00",
          "model": "gemma3:27b",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 35900.0,
          "completionTokens": 927,
          "environment": "default",
          "totalTokens": 2893,
          "costDetails": {},
          "promptTokens": 1966,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-20-00-38-511489_chatcmpl-62a2a08c-4875-483c-8629-71ac56704e92",
          "traceId": "69660530",
          "type": "GENERATION",
          "name": "6966_tpusg_gen_attempt#2",
          "startTime": "2025-07-30T17:00:38.511000+00:00",
          "endTime": "2025-07-30T17:01:21.364000+00:00",
          "model": "gemma3:27b",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 42853.0,
          "completionTokens": 1126,
          "environment": "default",
          "totalTokens": 3174,
          "costDetails": {},
          "promptTokens": 2048,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-20-01-30-015547_chatcmpl-df1ff3ae-86f0-4f56-8960-02b495f68da8",
          "traceId": "69660530",
          "type": "GENERATION",
          "name": "6966_tpusg_gen_attempt#3",
          "startTime": "2025-07-30T17:01:30.015000+00:00",
          "endTime": "2025-07-30T17:02:13.297000+00:00",
          "model": "gemma3:27b",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 43282.0,
          "completionTokens": 1137,
          "environment": "default",
          "totalTokens": 3185,
          "costDetails": {},
          "promptTokens": 2048,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-20-02-21-712451_chatcmpl-94e704c5-207f-4d8a-802a-1b7edd393fa9",
          "traceId": "69660530",
          "type": "GENERATION",
          "name": "6966_tpusg_gen_attempt#4",
          "startTime": "2025-07-30T17:02:21.712000+00:00",
          "endTime": "2025-07-30T17:03:06.580000+00:00",
          "model": "gemma3:27b",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 44868.0,
          "completionTokens": 1180,
          "environment": "default",
          "totalTokens": 3228,
          "costDetails": {},
          "promptTokens": 2048,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-20-03-14-807723_chatcmpl-1bdbf9ea-b11d-4411-93e0-f40e38b72c47",
          "traceId": "69660530",
          "type": "GENERATION",
          "name": "6966_tpusg_gen_attempt#5",
          "startTime": "2025-07-30T17:03:14.807000+00:00",
          "endTime": "2025-07-30T17:03:56.387000+00:00",
          "model": "gemma3:27b",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 41580.0,
          "completionTokens": 1091,
          "environment": "default",
          "totalTokens": 3139,
          "costDetails": {},
          "promptTokens": 2048,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "37e2ebef-2ae8-4540-944f-f516749039fa",
          "traceId": "69660530",
          "type": "SPAN",
          "name": "error_69_tpusg_failure_signal_tpu_sketch_generator",
          "startTime": "2025-07-30T17:04:04.686000+00:00",
          "level": "ERROR",
          "statusMessage": "Failed. Last error: Traceback (most recent call last):\n  File \"script_57bfe6cc_1753895036.py\", line 66, in <module>\n    if scores > confidence_threshold:\nValueError: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()",
          "calculatedTotalCost": 0.0,
          "completionTokens": 0,
          "environment": "default",
          "totalTokens": 0,
          "costDetails": {},
          "promptTokens": 0,
          "endTime": null,
          "model": null,
          "modelParameters": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null,
          "latency": null
        }
      ],
      "updatedAt": "2025-07-30T17:04:10.032Z",
      "createdAt": "2025-07-30T16:59:54.799Z",
      "environment": "default"
    },
    {
      "id": "eb4cf0fc",
      "timestamp": "2025-07-30T16:55:55.701000+00:00",
      "name": "eb4c_tpu_sketch_generator",
      "input": null,
      "output": {
        "status": "failed",
        "last_code": "import numpy as np\nimport cv2\nfrom tflite_runtime.interpreter import Interpreter, load_delegate\n\n# Configuration Parameters\nmodel_path  = \"/home/mendel/tinyml_autopilot/models/edgetpu_detect.tflite\"\nlabel_path  = \"/home/mendel/tinyml_autopilot/models/labelmap.txt\"\ninput_video_path  = \"/home/mendel/tinyml_autopilot/data//sheeps.mp4\"\noutput_video_path  = \"/home/mendel/tinyml_autopilot/results/sheeps_detections.mp4\"\n\n# Load Labels\nwith open(label_path, 'r') as f:\n   labels = [line.strip() for line in f.readlines()]\n\n# Load Interpreter with EdgeTPU\ntry:\n   interpreter = Interpreter(model_path=model_path,\n                             experimental_delegates=[load_delegate('libedgetpu.so.1.0')])\nexcept:\n   interpreter = Interpreter(model_path=model_path,\n                             experimental_delegates=[load_delegate('/usr/lib/aarch64-linux-gnu/libedgetpu.so.1.0')])\n\ninterpreter.allocate_tensors()\n\n# Get Model Details\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\ninput_shape = input_details[0]['shape']\ninput_dtype = input_details[0]['dtype']\n\n# Input Acquisition & Preprocessing Loop\ncap = cv2.VideoCapture(input_video_path)\nif not cap.isOpened():\n   print(\"Error opening video stream or file\")\n   exit()\n\nfourcc = cv2.VideoWriter_fourcc(*'mp4v')\nout = cv2.VideoWriter(output_video_path, fourcc, 30.0, (int(cap.get(3)), int(cap.get(4))))\n\nwhile True:\n   ret, frame = cap.read()\n   if not ret:\n       break\n\n   resized_frame = cv2.resize(frame, (input_shape[1], input_shape[2]))\n   input_data = np.expand_dims(resized_frame, axis=0)\n   if input_dtype == np.float32:\n       input_data = (np.float32(input_data) - 127.5) / 127.5\n   else:\n       input_data = input_data.astype(np.uint8)\n\n   # Inference\n   interpreter.set_tensor(input_details[0]['index'], input_data)\n   interpreter.invoke()\n\n   # Output Interpretation & Handling\n   output_data = interpreter.get_tensor(output_details[0]['index'])\n   boxes = output_data[0][0:4]\n   classes = output_data[0][4]\n   scores = output_data[0][5]\n\n   if scores > 0.5:\n       x1, y1, x2, y2 = boxes\n       class_id = int(classes)\n       label = labels[class_id]\n       cv2.rectangle(frame, (int(x1), int(y1)), (int(x2), int(y2)), (0, 255, 0), 2)\n       cv2.putText(frame, f\"{label}: {scores:.2f}\", (int(x1), int(y1) - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n\n   out.write(frame)\n\ncap.release()\nout.release()\ncv2.destroyAllWindows()",
        "last_error": "Traceback (most recent call last):\n  File \"script_1f389844_1753894779.py\", line 62, in <module>\n    if scores > 0.5:\nValueError: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()"
      },
      "session_id": "gemma3:27b_85a9_tpusg_batch",
      "metadata": {
        "num_run": 22
      },
      "tags": [
        "benchmark",
        "gemma3:27b",
        "tpu_sketch_generator"
      ],
      "latency": 232.26,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-19-55-55-702968_chatcmpl-31430011-ca29-48d3-a34a-2be7cc640a8e",
          "traceId": "eb4cf0fc",
          "type": "GENERATION",
          "name": "eb4c_tpusg_gen_attempt#1",
          "startTime": "2025-07-30T16:55:55.702000+00:00",
          "endTime": "2025-07-30T16:56:28.140000+00:00",
          "model": "gemma3:27b",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 32438.0,
          "completionTokens": 834,
          "environment": "default",
          "totalTokens": 2800,
          "costDetails": {},
          "promptTokens": 1966,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-19-56-36-378938_chatcmpl-c0cd1b3b-3522-4f7a-b28a-4de46ba9cc2c",
          "traceId": "eb4cf0fc",
          "type": "GENERATION",
          "name": "eb4c_tpusg_gen_attempt#2",
          "startTime": "2025-07-30T16:56:36.378000+00:00",
          "endTime": "2025-07-30T16:57:14.041000+00:00",
          "model": "gemma3:27b",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 37663.0,
          "completionTokens": 979,
          "environment": "default",
          "totalTokens": 3027,
          "costDetails": {},
          "promptTokens": 2048,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-19-57-22-416254_chatcmpl-978ee3dc-b4ed-4684-a128-b5a7fc952c4a",
          "traceId": "eb4cf0fc",
          "type": "GENERATION",
          "name": "eb4c_tpusg_gen_attempt#3",
          "startTime": "2025-07-30T16:57:22.416000+00:00",
          "endTime": "2025-07-30T16:58:00.098000+00:00",
          "model": "gemma3:27b",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 37682.0,
          "completionTokens": 982,
          "environment": "default",
          "totalTokens": 3030,
          "costDetails": {},
          "promptTokens": 2048,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-19-58-08-477627_chatcmpl-8e806586-becb-490b-be81-5c554a9b4936",
          "traceId": "eb4cf0fc",
          "type": "GENERATION",
          "name": "eb4c_tpusg_gen_attempt#4",
          "startTime": "2025-07-30T16:58:08.477000+00:00",
          "endTime": "2025-07-30T16:58:51.290000+00:00",
          "model": "gemma3:27b",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 42813.0,
          "completionTokens": 1121,
          "environment": "default",
          "totalTokens": 3169,
          "costDetails": {},
          "promptTokens": 2048,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-19-58-59-598304_chatcmpl-8054b18d-1468-4dc6-b157-33763e7c76a8",
          "traceId": "eb4cf0fc",
          "type": "GENERATION",
          "name": "eb4c_tpusg_gen_attempt#5",
          "startTime": "2025-07-30T16:58:59.598000+00:00",
          "endTime": "2025-07-30T16:59:39.589000+00:00",
          "model": "gemma3:27b",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 39991.0,
          "completionTokens": 1039,
          "environment": "default",
          "totalTokens": 3087,
          "costDetails": {},
          "promptTokens": 2048,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "83b6d0e6-ae39-450b-8749-718cdfc726da",
          "traceId": "eb4cf0fc",
          "type": "SPAN",
          "name": "error_eb_tpusg_failure_signal_tpu_sketch_generator",
          "startTime": "2025-07-30T16:59:47.962000+00:00",
          "level": "ERROR",
          "statusMessage": "Failed. Last error: Traceback (most recent call last):\n  File \"script_1f389844_1753894779.py\", line 62, in <module>\n    if scores > 0.5:\nValueError: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()",
          "calculatedTotalCost": 0.0,
          "completionTokens": 0,
          "environment": "default",
          "totalTokens": 0,
          "costDetails": {},
          "promptTokens": 0,
          "endTime": null,
          "model": null,
          "modelParameters": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null,
          "latency": null
        }
      ],
      "updatedAt": "2025-07-30T16:59:53.438Z",
      "createdAt": "2025-07-30T16:55:56.220Z",
      "environment": "default"
    },
    {
      "id": "506219b3",
      "timestamp": "2025-07-30T16:51:45.923000+00:00",
      "name": "5062_tpu_sketch_generator",
      "input": null,
      "output": {
        "status": "failed",
        "last_code": "import numpy as np\nimport cv2\nfrom tflite_runtime.interpreter import Interpreter, load_delegate\n\n# Configuration Parameters\nmodel_path  = \"/home/mendel/tinyml_autopilot/models/edgetpu_detect.tflite\"\nlabel_path  = \"/home/mendel/tinyml_autopilot/models/labelmap.txt\"\ninput_video_path  = \"/home/mendel/tinyml_autopilot/data//sheeps.mp4\"\noutput_video_path  = \"/home/mendel/tinyml_autopilot/results/sheeps_detections.mp4\"\n\n# Load Labels\nwith open(label_path, 'r') as f:\n   labels = [line.strip() for line in f.readlines()]\n\n# Load Interpreter with EdgeTPU\ntry:\n   interpreter = Interpreter(model_path=model_path,\n                             experimental_delegates=[load_delegate('libedgetpu.so.1')])\nexcept:\n   interpreter = Interpreter(model_path=model_path,\n                             experimental_delegates=[load_delegate('/usr/lib/aarch64-linux-gnu/libedgetpu.so.1')])\n\ninterpreter.allocate_tensors()\n\n# Get Model Details\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\ninput_shape = input_details[0]['shape']\ninput_data_type = input_details[0]['dtype']\n\n# Video Setup\ncap = cv2.VideoCapture(input_video_path)\nif not cap.isOpened():\n   print(\"Error opening video stream or file\")\n   exit()\n\nframe_width = int(cap.get(3))\nframe_height = int(cap.get(4))\nfourcc = cv2.VideoWriter_fourcc(*'mp4v')  # or use 'XVID'\nout = cv2.VideoWriter(output_video_path, fourcc, 20.0, (frame_width, frame_height))\n\n# Main loop\nwhile (cap.isOpened()):\n   ret, frame = cap.read()\n   if not ret:\n       break\n\n   # Preprocessing\n   resized_frame = cv2.resize(frame, (input_shape[1], input_shape[2]))\n   input_data = np.expand_dims(resized_frame, axis=0)\n\n   # Check input data type and convert if necessary\n   if input_data_type == np.uint8:\n       input_data = input_data.astype(np.uint8)\n   elif input_data_type == np.float32:\n       input_data = input_data.astype(np.float32)\n   else:\n       print(f\"Unsupported input data type: {input_data_type}\")\n       exit()\n\n   # Inference\n   interpreter.set_tensor(input_details[0]['index'], input_data)\n   interpreter.invoke()\n\n   # Post-processing\n   output_data = interpreter.get_tensor(output_details[0]['index'])\n   boxes = output_data[0][0:4]\n   classes = output_data[0][4]\n   scores = output_data[0][5]\n\n   confidence_threshold = 0.5\n\n   if scores > confidence_threshold:\n       x0 = int(boxes[0] * frame_width)\n       y0 = int(boxes[1] * frame_height)\n       x1 = int(boxes[2] * frame_width)\n       y1 = int(boxes[3] * frame_height)\n\n       class_id = int(classes)\n       label = labels[class_id]\n       confidence = scores\n\n       cv2.rectangle(frame, (x0, y0), (x1, y1), (0, 255, 0), 2)\n       cv2.putText(frame, f'{label}: {confidence:.2f}', (x0, y0 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n\n   out.write(frame)\n\ncap.release()\nout.release()\ncv2.destroyAllWindows()",
        "last_error": "Traceback (most recent call last):\n  File \"script_a6dc0deb_1753894541.py\", line 73, in <module>\n    if scores > confidence_threshold:\nValueError: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()"
      },
      "session_id": "gemma3:27b_85a9_tpusg_batch",
      "metadata": {
        "num_run": 21
      },
      "tags": [
        "benchmark",
        "gemma3:27b",
        "tpu_sketch_generator"
      ],
      "latency": 244.008,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-19-51-45-925051_chatcmpl-dded838a-b6e5-49c6-a68b-20507013d334",
          "traceId": "506219b3",
          "type": "GENERATION",
          "name": "5062_tpusg_gen_attempt#1",
          "startTime": "2025-07-30T16:51:45.925000+00:00",
          "endTime": "2025-07-30T16:52:19.999000+00:00",
          "model": "gemma3:27b",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 34074.0,
          "completionTokens": 880,
          "environment": "default",
          "totalTokens": 2846,
          "costDetails": {},
          "promptTokens": 1966,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-19-52-28-059843_chatcmpl-7f3a178a-7da2-4550-b69a-8f26cf2d9335",
          "traceId": "506219b3",
          "type": "GENERATION",
          "name": "5062_tpusg_gen_attempt#2",
          "startTime": "2025-07-30T16:52:28.059000+00:00",
          "endTime": "2025-07-30T16:53:11.373000+00:00",
          "model": "gemma3:27b",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 43314.0,
          "completionTokens": 1141,
          "environment": "default",
          "totalTokens": 3189,
          "costDetails": {},
          "promptTokens": 2048,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-19-53-19-769788_chatcmpl-e1ae579b-579a-4281-9763-93ad534b585e",
          "traceId": "506219b3",
          "type": "GENERATION",
          "name": "5062_tpusg_gen_attempt#3",
          "startTime": "2025-07-30T16:53:19.769000+00:00",
          "endTime": "2025-07-30T16:54:02.137000+00:00",
          "model": "gemma3:27b",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 42368.0,
          "completionTokens": 1112,
          "environment": "default",
          "totalTokens": 3160,
          "costDetails": {},
          "promptTokens": 2048,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-19-54-10-530094_chatcmpl-a2f08748-4d42-4a44-aa31-d716ae03fbec",
          "traceId": "506219b3",
          "type": "GENERATION",
          "name": "5062_tpusg_gen_attempt#4",
          "startTime": "2025-07-30T16:54:10.530000+00:00",
          "endTime": "2025-07-30T16:54:53.629000+00:00",
          "model": "gemma3:27b",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 43099.0,
          "completionTokens": 1126,
          "environment": "default",
          "totalTokens": 3174,
          "costDetails": {},
          "promptTokens": 2048,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-19-55-01-853055_chatcmpl-d2a59470-7c65-4303-9952-7ec6130519e0",
          "traceId": "506219b3",
          "type": "GENERATION",
          "name": "5062_tpusg_gen_attempt#5",
          "startTime": "2025-07-30T16:55:01.853000+00:00",
          "endTime": "2025-07-30T16:55:41.683000+00:00",
          "model": "gemma3:27b",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 39830.0,
          "completionTokens": 1041,
          "environment": "default",
          "totalTokens": 3089,
          "costDetails": {},
          "promptTokens": 2048,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "f47915a8-808d-449e-9e28-512270a064c9",
          "traceId": "506219b3",
          "type": "SPAN",
          "name": "error_50_tpusg_failure_signal_tpu_sketch_generator",
          "startTime": "2025-07-30T16:55:49.933000+00:00",
          "level": "ERROR",
          "statusMessage": "Failed. Last error: Traceback (most recent call last):\n  File \"script_a6dc0deb_1753894541.py\", line 73, in <module>\n    if scores > confidence_threshold:\nValueError: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()",
          "calculatedTotalCost": 0.0,
          "completionTokens": 0,
          "environment": "default",
          "totalTokens": 0,
          "costDetails": {},
          "promptTokens": 0,
          "endTime": null,
          "model": null,
          "modelParameters": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null,
          "latency": null
        }
      ],
      "updatedAt": "2025-07-30T16:55:55.194Z",
      "createdAt": "2025-07-30T16:51:46.445Z",
      "environment": "default"
    },
    {
      "id": "db3c2b2d",
      "timestamp": "2025-07-30T16:47:37.301000+00:00",
      "name": "db3c_tpu_sketch_generator",
      "input": null,
      "output": {
        "status": "failed",
        "last_code": "import cv2\nimport numpy as np\nfrom tflite_runtime.interpreter import Interpreter\n\n# Load the TFLite model and allocate tensors.\nmodel_path  = \"/home/mendel/tinyml_autopilot/models/edgetpu_detect.tflite\"\ninterpreter = Interpreter(model_path)\ninterpreter.allocate_tensors()\n\n# Get input and output details\ninput_details  = \"/home/mendel/tinyml_autopilot/data//sheeps.mp4\"\noutput_details  = \"/home/mendel/tinyml_autopilot/results/sheeps_detections.mp4\"\ninput_shape = input_details[0]['shape']\ninput_data_type = input_details[0]['dtype']\n\n# Video Setup\ninput_video_path = \"/home/mendel/tinyml_autopilot/data/sheeps.mp4\"\noutput_video_path = \"/home/mendel/tinyml_autopilot/results/sheeps_detection.mp4\"\ncap = cv2.VideoCapture(input_video_path)\nif not cap.isOpened():\n   print(\"Error opening video file\")\n   exit()\n\nframe_width = int(cap.get(3))\nframe_height = int(cap.get(4))\nfourcc = cv2.VideoWriter_fourcc(*'mp4v')\nout = cv2.VideoWriter(output_video_path, fourcc, 20.0, (frame_width, frame_height))\n\n# Load labels\nlabels = []\nwith open(\"/home/mendel/tinyml_autopilot/models/labels.txt\", \"r\") as f:\n   for line in f:\n       labels.append(line.strip())\n\n# Inference Loop\nwhile True:\n   ret, frame = cap.read()\n   if not ret:\n       break\n\n   # Preprocessing\n   resized_frame = cv2.resize(frame, (input_shape[1], input_shape[2]))\n   input_data = np.expand_dims(resized_frame, axis=0)\n   if input_data_type == np.float32:\n       input_data = (np.float32(input_data) - 127.5) / 127.5\n\n   # Inference\n   interpreter.set_tensor(input_details[0]['index'], input_data)\n   interpreter.invoke()\n\n   # Post-processing\n   output_data = interpreter.get_tensor(output_details[0]['index'])\n   boxes = output_data[..., 0:4]\n   classes = output_data[..., 4]\n   scores = output_data[..., 5]\n\n   # Filter detections based on confidence threshold\n   confidence_threshold = 0.5\n   valid_detections = []\n   for i in range(boxes.shape[0]):\n       if scores[i] > confidence_threshold:\n           x1, y1, x2, y2 = boxes[i]\n           class_id = int(classes[i])\n           confidence = scores[i]\n           valid_detections.append((x1, y1, x2, y2, class_id, confidence))\n\n   # Draw bounding boxes and labels on the frame\n   for x1, y1, x2, y2, class_id, confidence in valid_detections:\n       x1, y1, x2, y2 = int(x1 * frame_width), int(y1 * frame_height), int(x2 * frame_width), int(y2 * frame_height)\n       label = labels[class_id]\n       cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n       cv2.putText(frame, f\"{label}: {confidence:.2f}\", (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n\n   # Write the output frame\n   out.write(frame)\n\n# Release resources\ncap.release()\nout.release()\ncv2.destroyAllWindows()",
        "last_error": "Traceback (most recent call last):\n  File \"script_82567684_1753894292.py\", line 13, in <module>\n    input_shape = input_details[0]['shape']\nTypeError: string indices must be integers"
      },
      "session_id": "gemma3:27b_85a9_tpusg_batch",
      "metadata": {
        "num_run": 20
      },
      "tags": [
        "benchmark",
        "gemma3:27b",
        "tpu_sketch_generator"
      ],
      "latency": 242.521,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-19-47-37-304093_chatcmpl-7400e452-fdf7-4f12-a335-4445881f86cd",
          "traceId": "db3c2b2d",
          "type": "GENERATION",
          "name": "db3c_tpusg_gen_attempt#1",
          "startTime": "2025-07-30T16:47:37.304000+00:00",
          "endTime": "2025-07-30T16:48:16.104000+00:00",
          "model": "gemma3:27b",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 38800.0,
          "completionTokens": 1008,
          "environment": "default",
          "totalTokens": 2974,
          "costDetails": {},
          "promptTokens": 1966,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-19-48-24-468357_chatcmpl-96359e96-9ef0-478e-83fa-a8dae7b7bfde",
          "traceId": "db3c2b2d",
          "type": "GENERATION",
          "name": "db3c_tpusg_gen_attempt#2",
          "startTime": "2025-07-30T16:48:24.468000+00:00",
          "endTime": "2025-07-30T16:49:04.585000+00:00",
          "model": "gemma3:27b",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 40117.0,
          "completionTokens": 1047,
          "environment": "default",
          "totalTokens": 3095,
          "costDetails": {},
          "promptTokens": 2048,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-19-49-08-646771_chatcmpl-5bdc6b47-3c03-4b55-b013-76f7f7b7e07a",
          "traceId": "db3c2b2d",
          "type": "GENERATION",
          "name": "db3c_tpusg_gen_attempt#3",
          "startTime": "2025-07-30T16:49:08.646000+00:00",
          "endTime": "2025-07-30T16:49:54.546000+00:00",
          "model": "gemma3:27b",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 45900.0,
          "completionTokens": 1211,
          "environment": "default",
          "totalTokens": 3259,
          "costDetails": {},
          "promptTokens": 2048,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-19-50-02-313505_chatcmpl-5f235f62-579d-4ee3-8468-3a938dc43385",
          "traceId": "db3c2b2d",
          "type": "GENERATION",
          "name": "db3c_tpusg_gen_attempt#4",
          "startTime": "2025-07-30T16:50:02.313000+00:00",
          "endTime": "2025-07-30T16:50:43.605000+00:00",
          "model": "gemma3:27b",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 41292.0,
          "completionTokens": 1082,
          "environment": "default",
          "totalTokens": 3130,
          "costDetails": {},
          "promptTokens": 2048,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-19-50-51-352951_chatcmpl-f2d99fae-9146-4146-b187-ca74f62443d3",
          "traceId": "db3c2b2d",
          "type": "GENERATION",
          "name": "db3c_tpusg_gen_attempt#5",
          "startTime": "2025-07-30T16:50:51.352000+00:00",
          "endTime": "2025-07-30T16:51:32.078000+00:00",
          "model": "gemma3:27b",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 40726.0,
          "completionTokens": 1063,
          "environment": "default",
          "totalTokens": 3111,
          "costDetails": {},
          "promptTokens": 2048,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "d2fa861f-0e59-41e0-9182-0adbda58536d",
          "traceId": "db3c2b2d",
          "type": "SPAN",
          "name": "error_db_tpusg_failure_signal_tpu_sketch_generator",
          "startTime": "2025-07-30T16:51:39.825000+00:00",
          "level": "ERROR",
          "statusMessage": "Failed. Last error: Traceback (most recent call last):\n  File \"script_82567684_1753894292.py\", line 13, in <module>\n    input_shape = input_details[0]['shape']\nTypeError: string indices must be integers",
          "calculatedTotalCost": 0.0,
          "completionTokens": 0,
          "environment": "default",
          "totalTokens": 0,
          "costDetails": {},
          "promptTokens": 0,
          "endTime": null,
          "model": null,
          "modelParameters": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null,
          "latency": null
        }
      ],
      "updatedAt": "2025-07-30T16:51:45.031Z",
      "createdAt": "2025-07-30T16:47:37.823Z",
      "environment": "default"
    },
    {
      "id": "9dccacd2",
      "timestamp": "2025-07-30T16:43:33.261000+00:00",
      "name": "9dcc_tpu_sketch_generator",
      "input": null,
      "output": {
        "status": "failed",
        "last_code": "import numpy as np\nimport cv2\nfrom tflite_runtime.interpreter import Interpreter, load_delegate\n\n# Configuration Parameters\nmodel_path  = \"/home/mendel/tinyml_autopilot/models/edgetpu_detect.tflite\"\nlabel_path  = \"/home/mendel/tinyml_autopilot/models/labelmap.txt\"\ninput_video_path  = \"/home/mendel/tinyml_autopilot/data//sheeps.mp4\"\noutput_video_path  = \"/home/mendel/tinyml_autopilot/results/sheeps_detections.mp4\"\n\n# Load Labels\nwith open(label_path, 'r') as f:\n   labels = [line.strip() for line in f.readlines()]\n\n# Load Interpreter with EdgeTPU\ntry:\n   interpreter = Interpreter(model_path=model_path,\n                             experimental_delegates=[load_delegate('libedgetpu.so.1.0')])\nexcept:\n   interpreter = Interpreter(model_path=model_path,\n                             experimental_delegates=[load_delegate('/usr/lib/aarch64-linux-gnu/libedgetpu.so.1.0')])\ninterpreter.allocate_tensors()\n\n# Get Model Details\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\ninput_shape = input_details[0]['shape']\nfloating_model = (input_details[0]['dtype'] == np.float32)\n\n# Input Acquisition & Preprocessing Loop\ncap = cv2.VideoCapture(input_video_path)\nif not cap.isOpened():\n   print(\"Error opening video stream or file\")\n   exit()\n\nfourcc = cv2.VideoWriter_fourcc(*'mp4v')\nout = cv2.VideoWriter(output_video_path, fourcc, 20.0, (int(cap.get(3)), int(cap.get(4))))\n\nwhile (cap.isOpened()):\n   ret, frame = cap.read()\n   if not ret:\n       break\n\n   resized_frame = cv2.resize(frame, (input_shape[1], input_shape[2]))\n   input_data = np.expand_dims(resized_frame, axis=0)\n\n   if floating_model:\n       input_data = (np.float32(input_data) - 127.5) / 127.5\n\n   # Inference\n   interpreter.set_tensor(input_details[0]['index'], input_data)\n   interpreter.invoke()\n\n   # Output Interpretation & Handling\n   output_data = interpreter.get_tensor(output_details[0]['index'])\n   boxes = output_data[0][0:4]\n   classes = output_data[0][4]\n   scores = output_data[0][5]\n\n   confidence_threshold = 0.5\n   if scores > confidence_threshold:\n       class_id = int(classes)\n       label = labels[class_id]\n\n       x1 = int(boxes[0] * frame.shape[1])\n       y1 = int(boxes[1] * frame.shape[0])\n       x2 = int(boxes[2] * frame.shape[1])\n       y2 = int(boxes[3] * frame.shape[0])\n\n       cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n       cv2.putText(frame, f\"{label}: {scores:.2f}\", (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n\n   out.write(frame)\n\ncap.release()\nout.release()\ncv2.destroyAllWindows()",
        "last_error": "Traceback (most recent call last):\n  File \"script_e6132835_1753894042.py\", line 61, in <module>\n    if scores > confidence_threshold:\nValueError: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()"
      },
      "session_id": "gemma3:27b_85a9_tpusg_batch",
      "metadata": {
        "num_run": 19
      },
      "tags": [
        "benchmark",
        "gemma3:27b",
        "tpu_sketch_generator"
      ],
      "latency": 237.196,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-19-43-33-263315_chatcmpl-f47f1d10-f80a-438d-af2b-0bb26546513d",
          "traceId": "9dccacd2",
          "type": "GENERATION",
          "name": "9dcc_tpusg_gen_attempt#1",
          "startTime": "2025-07-30T16:43:33.263000+00:00",
          "endTime": "2025-07-30T16:44:08.017000+00:00",
          "model": "gemma3:27b",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 34754.0,
          "completionTokens": 895,
          "environment": "default",
          "totalTokens": 2861,
          "costDetails": {},
          "promptTokens": 1966,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-19-44-16-253504_chatcmpl-696f93a2-1930-4378-8a6a-494581657c0d",
          "traceId": "9dccacd2",
          "type": "GENERATION",
          "name": "9dcc_tpusg_gen_attempt#2",
          "startTime": "2025-07-30T16:44:16.253000+00:00",
          "endTime": "2025-07-30T16:44:56.825000+00:00",
          "model": "gemma3:27b",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 40572.0,
          "completionTokens": 1059,
          "environment": "default",
          "totalTokens": 3107,
          "costDetails": {},
          "promptTokens": 2048,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-19-45-05-308463_chatcmpl-2795e045-c8a3-4f32-adcd-e615a6d7be5d",
          "traceId": "9dccacd2",
          "type": "GENERATION",
          "name": "9dcc_tpusg_gen_attempt#3",
          "startTime": "2025-07-30T16:45:05.308000+00:00",
          "endTime": "2025-07-30T16:45:44.819000+00:00",
          "model": "gemma3:27b",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 39511.0,
          "completionTokens": 1031,
          "environment": "default",
          "totalTokens": 3079,
          "costDetails": {},
          "promptTokens": 2048,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-19-45-53-257680_chatcmpl-23c733a5-2ea7-4cb5-8750-5f5e92ea68d7",
          "traceId": "9dccacd2",
          "type": "GENERATION",
          "name": "9dcc_tpusg_gen_attempt#4",
          "startTime": "2025-07-30T16:45:53.257000+00:00",
          "endTime": "2025-07-30T16:46:32.052000+00:00",
          "model": "gemma3:27b",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 38795.0,
          "completionTokens": 1009,
          "environment": "default",
          "totalTokens": 3057,
          "costDetails": {},
          "promptTokens": 2048,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-19-46-40-313664_chatcmpl-21ca1b98-053d-4338-83ef-84191c107023",
          "traceId": "9dccacd2",
          "type": "GENERATION",
          "name": "9dcc_tpusg_gen_attempt#5",
          "startTime": "2025-07-30T16:46:40.313000+00:00",
          "endTime": "2025-07-30T16:47:22.244000+00:00",
          "model": "gemma3:27b",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 41931.0,
          "completionTokens": 1100,
          "environment": "default",
          "totalTokens": 3148,
          "costDetails": {},
          "promptTokens": 2048,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "c7011209-1449-4782-8c27-363b9d68c41f",
          "traceId": "9dccacd2",
          "type": "SPAN",
          "name": "error_9d_tpusg_failure_signal_tpu_sketch_generator",
          "startTime": "2025-07-30T16:47:30.459000+00:00",
          "level": "ERROR",
          "statusMessage": "Failed. Last error: Traceback (most recent call last):\n  File \"script_e6132835_1753894042.py\", line 61, in <module>\n    if scores > confidence_threshold:\nValueError: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()",
          "calculatedTotalCost": 0.0,
          "completionTokens": 0,
          "environment": "default",
          "totalTokens": 0,
          "costDetails": {},
          "promptTokens": 0,
          "endTime": null,
          "model": null,
          "modelParameters": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null,
          "latency": null
        }
      ],
      "updatedAt": "2025-07-30T16:47:35.954Z",
      "createdAt": "2025-07-30T16:43:33.784Z",
      "environment": "default"
    },
    {
      "id": "94bc6333",
      "timestamp": "2025-07-30T16:39:31.563000+00:00",
      "name": "94bc_tpu_sketch_generator",
      "input": null,
      "output": {
        "status": "failed",
        "last_code": "import numpy as np\nimport cv2\nfrom tflite_runtime.interpreter import Interpreter, load_delegate\n\n# Configuration Parameters\nmodel_path  = \"/home/mendel/tinyml_autopilot/models/edgetpu_detect.tflite\"\nlabel_path  = \"/home/mendel/tinyml_autopilot/models/labelmap.txt\"\ninput_video_path  = \"/home/mendel/tinyml_autopilot/data//sheeps.mp4\"\noutput_video_path  = \"/home/mendel/tinyml_autopilot/results/sheeps_detections.mp4\"\n\n# Load Labels\nwith open(label_path, 'r') as f:\n   labels = [line.strip() for line in f.readlines()]\n\n# Load Interpreter with EdgeTPU\ntry:\n   interpreter = Interpreter(model_path=model_path,\n                             experimental_delegates=[load_delegate('libedgetpu.so.1.0')])\nexcept:\n   interpreter = Interpreter(model_path=model_path,\n                             experimental_delegates=[load_delegate('/usr/lib/aarch64-linux-gnu/libedgetpu.so.1.0')])\n\ninterpreter.allocate_tensors()\n\n# Get Model Details\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\ninput_shape = input_details[0]['shape']\nfloating_model = (input_details[0]['dtype'] == np.float32)\n\n# Input Acquisition & Preprocessing Loop\ncap = cv2.VideoCapture(input_video_path)\nfourcc = cv2.VideoWriter_fourcc(*'mp4v')\nout = cv2.VideoWriter(output_video_path, fourcc, 20.0, (int(cap.get(3)), int(cap.get(4))))\n\nwhile(cap.isOpened()):\n   ret, frame = cap.read()\n   if not ret:\n       break\n\n   resized_frame = cv2.resize(frame, (input_shape[1], input_shape[2]))\n   input_data = np.expand_dims(resized_frame, axis=0)\n\n   if floating_model:\n       input_data = (np.float32(input_data) - 127.5) / 127.5\n\n   # Inference\n   interpreter.set_tensor(input_details[0]['index'], input_data)\n   interpreter.invoke()\n\n   # Output Interpretation & Handling\n   output_data = interpreter.get_tensor(output_details[0]['index'])\n   boxes = output_data[0][0:4]\n   classes = output_data[0][4]\n   confidence = output_data[0][5]\n\n   # Check if confidence is greater than 0.5 before accessing elements\n   if confidence > 0.5:\n       x_min = int(boxes[0] * frame.shape[1])\n       y_min = int(boxes[1] * frame.shape[0])\n       x_max = int(boxes[2] * frame.shape[1])\n       y_max = int(boxes[3] * frame.shape[0])\n\n       class_name = labels[int(classes)]\n\n       cv2.rectangle(frame, (x_min, y_min), (x_max, y_max), (0, 255, 0), 2)\n       cv2.putText(frame, f'{class_name}: {confidence:.2f}', (x_min, y_min - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n\n   out.write(frame)\n\ncap.release()\nout.release()\ncv2.destroyAllWindows()",
        "last_error": "Traceback (most recent call last):\n  File \"script_94741fcb_1753893798.py\", line 58, in <module>\n    if confidence > 0.5:\nValueError: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()"
      },
      "session_id": "gemma3:27b_85a9_tpusg_batch",
      "metadata": {
        "num_run": 18
      },
      "tags": [
        "benchmark",
        "gemma3:27b",
        "tpu_sketch_generator"
      ],
      "latency": 235.434,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-19-39-31-565232_chatcmpl-5cdc9513-b581-43bd-8e5c-58efd6be11c1",
          "traceId": "94bc6333",
          "type": "GENERATION",
          "name": "94bc_tpusg_gen_attempt#1",
          "startTime": "2025-07-30T16:39:31.565000+00:00",
          "endTime": "2025-07-30T16:40:04.692000+00:00",
          "model": "gemma3:27b",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 33127.0,
          "completionTokens": 852,
          "environment": "default",
          "totalTokens": 2818,
          "costDetails": {},
          "promptTokens": 1966,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-19-40-12-896444_chatcmpl-d1965c40-392a-42cd-b828-3f045ce01879",
          "traceId": "94bc6333",
          "type": "GENERATION",
          "name": "94bc_tpusg_gen_attempt#2",
          "startTime": "2025-07-30T16:40:12.896000+00:00",
          "endTime": "2025-07-30T16:40:52.637000+00:00",
          "model": "gemma3:27b",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 39741.0,
          "completionTokens": 1033,
          "environment": "default",
          "totalTokens": 3081,
          "costDetails": {},
          "promptTokens": 2048,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-19-41-00-917780_chatcmpl-f511fee9-127b-48f7-86d3-c387f019c66e",
          "traceId": "94bc6333",
          "type": "GENERATION",
          "name": "94bc_tpusg_gen_attempt#3",
          "startTime": "2025-07-30T16:41:00.917000+00:00",
          "endTime": "2025-07-30T16:41:42.953000+00:00",
          "model": "gemma3:27b",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 42036.0,
          "completionTokens": 1098,
          "environment": "default",
          "totalTokens": 3146,
          "costDetails": {},
          "promptTokens": 2048,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-19-41-51-562441_chatcmpl-d1ea46d6-01b1-4a5f-a91d-bf4e16f06dae",
          "traceId": "94bc6333",
          "type": "GENERATION",
          "name": "94bc_tpusg_gen_attempt#4",
          "startTime": "2025-07-30T16:41:51.562000+00:00",
          "endTime": "2025-07-30T16:42:30.120000+00:00",
          "model": "gemma3:27b",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 38558.0,
          "completionTokens": 1000,
          "environment": "default",
          "totalTokens": 3048,
          "costDetails": {},
          "promptTokens": 2048,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-19-42-38-503886_chatcmpl-79ab53e7-dc72-431d-a5a8-b750171c9e2d",
          "traceId": "94bc6333",
          "type": "GENERATION",
          "name": "94bc_tpusg_gen_attempt#5",
          "startTime": "2025-07-30T16:42:38.503000+00:00",
          "endTime": "2025-07-30T16:43:18.626000+00:00",
          "model": "gemma3:27b",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 40123.0,
          "completionTokens": 1050,
          "environment": "default",
          "totalTokens": 3098,
          "costDetails": {},
          "promptTokens": 2048,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "848ae6d1-86b7-4b6d-807b-c402214d4e6c",
          "traceId": "94bc6333",
          "type": "SPAN",
          "name": "error_94_tpusg_failure_signal_tpu_sketch_generator",
          "startTime": "2025-07-30T16:43:26.999000+00:00",
          "level": "ERROR",
          "statusMessage": "Failed. Last error: Traceback (most recent call last):\n  File \"script_94741fcb_1753893798.py\", line 58, in <module>\n    if confidence > 0.5:\nValueError: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()",
          "calculatedTotalCost": 0.0,
          "completionTokens": 0,
          "environment": "default",
          "totalTokens": 0,
          "costDetails": {},
          "promptTokens": 0,
          "endTime": null,
          "model": null,
          "modelParameters": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null,
          "latency": null
        }
      ],
      "updatedAt": "2025-07-30T16:43:32.303Z",
      "createdAt": "2025-07-30T16:39:32.084Z",
      "environment": "default"
    },
    {
      "id": "8fa803ed",
      "timestamp": "2025-07-30T16:35:08.704000+00:00",
      "name": "8fa8_tpu_sketch_generator",
      "input": null,
      "output": {
        "status": "failed",
        "last_code": "import numpy as np\nimport cv2\nfrom tflite_runtime.interpreter import Interpreter, load_delegate\n\n# Configuration Parameters\nmodel_path  = \"/home/mendel/tinyml_autopilot/models/edgetpu_detect.tflite\"\nlabel_path  = \"/home/mendel/tinyml_autopilot/models/labelmap.txt\"\ninput_video_path  = \"/home/mendel/tinyml_autopilot/data//sheeps.mp4\"\noutput_video_path  = \"/home/mendel/tinyml_autopilot/results/sheeps_detections.mp4\"\nconfidence_threshold  = 0.5\n\n# Load Labels\nwith open(label_path, 'r') as f:\n    labels = [line.strip() for line in f.readlines()]\n\n# Load Interpreter with EdgeTPU\ntry:\n    interpreter = Interpreter(model_path=model_path,\n                              experimental_delegates=[load_delegate('libedgetpu.so.1.0')])\nexcept:\n    interpreter = Interpreter(model_path=model_path,\n                              experimental_delegates=[load_delegate('/usr/lib/aarch64-linux-gnu/libedgetpu.so.1.0')])\n\ninterpreter.allocate_tensors()\n\n# Get Model Details\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\n\ninput_shape = input_details[0]['shape']\nfloating_model = (input_details[0]['dtype'] == np.float32)\n\n# Initialize Video Capture and Output\ncap = cv2.VideoCapture(input_video_path)\nif not cap.isOpened():\n    print(\"Error opening video stream or file\")\n    exit()\n\nfourcc = cv2.VideoWriter_fourcc(*'mp4v')\nout = cv2.VideoWriter(output_video_path, fourcc, 30.0, (int(cap.get(3)), int(cap.get(4))))\n\n\n# Input Acquisition & Preprocessing Loop\nwhile(cap.isOpened()):\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    # Preprocess Data\n    resized_frame = cv2.resize(frame, (input_shape[1], input_shape[2]))\n    input_data = np.expand_dims(resized_frame, axis=0)\n\n    if floating_model:\n        input_data = (np.float32(input_data) - 127.5) / 127.5\n\n    # Inference\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n    interpreter.invoke()\n\n    # Get Output\n    output_data = interpreter.get_tensor(output_details[0]['index'])\n\n    # Interpret Results\n    boxes = output_data[0, ..., 1:5]\n    classes = output_data[0, ..., 5]\n    scores = output_data[0, ..., 6]\n\n    # Post-processing\n    for i in range(boxes.shape[0]):\n        if scores[i] > confidence_threshold:\n            ymin, xmin, ymax, xmax = boxes[i]\n            ymin = int(ymin * frame.shape[0])\n            xmin = int(xmin * frame.shape[1])\n            ymax = int(ymax * frame.shape[0])\n            xmax = int(xmax * frame.shape[1])\n\n            class_id = int(classes[i])\n            label = labels[class_id]\n\n            cv2.rectangle(frame, (xmin, ymin), (xmax, ymax), (0, 255, 0), 2)\n            cv2.putText(frame, f'{label}: {scores[i]:.2f}', (xmin, ymin - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n\n    # Handle Output\n    out.write(frame)\n\n# Cleanup\ncap.release()\nout.release()\ncv2.destroyAllWindows()",
        "last_error": "Traceback (most recent call last):\n  File \"script_9343285f_1753893558.py\", line 65, in <module>\n    classes = output_data[0, ..., 5]\nIndexError: index 5 is out of bounds for axis 2 with size 4"
      },
      "session_id": "gemma3:27b_85a9_tpusg_batch",
      "metadata": {
        "num_run": 17
      },
      "tags": [
        "benchmark",
        "gemma3:27b",
        "tpu_sketch_generator"
      ],
      "latency": 257.738,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-19-35-08-706765_chatcmpl-dc9003b6-63d2-455a-b760-cb57301e847a",
          "traceId": "8fa803ed",
          "type": "GENERATION",
          "name": "8fa8_tpusg_gen_attempt#1",
          "startTime": "2025-07-30T16:35:08.706000+00:00",
          "endTime": "2025-07-30T16:35:44.654000+00:00",
          "model": "gemma3:27b",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 35948.0,
          "completionTokens": 933,
          "environment": "default",
          "totalTokens": 2899,
          "costDetails": {},
          "promptTokens": 1966,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-19-35-53-039948_chatcmpl-4927de3f-dd30-480a-aa5f-a40543136028",
          "traceId": "8fa803ed",
          "type": "GENERATION",
          "name": "8fa8_tpusg_gen_attempt#2",
          "startTime": "2025-07-30T16:35:53.039000+00:00",
          "endTime": "2025-07-30T16:36:36.873000+00:00",
          "model": "gemma3:27b",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 43834.0,
          "completionTokens": 1155,
          "environment": "default",
          "totalTokens": 3203,
          "costDetails": {},
          "promptTokens": 2048,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-19-36-45-103570_chatcmpl-1f7a3f8f-7fd8-44c2-ab93-cb7c0ac765ba",
          "traceId": "8fa803ed",
          "type": "GENERATION",
          "name": "8fa8_tpusg_gen_attempt#3",
          "startTime": "2025-07-30T16:36:45.103000+00:00",
          "endTime": "2025-07-30T16:37:28.221000+00:00",
          "model": "gemma3:27b",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 43118.0,
          "completionTokens": 1134,
          "environment": "default",
          "totalTokens": 3182,
          "costDetails": {},
          "promptTokens": 2048,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-19-37-36-415548_chatcmpl-42085d5c-b78b-438e-94ae-51c11b5d9c85",
          "traceId": "8fa803ed",
          "type": "GENERATION",
          "name": "8fa8_tpusg_gen_attempt#4",
          "startTime": "2025-07-30T16:37:36.415000+00:00",
          "endTime": "2025-07-30T16:38:28.648000+00:00",
          "model": "gemma3:27b",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 52233.0,
          "completionTokens": 1390,
          "environment": "default",
          "totalTokens": 3438,
          "costDetails": {},
          "promptTokens": 2048,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-19-38-37-062328_chatcmpl-54fe003a-4bc0-4c82-90f7-57a56f373ce2",
          "traceId": "8fa803ed",
          "type": "GENERATION",
          "name": "8fa8_tpusg_gen_attempt#5",
          "startTime": "2025-07-30T16:38:37.062000+00:00",
          "endTime": "2025-07-30T16:39:18.131000+00:00",
          "model": "gemma3:27b",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 41069.0,
          "completionTokens": 1072,
          "environment": "default",
          "totalTokens": 3120,
          "costDetails": {},
          "promptTokens": 2048,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "d5538a62-9622-42f4-a891-fc69238de310",
          "traceId": "8fa803ed",
          "type": "SPAN",
          "name": "error_8f_tpusg_failure_signal_tpu_sketch_generator",
          "startTime": "2025-07-30T16:39:26.444000+00:00",
          "level": "ERROR",
          "statusMessage": "Failed. Last error: Traceback (most recent call last):\n  File \"script_9343285f_1753893558.py\", line 65, in <module>\n    classes = output_data[0, ..., 5]\nIndexError: index 5 is out of bounds for axis 2 with size 4",
          "calculatedTotalCost": 0.0,
          "completionTokens": 0,
          "environment": "default",
          "totalTokens": 0,
          "costDetails": {},
          "promptTokens": 0,
          "endTime": null,
          "model": null,
          "modelParameters": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null,
          "latency": null
        }
      ],
      "updatedAt": "2025-07-30T16:39:31.964Z",
      "createdAt": "2025-07-30T16:35:09.228Z",
      "environment": "default"
    },
    {
      "id": "c0e353b4",
      "timestamp": "2025-07-30T16:30:21.811000+00:00",
      "name": "c0e3_tpu_sketch_generator",
      "input": null,
      "output": {
        "status": "failed",
        "last_code": "import cv2\nimport numpy as np\nimport tensorflow as tf\n\n# Video Setup\ncap = cv2.VideoCapture('sheeps.mp4') # Replace with your video file\nif not cap.isOpened():\n  print(\"Error opening video stream or file\")\n  exit()\n\nframe_width = int(cap.get(3))\nframe_height = int(cap.get(4))\nfps = int(cap.get(cv2.CAP_PROP_FPS))\n\nfourcc = cv2.VideoWriter_fourcc(*'mp4v')\nout = cv2.VideoWriter('sheeps_detection.mp4', fourcc, fps, (frame_width, frame_height))\n\n# Load labels\nwith open('labels.txt', 'r') as f:\n  labels = [line.strip() for line in f.readlines()]\n\n# Load the model\ninterpreter = tf.lite.Interpreter(model_path='detect.tflite')\ninterpreter.allocate_tensors()\n\n# Get input and output tensor information\ninput_details  = \"/home/mendel/tinyml_autopilot/data//sheeps.mp4\"\noutput_details  = \"/home/mendel/tinyml_autopilot/results/sheeps_detections.mp4\"\ninput_shape = input_details[0]['shape']\ninput_data_type = input_details[0]['dtype']\n\n# Confidence threshold\nconfidence_threshold  = 0.5\n\nwhile True:\n  ret, frame = cap.read()\n  if not ret:\n      break\n\n  # Resize the frame to match the model's input size\n  resized_frame = cv2.resize(frame, (input_shape[1], input_shape[2]))\n  input_tensor = np.expand_dims(resized_frame, axis=0)\n  input_tensor = np.array(input_tensor, dtype=input_data_type)\n\n  # Perform inference\n  interpreter.set_tensor(input_details[0]['index'], input_tensor)\n  interpreter.invoke()\n\n  # Get the output tensor\n  output_tensor = interpreter.get_tensor(output_details[0]['index'])\n\n  # Process the output tensor\n  boxes = output_tensor[0, 0, :, 0:4]\n  classes = output_tensor[0, 0, :, 4]\n  scores = output_tensor[0, 0, :, 5]\n\n  # Filter detections based on confidence threshold\n  valid_detections = []\n  for i in range(boxes.shape[0]):\n      if scores[i] > confidence_threshold:\n          x1, y1, x2, y2 = boxes[i]\n          class_id = int(classes[i])\n          class_name = labels[class_id]\n          confidence = scores[i]\n          valid_detections.append((x1, y1, x2, y2, class_name, confidence))\n\n  # Draw bounding boxes and labels on the frame\n  for x1, y1, x2, y2, class_name, confidence in valid_detections:\n      x1, y1, x2, y2 = int(x1 * frame_width / input_shape[1]), int(y1 * frame_height / input_shape[2]), int(x2 * frame_width / input_shape[1]), int(y2 * frame_height / input_shape[2])\n      cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n      label = f\"{class_name}: {confidence:.2f}\"\n      cv2.putText(frame, label, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n\n  # Write the frame to the output video\n  out.write(frame)\n\n# Release resources\ncap.release()\nout.release()\ncv2.destroyAllWindows()",
        "last_error": "Traceback (most recent call last):\n  File \"script_d03ea379_1753893294.py\", line 3, in <module>\n    import tensorflow as tf\nModuleNotFoundError: No module named 'tensorflow'"
      },
      "session_id": "gemma3:27b_85a9_tpusg_batch",
      "metadata": {
        "num_run": 16
      },
      "tags": [
        "benchmark",
        "gemma3:27b",
        "tpu_sketch_generator"
      ],
      "latency": 280.227,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-19-30-21-813520_chatcmpl-4555305d-08ab-4604-b52d-5f22db455166",
          "traceId": "c0e353b4",
          "type": "GENERATION",
          "name": "c0e3_tpusg_gen_attempt#1",
          "startTime": "2025-07-30T16:30:21.813000+00:00",
          "endTime": "2025-07-30T16:31:28.528000+00:00",
          "model": "gemma3:27b",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 66715.0,
          "completionTokens": 1085,
          "environment": "default",
          "totalTokens": 3051,
          "costDetails": {},
          "promptTokens": 1966,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-19-31-36-907600_chatcmpl-10e4e6ac-d250-490f-8338-b9b85df87952",
          "traceId": "c0e353b4",
          "type": "GENERATION",
          "name": "c0e3_tpusg_gen_attempt#2",
          "startTime": "2025-07-30T16:31:36.907000+00:00",
          "endTime": "2025-07-30T16:32:22.767000+00:00",
          "model": "gemma3:27b",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 45860.0,
          "completionTokens": 1125,
          "environment": "default",
          "totalTokens": 3173,
          "costDetails": {},
          "promptTokens": 2048,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-19-32-26-825022_chatcmpl-17ec252e-20d8-4085-ab4d-6e82620f638b",
          "traceId": "c0e353b4",
          "type": "GENERATION",
          "name": "c0e3_tpusg_gen_attempt#3",
          "startTime": "2025-07-30T16:32:26.825000+00:00",
          "endTime": "2025-07-30T16:33:11.235000+00:00",
          "model": "gemma3:27b",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 44410.0,
          "completionTokens": 1165,
          "environment": "default",
          "totalTokens": 3213,
          "costDetails": {},
          "promptTokens": 2048,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-19-33-19-015144_chatcmpl-4c59b373-c759-4a43-b820-14115e13cf0e",
          "traceId": "c0e353b4",
          "type": "GENERATION",
          "name": "c0e3_tpusg_gen_attempt#4",
          "startTime": "2025-07-30T16:33:19.015000+00:00",
          "endTime": "2025-07-30T16:34:01.789000+00:00",
          "model": "gemma3:27b",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 42774.0,
          "completionTokens": 1126,
          "environment": "default",
          "totalTokens": 3174,
          "costDetails": {},
          "promptTokens": 2048,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-19-34-09-764479_chatcmpl-3ab8f3ba-cdd6-4d2e-9c36-7993b45bb3e8",
          "traceId": "c0e353b4",
          "type": "GENERATION",
          "name": "c0e3_tpusg_gen_attempt#5",
          "startTime": "2025-07-30T16:34:09.764000+00:00",
          "endTime": "2025-07-30T16:34:54.308000+00:00",
          "model": "gemma3:27b",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 44544.0,
          "completionTokens": 1176,
          "environment": "default",
          "totalTokens": 3224,
          "costDetails": {},
          "promptTokens": 2048,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "5fb4bd8f-c5e2-4f9d-a096-9b94a79f2b17",
          "traceId": "c0e353b4",
          "type": "SPAN",
          "name": "error_c0_tpusg_failure_signal_tpu_sketch_generator",
          "startTime": "2025-07-30T16:35:02.040000+00:00",
          "level": "ERROR",
          "statusMessage": "Failed. Last error: Traceback (most recent call last):\n  File \"script_d03ea379_1753893294.py\", line 3, in <module>\n    import tensorflow as tf\nModuleNotFoundError: No module named 'tensorflow'",
          "calculatedTotalCost": 0.0,
          "completionTokens": 0,
          "environment": "default",
          "totalTokens": 0,
          "costDetails": {},
          "promptTokens": 0,
          "endTime": null,
          "model": null,
          "modelParameters": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null,
          "latency": null
        }
      ],
      "updatedAt": "2025-07-30T16:35:07.517Z",
      "createdAt": "2025-07-30T16:30:22.337Z",
      "environment": "default"
    },
    {
      "id": "70e32f98",
      "timestamp": "2025-07-30T16:29:54.041000+00:00",
      "name": "70e3_tpu_sketch_generator",
      "input": null,
      "output": {
        "status": "failed",
        "last_code": "",
        "last_error": "Unexpected error during generation: litellm.APIConnectionError: OllamaException - {\"error\":\"llama runner process has terminated: CUDA error: all CUDA-capable devices are busy or unavailable\\n  current device: 0, in function ggml_backend_cuda_device_get_memory at //ml/backend/ggml/ggml/src/ggml-cuda/ggml-cuda.cu:2898\\n  cudaMemGetInfo(free, total)\\n//ml/backend/ggml/ggml/src/ggml-cuda/ggml-cuda.cu:73: CUDA error\"}"
      },
      "session_id": "gemma3:27b_85a9_tpusg_batch",
      "metadata": {
        "num_run": 15
      },
      "tags": [
        "benchmark",
        "gemma3:27b",
        "tpu_sketch_generator"
      ],
      "latency": 0.0,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "c85a6918-26e6-44fe-86b3-4fe9f68aac7f",
          "traceId": "70e32f98",
          "type": "SPAN",
          "name": "error_70_tpusg_failure_signal_tpu_sketch_generator",
          "startTime": "2025-07-30T16:30:14.667000+00:00",
          "level": "ERROR",
          "statusMessage": "Failed. Last error: Unexpected error during generation: litellm.APIConnectionError: OllamaException - {\"error\":\"llama runner process has terminated: CUDA error: all CUDA-capable devices are busy or unavailable\\n  current device: 0, in function ggml_backend_cuda_device_get_memory at //ml/backend/ggml/ggml/src/ggml-cuda/ggml-cuda.cu:2898\\n  cudaMemGetInfo(free, total)\\n//ml/backend/ggml/ggml/src/ggml-cuda/ggml-cuda.cu:73: CUDA error\"}",
          "calculatedTotalCost": 0.0,
          "completionTokens": 0,
          "environment": "default",
          "totalTokens": 0,
          "costDetails": {},
          "promptTokens": 0,
          "endTime": null,
          "model": null,
          "modelParameters": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null,
          "latency": null
        }
      ],
      "updatedAt": "2025-07-30T16:30:20.193Z",
      "createdAt": "2025-07-30T16:29:54.564Z",
      "environment": "default"
    },
    {
      "id": "50bf6317",
      "timestamp": "2025-07-30T16:29:25.786000+00:00",
      "name": "50bf_tpu_sketch_generator",
      "input": null,
      "output": {
        "status": "failed",
        "last_code": "",
        "last_error": "Unexpected error during generation: litellm.APIConnectionError: OllamaException - {\"error\":\"llama runner process has terminated: CUDA error\"}"
      },
      "session_id": "gemma3:27b_85a9_tpusg_batch",
      "metadata": {
        "num_run": 14
      },
      "tags": [
        "benchmark",
        "gemma3:27b",
        "tpu_sketch_generator"
      ],
      "latency": 0.0,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "57e4c596-d1a5-455d-9404-ce8730abd95a",
          "traceId": "50bf6317",
          "type": "SPAN",
          "name": "error_50_tpusg_failure_signal_tpu_sketch_generator",
          "startTime": "2025-07-30T16:29:48.412000+00:00",
          "level": "ERROR",
          "statusMessage": "Failed. Last error: Unexpected error during generation: litellm.APIConnectionError: OllamaException - {\"error\":\"llama runner process has terminated: CUDA error\"}",
          "calculatedTotalCost": 0.0,
          "completionTokens": 0,
          "environment": "default",
          "totalTokens": 0,
          "costDetails": {},
          "promptTokens": 0,
          "endTime": null,
          "model": null,
          "modelParameters": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null,
          "latency": null
        }
      ],
      "updatedAt": "2025-07-30T16:29:53.899Z",
      "createdAt": "2025-07-30T16:29:26.308Z",
      "environment": "default"
    },
    {
      "id": "cb654918",
      "timestamp": "2025-07-30T16:28:56.069000+00:00",
      "name": "cb65_tpu_sketch_generator",
      "input": null,
      "output": {
        "status": "failed",
        "last_code": "",
        "last_error": "Unexpected error during generation: litellm.APIConnectionError: OllamaException - {\"error\":\"llama runner process has terminated: CUDA error: all CUDA-capable devices are busy or unavailable\\n  current device: 0, in function ggml_backend_cuda_device_get_memory at //ml/backend/ggml/ggml/src/ggml-cuda/ggml-cuda.cu:2898\\n  cudaMemGetInfo(free, total)\\n//ml/backend/ggml/ggml/src/ggml-cuda/ggml-cuda.cu:73: CUDA error\"}"
      },
      "session_id": "gemma3:27b_85a9_tpusg_batch",
      "metadata": {
        "num_run": 13
      },
      "tags": [
        "benchmark",
        "gemma3:27b",
        "tpu_sketch_generator"
      ],
      "latency": 0.0,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "68e0b461-1430-47e4-a3f7-cfca1399fc09",
          "traceId": "cb654918",
          "type": "SPAN",
          "name": "error_cb_tpusg_failure_signal_tpu_sketch_generator",
          "startTime": "2025-07-30T16:29:18.133000+00:00",
          "level": "ERROR",
          "statusMessage": "Failed. Last error: Unexpected error during generation: litellm.APIConnectionError: OllamaException - {\"error\":\"llama runner process has terminated: CUDA error: all CUDA-capable devices are busy or unavailable\\n  current device: 0, in function ggml_backend_cuda_device_get_memory at //ml/backend/ggml/ggml/src/ggml-cuda/ggml-cuda.cu:2898\\n  cudaMemGetInfo(free, total)\\n//ml/backend/ggml/ggml/src/ggml-cuda/ggml-cuda.cu:73: CUDA error\"}",
          "calculatedTotalCost": 0.0,
          "completionTokens": 0,
          "environment": "default",
          "totalTokens": 0,
          "costDetails": {},
          "promptTokens": 0,
          "endTime": null,
          "model": null,
          "modelParameters": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null,
          "latency": null
        }
      ],
      "updatedAt": "2025-07-30T16:29:23.690Z",
      "createdAt": "2025-07-30T16:28:56.591Z",
      "environment": "default"
    },
    {
      "id": "83639320",
      "timestamp": "2025-07-30T16:28:31.527000+00:00",
      "name": "8363_tpu_sketch_generator",
      "input": null,
      "output": {
        "status": "failed",
        "last_code": "",
        "last_error": "Unexpected error during generation: litellm.APIConnectionError: OllamaException - {\"error\":\"llama runner process has terminated: CUDA error: all CUDA-capable devices are busy or unavailable\\n  current device: 0, in function ggml_backend_cuda_device_get_memory at //ml/backend/ggml/ggml/src/ggml-cuda/ggml-cuda.cu:2898\\n  cudaMemGetInfo(free, total)\\n//ml/backend/ggml/ggml/src/ggml-cuda/ggml-cuda.cu:73: CUDA error\"}"
      },
      "session_id": "gemma3:27b_85a9_tpusg_batch",
      "metadata": {
        "num_run": 12
      },
      "tags": [
        "benchmark",
        "gemma3:27b",
        "tpu_sketch_generator"
      ],
      "latency": 0.0,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "04c74fde-d7c6-4ec0-a387-7788f100e572",
          "traceId": "83639320",
          "type": "SPAN",
          "name": "error_83_tpusg_failure_signal_tpu_sketch_generator",
          "startTime": "2025-07-30T16:28:50.017000+00:00",
          "level": "ERROR",
          "statusMessage": "Failed. Last error: Unexpected error during generation: litellm.APIConnectionError: OllamaException - {\"error\":\"llama runner process has terminated: CUDA error: all CUDA-capable devices are busy or unavailable\\n  current device: 0, in function ggml_backend_cuda_device_get_memory at //ml/backend/ggml/ggml/src/ggml-cuda/ggml-cuda.cu:2898\\n  cudaMemGetInfo(free, total)\\n//ml/backend/ggml/ggml/src/ggml-cuda/ggml-cuda.cu:73: CUDA error\"}",
          "calculatedTotalCost": 0.0,
          "completionTokens": 0,
          "environment": "default",
          "totalTokens": 0,
          "costDetails": {},
          "promptTokens": 0,
          "endTime": null,
          "model": null,
          "modelParameters": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null,
          "latency": null
        }
      ],
      "updatedAt": "2025-07-30T16:28:55.184Z",
      "createdAt": "2025-07-30T16:28:32.050Z",
      "environment": "default"
    },
    {
      "id": "709f7a09",
      "timestamp": "2025-07-30T16:28:05.790000+00:00",
      "name": "709f_tpu_sketch_generator",
      "input": null,
      "output": {
        "status": "failed",
        "last_code": "",
        "last_error": "Unexpected error during generation: litellm.APIConnectionError: OllamaException - {\"error\":\"llama runner process has terminated: CUDA error\"}"
      },
      "session_id": "gemma3:27b_85a9_tpusg_batch",
      "metadata": {
        "num_run": 11
      },
      "tags": [
        "benchmark",
        "gemma3:27b",
        "tpu_sketch_generator"
      ],
      "latency": 0.0,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "14536dee-894b-48df-a484-efa55de8cca0",
          "traceId": "709f7a09",
          "type": "SPAN",
          "name": "error_70_tpusg_failure_signal_tpu_sketch_generator",
          "startTime": "2025-07-30T16:28:25.227000+00:00",
          "level": "ERROR",
          "statusMessage": "Failed. Last error: Unexpected error during generation: litellm.APIConnectionError: OllamaException - {\"error\":\"llama runner process has terminated: CUDA error\"}",
          "calculatedTotalCost": 0.0,
          "completionTokens": 0,
          "environment": "default",
          "totalTokens": 0,
          "costDetails": {},
          "promptTokens": 0,
          "endTime": null,
          "model": null,
          "modelParameters": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null,
          "latency": null
        }
      ],
      "updatedAt": "2025-07-30T16:28:30.495Z",
      "createdAt": "2025-07-30T16:28:06.312Z",
      "environment": "default"
    },
    {
      "id": "e8af9416",
      "timestamp": "2025-07-30T16:27:41.200000+00:00",
      "name": "e8af_tpu_sketch_generator",
      "input": null,
      "output": {
        "status": "failed",
        "last_code": "",
        "last_error": "Unexpected error during generation: litellm.APIConnectionError: OllamaException - {\"error\":\"llama runner process has terminated: CUDA error\"}"
      },
      "session_id": "gemma3:27b_85a9_tpusg_batch",
      "metadata": {
        "num_run": 10
      },
      "tags": [
        "benchmark",
        "gemma3:27b",
        "tpu_sketch_generator"
      ],
      "latency": 0.0,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "4ca23000-8f9a-4168-b93c-9671d9bed3c1",
          "traceId": "e8af9416",
          "type": "SPAN",
          "name": "error_e8_tpusg_failure_signal_tpu_sketch_generator",
          "startTime": "2025-07-30T16:27:59.982000+00:00",
          "level": "ERROR",
          "statusMessage": "Failed. Last error: Unexpected error during generation: litellm.APIConnectionError: OllamaException - {\"error\":\"llama runner process has terminated: CUDA error\"}",
          "calculatedTotalCost": 0.0,
          "completionTokens": 0,
          "environment": "default",
          "totalTokens": 0,
          "costDetails": {},
          "promptTokens": 0,
          "endTime": null,
          "model": null,
          "modelParameters": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null,
          "latency": null
        }
      ],
      "updatedAt": "2025-07-30T16:28:05.506Z",
      "createdAt": "2025-07-30T16:27:41.722Z",
      "environment": "default"
    },
    {
      "id": "3dd33b04",
      "timestamp": "2025-07-30T16:27:16.405000+00:00",
      "name": "3dd3_tpu_sketch_generator",
      "input": null,
      "output": {
        "status": "failed",
        "last_code": "",
        "last_error": "Unexpected error during generation: litellm.APIConnectionError: OllamaException - {\"error\":\"llama runner process has terminated: CUDA error\"}"
      },
      "session_id": "gemma3:27b_85a9_tpusg_batch",
      "metadata": {
        "num_run": 9
      },
      "tags": [
        "benchmark",
        "gemma3:27b",
        "tpu_sketch_generator"
      ],
      "latency": 0.0,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "8d986505-9fd2-4f06-af3d-002a5b87ec39",
          "traceId": "3dd33b04",
          "type": "SPAN",
          "name": "error_3d_tpusg_failure_signal_tpu_sketch_generator",
          "startTime": "2025-07-30T16:27:35.233000+00:00",
          "level": "ERROR",
          "statusMessage": "Failed. Last error: Unexpected error during generation: litellm.APIConnectionError: OllamaException - {\"error\":\"llama runner process has terminated: CUDA error\"}",
          "calculatedTotalCost": 0.0,
          "completionTokens": 0,
          "environment": "default",
          "totalTokens": 0,
          "costDetails": {},
          "promptTokens": 0,
          "endTime": null,
          "model": null,
          "modelParameters": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null,
          "latency": null
        }
      ],
      "updatedAt": "2025-07-30T16:27:40.517Z",
      "createdAt": "2025-07-30T16:27:16.926Z",
      "environment": "default"
    },
    {
      "id": "b2fe0b78",
      "timestamp": "2025-07-30T16:26:52.604000+00:00",
      "name": "b2fe_tpu_sketch_generator",
      "input": null,
      "output": {
        "status": "failed",
        "last_code": "",
        "last_error": "Unexpected error during generation: litellm.APIConnectionError: OllamaException - {\"error\":\"llama runner process has terminated: CUDA error\"}"
      },
      "session_id": "gemma3:27b_85a9_tpusg_batch",
      "metadata": {
        "num_run": 8
      },
      "tags": [
        "benchmark",
        "gemma3:27b",
        "tpu_sketch_generator"
      ],
      "latency": 0.0,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "313669e6-2765-4200-91a3-8ae5f1cf7b58",
          "traceId": "b2fe0b78",
          "type": "SPAN",
          "name": "error_b2_tpusg_failure_signal_tpu_sketch_generator",
          "startTime": "2025-07-30T16:27:09.978000+00:00",
          "level": "ERROR",
          "statusMessage": "Failed. Last error: Unexpected error during generation: litellm.APIConnectionError: OllamaException - {\"error\":\"llama runner process has terminated: CUDA error\"}",
          "calculatedTotalCost": 0.0,
          "completionTokens": 0,
          "environment": "default",
          "totalTokens": 0,
          "costDetails": {},
          "promptTokens": 0,
          "endTime": null,
          "model": null,
          "modelParameters": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null,
          "latency": null
        }
      ],
      "updatedAt": "2025-07-30T16:27:15.229Z",
      "createdAt": "2025-07-30T16:26:53.125Z",
      "environment": "default"
    },
    {
      "id": "4b0027db",
      "timestamp": "2025-07-30T16:26:27.046000+00:00",
      "name": "4b00_tpu_sketch_generator",
      "input": null,
      "output": {
        "status": "failed",
        "last_code": "",
        "last_error": "Unexpected error during generation: litellm.APIConnectionError: OllamaException - {\"error\":\"llama runner process has terminated: CUDA error\"}"
      },
      "session_id": "gemma3:27b_85a9_tpusg_batch",
      "metadata": {
        "num_run": 7
      },
      "tags": [
        "benchmark",
        "gemma3:27b",
        "tpu_sketch_generator"
      ],
      "latency": 0.0,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "e7b4ef5f-d70f-49c5-857b-9561eb4b0f58",
          "traceId": "4b0027db",
          "type": "SPAN",
          "name": "error_4b_tpusg_failure_signal_tpu_sketch_generator",
          "startTime": "2025-07-30T16:26:45.215000+00:00",
          "level": "ERROR",
          "statusMessage": "Failed. Last error: Unexpected error during generation: litellm.APIConnectionError: OllamaException - {\"error\":\"llama runner process has terminated: CUDA error\"}",
          "calculatedTotalCost": 0.0,
          "completionTokens": 0,
          "environment": "default",
          "totalTokens": 0,
          "costDetails": {},
          "promptTokens": 0,
          "endTime": null,
          "model": null,
          "modelParameters": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null,
          "latency": null
        }
      ],
      "updatedAt": "2025-07-30T16:26:50.736Z",
      "createdAt": "2025-07-30T16:26:27.568Z",
      "environment": "default"
    },
    {
      "id": "b3dbcd53",
      "timestamp": "2025-07-30T16:26:01.241000+00:00",
      "name": "b3db_tpu_sketch_generator",
      "input": null,
      "output": {
        "status": "failed",
        "last_code": "",
        "last_error": "Unexpected error during generation: litellm.APIConnectionError: OllamaException - {\"error\":\"llama runner process has terminated: CUDA error\"}"
      },
      "session_id": "gemma3:27b_85a9_tpusg_batch",
      "metadata": {
        "num_run": 6
      },
      "tags": [
        "benchmark",
        "gemma3:27b",
        "tpu_sketch_generator"
      ],
      "latency": 0.0,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "2dbe24be-6587-44de-b214-2f736366e123",
          "traceId": "b3dbcd53",
          "type": "SPAN",
          "name": "error_b3_tpusg_failure_signal_tpu_sketch_generator",
          "startTime": "2025-07-30T16:26:20.223000+00:00",
          "level": "ERROR",
          "statusMessage": "Failed. Last error: Unexpected error during generation: litellm.APIConnectionError: OllamaException - {\"error\":\"llama runner process has terminated: CUDA error\"}",
          "calculatedTotalCost": 0.0,
          "completionTokens": 0,
          "environment": "default",
          "totalTokens": 0,
          "costDetails": {},
          "promptTokens": 0,
          "endTime": null,
          "model": null,
          "modelParameters": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null,
          "latency": null
        }
      ],
      "updatedAt": "2025-07-30T16:26:25.447Z",
      "createdAt": "2025-07-30T16:26:01.764Z",
      "environment": "default"
    },
    {
      "id": "0fefba25",
      "timestamp": "2025-07-30T16:25:36.695000+00:00",
      "name": "0fef_tpu_sketch_generator",
      "input": null,
      "output": {
        "status": "failed",
        "last_code": "",
        "last_error": "Unexpected error during generation: litellm.APIConnectionError: OllamaException - {\"error\":\"llama runner process has terminated: CUDA error\"}"
      },
      "session_id": "gemma3:27b_85a9_tpusg_batch",
      "metadata": {
        "num_run": 5
      },
      "tags": [
        "benchmark",
        "gemma3:27b",
        "tpu_sketch_generator"
      ],
      "latency": 0.0,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "da182fa7-784c-46b9-b3e0-f12967d282b5",
          "traceId": "0fefba25",
          "type": "SPAN",
          "name": "error_0f_tpusg_failure_signal_tpu_sketch_generator",
          "startTime": "2025-07-30T16:25:55.226000+00:00",
          "level": "ERROR",
          "statusMessage": "Failed. Last error: Unexpected error during generation: litellm.APIConnectionError: OllamaException - {\"error\":\"llama runner process has terminated: CUDA error\"}",
          "calculatedTotalCost": 0.0,
          "completionTokens": 0,
          "environment": "default",
          "totalTokens": 0,
          "costDetails": {},
          "promptTokens": 0,
          "endTime": null,
          "model": null,
          "modelParameters": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null,
          "latency": null
        }
      ],
      "updatedAt": "2025-07-30T16:26:00.358Z",
      "createdAt": "2025-07-30T16:25:37.216Z",
      "environment": "default"
    },
    {
      "id": "6d20b6c2",
      "timestamp": "2025-07-30T16:25:10.938000+00:00",
      "name": "6d20_tpu_sketch_generator",
      "input": null,
      "output": {
        "status": "failed",
        "last_code": "",
        "last_error": "Unexpected error during generation: litellm.APIConnectionError: OllamaException - {\"error\":\"llama runner process has terminated: CUDA error\"}"
      },
      "session_id": "gemma3:27b_85a9_tpusg_batch",
      "metadata": {
        "num_run": 4
      },
      "tags": [
        "benchmark",
        "gemma3:27b",
        "tpu_sketch_generator"
      ],
      "latency": 0.0,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "e95b6979-d85e-4787-ab3d-8cd62987bb2c",
          "traceId": "6d20b6c2",
          "type": "SPAN",
          "name": "error_6d_tpusg_failure_signal_tpu_sketch_generator",
          "startTime": "2025-07-30T16:25:30.213000+00:00",
          "level": "ERROR",
          "statusMessage": "Failed. Last error: Unexpected error during generation: litellm.APIConnectionError: OllamaException - {\"error\":\"llama runner process has terminated: CUDA error\"}",
          "calculatedTotalCost": 0.0,
          "completionTokens": 0,
          "environment": "default",
          "totalTokens": 0,
          "costDetails": {},
          "promptTokens": 0,
          "endTime": null,
          "model": null,
          "modelParameters": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null,
          "latency": null
        }
      ],
      "updatedAt": "2025-07-30T16:25:35.570Z",
      "createdAt": "2025-07-30T16:25:11.458Z",
      "environment": "default"
    },
    {
      "id": "5c08ea9c",
      "timestamp": "2025-07-30T16:24:46.377000+00:00",
      "name": "5c08_tpu_sketch_generator",
      "input": null,
      "output": {
        "status": "failed",
        "last_code": "",
        "last_error": "Unexpected error during generation: litellm.APIConnectionError: OllamaException - {\"error\":\"llama runner process has terminated: CUDA error\"}"
      },
      "session_id": "gemma3:27b_85a9_tpusg_batch",
      "metadata": {
        "num_run": 3
      },
      "tags": [
        "benchmark",
        "gemma3:27b",
        "tpu_sketch_generator"
      ],
      "latency": 0.0,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "51757002-d1c3-4618-b928-4d85f538017d",
          "traceId": "5c08ea9c",
          "type": "SPAN",
          "name": "error_5c_tpusg_failure_signal_tpu_sketch_generator",
          "startTime": "2025-07-30T16:25:04.925000+00:00",
          "level": "ERROR",
          "statusMessage": "Failed. Last error: Unexpected error during generation: litellm.APIConnectionError: OllamaException - {\"error\":\"llama runner process has terminated: CUDA error\"}",
          "calculatedTotalCost": 0.0,
          "completionTokens": 0,
          "environment": "default",
          "totalTokens": 0,
          "costDetails": {},
          "promptTokens": 0,
          "endTime": null,
          "model": null,
          "modelParameters": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null,
          "latency": null
        }
      ],
      "updatedAt": "2025-07-30T16:25:10.583Z",
      "createdAt": "2025-07-30T16:24:46.899Z",
      "environment": "default"
    },
    {
      "id": "1e1c0c16",
      "timestamp": "2025-07-30T16:24:21.642000+00:00",
      "name": "1e1c_tpu_sketch_generator",
      "input": null,
      "output": {
        "status": "failed",
        "last_code": "",
        "last_error": "Unexpected error during generation: litellm.APIConnectionError: OllamaException - {\"error\":\"llama runner process has terminated: CUDA error\"}"
      },
      "session_id": "gemma3:27b_85a9_tpusg_batch",
      "metadata": {
        "num_run": 2
      },
      "tags": [
        "benchmark",
        "gemma3:27b",
        "tpu_sketch_generator"
      ],
      "latency": 0.0,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "fe0919c1-f0c4-40e7-b3bd-a85652d38e9b",
          "traceId": "1e1c0c16",
          "type": "SPAN",
          "name": "error_1e_tpusg_failure_signal_tpu_sketch_generator",
          "startTime": "2025-07-30T16:24:40.194000+00:00",
          "level": "ERROR",
          "statusMessage": "Failed. Last error: Unexpected error during generation: litellm.APIConnectionError: OllamaException - {\"error\":\"llama runner process has terminated: CUDA error\"}",
          "calculatedTotalCost": 0.0,
          "completionTokens": 0,
          "environment": "default",
          "totalTokens": 0,
          "costDetails": {},
          "promptTokens": 0,
          "endTime": null,
          "model": null,
          "modelParameters": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null,
          "latency": null
        }
      ],
      "updatedAt": "2025-07-30T16:24:45.790Z",
      "createdAt": "2025-07-30T16:24:22.163Z",
      "environment": "default"
    },
    {
      "id": "8c262c73",
      "timestamp": "2025-07-30T16:23:56.788000+00:00",
      "name": "8c26_tpu_sketch_generator",
      "input": null,
      "output": {
        "status": "failed",
        "last_code": "",
        "last_error": "Unexpected error during generation: litellm.APIConnectionError: OllamaException - {\"error\":\"llama runner process has terminated: CUDA error\"}"
      },
      "session_id": "gemma3:27b_85a9_tpusg_batch",
      "metadata": {
        "num_run": 1
      },
      "tags": [
        "benchmark",
        "gemma3:27b",
        "tpu_sketch_generator"
      ],
      "latency": 0.0,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "522643a0-f7dd-405b-86f5-691c3ca680f2",
          "traceId": "8c262c73",
          "type": "SPAN",
          "name": "error_8c_tpusg_failure_signal_tpu_sketch_generator",
          "startTime": "2025-07-30T16:24:15.175000+00:00",
          "level": "ERROR",
          "statusMessage": "Failed. Last error: Unexpected error during generation: litellm.APIConnectionError: OllamaException - {\"error\":\"llama runner process has terminated: CUDA error\"}",
          "calculatedTotalCost": 0.0,
          "completionTokens": 0,
          "environment": "default",
          "totalTokens": 0,
          "costDetails": {},
          "promptTokens": 0,
          "endTime": null,
          "model": null,
          "modelParameters": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null,
          "latency": null
        }
      ],
      "updatedAt": "2025-07-30T16:24:20.498Z",
      "createdAt": "2025-07-30T16:23:57.308Z",
      "environment": "default"
    }
  ],
  "meta": {
    "total_items": 30
  }
}
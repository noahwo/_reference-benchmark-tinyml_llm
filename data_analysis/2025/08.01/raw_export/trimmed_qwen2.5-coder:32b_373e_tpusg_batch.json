{
  "data": [
    {
      "id": "9187f281",
      "timestamp": "2025-08-03T20:26:58.621000+00:00",
      "name": "9187_tpu_sketch_generator",
      "input": null,
      "output": {
        "status": "failed",
        "last_code": "import numpy as np\nfrom tflite_runtime.interpreter import Interpreter, load_delegate\nimport cv2\n\n# Phase 1: Setup\nmodel_path  = \"/home/mendel/tinyml_autopilot/models/edgetpu_detect.tflite\"\nlabel_path  = \"/home/mendel/tinyml_autopilot/models/labelmap.txt\"\ninput_path  = \"/home/mendel/tinyml_autopilot/data//sheeps.mp4\"\noutput_path  = \"/home/mendel/tinyml_autopilot/results/sheeps_detections.mp4\"\nconfidence_threshold  = 0.5\n\n# Load labels\nwith open(label_path, 'r') as f:\n    labels = [line.strip() for line in f.readlines()]\n\n# Load Interpreter with EdgeTPU\ntry:\n    interpreter = Interpreter(model_path=model_path,\n                              experimental_delegates=[load_delegate('libedgetpu.so.1.0')])\nexcept Exception as e:\n    print(f\"Failed to load libedgetpu.so.1.0: {e}\")\n    try:\n        interpreter = Interpreter(model_path=model_path,\n                                  experimental_delegates=[load_delegate('/usr/lib/aarch64-linux-gnu/libedgetpu.so.1.0')])\n    except Exception as e:\n        print(f\"Failed to load /usr/lib/aarch64-linux-gnu/libedgetpu.so.1.0: {e}\")\n        raise\n\ninterpreter.allocate_tensors()\n\n# Get Model Details\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\n\nfloating_model = (input_details[0]['dtype'] == np.float32)\n\n# Phase 2: Input Acquisition & Preprocessing Loop\ncap = cv2.VideoCapture(input_path)\nif not cap.isOpened():\n    raise IOError(\"Cannot open video file\")\n\nframe_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\nframe_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\nfps = cap.get(cv2.CAP_PROP_FPS)\n\nout = cv2.VideoWriter(output_path, cv2.VideoWriter_fourcc(*'mp4v'), fps, (frame_width, frame_height))\n\nwhile True:\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    # Preprocess Data\n    input_data = cv2.resize(frame, (input_details[0]['shape'][1], input_details[0]['shape'][2]))\n    input_data = np.expand_dims(input_data, axis=0)\n\n    if floating_model:\n        input_data = (np.float32(input_data) - 127.5) / 127.5\n\n    # Phase 3: Inference\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n    interpreter.invoke()\n\n    # Phase 4: Output Interpretation & Handling Loop\n    output_data = interpreter.get_tensor(output_details[0]['index'])\n    num_detections = int(interpreter.get_tensor(output_details[1]['index'])[0])  # Access the first element of the array\n    detection_boxes = interpreter.get_tensor(output_details[2]['index'])[0]\n    detection_classes = interpreter.get_tensor(output_details[3]['index'])[0].astype(int)\n    detection_scores = interpreter.get_tensor(output_details[4]['index'])[0]\n\n    for i in range(num_detections):\n        if detection_scores[i] > confidence_threshold:\n            box = detection_boxes[i]\n            class_id = detection_classes[i]\n            score = detection_scores[i]\n\n            # Scale and clip bounding boxes\n            ymin, xmin, ymax, xmax = box\n            (left, right, top, bottom) = (xmin * frame_width, xmax * frame_width,\n                                          ymin * frame_height, ymax * frame_height)\n\n            cv2.rectangle(frame, (int(left), int(top)), (int(right), int(bottom)), (0, 255, 0), 2)\n            label = f'{labels[class_id]}: {score:.2f}'\n            cv2.putText(frame, label, (int(left), int(top) - 10),\n                        cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n\n    # Handle Output\n    out.write(frame)\n\n# Phase 5: Cleanup\ncap.release()\nout.release()\ncv2.destroyAllWindows()",
        "last_error": "Traceback (most recent call last):\n  File \"script_f07cbbf9_1754253005.py\", line 66, in <module>\n    num_detections = int(interpreter.get_tensor(output_details[1]['index'])[0])  # Access the first element of the array\nTypeError: only size-1 arrays can be converted to Python scalars"
      },
      "session_id": "qwen2.5-coder:32b_373e_tpusg_batch",
      "metadata": {
        "num_run": 30
      },
      "tags": [
        "benchmark",
        "qwen2.5-coder:32b",
        "tpu_sketch_generator"
      ],
      "latency": 195.581,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-23-26-58-623461_chatcmpl-d456356f-f7ef-4ef4-9449-f86f7fe557b1",
          "traceId": "9187f281",
          "type": "GENERATION",
          "name": "9187_tpusg_gen_attempt#1",
          "startTime": "2025-08-03T20:26:58.623000+00:00",
          "endTime": "2025-08-03T20:27:24.068000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 25445.0,
          "environment": "default",
          "totalTokens": 2709,
          "costDetails": {},
          "completionTokens": 876,
          "promptTokens": 1833,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-23-27-32-199896_chatcmpl-7efc0545-3aad-4799-bcdb-d76776f9b021",
          "traceId": "9187f281",
          "type": "GENERATION",
          "name": "9187_tpusg_gen_attempt#2",
          "startTime": "2025-08-03T20:27:32.199000+00:00",
          "endTime": "2025-08-03T20:28:03.636000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 31437.0,
          "environment": "default",
          "totalTokens": 3145,
          "costDetails": {},
          "completionTokens": 1097,
          "promptTokens": 2048,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-23-28-11-711563_chatcmpl-3e83fecb-1b1f-4eeb-9735-fa7ce5b59e42",
          "traceId": "9187f281",
          "type": "GENERATION",
          "name": "9187_tpusg_gen_attempt#3",
          "startTime": "2025-08-03T20:28:11.711000+00:00",
          "endTime": "2025-08-03T20:28:43.496000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 31785.0,
          "environment": "default",
          "totalTokens": 3159,
          "costDetails": {},
          "completionTokens": 1111,
          "promptTokens": 2048,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-23-28-51-528170_chatcmpl-496d344a-d7e5-42f9-9f00-e6a9bcdd527d",
          "traceId": "9187f281",
          "type": "GENERATION",
          "name": "9187_tpusg_gen_attempt#4",
          "startTime": "2025-08-03T20:28:51.528000+00:00",
          "endTime": "2025-08-03T20:29:25.024000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 33496.0,
          "environment": "default",
          "totalTokens": 3224,
          "costDetails": {},
          "completionTokens": 1176,
          "promptTokens": 2048,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-23-29-33-105883_chatcmpl-d44da67f-95b7-4f24-a69a-9ee02daa237f",
          "traceId": "9187f281",
          "type": "GENERATION",
          "name": "9187_tpusg_gen_attempt#5",
          "startTime": "2025-08-03T20:29:33.105000+00:00",
          "endTime": "2025-08-03T20:30:05.979000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 32874.0,
          "environment": "default",
          "totalTokens": 3200,
          "costDetails": {},
          "completionTokens": 1152,
          "promptTokens": 2048,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "b5996bcc-41c4-42e2-9ffa-2ba8fba657f5",
          "traceId": "9187f281",
          "type": "SPAN",
          "name": "error_91_tpusg_failure_signal_tpu_sketch_generator",
          "startTime": "2025-08-03T20:30:14.204000+00:00",
          "level": "ERROR",
          "statusMessage": "Failed. Last error: Traceback (most recent call last):\n  File \"script_f07cbbf9_1754253005.py\", line 66, in <module>\n    num_detections = int(interpreter.get_tensor(output_details[1]['index'])[0])  # Access the first element of the array\nTypeError: only size-1 arrays can be converted to Python scalars",
          "calculatedTotalCost": 0.0,
          "environment": "default",
          "totalTokens": 0,
          "costDetails": {},
          "completionTokens": 0,
          "promptTokens": 0,
          "endTime": null,
          "model": null,
          "modelParameters": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null,
          "latency": null
        }
      ],
      "createdAt": "2025-08-03T20:26:59.147Z",
      "environment": "default",
      "updatedAt": "2025-08-03T20:30:19.332Z"
    },
    {
      "id": "31f7a5fb",
      "timestamp": "2025-08-03T20:23:45.572000+00:00",
      "name": "31f7_tpu_sketch_generator",
      "input": null,
      "output": {
        "status": "failed",
        "last_code": "num_detections = int(interpreter.get_tensor(output_details[1]['index'])[0])",
        "last_error": "Unexpected error during generation: Generated script is not complete. Please ensure to generate a complete Python script."
      },
      "session_id": "qwen2.5-coder:32b_373e_tpusg_batch",
      "metadata": {
        "num_run": 29
      },
      "tags": [
        "benchmark",
        "qwen2.5-coder:32b",
        "tpu_sketch_generator"
      ],
      "latency": 185.8,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-23-23-45-574143_chatcmpl-26d140c2-1b08-4521-b5f1-1fe5247382fd",
          "traceId": "31f7a5fb",
          "type": "GENERATION",
          "name": "31f7_tpusg_gen_attempt#1",
          "startTime": "2025-08-03T20:23:45.574000+00:00",
          "endTime": "2025-08-03T20:24:11.010000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 25436.0,
          "environment": "default",
          "totalTokens": 2709,
          "costDetails": {},
          "completionTokens": 876,
          "promptTokens": 1833,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-23-24-19-358208_chatcmpl-126ffec6-9b8e-459e-a0da-c49903f65010",
          "traceId": "31f7a5fb",
          "type": "GENERATION",
          "name": "31f7_tpusg_gen_attempt#2",
          "startTime": "2025-08-03T20:24:19.358000+00:00",
          "endTime": "2025-08-03T20:24:51.869000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 32511.0,
          "environment": "default",
          "totalTokens": 3186,
          "costDetails": {},
          "completionTokens": 1138,
          "promptTokens": 2048,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-23-25-00-004255_chatcmpl-66e7d883-bdf1-4245-a181-a53b33631a62",
          "traceId": "31f7a5fb",
          "type": "GENERATION",
          "name": "31f7_tpusg_gen_attempt#3",
          "startTime": "2025-08-03T20:25:00.004000+00:00",
          "endTime": "2025-08-03T20:25:32.607000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 32603.0,
          "environment": "default",
          "totalTokens": 3190,
          "costDetails": {},
          "completionTokens": 1142,
          "promptTokens": 2048,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-23-25-40-700740_chatcmpl-633b8a94-3847-4b28-a14b-6901994aeb89",
          "traceId": "31f7a5fb",
          "type": "GENERATION",
          "name": "31f7_tpusg_gen_attempt#4",
          "startTime": "2025-08-03T20:25:40.700000+00:00",
          "endTime": "2025-08-03T20:26:11.221000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 30521.0,
          "environment": "default",
          "totalTokens": 3110,
          "costDetails": {},
          "completionTokens": 1062,
          "promptTokens": 2048,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-23-26-19-543557_chatcmpl-7304fed8-dd56-4dc9-8e75-05f7ff5d5be6",
          "traceId": "31f7a5fb",
          "type": "GENERATION",
          "name": "31f7_tpusg_gen_attempt#5",
          "startTime": "2025-08-03T20:26:19.543000+00:00",
          "endTime": "2025-08-03T20:26:51.365000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 31822.0,
          "environment": "default",
          "totalTokens": 3159,
          "costDetails": {},
          "completionTokens": 1111,
          "promptTokens": 2048,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "1ca6eab5-cbc6-41ba-8cc8-3d9901fc821f",
          "traceId": "31f7a5fb",
          "type": "SPAN",
          "name": "error_31_tpusg_failure_signal_tpu_sketch_generator",
          "startTime": "2025-08-03T20:26:51.374000+00:00",
          "level": "ERROR",
          "statusMessage": "Failed. Last error: Unexpected error during generation: Generated script is not complete. Please ensure to generate a complete Python script.",
          "calculatedTotalCost": 0.0,
          "environment": "default",
          "totalTokens": 0,
          "costDetails": {},
          "completionTokens": 0,
          "promptTokens": 0,
          "endTime": null,
          "model": null,
          "modelParameters": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null,
          "latency": null
        }
      ],
      "createdAt": "2025-08-03T20:23:46.097Z",
      "environment": "default",
      "updatedAt": "2025-08-03T20:26:57.074Z"
    },
    {
      "id": "eaad5bed",
      "timestamp": "2025-08-03T20:20:23.856000+00:00",
      "name": "eaad_tpu_sketch_generator",
      "input": null,
      "output": {
        "status": "failed",
        "last_code": "import numpy as np\nfrom tflite_runtime.interpreter import Interpreter, load_delegate\nimport cv2\n\n# Phase 1: Setup\nmodel_path  = \"/home/mendel/tinyml_autopilot/models/edgetpu_detect.tflite\"\nlabel_path  = \"/home/mendel/tinyml_autopilot/models/labelmap.txt\"\ninput_path  = \"/home/mendel/tinyml_autopilot/data//sheeps.mp4\"\noutput_path  = \"/home/mendel/tinyml_autopilot/results/sheeps_detections.mp4\"\nconfidence_threshold  = 0.5\n\n# Load labels\nwith open(label_path, 'r') as f:\n    labels = [line.strip() for line in f.readlines()]\n\n# Load Interpreter with EdgeTPU\ntry:\n    interpreter = Interpreter(model_path=model_path,\n                              experimental_delegates=[load_delegate('libedgetpu.so.1.0')])\nexcept Exception as e:\n    print(f\"Failed to load libedgetpu.so.1.0: {e}\")\n    try:\n        interpreter = Interpreter(model_path=model_path,\n                                  experimental_delegates=[load_delegate('/usr/lib/aarch64-linux-gnu/libedgetpu.so.1.0')])\n    except Exception as e:\n        print(f\"Failed to load /usr/lib/aarch64-linux-gnu/libedgetpu.so.1.0: {e}\")\n        raise\n\ninterpreter.allocate_tensors()\n\n# Get Model Details\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\n\nfloating_model = (input_details[0]['dtype'] == np.float32)\n\n# Phase 2: Input Acquisition & Preprocessing Loop\ncap = cv2.VideoCapture(input_path)\nif not cap.isOpened():\n    raise IOError(\"Cannot open video file\")\n\nframe_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\nframe_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\nfps = cap.get(cv2.CAP_PROP_FPS)\n\nout = cv2.VideoWriter(output_path, cv2.VideoWriter_fourcc(*'mp4v'), fps, (frame_width, frame_height))\n\nwhile True:\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    # Preprocess Data\n    input_data = cv2.resize(frame, (input_details[0]['shape'][1], input_details[0]['shape'][2]))\n    input_data = np.expand_dims(input_data, axis=0)\n\n    if floating_model:\n        input_data = (np.float32(input_data) - 127.5) / 127.5\n\n    # Phase 3: Inference\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n    interpreter.invoke()\n\n    # Phase 4: Output Interpretation & Handling Loop\n    output_data = interpreter.get_tensor(output_details[0]['index'])\n    num_detections = int(interpreter.get_tensor(output_details[1]['index'])[0])  # Access the scalar value directly from the array\n    detection_boxes = interpreter.get_tensor(output_details[2]['index'])[0]\n    detection_classes = interpreter.get_tensor(output_details[3]['index'])[0].astype(int)\n    detection_scores = interpreter.get_tensor(output_details[4]['index'])[0]\n\n    for i in range(num_detections):\n        if detection_scores[i] > confidence_threshold:\n            box = detection_boxes[i]\n            class_id = detection_classes[i]\n            score = detection_scores[i]\n\n            # Scale the bounding box coordinates\n            ymin, xmin, ymax, xmax = box\n            (left, right, top, bottom) = (xmin * frame_width, xmax * frame_width,\n                                          ymin * frame_height, ymax * frame_height)\n\n            # Draw the bounding box and label on the frame\n            cv2.rectangle(frame, (int(left), int(top)), (int(right), int(bottom)), (0, 255, 0), 2)\n            label = f'{labels[class_id]}: {score:.2f}'\n            cv2.putText(frame, label, (int(left), int(top) - 10),\n                        cv2.FONT_HERSHEY_SIMPLEX, 0.9, (36, 255, 12), 2)\n\n    # Write the frame to the output video\n    out.write(frame)\n\n# Release resources\ncap.release()\nout.release()\ncv2.destroyAllWindows()",
        "last_error": "Traceback (most recent call last):\n  File \"script_0b9df397_1754252611.py\", line 66, in <module>\n    num_detections = int(interpreter.get_tensor(output_details[1]['index'])[0])  # Access the scalar value directly from the array\nTypeError: only size-1 arrays can be converted to Python scalars"
      },
      "session_id": "qwen2.5-coder:32b_373e_tpusg_batch",
      "metadata": {
        "num_run": 28
      },
      "tags": [
        "benchmark",
        "qwen2.5-coder:32b",
        "tpu_sketch_generator"
      ],
      "latency": 195.822,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-23-20-23-858365_chatcmpl-2798285a-6d59-4e96-b189-47392bcaf1c2",
          "traceId": "eaad5bed",
          "type": "GENERATION",
          "name": "eaad_tpusg_gen_attempt#1",
          "startTime": "2025-08-03T20:20:23.858000+00:00",
          "endTime": "2025-08-03T20:20:49.991000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 26133.0,
          "environment": "default",
          "totalTokens": 2726,
          "costDetails": {},
          "completionTokens": 893,
          "promptTokens": 1833,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-23-20-58-099929_chatcmpl-c78d0039-0894-43c9-bc06-8a5554b47d6c",
          "traceId": "eaad5bed",
          "type": "GENERATION",
          "name": "eaad_tpusg_gen_attempt#2",
          "startTime": "2025-08-03T20:20:58.099000+00:00",
          "endTime": "2025-08-03T20:21:30.776000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 32677.0,
          "environment": "default",
          "totalTokens": 3192,
          "costDetails": {},
          "completionTokens": 1144,
          "promptTokens": 2048,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-23-21-38-827194_chatcmpl-3be64ee8-48c0-445d-a1d0-8615e490eaa9",
          "traceId": "eaad5bed",
          "type": "GENERATION",
          "name": "eaad_tpusg_gen_attempt#3",
          "startTime": "2025-08-03T20:21:38.827000+00:00",
          "endTime": "2025-08-03T20:22:12.187000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 33360.0,
          "environment": "default",
          "totalTokens": 3218,
          "costDetails": {},
          "completionTokens": 1170,
          "promptTokens": 2048,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-23-22-20-579458_chatcmpl-266c7232-bf1f-433f-8a53-898fa531efba",
          "traceId": "eaad5bed",
          "type": "GENERATION",
          "name": "eaad_tpusg_gen_attempt#4",
          "startTime": "2025-08-03T20:22:20.579000+00:00",
          "endTime": "2025-08-03T20:22:51.423000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 30844.0,
          "environment": "default",
          "totalTokens": 3122,
          "costDetails": {},
          "completionTokens": 1074,
          "promptTokens": 2048,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-23-22-59-524576_chatcmpl-bb1f5bf8-72ae-476d-92dd-817f9a773f50",
          "traceId": "eaad5bed",
          "type": "GENERATION",
          "name": "eaad_tpusg_gen_attempt#5",
          "startTime": "2025-08-03T20:22:59.524000+00:00",
          "endTime": "2025-08-03T20:23:31.558000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 32034.0,
          "environment": "default",
          "totalTokens": 3168,
          "costDetails": {},
          "completionTokens": 1120,
          "promptTokens": 2048,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "48fb2a05-ec8c-4b9b-9326-2f10cbd11bcc",
          "traceId": "eaad5bed",
          "type": "SPAN",
          "name": "error_ea_tpusg_failure_signal_tpu_sketch_generator",
          "startTime": "2025-08-03T20:23:39.680000+00:00",
          "level": "ERROR",
          "statusMessage": "Failed. Last error: Traceback (most recent call last):\n  File \"script_0b9df397_1754252611.py\", line 66, in <module>\n    num_detections = int(interpreter.get_tensor(output_details[1]['index'])[0])  # Access the scalar value directly from the array\nTypeError: only size-1 arrays can be converted to Python scalars",
          "calculatedTotalCost": 0.0,
          "environment": "default",
          "totalTokens": 0,
          "costDetails": {},
          "completionTokens": 0,
          "promptTokens": 0,
          "endTime": null,
          "model": null,
          "modelParameters": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null,
          "latency": null
        }
      ],
      "createdAt": "2025-08-03T20:20:24.381Z",
      "environment": "default",
      "updatedAt": "2025-08-03T20:23:45.163Z"
    },
    {
      "id": "07423739",
      "timestamp": "2025-08-03T20:17:03.255000+00:00",
      "name": "0742_tpu_sketch_generator",
      "input": null,
      "output": {
        "status": "failed",
        "last_code": "import numpy as np\nfrom tflite_runtime.interpreter import Interpreter, load_delegate\n\n# Phase 1: Setup\nmodel_path  = \"/home/mendel/tinyml_autopilot/models/edgetpu_detect.tflite\"\nlabel_path  = \"/home/mendel/tinyml_autopilot/models/labelmap.txt\"\ninput_path  = \"/home/mendel/tinyml_autopilot/data//sheeps.mp4\"\noutput_path  = \"/home/mendel/tinyml_autopilot/results/sheeps_detections.mp4\"\nconfidence_threshold  = 0.5\n\n# Load labels\nwith open(label_path, 'r') as f:\n    labels = [line.strip() for line in f.readlines()]\n\n# Load Interpreter with EdgeTPU\ntry:\n    interpreter = Interpreter(model_path=model_path,\n                              experimental_delegates=[load_delegate('libedgetpu.so.1.0')])\nexcept Exception as e:\n    print(f\"Failed to load libedgetpu.so.1.0: {e}\")\n    try:\n        interpreter = Interpreter(model_path=model_path,\n                                  experimental_delegates=[load_delegate('/usr/lib/aarch64-linux-gnu/libedgetpu.so.1.0')])\n    except Exception as e:\n        print(f\"Failed to load /usr/lib/aarch64-linux-gnu/libedgetpu.so.1.0: {e}\")\n        raise\n\ninterpreter.allocate_tensors()\n\n# Get Model Details\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\n\nfloating_model = (input_details[0]['dtype'] == np.float32)\n\n# Phase 2: Input Acquisition & Preprocessing Loop\nimport cv2\n\ncap = cv2.VideoCapture(input_path)\nif not cap.isOpened():\n    raise IOError(\"Cannot open video file\")\n\nframe_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\nframe_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\nfps = cap.get(cv2.CAP_PROP_FPS)\n\nout = cv2.VideoWriter(output_path, cv2.VideoWriter_fourcc(*'mp4v'), fps, (frame_width, frame_height))\n\nwhile True:\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    # Preprocess Data\n    input_data = cv2.resize(frame, (input_details[0]['shape'][1], input_details[0]['shape'][2]))\n    input_data = np.expand_dims(input_data, axis=0)\n\n    if floating_model:\n        input_data = (np.float32(input_data) - 127.5) / 127.5\n\n    # Phase 3: Inference\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n    interpreter.invoke()\n\n    # Phase 4: Output Interpretation & Handling Loop\n    output_data = interpreter.get_tensor(output_details[0]['index'])\n    num_detections = int(interpreter.get_tensor(output_details[1]['index']).item())  # Correctly extract the scalar value\n    detection_boxes = interpreter.get_tensor(output_details[2]['index'])[0]\n    detection_classes = interpreter.get_tensor(output_details[3]['index'])[0].astype(int)\n    detection_scores = interpreter.get_tensor(output_details[4]['index'])[0]\n\n    for i in range(num_detections):\n        if detection_scores[i] > confidence_threshold:\n            box = detection_boxes[i]\n            class_id = detection_classes[i]\n            score = detection_scores[i]\n\n            # Scale and clip bounding boxes\n            ymin, xmin, ymax, xmax = box\n            (left, right, top, bottom) = (xmin * frame_width, xmax * frame_width,\n                                          ymin * frame_height, ymax * frame_height)\n\n            cv2.rectangle(frame, (int(left), int(top)), (int(right), int(bottom)), (0, 255, 0), 2)\n            label = f'{labels[class_id]}: {score:.2f}'\n            cv2.putText(frame, label, (int(left), int(top) - 10),\n                        cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n\n    # Write the frame to the output video\n    out.write(frame)\n\n# Phase 5: Cleanup\ncap.release()\nout.release()\ncv2.destroyAllWindows()",
        "last_error": "Traceback (most recent call last):\n  File \"script_f522efe4_1754252410.py\", line 67, in <module>\n    num_detections = int(interpreter.get_tensor(output_details[1]['index']).item())  # Correctly extract the scalar value\nValueError: can only convert an array of size 1 to a Python scalar"
      },
      "session_id": "qwen2.5-coder:32b_373e_tpusg_batch",
      "metadata": {
        "num_run": 27
      },
      "tags": [
        "benchmark",
        "qwen2.5-coder:32b",
        "tpu_sketch_generator"
      ],
      "latency": 195.016,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-23-17-03-257178_chatcmpl-c3045048-98ea-4046-87d6-15047174f750",
          "traceId": "07423739",
          "type": "GENERATION",
          "name": "0742_tpusg_gen_attempt#1",
          "startTime": "2025-08-03T20:17:03.257000+00:00",
          "endTime": "2025-08-03T20:17:28.886000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 25629.0,
          "environment": "default",
          "totalTokens": 2709,
          "costDetails": {},
          "completionTokens": 876,
          "promptTokens": 1833,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-23-17-36-976681_chatcmpl-a638bda9-a80a-44de-92da-0fe03db541ed",
          "traceId": "07423739",
          "type": "GENERATION",
          "name": "0742_tpusg_gen_attempt#2",
          "startTime": "2025-08-03T20:17:36.976000+00:00",
          "endTime": "2025-08-03T20:18:09.508000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 32532.0,
          "environment": "default",
          "totalTokens": 3187,
          "costDetails": {},
          "completionTokens": 1139,
          "promptTokens": 2048,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-23-18-17-768688_chatcmpl-06596f87-40c1-481d-9d2f-9356a3350e30",
          "traceId": "07423739",
          "type": "GENERATION",
          "name": "0742_tpusg_gen_attempt#3",
          "startTime": "2025-08-03T20:18:17.768000+00:00",
          "endTime": "2025-08-03T20:18:50.306000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 32538.0,
          "environment": "default",
          "totalTokens": 3186,
          "costDetails": {},
          "completionTokens": 1138,
          "promptTokens": 2048,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-23-18-58-412857_chatcmpl-c627b446-82cf-4daa-be8c-221f41030902",
          "traceId": "07423739",
          "type": "GENERATION",
          "name": "0742_tpusg_gen_attempt#4",
          "startTime": "2025-08-03T20:18:58.412000+00:00",
          "endTime": "2025-08-03T20:19:30.571000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 32159.0,
          "environment": "default",
          "totalTokens": 3172,
          "costDetails": {},
          "completionTokens": 1124,
          "promptTokens": 2048,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-23-19-38-626372_chatcmpl-ce4b24b0-0ee2-4e79-982a-dd690afc7053",
          "traceId": "07423739",
          "type": "GENERATION",
          "name": "0742_tpusg_gen_attempt#5",
          "startTime": "2025-08-03T20:19:38.626000+00:00",
          "endTime": "2025-08-03T20:20:10.053000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 31427.0,
          "environment": "default",
          "totalTokens": 3140,
          "costDetails": {},
          "completionTokens": 1092,
          "promptTokens": 2048,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "90a3e17d-9554-4106-a946-fd5a403ca793",
          "traceId": "07423739",
          "type": "SPAN",
          "name": "error_07_tpusg_failure_signal_tpu_sketch_generator",
          "startTime": "2025-08-03T20:20:18.273000+00:00",
          "level": "ERROR",
          "statusMessage": "Failed. Last error: Traceback (most recent call last):\n  File \"script_f522efe4_1754252410.py\", line 67, in <module>\n    num_detections = int(interpreter.get_tensor(output_details[1]['index']).item())  # Correctly extract the scalar value\nValueError: can only convert an array of size 1 to a Python scalar",
          "calculatedTotalCost": 0.0,
          "environment": "default",
          "totalTokens": 0,
          "costDetails": {},
          "completionTokens": 0,
          "promptTokens": 0,
          "endTime": null,
          "model": null,
          "modelParameters": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null,
          "latency": null
        }
      ],
      "createdAt": "2025-08-03T20:17:03.779Z",
      "environment": "default",
      "updatedAt": "2025-08-03T20:20:23.519Z"
    },
    {
      "id": "d959b910",
      "timestamp": "2025-08-03T20:13:40.528000+00:00",
      "name": "d959_tpu_sketch_generator",
      "input": null,
      "output": {
        "status": "failed",
        "last_code": "import numpy as np\nfrom tflite_runtime.interpreter import Interpreter, load_delegate\nimport cv2\n\n# Phase 1: Setup\nmodel_path  = \"/home/mendel/tinyml_autopilot/models/edgetpu_detect.tflite\"\nlabel_path  = \"/home/mendel/tinyml_autopilot/models/labelmap.txt\"\ninput_path  = \"/home/mendel/tinyml_autopilot/data//sheeps.mp4\"\noutput_path  = \"/home/mendel/tinyml_autopilot/results/sheeps_detections.mp4\"\nconfidence_threshold  = 0.5\n\n# Load labels\nwith open(label_path, 'r') as f:\n    labels = [line.strip() for line in f.readlines()]\n\n# Load Interpreter with EdgeTPU\ntry:\n    interpreter = Interpreter(model_path=model_path,\n                              experimental_delegates=[load_delegate('libedgetpu.so.1.0')])\nexcept Exception as e:\n    print(f\"Failed to load libedgetpu.so.1.0: {e}\")\n    try:\n        interpreter = Interpreter(model_path=model_path,\n                                  experimental_delegates=[load_delegate('/usr/lib/aarch64-linux-gnu/libedgetpu.so.1.0')])\n    except Exception as e:\n        print(f\"Failed to load /usr/lib/aarch64-linux-gnu/libedgetpu.so.1.0: {e}\")\n        raise\n\ninterpreter.allocate_tensors()\n\n# Get Model Details\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\n\nfloating_model = (input_details[0]['dtype'] == np.float32)\n\n# Phase 2: Input Acquisition & Preprocessing Loop\ncap = cv2.VideoCapture(input_path)\nif not cap.isOpened():\n    raise IOError(\"Cannot open video file\")\n\nframe_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\nframe_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\nfps = cap.get(cv2.CAP_PROP_FPS)\n\nout = cv2.VideoWriter(output_path, cv2.VideoWriter_fourcc(*'mp4v'), fps, (frame_width, frame_height))\n\nwhile True:\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    # Preprocess Data\n    input_data = cv2.resize(frame, (input_details[0]['shape'][1], input_details[0]['shape'][2]))\n    input_data = np.expand_dims(input_data, axis=0)\n\n    if floating_model:\n        input_data = (np.float32(input_data) - 127.5) / 127.5\n\n    # Phase 3: Inference\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n    interpreter.invoke()\n\n    # Phase 4: Output Interpretation & Handling Loop\n    output_data = interpreter.get_tensor(output_details[0]['index'])\n    \n    # Print the shapes of the output tensors for debugging\n    print(f\"Output Details:\")\n    for i, detail in enumerate(output_details):\n        print(f\"Tensor {i}: Shape={detail['shape']}, Type={detail['dtype']}\")\n\n    num_detections = interpreter.get_tensor(output_details[1]['index'])[0]  # Extract scalar value correctly\n    detection_boxes = interpreter.get_tensor(output_details[2]['index'])\n    detection_classes = interpreter.get_tensor(output_details[3]['index']).astype(int)\n    detection_scores = interpreter.get_tensor(output_details[4]['index'])\n\n    for i in range(num_detections):\n        if detection_scores[i] > confidence_threshold:\n            box = detection_boxes[i]\n            class_id = detection_classes[i]\n            score = detection_scores[i]\n\n            # Scale the bounding box coordinates\n            ymin, xmin, ymax, xmax = box\n            (left, right, top, bottom) = (xmin * frame_width, xmax * frame_width,\n                                          ymin * frame_height, ymax * frame_height)\n\n            # Draw the bounding box and label on the frame\n            cv2.rectangle(frame, (int(left), int(top)), (int(right), int(bottom)), (0, 255, 0), 2)\n            label = f'{labels[class_id]}: {score:.2f}'\n            cv2.putText(frame, label, (int(left), int(top) - 10),\n                        cv2.FONT_HERSHEY_SIMPLEX, 0.9, (36, 255, 12), 2)\n\n    # Write the frame to the output video\n    out.write(frame)\n\n# Release resources\ncap.release()\nout.release()\ncv2.destroyAllWindows()",
        "last_error": "Output Details:\nTensor 0: Shape=[ 1 10  4], Type=<class 'numpy.float32'>\nTensor 1: Shape=[ 1 10], Type=<class 'numpy.float32'>\nTensor 2: Shape=[ 1 10], Type=<class 'numpy.float32'>\nTensor 3: Shape=[1], Type=<class 'numpy.float32'>\nTraceback (most recent call last):\n  File \"script_104934af_1754252208.py\", line 75, in <module>\n    detection_scores = interpreter.get_tensor(output_details[4]['index'])\nIndexError: list index out of range"
      },
      "session_id": "qwen2.5-coder:32b_373e_tpusg_batch",
      "metadata": {
        "num_run": 26
      },
      "tags": [
        "benchmark",
        "qwen2.5-coder:32b",
        "tpu_sketch_generator"
      ],
      "latency": 196.495,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-23-13-40-529889_chatcmpl-292c7264-1d29-45a2-9150-ed52e462788b",
          "traceId": "d959b910",
          "type": "GENERATION",
          "name": "d959_tpusg_gen_attempt#1",
          "startTime": "2025-08-03T20:13:40.529000+00:00",
          "endTime": "2025-08-03T20:14:06.441000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 25912.0,
          "environment": "default",
          "totalTokens": 2726,
          "costDetails": {},
          "completionTokens": 893,
          "promptTokens": 1833,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-23-14-14-730593_chatcmpl-da30993f-b065-4e2d-917c-fda6b0be1e3b",
          "traceId": "d959b910",
          "type": "GENERATION",
          "name": "d959_tpusg_gen_attempt#2",
          "startTime": "2025-08-03T20:14:14.730000+00:00",
          "endTime": "2025-08-03T20:14:46.653000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 31923.0,
          "environment": "default",
          "totalTokens": 3164,
          "costDetails": {},
          "completionTokens": 1116,
          "promptTokens": 2048,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-23-14-54-814472_chatcmpl-8da6c197-231a-447f-b8d4-bed729135d9c",
          "traceId": "d959b910",
          "type": "GENERATION",
          "name": "d959_tpusg_gen_attempt#3",
          "startTime": "2025-08-03T20:14:54.814000+00:00",
          "endTime": "2025-08-03T20:15:29.563000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 34749.0,
          "environment": "default",
          "totalTokens": 3271,
          "costDetails": {},
          "completionTokens": 1223,
          "promptTokens": 2048,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-23-15-37-672439_chatcmpl-182bde2c-2ff7-4dc6-bd98-beee6c51d471",
          "traceId": "d959b910",
          "type": "GENERATION",
          "name": "d959_tpusg_gen_attempt#4",
          "startTime": "2025-08-03T20:15:37.672000+00:00",
          "endTime": "2025-08-03T20:16:08.920000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 31248.0,
          "environment": "default",
          "totalTokens": 3127,
          "costDetails": {},
          "completionTokens": 1079,
          "promptTokens": 2048,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-23-16-17-104252_chatcmpl-a3ea0862-7344-4525-84e9-8ed18383eb01",
          "traceId": "d959b910",
          "type": "GENERATION",
          "name": "d959_tpusg_gen_attempt#5",
          "startTime": "2025-08-03T20:16:17.104000+00:00",
          "endTime": "2025-08-03T20:16:48.958000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 31854.0,
          "environment": "default",
          "totalTokens": 3153,
          "costDetails": {},
          "completionTokens": 1105,
          "promptTokens": 2048,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "1a9e1957-bbcc-4e7d-9631-a00cf0f57a6d",
          "traceId": "d959b910",
          "type": "SPAN",
          "name": "error_d9_tpusg_failure_signal_tpu_sketch_generator",
          "startTime": "2025-08-03T20:16:57.024000+00:00",
          "level": "ERROR",
          "statusMessage": "Failed. Last error: Output Details:\nTensor 0: Shape=[ 1 10  4], Type=<class 'numpy.float32'>\nTensor 1: Shape=[ 1 10], Type=<class 'numpy.float32'>\nTensor 2: Shape=[ 1 10], Type=<class 'numpy.float32'>\nTensor 3: Shape=[1], Type=<class 'numpy.float32'>\nTraceback (most recent call last):\n  File \"script_104934af_1754252208.py\", line 75, in <module>\n    detection_scores = interpreter.get_tensor(output_details[4]['index'])\nIndexError: list index out of range",
          "calculatedTotalCost": 0.0,
          "environment": "default",
          "totalTokens": 0,
          "costDetails": {},
          "completionTokens": 0,
          "promptTokens": 0,
          "endTime": null,
          "model": null,
          "modelParameters": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null,
          "latency": null
        }
      ],
      "createdAt": "2025-08-03T20:13:41.052Z",
      "environment": "default",
      "updatedAt": "2025-08-03T20:17:02.279Z"
    },
    {
      "id": "102c2bea",
      "timestamp": "2025-08-03T20:09:37.910000+00:00",
      "name": "102c_tpu_sketch_generator",
      "input": null,
      "output": {
        "status": "success",
        "sketch": "import numpy as np\nfrom tflite_runtime.interpreter import Interpreter, load_delegate\n\n# Phase 1: Setup\nmodel_path  = \"/home/mendel/tinyml_autopilot/models/edgetpu_detect.tflite\"\nlabel_path  = \"/home/mendel/tinyml_autopilot/models/labelmap.txt\"\ninput_path  = \"/home/mendel/tinyml_autopilot/data//sheeps.mp4\"\noutput_path  = \"/home/mendel/tinyml_autopilot/results/sheeps_detections.mp4\"\nconfidence_threshold  = 0.5\n\n# Load labels\nwith open(label_path, 'r') as f:\n    labels = [line.strip() for line in f.readlines()]\n\n# Load Interpreter with EdgeTPU\ntry:\n    interpreter = Interpreter(model_path=model_path,\n                              experimental_delegates=[load_delegate('libedgetpu.so.1.0')])\nexcept Exception as e:\n    print(f\"Failed to load libedgetpu.so.1.0: {e}\")\n    try:\n        interpreter = Interpreter(model_path=model_path,\n                                  experimental_delegates=[load_delegate('/usr/lib/aarch64-linux-gnu/libedgetpu.so.1.0')])\n    except Exception as e:\n        print(f\"Failed to load /usr/lib/aarch64-linux-gnu/libedgetpu.so.1.0: {e}\")\n        raise\n\ninterpreter.allocate_tensors()\n\n# Get Model Details\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\n\nfloating_model = (input_details[0]['dtype'] == np.float32)\n\n# Phase 2: Input Acquisition & Preprocessing Loop\nimport cv2\n\ncap = cv2.VideoCapture(input_path)\nif not cap.isOpened():\n    raise IOError(\"Cannot open video file\")\n\nframe_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\nframe_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\nfps = cap.get(cv2.CAP_PROP_FPS)\n\nout = cv2.VideoWriter(output_path, cv2.VideoWriter_fourcc(*'mp4v'), fps, (frame_width, frame_height))\n\nwhile True:\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    # Preprocess Data\n    input_data = cv2.resize(frame, (input_details[0]['shape'][1], input_details[0]['shape'][2]))\n    input_data = np.expand_dims(input_data, axis=0)\n\n    if floating_model:\n        input_data = (np.float32(input_data) - 127.5) / 127.5\n\n    # Phase 3: Inference\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n    interpreter.invoke()\n\n    # Phase 4: Output Interpretation & Handling Loop\n    detection_boxes = interpreter.get_tensor(output_details[0]['index'])[0]\n    detection_classes = interpreter.get_tensor(output_details[1]['index'])[0].astype(int)\n    detection_scores = interpreter.get_tensor(output_details[2]['index'])[0]\n\n    num_detections = len(detection_scores)  # Assuming the number of detections is the length of scores\n\n    for i in range(num_detections):\n        if detection_scores[i] > confidence_threshold:\n            box = detection_boxes[i]\n            class_id = detection_classes[i]\n            score = detection_scores[i]\n\n            # Scale and clip bounding boxes\n            ymin, xmin, ymax, xmax = box\n            (left, right, top, bottom) = (xmin * frame_width, xmax * frame_width,\n                                          ymin * frame_height, ymax * frame_height)\n\n            cv2.rectangle(frame, (int(left), int(top)), (int(right), int(bottom)), (0, 255, 0), 2)\n            label = f'{labels[class_id]}: {score:.2f}'\n            cv2.putText(frame, label, (int(left), int(top) - 10),\n                        cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n\n    # Handle Output\n    out.write(frame)\n\n# Phase 5: Cleanup\ncap.release()\nout.release()\ncv2.destroyAllWindows()"
      },
      "session_id": "qwen2.5-coder:32b_373e_tpusg_batch",
      "metadata": {
        "num_run": 25
      },
      "tags": [
        "benchmark",
        "qwen2.5-coder:32b",
        "tpu_sketch_generator"
      ],
      "latency": 185.082,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-23-09-37-911789_chatcmpl-ad16444e-92fb-4475-96c7-2c45559f8f8f",
          "traceId": "102c2bea",
          "type": "GENERATION",
          "name": "102c_tpusg_gen_attempt#1",
          "startTime": "2025-08-03T20:09:37.911000+00:00",
          "endTime": "2025-08-03T20:10:03.350000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 25439.0,
          "environment": "default",
          "totalTokens": 2709,
          "costDetails": {},
          "completionTokens": 876,
          "promptTokens": 1833,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-23-10-11-482143_chatcmpl-4f42b749-2535-4957-87d3-e31a14b90060",
          "traceId": "102c2bea",
          "type": "GENERATION",
          "name": "102c_tpusg_gen_attempt#2",
          "startTime": "2025-08-03T20:10:11.482000+00:00",
          "endTime": "2025-08-03T20:10:43.467000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 31985.0,
          "environment": "default",
          "totalTokens": 3166,
          "costDetails": {},
          "completionTokens": 1118,
          "promptTokens": 2048,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-23-10-51-549772_chatcmpl-bb9544b5-e568-4869-b5f7-ebddaa24058a",
          "traceId": "102c2bea",
          "type": "GENERATION",
          "name": "102c_tpusg_gen_attempt#3",
          "startTime": "2025-08-03T20:10:51.549000+00:00",
          "endTime": "2025-08-03T20:11:24.405000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 32856.0,
          "environment": "default",
          "totalTokens": 3199,
          "costDetails": {},
          "completionTokens": 1151,
          "promptTokens": 2048,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-23-11-32-588545_chatcmpl-f90c5616-bde4-4d17-b96e-7893fdd6e89e",
          "traceId": "102c2bea",
          "type": "GENERATION",
          "name": "102c_tpusg_gen_attempt#4",
          "startTime": "2025-08-03T20:11:32.588000+00:00",
          "endTime": "2025-08-03T20:12:03.788000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 31200.0,
          "environment": "default",
          "totalTokens": 3136,
          "costDetails": {},
          "completionTokens": 1088,
          "promptTokens": 2048,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-23-12-11-916482_chatcmpl-b5629ac5-e8aa-4f31-91ce-86686a59a056",
          "traceId": "102c2bea",
          "type": "GENERATION",
          "name": "102c_tpusg_gen_attempt#5",
          "startTime": "2025-08-03T20:12:11.916000+00:00",
          "endTime": "2025-08-03T20:12:42.993000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 31077.0,
          "environment": "default",
          "totalTokens": 3131,
          "costDetails": {},
          "completionTokens": 1083,
          "promptTokens": 2048,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        }
      ],
      "createdAt": "2025-08-03T20:09:38.435Z",
      "environment": "default",
      "updatedAt": "2025-08-03T20:13:40.730Z"
    },
    {
      "id": "4a32a6aa",
      "timestamp": "2025-08-03T20:06:19.660000+00:00",
      "name": "4a32_tpu_sketch_generator",
      "input": null,
      "output": {
        "status": "failed",
        "last_code": "import numpy as np\nfrom tflite_runtime.interpreter import Interpreter, load_delegate\nimport cv2\n\n# Phase 1: Setup\nmodel_path  = \"/home/mendel/tinyml_autopilot/models/edgetpu_detect.tflite\"\nlabel_path  = \"/home/mendel/tinyml_autopilot/models/labelmap.txt\"\ninput_path  = \"/home/mendel/tinyml_autopilot/data//sheeps.mp4\"\noutput_path  = \"/home/mendel/tinyml_autopilot/results/sheeps_detections.mp4\"\nconfidence_threshold  = 0.5\n\n# Load labels\nwith open(label_path, 'r') as f:\n    labels = [line.strip() for line in f.readlines()]\n\n# Load Interpreter with EdgeTPU\ntry:\n    interpreter = Interpreter(model_path=model_path,\n                              experimental_delegates=[load_delegate('libedgetpu.so.1.0')])\nexcept Exception as e:\n    print(f\"Failed to load libedgetpu.so.1.0: {e}\")\n    try:\n        interpreter = Interpreter(model_path=model_path,\n                                  experimental_delegates=[load_delegate('/usr/lib/aarch64-linux-gnu/libedgetpu.so.1.0')])\n    except Exception as e:\n        print(f\"Failed to load /usr/lib/aarch64-linux-gnu/libedgetpu.so.1.0: {e}\")\n        raise\n\ninterpreter.allocate_tensors()\n\n# Get Model Details\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\n\nfloating_model = (input_details[0]['dtype'] == np.float32)\n\n# Phase 2: Input Acquisition & Preprocessing Loop\ncap = cv2.VideoCapture(input_path)\nif not cap.isOpened():\n    raise IOError(\"Cannot open video file\")\n\nframe_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\nframe_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\nfps = cap.get(cv2.CAP_PROP_FPS)\n\nout = cv2.VideoWriter(output_path, cv2.VideoWriter_fourcc(*'mp4v'), fps, (frame_width, frame_height))\n\nwhile True:\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    # Preprocess Data\n    input_data = cv2.resize(frame, (input_details[0]['shape'][1], input_details[0]['shape'][2]))\n    input_data = np.expand_dims(input_data, axis=0)\n\n    if floating_model:\n        input_data = (np.float32(input_data) - 127.5) / 127.5\n\n    # Phase 3: Inference\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n    interpreter.invoke()\n\n    # Phase 4: Output Interpretation & Handling Loop\n    output_data = interpreter.get_tensor(output_details[0]['index'])\n    detection_boxes = interpreter.get_tensor(output_details[1]['index'])[0]\n    detection_classes = interpreter.get_tensor(output_details[2]['index'])[0].astype(int)\n    detection_scores = interpreter.get_tensor(output_details[3]['index'])[0]\n\n    # Determine the number of detections based on scores\n    num_detections = np.count_nonzero(detection_scores > confidence_threshold)\n\n    for i in range(num_detections):\n        if detection_scores[i] > confidence_threshold:\n            box = detection_boxes[i]\n            class_id = detection_classes[i]\n            score = detection_scores[i]\n\n            # Scale and clip bounding boxes\n            ymin, xmin, ymax, xmax = box\n            (left, right, top, bottom) = (xmin * frame_width, xmax * frame_width,\n                                          ymin * frame_height, ymax * frame_height)\n\n            cv2.rectangle(frame, (int(left), int(top)), (int(right), int(bottom)), (0, 255, 0), 2)\n            label = f'{labels[class_id]}: {score:.2f}'\n            cv2.putText(frame, label, (int(left), int(top) - 10),\n                        cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n\n    # Write the frame to the output video\n    out.write(frame)\n\n# Release resources\ncap.release()\nout.release()\ncv2.destroyAllWindows()",
        "last_error": "Traceback (most recent call last):\n  File \"script_671e8562_1754251763.py\", line 74, in <module>\n    if detection_scores[i] > confidence_threshold:\nIndexError: invalid index to scalar variable."
      },
      "session_id": "qwen2.5-coder:32b_373e_tpusg_batch",
      "metadata": {
        "num_run": 24
      },
      "tags": [
        "benchmark",
        "qwen2.5-coder:32b",
        "tpu_sketch_generator"
      ],
      "latency": 191.765,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-23-06-19-661101_chatcmpl-7ede116e-be16-42fd-b344-1d40aa793701",
          "traceId": "4a32a6aa",
          "type": "GENERATION",
          "name": "4a32_tpusg_gen_attempt#1",
          "startTime": "2025-08-03T20:06:19.661000+00:00",
          "endTime": "2025-08-03T20:06:45.104000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 25443.0,
          "environment": "default",
          "totalTokens": 2709,
          "costDetails": {},
          "completionTokens": 876,
          "promptTokens": 1833,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-23-06-53-213728_chatcmpl-b7dd99cc-afdb-4eca-b5bc-df6ab6b62165",
          "traceId": "4a32a6aa",
          "type": "GENERATION",
          "name": "4a32_tpusg_gen_attempt#2",
          "startTime": "2025-08-03T20:06:53.213000+00:00",
          "endTime": "2025-08-03T20:07:25.706000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 32493.0,
          "environment": "default",
          "totalTokens": 3186,
          "costDetails": {},
          "completionTokens": 1138,
          "promptTokens": 2048,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-23-07-33-760155_chatcmpl-c318fe77-b85e-48c8-9994-019fa2d43239",
          "traceId": "4a32a6aa",
          "type": "GENERATION",
          "name": "4a32_tpusg_gen_attempt#3",
          "startTime": "2025-08-03T20:07:33.760000+00:00",
          "endTime": "2025-08-03T20:08:04.300000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 30540.0,
          "environment": "default",
          "totalTokens": 3110,
          "costDetails": {},
          "completionTokens": 1062,
          "promptTokens": 2048,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-23-08-12-368290_chatcmpl-28d33d20-6357-4326-8f66-42195ded40c4",
          "traceId": "4a32a6aa",
          "type": "GENERATION",
          "name": "4a32_tpusg_gen_attempt#4",
          "startTime": "2025-08-03T20:08:12.368000+00:00",
          "endTime": "2025-08-03T20:08:43.434000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 31066.0,
          "environment": "default",
          "totalTokens": 3129,
          "costDetails": {},
          "completionTokens": 1081,
          "promptTokens": 2048,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-23-08-51-516792_chatcmpl-2ea16356-1453-4142-97b3-06910d6a6f72",
          "traceId": "4a32a6aa",
          "type": "GENERATION",
          "name": "4a32_tpusg_gen_attempt#5",
          "startTime": "2025-08-03T20:08:51.516000+00:00",
          "endTime": "2025-08-03T20:09:23.314000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 31798.0,
          "environment": "default",
          "totalTokens": 3157,
          "costDetails": {},
          "completionTokens": 1109,
          "promptTokens": 2048,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "7054d662-6b0d-44a9-a4ae-b5a5520d459f",
          "traceId": "4a32a6aa",
          "type": "SPAN",
          "name": "error_4a_tpusg_failure_signal_tpu_sketch_generator",
          "startTime": "2025-08-03T20:09:31.426000+00:00",
          "level": "ERROR",
          "statusMessage": "Failed. Last error: Traceback (most recent call last):\n  File \"script_671e8562_1754251763.py\", line 74, in <module>\n    if detection_scores[i] > confidence_threshold:\nIndexError: invalid index to scalar variable.",
          "calculatedTotalCost": 0.0,
          "environment": "default",
          "totalTokens": 0,
          "costDetails": {},
          "completionTokens": 0,
          "promptTokens": 0,
          "endTime": null,
          "model": null,
          "modelParameters": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null,
          "latency": null
        }
      ],
      "createdAt": "2025-08-03T20:06:20.182Z",
      "environment": "default",
      "updatedAt": "2025-08-03T20:09:36.949Z"
    },
    {
      "id": "7b37072a",
      "timestamp": "2025-08-03T20:03:00.128000+00:00",
      "name": "7b37_tpu_sketch_generator",
      "input": null,
      "output": {
        "status": "failed",
        "last_code": "import numpy as np\nfrom tflite_runtime.interpreter import Interpreter, load_delegate\nimport cv2\n\n# Phase 1: Setup\nmodel_path  = \"/home/mendel/tinyml_autopilot/models/edgetpu_detect.tflite\"\nlabel_path  = \"/home/mendel/tinyml_autopilot/models/labelmap.txt\"\ninput_path  = \"/home/mendel/tinyml_autopilot/data//sheeps.mp4\"\noutput_path  = \"/home/mendel/tinyml_autopilot/results/sheeps_detections.mp4\"\nconfidence_threshold  = 0.5\n\n# Load labels\nwith open(label_path, 'r') as f:\n    labels = [line.strip() for line in f.readlines()]\n\n# Load Interpreter with EdgeTPU\ntry:\n    interpreter = Interpreter(model_path=model_path,\n                              experimental_delegates=[load_delegate('libedgetpu.so.1.0')])\nexcept Exception as e:\n    print(f\"Failed to load libedgetpu.so.1.0: {e}\")\n    try:\n        interpreter = Interpreter(model_path=model_path,\n                                  experimental_delegates=[load_delegate('/usr/lib/aarch64-linux-gnu/libedgetpu.so.1.0')])\n    except Exception as e:\n        print(f\"Failed to load /usr/lib/aarch64-linux-gnu/libedgetpu.so.1.0: {e}\")\n        raise\n\ninterpreter.allocate_tensors()\n\n# Get Model Details\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\n\nfloating_model = (input_details[0]['dtype'] == np.float32)\n\n# Phase 2: Input Acquisition & Preprocessing Loop\ncap = cv2.VideoCapture(input_path)\nif not cap.isOpened():\n    raise IOError(\"Cannot open video file\")\n\nframe_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\nframe_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\nfps = cap.get(cv2.CAP_PROP_FPS)\n\nout = cv2.VideoWriter(output_path, cv2.VideoWriter_fourcc(*'mp4v'), fps, (frame_width, frame_height))\n\nwhile True:\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    # Preprocess Data\n    input_data = cv2.resize(frame, (input_details[0]['shape'][1], input_details[0]['shape'][2]))\n    input_data = np.expand_dims(input_data, axis=0)\n\n    if floating_model:\n        input_data = (np.float32(input_data) - 127.5) / 127.5\n\n    # Phase 3: Inference\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n    interpreter.invoke()\n\n    # Phase 4: Output Interpretation & Handling Loop\n    output_data = interpreter.get_tensor(output_details[0]['index'])\n    num_detections = int(interpreter.get_tensor(output_details[1]['index'])[0])  # Access the first element of the array\n    detection_boxes = interpreter.get_tensor(output_details[2]['index'])[0]\n    detection_classes = interpreter.get_tensor(output_details[3]['index'])[0].astype(int)\n    detection_scores = interpreter.get_tensor(output_details[4]['index'])[0]\n\n    for i in range(num_detections):\n        if detection_scores[i] > confidence_threshold:\n            box = detection_boxes[i]\n            class_id = detection_classes[i]\n            score = detection_scores[i]\n\n            # Scale and clip bounding boxes\n            ymin, xmin, ymax, xmax = box\n            (left, right, top, bottom) = (xmin * frame_width, xmax * frame_width,\n                                          ymin * frame_height, ymax * frame_height)\n\n            cv2.rectangle(frame, (int(left), int(top)), (int(right), int(bottom)), (0, 255, 0), 2)\n            label = f'{labels[class_id]}: {score:.2f}'\n            cv2.putText(frame, label, (int(left), int(top) - 10),\n                        cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n\n    # Handle Output\n    out.write(frame)\n\n# Phase 5: Cleanup\ncap.release()\nout.release()\ncv2.destroyAllWindows()",
        "last_error": "Traceback (most recent call last):\n  File \"script_8e2e07b4_1754251565.py\", line 66, in <module>\n    num_detections = int(interpreter.get_tensor(output_details[1]['index'])[0])  # Access the first element of the array\nTypeError: only size-1 arrays can be converted to Python scalars"
      },
      "session_id": "qwen2.5-coder:32b_373e_tpusg_batch",
      "metadata": {
        "num_run": 23
      },
      "tags": [
        "benchmark",
        "qwen2.5-coder:32b",
        "tpu_sketch_generator"
      ],
      "latency": 193.618,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-23-03-00-130147_chatcmpl-69d4a8e4-e3f6-4c55-ad12-86dfdda90db8",
          "traceId": "7b37072a",
          "type": "GENERATION",
          "name": "7b37_tpusg_gen_attempt#1",
          "startTime": "2025-08-03T20:03:00.130000+00:00",
          "endTime": "2025-08-03T20:03:25.702000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 25572.0,
          "environment": "default",
          "totalTokens": 2709,
          "costDetails": {},
          "completionTokens": 876,
          "promptTokens": 1833,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-23-03-33-802431_chatcmpl-fa1857cf-01c6-45de-ad47-6d4429866dd2",
          "traceId": "7b37072a",
          "type": "GENERATION",
          "name": "7b37_tpusg_gen_attempt#2",
          "startTime": "2025-08-03T20:03:33.802000+00:00",
          "endTime": "2025-08-03T20:04:06.441000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 32639.0,
          "environment": "default",
          "totalTokens": 3189,
          "costDetails": {},
          "completionTokens": 1141,
          "promptTokens": 2048,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-23-04-14-728847_chatcmpl-dea78060-0249-4222-8716-fd2514396f16",
          "traceId": "7b37072a",
          "type": "GENERATION",
          "name": "7b37_tpusg_gen_attempt#3",
          "startTime": "2025-08-03T20:04:14.728000+00:00",
          "endTime": "2025-08-03T20:04:46.209000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 31481.0,
          "environment": "default",
          "totalTokens": 3144,
          "costDetails": {},
          "completionTokens": 1096,
          "promptTokens": 2048,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-23-04-54-279687_chatcmpl-6b81d09a-814b-4038-ad16-aa6283c33dfc",
          "traceId": "7b37072a",
          "type": "GENERATION",
          "name": "7b37_tpusg_gen_attempt#4",
          "startTime": "2025-08-03T20:04:54.279000+00:00",
          "endTime": "2025-08-03T20:05:24.287000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 30008.0,
          "environment": "default",
          "totalTokens": 3090,
          "costDetails": {},
          "completionTokens": 1042,
          "promptTokens": 2048,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-23-05-32-330344_chatcmpl-67261d54-96b8-4476-bfa1-197c672c1961",
          "traceId": "7b37072a",
          "type": "GENERATION",
          "name": "7b37_tpusg_gen_attempt#5",
          "startTime": "2025-08-03T20:05:32.330000+00:00",
          "endTime": "2025-08-03T20:06:05.587000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 33257.0,
          "environment": "default",
          "totalTokens": 3214,
          "costDetails": {},
          "completionTokens": 1166,
          "promptTokens": 2048,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "9635267c-bf14-42c8-b351-f1ce5793dc5b",
          "traceId": "7b37072a",
          "type": "SPAN",
          "name": "error_7b_tpusg_failure_signal_tpu_sketch_generator",
          "startTime": "2025-08-03T20:06:13.748000+00:00",
          "level": "ERROR",
          "statusMessage": "Failed. Last error: Traceback (most recent call last):\n  File \"script_8e2e07b4_1754251565.py\", line 66, in <module>\n    num_detections = int(interpreter.get_tensor(output_details[1]['index'])[0])  # Access the first element of the array\nTypeError: only size-1 arrays can be converted to Python scalars",
          "calculatedTotalCost": 0.0,
          "environment": "default",
          "totalTokens": 0,
          "costDetails": {},
          "completionTokens": 0,
          "promptTokens": 0,
          "endTime": null,
          "model": null,
          "modelParameters": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null,
          "latency": null
        }
      ],
      "createdAt": "2025-08-03T20:03:00.650Z",
      "environment": "default",
      "updatedAt": "2025-08-03T20:06:19.408Z"
    },
    {
      "id": "5f1f0f5a",
      "timestamp": "2025-08-03T19:59:38.172000+00:00",
      "name": "5f1f_tpu_sketch_generator",
      "input": null,
      "output": {
        "status": "failed",
        "last_code": "import numpy as np\nfrom tflite_runtime.interpreter import Interpreter, load_delegate\nimport cv2\n\n# Phase 1: Setup\nmodel_path  = \"/home/mendel/tinyml_autopilot/models/edgetpu_detect.tflite\"\nlabel_path  = \"/home/mendel/tinyml_autopilot/models/labelmap.txt\"\ninput_path  = \"/home/mendel/tinyml_autopilot/data//sheeps.mp4\"\noutput_path  = \"/home/mendel/tinyml_autopilot/results/sheeps_detections.mp4\"\nconfidence_threshold  = 0.5\n\n# Load labels\nwith open(label_path, 'r') as f:\n    labels = [line.strip() for line in f.readlines()]\n\n# Load Interpreter with EdgeTPU\ntry:\n    interpreter = Interpreter(model_path=model_path,\n                              experimental_delegates=[load_delegate('libedgetpu.so.1.0')])\nexcept Exception as e:\n    print(f\"Failed to load libedgetpu.so.1.0: {e}\")\n    try:\n        interpreter = Interpreter(model_path=model_path,\n                                  experimental_delegates=[load_delegate('/usr/lib/aarch64-linux-gnu/libedgetpu.so.1.0')])\n    except Exception as e:\n        print(f\"Failed to load /usr/lib/aarch64-linux-gnu/libedgetpu.so.1.0: {e}\")\n        raise\n\ninterpreter.allocate_tensors()\n\n# Get Model Details\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\n\nfloating_model = (input_details[0]['dtype'] == np.float32)\n\n# Phase 2: Input Acquisition & Preprocessing Loop\ncap = cv2.VideoCapture(input_path)\nif not cap.isOpened():\n    raise IOError(\"Cannot open video file\")\n\nframe_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\nframe_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\nfps = cap.get(cv2.CAP_PROP_FPS)\n\nout = cv2.VideoWriter(output_path, cv2.VideoWriter_fourcc(*'mp4v'), fps, (frame_width, frame_height))\n\nwhile True:\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    # Preprocess Data\n    input_data = cv2.resize(frame, (input_details[0]['shape'][1], input_details[0]['shape'][2]))\n    input_data = np.expand_dims(input_data, axis=0)\n\n    if floating_model:\n        input_data = (np.float32(input_data) - 127.5) / 127.5\n\n    # Phase 3: Inference\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n    interpreter.invoke()\n\n    # Phase 4: Output Interpretation & Handling Loop\n    num_detections = int(interpreter.get_tensor(output_details[0]['index'])[0])  # Correctly extract the scalar value from the array\n    detection_boxes = interpreter.get_tensor(output_details[1]['index'])[0]\n    detection_classes = interpreter.get_tensor(output_details[2]['index'])[0].astype(int)\n    detection_scores = interpreter.get_tensor(output_details[3]['index'])[0]\n\n    for i in range(num_detections):\n        if detection_scores[i] > confidence_threshold:\n            box = detection_boxes[i]\n            class_id = detection_classes[i]\n            score = detection_scores[i]\n\n            # Scale and clip bounding boxes\n            ymin, xmin, ymax, xmax = box\n            (left, right, top, bottom) = (xmin * frame_width, xmax * frame_width,\n                                          ymin * frame_height, ymax * frame_height)\n\n            cv2.rectangle(frame, (int(left), int(top)), (int(right), int(bottom)), (0, 255, 0), 2)\n            label = f'{labels[class_id]}: {score:.2f}'\n            cv2.putText(frame, label, (int(left), int(top) - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (36, 255, 12), 2)\n\n    out.write(frame)\n\n# Release resources\ncap.release()\nout.release()\ncv2.destroyAllWindows()",
        "last_error": "Traceback (most recent call last):\n  File \"script_1949bd80_1754251365.py\", line 65, in <module>\n    num_detections = int(interpreter.get_tensor(output_details[0]['index'])[0])  # Correctly extract the scalar value from the array\nTypeError: only size-1 arrays can be converted to Python scalars"
      },
      "session_id": "qwen2.5-coder:32b_373e_tpusg_batch",
      "metadata": {
        "num_run": 22
      },
      "tags": [
        "benchmark",
        "qwen2.5-coder:32b",
        "tpu_sketch_generator"
      ],
      "latency": 195.824,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-22-59-38-173525_chatcmpl-71dd8f4f-8004-4bf7-8a82-c315fdf7375e",
          "traceId": "5f1f0f5a",
          "type": "GENERATION",
          "name": "5f1f_tpusg_gen_attempt#1",
          "startTime": "2025-08-03T19:59:38.173000+00:00",
          "endTime": "2025-08-03T20:00:03.628000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 25455.0,
          "environment": "default",
          "totalTokens": 2709,
          "costDetails": {},
          "completionTokens": 876,
          "promptTokens": 1833,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-23-00-11-703507_chatcmpl-40e3e767-47d2-4a60-aa79-eaffc23f86c9",
          "traceId": "5f1f0f5a",
          "type": "GENERATION",
          "name": "5f1f_tpusg_gen_attempt#2",
          "startTime": "2025-08-03T20:00:11.703000+00:00",
          "endTime": "2025-08-03T20:00:44.790000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 33087.0,
          "environment": "default",
          "totalTokens": 3196,
          "costDetails": {},
          "completionTokens": 1148,
          "promptTokens": 2048,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-23-00-52-856771_chatcmpl-8a3fb662-8178-4aaf-8dfb-eba067149b9e",
          "traceId": "5f1f0f5a",
          "type": "GENERATION",
          "name": "5f1f_tpusg_gen_attempt#3",
          "startTime": "2025-08-03T20:00:52.856000+00:00",
          "endTime": "2025-08-03T20:01:25.831000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 32975.0,
          "environment": "default",
          "totalTokens": 3186,
          "costDetails": {},
          "completionTokens": 1138,
          "promptTokens": 2048,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-23-01-33-848140_chatcmpl-26ad9452-14af-4ee2-9865-a86daf61805f",
          "traceId": "5f1f0f5a",
          "type": "GENERATION",
          "name": "5f1f_tpusg_gen_attempt#4",
          "startTime": "2025-08-03T20:01:33.848000+00:00",
          "endTime": "2025-08-03T20:02:04.610000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 30762.0,
          "environment": "default",
          "totalTokens": 3104,
          "costDetails": {},
          "completionTokens": 1056,
          "promptTokens": 2048,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-23-02-12-771984_chatcmpl-39937ab9-c310-4cd5-b406-c34c316c6d4f",
          "traceId": "5f1f0f5a",
          "type": "GENERATION",
          "name": "5f1f_tpusg_gen_attempt#5",
          "startTime": "2025-08-03T20:02:12.771000+00:00",
          "endTime": "2025-08-03T20:02:45.715000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 32944.0,
          "environment": "default",
          "totalTokens": 3196,
          "costDetails": {},
          "completionTokens": 1148,
          "promptTokens": 2048,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "35ca2cd9-93ed-42d9-9e23-0f3a83bb61e8",
          "traceId": "5f1f0f5a",
          "type": "SPAN",
          "name": "error_5f_tpusg_failure_signal_tpu_sketch_generator",
          "startTime": "2025-08-03T20:02:53.997000+00:00",
          "level": "ERROR",
          "statusMessage": "Failed. Last error: Traceback (most recent call last):\n  File \"script_1949bd80_1754251365.py\", line 65, in <module>\n    num_detections = int(interpreter.get_tensor(output_details[0]['index'])[0])  # Correctly extract the scalar value from the array\nTypeError: only size-1 arrays can be converted to Python scalars",
          "calculatedTotalCost": 0.0,
          "environment": "default",
          "totalTokens": 0,
          "costDetails": {},
          "completionTokens": 0,
          "promptTokens": 0,
          "endTime": null,
          "model": null,
          "modelParameters": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null,
          "latency": null
        }
      ],
      "createdAt": "2025-08-03T19:59:38.696Z",
      "environment": "default",
      "updatedAt": "2025-08-03T20:02:59.464Z"
    },
    {
      "id": "c8f4f7fe",
      "timestamp": "2025-08-03T19:55:35.602000+00:00",
      "name": "c8f4_tpu_sketch_generator",
      "input": null,
      "output": {
        "status": "success",
        "sketch": "import numpy as np\nfrom tflite_runtime.interpreter import Interpreter, load_delegate\nimport cv2\n\n# Phase 1: Setup\nmodel_path  = \"/home/mendel/tinyml_autopilot/models/edgetpu_detect.tflite\"\nlabel_path  = \"/home/mendel/tinyml_autopilot/models/labelmap.txt\"\ninput_path  = \"/home/mendel/tinyml_autopilot/data//sheeps.mp4\"\noutput_path  = \"/home/mendel/tinyml_autopilot/results/sheeps_detections.mp4\"\nconfidence_threshold  = 0.5\n\n# Load labels\nwith open(label_path, 'r') as f:\n    labels = [line.strip() for line in f.readlines()]\n\n# Load Interpreter with EdgeTPU\ntry:\n    interpreter = Interpreter(model_path=model_path,\n                              experimental_delegates=[load_delegate('libedgetpu.so.1.0')])\nexcept Exception as e:\n    print(f\"Failed to load libedgetpu.so.1.0: {e}\")\n    try:\n        interpreter = Interpreter(model_path=model_path,\n                                  experimental_delegates=[load_delegate('/usr/lib/aarch64-linux-gnu/libedgetpu.so.1.0')])\n    except Exception as e:\n        print(f\"Failed to load /usr/lib/aarch64-linux-gnu/libedgetpu.so.1.0: {e}\")\n        raise\n\ninterpreter.allocate_tensors()\n\n# Get Model Details\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\n\nfloating_model = (input_details[0]['dtype'] == np.float32)\n\n# Phase 2: Input Acquisition & Preprocessing Loop\ncap = cv2.VideoCapture(input_path)\nif not cap.isOpened():\n    raise IOError(\"Cannot open video file\")\n\nframe_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\nframe_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\nfps = cap.get(cv2.CAP_PROP_FPS)\n\nout = cv2.VideoWriter(output_path, cv2.VideoWriter_fourcc(*'mp4v'), fps, (frame_width, frame_height))\n\nwhile True:\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    # Preprocess Data\n    input_data = cv2.resize(frame, (input_details[0]['shape'][1], input_details[0]['shape'][2]))\n    input_data = np.expand_dims(input_data, axis=0)\n\n    if floating_model:\n        input_data = (np.float32(input_data) - 127.5) / 127.5\n\n    # Phase 3: Inference\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n    interpreter.invoke()\n\n    # Phase 4: Output Interpretation & Handling Loop\n    detection_boxes = interpreter.get_tensor(output_details[0]['index'])[0]\n    detection_classes = interpreter.get_tensor(output_details[1]['index'])[0].astype(int)\n    detection_scores = interpreter.get_tensor(output_details[2]['index'])[0]\n\n    num_detections = len(detection_scores)  # Assuming the number of detections is the length of scores\n\n    for i in range(num_detections):\n        if detection_scores[i] > confidence_threshold:\n            box = detection_boxes[i]\n            class_id = detection_classes[i]\n            score = detection_scores[i]\n\n            # Scale and clip bounding boxes\n            ymin, xmin, ymax, xmax = box\n            (left, right, top, bottom) = (xmin * frame_width, xmax * frame_width,\n                                          ymin * frame_height, ymax * frame_height)\n\n            cv2.rectangle(frame, (int(left), int(top)), (int(right), int(bottom)), (0, 255, 0), 2)\n            label = f'{labels[class_id]}: {score:.2f}'\n            cv2.putText(frame, label, (int(left), int(top) - 10),\n                        cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n\n    # Write the frame with detections to the output video\n    out.write(frame)\n\n# Release resources\ncap.release()\nout.release()\ncv2.destroyAllWindows()"
      },
      "session_id": "qwen2.5-coder:32b_373e_tpusg_batch",
      "metadata": {
        "num_run": 21
      },
      "tags": [
        "benchmark",
        "qwen2.5-coder:32b",
        "tpu_sketch_generator"
      ],
      "latency": 185.007,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-22-55-35-603764_chatcmpl-56f6faf9-5648-4ad4-9fbc-b0b3a3f6959b",
          "traceId": "c8f4f7fe",
          "type": "GENERATION",
          "name": "c8f4_tpusg_gen_attempt#1",
          "startTime": "2025-08-03T19:55:35.603000+00:00",
          "endTime": "2025-08-03T19:56:01.041000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 25438.0,
          "environment": "default",
          "totalTokens": 2709,
          "costDetails": {},
          "completionTokens": 876,
          "promptTokens": 1833,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-22-56-09-158210_chatcmpl-af2a2777-4151-408a-a23e-dc36d63ed4eb",
          "traceId": "c8f4f7fe",
          "type": "GENERATION",
          "name": "c8f4_tpusg_gen_attempt#2",
          "startTime": "2025-08-03T19:56:09.158000+00:00",
          "endTime": "2025-08-03T19:56:41.695000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 32537.0,
          "environment": "default",
          "totalTokens": 3187,
          "costDetails": {},
          "completionTokens": 1139,
          "promptTokens": 2048,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-22-56-49-750451_chatcmpl-f6ce1f8b-7a94-4d92-800d-03f2cc4b9ed6",
          "traceId": "c8f4f7fe",
          "type": "GENERATION",
          "name": "c8f4_tpusg_gen_attempt#3",
          "startTime": "2025-08-03T19:56:49.750000+00:00",
          "endTime": "2025-08-03T19:57:20.326000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 30576.0,
          "environment": "default",
          "totalTokens": 3112,
          "costDetails": {},
          "completionTokens": 1064,
          "promptTokens": 2048,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-22-57-28-390719_chatcmpl-d0ae3b12-9346-4db4-a02a-14687fbcf10a",
          "traceId": "c8f4f7fe",
          "type": "GENERATION",
          "name": "c8f4_tpusg_gen_attempt#4",
          "startTime": "2025-08-03T19:57:28.390000+00:00",
          "endTime": "2025-08-03T19:57:59.875000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 31485.0,
          "environment": "default",
          "totalTokens": 3147,
          "costDetails": {},
          "completionTokens": 1099,
          "promptTokens": 2048,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-22-58-07-988736_chatcmpl-bc8dbccc-eceb-4a75-9cfc-b4e80f002d1a",
          "traceId": "c8f4f7fe",
          "type": "GENERATION",
          "name": "c8f4_tpusg_gen_attempt#5",
          "startTime": "2025-08-03T19:58:07.988000+00:00",
          "endTime": "2025-08-03T19:58:40.610000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 32622.0,
          "environment": "default",
          "totalTokens": 3190,
          "costDetails": {},
          "completionTokens": 1142,
          "promptTokens": 2048,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        }
      ],
      "createdAt": "2025-08-03T19:55:36.124Z",
      "environment": "default",
      "updatedAt": "2025-08-03T19:59:38.406Z"
    },
    {
      "id": "b458eb18",
      "timestamp": "2025-08-03T19:52:18.056000+00:00",
      "name": "b458_tpu_sketch_generator",
      "input": null,
      "output": {
        "status": "failed",
        "last_code": "import numpy as np\nfrom tflite_runtime.interpreter import Interpreter, load_delegate\nimport cv2\n\n# Phase 1: Setup\nmodel_path  = \"/home/mendel/tinyml_autopilot/models/edgetpu_detect.tflite\"\nlabel_path  = \"/home/mendel/tinyml_autopilot/models/labelmap.txt\"\ninput_path  = \"/home/mendel/tinyml_autopilot/data//sheeps.mp4\"\noutput_path  = \"/home/mendel/tinyml_autopilot/results/sheeps_detections.mp4\"\nconfidence_threshold  = 0.5\n\n# Load labels\nwith open(label_path, 'r') as f:\n    labels = [line.strip() for line in f.readlines()]\n\n# Load Interpreter with EdgeTPU\ntry:\n    interpreter = Interpreter(model_path=model_path,\n                              experimental_delegates=[load_delegate('libedgetpu.so.1.0')])\nexcept Exception as e:\n    print(f\"Failed to load libedgetpu.so.1.0: {e}\")\n    try:\n        interpreter = Interpreter(model_path=model_path,\n                                  experimental_delegates=[load_delegate('/usr/lib/aarch64-linux-gnu/libedgetpu.so.1.0')])\n    except Exception as e:\n        print(f\"Failed to load /usr/lib/aarch64-linux-gnu/libedgetpu.so.1.0: {e}\")\n        raise\n\ninterpreter.allocate_tensors()\n\n# Get Model Details\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\n\nfloating_model = (input_details[0]['dtype'] == np.float32)\n\n# Phase 2: Input Acquisition & Preprocessing Loop\ncap = cv2.VideoCapture(input_path)\nif not cap.isOpened():\n    raise IOError(\"Cannot open video file\")\n\nframe_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\nframe_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\nfps = cap.get(cv2.CAP_PROP_FPS)\n\nout = cv2.VideoWriter(output_path, cv2.VideoWriter_fourcc(*'mp4v'), fps, (frame_width, frame_height))\n\nwhile True:\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    # Preprocess Data\n    input_data = cv2.resize(frame, (input_details[0]['shape'][1], input_details[0]['shape'][2]))\n    input_data = np.expand_dims(input_data, axis=0)\n\n    if floating_model:\n        input_data = (np.float32(input_data) - 127.5) / 127.5\n\n    # Phase 3: Inference\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n    interpreter.invoke()\n\n    # Phase 4: Output Interpretation & Handling Loop\n    output_data = interpreter.get_tensor(output_details[0]['index'])\n    num_detections = int(interpreter.get_tensor(output_details[1]['index']))  # Ensure we get the scalar value\n    detection_boxes = interpreter.get_tensor(output_details[2]['index'])[0]\n    detection_classes = interpreter.get_tensor(output_details[3]['index'])[0].astype(int)\n    detection_scores = interpreter.get_tensor(output_details[4]['index'])[0]\n\n    for i in range(num_detections):\n        if detection_scores[i] > confidence_threshold:\n            box = detection_boxes[i]\n            class_id = detection_classes[i]\n            score = detection_scores[i]\n\n            # Scale the bounding box coordinates\n            ymin, xmin, ymax, xmax = box\n            (left, right, top, bottom) = (xmin * frame_width, xmax * frame_width,\n                                          ymin * frame_height, ymax * frame_height)\n\n            # Draw the bounding box and label on the frame\n            cv2.rectangle(frame, (int(left), int(top)), (int(right), int(bottom)), (0, 255, 0), 2)\n            label = f'{labels[class_id]}: {score:.2f}'\n            cv2.putText(frame, label, (int(left), int(top) - 10),\n                        cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n\n    # Write the frame to the output video\n    out.write(frame)\n\n# Release resources\ncap.release()\nout.release()\ncv2.destroyAllWindows()",
        "last_error": "Traceback (most recent call last):\n  File \"script_4603a1eb_1754250921.py\", line 66, in <module>\n    num_detections = int(interpreter.get_tensor(output_details[1]['index']))  # Ensure we get the scalar value\nTypeError: only size-1 arrays can be converted to Python scalars"
      },
      "session_id": "qwen2.5-coder:32b_373e_tpusg_batch",
      "metadata": {
        "num_run": 20
      },
      "tags": [
        "benchmark",
        "qwen2.5-coder:32b",
        "tpu_sketch_generator"
      ],
      "latency": 191.43,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-22-52-18-057792_chatcmpl-05022ea5-49e4-4417-980d-0fd9ea1f73e7",
          "traceId": "b458eb18",
          "type": "GENERATION",
          "name": "b458_tpusg_gen_attempt#1",
          "startTime": "2025-08-03T19:52:18.057000+00:00",
          "endTime": "2025-08-03T19:52:43.935000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 25878.0,
          "environment": "default",
          "totalTokens": 2726,
          "costDetails": {},
          "completionTokens": 893,
          "promptTokens": 1833,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-22-52-52-086929_chatcmpl-92c73530-3c3f-4851-b164-60b3422a30f5",
          "traceId": "b458eb18",
          "type": "GENERATION",
          "name": "b458_tpusg_gen_attempt#2",
          "startTime": "2025-08-03T19:52:52.086000+00:00",
          "endTime": "2025-08-03T19:53:23.700000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 31614.0,
          "environment": "default",
          "totalTokens": 3151,
          "costDetails": {},
          "completionTokens": 1103,
          "promptTokens": 2048,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-22-53-31-799255_chatcmpl-922e4860-1ad5-4a45-9ba1-88104f923884",
          "traceId": "b458eb18",
          "type": "GENERATION",
          "name": "b458_tpusg_gen_attempt#3",
          "startTime": "2025-08-03T19:53:31.799000+00:00",
          "endTime": "2025-08-03T19:54:02.923000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 31124.0,
          "environment": "default",
          "totalTokens": 3132,
          "costDetails": {},
          "completionTokens": 1084,
          "promptTokens": 2048,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-22-54-11-019173_chatcmpl-fefcf98a-77fd-4017-b582-462ecead6de1",
          "traceId": "b458eb18",
          "type": "GENERATION",
          "name": "b458_tpusg_gen_attempt#4",
          "startTime": "2025-08-03T19:54:11.019000+00:00",
          "endTime": "2025-08-03T19:54:42.134000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 31115.0,
          "environment": "default",
          "totalTokens": 3132,
          "costDetails": {},
          "completionTokens": 1084,
          "promptTokens": 2048,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-22-54-50-210840_chatcmpl-a64f0ee9-952f-481e-8d77-da6f632ca7f7",
          "traceId": "b458eb18",
          "type": "GENERATION",
          "name": "b458_tpusg_gen_attempt#5",
          "startTime": "2025-08-03T19:54:50.210000+00:00",
          "endTime": "2025-08-03T19:55:21.277000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 31067.0,
          "environment": "default",
          "totalTokens": 3131,
          "costDetails": {},
          "completionTokens": 1083,
          "promptTokens": 2048,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "5110780b-cbcb-4c44-9b14-023b9344dbaf",
          "traceId": "b458eb18",
          "type": "SPAN",
          "name": "error_b4_tpusg_failure_signal_tpu_sketch_generator",
          "startTime": "2025-08-03T19:55:29.487000+00:00",
          "level": "ERROR",
          "statusMessage": "Failed. Last error: Traceback (most recent call last):\n  File \"script_4603a1eb_1754250921.py\", line 66, in <module>\n    num_detections = int(interpreter.get_tensor(output_details[1]['index']))  # Ensure we get the scalar value\nTypeError: only size-1 arrays can be converted to Python scalars",
          "calculatedTotalCost": 0.0,
          "environment": "default",
          "totalTokens": 0,
          "costDetails": {},
          "completionTokens": 0,
          "promptTokens": 0,
          "endTime": null,
          "model": null,
          "modelParameters": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null,
          "latency": null
        }
      ],
      "createdAt": "2025-08-03T19:52:18.578Z",
      "environment": "default",
      "updatedAt": "2025-08-03T19:55:34.817Z"
    },
    {
      "id": "f1fd4daf",
      "timestamp": "2025-08-03T19:49:01.492000+00:00",
      "name": "f1fd_tpu_sketch_generator",
      "input": null,
      "output": {
        "status": "failed",
        "last_code": "import numpy as np\nfrom tflite_runtime.interpreter import Interpreter, load_delegate\nimport cv2\n\n# Phase 1: Setup\nmodel_path  = \"/home/mendel/tinyml_autopilot/models/edgetpu_detect.tflite\"\nlabel_path  = \"/home/mendel/tinyml_autopilot/models/labelmap.txt\"\ninput_path  = \"/home/mendel/tinyml_autopilot/data//sheeps.mp4\"\noutput_path  = \"/home/mendel/tinyml_autopilot/results/sheeps_detections.mp4\"\nconfidence_threshold  = 0.5\n\n# Load labels\nwith open(label_path, 'r') as f:\n    labels = [line.strip() for line in f.readlines()]\n\n# Load Interpreter with EdgeTPU\ntry:\n    interpreter = Interpreter(model_path=model_path,\n                              experimental_delegates=[load_delegate('libedgetpu.so.1.0')])\nexcept Exception as e:\n    print(f\"Failed to load libedgetpu.so.1.0: {e}\")\n    try:\n        interpreter = Interpreter(model_path=model_path,\n                                  experimental_delegates=[load_delegate('/usr/lib/aarch64-linux-gnu/libedgetpu.so.1.0')])\n    except Exception as e:\n        print(f\"Failed to load /usr/lib/aarch64-linux-gnu/libedgetpu.so.1.0: {e}\")\n        raise\n\ninterpreter.allocate_tensors()\n\n# Get Model Details\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\n\nfloating_model = (input_details[0]['dtype'] == np.float32)\n\n# Phase 2: Input Acquisition & Preprocessing Loop\ncap = cv2.VideoCapture(input_path)\nif not cap.isOpened():\n    raise IOError(\"Cannot open video file\")\n\nframe_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\nframe_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\nfps = cap.get(cv2.CAP_PROP_FPS)\n\nout = cv2.VideoWriter(output_path, cv2.VideoWriter_fourcc(*'mp4v'), fps, (frame_width, frame_height))\n\nwhile True:\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    # Preprocess Data\n    input_data = cv2.resize(frame, (input_details[0]['shape'][1], input_details[0]['shape'][2]))\n    input_data = np.expand_dims(input_data, axis=0)\n\n    if floating_model:\n        input_data = (np.float32(input_data) - 127.5) / 127.5\n\n    # Phase 3: Inference\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n    interpreter.invoke()\n\n    # Phase 4: Output Interpretation & Handling Loop\n    output_data = interpreter.get_tensor(output_details[0]['index'])\n    \n    # Ensure num_detections is a scalar value using [0]\n    num_detections = int(interpreter.get_tensor(output_details[1]['index'])[0])\n    detection_boxes = interpreter.get_tensor(output_details[2]['index'])[0]\n    detection_classes = interpreter.get_tensor(output_details[3]['index'])[0].astype(int)\n    detection_scores = interpreter.get_tensor(output_details[4]['index'])[0]\n\n    for i in range(num_detections):\n        if detection_scores[i] > confidence_threshold:\n            box = detection_boxes[i]\n            class_id = detection_classes[i]\n            score = detection_scores[i]\n\n            # Scale and clip bounding boxes\n            ymin, xmin, ymax, xmax = box\n            (left, right, top, bottom) = (xmin * frame_width, xmax * frame_width,\n                                          ymin * frame_height, ymax * frame_height)\n\n            cv2.rectangle(frame, (int(left), int(top)), (int(right), int(bottom)), (0, 255, 0), 2)\n            label = f'{labels[class_id]}: {score:.2f}'\n            cv2.putText(frame, label, (int(left), int(top) - 10),\n                        cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n\n    # Handle Output\n    out.write(frame)\n\n# Phase 5: Cleanup\ncap.release()\nout.release()\ncv2.destroyAllWindows()",
        "last_error": "Traceback (most recent call last):\n  File \"script_99ce4837_1754250722.py\", line 68, in <module>\n    num_detections = int(interpreter.get_tensor(output_details[1]['index'])[0])\nTypeError: only size-1 arrays can be converted to Python scalars"
      },
      "session_id": "qwen2.5-coder:32b_373e_tpusg_batch",
      "metadata": {
        "num_run": 19
      },
      "tags": [
        "benchmark",
        "qwen2.5-coder:32b",
        "tpu_sketch_generator"
      ],
      "latency": 189.558,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-22-49-01-494600_chatcmpl-9cdc2eb6-0b15-49e8-b100-db235a72dde7",
          "traceId": "f1fd4daf",
          "type": "GENERATION",
          "name": "f1fd_tpusg_gen_attempt#1",
          "startTime": "2025-08-03T19:49:01.494000+00:00",
          "endTime": "2025-08-03T19:49:26.956000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 25462.0,
          "environment": "default",
          "totalTokens": 2709,
          "costDetails": {},
          "completionTokens": 876,
          "promptTokens": 1833,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-22-49-35-016942_chatcmpl-5b305320-a3f9-45aa-87b4-676772da76a4",
          "traceId": "f1fd4daf",
          "type": "GENERATION",
          "name": "f1fd_tpusg_gen_attempt#2",
          "startTime": "2025-08-03T19:49:35.016000+00:00",
          "endTime": "2025-08-03T19:50:06.745000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 31729.0,
          "environment": "default",
          "totalTokens": 3154,
          "costDetails": {},
          "completionTokens": 1106,
          "promptTokens": 2048,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-22-50-15-026254_chatcmpl-345f1963-ee8e-4f4b-8725-8677b314f9fc",
          "traceId": "f1fd4daf",
          "type": "GENERATION",
          "name": "f1fd_tpusg_gen_attempt#3",
          "startTime": "2025-08-03T19:50:15.026000+00:00",
          "endTime": "2025-08-03T19:50:46.384000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 31358.0,
          "environment": "default",
          "totalTokens": 3141,
          "costDetails": {},
          "completionTokens": 1093,
          "promptTokens": 2048,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-22-50-54-489901_chatcmpl-ab42cc7d-bae6-4b9f-86ab-ab85596e0e04",
          "traceId": "f1fd4daf",
          "type": "GENERATION",
          "name": "f1fd_tpusg_gen_attempt#4",
          "startTime": "2025-08-03T19:50:54.489000+00:00",
          "endTime": "2025-08-03T19:51:25+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 30511.0,
          "environment": "default",
          "totalTokens": 3109,
          "costDetails": {},
          "completionTokens": 1061,
          "promptTokens": 2048,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-22-51-33-082297_chatcmpl-80e4b4cb-75af-4117-8533-8852b634a3d9",
          "traceId": "f1fd4daf",
          "type": "GENERATION",
          "name": "f1fd_tpusg_gen_attempt#5",
          "startTime": "2025-08-03T19:51:33.082000+00:00",
          "endTime": "2025-08-03T19:52:02.920000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 29838.0,
          "environment": "default",
          "totalTokens": 3083,
          "costDetails": {},
          "completionTokens": 1035,
          "promptTokens": 2048,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "78458c12-5317-449b-998b-544147521b6e",
          "traceId": "f1fd4daf",
          "type": "SPAN",
          "name": "error_f1_tpusg_failure_signal_tpu_sketch_generator",
          "startTime": "2025-08-03T19:52:11.052000+00:00",
          "level": "ERROR",
          "statusMessage": "Failed. Last error: Traceback (most recent call last):\n  File \"script_99ce4837_1754250722.py\", line 68, in <module>\n    num_detections = int(interpreter.get_tensor(output_details[1]['index'])[0])\nTypeError: only size-1 arrays can be converted to Python scalars",
          "calculatedTotalCost": 0.0,
          "environment": "default",
          "totalTokens": 0,
          "costDetails": {},
          "completionTokens": 0,
          "promptTokens": 0,
          "endTime": null,
          "model": null,
          "modelParameters": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null,
          "latency": null
        }
      ],
      "createdAt": "2025-08-03T19:49:02.011Z",
      "environment": "default",
      "updatedAt": "2025-08-03T19:52:16.285Z"
    },
    {
      "id": "3d56a955",
      "timestamp": "2025-08-03T19:46:20.623000+00:00",
      "name": "3d56_tpu_sketch_generator",
      "input": null,
      "output": {
        "status": "success",
        "sketch": "import numpy as np\nfrom tflite_runtime.interpreter import Interpreter, load_delegate\nimport cv2\n\n# Phase 1: Setup\nmodel_path  = \"/home/mendel/tinyml_autopilot/models/edgetpu_detect.tflite\"\nlabel_path  = \"/home/mendel/tinyml_autopilot/models/labelmap.txt\"\ninput_path  = \"/home/mendel/tinyml_autopilot/data//sheeps.mp4\"\noutput_path  = \"/home/mendel/tinyml_autopilot/results/sheeps_detections.mp4\"\nconfidence_threshold  = 0.5\n\n# Load labels\nwith open(label_path, 'r') as f:\n    labels = [line.strip() for line in f.readlines()]\n\n# Load Interpreter with EdgeTPU\ntry:\n    interpreter = Interpreter(model_path=model_path,\n                              experimental_delegates=[load_delegate('libedgetpu.so.1.0')])\nexcept Exception as e:\n    print(f\"Failed to load libedgetpu.so.1.0: {e}\")\n    try:\n        interpreter = Interpreter(model_path=model_path,\n                                  experimental_delegates=[load_delegate('/usr/lib/aarch64-linux-gnu/libedgetpu.so.1.0')])\n    except Exception as e:\n        print(f\"Failed to load /usr/lib/aarch64-linux-gnu/libedgetpu.so.1.0: {e}\")\n        raise\n\ninterpreter.allocate_tensors()\n\n# Get Model Details\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\n\nprint(\"Input details:\", input_details)\nprint(\"Output details:\", output_details)\n\nfloating_model = (input_details[0]['dtype'] == np.float32)\n\n# Phase 2: Input Acquisition & Preprocessing Loop\ncap = cv2.VideoCapture(input_path)\nif not cap.isOpened():\n    raise IOError(\"Cannot open video file\")\n\nframe_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\nframe_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\nfps = cap.get(cv2.CAP_PROP_FPS)\n\nout = cv2.VideoWriter(output_path, cv2.VideoWriter_fourcc(*'mp4v'), fps, (frame_width, frame_height))\n\nwhile True:\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    # Preprocess Data\n    input_data = cv2.resize(frame, (input_details[0]['shape'][1], input_details[0]['shape'][2]))\n    input_data = np.expand_dims(input_data, axis=0)\n\n    if floating_model:\n        input_data = (np.float32(input_data) - 127.5) / 127.5\n\n    # Phase 3: Inference\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n    interpreter.invoke()\n\n    # Phase 4: Output Interpretation & Handling Loop\n    output_data = interpreter.get_tensor(output_details[0]['index'])\n    num_detections = np.squeeze(interpreter.get_tensor(output_details[1]['index']))\n\n    if len(output_details) > 2:\n        detection_boxes = interpreter.get_tensor(output_details[2]['index'])[0]\n    else:\n        print(\"Detection boxes output not found.\")\n        continue\n\n    if len(output_details) > 3:\n        detection_classes = interpreter.get_tensor(output_details[3]['index'])[0].astype(int)\n    else:\n        print(\"Detection classes output not found.\")\n        continue\n\n    if len(output_details) > 4:\n        detection_scores = interpreter.get_tensor(output_details[4]['index'])[0]\n    else:\n        print(\"Detection scores output not found.\")\n        continue\n\n    for i in range(num_detections):\n        if detection_scores[i] > confidence_threshold:\n            box = detection_boxes[i]\n            class_id = detection_classes[i]\n            score = detection_scores[i]\n\n            # Scale the bounding box coordinates\n            ymin, xmin, ymax, xmax = box\n            (left, right, top, bottom) = (xmin * frame_width, xmax * frame_width,\n                                          ymin * frame_height, ymax * frame_height)\n\n            # Draw the bounding box and label on the frame\n            cv2.rectangle(frame, (int(left), int(top)), (int(right), int(bottom)), (0, 255, 0), 2)\n            label = f'{labels[class_id]}: {score:.2f}'\n            cv2.putText(frame, label, (int(left), int(top) - 10),\n                        cv2.FONT_HERSHEY_SIMPLEX, 0.9, (36, 255, 12), 2)\n\n    # Write the frame to the output video\n    out.write(frame)\n\n# Release resources\ncap.release()\nout.release()\ncv2.destroyAllWindows()"
      },
      "session_id": "qwen2.5-coder:32b_373e_tpusg_batch",
      "metadata": {
        "num_run": 18
      },
      "tags": [
        "benchmark",
        "qwen2.5-coder:32b",
        "tpu_sketch_generator"
      ],
      "latency": 106.968,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-22-46-20-624893_chatcmpl-1197e40b-73d2-41f6-9e5a-0e4490de1047",
          "traceId": "3d56a955",
          "type": "GENERATION",
          "name": "3d56_tpusg_gen_attempt#1",
          "startTime": "2025-08-03T19:46:20.624000+00:00",
          "endTime": "2025-08-03T19:46:47.469000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 26845.0,
          "environment": "default",
          "totalTokens": 2726,
          "costDetails": {},
          "completionTokens": 893,
          "promptTokens": 1833,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-22-46-55-563675_chatcmpl-5ee36c30-162f-45ae-873d-087c8fe18137",
          "traceId": "3d56a955",
          "type": "GENERATION",
          "name": "3d56_tpusg_gen_attempt#2",
          "startTime": "2025-08-03T19:46:55.563000+00:00",
          "endTime": "2025-08-03T19:47:26.010000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 30447.0,
          "environment": "default",
          "totalTokens": 3104,
          "costDetails": {},
          "completionTokens": 1056,
          "promptTokens": 2048,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-22-47-34-109683_chatcmpl-76c9f23f-30d3-4341-a242-d93dc462df08",
          "traceId": "3d56a955",
          "type": "GENERATION",
          "name": "3d56_tpusg_gen_attempt#3",
          "startTime": "2025-08-03T19:47:34.109000+00:00",
          "endTime": "2025-08-03T19:48:07.592000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 33483.0,
          "environment": "default",
          "totalTokens": 3222,
          "costDetails": {},
          "completionTokens": 1174,
          "promptTokens": 2048,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        }
      ],
      "createdAt": "2025-08-03T19:46:21.144Z",
      "environment": "default",
      "updatedAt": "2025-08-03T19:49:00.348Z"
    },
    {
      "id": "d4279457",
      "timestamp": "2025-08-03T19:43:38.063000+00:00",
      "name": "d427_tpu_sketch_generator",
      "input": null,
      "output": {
        "status": "success",
        "sketch": "import numpy as np\nfrom tflite_runtime.interpreter import Interpreter, load_delegate\nimport cv2\n\n# Phase 1: Setup\nmodel_path  = \"/home/mendel/tinyml_autopilot/models/edgetpu_detect.tflite\"\nlabel_path  = \"/home/mendel/tinyml_autopilot/models/labelmap.txt\"\ninput_path  = \"/home/mendel/tinyml_autopilot/data//sheeps.mp4\"\noutput_path  = \"/home/mendel/tinyml_autopilot/results/sheeps_detections.mp4\"\nconfidence_threshold  = 0.5\n\n# Load labels\nwith open(label_path, 'r') as f:\n    labels = [line.strip() for line in f.readlines()]\n\n# Load Interpreter with EdgeTPU\ntry:\n    interpreter = Interpreter(model_path=model_path,\n                              experimental_delegates=[load_delegate('libedgetpu.so.1.0')])\nexcept Exception as e:\n    print(f\"Failed to load libedgetpu.so.1.0: {e}\")\n    try:\n        interpreter = Interpreter(model_path=model_path,\n                                  experimental_delegates=[load_delegate('/usr/lib/aarch64-linux-gnu/libedgetpu.so.1.0')])\n    except Exception as e:\n        print(f\"Failed to load /usr/lib/aarch64-linux-gnu/libedgetpu.so.1.0: {e}\")\n        raise\n\ninterpreter.allocate_tensors()\n\n# Get Model Details\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\n\nfloating_model = (input_details[0]['dtype'] == np.float32)\n\n# Phase 2: Input Acquisition & Preprocessing Loop\ncap = cv2.VideoCapture(input_path)\nif not cap.isOpened():\n    raise IOError(\"Cannot open video file\")\n\nframe_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\nframe_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\nfps = cap.get(cv2.CAP_PROP_FPS)\n\nout = cv2.VideoWriter(output_path, cv2.VideoWriter_fourcc(*'mp4v'), fps, (frame_width, frame_height))\n\nwhile True:\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    # Preprocess Data\n    input_data = cv2.resize(frame, (input_details[0]['shape'][1], input_details[0]['shape'][2]))\n    input_data = np.expand_dims(input_data, axis=0)\n\n    if floating_model:\n        input_data = (np.float32(input_data) - 127.5) / 127.5\n\n    # Phase 3: Inference\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n    interpreter.invoke()\n\n    # Phase 4: Output Interpretation & Handling Loop\n    detection_boxes = interpreter.get_tensor(output_details[0]['index'])[0]\n    detection_classes = interpreter.get_tensor(output_details[1]['index'])[0].astype(int)\n    detection_scores = interpreter.get_tensor(output_details[2]['index'])[0]\n\n    for i in range(len(detection_scores)):\n        if detection_scores[i] > confidence_threshold:\n            box = detection_boxes[i]\n            class_id = detection_classes[i]\n            score = detection_scores[i]\n\n            # Scale and clip bounding boxes\n            ymin, xmin, ymax, xmax = box\n            (left, right, top, bottom) = (xmin * frame_width, xmax * frame_width,\n                                          ymin * frame_height, ymax * frame_height)\n\n            cv2.rectangle(frame, (int(left), int(top)), (int(right), int(bottom)), (0, 255, 0), 2)\n            label = f'{labels[class_id]}: {score:.2f}'\n            cv2.putText(frame, label, (int(left), int(top) - 10),\n                        cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n\n    # Handle Output\n    out.write(frame)\n\n# Phase 5: Cleanup\ncap.release()\nout.release()\ncv2.destroyAllWindows()"
      },
      "session_id": "qwen2.5-coder:32b_373e_tpusg_batch",
      "metadata": {
        "num_run": 17
      },
      "tags": [
        "benchmark",
        "qwen2.5-coder:32b",
        "tpu_sketch_generator"
      ],
      "latency": 103.601,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-22-43-38-064623_chatcmpl-4a77e965-9ce7-4779-8864-867cacef54d7",
          "traceId": "d4279457",
          "type": "GENERATION",
          "name": "d427_tpusg_gen_attempt#1",
          "startTime": "2025-08-03T19:43:38.064000+00:00",
          "endTime": "2025-08-03T19:44:03.491000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 25427.0,
          "environment": "default",
          "totalTokens": 2709,
          "costDetails": {},
          "completionTokens": 876,
          "promptTokens": 1833,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-22-44-11-592473_chatcmpl-6297c9b0-2bd1-443f-80ab-d82161e74c09",
          "traceId": "d4279457",
          "type": "GENERATION",
          "name": "d427_tpusg_gen_attempt#2",
          "startTime": "2025-08-03T19:44:11.592000+00:00",
          "endTime": "2025-08-03T19:44:42.788000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 31196.0,
          "environment": "default",
          "totalTokens": 3135,
          "costDetails": {},
          "completionTokens": 1087,
          "promptTokens": 2048,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-22-44-50-885842_chatcmpl-5a54f9d5-811a-4922-aa76-0f92b384bd4b",
          "traceId": "d4279457",
          "type": "GENERATION",
          "name": "d427_tpusg_gen_attempt#3",
          "startTime": "2025-08-03T19:44:50.885000+00:00",
          "endTime": "2025-08-03T19:45:21.665000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 30780.0,
          "environment": "default",
          "totalTokens": 3119,
          "costDetails": {},
          "completionTokens": 1071,
          "promptTokens": 2048,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        }
      ],
      "createdAt": "2025-08-03T19:43:38.583Z",
      "environment": "default",
      "updatedAt": "2025-08-03T19:46:19.823Z"
    },
    {
      "id": "1957a8d2",
      "timestamp": "2025-08-03T19:41:36.553000+00:00",
      "name": "1957_tpu_sketch_generator",
      "input": null,
      "output": {
        "status": "success",
        "sketch": "import numpy as np\nfrom tflite_runtime.interpreter import Interpreter, load_delegate\nimport cv2\n\n# Phase 1: Setup\nmodel_path  = \"/home/mendel/tinyml_autopilot/models/edgetpu_detect.tflite\"\nlabel_path  = \"/home/mendel/tinyml_autopilot/models/labelmap.txt\"\ninput_path  = \"/home/mendel/tinyml_autopilot/data//sheeps.mp4\"\noutput_path  = \"/home/mendel/tinyml_autopilot/results/sheeps_detections.mp4\"\nconfidence_threshold  = 0.5\n\n# Load labels\nwith open(label_path, 'r') as f:\n    labels = [line.strip() for line in f.readlines()]\n\n# Load Interpreter with EdgeTPU\ntry:\n    interpreter = Interpreter(model_path=model_path,\n                              experimental_delegates=[load_delegate('libedgetpu.so.1.0')])\nexcept Exception as e:\n    print(f\"Failed to load libedgetpu.so.1.0: {e}\")\n    try:\n        interpreter = Interpreter(model_path=model_path,\n                                  experimental_delegates=[load_delegate('/usr/lib/aarch64-linux-gnu/libedgetpu.so.1.0')])\n    except Exception as e:\n        print(f\"Failed to load /usr/lib/aarch64-linux-gnu/libedgetpu.so.1.0: {e}\")\n        raise\n\ninterpreter.allocate_tensors()\n\n# Get Model Details\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\n\nfloating_model = (input_details[0]['dtype'] == np.float32)\n\n# Debugging output details\nprint(\"Output Details:\")\nfor i, detail in enumerate(output_details):\n    print(f\"Output {i}: {detail}\")\n\n# Phase 2: Input Acquisition & Preprocessing Loop\ncap = cv2.VideoCapture(input_path)\nif not cap.isOpened():\n    raise IOError(\"Cannot open video file\")\n\nframe_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\nframe_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\nfps = cap.get(cv2.CAP_PROP_FPS)\n\nout = cv2.VideoWriter(output_path, cv2.VideoWriter_fourcc(*'mp4v'), fps, (frame_width, frame_height))\n\nwhile True:\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    # Preprocess Data\n    input_data = cv2.resize(frame, (input_details[0]['shape'][1], input_details[0]['shape'][2]))\n    input_data = np.expand_dims(input_data, axis=0)\n\n    if floating_model:\n        input_data = (np.float32(input_data) - 127.5) / 127.5\n\n    # Phase 3: Inference\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n    interpreter.invoke()\n\n    # Phase 4: Output Interpretation & Handling Loop\n    output_data = interpreter.get_tensor(output_details[0]['index'])\n    num_detections = np.squeeze(interpreter.get_tensor(output_details[1]['index']))\n\n    if len(output_details) > 2:\n        detection_boxes = interpreter.get_tensor(output_details[2]['index'])[0]\n    else:\n        print(\"Error: Not enough output details for detection boxes.\")\n        break\n\n    if len(output_details) > 3:\n        detection_classes = interpreter.get_tensor(output_details[3]['index'])[0].astype(int)\n    else:\n        print(\"Error: Not enough output details for detection classes.\")\n        break\n\n    if len(output_details) > 4:\n        detection_scores = interpreter.get_tensor(output_details[4]['index'])[0]\n    else:\n        print(\"Error: Not enough output details for detection scores.\")\n        break\n\n    for i in range(int(num_detections)):\n        if detection_scores[i] > confidence_threshold:\n            box = detection_boxes[i]\n            class_id = detection_classes[i]\n            score = detection_scores[i]\n\n            # Scale the bounding box coordinates\n            ymin, xmin, ymax, xmax = box\n            (left, right, top, bottom) = (xmin * frame_width, xmax * frame_width,\n                                          ymin * frame_height, ymax * frame_height)\n\n            # Draw the bounding box and label on the frame\n            cv2.rectangle(frame, (int(left), int(top)), (int(right), int(bottom)), (0, 255, 0), 2)\n            label = f\"{labels[class_id]}: {score:.2f}\"\n            cv2.putText(frame, label, (int(left), int(top) - 10),\n                        cv2.FONT_HERSHEY_SIMPLEX, 0.9, (36, 255, 12), 2)\n\n    # Write the frame to the output video\n    out.write(frame)\n\n# Release resources\ncap.release()\nout.release()\ncv2.destroyAllWindows()"
      },
      "session_id": "qwen2.5-coder:32b_373e_tpusg_batch",
      "metadata": {
        "num_run": 16
      },
      "tags": [
        "benchmark",
        "qwen2.5-coder:32b",
        "tpu_sketch_generator"
      ],
      "latency": 107.41,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-22-41-36-554949_chatcmpl-a7477c92-86a2-431b-b3df-34bb17f99811",
          "traceId": "1957a8d2",
          "type": "GENERATION",
          "name": "1957_tpusg_gen_attempt#1",
          "startTime": "2025-08-03T19:41:36.554000+00:00",
          "endTime": "2025-08-03T19:42:02.457000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 25903.0,
          "environment": "default",
          "totalTokens": 2726,
          "costDetails": {},
          "completionTokens": 893,
          "promptTokens": 1833,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-22-42-10-572751_chatcmpl-4271354e-28e9-4ee3-918a-5be1c4edf98d",
          "traceId": "1957a8d2",
          "type": "GENERATION",
          "name": "1957_tpusg_gen_attempt#2",
          "startTime": "2025-08-03T19:42:10.572000+00:00",
          "endTime": "2025-08-03T19:42:41.827000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 31255.0,
          "environment": "default",
          "totalTokens": 3138,
          "costDetails": {},
          "completionTokens": 1090,
          "promptTokens": 2048,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-22-42-49-953170_chatcmpl-23f9a912-7a8a-4dab-8fad-47b6124e174c",
          "traceId": "1957a8d2",
          "type": "GENERATION",
          "name": "1957_tpusg_gen_attempt#3",
          "startTime": "2025-08-03T19:42:49.953000+00:00",
          "endTime": "2025-08-03T19:43:23.964000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 34011.0,
          "environment": "default",
          "totalTokens": 3242,
          "costDetails": {},
          "completionTokens": 1194,
          "promptTokens": 2048,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        }
      ],
      "createdAt": "2025-08-03T19:41:37.072Z",
      "environment": "default",
      "updatedAt": "2025-08-03T19:43:37.299Z"
    },
    {
      "id": "2b2c9e0b",
      "timestamp": "2025-08-03T19:38:18.947000+00:00",
      "name": "2b2c_tpu_sketch_generator",
      "input": null,
      "output": {
        "status": "failed",
        "last_code": "import numpy as np\nfrom tflite_runtime.interpreter import Interpreter, load_delegate\nimport cv2\n\n# Phase 1: Setup\nmodel_path  = \"/home/mendel/tinyml_autopilot/models/edgetpu_detect.tflite\"\nlabel_path  = \"/home/mendel/tinyml_autopilot/models/labelmap.txt\"\ninput_path  = \"/home/mendel/tinyml_autopilot/data//sheeps.mp4\"\noutput_path  = \"/home/mendel/tinyml_autopilot/results/sheeps_detections.mp4\"\nconfidence_threshold  = 0.5\n\n# Load labels\nwith open(label_path, 'r') as f:\n    labels = [line.strip() for line in f.readlines()]\n\n# Load Interpreter with EdgeTPU\ntry:\n    interpreter = Interpreter(model_path=model_path,\n                              experimental_delegates=[load_delegate('libedgetpu.so.1.0')])\nexcept Exception as e:\n    print(f\"Failed to load libedgetpu.so.1.0: {e}\")\n    try:\n        interpreter = Interpreter(model_path=model_path,\n                                  experimental_delegates=[load_delegate('/usr/lib/aarch64-linux-gnu/libedgetpu.so.1.0')])\n    except Exception as e:\n        print(f\"Failed to load /usr/lib/aarch64-linux-gnu/libedgetpu.so.1.0: {e}\")\n        raise\n\ninterpreter.allocate_tensors()\n\n# Get Model Details\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\n\nfloating_model = (input_details[0]['dtype'] == np.float32)\n\n# Phase 2: Input Acquisition & Preprocessing Loop\ncap = cv2.VideoCapture(input_path)\nif not cap.isOpened():\n    raise IOError(\"Cannot open video file\")\n\nframe_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\nframe_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\nfps = cap.get(cv2.CAP_PROP_FPS)\n\nout = cv2.VideoWriter(output_path, cv2.VideoWriter_fourcc(*'mp4v'), fps, (frame_width, frame_height))\n\nwhile True:\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    # Preprocess Data\n    input_data = cv2.resize(frame, (input_details[0]['shape'][1], input_details[0]['shape'][2]))\n    input_data = np.expand_dims(input_data, axis=0)\n\n    if floating_model:\n        input_data = (np.float32(input_data) - 127.5) / 127.5\n\n    # Phase 3: Inference\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n    interpreter.invoke()\n\n    # Phase 4: Output Interpretation & Handling Loop\n    output_data = interpreter.get_tensor(output_details[0]['index'])\n    num_detections_tensor = interpreter.get_tensor(output_details[1]['index'])\n\n    # Ensure num_detections is a scalar\n    num_detections = int(num_detections_tensor.item()) if isinstance(num_detections_tensor, np.ndarray) else int(num_detections_tensor)\n\n    detection_boxes = interpreter.get_tensor(output_details[2]['index'])[0]\n    detection_classes = interpreter.get_tensor(output_details[3]['index'])[0].astype(int)\n    detection_scores = interpreter.get_tensor(output_details[4]['index'])[0]\n\n    for i in range(num_detections):\n        if detection_scores[i] > confidence_threshold:\n            box = detection_boxes[i]\n            class_id = detection_classes[i]\n            score = detection_scores[i]\n\n            # Scale and clip bounding boxes\n            ymin, xmin, ymax, xmax = box\n            (left, right, top, bottom) = (xmin * frame_width, xmax * frame_width,\n                                          ymin * frame_height, ymax * frame_height)\n\n            cv2.rectangle(frame, (int(left), int(top)), (int(right), int(bottom)), (0, 255, 0), 2)\n            label = f'{labels[class_id]}: {score:.2f}'\n            cv2.putText(frame, label, (int(left), int(top) - 10),\n                        cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n\n    # Handle Output\n    out.write(frame)\n\n# Phase 5: Cleanup\ncap.release()\nout.release()\ncv2.destroyAllWindows()",
        "last_error": "Traceback (most recent call last):\n  File \"script_5e5d81be_1754250082.py\", line 69, in <module>\n    num_detections = int(num_detections_tensor.item()) if isinstance(num_detections_tensor, np.ndarray) else int(num_detections_tensor)\nValueError: can only convert an array of size 1 to a Python scalar"
      },
      "session_id": "qwen2.5-coder:32b_373e_tpusg_batch",
      "metadata": {
        "num_run": 15
      },
      "tags": [
        "benchmark",
        "qwen2.5-coder:32b",
        "tpu_sketch_generator"
      ],
      "latency": 191.62,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-22-38-18-948944_chatcmpl-f04ca66a-32dd-4dfb-93c9-26745a03297c",
          "traceId": "2b2c9e0b",
          "type": "GENERATION",
          "name": "2b2c_tpusg_gen_attempt#1",
          "startTime": "2025-08-03T19:38:18.948000+00:00",
          "endTime": "2025-08-03T19:38:44.633000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 25685.0,
          "environment": "default",
          "totalTokens": 2709,
          "costDetails": {},
          "completionTokens": 876,
          "promptTokens": 1833,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-22-38-52-729361_chatcmpl-32cbdc35-ece7-4963-b445-9705473ab4bd",
          "traceId": "2b2c9e0b",
          "type": "GENERATION",
          "name": "2b2c_tpusg_gen_attempt#2",
          "startTime": "2025-08-03T19:38:52.729000+00:00",
          "endTime": "2025-08-03T19:39:24.725000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 31996.0,
          "environment": "default",
          "totalTokens": 3166,
          "costDetails": {},
          "completionTokens": 1118,
          "promptTokens": 2048,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-22-39-32-860478_chatcmpl-1703c1a4-17c9-48bd-9835-3053b3310ede",
          "traceId": "2b2c9e0b",
          "type": "GENERATION",
          "name": "2b2c_tpusg_gen_attempt#3",
          "startTime": "2025-08-03T19:39:32.860000+00:00",
          "endTime": "2025-08-03T19:40:03.226000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 30366.0,
          "environment": "default",
          "totalTokens": 3104,
          "costDetails": {},
          "completionTokens": 1056,
          "promptTokens": 2048,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-22-40-11-270663_chatcmpl-4201eb08-8315-4e41-bea3-41277d63c16a",
          "traceId": "2b2c9e0b",
          "type": "GENERATION",
          "name": "2b2c_tpusg_gen_attempt#4",
          "startTime": "2025-08-03T19:40:11.270000+00:00",
          "endTime": "2025-08-03T19:40:42.441000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 31171.0,
          "environment": "default",
          "totalTokens": 3131,
          "costDetails": {},
          "completionTokens": 1083,
          "promptTokens": 2048,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-22-40-50-593714_chatcmpl-7f7c52f0-23b4-4259-92d4-bfab42316d53",
          "traceId": "2b2c9e0b",
          "type": "GENERATION",
          "name": "2b2c_tpusg_gen_attempt#5",
          "startTime": "2025-08-03T19:40:50.593000+00:00",
          "endTime": "2025-08-03T19:41:22.453000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 31860.0,
          "environment": "default",
          "totalTokens": 3156,
          "costDetails": {},
          "completionTokens": 1108,
          "promptTokens": 2048,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "ba23ac5e-06c7-4d1a-96a9-18a5cbba9666",
          "traceId": "2b2c9e0b",
          "type": "SPAN",
          "name": "error_2b_tpusg_failure_signal_tpu_sketch_generator",
          "startTime": "2025-08-03T19:41:30.568000+00:00",
          "level": "ERROR",
          "statusMessage": "Failed. Last error: Traceback (most recent call last):\n  File \"script_5e5d81be_1754250082.py\", line 69, in <module>\n    num_detections = int(num_detections_tensor.item()) if isinstance(num_detections_tensor, np.ndarray) else int(num_detections_tensor)\nValueError: can only convert an array of size 1 to a Python scalar",
          "calculatedTotalCost": 0.0,
          "environment": "default",
          "totalTokens": 0,
          "costDetails": {},
          "completionTokens": 0,
          "promptTokens": 0,
          "endTime": null,
          "model": null,
          "modelParameters": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null,
          "latency": null
        }
      ],
      "createdAt": "2025-08-03T19:38:19.466Z",
      "environment": "default",
      "updatedAt": "2025-08-03T19:41:36.218Z"
    },
    {
      "id": "b53a5967",
      "timestamp": "2025-08-03T19:34:59.276000+00:00",
      "name": "b53a_tpu_sketch_generator",
      "input": null,
      "output": {
        "status": "failed",
        "last_code": "import numpy as np\nfrom tflite_runtime.interpreter import Interpreter, load_delegate\nimport cv2\n\n# Phase 1: Setup\nmodel_path  = \"/home/mendel/tinyml_autopilot/models/edgetpu_detect.tflite\"\nlabel_path  = \"/home/mendel/tinyml_autopilot/models/labelmap.txt\"\ninput_path  = \"/home/mendel/tinyml_autopilot/data//sheeps.mp4\"\noutput_path  = \"/home/mendel/tinyml_autopilot/results/sheeps_detections.mp4\"\nconfidence_threshold  = 0.5\n\n# Load labels\nwith open(label_path, 'r') as f:\n    labels = [line.strip() for line in f.readlines()]\n\n# Load Interpreter with EdgeTPU\ntry:\n    interpreter = Interpreter(model_path=model_path,\n                              experimental_delegates=[load_delegate('libedgetpu.so.1.0')])\nexcept Exception as e:\n    print(f\"Failed to load libedgetpu.so.1.0: {e}\")\n    try:\n        interpreter = Interpreter(model_path=model_path,\n                                  experimental_delegates=[load_delegate('/usr/lib/aarch64-linux-gnu/libedgetpu.so.1.0')])\n    except Exception as e:\n        print(f\"Failed to load /usr/lib/aarch64-linux-gnu/libedgetpu.so.1.0: {e}\")\n        raise\n\ninterpreter.allocate_tensors()\n\n# Get Model Details\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\n\nfloating_model = (input_details[0]['dtype'] == np.float32)\n\n# Phase 2: Input Acquisition & Preprocessing Loop\ncap = cv2.VideoCapture(input_path)\nif not cap.isOpened():\n    raise IOError(\"Cannot open video file\")\n\nframe_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\nframe_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\nfps = cap.get(cv2.CAP_PROP_FPS)\n\nout = cv2.VideoWriter(output_path, cv2.VideoWriter_fourcc(*'mp4v'), fps, (frame_width, frame_height))\n\nwhile True:\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    # Preprocess Data\n    input_data = cv2.resize(frame, (input_details[0]['shape'][1], input_details[0]['shape'][2]))\n    input_data = np.expand_dims(input_data, axis=0)\n\n    if floating_model:\n        input_data = (np.float32(input_data) - 127.5) / 127.5\n\n    # Phase 3: Inference\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n    interpreter.invoke()\n\n    # Phase 4: Output Interpretation & Handling Loop\n    num_detections = int(interpreter.get_tensor(output_details[0]['index'])[0])  # Correctly extract the scalar value from the array\n    detection_boxes = interpreter.get_tensor(output_details[1]['index'])[0]\n    detection_classes = interpreter.get_tensor(output_details[2]['index'])[0].astype(int)\n    detection_scores = interpreter.get_tensor(output_details[3]['index'])[0]\n\n    for i in range(num_detections):\n        if detection_scores[i] > confidence_threshold:\n            box = detection_boxes[i]\n            class_id = detection_classes[i]\n            score = detection_scores[i]\n\n            # Scale and clip bounding boxes\n            ymin, xmin, ymax, xmax = box\n            (left, right, top, bottom) = (xmin * frame_width, xmax * frame_width,\n                                          ymin * frame_height, ymax * frame_height)\n\n            cv2.rectangle(frame, (int(left), int(top)), (int(right), int(bottom)), (0, 255, 0), 2)\n            label = f'{labels[class_id]}: {score:.2f}'\n            cv2.putText(frame, label, (int(left), int(top) - 10),\n                        cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n\n    # Write the frame with detections to the output video\n    out.write(frame)\n\n# Release resources\ncap.release()\nout.release()\ncv2.destroyAllWindows()",
        "last_error": "Traceback (most recent call last):\n  File \"script_46939857_1754249883.py\", line 65, in <module>\n    num_detections = int(interpreter.get_tensor(output_details[0]['index'])[0])  # Correctly extract the scalar value from the array\nTypeError: only size-1 arrays can be converted to Python scalars"
      },
      "session_id": "qwen2.5-coder:32b_373e_tpusg_batch",
      "metadata": {
        "num_run": 14
      },
      "tags": [
        "benchmark",
        "qwen2.5-coder:32b",
        "tpu_sketch_generator"
      ],
      "latency": 192.644,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-22-34-59-277768_chatcmpl-6a997167-3acf-4a2e-86cc-0f17151f6847",
          "traceId": "b53a5967",
          "type": "GENERATION",
          "name": "b53a_tpusg_gen_attempt#1",
          "startTime": "2025-08-03T19:34:59.277000+00:00",
          "endTime": "2025-08-03T19:35:24.715000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 25438.0,
          "environment": "default",
          "totalTokens": 2709,
          "costDetails": {},
          "completionTokens": 876,
          "promptTokens": 1833,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-22-35-32-869997_chatcmpl-91cd3132-67e6-4366-a6e5-a29310579589",
          "traceId": "b53a5967",
          "type": "GENERATION",
          "name": "b53a_tpusg_gen_attempt#2",
          "startTime": "2025-08-03T19:35:32.869000+00:00",
          "endTime": "2025-08-03T19:36:05.642000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 32773.0,
          "environment": "default",
          "totalTokens": 3196,
          "costDetails": {},
          "completionTokens": 1148,
          "promptTokens": 2048,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-22-36-13-966291_chatcmpl-4243646e-4910-496a-89e4-faa52613f11e",
          "traceId": "b53a5967",
          "type": "GENERATION",
          "name": "b53a_tpusg_gen_attempt#3",
          "startTime": "2025-08-03T19:36:13.966000+00:00",
          "endTime": "2025-08-03T19:36:44.319000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 30353.0,
          "environment": "default",
          "totalTokens": 3103,
          "costDetails": {},
          "completionTokens": 1055,
          "promptTokens": 2048,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-22-36-52-506453_chatcmpl-21e4ea1c-fb93-41be-a237-b307f33d44a9",
          "traceId": "b53a5967",
          "type": "GENERATION",
          "name": "b53a_tpusg_gen_attempt#4",
          "startTime": "2025-08-03T19:36:52.506000+00:00",
          "endTime": "2025-08-03T19:37:22.892000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 30386.0,
          "environment": "default",
          "totalTokens": 3104,
          "costDetails": {},
          "completionTokens": 1056,
          "promptTokens": 2048,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-22-37-31-001667_chatcmpl-fbce63b4-1e80-4ff8-99fd-9499b1078838",
          "traceId": "b53a5967",
          "type": "GENERATION",
          "name": "b53a_tpusg_gen_attempt#5",
          "startTime": "2025-08-03T19:37:31.001000+00:00",
          "endTime": "2025-08-03T19:38:03.804000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 32803.0,
          "environment": "default",
          "totalTokens": 3197,
          "costDetails": {},
          "completionTokens": 1149,
          "promptTokens": 2048,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "c012729d-28b8-48c6-b6d0-671707e7bb6b",
          "traceId": "b53a5967",
          "type": "SPAN",
          "name": "error_b5_tpusg_failure_signal_tpu_sketch_generator",
          "startTime": "2025-08-03T19:38:11.921000+00:00",
          "level": "ERROR",
          "statusMessage": "Failed. Last error: Traceback (most recent call last):\n  File \"script_46939857_1754249883.py\", line 65, in <module>\n    num_detections = int(interpreter.get_tensor(output_details[0]['index'])[0])  # Correctly extract the scalar value from the array\nTypeError: only size-1 arrays can be converted to Python scalars",
          "calculatedTotalCost": 0.0,
          "environment": "default",
          "totalTokens": 0,
          "costDetails": {},
          "completionTokens": 0,
          "promptTokens": 0,
          "endTime": null,
          "model": null,
          "modelParameters": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null,
          "latency": null
        }
      ],
      "createdAt": "2025-08-03T19:34:59.795Z",
      "environment": "default",
      "updatedAt": "2025-08-03T19:38:17.600Z"
    },
    {
      "id": "0300d23e",
      "timestamp": "2025-08-03T19:31:39.658000+00:00",
      "name": "0300_tpu_sketch_generator",
      "input": null,
      "output": {
        "status": "failed",
        "last_code": "import numpy as np\nfrom tflite_runtime.interpreter import Interpreter, load_delegate\nimport cv2\n\n# Phase 1: Setup\nmodel_path  = \"/home/mendel/tinyml_autopilot/models/edgetpu_detect.tflite\"\nlabel_path  = \"/home/mendel/tinyml_autopilot/models/labelmap.txt\"\ninput_path  = \"/home/mendel/tinyml_autopilot/data//sheeps.mp4\"\noutput_path  = \"/home/mendel/tinyml_autopilot/results/sheeps_detections.mp4\"\nconfidence_threshold  = 0.5\n\n# Load labels\nwith open(label_path, 'r') as f:\n    labels = [line.strip() for line in f.readlines()]\n\n# Load Interpreter with EdgeTPU\ntry:\n    interpreter = Interpreter(model_path=model_path,\n                              experimental_delegates=[load_delegate('libedgetpu.so.1.0')])\nexcept Exception as e:\n    print(f\"Failed to load libedgetpu.so.1.0: {e}\")\n    try:\n        interpreter = Interpreter(model_path=model_path,\n                                  experimental_delegates=[load_delegate('/usr/lib/aarch64-linux-gnu/libedgetpu.so.1.0')])\n    except Exception as e:\n        print(f\"Failed to load /usr/lib/aarch64-linux-gnu/libedgetpu.so.1.0: {e}\")\n        raise\n\ninterpreter.allocate_tensors()\n\n# Get Model Details\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\n\nfloating_model = (input_details[0]['dtype'] == np.float32)\n\n# Phase 2: Input Acquisition & Preprocessing Loop\ncap = cv2.VideoCapture(input_path)\nif not cap.isOpened():\n    raise IOError(\"Cannot open video file\")\n\nframe_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\nframe_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\nfps = cap.get(cv2.CAP_PROP_FPS)\n\nout = cv2.VideoWriter(output_path, cv2.VideoWriter_fourcc(*'mp4v'), fps, (frame_width, frame_height))\n\nwhile True:\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    # Preprocess Data\n    input_data = cv2.resize(frame, (input_details[0]['shape'][1], input_details[0]['shape'][2]))\n    input_data = np.expand_dims(input_data, axis=0)\n\n    if floating_model:\n        input_data = (np.float32(input_data) - 127.5) / 127.5\n\n    # Phase 3: Inference\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n    interpreter.invoke()\n\n    # Phase 4: Output Interpretation & Handling Loop\n    output_data = interpreter.get_tensor(output_details[0]['index'])\n    num_detections = int(interpreter.get_tensor(output_details[1]['index']))  # Ensure we get the scalar value\n    detection_boxes = interpreter.get_tensor(output_details[2]['index'])[0]\n    detection_classes = interpreter.get_tensor(output_details[3]['index'])[0].astype(int)\n    detection_scores = interpreter.get_tensor(output_details[4]['index'])[0]\n\n    for i in range(num_detections):\n        if detection_scores[i] > confidence_threshold:\n            box = detection_boxes[i]\n            class_id = detection_classes[i]\n            score = detection_scores[i]\n\n            # Scale the bounding box coordinates\n            ymin, xmin, ymax, xmax = box\n            (left, right, top, bottom) = (xmin * frame_width, xmax * frame_width,\n                                          ymin * frame_height, ymax * frame_height)\n\n            # Draw the bounding box and label on the frame\n            cv2.rectangle(frame, (int(left), int(top)), (int(right), int(bottom)), (0, 255, 0), 2)\n            label = f'{labels[class_id]}: {score:.2f}'\n            cv2.putText(frame, label, (int(left), int(top) - 10),\n                        cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n\n    # Write the frame to the output video\n    out.write(frame)\n\n# Release resources\ncap.release()\nout.release()\ncv2.destroyAllWindows()",
        "last_error": "Traceback (most recent call last):\n  File \"script_c058c23f_1754249685.py\", line 66, in <module>\n    num_detections = int(interpreter.get_tensor(output_details[1]['index']))  # Ensure we get the scalar value\nTypeError: only size-1 arrays can be converted to Python scalars"
      },
      "session_id": "qwen2.5-coder:32b_373e_tpusg_batch",
      "metadata": {
        "num_run": 13
      },
      "tags": [
        "benchmark",
        "qwen2.5-coder:32b",
        "tpu_sketch_generator"
      ],
      "latency": 193.763,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-22-31-39-659524_chatcmpl-385d7beb-1efa-4ec7-9cfb-30d9db84852d",
          "traceId": "0300d23e",
          "type": "GENERATION",
          "name": "0300_tpusg_gen_attempt#1",
          "startTime": "2025-08-03T19:31:39.659000+00:00",
          "endTime": "2025-08-03T19:32:05.560000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 25901.0,
          "environment": "default",
          "totalTokens": 2726,
          "costDetails": {},
          "completionTokens": 893,
          "promptTokens": 1833,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-22-32-14-075579_chatcmpl-df34d194-f4b2-4bb3-9e1b-fd2786f2d65f",
          "traceId": "0300d23e",
          "type": "GENERATION",
          "name": "0300_tpusg_gen_attempt#2",
          "startTime": "2025-08-03T19:32:14.075000+00:00",
          "endTime": "2025-08-03T19:32:45.755000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 31680.0,
          "environment": "default",
          "totalTokens": 3154,
          "costDetails": {},
          "completionTokens": 1106,
          "promptTokens": 2048,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-22-32-53-938946_chatcmpl-61472ffb-5a23-4631-ac43-4ea6adfe0a5e",
          "traceId": "0300d23e",
          "type": "GENERATION",
          "name": "0300_tpusg_gen_attempt#3",
          "startTime": "2025-08-03T19:32:53.938000+00:00",
          "endTime": "2025-08-03T19:33:25.009000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 31071.0,
          "environment": "default",
          "totalTokens": 3131,
          "costDetails": {},
          "completionTokens": 1083,
          "promptTokens": 2048,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-22-33-33-055585_chatcmpl-3c5d72ff-68cc-43b0-a960-62f62509ca72",
          "traceId": "0300d23e",
          "type": "GENERATION",
          "name": "0300_tpusg_gen_attempt#4",
          "startTime": "2025-08-03T19:33:33.055000+00:00",
          "endTime": "2025-08-03T19:34:05.172000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 32117.0,
          "environment": "default",
          "totalTokens": 3171,
          "costDetails": {},
          "completionTokens": 1123,
          "promptTokens": 2048,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-22-34-13-642618_chatcmpl-01a6fe10-e0d0-4f61-9d55-6ce7b3ec7721",
          "traceId": "0300d23e",
          "type": "GENERATION",
          "name": "0300_tpusg_gen_attempt#5",
          "startTime": "2025-08-03T19:34:13.642000+00:00",
          "endTime": "2025-08-03T19:34:45.321000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 31679.0,
          "environment": "default",
          "totalTokens": 3154,
          "costDetails": {},
          "completionTokens": 1106,
          "promptTokens": 2048,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "7be0c5cb-cf23-4280-84dd-b32b279782ec",
          "traceId": "0300d23e",
          "type": "SPAN",
          "name": "error_03_tpusg_failure_signal_tpu_sketch_generator",
          "startTime": "2025-08-03T19:34:53.422000+00:00",
          "level": "ERROR",
          "statusMessage": "Failed. Last error: Traceback (most recent call last):\n  File \"script_c058c23f_1754249685.py\", line 66, in <module>\n    num_detections = int(interpreter.get_tensor(output_details[1]['index']))  # Ensure we get the scalar value\nTypeError: only size-1 arrays can be converted to Python scalars",
          "calculatedTotalCost": 0.0,
          "environment": "default",
          "totalTokens": 0,
          "costDetails": {},
          "completionTokens": 0,
          "promptTokens": 0,
          "endTime": null,
          "model": null,
          "modelParameters": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null,
          "latency": null
        }
      ],
      "createdAt": "2025-08-03T19:31:40.174Z",
      "environment": "default",
      "updatedAt": "2025-08-03T19:34:58.865Z"
    },
    {
      "id": "7f895d3e",
      "timestamp": "2025-08-03T19:28:23.104000+00:00",
      "name": "7f89_tpu_sketch_generator",
      "input": null,
      "output": {
        "status": "failed",
        "last_code": "import numpy as np\nfrom tflite_runtime.interpreter import Interpreter, load_delegate\nimport cv2\n\n# Phase 1: Setup\nmodel_path  = \"/home/mendel/tinyml_autopilot/models/edgetpu_detect.tflite\"\nlabel_path  = \"/home/mendel/tinyml_autopilot/models/labelmap.txt\"\ninput_path  = \"/home/mendel/tinyml_autopilot/data//sheeps.mp4\"\noutput_path  = \"/home/mendel/tinyml_autopilot/results/sheeps_detections.mp4\"\nconfidence_threshold  = 0.5\n\n# Load labels\nwith open(label_path, 'r') as f:\n    labels = [line.strip() for line in f.readlines()]\n\n# Load Interpreter with EdgeTPU\ntry:\n    interpreter = Interpreter(model_path=model_path,\n                              experimental_delegates=[load_delegate('libedgetpu.so.1.0')])\nexcept Exception as e:\n    print(f\"Failed to load libedgetpu.so.1.0: {e}\")\n    try:\n        interpreter = Interpreter(model_path=model_path,\n                                  experimental_delegates=[load_delegate('/usr/lib/aarch64-linux-gnu/libedgetpu.so.1.0')])\n    except Exception as e:\n        print(f\"Failed to load /usr/lib/aarch64-linux-gnu/libedgetpu.so.1.0: {e}\")\n        raise\n\ninterpreter.allocate_tensors()\n\n# Get Model Details\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\n\nfloating_model = (input_details[0]['dtype'] == np.float32)\n\n# Phase 2: Input Acquisition & Preprocessing Loop\ncap = cv2.VideoCapture(input_path)\nif not cap.isOpened():\n    raise IOError(\"Cannot open video file\")\n\nframe_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\nframe_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\nfps = cap.get(cv2.CAP_PROP_FPS)\n\nout = cv2.VideoWriter(output_path, cv2.VideoWriter_fourcc(*'mp4v'), fps, (frame_width, frame_height))\n\nwhile True:\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    # Preprocess Data\n    input_data = cv2.resize(frame, (input_details[0]['shape'][1], input_details[0]['shape'][2]))\n    input_data = np.expand_dims(input_data, axis=0)\n\n    if floating_model:\n        input_data = (np.float32(input_data) - 127.5) / 127.5\n\n    # Phase 3: Inference\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n    interpreter.invoke()\n\n    # Phase 4: Output Interpretation & Handling Loop\n    output_data = interpreter.get_tensor(output_details[0]['index'])\n    num_detections = int(interpreter.get_tensor(output_details[1]['index']))  # Directly convert to int\n\n    detection_boxes = interpreter.get_tensor(output_details[2]['index'])[0]\n    detection_classes = interpreter.get_tensor(output_details[3]['index'])[0].astype(int)\n    detection_scores = interpreter.get_tensor(output_details[4]['index'])[0]\n\n    for i in range(num_detections):\n        if detection_scores[i] > confidence_threshold:\n            box = detection_boxes[i]\n            class_id = detection_classes[i]\n            score = detection_scores[i]\n\n            # Scale the bounding box coordinates\n            ymin, xmin, ymax, xmax = box\n            (left, right, top, bottom) = (xmin * frame_width, xmax * frame_width,\n                                          ymin * frame_height, ymax * frame_height)\n\n            # Draw the bounding box and label on the frame\n            cv2.rectangle(frame, (int(left), int(top)), (int(right), int(bottom)), (0, 255, 0), 2)\n            label = f'{labels[class_id]}: {score:.2f}'\n            cv2.putText(frame, label, (int(left), int(top) - 10),\n                        cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n\n    # Write the frame to the output video\n    out.write(frame)\n\n# Release resources\ncap.release()\nout.release()\ncv2.destroyAllWindows()",
        "last_error": "Traceback (most recent call last):\n  File \"script_21dbac4c_1754249486.py\", line 66, in <module>\n    num_detections = int(interpreter.get_tensor(output_details[1]['index']))  # Directly convert to int\nTypeError: only size-1 arrays can be converted to Python scalars"
      },
      "session_id": "qwen2.5-coder:32b_373e_tpusg_batch",
      "metadata": {
        "num_run": 12
      },
      "tags": [
        "benchmark",
        "qwen2.5-coder:32b",
        "tpu_sketch_generator"
      ],
      "latency": 191.003,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-22-28-23-105503_chatcmpl-a1612472-3aa5-4cf7-90ee-2324ae5274f2",
          "traceId": "7f895d3e",
          "type": "GENERATION",
          "name": "7f89_tpusg_gen_attempt#1",
          "startTime": "2025-08-03T19:28:23.105000+00:00",
          "endTime": "2025-08-03T19:28:49.066000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 25961.0,
          "environment": "default",
          "totalTokens": 2726,
          "costDetails": {},
          "completionTokens": 893,
          "promptTokens": 1833,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-22-28-57-138562_chatcmpl-658d6826-eb06-4b97-99d4-37492cb6b2f6",
          "traceId": "7f895d3e",
          "type": "GENERATION",
          "name": "7f89_tpusg_gen_attempt#2",
          "startTime": "2025-08-03T19:28:57.138000+00:00",
          "endTime": "2025-08-03T19:29:28.085000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 30947.0,
          "environment": "default",
          "totalTokens": 3126,
          "costDetails": {},
          "completionTokens": 1078,
          "promptTokens": 2048,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-22-29-36-175962_chatcmpl-59bee86f-b954-410d-92a2-6d668d61de10",
          "traceId": "7f895d3e",
          "type": "GENERATION",
          "name": "7f89_tpusg_gen_attempt#3",
          "startTime": "2025-08-03T19:29:36.175000+00:00",
          "endTime": "2025-08-03T19:30:07.251000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 31076.0,
          "environment": "default",
          "totalTokens": 3131,
          "costDetails": {},
          "completionTokens": 1083,
          "promptTokens": 2048,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-22-30-15-509765_chatcmpl-89154319-ff12-48b6-a719-c23c3e8c579b",
          "traceId": "7f895d3e",
          "type": "GENERATION",
          "name": "7f89_tpusg_gen_attempt#4",
          "startTime": "2025-08-03T19:30:15.509000+00:00",
          "endTime": "2025-08-03T19:30:45.423000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 29914.0,
          "environment": "default",
          "totalTokens": 3074,
          "costDetails": {},
          "completionTokens": 1026,
          "promptTokens": 2048,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-22-30-53-576748_chatcmpl-f943ece3-bc41-4bcd-8291-15aec82664f9",
          "traceId": "7f895d3e",
          "type": "GENERATION",
          "name": "7f89_tpusg_gen_attempt#5",
          "startTime": "2025-08-03T19:30:53.576000+00:00",
          "endTime": "2025-08-03T19:31:26.131000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 32555.0,
          "environment": "default",
          "totalTokens": 3169,
          "costDetails": {},
          "completionTokens": 1121,
          "promptTokens": 2048,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "7d6f8775-dcea-4813-9266-fae6d1103917",
          "traceId": "7f895d3e",
          "type": "SPAN",
          "name": "error_7f_tpusg_failure_signal_tpu_sketch_generator",
          "startTime": "2025-08-03T19:31:34.108000+00:00",
          "level": "ERROR",
          "statusMessage": "Failed. Last error: Traceback (most recent call last):\n  File \"script_21dbac4c_1754249486.py\", line 66, in <module>\n    num_detections = int(interpreter.get_tensor(output_details[1]['index']))  # Directly convert to int\nTypeError: only size-1 arrays can be converted to Python scalars",
          "calculatedTotalCost": 0.0,
          "environment": "default",
          "totalTokens": 0,
          "costDetails": {},
          "completionTokens": 0,
          "promptTokens": 0,
          "endTime": null,
          "model": null,
          "modelParameters": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null,
          "latency": null
        }
      ],
      "createdAt": "2025-08-03T19:28:23.621Z",
      "environment": "default",
      "updatedAt": "2025-08-03T19:31:39.318Z"
    },
    {
      "id": "deb17537",
      "timestamp": "2025-08-03T19:24:20.548000+00:00",
      "name": "deb1_tpu_sketch_generator",
      "input": null,
      "output": {
        "status": "success",
        "sketch": "import numpy as np\nfrom tflite_runtime.interpreter import Interpreter, load_delegate\nimport cv2\n\n# Phase 1: Setup\nmodel_path    = \"/home/mendel/tinyml_autopilot/models/edgetpu_detect.tflite\"\nlabel_path    = \"/home/mendel/tinyml_autopilot/models/labelmap.txt\"\ninput_path    = \"/home/mendel/tinyml_autopilot/data//sheeps.mp4\"\noutput_path   = \"/home/mendel/tinyml_autopilot/results/sheeps_detections.mp4\"\nconfidence_threshold  = 0.5\n\n# Load labels\nwith open(label_path, 'r') as f:\n    labels = [line.strip() for line in f.readlines()]\n\n# Load Interpreter with EdgeTPU\ntry:\n    interpreter = Interpreter(model_path=model_path,\n                              experimental_delegates=[load_delegate('libedgetpu.so.1.0')])\nexcept Exception as e:\n    print(f\"Failed to load libedgetpu.so.1.0: {e}\")\n    try:\n        interpreter = Interpreter(model_path=model_path,\n                                  experimental_delegates=[load_delegate('/usr/lib/aarch64-linux-gnu/libedgetpu.so.1.0')])\n    except Exception as e:\n        print(f\"Failed to load /usr/lib/aarch64-linux-gnu/libedgetpu.so.1.0: {e}\")\n        raise\n\ninterpreter.allocate_tensors()\n\n# Get Model Details\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\n\nfloating_model = (input_details[0]['dtype'] == np.float32)\n\n# Phase 2: Input Acquisition & Preprocessing Loop\ncap = cv2.VideoCapture(input_path)\nif not cap.isOpened():\n    raise IOError(\"Cannot open video file\")\n\nframe_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\nframe_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\nfps = cap.get(cv2.CAP_PROP_FPS)\n\nout = cv2.VideoWriter(output_path, cv2.VideoWriter_fourcc(*'mp4v'), fps, (frame_width, frame_height))\n\nwhile True:\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    # Preprocess Data\n    input_data = cv2.resize(frame, (input_details[0]['shape'][1], input_details[0]['shape'][2]))\n    input_data = np.expand_dims(input_data, axis=0)\n\n    if floating_model:\n        input_data = (np.float32(input_data) - 127.5) / 127.5\n\n    # Phase 3: Inference\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n    interpreter.invoke()\n\n    # Phase 4: Output Interpretation & Handling Loop\n    detection_boxes = interpreter.get_tensor(output_details[0]['index'])[0]\n    detection_classes = interpreter.get_tensor(output_details[1]['index'])[0].astype(int)\n    detection_scores = interpreter.get_tensor(output_details[2]['index'])[0]\n\n    num_detections = len(detection_scores)  # Assuming the number of detections is the length of scores\n\n    for i in range(num_detections):\n        if detection_scores[i] > confidence_threshold:\n            box = detection_boxes[i]\n            class_id = detection_classes[i]\n            score = detection_scores[i]\n\n            # Scale and clip bounding boxes\n            ymin, xmin, ymax, xmax = box\n            (left, right, top, bottom) = (xmin * frame_width, xmax * frame_width,\n                                          ymin * frame_height, ymax * frame_height)\n\n            cv2.rectangle(frame, (int(left), int(top)), (int(right), int(bottom)), (0, 255, 0), 2)\n            label = f'{labels[class_id]}: {score:.2f}'\n            cv2.putText(frame, label, (int(left), int(top) - 10),\n                        cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n\n    # Write the frame with detections to the output video\n    out.write(frame)\n\n# Release resources\ncap.release()\nout.release()\ncv2.destroyAllWindows()"
      },
      "session_id": "qwen2.5-coder:32b_373e_tpusg_batch",
      "metadata": {
        "num_run": 11
      },
      "tags": [
        "benchmark",
        "qwen2.5-coder:32b",
        "tpu_sketch_generator"
      ],
      "latency": 184.327,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-22-24-20-550491_chatcmpl-593fe776-760c-4e75-9d02-a9268a71598a",
          "traceId": "deb17537",
          "type": "GENERATION",
          "name": "deb1_tpusg_gen_attempt#1",
          "startTime": "2025-08-03T19:24:20.550000+00:00",
          "endTime": "2025-08-03T19:24:46.075000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 25525.0,
          "environment": "default",
          "totalTokens": 2709,
          "costDetails": {},
          "completionTokens": 876,
          "promptTokens": 1833,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-22-24-54-161573_chatcmpl-daf07afc-df79-44a9-908e-7247d58d9b77",
          "traceId": "deb17537",
          "type": "GENERATION",
          "name": "deb1_tpusg_gen_attempt#2",
          "startTime": "2025-08-03T19:24:54.161000+00:00",
          "endTime": "2025-08-03T19:25:25.840000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 31679.0,
          "environment": "default",
          "totalTokens": 3154,
          "costDetails": {},
          "completionTokens": 1106,
          "promptTokens": 2048,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-22-25-33-930498_chatcmpl-1268e709-7618-45cd-a89c-3aa118bb8e88",
          "traceId": "deb17537",
          "type": "GENERATION",
          "name": "deb1_tpusg_gen_attempt#3",
          "startTime": "2025-08-03T19:25:33.930000+00:00",
          "endTime": "2025-08-03T19:26:05.719000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 31789.0,
          "environment": "default",
          "totalTokens": 3158,
          "costDetails": {},
          "completionTokens": 1110,
          "promptTokens": 2048,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-22-26-14-030726_chatcmpl-562889e6-ec72-42f6-b302-bc0e83bcc62b",
          "traceId": "deb17537",
          "type": "GENERATION",
          "name": "deb1_tpusg_gen_attempt#4",
          "startTime": "2025-08-03T19:26:14.030000+00:00",
          "endTime": "2025-08-03T19:26:44.929000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 30899.0,
          "environment": "default",
          "totalTokens": 3122,
          "costDetails": {},
          "completionTokens": 1074,
          "promptTokens": 2048,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-22-26-53-009431_chatcmpl-6adfd63d-3c1c-46ed-acc4-3f95887c41f5",
          "traceId": "deb17537",
          "type": "GENERATION",
          "name": "deb1_tpusg_gen_attempt#5",
          "startTime": "2025-08-03T19:26:53.009000+00:00",
          "endTime": "2025-08-03T19:27:24.877000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 31868.0,
          "environment": "default",
          "totalTokens": 3161,
          "costDetails": {},
          "completionTokens": 1113,
          "promptTokens": 2048,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        }
      ],
      "createdAt": "2025-08-03T19:24:21.065Z",
      "environment": "default",
      "updatedAt": "2025-08-03T19:28:22.997Z"
    },
    {
      "id": "bc8950af",
      "timestamp": "2025-08-03T19:20:52.945000+00:00",
      "name": "bc89_tpu_sketch_generator",
      "input": null,
      "output": {
        "status": "failed",
        "last_code": "import numpy as np\nfrom tflite_runtime.interpreter import Interpreter, load_delegate\n\n# Phase 1: Setup\nmodel_path  = \"/home/mendel/tinyml_autopilot/models/edgetpu_detect.tflite\"\nlabel_path  = \"/home/mendel/tinyml_autopilot/models/labelmap.txt\"\ninput_path  = \"/home/mendel/tinyml_autopilot/data//sheeps.mp4\"\noutput_path  = \"/home/mendel/tinyml_autopilot/results/sheeps_detections.mp4\"\nconfidence_threshold  = 0.5\n\n# Load labels\nwith open(label_path, 'r') as f:\n    labels = [line.strip() for line in f.readlines()]\n\n# Load Interpreter with EdgeTPU\ntry:\n    interpreter = Interpreter(model_path=model_path,\n                              experimental_delegates=[load_delegate('libedgetpu.so.1.0')])\nexcept Exception as e:\n    print(f\"Failed to load libedgetpu.so.1.0: {e}\")\n    try:\n        interpreter = Interpreter(model_path=model_path,\n                                  experimental_delegates=[load_delegate('/usr/lib/aarch64-linux-gnu/libedgetpu.so.1.0')])\n    except Exception as e:\n        print(f\"Failed to load /usr/lib/aarch64-linux-gnu/libedgetpu.so.1.0: {e}\")\n        raise\n\ninterpreter.allocate_tensors()\n\n# Get Model Details\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\n\nfloating_model = (input_details[0]['dtype'] == np.float32)\n\n# Phase 2: Input Acquisition & Preprocessing Loop\ncap = cv2.VideoCapture(input_path)\nif not cap.isOpened():\n    raise IOError(\"Cannot open video file\")\n\nframe_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\nframe_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\nfps = cap.get(cv2.CAP_PROP_FPS)\n\nout = cv2.VideoWriter(output_path, cv2.VideoWriter_fourcc(*'mp4v'), fps, (frame_width, frame_height))\n\nwhile True:\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    # Preprocess Data\n    input_data = cv2.resize(frame, (input_details[0]['shape'][1], input_details[0]['shape'][2]))\n    input_data = np.expand_dims(input_data, axis=0)\n\n    if floating_model:\n        input_data = (np.float32(input_data) - 127.5) / 127.5\n\n    # Phase 3: Inference\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n    interpreter.invoke()\n\n    # Phase 4: Output Interpretation & Handling Loop\n    num_detections = int(interpreter.get_tensor(output_details[0]['index'])[0])\n    detection_boxes = interpreter.get_tensor(output_details[1]['index'])[0]\n    detection_classes = interpreter.get_tensor(output_details[2]['index'])[0].astype(int)\n    detection_scores = interpreter.get_tensor(output_details[3]['index'])[0]\n\n    for i in range(num_detections):\n        if detection_scores[i] > confidence_threshold:\n            box = detection_boxes[i]\n            class_id = detection_classes[i]\n            score = detection_scores[i]\n\n            # Scale and clip bounding boxes\n            ymin, xmin, ymax, xmax = box\n            (left, right, top, bottom) = (xmin * frame_width, xmax * frame_width,\n                                          ymin * frame_height, ymax * frame_height)\n\n            cv2.rectangle(frame, (int(left), int(top)), (int(right), int(bottom)), (0, 255, 0), 2)\n            label = f'{labels[class_id]}: {score:.2f}'\n            cv2.putText(frame, label, (int(left), int(top) - 10),\n                        cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n\n    # Write the frame to the output video\n    out.write(frame)\n\n# Phase 5: Cleanup\ncap.release()\nout.release()\ncv2.destroyAllWindows()",
        "last_error": "Traceback (most recent call last):\n  File \"script_0128524a_1754249050.py\", line 37, in <module>\n    cap = cv2.VideoCapture(input_path)\nNameError: name 'cv2' is not defined"
      },
      "session_id": "qwen2.5-coder:32b_373e_tpusg_batch",
      "metadata": {
        "num_run": 10
      },
      "tags": [
        "benchmark",
        "qwen2.5-coder:32b",
        "tpu_sketch_generator"
      ],
      "latency": 201.92,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-22-20-52-946024_chatcmpl-b3bdef5e-6627-4e7c-b1f4-70eea56d121e",
          "traceId": "bc8950af",
          "type": "GENERATION",
          "name": "bc89_tpusg_gen_attempt#1",
          "startTime": "2025-08-03T19:20:52.946000+00:00",
          "endTime": "2025-08-03T19:21:18.482000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 25536.0,
          "environment": "default",
          "totalTokens": 2709,
          "costDetails": {},
          "completionTokens": 876,
          "promptTokens": 1833,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-22-21-26-545219_chatcmpl-99e8b04a-756e-46e5-8a0b-f240bb043e5c",
          "traceId": "bc8950af",
          "type": "GENERATION",
          "name": "bc89_tpusg_gen_attempt#2",
          "startTime": "2025-08-03T19:21:26.545000+00:00",
          "endTime": "2025-08-03T19:21:59.506000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 32961.0,
          "environment": "default",
          "totalTokens": 3196,
          "costDetails": {},
          "completionTokens": 1148,
          "promptTokens": 2048,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-22-22-07-600741_chatcmpl-f08700ee-12f2-4b8d-bd38-6647834bfbbc",
          "traceId": "bc8950af",
          "type": "GENERATION",
          "name": "bc89_tpusg_gen_attempt#3",
          "startTime": "2025-08-03T19:22:07.600000+00:00",
          "endTime": "2025-08-03T19:22:37.957000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 30357.0,
          "environment": "default",
          "totalTokens": 3102,
          "costDetails": {},
          "completionTokens": 1054,
          "promptTokens": 2048,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-22-22-46-074909_chatcmpl-c96bcde7-1516-4fd7-aada-3cf7500b8d23",
          "traceId": "bc8950af",
          "type": "GENERATION",
          "name": "bc89_tpusg_gen_attempt#4",
          "startTime": "2025-08-03T19:22:46.074000+00:00",
          "endTime": "2025-08-03T19:23:16.556000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 30482.0,
          "environment": "default",
          "totalTokens": 3104,
          "costDetails": {},
          "completionTokens": 1056,
          "promptTokens": 2048,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-22-23-24-676194_chatcmpl-11a72080-ee71-4258-87ea-3094311064b7",
          "traceId": "bc8950af",
          "type": "GENERATION",
          "name": "bc89_tpusg_gen_attempt#5",
          "startTime": "2025-08-03T19:23:24.676000+00:00",
          "endTime": "2025-08-03T19:24:10.266000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 45590.0,
          "environment": "default",
          "totalTokens": 3676,
          "costDetails": {},
          "completionTokens": 1628,
          "promptTokens": 2048,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "5f722583-ba54-4b75-a87f-8532a534ef55",
          "traceId": "bc8950af",
          "type": "SPAN",
          "name": "error_bc_tpusg_failure_signal_tpu_sketch_generator",
          "startTime": "2025-08-03T19:24:14.866000+00:00",
          "level": "ERROR",
          "statusMessage": "Failed. Last error: Traceback (most recent call last):\n  File \"script_0128524a_1754249050.py\", line 37, in <module>\n    cap = cv2.VideoCapture(input_path)\nNameError: name 'cv2' is not defined",
          "calculatedTotalCost": 0.0,
          "environment": "default",
          "totalTokens": 0,
          "costDetails": {},
          "completionTokens": 0,
          "promptTokens": 0,
          "endTime": null,
          "model": null,
          "modelParameters": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null,
          "latency": null
        }
      ],
      "createdAt": "2025-08-03T19:20:53.461Z",
      "environment": "default",
      "updatedAt": "2025-08-03T19:24:20.229Z"
    },
    {
      "id": "057fe0b1",
      "timestamp": "2025-08-03T19:17:34.414000+00:00",
      "name": "057f_tpu_sketch_generator",
      "input": null,
      "output": {
        "status": "failed",
        "last_code": "import numpy as np\nfrom tflite_runtime.interpreter import Interpreter, load_delegate\nimport cv2\n\n# Phase 1: Setup\nmodel_path  = \"/home/mendel/tinyml_autopilot/models/edgetpu_detect.tflite\"\nlabel_path  = \"/home/mendel/tinyml_autopilot/models/labelmap.txt\"\ninput_path  = \"/home/mendel/tinyml_autopilot/data//sheeps.mp4\"\noutput_path  = \"/home/mendel/tinyml_autopilot/results/sheeps_detections.mp4\"\nconfidence_threshold  = 0.5\n\n# Load labels\nwith open(label_path, 'r') as f:\n    labels = [line.strip() for line in f.readlines()]\n\n# Load Interpreter with EdgeTPU\ntry:\n    interpreter = Interpreter(model_path=model_path,\n                              experimental_delegates=[load_delegate('libedgetpu.so.1.0')])\nexcept Exception as e:\n    print(f\"Failed to load libedgetpu.so.1.0: {e}\")\n    try:\n        interpreter = Interpreter(model_path=model_path,\n                                  experimental_delegates=[load_delegate('/usr/lib/aarch64-linux-gnu/libedgetpu.so.1.0')])\n    except Exception as e:\n        print(f\"Failed to load /usr/lib/aarch64-linux-gnu/libedgetpu.so.1.0: {e}\")\n        raise\n\ninterpreter.allocate_tensors()\n\n# Get Model Details\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\n\nfloating_model = (input_details[0]['dtype'] == np.float32)\n\n# Phase 2: Input Acquisition & Preprocessing Loop\ncap = cv2.VideoCapture(input_path)\nif not cap.isOpened():\n    raise IOError(\"Cannot open video file\")\n\nframe_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\nframe_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\nfps = cap.get(cv2.CAP_PROP_FPS)\n\nout = cv2.VideoWriter(output_path, cv2.VideoWriter_fourcc(*'mp4v'), fps, (frame_width, frame_height))\n\nwhile True:\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    # Preprocess Data\n    input_data = cv2.resize(frame, (input_details[0]['shape'][1], input_details[0]['shape'][2]))\n    input_data = np.expand_dims(input_data, axis=0)\n\n    if floating_model:\n        input_data = (np.float32(input_data) - 127.5) / 127.5\n\n    # Phase 3: Inference\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n    interpreter.invoke()\n\n    # Phase 4: Output Interpretation & Handling Loop\n    output_data = interpreter.get_tensor(output_details[0]['index'])\n    \n    # Ensure num_detections is a scalar value\n    num_detections = int(interpreter.get_tensor(output_details[1]['index'])[0])  # This line was correct, but let's ensure it's handled properly\n\n    detection_boxes = interpreter.get_tensor(output_details[2]['index'])[0]\n    detection_classes = interpreter.get_tensor(output_details[3]['index'])[0].astype(int)\n    detection_scores = interpreter.get_tensor(output_details[4]['index'])[0]\n\n    for i in range(num_detections):\n        if detection_scores[i] > confidence_threshold:\n            box = detection_boxes[i]\n            class_id = detection_classes[i]\n            score = detection_scores[i]\n\n            # Scale and clip bounding boxes\n            ymin, xmin, ymax, xmax = box\n            (left, right, top, bottom) = (xmin * frame_width, xmax * frame_width,\n                                          ymin * frame_height, ymax * frame_height)\n\n            cv2.rectangle(frame, (int(left), int(top)), (int(right), int(bottom)), (0, 255, 0), 2)\n            label = f'{labels[class_id]}: {score:.2f}'\n            cv2.putText(frame, label, (int(left), int(top) - 10),\n                        cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n\n    # Handle Output\n    out.write(frame)\n\n# Phase 5: Cleanup\ncap.release()\nout.release()\ncv2.destroyAllWindows()",
        "last_error": "Traceback (most recent call last):\n  File \"script_e4c73911_1754248838.py\", line 68, in <module>\n    num_detections = int(interpreter.get_tensor(output_details[1]['index'])[0])  # This line was correct, but let's ensure it's handled properly\nTypeError: only size-1 arrays can be converted to Python scalars"
      },
      "session_id": "qwen2.5-coder:32b_373e_tpusg_batch",
      "metadata": {
        "num_run": 9
      },
      "tags": [
        "benchmark",
        "qwen2.5-coder:32b",
        "tpu_sketch_generator"
      ],
      "latency": 192.17,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-22-17-34-415756_chatcmpl-b76149c8-8c2c-436f-b506-653f96d458ac",
          "traceId": "057fe0b1",
          "type": "GENERATION",
          "name": "057f_tpusg_gen_attempt#1",
          "startTime": "2025-08-03T19:17:34.415000+00:00",
          "endTime": "2025-08-03T19:17:59.867000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 25452.0,
          "environment": "default",
          "totalTokens": 2709,
          "costDetails": {},
          "completionTokens": 876,
          "promptTokens": 1833,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-22-18-07-927583_chatcmpl-59b0440d-4d24-4a8f-8971-166100e7ef17",
          "traceId": "057fe0b1",
          "type": "GENERATION",
          "name": "057f_tpusg_gen_attempt#2",
          "startTime": "2025-08-03T19:18:07.927000+00:00",
          "endTime": "2025-08-03T19:18:39.595000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 31668.0,
          "environment": "default",
          "totalTokens": 3154,
          "costDetails": {},
          "completionTokens": 1106,
          "promptTokens": 2048,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-22-18-47-844476_chatcmpl-acf41cf1-6057-4a08-bb2e-49fe64ea5cd5",
          "traceId": "057fe0b1",
          "type": "GENERATION",
          "name": "057f_tpusg_gen_attempt#3",
          "startTime": "2025-08-03T19:18:47.844000+00:00",
          "endTime": "2025-08-03T19:19:19.207000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 31363.0,
          "environment": "default",
          "totalTokens": 3141,
          "costDetails": {},
          "completionTokens": 1093,
          "promptTokens": 2048,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-22-19-27-274704_chatcmpl-58faec9e-3bec-468a-916a-6a83552438b1",
          "traceId": "057fe0b1",
          "type": "GENERATION",
          "name": "057f_tpusg_gen_attempt#4",
          "startTime": "2025-08-03T19:19:27.274000+00:00",
          "endTime": "2025-08-03T19:19:58.636000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 31362.0,
          "environment": "default",
          "totalTokens": 3141,
          "costDetails": {},
          "completionTokens": 1093,
          "promptTokens": 2048,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-22-20-06-743203_chatcmpl-85258ef4-2b18-4892-9406-e33a9fa76245",
          "traceId": "057fe0b1",
          "type": "GENERATION",
          "name": "057f_tpusg_gen_attempt#5",
          "startTime": "2025-08-03T19:20:06.743000+00:00",
          "endTime": "2025-08-03T19:20:38.495000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 31752.0,
          "environment": "default",
          "totalTokens": 3156,
          "costDetails": {},
          "completionTokens": 1108,
          "promptTokens": 2048,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "0c91efca-5be9-4afb-8bfb-f86c90e15a70",
          "traceId": "057fe0b1",
          "type": "SPAN",
          "name": "error_05_tpusg_failure_signal_tpu_sketch_generator",
          "startTime": "2025-08-03T19:20:46.585000+00:00",
          "level": "ERROR",
          "statusMessage": "Failed. Last error: Traceback (most recent call last):\n  File \"script_e4c73911_1754248838.py\", line 68, in <module>\n    num_detections = int(interpreter.get_tensor(output_details[1]['index'])[0])  # This line was correct, but let's ensure it's handled properly\nTypeError: only size-1 arrays can be converted to Python scalars",
          "calculatedTotalCost": 0.0,
          "environment": "default",
          "totalTokens": 0,
          "costDetails": {},
          "completionTokens": 0,
          "promptTokens": 0,
          "endTime": null,
          "model": null,
          "modelParameters": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null,
          "latency": null
        }
      ],
      "createdAt": "2025-08-03T19:17:34.932Z",
      "environment": "default",
      "updatedAt": "2025-08-03T19:20:52.177Z"
    },
    {
      "id": "0414d6c1",
      "timestamp": "2025-08-03T19:14:11.370000+00:00",
      "name": "0414_tpu_sketch_generator",
      "input": null,
      "output": {
        "status": "failed",
        "last_code": "import numpy as np\nfrom tflite_runtime.interpreter import Interpreter, load_delegate\nimport cv2\n\n# Phase 1: Setup\nmodel_path  = \"/home/mendel/tinyml_autopilot/models/edgetpu_detect.tflite\"\nlabel_path  = \"/home/mendel/tinyml_autopilot/models/labelmap.txt\"\ninput_path  = \"/home/mendel/tinyml_autopilot/data//sheeps.mp4\"\noutput_path  = \"/home/mendel/tinyml_autopilot/results/sheeps_detections.mp4\"\nconfidence_threshold  = 0.5\n\n# Load labels\nwith open(label_path, 'r') as f:\n    labels = [line.strip() for line in f.readlines()]\n\n# Load Interpreter with EdgeTPU\ntry:\n    interpreter = Interpreter(model_path=model_path,\n                              experimental_delegates=[load_delegate('libedgetpu.so.1.0')])\nexcept Exception as e:\n    print(f\"Failed to load libedgetpu.so.1.0: {e}\")\n    try:\n        interpreter = Interpreter(model_path=model_path,\n                                  experimental_delegates=[load_delegate('/usr/lib/aarch64-linux-gnu/libedgetpu.so.1.0')])\n    except Exception as e:\n        print(f\"Failed to load /usr/lib/aarch64-linux-gnu/libedgetpu.so.1.0: {e}\")\n        raise\n\ninterpreter.allocate_tensors()\n\n# Get Model Details\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\n\nfloating_model = (input_details[0]['dtype'] == np.float32)\n\n# Phase 2: Input Acquisition & Preprocessing Loop\ncap = cv2.VideoCapture(input_path)\nif not cap.isOpened():\n    raise IOError(\"Cannot open video file\")\n\nframe_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\nframe_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\nfps = cap.get(cv2.CAP_PROP_FPS)\n\nout = cv2.VideoWriter(output_path, cv2.VideoWriter_fourcc(*'mp4v'), fps, (frame_width, frame_height))\n\nwhile True:\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    # Preprocess Data\n    input_data = cv2.resize(frame, (input_details[0]['shape'][1], input_details[0]['shape'][2]))\n    input_data = np.expand_dims(input_data, axis=0)\n\n    if floating_model:\n        input_data = (np.float32(input_data) - 127.5) / 127.5\n\n    # Phase 3: Inference\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n    interpreter.invoke()\n\n    # Phase 4: Output Interpretation & Handling Loop\n    output_data = interpreter.get_tensor(output_details[0]['index'])\n    detection_boxes = interpreter.get_tensor(output_details[1]['index'])[0]\n    detection_classes = interpreter.get_tensor(output_details[2]['index'])[0].astype(int)\n    detection_scores = interpreter.get_tensor(output_details[3]['index'])[0]\n\n    # Assuming the first output tensor contains the number of detections\n    num_detections = int(output_data[0])  # Correctly extract the scalar value from the array\n\n    for i in range(num_detections):\n        if detection_scores[i] > confidence_threshold:\n            box = detection_boxes[i]\n            class_id = detection_classes[i]\n            score = detection_scores[i]\n\n            # Scale and clip bounding boxes\n            ymin, xmin, ymax, xmax = box\n            (left, right, top, bottom) = (xmin * frame_width, xmax * frame_width,\n                                          ymin * frame_height, ymax * frame_height)\n\n            cv2.rectangle(frame, (int(left), int(top)), (int(right), int(bottom)), (0, 255, 0), 2)\n            label = f'{labels[class_id]}: {score:.2f}'\n            cv2.putText(frame, label, (int(left), int(top) - 10),\n                        cv2.FONT_HERSHEY_SIMPLEX, 0.9, (36, 255, 12), 2)\n\n    # Write the frame with detections to the output video\n    out.write(frame)\n\n# Release resources\ncap.release()\nout.release()\ncv2.destroyAllWindows()",
        "last_error": "Traceback (most recent call last):\n  File \"script_940a805a_1754248640.py\", line 71, in <module>\n    num_detections = int(output_data[0])  # Correctly extract the scalar value from the array\nTypeError: only size-1 arrays can be converted to Python scalars"
      },
      "session_id": "qwen2.5-coder:32b_373e_tpusg_batch",
      "metadata": {
        "num_run": 8
      },
      "tags": [
        "benchmark",
        "qwen2.5-coder:32b",
        "tpu_sketch_generator"
      ],
      "latency": 197.426,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-22-14-11-371927_chatcmpl-9cc52a17-e630-4d79-8aa0-e37c1bdb1a05",
          "traceId": "0414d6c1",
          "type": "GENERATION",
          "name": "0414_tpusg_gen_attempt#1",
          "startTime": "2025-08-03T19:14:11.371000+00:00",
          "endTime": "2025-08-03T19:14:36.821000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 25450.0,
          "environment": "default",
          "totalTokens": 2709,
          "costDetails": {},
          "completionTokens": 876,
          "promptTokens": 1833,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-22-14-44-910631_chatcmpl-d333db95-bd28-4bc8-a89f-c542e1a4a75f",
          "traceId": "0414d6c1",
          "type": "GENERATION",
          "name": "0414_tpusg_gen_attempt#2",
          "startTime": "2025-08-03T19:14:44.910000+00:00",
          "endTime": "2025-08-03T19:15:18.351000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 33441.0,
          "environment": "default",
          "totalTokens": 3196,
          "costDetails": {},
          "completionTokens": 1148,
          "promptTokens": 2048,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-22-15-26-416102_chatcmpl-f7a2868a-a156-4d96-9d09-c6fe865fab15",
          "traceId": "0414d6c1",
          "type": "GENERATION",
          "name": "0414_tpusg_gen_attempt#3",
          "startTime": "2025-08-03T19:15:26.416000+00:00",
          "endTime": "2025-08-03T19:15:59.020000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 32604.0,
          "environment": "default",
          "totalTokens": 3177,
          "costDetails": {},
          "completionTokens": 1129,
          "promptTokens": 2048,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-22-16-07-094149_chatcmpl-47c4e83c-3542-4e12-8c26-3baf94cbcd29",
          "traceId": "0414d6c1",
          "type": "GENERATION",
          "name": "0414_tpusg_gen_attempt#4",
          "startTime": "2025-08-03T19:16:07.094000+00:00",
          "endTime": "2025-08-03T19:16:38.597000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 31503.0,
          "environment": "default",
          "totalTokens": 3147,
          "costDetails": {},
          "completionTokens": 1099,
          "promptTokens": 2048,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-22-16-46-887524_chatcmpl-3b9a2050-7cca-4541-95ca-bf7929cd3287",
          "traceId": "0414d6c1",
          "type": "GENERATION",
          "name": "0414_tpusg_gen_attempt#5",
          "startTime": "2025-08-03T19:16:46.887000+00:00",
          "endTime": "2025-08-03T19:17:20.692000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 33805.0,
          "environment": "default",
          "totalTokens": 3235,
          "costDetails": {},
          "completionTokens": 1187,
          "promptTokens": 2048,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "e2e2fc01-bd0c-4fe8-8d00-b64087c51e69",
          "traceId": "0414d6c1",
          "type": "SPAN",
          "name": "error_04_tpusg_failure_signal_tpu_sketch_generator",
          "startTime": "2025-08-03T19:17:28.797000+00:00",
          "level": "ERROR",
          "statusMessage": "Failed. Last error: Traceback (most recent call last):\n  File \"script_940a805a_1754248640.py\", line 71, in <module>\n    num_detections = int(output_data[0])  # Correctly extract the scalar value from the array\nTypeError: only size-1 arrays can be converted to Python scalars",
          "calculatedTotalCost": 0.0,
          "environment": "default",
          "totalTokens": 0,
          "costDetails": {},
          "completionTokens": 0,
          "promptTokens": 0,
          "endTime": null,
          "model": null,
          "modelParameters": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null,
          "latency": null
        }
      ],
      "createdAt": "2025-08-03T19:14:11.886Z",
      "environment": "default",
      "updatedAt": "2025-08-03T19:17:34.171Z"
    },
    {
      "id": "cbf5684e",
      "timestamp": "2025-08-03T19:10:51.831000+00:00",
      "name": "cbf5_tpu_sketch_generator",
      "input": null,
      "output": {
        "status": "failed",
        "last_code": "import numpy as np\nfrom tflite_runtime.interpreter import Interpreter, load_delegate\n\n# Phase 1: Setup\nmodel_path  = \"/home/mendel/tinyml_autopilot/models/edgetpu_detect.tflite\"\nlabel_path  = \"/home/mendel/tinyml_autopilot/models/labelmap.txt\"\ninput_path  = \"/home/mendel/tinyml_autopilot/data//sheeps.mp4\"\noutput_path  = \"/home/mendel/tinyml_autopilot/results/sheeps_detections.mp4\"\nconfidence_threshold  = 0.5\n\n# Load labels\nwith open(label_path, 'r') as f:\n    labels = [line.strip() for line in f.readlines()]\n\n# Load Interpreter with EdgeTPU\ntry:\n    interpreter = Interpreter(model_path=model_path,\n                              experimental_delegates=[load_delegate('libedgetpu.so.1.0')])\nexcept Exception as e:\n    print(f\"Failed to load libedgetpu.so.1.0: {e}\")\n    try:\n        interpreter = Interpreter(model_path=model_path,\n                                  experimental_delegates=[load_delegate('/usr/lib/aarch64-linux-gnu/libedgetpu.so.1.0')])\n    except Exception as e:\n        print(f\"Failed to load /usr/lib/aarch64-linux-gnu/libedgetpu.so.1.0: {e}\")\n        raise\n\ninterpreter.allocate_tensors()\n\n# Get Model Details\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\n\nfloating_model = (input_details[0]['dtype'] == np.float32)\n\n# Phase 2: Input Acquisition & Preprocessing Loop\nimport cv2\n\ncap = cv2.VideoCapture(input_path)\nif not cap.isOpened():\n    raise IOError(\"Cannot open video file\")\n\nframe_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\nframe_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\nfps = cap.get(cv2.CAP_PROP_FPS)\n\nout = cv2.VideoWriter(output_path, cv2.VideoWriter_fourcc(*'mp4v'), fps, (frame_width, frame_height))\n\nwhile True:\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    # Preprocess Data\n    input_data = cv2.resize(frame, (input_details[0]['shape'][1], input_details[0]['shape'][2]))\n    input_data = np.expand_dims(input_data, axis=0)\n\n    if floating_model:\n        input_data = (np.float32(input_data) - 127.5) / 127.5\n\n    # Phase 3: Inference\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n    interpreter.invoke()\n\n    # Phase 4: Output Interpretation & Handling Loop\n    output_data = interpreter.get_tensor(output_details[0]['index'])\n    num_detections = int(interpreter.get_tensor(output_details[1]['index'])[0])  # Access the first element of the array\n    detection_boxes = interpreter.get_tensor(output_details[2]['index'])[0]\n    detection_classes = interpreter.get_tensor(output_details[3]['index'])[0].astype(int)\n    detection_scores = interpreter.get_tensor(output_details[4]['index'])[0]\n\n    for i in range(num_detections):\n        if detection_scores[i] > confidence_threshold:\n            box = detection_boxes[i]\n            class_id = detection_classes[i]\n            score = detection_scores[i]\n\n            # Scale and clip bounding boxes\n            ymin, xmin, ymax, xmax = box\n            (left, right, top, bottom) = (xmin * frame_width, xmax * frame_width,\n                                          ymin * frame_height, ymax * frame_height)\n\n            cv2.rectangle(frame, (int(left), int(top)), (int(right), int(bottom)), (0, 255, 0), 2)\n            label = f'{labels[class_id]}: {score:.2f}'\n            cv2.putText(frame, label, (int(left), int(top) - 10),\n                        cv2.FONT_HERSHEY_SIMPLEX, 0.9, (36, 255, 12), 2)\n\n    # Write the frame with bounding boxes to the output video\n    out.write(frame)\n\n# Release resources\ncap.release()\nout.release()\ncv2.destroyAllWindows()",
        "last_error": "Traceback (most recent call last):\n  File \"script_b70fb865_1754248437.py\", line 67, in <module>\n    num_detections = int(interpreter.get_tensor(output_details[1]['index'])[0])  # Access the first element of the array\nTypeError: only size-1 arrays can be converted to Python scalars"
      },
      "session_id": "qwen2.5-coder:32b_373e_tpusg_batch",
      "metadata": {
        "num_run": 7
      },
      "tags": [
        "benchmark",
        "qwen2.5-coder:32b",
        "tpu_sketch_generator"
      ],
      "latency": 193.384,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-22-10-51-832493_chatcmpl-0b7c004f-d68d-4d08-affb-3a7e79636a99",
          "traceId": "cbf5684e",
          "type": "GENERATION",
          "name": "cbf5_tpusg_gen_attempt#1",
          "startTime": "2025-08-03T19:10:51.832000+00:00",
          "endTime": "2025-08-03T19:11:17.271000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 25439.0,
          "environment": "default",
          "totalTokens": 2709,
          "costDetails": {},
          "completionTokens": 876,
          "promptTokens": 1833,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-22-11-25-407968_chatcmpl-90c7ee00-72b0-405c-8776-6b8ec93be99c",
          "traceId": "cbf5684e",
          "type": "GENERATION",
          "name": "cbf5_tpusg_gen_attempt#2",
          "startTime": "2025-08-03T19:11:25.407000+00:00",
          "endTime": "2025-08-03T19:11:57.395000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 31988.0,
          "environment": "default",
          "totalTokens": 3166,
          "costDetails": {},
          "completionTokens": 1118,
          "promptTokens": 2048,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-22-12-05-643443_chatcmpl-f3f21feb-4443-440e-baa8-56a75e9ba000",
          "traceId": "cbf5684e",
          "type": "GENERATION",
          "name": "cbf5_tpusg_gen_attempt#3",
          "startTime": "2025-08-03T19:12:05.643000+00:00",
          "endTime": "2025-08-03T19:12:38.598000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 32955.0,
          "environment": "default",
          "totalTokens": 3202,
          "costDetails": {},
          "completionTokens": 1154,
          "promptTokens": 2048,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-22-12-46-695776_chatcmpl-dc52c73d-1dcd-49cc-a731-92fe3b2c9da0",
          "traceId": "cbf5684e",
          "type": "GENERATION",
          "name": "cbf5_tpusg_gen_attempt#4",
          "startTime": "2025-08-03T19:12:46.695000+00:00",
          "endTime": "2025-08-03T19:13:18.226000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 31531.0,
          "environment": "default",
          "totalTokens": 3148,
          "costDetails": {},
          "completionTokens": 1100,
          "promptTokens": 2048,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-22-13-26-293589_chatcmpl-4fec8dc7-e689-4ac1-bab7-73a74f1a65e2",
          "traceId": "cbf5684e",
          "type": "GENERATION",
          "name": "cbf5_tpusg_gen_attempt#5",
          "startTime": "2025-08-03T19:13:26.293000+00:00",
          "endTime": "2025-08-03T19:13:57.130000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 30837.0,
          "environment": "default",
          "totalTokens": 3121,
          "costDetails": {},
          "completionTokens": 1073,
          "promptTokens": 2048,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "85467c5b-3727-4776-ab5f-802a1ae83172",
          "traceId": "cbf5684e",
          "type": "SPAN",
          "name": "error_cb_tpusg_failure_signal_tpu_sketch_generator",
          "startTime": "2025-08-03T19:14:05.216000+00:00",
          "level": "ERROR",
          "statusMessage": "Failed. Last error: Traceback (most recent call last):\n  File \"script_b70fb865_1754248437.py\", line 67, in <module>\n    num_detections = int(interpreter.get_tensor(output_details[1]['index'])[0])  # Access the first element of the array\nTypeError: only size-1 arrays can be converted to Python scalars",
          "calculatedTotalCost": 0.0,
          "environment": "default",
          "totalTokens": 0,
          "costDetails": {},
          "completionTokens": 0,
          "promptTokens": 0,
          "endTime": null,
          "model": null,
          "modelParameters": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null,
          "latency": null
        }
      ],
      "createdAt": "2025-08-03T19:10:52.349Z",
      "environment": "default",
      "updatedAt": "2025-08-03T19:14:10.541Z"
    },
    {
      "id": "edc25797",
      "timestamp": "2025-08-03T19:07:29.300000+00:00",
      "name": "edc2_tpu_sketch_generator",
      "input": null,
      "output": {
        "status": "failed",
        "last_code": "import numpy as np\nfrom tflite_runtime.interpreter import Interpreter, load_delegate\nimport cv2\n\n# Phase 1: Setup\nmodel_path  = \"/home/mendel/tinyml_autopilot/models/edgetpu_detect.tflite\"\nlabel_path  = \"/home/mendel/tinyml_autopilot/models/labelmap.txt\"\ninput_path  = \"/home/mendel/tinyml_autopilot/data//sheeps.mp4\"\noutput_path  = \"/home/mendel/tinyml_autopilot/results/sheeps_detections.mp4\"\nconfidence_threshold  = 0.5\n\n# Load labels\nwith open(label_path, 'r') as f:\n    labels = [line.strip() for line in f.readlines()]\n\n# Load Interpreter with EdgeTPU\ntry:\n    interpreter = Interpreter(model_path=model_path,\n                              experimental_delegates=[load_delegate('libedgetpu.so.1.0')])\nexcept Exception as e:\n    print(f\"Failed to load libedgetpu.so.1.0: {e}\")\n    try:\n        interpreter = Interpreter(model_path=model_path,\n                                  experimental_delegates=[load_delegate('/usr/lib/aarch64-linux-gnu/libedgetpu.so.1.0')])\n    except Exception as e:\n        print(f\"Failed to load /usr/lib/aarch64-linux-gnu/libedgetpu.so.1.0: {e}\")\n        raise\n\ninterpreter.allocate_tensors()\n\n# Get Model Details\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\n\nfloating_model = (input_details[0]['dtype'] == np.float32)\n\n# Phase 2: Input Acquisition & Preprocessing Loop\ncap = cv2.VideoCapture(input_path)\nif not cap.isOpened():\n    raise IOError(\"Cannot open video file\")\n\nframe_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\nframe_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\nfps = cap.get(cv2.CAP_PROP_FPS)\n\nout = cv2.VideoWriter(output_path, cv2.VideoWriter_fourcc(*'mp4v'), fps, (frame_width, frame_height))\n\nwhile True:\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    # Preprocess Data\n    input_data = cv2.resize(frame, (input_details[0]['shape'][1], input_details[0]['shape'][2]))\n    input_data = np.expand_dims(input_data, axis=0)\n\n    if floating_model:\n        input_data = (np.float32(input_data) - 127.5) / 127.5\n\n    # Phase 3: Inference\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n    interpreter.invoke()\n\n    # Phase 4: Output Interpretation & Handling Loop\n    output_data = interpreter.get_tensor(output_details[0]['index'])\n    num_detections = int(interpreter.get_tensor(output_details[1]['index']))  # Correctly access the number of detections\n    detection_boxes = interpreter.get_tensor(output_details[2]['index'])[0]\n    detection_classes = interpreter.get_tensor(output_details[3]['index'])[0].astype(int)\n    detection_scores = interpreter.get_tensor(output_details[4]['index'])[0]\n\n    for i in range(num_detections):\n        if detection_scores[i] > confidence_threshold:\n            box = detection_boxes[i]\n            class_id = detection_classes[i]\n            score = detection_scores[i]\n\n            # Scale and clip bounding boxes\n            ymin, xmin, ymax, xmax = box\n            (left, right, top, bottom) = (xmin * frame_width, xmax * frame_width,\n                                          ymin * frame_height, ymax * frame_height)\n\n            cv2.rectangle(frame, (int(left), int(top)), (int(right), int(bottom)), (0, 255, 0), 2)\n            label = f'{labels[class_id]}: {score:.2f}'\n            cv2.putText(frame, label, (int(left), int(top) - 10),\n                        cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n\n    # Handle Output\n    out.write(frame)\n\n# Phase 5: Cleanup\ncap.release()\nout.release()\ncv2.destroyAllWindows()",
        "last_error": "Traceback (most recent call last):\n  File \"script_929ac7d9_1754248237.py\", line 66, in <module>\n    num_detections = int(interpreter.get_tensor(output_details[1]['index']))  # Correctly access the number of detections\nTypeError: only size-1 arrays can be converted to Python scalars"
      },
      "session_id": "qwen2.5-coder:32b_373e_tpusg_batch",
      "metadata": {
        "num_run": 6
      },
      "tags": [
        "benchmark",
        "qwen2.5-coder:32b",
        "tpu_sketch_generator"
      ],
      "latency": 196.41,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-22-07-29-302034_chatcmpl-e567640d-4306-4880-af64-b1ffd087e419",
          "traceId": "edc25797",
          "type": "GENERATION",
          "name": "edc2_tpusg_gen_attempt#1",
          "startTime": "2025-08-03T19:07:29.302000+00:00",
          "endTime": "2025-08-03T19:07:54.853000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 25551.0,
          "environment": "default",
          "totalTokens": 2709,
          "costDetails": {},
          "completionTokens": 876,
          "promptTokens": 1833,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-22-08-02-945241_chatcmpl-a9f0f877-a37a-4497-a7b7-678540f0ebea",
          "traceId": "edc25797",
          "type": "GENERATION",
          "name": "edc2_tpusg_gen_attempt#2",
          "startTime": "2025-08-03T19:08:02.945000+00:00",
          "endTime": "2025-08-03T19:08:34.944000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 31999.0,
          "environment": "default",
          "totalTokens": 3166,
          "costDetails": {},
          "completionTokens": 1118,
          "promptTokens": 2048,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-22-08-43-126914_chatcmpl-23ad17e0-42ea-48ec-a69a-725b3d1cbe55",
          "traceId": "edc25797",
          "type": "GENERATION",
          "name": "edc2_tpusg_gen_attempt#3",
          "startTime": "2025-08-03T19:08:43.126000+00:00",
          "endTime": "2025-08-03T19:09:16.113000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 32987.0,
          "environment": "default",
          "totalTokens": 3205,
          "costDetails": {},
          "completionTokens": 1157,
          "promptTokens": 2048,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-22-09-24-261158_chatcmpl-464a519a-6e6b-4fd7-8993-5d721793a37f",
          "traceId": "edc25797",
          "type": "GENERATION",
          "name": "edc2_tpusg_gen_attempt#4",
          "startTime": "2025-08-03T19:09:24.261000+00:00",
          "endTime": "2025-08-03T19:09:56.608000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 32347.0,
          "environment": "default",
          "totalTokens": 3180,
          "costDetails": {},
          "completionTokens": 1132,
          "promptTokens": 2048,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-22-10-04-653806_chatcmpl-5d7a69af-efcb-4170-bb1e-43302db02e4d",
          "traceId": "edc25797",
          "type": "GENERATION",
          "name": "edc2_tpusg_gen_attempt#5",
          "startTime": "2025-08-03T19:10:04.653000+00:00",
          "endTime": "2025-08-03T19:10:37.641000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 32988.0,
          "environment": "default",
          "totalTokens": 3204,
          "costDetails": {},
          "completionTokens": 1156,
          "promptTokens": 2048,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "5a35c2cd-af1f-41e2-90d2-41e77905a8cf",
          "traceId": "edc25797",
          "type": "SPAN",
          "name": "error_ed_tpusg_failure_signal_tpu_sketch_generator",
          "startTime": "2025-08-03T19:10:45.712000+00:00",
          "level": "ERROR",
          "statusMessage": "Failed. Last error: Traceback (most recent call last):\n  File \"script_929ac7d9_1754248237.py\", line 66, in <module>\n    num_detections = int(interpreter.get_tensor(output_details[1]['index']))  # Correctly access the number of detections\nTypeError: only size-1 arrays can be converted to Python scalars",
          "calculatedTotalCost": 0.0,
          "environment": "default",
          "totalTokens": 0,
          "costDetails": {},
          "completionTokens": 0,
          "promptTokens": 0,
          "endTime": null,
          "model": null,
          "modelParameters": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null,
          "latency": null
        }
      ],
      "createdAt": "2025-08-03T19:07:29.816Z",
      "environment": "default",
      "updatedAt": "2025-08-03T19:10:51.027Z"
    },
    {
      "id": "aadc63d1",
      "timestamp": "2025-08-03T19:04:08.739000+00:00",
      "name": "aadc_tpu_sketch_generator",
      "input": null,
      "output": {
        "status": "failed",
        "last_code": "import numpy as np\nfrom tflite_runtime.interpreter import Interpreter, load_delegate\nimport cv2\n\n# Phase 1: Setup\nmodel_path  = \"/home/mendel/tinyml_autopilot/models/edgetpu_detect.tflite\"\nlabel_path  = \"/home/mendel/tinyml_autopilot/models/labelmap.txt\"\ninput_path  = \"/home/mendel/tinyml_autopilot/data//sheeps.mp4\"\noutput_path  = \"/home/mendel/tinyml_autopilot/results/sheeps_detections.mp4\"\nconfidence_threshold  = 0.5\n\n# Load labels\nwith open(label_path, 'r') as f:\n    labels = [line.strip() for line in f.readlines()]\n\n# Load Interpreter with EdgeTPU\ntry:\n    interpreter = Interpreter(model_path=model_path,\n                              experimental_delegates=[load_delegate('libedgetpu.so.1.0')])\nexcept Exception as e:\n    print(f\"Failed to load libedgetpu.so.1.0: {e}\")\n    try:\n        interpreter = Interpreter(model_path=model_path,\n                                  experimental_delegates=[load_delegate('/usr/lib/aarch64-linux-gnu/libedgetpu.so.1.0')])\n    except Exception as e:\n        print(f\"Failed to load /usr/lib/aarch64-linux-gnu/libedgetpu.so.1.0: {e}\")\n        raise\n\ninterpreter.allocate_tensors()\n\n# Get Model Details\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\n\nfloating_model = (input_details[0]['dtype'] == np.float32)\n\n# Phase 2: Input Acquisition & Preprocessing Loop\ncap = cv2.VideoCapture(input_path)\nif not cap.isOpened():\n    raise IOError(\"Cannot open video file\")\n\nframe_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\nframe_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\nfps = cap.get(cv2.CAP_PROP_FPS)\n\nout = cv2.VideoWriter(output_path, cv2.VideoWriter_fourcc(*'mp4v'), fps, (frame_width, frame_height))\n\nwhile True:\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    # Preprocess Data\n    input_data = cv2.resize(frame, (input_details[0]['shape'][1], input_details[0]['shape'][2]))\n    input_data = np.expand_dims(input_data, axis=0)\n\n    if floating_model:\n        input_data = (np.float32(input_data) - 127.5) / 127.5\n\n    # Phase 3: Inference\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n    interpreter.invoke()\n\n    # Phase 4: Output Interpretation & Handling Loop\n    output_data = interpreter.get_tensor(output_details[0]['index'])\n    \n    # Ensure the number of detections is correctly extracted\n    num_detections = int(interpreter.get_tensor(output_details[1]['index']))  # Correctly extract the number of detections\n    \n    detection_boxes = interpreter.get_tensor(output_details[2]['index'])\n    detection_classes = interpreter.get_tensor(output_details[3]['index']).astype(int)\n    detection_scores = interpreter.get_tensor(output_details[4]['index'])\n\n    for i in range(num_detections):\n        if detection_scores[i] > confidence_threshold:\n            box = detection_boxes[i]\n            class_id = detection_classes[i]\n            score = detection_scores[i]\n\n            # Scale the bounding box coordinates\n            ymin, xmin, ymax, xmax = box\n            (left, right, top, bottom) = (xmin * frame_width, xmax * frame_width,\n                                          ymin * frame_height, ymax * frame_height)\n\n            # Draw the bounding box and label on the frame\n            cv2.rectangle(frame, (int(left), int(top)), (int(right), int(bottom)), (0, 255, 0), 2)\n            label = f'{labels[class_id]}: {score:.2f}'\n            cv2.putText(frame, label, (int(left), int(top) - 10),\n                        cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n\n    # Write the frame to the output video\n    out.write(frame)\n\n# Release resources\ncap.release()\nout.release()\ncv2.destroyAllWindows()",
        "last_error": "Traceback (most recent call last):\n  File \"script_60fe2de7_1754248035.py\", line 68, in <module>\n    num_detections = int(interpreter.get_tensor(output_details[1]['index']))  # Correctly extract the number of detections\nTypeError: only size-1 arrays can be converted to Python scalars"
      },
      "session_id": "qwen2.5-coder:32b_373e_tpusg_batch",
      "metadata": {
        "num_run": 5
      },
      "tags": [
        "benchmark",
        "qwen2.5-coder:32b",
        "tpu_sketch_generator"
      ],
      "latency": 194.894,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-22-04-08-741229_chatcmpl-ce87fe7d-2f90-4eab-b64f-6c21a6a98623",
          "traceId": "aadc63d1",
          "type": "GENERATION",
          "name": "aadc_tpusg_gen_attempt#1",
          "startTime": "2025-08-03T19:04:08.741000+00:00",
          "endTime": "2025-08-03T19:04:34.687000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 25946.0,
          "environment": "default",
          "totalTokens": 2726,
          "costDetails": {},
          "completionTokens": 893,
          "promptTokens": 1833,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-22-04-43-023973_chatcmpl-56c5141b-7715-4a80-9b1d-512e21bfd42c",
          "traceId": "aadc63d1",
          "type": "GENERATION",
          "name": "aadc_tpusg_gen_attempt#2",
          "startTime": "2025-08-03T19:04:43.023000+00:00",
          "endTime": "2025-08-03T19:05:14.269000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 31246.0,
          "environment": "default",
          "totalTokens": 3138,
          "costDetails": {},
          "completionTokens": 1090,
          "promptTokens": 2048,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-22-05-22-323494_chatcmpl-4438bb25-67b3-4a71-b9e4-76627beac997",
          "traceId": "aadc63d1",
          "type": "GENERATION",
          "name": "aadc_tpusg_gen_attempt#3",
          "startTime": "2025-08-03T19:05:22.323000+00:00",
          "endTime": "2025-08-03T19:05:55.719000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 33396.0,
          "environment": "default",
          "totalTokens": 3219,
          "costDetails": {},
          "completionTokens": 1171,
          "promptTokens": 2048,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-22-06-03-825295_chatcmpl-db35b57a-2c80-49d4-9a25-8d347d90c7bf",
          "traceId": "aadc63d1",
          "type": "GENERATION",
          "name": "aadc_tpusg_gen_attempt#4",
          "startTime": "2025-08-03T19:06:03.825000+00:00",
          "endTime": "2025-08-03T19:06:35.239000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 31414.0,
          "environment": "default",
          "totalTokens": 3129,
          "costDetails": {},
          "completionTokens": 1081,
          "promptTokens": 2048,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-22-06-43-307168_chatcmpl-63db460d-f3aa-49dd-8ca9-9d14c5233660",
          "traceId": "aadc63d1",
          "type": "GENERATION",
          "name": "aadc_tpusg_gen_attempt#5",
          "startTime": "2025-08-03T19:06:43.307000+00:00",
          "endTime": "2025-08-03T19:07:15.499000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 32192.0,
          "environment": "default",
          "totalTokens": 3165,
          "costDetails": {},
          "completionTokens": 1117,
          "promptTokens": 2048,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "04c45175-be1e-4663-9ce9-671bdada173b",
          "traceId": "aadc63d1",
          "type": "SPAN",
          "name": "error_aa_tpusg_failure_signal_tpu_sketch_generator",
          "startTime": "2025-08-03T19:07:23.635000+00:00",
          "level": "ERROR",
          "statusMessage": "Failed. Last error: Traceback (most recent call last):\n  File \"script_60fe2de7_1754248035.py\", line 68, in <module>\n    num_detections = int(interpreter.get_tensor(output_details[1]['index']))  # Correctly extract the number of detections\nTypeError: only size-1 arrays can be converted to Python scalars",
          "calculatedTotalCost": 0.0,
          "environment": "default",
          "totalTokens": 0,
          "costDetails": {},
          "completionTokens": 0,
          "promptTokens": 0,
          "endTime": null,
          "model": null,
          "modelParameters": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null,
          "latency": null
        }
      ],
      "createdAt": "2025-08-03T19:04:09.255Z",
      "environment": "default",
      "updatedAt": "2025-08-03T19:07:29.007Z"
    },
    {
      "id": "fb2aba96",
      "timestamp": "2025-08-03T19:00:57.096000+00:00",
      "name": "fb2a_tpu_sketch_generator",
      "input": null,
      "output": {
        "status": "failed",
        "last_code": "num_detections = int(interpreter.get_tensor(output_details[1]['index'])[0])  # Access the scalar value directly from array",
        "last_error": "Unexpected error during generation: Generated script is not complete. Please ensure to generate a complete Python script."
      },
      "session_id": "qwen2.5-coder:32b_373e_tpusg_batch",
      "metadata": {
        "num_run": 4
      },
      "tags": [
        "benchmark",
        "qwen2.5-coder:32b",
        "tpu_sketch_generator"
      ],
      "latency": 185.196,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-22-00-57-098088_chatcmpl-7d1b383c-5c58-4807-be01-55e395195284",
          "traceId": "fb2aba96",
          "type": "GENERATION",
          "name": "fb2a_tpusg_gen_attempt#1",
          "startTime": "2025-08-03T19:00:57.098000+00:00",
          "endTime": "2025-08-03T19:01:22.759000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 25661.0,
          "environment": "default",
          "totalTokens": 2709,
          "costDetails": {},
          "completionTokens": 876,
          "promptTokens": 1833,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-22-01-31-130921_chatcmpl-8cc4355e-0618-4f44-8c76-e49486508311",
          "traceId": "fb2aba96",
          "type": "GENERATION",
          "name": "fb2a_tpusg_gen_attempt#2",
          "startTime": "2025-08-03T19:01:31.130000+00:00",
          "endTime": "2025-08-03T19:02:03.627000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 32497.0,
          "environment": "default",
          "totalTokens": 3183,
          "costDetails": {},
          "completionTokens": 1135,
          "promptTokens": 2048,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-22-02-11-966936_chatcmpl-63df0e43-8c8d-4ae7-be9c-f711dc54d756",
          "traceId": "fb2aba96",
          "type": "GENERATION",
          "name": "fb2a_tpusg_gen_attempt#3",
          "startTime": "2025-08-03T19:02:11.966000+00:00",
          "endTime": "2025-08-03T19:02:43.809000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 31843.0,
          "environment": "default",
          "totalTokens": 3159,
          "costDetails": {},
          "completionTokens": 1111,
          "promptTokens": 2048,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-22-02-52-050358_chatcmpl-a2f201dc-97b6-48ab-ba33-4c93c30bb014",
          "traceId": "fb2aba96",
          "type": "GENERATION",
          "name": "fb2a_tpusg_gen_attempt#4",
          "startTime": "2025-08-03T19:02:52.050000+00:00",
          "endTime": "2025-08-03T19:03:22.921000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 30871.0,
          "environment": "default",
          "totalTokens": 3123,
          "costDetails": {},
          "completionTokens": 1075,
          "promptTokens": 2048,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-22-03-31-255664_chatcmpl-774a77ef-94c4-44a4-8dd6-4ac8b197023d",
          "traceId": "fb2aba96",
          "type": "GENERATION",
          "name": "fb2a_tpusg_gen_attempt#5",
          "startTime": "2025-08-03T19:03:31.255000+00:00",
          "endTime": "2025-08-03T19:04:02.288000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 31033.0,
          "environment": "default",
          "totalTokens": 3123,
          "costDetails": {},
          "completionTokens": 1075,
          "promptTokens": 2048,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "acdc1d6a-e681-412a-a5ec-4c768ad075d4",
          "traceId": "fb2aba96",
          "type": "SPAN",
          "name": "error_fb_tpusg_failure_signal_tpu_sketch_generator",
          "startTime": "2025-08-03T19:04:02.294000+00:00",
          "level": "ERROR",
          "statusMessage": "Failed. Last error: Unexpected error during generation: Generated script is not complete. Please ensure to generate a complete Python script.",
          "calculatedTotalCost": 0.0,
          "environment": "default",
          "totalTokens": 0,
          "costDetails": {},
          "completionTokens": 0,
          "promptTokens": 0,
          "endTime": null,
          "model": null,
          "modelParameters": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null,
          "latency": null
        }
      ],
      "createdAt": "2025-08-03T19:00:57.613Z",
      "environment": "default",
      "updatedAt": "2025-08-03T19:04:07.816Z"
    },
    {
      "id": "2fb081fe",
      "timestamp": "2025-08-03T18:57:35.492000+00:00",
      "name": "2fb0_tpu_sketch_generator",
      "input": null,
      "output": {
        "status": "failed",
        "last_code": "import numpy as np\nfrom tflite_runtime.interpreter import Interpreter, load_delegate\nimport cv2\n\n# Phase 1: Setup\nmodel_path    = \"/home/mendel/tinyml_autopilot/models/edgetpu_detect.tflite\"\nlabel_path    = \"/home/mendel/tinyml_autopilot/models/labelmap.txt\"\ninput_path    = \"/home/mendel/tinyml_autopilot/data//sheeps.mp4\"\noutput_path   = \"/home/mendel/tinyml_autopilot/results/sheeps_detections.mp4\"\nconfidence_threshold  = 0.5\n\n# Load labels\nwith open(label_path, 'r') as f:\n    labels = [line.strip() for line in f.readlines()]\n\n# Load Interpreter with EdgeTPU\ntry:\n    interpreter = Interpreter(model_path=model_path,\n                              experimental_delegates=[load_delegate('libedgetpu.so.1.0')])\nexcept Exception as e:\n    print(f\"Failed to load libedgetpu.so.1.0: {e}\")\n    try:\n        interpreter = Interpreter(model_path=model_path,\n                                  experimental_delegates=[load_delegate('/usr/lib/aarch64-linux-gnu/libedgetpu.so.1.0')])\n    except Exception as e:\n        print(f\"Failed to load /usr/lib/aarch64-linux-gnu/libedgetpu.so.1.0: {e}\")\n        raise\n\ninterpreter.allocate_tensors()\n\n# Get Model Details\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\n\nfloating_model = (input_details[0]['dtype'] == np.float32)\n\n# Phase 2: Input Acquisition & Preprocessing Loop\ncap = cv2.VideoCapture(input_path)\nif not cap.isOpened():\n    raise IOError(\"Cannot open video file\")\n\nframe_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\nframe_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\nfps = cap.get(cv2.CAP_PROP_FPS)\n\nout = cv2.VideoWriter(output_path, cv2.VideoWriter_fourcc(*'mp4v'), fps, (frame_width, frame_height))\n\nwhile True:\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    # Preprocess Data\n    input_data = cv2.resize(frame, (input_details[0]['shape'][1], input_details[0]['shape'][2]))\n    input_data = np.expand_dims(input_data, axis=0)\n\n    if floating_model:\n        input_data = (np.float32(input_data) - 127.5) / 127.5\n\n    # Phase 3: Inference\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n    interpreter.invoke()\n\n    # Phase 4: Output Interpretation & Handling Loop\n    output_data = interpreter.get_tensor(output_details[0]['index'])\n    \n    # Ensure num_detections is a scalar value\n    num_detections = int(interpreter.get_tensor(output_details[1]['index'])[0])\n    detection_boxes = interpreter.get_tensor(output_details[2]['index'])[0]\n    detection_classes = interpreter.get_tensor(output_details[3]['index'])[0].astype(int)\n    detection_scores = interpreter.get_tensor(output_details[4]['index'])[0]\n\n    for i in range(num_detections):\n        if detection_scores[i] > confidence_threshold:\n            box = detection_boxes[i]\n            class_id = detection_classes[i]\n            score = detection_scores[i]\n\n            # Scale and clip bounding boxes\n            ymin, xmin, ymax, xmax = box\n            (left, right, top, bottom) = (xmin * frame_width, xmax * frame_width,\n                                          ymin * frame_height, ymax * frame_height)\n\n            cv2.rectangle(frame, (int(left), int(top)), (int(right), int(bottom)), (0, 255, 0), 2)\n            label = f'{labels[class_id]}: {score:.2f}'\n            cv2.putText(frame, label, (int(left), int(top) - 10),\n                        cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n\n    # Write the frame with detections to the output video\n    out.write(frame)\n\n# Release resources\ncap.release()\nout.release()\ncv2.destroyAllWindows()",
        "last_error": "Traceback (most recent call last):\n  File \"script_1b89d458_1754247642.py\", line 68, in <module>\n    num_detections = int(interpreter.get_tensor(output_details[1]['index'])[0])\nTypeError: only size-1 arrays can be converted to Python scalars"
      },
      "session_id": "qwen2.5-coder:32b_373e_tpusg_batch",
      "metadata": {
        "num_run": 3
      },
      "tags": [
        "benchmark",
        "qwen2.5-coder:32b",
        "tpu_sketch_generator"
      ],
      "latency": 195.796,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-21-57-35-495023_chatcmpl-5394e44d-0158-42de-8aab-b6cbb6c47408",
          "traceId": "2fb081fe",
          "type": "GENERATION",
          "name": "2fb0_tpusg_gen_attempt#1",
          "startTime": "2025-08-03T18:57:35.495000+00:00",
          "endTime": "2025-08-03T18:58:00.935000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 25440.0,
          "environment": "default",
          "totalTokens": 2709,
          "costDetails": {},
          "completionTokens": 876,
          "promptTokens": 1833,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-21-58-09-193962_chatcmpl-22e8d5ff-75e9-4292-a4b9-945cd8023f6c",
          "traceId": "2fb081fe",
          "type": "GENERATION",
          "name": "2fb0_tpusg_gen_attempt#2",
          "startTime": "2025-08-03T18:58:09.193000+00:00",
          "endTime": "2025-08-03T18:58:40.870000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 31677.0,
          "environment": "default",
          "totalTokens": 3154,
          "costDetails": {},
          "completionTokens": 1106,
          "promptTokens": 2048,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-21-58-49-218278_chatcmpl-9dfaf9e2-fa0d-4145-9656-c5faae8c2193",
          "traceId": "2fb081fe",
          "type": "GENERATION",
          "name": "2fb0_tpusg_gen_attempt#3",
          "startTime": "2025-08-03T18:58:49.218000+00:00",
          "endTime": "2025-08-03T18:59:21.275000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 32057.0,
          "environment": "default",
          "totalTokens": 3169,
          "costDetails": {},
          "completionTokens": 1121,
          "promptTokens": 2048,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-21-59-29-545801_chatcmpl-df0b7c83-ff04-459b-8667-bbe947d291d7",
          "traceId": "2fb081fe",
          "type": "GENERATION",
          "name": "2fb0_tpusg_gen_attempt#4",
          "startTime": "2025-08-03T18:59:29.545000+00:00",
          "endTime": "2025-08-03T19:00:00.335000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 30790.0,
          "environment": "default",
          "totalTokens": 3116,
          "costDetails": {},
          "completionTokens": 1068,
          "promptTokens": 2048,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-22-00-08-570691_chatcmpl-e88179ca-e40a-4131-9f5c-c016c78f4720",
          "traceId": "2fb081fe",
          "type": "GENERATION",
          "name": "2fb0_tpusg_gen_attempt#5",
          "startTime": "2025-08-03T19:00:08.570000+00:00",
          "endTime": "2025-08-03T19:00:42.841000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 34271.0,
          "environment": "default",
          "totalTokens": 3150,
          "costDetails": {},
          "completionTokens": 1102,
          "promptTokens": 2048,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "58a9bcda-a41f-418e-9238-ab2b8b6fa7bf",
          "traceId": "2fb081fe",
          "type": "SPAN",
          "name": "error_2f_tpusg_failure_signal_tpu_sketch_generator",
          "startTime": "2025-08-03T19:00:51.291000+00:00",
          "level": "ERROR",
          "statusMessage": "Failed. Last error: Traceback (most recent call last):\n  File \"script_1b89d458_1754247642.py\", line 68, in <module>\n    num_detections = int(interpreter.get_tensor(output_details[1]['index'])[0])\nTypeError: only size-1 arrays can be converted to Python scalars",
          "calculatedTotalCost": 0.0,
          "environment": "default",
          "totalTokens": 0,
          "costDetails": {},
          "completionTokens": 0,
          "promptTokens": 0,
          "endTime": null,
          "model": null,
          "modelParameters": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null,
          "latency": null
        }
      ],
      "createdAt": "2025-08-03T18:57:36.011Z",
      "environment": "default",
      "updatedAt": "2025-08-03T19:00:56.807Z"
    },
    {
      "id": "5692b90a",
      "timestamp": "2025-08-03T18:54:51.904000+00:00",
      "name": "5692_tpu_sketch_generator",
      "input": null,
      "output": {
        "status": "success",
        "sketch": "import numpy as np\nfrom tflite_runtime.interpreter import Interpreter, load_delegate\nimport cv2\n\n# Phase 1: Setup\nmodel_path  = \"/home/mendel/tinyml_autopilot/models/edgetpu_detect.tflite\"\nlabel_path  = \"/home/mendel/tinyml_autopilot/models/labelmap.txt\"\ninput_path  = \"/home/mendel/tinyml_autopilot/data//sheeps.mp4\"\noutput_path  = \"/home/mendel/tinyml_autopilot/results/sheeps_detections.mp4\"\nconfidence_threshold  = 0.5\n\n# Load labels\nwith open(label_path, 'r') as f:\n    labels = [line.strip() for line in f.readlines()]\n\n# Load Interpreter with EdgeTPU\ntry:\n    interpreter = Interpreter(model_path=model_path,\n                              experimental_delegates=[load_delegate('libedgetpu.so.1.0')])\nexcept Exception as e:\n    print(f\"Failed to load libedgetpu.so.1.0: {e}\")\n    try:\n        interpreter = Interpreter(model_path=model_path,\n                                  experimental_delegates=[load_delegate('/usr/lib/aarch64-linux-gnu/libedgetpu.so.1.0')])\n    except Exception as e:\n        print(f\"Failed to load /usr/lib/aarch64-linux-gnu/libedgetpu.so.1.0: {e}\")\n        raise\n\ninterpreter.allocate_tensors()\n\n# Get Model Details\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\n\nfloating_model = (input_details[0]['dtype'] == np.float32)\n\n# Phase 2: Input Acquisition & Preprocessing Loop\ncap = cv2.VideoCapture(input_path)\nif not cap.isOpened():\n    raise IOError(\"Cannot open video file\")\n\nframe_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\nframe_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\nfps = cap.get(cv2.CAP_PROP_FPS)\n\nout = cv2.VideoWriter(output_path, cv2.VideoWriter_fourcc(*'mp4v'), fps, (frame_width, frame_height))\n\nwhile True:\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    # Preprocess Data\n    input_data = cv2.resize(frame, (input_details[0]['shape'][1], input_details[0]['shape'][2]))\n    input_data = np.expand_dims(input_data, axis=0)\n\n    if floating_model:\n        input_data = (np.float32(input_data) - 127.5) / 127.5\n\n    # Phase 3: Inference\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n    interpreter.invoke()\n\n    # Phase 4: Output Interpretation & Handling Loop\n    detection_boxes = interpreter.get_tensor(output_details[0]['index'])[0]\n    detection_classes = interpreter.get_tensor(output_details[1]['index'])[0].astype(int)\n    detection_scores = interpreter.get_tensor(output_details[2]['index'])[0]\n\n    for i in range(len(detection_scores)):\n        if detection_scores[i] > confidence_threshold:\n            box = detection_boxes[i]\n            class_id = detection_classes[i]\n            score = detection_scores[i]\n\n            # Scale and clip bounding boxes\n            ymin, xmin, ymax, xmax = box\n            (left, right, top, bottom) = (xmin * frame_width, xmax * frame_width,\n                                          ymin * frame_height, ymax * frame_height)\n\n            cv2.rectangle(frame, (int(left), int(top)), (int(right), int(bottom)), (0, 255, 0), 2)\n            label = f'{labels[class_id]}: {score:.2f}'\n            cv2.putText(frame, label, (int(left), int(top) - 10),\n                        cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n\n    # Handle Output\n    out.write(frame)\n\n# Phase 5: Cleanup\ncap.release()\nout.release()\ncv2.destroyAllWindows()"
      },
      "session_id": "qwen2.5-coder:32b_373e_tpusg_batch",
      "metadata": {
        "num_run": 2
      },
      "tags": [
        "benchmark",
        "qwen2.5-coder:32b",
        "tpu_sketch_generator"
      ],
      "latency": 104.836,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-21-54-51-906566_chatcmpl-ceacebbc-5691-4335-818a-5be96702e930",
          "traceId": "5692b90a",
          "type": "GENERATION",
          "name": "5692_tpusg_gen_attempt#1",
          "startTime": "2025-08-03T18:54:51.906000+00:00",
          "endTime": "2025-08-03T18:55:17.344000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 25438.0,
          "environment": "default",
          "totalTokens": 2709,
          "costDetails": {},
          "completionTokens": 876,
          "promptTokens": 1833,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-21-55-25-705451_chatcmpl-1ddc41a2-58ba-42e9-82ed-b9b34ff732f1",
          "traceId": "5692b90a",
          "type": "GENERATION",
          "name": "5692_tpusg_gen_attempt#2",
          "startTime": "2025-08-03T18:55:25.705000+00:00",
          "endTime": "2025-08-03T18:55:57.740000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 32035.0,
          "environment": "default",
          "totalTokens": 3168,
          "costDetails": {},
          "completionTokens": 1120,
          "promptTokens": 2048,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-21-56-05-982767_chatcmpl-6c4fb6d5-3254-465d-9415-adee3bf9264d",
          "traceId": "5692b90a",
          "type": "GENERATION",
          "name": "5692_tpusg_gen_attempt#3",
          "startTime": "2025-08-03T18:56:05.982000+00:00",
          "endTime": "2025-08-03T18:56:36.742000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 30760.0,
          "environment": "default",
          "totalTokens": 3119,
          "costDetails": {},
          "completionTokens": 1071,
          "promptTokens": 2048,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        }
      ],
      "createdAt": "2025-08-03T18:54:52.425Z",
      "environment": "default",
      "updatedAt": "2025-08-03T18:57:34.674Z"
    },
    {
      "id": "59c631ae",
      "timestamp": "2025-08-03T18:50:39.073000+00:00",
      "name": "59c6_tpu_sketch_generator",
      "input": null,
      "output": {
        "status": "failed",
        "last_code": "import numpy as np\nfrom tflite_runtime.interpreter import Interpreter, load_delegate\nimport cv2\n\n# Phase 1: Setup\nmodel_path  = \"/home/mendel/tinyml_autopilot/models/edgetpu_detect.tflite\"\nlabel_path  = \"/home/mendel/tinyml_autopilot/models/labelmap.txt\"\ninput_path  = \"/home/mendel/tinyml_autopilot/data//sheeps.mp4\"\noutput_path  = \"/home/mendel/tinyml_autopilot/results/sheeps_detections.mp4\"\nconfidence_threshold  = 0.5\n\n# Load labels\nwith open(label_path, 'r') as f:\n    labels = [line.strip() for line in f.readlines()]\n\n# Load Interpreter with EdgeTPU\ntry:\n    interpreter = Interpreter(model_path=model_path,\n                              experimental_delegates=[load_delegate('libedgetpu.so.1.0')])\nexcept Exception as e:\n    try:\n        interpreter = Interpreter(model_path=model_path,\n                                  experimental_delegates=[load_delegate('/usr/lib/aarch64-linux-gnu/libedgetpu.so.1.0')])\n    except Exception as e:\n        raise RuntimeError(\"Failed to load EdgeTPU delegate\") from e\n\ninterpreter.allocate_tensors()\n\n# Get Model Details\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\n\nfloating_model = (input_details[0]['dtype'] == np.float32)\n\n# Phase 2: Input Acquisition & Preprocessing Loop\ncap = cv2.VideoCapture(input_path)\nif not cap.isOpened():\n    raise RuntimeError(\"Failed to open video file\")\n\nframe_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\nframe_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\nfps = cap.get(cv2.CAP_PROP_FPS)\n\nout = cv2.VideoWriter(output_path, cv2.VideoWriter_fourcc(*'mp4v'), fps, (frame_width, frame_height))\n\nwhile cap.isOpened():\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    # Preprocess Data\n    input_data = cv2.resize(frame, (input_details[0]['shape'][1], input_details[0]['shape'][2]))\n    input_data = np.expand_dims(input_data, axis=0)\n\n    if floating_model:\n        input_data = (np.float32(input_data) - 127.5) / 127.5\n\n    # Phase 3: Inference\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n    interpreter.invoke()\n\n    # Phase 4: Output Interpretation & Handling Loop\n    num_detections = int(interpreter.get_tensor(output_details[0]['index'])[0])  # Ensure we get the scalar value correctly\n    detection_boxes = interpreter.get_tensor(output_details[1]['index'])[0]\n    detection_classes = interpreter.get_tensor(output_details[2]['index'])[0].astype(int)\n    detection_scores = interpreter.get_tensor(output_details[3]['index'])[0]\n\n    for i in range(num_detections):\n        if detection_scores[i] > confidence_threshold:\n            box = detection_boxes[i]\n            class_id = detection_classes[i]\n            score = detection_scores[i]\n\n            # Scale and clip bounding boxes\n            ymin, xmin, ymax, xmax = box\n            (left, right, top, bottom) = (xmin * frame_width, xmax * frame_width,\n                                          ymin * frame_height, ymax * frame_height)\n\n            cv2.rectangle(frame, (int(left), int(top)), (int(right), int(bottom)), (0, 255, 0), 2)\n            label = f'{labels[class_id]}: {score:.2f}'\n            cv2.putText(frame, label, (int(left), int(top) - 10),\n                        cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n\n    # Write the frame with detections to the output video\n    out.write(frame)\n\n# Release resources\ncap.release()\nout.release()\ncv2.destroyAllWindows()",
        "last_error": "Traceback (most recent call last):\n  File \"script_b82d0093_1754247277.py\", line 63, in <module>\n    num_detections = int(interpreter.get_tensor(output_details[0]['index'])[0])  # Ensure we get the scalar value correctly\nTypeError: only size-1 arrays can be converted to Python scalars"
      },
      "session_id": "qwen2.5-coder:32b_373e_tpusg_batch",
      "metadata": {
        "num_run": 1
      },
      "tags": [
        "benchmark",
        "qwen2.5-coder:32b",
        "tpu_sketch_generator"
      ],
      "latency": 246.572,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-21-50-39-075117_chatcmpl-603854bf-4ef6-4cb9-a05b-3f19562a30ef",
          "traceId": "59c631ae",
          "type": "GENERATION",
          "name": "59c6_tpusg_gen_attempt#1",
          "startTime": "2025-08-03T18:50:39.075000+00:00",
          "endTime": "2025-08-03T18:51:58.025000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 78950.0,
          "environment": "default",
          "totalTokens": 2675,
          "costDetails": {},
          "completionTokens": 842,
          "promptTokens": 1833,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-21-52-06-389339_chatcmpl-83d770b0-1482-460b-af89-2568de3208ca",
          "traceId": "59c631ae",
          "type": "GENERATION",
          "name": "59c6_tpusg_gen_attempt#2",
          "startTime": "2025-08-03T18:52:06.389000+00:00",
          "endTime": "2025-08-03T18:52:39.521000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 33132.0,
          "environment": "default",
          "totalTokens": 3209,
          "costDetails": {},
          "completionTokens": 1161,
          "promptTokens": 2048,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-21-52-47-815424_chatcmpl-250a0398-0e81-4c5d-a9a0-cd8c50fded3d",
          "traceId": "59c631ae",
          "type": "GENERATION",
          "name": "59c6_tpusg_gen_attempt#3",
          "startTime": "2025-08-03T18:52:47.815000+00:00",
          "endTime": "2025-08-03T18:53:19.513000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 31698.0,
          "environment": "default",
          "totalTokens": 3155,
          "costDetails": {},
          "completionTokens": 1107,
          "promptTokens": 2048,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-21-53-27-805102_chatcmpl-e9dfaf19-a357-4746-a1ef-7efcf2f39fbf",
          "traceId": "59c631ae",
          "type": "GENERATION",
          "name": "59c6_tpusg_gen_attempt#4",
          "startTime": "2025-08-03T18:53:27.805000+00:00",
          "endTime": "2025-08-03T18:53:58.509000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 30704.0,
          "environment": "default",
          "totalTokens": 3117,
          "costDetails": {},
          "completionTokens": 1069,
          "promptTokens": 2048,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-21-54-06-786612_chatcmpl-85f350dd-96d8-4e76-86e9-dcc339057cae",
          "traceId": "59c631ae",
          "type": "GENERATION",
          "name": "59c6_tpusg_gen_attempt#5",
          "startTime": "2025-08-03T18:54:06.786000+00:00",
          "endTime": "2025-08-03T18:54:37.377000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 30591.0,
          "environment": "default",
          "totalTokens": 3112,
          "costDetails": {},
          "completionTokens": 1064,
          "promptTokens": 2048,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "3899d163-cb57-478e-886a-41613c29bc82",
          "traceId": "59c631ae",
          "type": "SPAN",
          "name": "error_59_tpusg_failure_signal_tpu_sketch_generator",
          "startTime": "2025-08-03T18:54:45.647000+00:00",
          "level": "ERROR",
          "statusMessage": "Failed. Last error: Traceback (most recent call last):\n  File \"script_b82d0093_1754247277.py\", line 63, in <module>\n    num_detections = int(interpreter.get_tensor(output_details[0]['index'])[0])  # Ensure we get the scalar value correctly\nTypeError: only size-1 arrays can be converted to Python scalars",
          "calculatedTotalCost": 0.0,
          "environment": "default",
          "totalTokens": 0,
          "costDetails": {},
          "completionTokens": 0,
          "promptTokens": 0,
          "endTime": null,
          "model": null,
          "modelParameters": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null,
          "latency": null
        }
      ],
      "createdAt": "2025-08-03T18:50:40.112Z",
      "environment": "default",
      "updatedAt": "2025-08-03T18:54:50.884Z"
    }
  ],
  "meta": {
    "total_items": 30
  }
}
{
  "data": [
    {
      "id": "90b2eb0c",
      "timestamp": "2025-08-04T12:23:03.189000+00:00",
      "name": "90b2_tpu_sketch_generator",
      "input": null,
      "output": {
        "status": "failed",
        "last_code": "import numpy as np\nfrom tflite_runtime.interpreter import Interpreter, load_delegate\nimport cv2\n\n# Phase 1: Setup\nmodel_path  = \"/home/mendel/tinyml_autopilot/models/edgetpu_detect.tflite\"\nlabel_path  = \"/home/mendel/tinyml_autopilot/models/labelmap.txt\"\ninput_path  = \"/home/mendel/tinyml_autopilot/data//sheeps.mp4\"\noutput_path  = \"/home/mendel/tinyml_autopilot/results/sheeps_detections.mp4\"\nconfidence_threshold  = 0.5\n\n# Load labels\nwith open(label_path, 'r') as f:\n    labels = [line.strip() for line in f.readlines()]\n\n# Load Interpreter with EdgeTPU\ntry:\n    interpreter = Interpreter(model_path=model_path,\n                              experimental_delegates=[load_delegate('libedgetpu.so.1.0')])\nexcept Exception as e:\n    print(f\"Failed to load libedgetpu.so.1.0: {e}\")\n    try:\n        interpreter = Interpreter(model_path=model_path,\n                                  experimental_delegates=[load_delegate('/usr/lib/aarch64-linux-gnu/libedgetpu.so.1.0')])\n    except Exception as e:\n        print(f\"Failed to load /usr/lib/aarch64-linux-gnu/libedgetpu.so.1.0: {e}\")\n        raise\n\ninterpreter.allocate_tensors()\n\n# Get Model Details\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\n\nfloating_model = (input_details[0]['dtype'] == np.float32)\n\n# Phase 2: Input Acquisition & Preprocessing Loop\ncap = cv2.VideoCapture(input_path)\nif not cap.isOpened():\n    raise IOError(\"Cannot open video file\")\n\nframe_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\nframe_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\nfps = cap.get(cv2.CAP_PROP_FPS)\n\nout = cv2.VideoWriter(output_path, cv2.VideoWriter_fourcc(*'mp4v'), fps, (frame_width, frame_height))\n\nwhile True:\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    # Preprocess Data\n    input_data = cv2.resize(frame, (input_details[0]['shape'][1], input_details[0]['shape'][2]))\n    input_data = np.expand_dims(input_data, axis=0)\n\n    if floating_model:\n        input_data = (np.float32(input_data) - 127.5) / 127.5\n\n    # Phase 3: Inference\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n    interpreter.invoke()\n\n    # Phase 4: Output Interpretation & Handling Loop\n    output_data = interpreter.get_tensor(output_details[0]['index'])\n    num_detections = int(interpreter.get_tensor(output_details[1]['index']))  # Access the scalar value directly\n    detection_boxes = interpreter.get_tensor(output_details[2]['index'])[0]\n    detection_classes = interpreter.get_tensor(output_details[3]['index'])[0].astype(int)\n    detection_scores = interpreter.get_tensor(output_details[4]['index'])[0]\n\n    for i in range(num_detections):\n        if detection_scores[i] > confidence_threshold:\n            box = detection_boxes[i]\n            class_id = detection_classes[i]\n            score = detection_scores[i]\n\n            # Scale and clip bounding boxes\n            ymin, xmin, ymax, xmax = box\n            (left, right, top, bottom) = (xmin * frame_width, xmax * frame_width,\n                                          ymin * frame_height, ymax * frame_height)\n\n            cv2.rectangle(frame, (int(left), int(top)), (int(right), int(bottom)), (0, 255, 0), 2)\n            label = f'{labels[class_id]}: {score:.2f}'\n            cv2.putText(frame, label, (int(left), int(top) - 10),\n                        cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n\n    # Write the frame to the output video\n    out.write(frame)\n\n# Release resources\ncap.release()\nout.release()\ncv2.destroyAllWindows()",
        "last_error": "Traceback (most recent call last):\n  File \"script_506d44c7_1754310370.py\", line 66, in <module>\n    num_detections = int(interpreter.get_tensor(output_details[1]['index']))  # Access the scalar value directly\nTypeError: only size-1 arrays can be converted to Python scalars"
      },
      "session_id": "qwen2.5-coder:32b_ee11_tpusg_batch",
      "metadata": {
        "num_run": 30
      },
      "tags": [
        "benchmark",
        "qwen2.5-coder:32b",
        "tpu_sketch_generator"
      ],
      "latency": 195.075,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-15-23-03-191185_chatcmpl-fb799309-12c4-4c6d-ad9f-2c439ae2363c",
          "traceId": "90b2eb0c",
          "type": "GENERATION",
          "name": "90b2_tpusg_gen_attempt#1",
          "startTime": "2025-08-04T12:23:03.191000+00:00",
          "endTime": "2025-08-04T12:23:28.997000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 25806.0,
          "costDetails": {},
          "completionTokens": 876,
          "promptTokens": 1833,
          "totalTokens": 2709,
          "environment": "default",
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-15-23-37-070319_chatcmpl-1435500d-243b-42b5-8ca4-e9a0a40768b8",
          "traceId": "90b2eb0c",
          "type": "GENERATION",
          "name": "90b2_tpusg_gen_attempt#2",
          "startTime": "2025-08-04T12:23:37.070000+00:00",
          "endTime": "2025-08-04T12:24:09.163000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 32093.0,
          "costDetails": {},
          "completionTokens": 1105,
          "promptTokens": 2048,
          "totalTokens": 3153,
          "environment": "default",
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-15-24-17-245569_chatcmpl-a8505749-4f07-4052-9307-a6c64f267bff",
          "traceId": "90b2eb0c",
          "type": "GENERATION",
          "name": "90b2_tpusg_gen_attempt#3",
          "startTime": "2025-08-04T12:24:17.245000+00:00",
          "endTime": "2025-08-04T12:24:49.497000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 32252.0,
          "costDetails": {},
          "completionTokens": 1111,
          "promptTokens": 2048,
          "totalTokens": 3159,
          "environment": "default",
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-15-24-57-536826_chatcmpl-9fa300bb-052b-49b6-bd40-f08ed12c0aff",
          "traceId": "90b2eb0c",
          "type": "GENERATION",
          "name": "90b2_tpusg_gen_attempt#4",
          "startTime": "2025-08-04T12:24:57.536000+00:00",
          "endTime": "2025-08-04T12:25:30.386000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 32850.0,
          "costDetails": {},
          "completionTokens": 1133,
          "promptTokens": 2048,
          "totalTokens": 3181,
          "environment": "default",
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-15-25-38-490553_chatcmpl-339d5ae4-b154-444a-a05d-00688d47c46b",
          "traceId": "90b2eb0c",
          "type": "GENERATION",
          "name": "90b2_tpusg_gen_attempt#5",
          "startTime": "2025-08-04T12:25:38.490000+00:00",
          "endTime": "2025-08-04T12:26:10.206000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 31716.0,
          "costDetails": {},
          "completionTokens": 1090,
          "promptTokens": 2048,
          "totalTokens": 3138,
          "environment": "default",
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "ed26a48b-1278-49e1-92b9-7ddd1bbd535f",
          "traceId": "90b2eb0c",
          "type": "SPAN",
          "name": "error_90_tpusg_failure_signal_tpu_sketch_generator",
          "startTime": "2025-08-04T12:26:18.266000+00:00",
          "level": "ERROR",
          "statusMessage": "Failed. Last error: Traceback (most recent call last):\n  File \"script_506d44c7_1754310370.py\", line 66, in <module>\n    num_detections = int(interpreter.get_tensor(output_details[1]['index']))  # Access the scalar value directly\nTypeError: only size-1 arrays can be converted to Python scalars",
          "calculatedTotalCost": 0.0,
          "costDetails": {},
          "completionTokens": 0,
          "promptTokens": 0,
          "totalTokens": 0,
          "environment": "default",
          "endTime": null,
          "model": null,
          "modelParameters": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null,
          "latency": null
        }
      ],
      "createdAt": "2025-08-04T12:23:03.712Z",
      "updatedAt": "2025-08-04T12:26:23.425Z",
      "environment": "default"
    },
    {
      "id": "4ef499d0",
      "timestamp": "2025-08-04T12:19:41.457000+00:00",
      "name": "4ef4_tpu_sketch_generator",
      "input": null,
      "output": {
        "status": "failed",
        "last_code": "import numpy as np\nfrom tflite_runtime.interpreter import Interpreter, load_delegate\nimport cv2\n\n# Phase 1: Setup\nmodel_path  = \"/home/mendel/tinyml_autopilot/models/edgetpu_detect.tflite\"\nlabel_path  = \"/home/mendel/tinyml_autopilot/models/labelmap.txt\"\ninput_path  = \"/home/mendel/tinyml_autopilot/data//sheeps.mp4\"\noutput_path  = \"/home/mendel/tinyml_autopilot/results/sheeps_detections.mp4\"\nconfidence_threshold  = 0.5\n\n# Load labels\nwith open(label_path, 'r') as f:\n    labels = [line.strip() for line in f.readlines()]\n\n# Load Interpreter with EdgeTPU\ntry:\n    interpreter = Interpreter(model_path=model_path,\n                              experimental_delegates=[load_delegate('libedgetpu.so.1.0')])\nexcept Exception as e:\n    print(f\"Failed to load libedgetpu.so.1.0: {e}\")\n    try:\n        interpreter = Interpreter(model_path=model_path,\n                                  experimental_delegates=[load_delegate('/usr/lib/aarch64-linux-gnu/libedgetpu.so.1.0')])\n    except Exception as e:\n        print(f\"Failed to load /usr/lib/aarch64-linux-gnu/libedgetpu.so.1.0: {e}\")\n        raise\n\ninterpreter.allocate_tensors()\n\n# Get Model Details\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\n\nfloating_model = (input_details[0]['dtype'] == np.float32)\n\n# Phase 2: Input Acquisition & Preprocessing Loop\ncap = cv2.VideoCapture(input_path)\nif not cap.isOpened():\n    raise IOError(\"Cannot open video file\")\n\nframe_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\nframe_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\nfps = cap.get(cv2.CAP_PROP_FPS)\n\nout = cv2.VideoWriter(output_path, cv2.VideoWriter_fourcc(*'mp4v'), fps, (frame_width, frame_height))\n\nwhile True:\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    # Preprocess Data\n    input_data = cv2.resize(frame, (input_details[0]['shape'][1], input_details[0]['shape'][2]))\n    input_data = np.expand_dims(input_data, axis=0)\n\n    if floating_model:\n        input_data = (np.float32(input_data) - 127.5) / 127.5\n\n    # Phase 3: Inference\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n    interpreter.invoke()\n\n    # Phase 4: Output Interpretation & Handling Loop\n    output_data = interpreter.get_tensor(output_details[0]['index'])\n    \n    # Assuming the second output tensor is a single value array containing num_detections\n    num_detections = int(interpreter.get_tensor(output_details[1]['index']))\n    detection_boxes = interpreter.get_tensor(output_details[2]['index'])[0]\n    detection_classes = interpreter.get_tensor(output_details[3]['index'])[0].astype(int)\n    detection_scores = interpreter.get_tensor(output_details[4]['index'])[0]\n\n    for i in range(num_detections):\n        if detection_scores[i] > confidence_threshold:\n            box = detection_boxes[i]\n            class_id = detection_classes[i]\n            score = detection_scores[i]\n\n            # Scale and clip bounding boxes\n            ymin, xmin, ymax, xmax = box\n            (left, right, top, bottom) = (xmin * frame_width, xmax * frame_width,\n                                          ymin * frame_height, ymax * frame_height)\n\n            cv2.rectangle(frame, (int(left), int(top)), (int(right), int(bottom)), (0, 255, 0), 2)\n            label = f'{labels[class_id]}: {score:.2f}'\n            cv2.putText(frame, label, (int(left), int(top) - 10),\n                        cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n\n    # Handle Output\n    out.write(frame)\n\n# Phase 5: Cleanup\ncap.release()\nout.release()\ncv2.destroyAllWindows()",
        "last_error": "Traceback (most recent call last):\n  File \"script_78ae5bf2_1754310169.py\", line 68, in <module>\n    num_detections = int(interpreter.get_tensor(output_details[1]['index']))\nTypeError: only size-1 arrays can be converted to Python scalars"
      },
      "session_id": "qwen2.5-coder:32b_ee11_tpusg_batch",
      "metadata": {
        "num_run": 29
      },
      "tags": [
        "benchmark",
        "qwen2.5-coder:32b",
        "tpu_sketch_generator"
      ],
      "latency": 195.71,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-15-19-41-459555_chatcmpl-12b6c710-80ab-4989-8afe-02e93c4f1d1f",
          "traceId": "4ef499d0",
          "type": "GENERATION",
          "name": "4ef4_tpusg_gen_attempt#1",
          "startTime": "2025-08-04T12:19:41.459000+00:00",
          "endTime": "2025-08-04T12:20:07.242000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 25783.0,
          "costDetails": {},
          "completionTokens": 876,
          "promptTokens": 1833,
          "totalTokens": 2709,
          "environment": "default",
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-15-20-15-314311_chatcmpl-37e87aff-c9ac-4fba-8d2b-f6e4a85279c1",
          "traceId": "4ef499d0",
          "type": "GENERATION",
          "name": "4ef4_tpusg_gen_attempt#2",
          "startTime": "2025-08-04T12:20:15.314000+00:00",
          "endTime": "2025-08-04T12:20:48.342000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 33028.0,
          "costDetails": {},
          "completionTokens": 1140,
          "promptTokens": 2048,
          "totalTokens": 3188,
          "environment": "default",
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-15-20-56-423213_chatcmpl-d012b724-b56e-43f3-8938-2eb4aec0472f",
          "traceId": "4ef499d0",
          "type": "GENERATION",
          "name": "4ef4_tpusg_gen_attempt#3",
          "startTime": "2025-08-04T12:20:56.423000+00:00",
          "endTime": "2025-08-04T12:21:27.356000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 30933.0,
          "costDetails": {},
          "completionTokens": 1061,
          "promptTokens": 2048,
          "totalTokens": 3109,
          "environment": "default",
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-15-21-35-380420_chatcmpl-c2e9eda0-5c84-4ae2-b43e-b96b25c6edc4",
          "traceId": "4ef499d0",
          "type": "GENERATION",
          "name": "4ef4_tpusg_gen_attempt#4",
          "startTime": "2025-08-04T12:21:35.380000+00:00",
          "endTime": "2025-08-04T12:22:06.831000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 31451.0,
          "costDetails": {},
          "completionTokens": 1081,
          "promptTokens": 2048,
          "totalTokens": 3129,
          "environment": "default",
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-15-22-15-138520_chatcmpl-be273513-9bf1-4793-a3b6-76ef217b530e",
          "traceId": "4ef499d0",
          "type": "GENERATION",
          "name": "4ef4_tpusg_gen_attempt#5",
          "startTime": "2025-08-04T12:22:15.138000+00:00",
          "endTime": "2025-08-04T12:22:49.152000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 34014.0,
          "costDetails": {},
          "completionTokens": 1177,
          "promptTokens": 2048,
          "totalTokens": 3225,
          "environment": "default",
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "90afaa4f-36f4-432a-8824-e4df5533ca5e",
          "traceId": "4ef499d0",
          "type": "SPAN",
          "name": "error_4e_tpusg_failure_signal_tpu_sketch_generator",
          "startTime": "2025-08-04T12:22:57.169000+00:00",
          "level": "ERROR",
          "statusMessage": "Failed. Last error: Traceback (most recent call last):\n  File \"script_78ae5bf2_1754310169.py\", line 68, in <module>\n    num_detections = int(interpreter.get_tensor(output_details[1]['index']))\nTypeError: only size-1 arrays can be converted to Python scalars",
          "calculatedTotalCost": 0.0,
          "costDetails": {},
          "completionTokens": 0,
          "promptTokens": 0,
          "totalTokens": 0,
          "environment": "default",
          "endTime": null,
          "model": null,
          "modelParameters": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null,
          "latency": null
        }
      ],
      "createdAt": "2025-08-04T12:19:41.982Z",
      "updatedAt": "2025-08-04T12:23:02.647Z",
      "environment": "default"
    },
    {
      "id": "04bb8d22",
      "timestamp": "2025-08-04T12:16:21.813000+00:00",
      "name": "04bb_tpu_sketch_generator",
      "input": null,
      "output": {
        "status": "failed",
        "last_code": "import numpy as np\nfrom tflite_runtime.interpreter import Interpreter, load_delegate\nimport cv2\n\n# Phase 1: Setup\nmodel_path  = \"/home/mendel/tinyml_autopilot/models/edgetpu_detect.tflite\"\nlabel_path  = \"/home/mendel/tinyml_autopilot/models/labelmap.txt\"\ninput_path  = \"/home/mendel/tinyml_autopilot/data//sheeps.mp4\"\noutput_path  = \"/home/mendel/tinyml_autopilot/results/sheeps_detections.mp4\"\nconfidence_threshold  = 0.5\n\n# Load labels\nwith open(label_path, 'r') as f:\n    labels = [line.strip() for line in f.readlines()]\n\n# Load Interpreter with EdgeTPU\ntry:\n    interpreter = Interpreter(model_path=model_path,\n                              experimental_delegates=[load_delegate('libedgetpu.so.1.0')])\nexcept Exception as e:\n    print(f\"Failed to load libedgetpu.so.1.0: {e}\")\n    try:\n        interpreter = Interpreter(model_path=model_path,\n                                  experimental_delegates=[load_delegate('/usr/lib/aarch64-linux-gnu/libedgetpu.so.1.0')])\n    except Exception as e:\n        print(f\"Failed to load /usr/lib/aarch64-linux-gnu/libedgetpu.so.1.0: {e}\")\n        raise\n\ninterpreter.allocate_tensors()\n\n# Get Model Details\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\n\nfloating_model = (input_details[0]['dtype'] == np.float32)\n\n# Phase 2: Input Acquisition & Preprocessing Loop\ncap = cv2.VideoCapture(input_path)\nif not cap.isOpened():\n    raise IOError(\"Cannot open video file\")\n\nframe_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\nframe_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\nfps = cap.get(cv2.CAP_PROP_FPS)\n\nout = cv2.VideoWriter(output_path, cv2.VideoWriter_fourcc(*'mp4v'), fps, (frame_width, frame_height))\n\nwhile True:\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    # Preprocess Data\n    input_data = cv2.resize(frame, (input_details[0]['shape'][1], input_details[0]['shape'][2]))\n    input_data = np.expand_dims(input_data, axis=0)\n\n    if floating_model:\n        input_data = (np.float32(input_data) - 127.5) / 127.5\n\n    # Phase 3: Inference\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n    interpreter.invoke()\n\n    # Phase 4: Output Interpretation & Handling Loop\n    output_data = interpreter.get_tensor(output_details[0]['index'])\n    num_detections = int(interpreter.get_tensor(output_details[1]['index']))  # Correctly access the number of detections\n    detection_boxes = interpreter.get_tensor(output_details[2]['index'])[0]\n    detection_classes = interpreter.get_tensor(output_details[3]['index'])[0].astype(int)\n    detection_scores = interpreter.get_tensor(output_details[4]['index'])[0]\n\n    for i in range(num_detections):\n        if detection_scores[i] > confidence_threshold:\n            box = detection_boxes[i]\n            class_id = detection_classes[i]\n            score = detection_scores[i]\n\n            # Scale and clip bounding boxes\n            ymin, xmin, ymax, xmax = box\n            (left, right, top, bottom) = (xmin * frame_width, xmax * frame_width,\n                                          ymin * frame_height, ymax * frame_height)\n\n            cv2.rectangle(frame, (int(left), int(top)), (int(right), int(bottom)), (0, 255, 0), 2)\n            label = f'{labels[class_id]}: {score:.2f}'\n            cv2.putText(frame, label, (int(left), int(top) - 10),\n                        cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n\n    # Handle Output\n    out.write(frame)\n\n# Phase 5: Cleanup\ncap.release()\nout.release()\ncv2.destroyAllWindows()",
        "last_error": "Traceback (most recent call last):\n  File \"script_8add7014_1754309966.py\", line 66, in <module>\n    num_detections = int(interpreter.get_tensor(output_details[1]['index']))  # Correctly access the number of detections\nTypeError: only size-1 arrays can be converted to Python scalars"
      },
      "session_id": "qwen2.5-coder:32b_ee11_tpusg_batch",
      "metadata": {
        "num_run": 28
      },
      "tags": [
        "benchmark",
        "qwen2.5-coder:32b",
        "tpu_sketch_generator"
      ],
      "latency": 193.246,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-15-16-21-815484_chatcmpl-f1264113-30ee-46fb-9eac-63786fda9c2d",
          "traceId": "04bb8d22",
          "type": "GENERATION",
          "name": "04bb_tpusg_gen_attempt#1",
          "startTime": "2025-08-04T12:16:21.815000+00:00",
          "endTime": "2025-08-04T12:16:47.596000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 25781.0,
          "costDetails": {},
          "completionTokens": 876,
          "promptTokens": 1833,
          "totalTokens": 2709,
          "environment": "default",
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-15-16-55-679461_chatcmpl-45f5a448-93cf-49c2-9aa3-282708340dde",
          "traceId": "04bb8d22",
          "type": "GENERATION",
          "name": "04bb_tpusg_gen_attempt#2",
          "startTime": "2025-08-04T12:16:55.679000+00:00",
          "endTime": "2025-08-04T12:17:27.073000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 31394.0,
          "costDetails": {},
          "completionTokens": 1079,
          "promptTokens": 2048,
          "totalTokens": 3127,
          "environment": "default",
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-15-17-35-131549_chatcmpl-3565df4e-44da-4f09-a76b-902366f9d56b",
          "traceId": "04bb8d22",
          "type": "GENERATION",
          "name": "04bb_tpusg_gen_attempt#3",
          "startTime": "2025-08-04T12:17:35.131000+00:00",
          "endTime": "2025-08-04T12:18:06.216000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 31085.0,
          "costDetails": {},
          "completionTokens": 1067,
          "promptTokens": 2048,
          "totalTokens": 3115,
          "environment": "default",
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-15-18-14-279104_chatcmpl-1c64fc92-9cee-4e0b-9833-39a58207439a",
          "traceId": "04bb8d22",
          "type": "GENERATION",
          "name": "04bb_tpusg_gen_attempt#4",
          "startTime": "2025-08-04T12:18:14.279000+00:00",
          "endTime": "2025-08-04T12:18:45.718000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 31439.0,
          "costDetails": {},
          "completionTokens": 1079,
          "promptTokens": 2048,
          "totalTokens": 3127,
          "environment": "default",
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-15-18-53-870354_chatcmpl-fc83a08b-cd52-4432-bfd4-18716c1aa004",
          "traceId": "04bb8d22",
          "type": "GENERATION",
          "name": "04bb_tpusg_gen_attempt#5",
          "startTime": "2025-08-04T12:18:53.870000+00:00",
          "endTime": "2025-08-04T12:19:26.993000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 33123.0,
          "costDetails": {},
          "completionTokens": 1143,
          "promptTokens": 2048,
          "totalTokens": 3191,
          "environment": "default",
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "3ff3de02-4cbb-40c4-9624-eb7a5526922b",
          "traceId": "04bb8d22",
          "type": "SPAN",
          "name": "error_04_tpusg_failure_signal_tpu_sketch_generator",
          "startTime": "2025-08-04T12:19:35.061000+00:00",
          "level": "ERROR",
          "statusMessage": "Failed. Last error: Traceback (most recent call last):\n  File \"script_8add7014_1754309966.py\", line 66, in <module>\n    num_detections = int(interpreter.get_tensor(output_details[1]['index']))  # Correctly access the number of detections\nTypeError: only size-1 arrays can be converted to Python scalars",
          "calculatedTotalCost": 0.0,
          "costDetails": {},
          "completionTokens": 0,
          "promptTokens": 0,
          "totalTokens": 0,
          "environment": "default",
          "endTime": null,
          "model": null,
          "modelParameters": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null,
          "latency": null
        }
      ],
      "createdAt": "2025-08-04T12:16:22.337Z",
      "updatedAt": "2025-08-04T12:19:40.509Z",
      "environment": "default"
    },
    {
      "id": "d2905e8d",
      "timestamp": "2025-08-04T12:13:06.118000+00:00",
      "name": "d290_tpu_sketch_generator",
      "input": null,
      "output": {
        "status": "failed",
        "last_code": "num_detections = int(interpreter.get_tensor(output_details[1]['index'])[0])  # Access the first element of the array directly",
        "last_error": "Unexpected error during generation: Generated script is not complete. Please ensure to generate a complete Python script."
      },
      "session_id": "qwen2.5-coder:32b_ee11_tpusg_batch",
      "metadata": {
        "num_run": 27
      },
      "tags": [
        "benchmark",
        "qwen2.5-coder:32b",
        "tpu_sketch_generator"
      ],
      "latency": 190.263,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-15-13-06-120528_chatcmpl-79d9b67e-dac5-4ec9-9c47-c69f49a4af90",
          "traceId": "d2905e8d",
          "type": "GENERATION",
          "name": "d290_tpusg_gen_attempt#1",
          "startTime": "2025-08-04T12:13:06.120000+00:00",
          "endTime": "2025-08-04T12:13:32.234000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 26114.0,
          "costDetails": {},
          "completionTokens": 876,
          "promptTokens": 1833,
          "totalTokens": 2709,
          "environment": "default",
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-15-13-40-333924_chatcmpl-10e48d85-d262-4d15-8a3e-d873744bd675",
          "traceId": "d2905e8d",
          "type": "GENERATION",
          "name": "d290_tpusg_gen_attempt#2",
          "startTime": "2025-08-04T12:13:40.333000+00:00",
          "endTime": "2025-08-04T12:14:12.836000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 32503.0,
          "costDetails": {},
          "completionTokens": 1118,
          "promptTokens": 2048,
          "totalTokens": 3166,
          "environment": "default",
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-15-14-20-907480_chatcmpl-f6e7ec38-67ea-4947-917f-bda75aa7d26e",
          "traceId": "d2905e8d",
          "type": "GENERATION",
          "name": "d290_tpusg_gen_attempt#3",
          "startTime": "2025-08-04T12:14:20.907000+00:00",
          "endTime": "2025-08-04T12:14:54.013000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 33106.0,
          "costDetails": {},
          "completionTokens": 1139,
          "promptTokens": 2048,
          "totalTokens": 3187,
          "environment": "default",
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-15-15-02-122317_chatcmpl-7776b72c-9ee0-443b-a052-d61183fdf280",
          "traceId": "d2905e8d",
          "type": "GENERATION",
          "name": "d290_tpusg_gen_attempt#4",
          "startTime": "2025-08-04T12:15:02.122000+00:00",
          "endTime": "2025-08-04T12:15:34.700000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 32578.0,
          "costDetails": {},
          "completionTokens": 1123,
          "promptTokens": 2048,
          "totalTokens": 3171,
          "environment": "default",
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-15-15-42-876551_chatcmpl-2e6aeabd-bc04-46fc-8857-501af5c2cfa2",
          "traceId": "d2905e8d",
          "type": "GENERATION",
          "name": "d290_tpusg_gen_attempt#5",
          "startTime": "2025-08-04T12:15:42.876000+00:00",
          "endTime": "2025-08-04T12:16:16.375000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 33499.0,
          "costDetails": {},
          "completionTokens": 1156,
          "promptTokens": 2048,
          "totalTokens": 3204,
          "environment": "default",
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "1839c48d-cb84-4f66-b2b8-f10c375e18f1",
          "traceId": "d2905e8d",
          "type": "SPAN",
          "name": "error_d2_tpusg_failure_signal_tpu_sketch_generator",
          "startTime": "2025-08-04T12:16:16.383000+00:00",
          "level": "ERROR",
          "statusMessage": "Failed. Last error: Unexpected error during generation: Generated script is not complete. Please ensure to generate a complete Python script.",
          "calculatedTotalCost": 0.0,
          "costDetails": {},
          "completionTokens": 0,
          "promptTokens": 0,
          "totalTokens": 0,
          "environment": "default",
          "endTime": null,
          "model": null,
          "modelParameters": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null,
          "latency": null
        }
      ],
      "createdAt": "2025-08-04T12:13:06.640Z",
      "updatedAt": "2025-08-04T12:16:21.781Z",
      "environment": "default"
    },
    {
      "id": "1d5c407b",
      "timestamp": "2025-08-04T12:10:19.209000+00:00",
      "name": "1d5c_tpu_sketch_generator",
      "input": null,
      "output": {
        "status": "success",
        "sketch": "import numpy as np\nfrom tflite_runtime.interpreter import Interpreter, load_delegate\nimport cv2\n\n# Phase 1: Setup\nmodel_path  = \"/home/mendel/tinyml_autopilot/models/edgetpu_detect.tflite\"\nlabel_path  = \"/home/mendel/tinyml_autopilot/models/labelmap.txt\"\ninput_path  = \"/home/mendel/tinyml_autopilot/data//sheeps.mp4\"\noutput_path  = \"/home/mendel/tinyml_autopilot/results/sheeps_detections.mp4\"\nconfidence_threshold  = 0.5\n\n# Load labels\nwith open(label_path, 'r') as f:\n    labels = [line.strip() for line in f.readlines()]\n\n# Load Interpreter with EdgeTPU\ntry:\n    interpreter = Interpreter(model_path=model_path,\n                              experimental_delegates=[load_delegate('libedgetpu.so.1.0')])\nexcept Exception as e:\n    print(f\"Failed to load libedgetpu.so.1.0: {e}\")\n    try:\n        interpreter = Interpreter(model_path=model_path,\n                                  experimental_delegates=[load_delegate('/usr/lib/aarch64-linux-gnu/libedgetpu.so.1.0')])\n    except Exception as e:\n        print(f\"Failed to load /usr/lib/aarch64-linux-gnu/libedgetpu.so.1.0: {e}\")\n        raise\n\ninterpreter.allocate_tensors()\n\n# Get Model Details\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\n\nfloating_model = (input_details[0]['dtype'] == np.float32)\n\n# Phase 2: Input Acquisition & Preprocessing Loop\ncap = cv2.VideoCapture(input_path)\nif not cap.isOpened():\n    raise IOError(\"Cannot open video file\")\n\nframe_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\nframe_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\nfps = cap.get(cv2.CAP_PROP_FPS)\n\nout = cv2.VideoWriter(output_path, cv2.VideoWriter_fourcc(*'mp4v'), fps, (frame_width, frame_height))\n\nwhile True:\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    # Preprocess Data\n    input_data = cv2.resize(frame, (input_details[0]['shape'][1], input_details[0]['shape'][2]))\n    input_data = np.expand_dims(input_data, axis=0)\n\n    if floating_model:\n        input_data = (np.float32(input_data) - 127.5) / 127.5\n\n    # Phase 3: Inference\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n    interpreter.invoke()\n\n    # Phase 4: Output Interpretation & Handling Loop\n    detection_boxes = interpreter.get_tensor(output_details[0]['index'])[0]\n    detection_classes = interpreter.get_tensor(output_details[1]['index'])[0].astype(int)\n    detection_scores = interpreter.get_tensor(output_details[2]['index'])[0]\n\n    num_detections = len(detection_scores)  # Assuming the number of detections is the length of scores\n\n    for i in range(num_detections):\n        if detection_scores[i] > confidence_threshold:\n            box = detection_boxes[i]\n            class_id = detection_classes[i]\n            score = detection_scores[i]\n\n            # Scale and clip bounding boxes\n            ymin, xmin, ymax, xmax = box\n            (left, right, top, bottom) = (xmin * frame_width, xmax * frame_width,\n                                          ymin * frame_height, ymax * frame_height)\n\n            cv2.rectangle(frame, (int(left), int(top)), (int(right), int(bottom)), (0, 255, 0), 2)\n            label = f'{labels[class_id]}: {score:.2f}'\n            cv2.putText(frame, label, (int(left), int(top) - 10),\n                        cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n\n    # Handle Output\n    out.write(frame)\n\n# Phase 5: Cleanup\ncap.release()\nout.release()\ncv2.destroyAllWindows()"
      },
      "session_id": "qwen2.5-coder:32b_ee11_tpusg_batch",
      "metadata": {
        "num_run": 26
      },
      "tags": [
        "benchmark",
        "qwen2.5-coder:32b",
        "tpu_sketch_generator"
      ],
      "latency": 107.986,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-15-10-19-211315_chatcmpl-8e5edc01-b71d-4e1f-8fe6-a75eda9d9203",
          "traceId": "1d5c407b",
          "type": "GENERATION",
          "name": "1d5c_tpusg_gen_attempt#1",
          "startTime": "2025-08-04T12:10:19.211000+00:00",
          "endTime": "2025-08-04T12:10:45.036000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 25825.0,
          "costDetails": {},
          "completionTokens": 876,
          "promptTokens": 1833,
          "totalTokens": 2709,
          "environment": "default",
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-15-10-53-121797_chatcmpl-a650acef-cdb8-4f29-8ff8-a5279c9d98c2",
          "traceId": "1d5c407b",
          "type": "GENERATION",
          "name": "1d5c_tpusg_gen_attempt#2",
          "startTime": "2025-08-04T12:10:53.121000+00:00",
          "endTime": "2025-08-04T12:11:26.740000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 33619.0,
          "costDetails": {},
          "completionTokens": 1162,
          "promptTokens": 2048,
          "totalTokens": 3210,
          "environment": "default",
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-15-11-34-802093_chatcmpl-2cb7f18d-dc96-449b-8bd9-2208e7335f7f",
          "traceId": "1d5c407b",
          "type": "GENERATION",
          "name": "1d5c_tpusg_gen_attempt#3",
          "startTime": "2025-08-04T12:11:34.802000+00:00",
          "endTime": "2025-08-04T12:12:07.197000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 32395.0,
          "costDetails": {},
          "completionTokens": 1112,
          "promptTokens": 2048,
          "totalTokens": 3160,
          "environment": "default",
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        }
      ],
      "createdAt": "2025-08-04T12:10:19.731Z",
      "updatedAt": "2025-08-04T12:13:04.960Z",
      "environment": "default"
    },
    {
      "id": "9f0d493c",
      "timestamp": "2025-08-04T12:06:54.514000+00:00",
      "name": "9f0d_tpu_sketch_generator",
      "input": null,
      "output": {
        "status": "failed",
        "last_code": "import numpy as np\nfrom tflite_runtime.interpreter import Interpreter, load_delegate\nimport cv2\n\n# Phase 1: Setup\nmodel_path  = \"/home/mendel/tinyml_autopilot/models/edgetpu_detect.tflite\"\nlabel_path  = \"/home/mendel/tinyml_autopilot/models/labelmap.txt\"\ninput_path  = \"/home/mendel/tinyml_autopilot/data//sheeps.mp4\"\noutput_path  = \"/home/mendel/tinyml_autopilot/results/sheeps_detections.mp4\"\nconfidence_threshold  = 0.5\n\n# Load labels\nwith open(label_path, 'r') as f:\n    labels = [line.strip() for line in f.readlines()]\n\n# Load Interpreter with EdgeTPU\ntry:\n    interpreter = Interpreter(model_path=model_path,\n                              experimental_delegates=[load_delegate('libedgetpu.so.1.0')])\nexcept Exception as e:\n    print(f\"Failed to load libedgetpu.so.1.0: {e}\")\n    try:\n        interpreter = Interpreter(model_path=model_path,\n                                  experimental_delegates=[load_delegate('/usr/lib/aarch64-linux-gnu/libedgetpu.so.1.0')])\n    except Exception as e:\n        print(f\"Failed to load /usr/lib/aarch64-linux-gnu/libedgetpu.so.1.0: {e}\")\n        raise\n\ninterpreter.allocate_tensors()\n\n# Get Model Details\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\n\nfloating_model = (input_details[0]['dtype'] == np.float32)\n\nprint(\"Input details:\", input_details)\nprint(\"Output details:\", output_details)\n\n# Phase 2: Input Acquisition & Preprocessing Loop\ncap = cv2.VideoCapture(input_path)\nif not cap.isOpened():\n    raise IOError(\"Cannot open video file\")\n\nframe_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\nframe_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\nfps = cap.get(cv2.CAP_PROP_FPS)\n\nout = cv2.VideoWriter(output_path, cv2.VideoWriter_fourcc(*'mp4v'), fps, (frame_width, frame_height))\n\nwhile True:\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    # Preprocess Data\n    input_data = cv2.resize(frame, (input_details[0]['shape'][1], input_details[0]['shape'][2]))\n    input_data = np.expand_dims(input_data, axis=0)\n\n    if floating_model:\n        input_data = (np.float32(input_data) - 127.5) / 127.5\n\n    # Phase 3: Inference\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n    interpreter.invoke()\n\n    # Phase 4: Output Interpretation & Handling Loop\n    output_data = interpreter.get_tensor(output_details[0]['index'])\n    \n    # Assuming the model outputs boxes, classes, and scores in this order\n    if len(output_details) >= 3:\n        detection_boxes = interpreter.get_tensor(output_details[1]['index'])[0]\n        detection_classes = interpreter.get_tensor(output_details[2]['index'])[0].astype(int)\n        detection_scores = interpreter.get_tensor(output_details[3]['index'])\n\n        # Debugging: Print shapes of output tensors\n        print(f\"Detection boxes shape: {detection_boxes.shape}\")\n        print(f\"Detection classes shape: {detection_classes.shape}\")\n        print(f\"Detection scores shape: {detection_scores.shape}\")\n\n        # Determine the number of detections based on the shape of the boxes tensor\n        num_detections = detection_boxes.shape[0]\n\n        for i in range(num_detections):\n            if detection_scores[i] > confidence_threshold:\n                box = detection_boxes[i]\n                class_id = detection_classes[i]\n                score = detection_scores[i]\n\n                # Scale and clip bounding boxes\n                ymin, xmin, ymax, xmax = box\n                (left, right, top, bottom) = (xmin * frame_width, xmax * frame_width,\n                                              ymin * frame_height, ymax * frame_height)\n\n                cv2.rectangle(frame, (int(left), int(top)), (int(right), int(bottom)), (0, 255, 0), 2)\n                label = f'{labels[class_id]}: {score:.2f}'\n                cv2.putText(frame, label, (int(left), int(top) - 10),\n                            cv2.FONT_HERSHEY_SIMPLEX, 0.9, (36, 255, 12), 2)\n\n    # Write the frame with detections to the output video\n    out.write(frame)\n\n# Release resources\ncap.release()\nout.release()\ncv2.destroyAllWindows()",
        "last_error": "Input details: [{'name': 'normalized_input_image_tensor', 'index': 175, 'shape': array([  1, 300, 300,   3], dtype=int32), 'shape_signature': array([  1, 300, 300,   3], dtype=int32), 'dtype': <class 'numpy.uint8'>, 'quantization': (0.0078125, 128), 'quantization_parameters': {'scales': array([0.0078125], dtype=float32), 'zero_points': array([128], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}]\nOutput details: [{'name': 'TFLite_Detection_PostProcess', 'index': 167, 'shape': array([ 1, 10,  4], dtype=int32), 'shape_signature': array([ 1, 10,  4], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'TFLite_Detection_PostProcess:1', 'index': 168, 'shape': array([ 1, 10], dtype=int32), 'shape_signature': array([ 1, 10], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'TFLite_Detection_PostProcess:2', 'index': 169, 'shape': array([ 1, 10], dtype=int32), 'shape_signature': array([ 1, 10], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'TFLite_Detection_PostProcess:3', 'index': 170, 'shape': array([1], dtype=int32), 'shape_signature': array([1], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}]\nDetection boxes shape: (10,)\nDetection classes shape: (10,)\nDetection scores shape: (1,)\nTraceback (most recent call last):\n  File \"script_6d2b607f_1754309404.py\", line 91, in <module>\n    ymin, xmin, ymax, xmax = box\nTypeError: cannot unpack non-iterable numpy.float32 object"
      },
      "session_id": "qwen2.5-coder:32b_ee11_tpusg_batch",
      "metadata": {
        "num_run": 25
      },
      "tags": [
        "benchmark",
        "qwen2.5-coder:32b",
        "tpu_sketch_generator"
      ],
      "latency": 198.084,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-15-06-54-516567_chatcmpl-43de26b4-08d6-4c40-832b-81be96f8ff62",
          "traceId": "9f0d493c",
          "type": "GENERATION",
          "name": "9f0d_tpusg_gen_attempt#1",
          "startTime": "2025-08-04T12:06:54.516000+00:00",
          "endTime": "2025-08-04T12:07:20.336000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 25820.0,
          "costDetails": {},
          "completionTokens": 876,
          "promptTokens": 1833,
          "totalTokens": 2709,
          "environment": "default",
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-15-07-28-429516_chatcmpl-189e9ae2-449f-46f0-af2a-e92a4536f9a1",
          "traceId": "9f0d493c",
          "type": "GENERATION",
          "name": "9f0d_tpusg_gen_attempt#2",
          "startTime": "2025-08-04T12:07:28.429000+00:00",
          "endTime": "2025-08-04T12:08:00.901000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 32472.0,
          "costDetails": {},
          "completionTokens": 1118,
          "promptTokens": 2048,
          "totalTokens": 3166,
          "environment": "default",
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-15-08-09-030862_chatcmpl-4dd4e777-daa9-487b-a593-1dd8eb6c7e12",
          "traceId": "9f0d493c",
          "type": "GENERATION",
          "name": "9f0d_tpusg_gen_attempt#3",
          "startTime": "2025-08-04T12:08:09.030000+00:00",
          "endTime": "2025-08-04T12:08:40.119000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 31089.0,
          "costDetails": {},
          "completionTokens": 1067,
          "promptTokens": 2048,
          "totalTokens": 3115,
          "environment": "default",
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-15-08-48-227036_chatcmpl-67d6cd24-88eb-4a5b-a02d-412873fd3c42",
          "traceId": "9f0d493c",
          "type": "GENERATION",
          "name": "9f0d_tpusg_gen_attempt#4",
          "startTime": "2025-08-04T12:08:48.227000+00:00",
          "endTime": "2025-08-04T12:09:20.656000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 32429.0,
          "costDetails": {},
          "completionTokens": 1115,
          "promptTokens": 2048,
          "totalTokens": 3163,
          "environment": "default",
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-15-09-28-736607_chatcmpl-e907b6bc-f097-4e0d-b4d6-852cacc0b880",
          "traceId": "9f0d493c",
          "type": "GENERATION",
          "name": "9f0d_tpusg_gen_attempt#5",
          "startTime": "2025-08-04T12:09:28.736000+00:00",
          "endTime": "2025-08-04T12:10:04.555000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 35819.0,
          "costDetails": {},
          "completionTokens": 1239,
          "promptTokens": 2048,
          "totalTokens": 3287,
          "environment": "default",
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "606769ee-9629-459e-8626-dcb69a537e1e",
          "traceId": "9f0d493c",
          "type": "SPAN",
          "name": "error_9f_tpusg_failure_signal_tpu_sketch_generator",
          "startTime": "2025-08-04T12:10:12.600000+00:00",
          "level": "ERROR",
          "statusMessage": "Failed. Last error: Input details: [{'name': 'normalized_input_image_tensor', 'index': 175, 'shape': array([  1, 300, 300,   3], dtype=int32), 'shape_signature': array([  1, 300, 300,   3], dtype=int32), 'dtype': <class 'numpy.uint8'>, 'quantization': (0.0078125, 128), 'quantization_parameters': {'scales': array([0.0078125], dtype=float32), 'zero_points': array([128], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}]\nOutput details: [{'name': 'TFLite_Detection_PostProcess', 'index': 167, 'shape': array([ 1, 10,  4], dtype=int32), 'shape_signature': array([ 1, 10,  4], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'TFLite_Detection_PostProcess:1', 'index': 168, 'shape': array([ 1, 10], dtype=int32), 'shape_signature': array([ 1, 10], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'TFLite_Detection_PostProcess:2', 'index': 169, 'shape': array([ 1, 10], dtype=int32), 'shape_signature': array([ 1, 10], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'TFLite_Detection_PostProcess:3', 'index': 170, 'shape': array([1], dtype=int32), 'shape_signature': array([1], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}]\nDetection boxes shape: (10,)\nDetection classes shape: (10,)\nDetection scores shape: (1,)\nTraceback (most recent call last):\n  File \"script_6d2b607f_1754309404.py\", line 91, in <module>\n    ymin, xmin, ymax, xmax = box\nTypeError: cannot unpack non-iterable numpy.float32 object",
          "calculatedTotalCost": 0.0,
          "costDetails": {},
          "completionTokens": 0,
          "promptTokens": 0,
          "totalTokens": 0,
          "environment": "default",
          "endTime": null,
          "model": null,
          "modelParameters": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null,
          "latency": null
        }
      ],
      "createdAt": "2025-08-04T12:06:55.037Z",
      "updatedAt": "2025-08-04T12:10:17.704Z",
      "environment": "default"
    },
    {
      "id": "96e5032d",
      "timestamp": "2025-08-04T12:03:34.905000+00:00",
      "name": "96e5_tpu_sketch_generator",
      "input": null,
      "output": {
        "status": "failed",
        "last_code": "import numpy as np\nfrom tflite_runtime.interpreter import Interpreter, load_delegate\n\n# Phase 1: Setup\nmodel_path  = \"/home/mendel/tinyml_autopilot/models/edgetpu_detect.tflite\"\nlabel_path  = \"/home/mendel/tinyml_autopilot/models/labelmap.txt\"\ninput_path  = \"/home/mendel/tinyml_autopilot/data//sheeps.mp4\"\noutput_path  = \"/home/mendel/tinyml_autopilot/results/sheeps_detections.mp4\"\nconfidence_threshold  = 0.5\n\n# Load labels\nwith open(label_path, 'r') as f:\n    labels = [line.strip() for line in f.readlines()]\n\n# Load Interpreter with EdgeTPU\ntry:\n    interpreter = Interpreter(model_path=model_path,\n                              experimental_delegates=[load_delegate('libedgetpu.so.1.0')])\nexcept Exception as e:\n    print(f\"Failed to load libedgetpu.so.1.0: {e}\")\n    try:\n        interpreter = Interpreter(model_path=model_path,\n                                  experimental_delegates=[load_delegate('/usr/lib/aarch64-linux-gnu/libedgetpu.so.1.0')])\n    except Exception as e:\n        print(f\"Failed to load /usr/lib/aarch64-linux-gnu/libedgetpu.so.1.0: {e}\")\n        raise\n\ninterpreter.allocate_tensors()\n\n# Get Model Details\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\n\nfloating_model = (input_details[0]['dtype'] == np.float32)\n\n# Phase 2: Input Acquisition & Preprocessing Loop\nimport cv2\n\ncap = cv2.VideoCapture(input_path)\nif not cap.isOpened():\n    raise IOError(\"Cannot open video file\")\n\nframe_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\nframe_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\nfps = cap.get(cv2.CAP_PROP_FPS)\n\nout = cv2.VideoWriter(output_path, cv2.VideoWriter_fourcc(*'mp4v'), fps, (frame_width, frame_height))\n\nwhile True:\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    # Preprocess Data\n    input_data = cv2.resize(frame, (input_details[0]['shape'][1], input_details[0]['shape'][2]))\n    input_data = np.expand_dims(input_data, axis=0)\n\n    if floating_model:\n        input_data = (np.float32(input_data) - 127.5) / 127.5\n\n    # Phase 3: Inference\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n    interpreter.invoke()\n\n    # Phase 4: Output Interpretation & Handling Loop\n    output_data = interpreter.get_tensor(output_details[0]['index'])\n    num_detections = int(interpreter.get_tensor(output_details[1]['index']))  # Correctly extract the scalar value\n    detection_boxes = interpreter.get_tensor(output_details[2]['index'])[0]\n    detection_classes = interpreter.get_tensor(output_details[3]['index'])[0].astype(int)\n    detection_scores = interpreter.get_tensor(output_details[4]['index'])[0]\n\n    for i in range(num_detections):\n        if detection_scores[i] > confidence_threshold:\n            box = detection_boxes[i]\n            class_id = detection_classes[i]\n            score = detection_scores[i]\n\n            # Scale and clip bounding boxes\n            ymin, xmin, ymax, xmax = box\n            (left, right, top, bottom) = (xmin * frame_width, xmax * frame_width,\n                                          ymin * frame_height, ymax * frame_height)\n\n            cv2.rectangle(frame, (int(left), int(top)), (int(right), int(bottom)), (0, 255, 0), 2)\n            label = f'{labels[class_id]}: {score:.2f}'\n            cv2.putText(frame, label, (int(left), int(top) - 10),\n                        cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n\n    # Write the frame to the output video\n    out.write(frame)\n\n# Phase 5: Cleanup\ncap.release()\nout.release()\ncv2.destroyAllWindows()",
        "last_error": "Traceback (most recent call last):\n  File \"script_7dd8a1b1_1754309200.py\", line 67, in <module>\n    num_detections = int(interpreter.get_tensor(output_details[1]['index']))  # Correctly extract the scalar value\nTypeError: only size-1 arrays can be converted to Python scalars"
      },
      "session_id": "qwen2.5-coder:32b_ee11_tpusg_batch",
      "metadata": {
        "num_run": 24
      },
      "tags": [
        "benchmark",
        "qwen2.5-coder:32b",
        "tpu_sketch_generator"
      ],
      "latency": 193.609,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-15-03-34-907028_chatcmpl-0d8e968c-1c71-4cbe-8201-d5d469e8c878",
          "traceId": "96e5032d",
          "type": "GENERATION",
          "name": "96e5_tpusg_gen_attempt#1",
          "startTime": "2025-08-04T12:03:34.907000+00:00",
          "endTime": "2025-08-04T12:04:00.829000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 25922.0,
          "costDetails": {},
          "completionTokens": 876,
          "promptTokens": 1833,
          "totalTokens": 2709,
          "environment": "default",
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-15-04-08-957489_chatcmpl-21cdc5be-633f-498f-ab0c-e68b23b64be5",
          "traceId": "96e5032d",
          "type": "GENERATION",
          "name": "96e5_tpusg_gen_attempt#2",
          "startTime": "2025-08-04T12:04:08.957000+00:00",
          "endTime": "2025-08-04T12:04:42.009000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 33052.0,
          "costDetails": {},
          "completionTokens": 1141,
          "promptTokens": 2048,
          "totalTokens": 3189,
          "environment": "default",
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-15-04-50-068145_chatcmpl-89b627b3-3d4e-486e-abc0-645b898bb094",
          "traceId": "96e5032d",
          "type": "GENERATION",
          "name": "96e5_tpusg_gen_attempt#3",
          "startTime": "2025-08-04T12:04:50.068000+00:00",
          "endTime": "2025-08-04T12:05:20.836000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 30768.0,
          "costDetails": {},
          "completionTokens": 1054,
          "promptTokens": 2048,
          "totalTokens": 3102,
          "environment": "default",
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-15-05-28-957014_chatcmpl-778eea78-5e1d-4b15-ae0f-b189392b8b18",
          "traceId": "96e5032d",
          "type": "GENERATION",
          "name": "96e5_tpusg_gen_attempt#4",
          "startTime": "2025-08-04T12:05:28.957000+00:00",
          "endTime": "2025-08-04T12:06:00.321000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 31364.0,
          "costDetails": {},
          "completionTokens": 1077,
          "promptTokens": 2048,
          "totalTokens": 3125,
          "environment": "default",
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-15-06-08-379596_chatcmpl-778471ba-c917-48b0-88d1-b8318d2974d9",
          "traceId": "96e5032d",
          "type": "GENERATION",
          "name": "96e5_tpusg_gen_attempt#5",
          "startTime": "2025-08-04T12:06:08.379000+00:00",
          "endTime": "2025-08-04T12:06:40.469000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 32090.0,
          "costDetails": {},
          "completionTokens": 1103,
          "promptTokens": 2048,
          "totalTokens": 3151,
          "environment": "default",
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "a2c276d1-2be9-4bb8-bdc7-2369bf688bd7",
          "traceId": "96e5032d",
          "type": "SPAN",
          "name": "error_96_tpusg_failure_signal_tpu_sketch_generator",
          "startTime": "2025-08-04T12:06:48.516000+00:00",
          "level": "ERROR",
          "statusMessage": "Failed. Last error: Traceback (most recent call last):\n  File \"script_7dd8a1b1_1754309200.py\", line 67, in <module>\n    num_detections = int(interpreter.get_tensor(output_details[1]['index']))  # Correctly extract the scalar value\nTypeError: only size-1 arrays can be converted to Python scalars",
          "calculatedTotalCost": 0.0,
          "costDetails": {},
          "completionTokens": 0,
          "promptTokens": 0,
          "totalTokens": 0,
          "environment": "default",
          "endTime": null,
          "model": null,
          "modelParameters": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null,
          "latency": null
        }
      ],
      "createdAt": "2025-08-04T12:03:35.428Z",
      "updatedAt": "2025-08-04T12:06:54.115Z",
      "environment": "default"
    },
    {
      "id": "a4877be0",
      "timestamp": "2025-08-04T12:00:10.914000+00:00",
      "name": "a487_tpu_sketch_generator",
      "input": null,
      "output": {
        "status": "failed",
        "last_code": "import numpy as np\nfrom tflite_runtime.interpreter import Interpreter, load_delegate\nimport cv2\n\n# Phase 1: Setup\nmodel_path  = \"/home/mendel/tinyml_autopilot/models/edgetpu_detect.tflite\"\nlabel_path  = \"/home/mendel/tinyml_autopilot/models/labelmap.txt\"\ninput_path  = \"/home/mendel/tinyml_autopilot/data//sheeps.mp4\"\noutput_path  = \"/home/mendel/tinyml_autopilot/results/sheeps_detections.mp4\"\nconfidence_threshold  = 0.5\n\n# Load labels\nwith open(label_path, 'r') as f:\n    labels = [line.strip() for line in f.readlines()]\n\n# Load Interpreter with EdgeTPU\ntry:\n    interpreter = Interpreter(model_path=model_path,\n                              experimental_delegates=[load_delegate('libedgetpu.so.1.0')])\nexcept Exception as e:\n    print(f\"Failed to load libedgetpu.so.1.0: {e}\")\n    try:\n        interpreter = Interpreter(model_path=model_path,\n                                  experimental_delegates=[load_delegate('/usr/lib/aarch64-linux-gnu/libedgetpu.so.1.0')])\n    except Exception as e:\n        print(f\"Failed to load /usr/lib/aarch64-linux-gnu/libedgetpu.so.1.0: {e}\")\n        raise\n\ninterpreter.allocate_tensors()\n\n# Get Model Details\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\n\nfloating_model = (input_details[0]['dtype'] == np.float32)\n\n# Phase 2: Input Acquisition & Preprocessing Loop\ncap = cv2.VideoCapture(input_path)\nif not cap.isOpened():\n    raise IOError(\"Cannot open video file\")\n\nframe_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\nframe_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\nfps = cap.get(cv2.CAP_PROP_FPS)\n\nout = cv2.VideoWriter(output_path, cv2.VideoWriter_fourcc(*'mp4v'), fps, (frame_width, frame_height))\n\nwhile True:\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    # Preprocess Data\n    input_data = cv2.resize(frame, (input_details[0]['shape'][1], input_details[0]['shape'][2]))\n    input_data = np.expand_dims(input_data, axis=0)\n\n    if floating_model:\n        input_data = (np.float32(input_data) - 127.5) / 127.5\n\n    # Phase 3: Inference\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n    interpreter.invoke()\n\n    # Phase 4: Output Interpretation & Handling Loop\n    output_data = interpreter.get_tensor(output_details[0]['index'])\n    \n    # Assuming the second output tensor is a single value array containing num_detections\n    num_detections = int(interpreter.get_tensor(output_details[1]['index']))\n    detection_boxes = interpreter.get_tensor(output_details[2]['index'])[0]\n    detection_classes = interpreter.get_tensor(output_details[3]['index'])[0].astype(int)\n    detection_scores = interpreter.get_tensor(output_details[4]['index'])[0]\n\n    for i in range(num_detections):\n        if detection_scores[i] > confidence_threshold:\n            box = detection_boxes[i]\n            class_id = detection_classes[i]\n            score = detection_scores[i]\n\n            # Scale and clip bounding boxes\n            ymin, xmin, ymax, xmax = box\n            (left, right, top, bottom) = (xmin * frame_width, xmax * frame_width,\n                                          ymin * frame_height, ymax * frame_height)\n\n            cv2.rectangle(frame, (int(left), int(top)), (int(right), int(bottom)), (0, 255, 0), 2)\n            label = f'{labels[class_id]}: {score:.2f}'\n            cv2.putText(frame, label, (int(left), int(top) - 10),\n                        cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n\n    # Handle Output\n    out.write(frame)\n\n# Phase 5: Cleanup\ncap.release()\nout.release()\ncv2.destroyAllWindows()",
        "last_error": "Traceback (most recent call last):\n  File \"script_21ef22d8_1754309000.py\", line 68, in <module>\n    num_detections = int(interpreter.get_tensor(output_details[1]['index']))\nTypeError: only size-1 arrays can be converted to Python scalars"
      },
      "session_id": "qwen2.5-coder:32b_ee11_tpusg_batch",
      "metadata": {
        "num_run": 23
      },
      "tags": [
        "benchmark",
        "qwen2.5-coder:32b",
        "tpu_sketch_generator"
      ],
      "latency": 197.905,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-15-00-10-916069_chatcmpl-b9e3b60b-dbe8-45fd-b127-e36378051617",
          "traceId": "a4877be0",
          "type": "GENERATION",
          "name": "a487_tpusg_gen_attempt#1",
          "startTime": "2025-08-04T12:00:10.916000+00:00",
          "endTime": "2025-08-04T12:00:36.835000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 25919.0,
          "costDetails": {},
          "completionTokens": 876,
          "promptTokens": 1833,
          "totalTokens": 2709,
          "environment": "default",
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-15-00-44-943200_chatcmpl-4bdaef6a-d9ec-41c4-a99f-c46a08a3bb2a",
          "traceId": "a4877be0",
          "type": "GENERATION",
          "name": "a487_tpusg_gen_attempt#2",
          "startTime": "2025-08-04T12:00:44.943000+00:00",
          "endTime": "2025-08-04T12:01:18.009000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 33066.0,
          "costDetails": {},
          "completionTokens": 1141,
          "promptTokens": 2048,
          "totalTokens": 3189,
          "environment": "default",
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-15-01-26-112852_chatcmpl-29c6fc98-0353-45f8-a97c-46c5fa388428",
          "traceId": "a4877be0",
          "type": "GENERATION",
          "name": "a487_tpusg_gen_attempt#3",
          "startTime": "2025-08-04T12:01:26.112000+00:00",
          "endTime": "2025-08-04T12:01:59.218000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 33106.0,
          "costDetails": {},
          "completionTokens": 1143,
          "promptTokens": 2048,
          "totalTokens": 3191,
          "environment": "default",
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-15-02-07-255411_chatcmpl-afccffb3-b28e-46c2-a8e0-32bf719e67c1",
          "traceId": "a4877be0",
          "type": "GENERATION",
          "name": "a487_tpusg_gen_attempt#4",
          "startTime": "2025-08-04T12:02:07.255000+00:00",
          "endTime": "2025-08-04T12:02:40.150000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 32895.0,
          "costDetails": {},
          "completionTokens": 1135,
          "promptTokens": 2048,
          "totalTokens": 3183,
          "environment": "default",
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-15-02-48-244897_chatcmpl-f213e3d8-cd3e-4c04-b3f2-c5b9aea9f19f",
          "traceId": "a4877be0",
          "type": "GENERATION",
          "name": "a487_tpusg_gen_attempt#5",
          "startTime": "2025-08-04T12:02:48.244000+00:00",
          "endTime": "2025-08-04T12:03:20.731000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 32487.0,
          "costDetails": {},
          "completionTokens": 1120,
          "promptTokens": 2048,
          "totalTokens": 3168,
          "environment": "default",
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "da48ce23-1542-4161-af62-b7cd6311c292",
          "traceId": "a4877be0",
          "type": "SPAN",
          "name": "error_a4_tpusg_failure_signal_tpu_sketch_generator",
          "startTime": "2025-08-04T12:03:28.821000+00:00",
          "level": "ERROR",
          "statusMessage": "Failed. Last error: Traceback (most recent call last):\n  File \"script_21ef22d8_1754309000.py\", line 68, in <module>\n    num_detections = int(interpreter.get_tensor(output_details[1]['index']))\nTypeError: only size-1 arrays can be converted to Python scalars",
          "calculatedTotalCost": 0.0,
          "costDetails": {},
          "completionTokens": 0,
          "promptTokens": 0,
          "totalTokens": 0,
          "environment": "default",
          "endTime": null,
          "model": null,
          "modelParameters": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null,
          "latency": null
        }
      ],
      "createdAt": "2025-08-04T12:00:11.436Z",
      "updatedAt": "2025-08-04T12:03:34.116Z",
      "environment": "default"
    },
    {
      "id": "63d57eef",
      "timestamp": "2025-08-04T11:56:43.355000+00:00",
      "name": "63d5_tpu_sketch_generator",
      "input": null,
      "output": {
        "status": "success",
        "sketch": "import numpy as np\nfrom tflite_runtime.interpreter import Interpreter, load_delegate\n\n# Phase 1: Setup\nmodel_path  = \"/home/mendel/tinyml_autopilot/models/edgetpu_detect.tflite\"\nlabel_path  = \"/home/mendel/tinyml_autopilot/models/labelmap.txt\"\ninput_path  = \"/home/mendel/tinyml_autopilot/data//sheeps.mp4\"\noutput_path  = \"/home/mendel/tinyml_autopilot/results/sheeps_detections.mp4\"\nconfidence_threshold  = 0.5\n\n# Load labels\nwith open(label_path, 'r') as f:\n    labels = [line.strip() for line in f.readlines()]\n\n# Load Interpreter with EdgeTPU\ntry:\n    interpreter = Interpreter(model_path=model_path,\n                              experimental_delegates=[load_delegate('libedgetpu.so.1.0')])\nexcept Exception as e:\n    print(f\"Failed to load libedgetpu.so.1.0: {e}\")\n    try:\n        interpreter = Interpreter(model_path=model_path,\n                                  experimental_delegates=[load_delegate('/usr/lib/aarch64-linux-gnu/libedgetpu.so.1.0')])\n    except Exception as e:\n        print(f\"Failed to load /usr/lib/aarch64-linux-gnu/libedgetpu.so.1.0: {e}\")\n        raise\n\ninterpreter.allocate_tensors()\n\n# Get Model Details\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\n\nfloating_model = (input_details[0]['dtype'] == np.float32)\n\n# Phase 2: Input Acquisition & Preprocessing Loop\nimport cv2\n\ncap = cv2.VideoCapture(input_path)\nif not cap.isOpened():\n    raise IOError(\"Cannot open video file\")\n\nframe_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\nframe_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\nfps = cap.get(cv2.CAP_PROP_FPS)\n\nout = cv2.VideoWriter(output_path, cv2.VideoWriter_fourcc(*'mp4v'), fps, (frame_width, frame_height))\n\nwhile True:\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    # Preprocess Data\n    input_data = cv2.resize(frame, (input_details[0]['shape'][1], input_details[0]['shape'][2]))\n    input_data = np.expand_dims(input_data, axis=0)\n\n    if floating_model:\n        input_data = (np.float32(input_data) - 127.5) / 127.5\n\n    # Phase 3: Inference\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n    interpreter.invoke()\n\n    # Phase 4: Output Interpretation & Handling Loop\n    detection_boxes = interpreter.get_tensor(output_details[0]['index'])[0]\n    detection_classes = interpreter.get_tensor(output_details[1]['index'])[0].astype(int)\n    detection_scores = interpreter.get_tensor(output_details[2]['index'])[0]\n    num_detections = int(interpreter.get_tensor(output_details[3]['index']))  # Access the scalar value directly\n\n    for i in range(num_detections):\n        if detection_scores[i] > confidence_threshold:\n            box = detection_boxes[i]\n            class_id = detection_classes[i]\n            score = detection_scores[i]\n\n            # Scale and clip bounding boxes\n            ymin, xmin, ymax, xmax = box\n            (left, right, top, bottom) = (xmin * frame_width, xmax * frame_width,\n                                          ymin * frame_height, ymax * frame_height)\n\n            cv2.rectangle(frame, (int(left), int(top)), (int(right), int(bottom)), (0, 255, 0), 2)\n            label = f'{labels[class_id]}: {score:.2f}'\n            cv2.putText(frame, label, (int(left), int(top) - 10),\n                        cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n\n    # Handle Output\n    out.write(frame)\n\n# Phase 5: Cleanup\ncap.release()\nout.release()\ncv2.destroyAllWindows()"
      },
      "session_id": "qwen2.5-coder:32b_ee11_tpusg_batch",
      "metadata": {
        "num_run": 22
      },
      "tags": [
        "benchmark",
        "qwen2.5-coder:32b",
        "tpu_sketch_generator"
      ],
      "latency": 149.073,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-14-56-43-356588_chatcmpl-1ef687bf-10c3-48ad-b496-e21ceaa71eb4",
          "traceId": "63d57eef",
          "type": "GENERATION",
          "name": "63d5_tpusg_gen_attempt#1",
          "startTime": "2025-08-04T11:56:43.356000+00:00",
          "endTime": "2025-08-04T11:57:09.175000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 25819.0,
          "costDetails": {},
          "completionTokens": 876,
          "promptTokens": 1833,
          "totalTokens": 2709,
          "environment": "default",
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-14-57-17-251658_chatcmpl-dc6a6d28-b58f-40a8-9961-37febf0c2314",
          "traceId": "63d57eef",
          "type": "GENERATION",
          "name": "63d5_tpusg_gen_attempt#2",
          "startTime": "2025-08-04T11:57:17.251000+00:00",
          "endTime": "2025-08-04T11:57:48.479000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 31228.0,
          "costDetails": {},
          "completionTokens": 1070,
          "promptTokens": 2048,
          "totalTokens": 3118,
          "environment": "default",
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-14-57-56-857903_chatcmpl-5bbad4ea-f918-45ae-8586-a117dec58b81",
          "traceId": "63d57eef",
          "type": "GENERATION",
          "name": "63d5_tpusg_gen_attempt#3",
          "startTime": "2025-08-04T11:57:56.857000+00:00",
          "endTime": "2025-08-04T11:58:31.180000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 34323.0,
          "costDetails": {},
          "completionTokens": 1167,
          "promptTokens": 2048,
          "totalTokens": 3215,
          "environment": "default",
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-14-58-39-208988_chatcmpl-23712bc5-a36c-493c-993b-4a77b06ab597",
          "traceId": "63d57eef",
          "type": "GENERATION",
          "name": "63d5_tpusg_gen_attempt#4",
          "startTime": "2025-08-04T11:58:39.208000+00:00",
          "endTime": "2025-08-04T11:59:12.429000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 33221.0,
          "costDetails": {},
          "completionTokens": 1132,
          "promptTokens": 2048,
          "totalTokens": 3180,
          "environment": "default",
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        }
      ],
      "createdAt": "2025-08-04T11:56:43.875Z",
      "updatedAt": "2025-08-04T12:00:10.123Z",
      "environment": "default"
    },
    {
      "id": "c0830786",
      "timestamp": "2025-08-04T11:53:22.729000+00:00",
      "name": "c083_tpu_sketch_generator",
      "input": null,
      "output": {
        "status": "failed",
        "last_code": "import numpy as np\nfrom tflite_runtime.interpreter import Interpreter, load_delegate\nimport cv2\n\n# Phase 1: Setup\nmodel_path  = \"/home/mendel/tinyml_autopilot/models/edgetpu_detect.tflite\"\nlabel_path  = \"/home/mendel/tinyml_autopilot/models/labelmap.txt\"\ninput_path  = \"/home/mendel/tinyml_autopilot/data//sheeps.mp4\"\noutput_path  = \"/home/mendel/tinyml_autopilot/results/sheeps_detections.mp4\"\nconfidence_threshold  = 0.5\n\n# Load labels\nwith open(label_path, 'r') as f:\n    labels = [line.strip() for line in f.readlines()]\n\n# Load Interpreter with EdgeTPU\ntry:\n    interpreter = Interpreter(model_path=model_path,\n                              experimental_delegates=[load_delegate('libedgetpu.so.1.0')])\nexcept Exception as e:\n    print(f\"Failed to load libedgetpu.so.1.0: {e}\")\n    try:\n        interpreter = Interpreter(model_path=model_path,\n                                  experimental_delegates=[load_delegate('/usr/lib/aarch64-linux-gnu/libedgetpu.so.1.0')])\n    except Exception as e:\n        print(f\"Failed to load /usr/lib/aarch64-linux-gnu/libedgetpu.so.1.0: {e}\")\n        raise\n\ninterpreter.allocate_tensors()\n\n# Get Model Details\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\n\nfloating_model = (input_details[0]['dtype'] == np.float32)\n\n# Phase 2: Input Acquisition & Preprocessing Loop\ncap = cv2.VideoCapture(input_path)\nif not cap.isOpened():\n    raise IOError(\"Cannot open video file\")\n\nframe_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\nframe_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\nfps = cap.get(cv2.CAP_PROP_FPS)\n\nout = cv2.VideoWriter(output_path, cv2.VideoWriter_fourcc(*'mp4v'), fps, (frame_width, frame_height))\n\nwhile True:\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    # Preprocess Data\n    input_data = cv2.resize(frame, (input_details[0]['shape'][1], input_details[0]['shape'][2]))\n    input_data = np.expand_dims(input_data, axis=0)\n\n    if floating_model:\n        input_data = (np.float32(input_data) - 127.5) / 127.5\n\n    # Phase 3: Inference\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n    interpreter.invoke()\n\n    # Phase 4: Output Interpretation & Handling Loop\n    output_data = interpreter.get_tensor(output_details[0]['index'])\n    num_detections = interpreter.get_tensor(output_details[1]['index']).item()  # Correctly extract the scalar value\n    detection_boxes = interpreter.get_tensor(output_details[2]['index'])[0]\n    detection_classes = interpreter.get_tensor(output_details[3]['index'])[0].astype(int)\n    detection_scores = interpreter.get_tensor(output_details[4]['index'])[0]\n\n    for i in range(num_detections):\n        if detection_scores[i] > confidence_threshold:\n            box = detection_boxes[i]\n            class_id = detection_classes[i]\n            score = detection_scores[i]\n\n            # Scale and clip bounding boxes\n            ymin, xmin, ymax, xmax = box\n            (left, right, top, bottom) = (xmin * frame_width, xmax * frame_width,\n                                          ymin * frame_height, ymax * frame_height)\n\n            cv2.rectangle(frame, (int(left), int(top)), (int(right), int(bottom)), (0, 255, 0), 2)\n            label = f'{labels[class_id]}: {score:.2f}'\n            cv2.putText(frame, label, (int(left), int(top) - 10),\n                        cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n\n    # Write the frame to the output video\n    out.write(frame)\n\n# Release resources\ncap.release()\nout.release()\ncv2.destroyAllWindows()",
        "last_error": "Traceback (most recent call last):\n  File \"script_a8fd616e_1754308589.py\", line 66, in <module>\n    num_detections = interpreter.get_tensor(output_details[1]['index']).item()  # Correctly extract the scalar value\nValueError: can only convert an array of size 1 to a Python scalar"
      },
      "session_id": "qwen2.5-coder:32b_ee11_tpusg_batch",
      "metadata": {
        "num_run": 21
      },
      "tags": [
        "benchmark",
        "qwen2.5-coder:32b",
        "tpu_sketch_generator"
      ],
      "latency": 194.391,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-14-53-22-731204_chatcmpl-fb97954c-b26c-44d9-ac9e-6f3365507796",
          "traceId": "c0830786",
          "type": "GENERATION",
          "name": "c083_tpusg_gen_attempt#1",
          "startTime": "2025-08-04T11:53:22.731000+00:00",
          "endTime": "2025-08-04T11:53:48.540000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 25809.0,
          "costDetails": {},
          "completionTokens": 876,
          "promptTokens": 1833,
          "totalTokens": 2709,
          "environment": "default",
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-14-53-56-664764_chatcmpl-6d40bafd-9696-49ab-bddd-878b52d6200a",
          "traceId": "c0830786",
          "type": "GENERATION",
          "name": "c083_tpusg_gen_attempt#2",
          "startTime": "2025-08-04T11:53:56.664000+00:00",
          "endTime": "2025-08-04T11:54:29.956000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 33292.0,
          "costDetails": {},
          "completionTokens": 1150,
          "promptTokens": 2048,
          "totalTokens": 3198,
          "environment": "default",
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-14-54-37-986191_chatcmpl-dbcabfb6-7b84-4b8e-857a-bae1437bbb72",
          "traceId": "c0830786",
          "type": "GENERATION",
          "name": "c083_tpusg_gen_attempt#3",
          "startTime": "2025-08-04T11:54:37.986000+00:00",
          "endTime": "2025-08-04T11:55:08.697000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 30711.0,
          "costDetails": {},
          "completionTokens": 1052,
          "promptTokens": 2048,
          "totalTokens": 3100,
          "environment": "default",
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-14-55-16-784148_chatcmpl-5b46cfdd-a05a-44cf-a17f-ff17ba05cb30",
          "traceId": "c0830786",
          "type": "GENERATION",
          "name": "c083_tpusg_gen_attempt#4",
          "startTime": "2025-08-04T11:55:16.784000+00:00",
          "endTime": "2025-08-04T11:55:49.319000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 32535.0,
          "costDetails": {},
          "completionTokens": 1121,
          "promptTokens": 2048,
          "totalTokens": 3169,
          "environment": "default",
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-14-55-57-396019_chatcmpl-7bc8e808-b0f2-4d72-bd99-af0cb1fe0e81",
          "traceId": "c0830786",
          "type": "GENERATION",
          "name": "c083_tpusg_gen_attempt#5",
          "startTime": "2025-08-04T11:55:57.396000+00:00",
          "endTime": "2025-08-04T11:56:29.006000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 31610.0,
          "costDetails": {},
          "completionTokens": 1086,
          "promptTokens": 2048,
          "totalTokens": 3134,
          "environment": "default",
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "626a845d-ff57-4c29-b22d-93e1df1d1c24",
          "traceId": "c0830786",
          "type": "SPAN",
          "name": "error_c0_tpusg_failure_signal_tpu_sketch_generator",
          "startTime": "2025-08-04T11:56:37.122000+00:00",
          "level": "ERROR",
          "statusMessage": "Failed. Last error: Traceback (most recent call last):\n  File \"script_a8fd616e_1754308589.py\", line 66, in <module>\n    num_detections = interpreter.get_tensor(output_details[1]['index']).item()  # Correctly extract the scalar value\nValueError: can only convert an array of size 1 to a Python scalar",
          "calculatedTotalCost": 0.0,
          "costDetails": {},
          "completionTokens": 0,
          "promptTokens": 0,
          "totalTokens": 0,
          "environment": "default",
          "endTime": null,
          "model": null,
          "modelParameters": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null,
          "latency": null
        }
      ],
      "createdAt": "2025-08-04T11:53:23.252Z",
      "updatedAt": "2025-08-04T11:56:42.416Z",
      "environment": "default"
    },
    {
      "id": "d958ce53",
      "timestamp": "2025-08-04T11:51:18.497000+00:00",
      "name": "d958_tpu_sketch_generator",
      "input": null,
      "output": {
        "status": "success",
        "sketch": "import numpy as np\nfrom tflite_runtime.interpreter import Interpreter, load_delegate\nimport cv2\n\n# Phase 1: Setup\nmodel_path  = \"/home/mendel/tinyml_autopilot/models/edgetpu_detect.tflite\"\nlabel_path  = \"/home/mendel/tinyml_autopilot/models/labelmap.txt\"\ninput_path  = \"/home/mendel/tinyml_autopilot/data//sheeps.mp4\"\noutput_path  = \"/home/mendel/tinyml_autopilot/results/sheeps_detections.mp4\"\nconfidence_threshold  = 0.5\n\n# Load labels\nwith open(label_path, 'r') as f:\n    labels = [line.strip() for line in f.readlines()]\n\n# Load Interpreter with EdgeTPU\ntry:\n    interpreter = Interpreter(model_path=model_path,\n                              experimental_delegates=[load_delegate('libedgetpu.so.1.0')])\nexcept Exception as e:\n    print(f\"Failed to load libedgetpu.so.1.0: {e}\")\n    try:\n        interpreter = Interpreter(model_path=model_path,\n                                  experimental_delegates=[load_delegate('/usr/lib/aarch64-linux-gnu/libedgetpu.so.1.0')])\n    except Exception as e:\n        print(f\"Failed to load /usr/lib/aarch64-linux-gnu/libedgetpu.so.1.0: {e}\")\n        raise\n\ninterpreter.allocate_tensors()\n\n# Get Model Details\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\n\nprint(\"Input details:\", input_details)\nprint(\"Output details:\", output_details)\n\nfloating_model = (input_details[0]['dtype'] == np.float32)\n\n# Phase 2: Input Acquisition & Preprocessing Loop\ncap = cv2.VideoCapture(input_path)\nif not cap.isOpened():\n    raise IOError(\"Cannot open video file\")\n\nframe_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\nframe_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\nfps = cap.get(cv2.CAP_PROP_FPS)\n\nout = cv2.VideoWriter(output_path, cv2.VideoWriter_fourcc(*'mp4v'), fps, (frame_width, frame_height))\n\nwhile True:\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    # Preprocess Data\n    input_data = cv2.resize(frame, (input_details[0]['shape'][1], input_details[0]['shape'][2]))\n    input_data = np.expand_dims(input_data, axis=0)\n\n    if floating_model:\n        input_data = (np.float32(input_data) - 127.5) / 127.5\n\n    # Phase 3: Inference\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n    interpreter.invoke()\n\n    # Phase 4: Output Interpretation & Handling Loop\n    output_data = interpreter.get_tensor(output_details[0]['index'])\n    num_detections = np.squeeze(interpreter.get_tensor(output_details[1]['index']))\n\n    if len(output_details) > 2:\n        detection_boxes = interpreter.get_tensor(output_details[2]['index'])[0]\n    else:\n        print(\"Error: Not enough output details for detection boxes.\")\n        break\n\n    if len(output_details) > 3:\n        detection_classes = interpreter.get_tensor(output_details[3]['index'])[0].astype(int)\n    else:\n        print(\"Error: Not enough output details for detection classes.\")\n        break\n\n    if len(output_details) > 4:\n        detection_scores = interpreter.get_tensor(output_details[4]['index'])[0]\n    else:\n        print(\"Error: Not enough output details for detection scores.\")\n        break\n\n    for i in range(int(num_detections)):\n        if detection_scores[i] > confidence_threshold:\n            box = detection_boxes[i]\n            class_id = detection_classes[i]\n            score = detection_scores[i]\n\n            # Scale the bounding box coordinates\n            ymin, xmin, ymax, xmax = box\n            (left, right, top, bottom) = (xmin * frame_width, xmax * frame_width,\n                                          ymin * frame_height, ymax * frame_height)\n\n            # Draw the bounding box and label on the frame\n            cv2.rectangle(frame, (int(left), int(top)), (int(right), int(bottom)), (0, 255, 0), 2)\n            label = f'{labels[class_id]}: {score:.2f}'\n            cv2.putText(frame, label, (int(left), int(top) - 10),\n                        cv2.FONT_HERSHEY_SIMPLEX, 0.9, (36, 255, 12), 2)\n\n    # Write the frame to the output video\n    out.write(frame)\n\n# Release resources\ncap.release()\nout.release()\ncv2.destroyAllWindows()"
      },
      "session_id": "qwen2.5-coder:32b_ee11_tpusg_batch",
      "metadata": {
        "num_run": 20
      },
      "tags": [
        "benchmark",
        "qwen2.5-coder:32b",
        "tpu_sketch_generator"
      ],
      "latency": 108.849,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-14-51-18-499282_chatcmpl-d1402877-62cc-491e-8799-7868e74aeebf",
          "traceId": "d958ce53",
          "type": "GENERATION",
          "name": "d958_tpusg_gen_attempt#1",
          "startTime": "2025-08-04T11:51:18.499000+00:00",
          "endTime": "2025-08-04T11:51:44.809000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 26310.0,
          "costDetails": {},
          "completionTokens": 893,
          "promptTokens": 1833,
          "totalTokens": 2726,
          "environment": "default",
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-14-51-52-862082_chatcmpl-c9cd2707-5eb0-4147-8a39-4818e4bcf7c4",
          "traceId": "d958ce53",
          "type": "GENERATION",
          "name": "d958_tpusg_gen_attempt#2",
          "startTime": "2025-08-04T11:51:52.862000+00:00",
          "endTime": "2025-08-04T11:52:24.567000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 31705.0,
          "costDetails": {},
          "completionTokens": 1090,
          "promptTokens": 2048,
          "totalTokens": 3138,
          "environment": "default",
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-14-52-32-662997_chatcmpl-b96a3f26-ed1c-4a6a-adf7-a9d68175c150",
          "traceId": "d958ce53",
          "type": "GENERATION",
          "name": "d958_tpusg_gen_attempt#3",
          "startTime": "2025-08-04T11:52:32.662000+00:00",
          "endTime": "2025-08-04T11:53:07.348000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 34686.0,
          "costDetails": {},
          "completionTokens": 1195,
          "promptTokens": 2048,
          "totalTokens": 3243,
          "environment": "default",
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        }
      ],
      "createdAt": "2025-08-04T11:51:19.020Z",
      "updatedAt": "2025-08-04T11:53:21.213Z",
      "environment": "default"
    },
    {
      "id": "cde56864",
      "timestamp": "2025-08-04T11:47:57.768000+00:00",
      "name": "cde5_tpu_sketch_generator",
      "input": null,
      "output": {
        "status": "failed",
        "last_code": "import numpy as np\nfrom tflite_runtime.interpreter import Interpreter, load_delegate\nimport cv2\n\n# Phase 1: Setup\nmodel_path  = \"/home/mendel/tinyml_autopilot/models/edgetpu_detect.tflite\"\nlabel_path  = \"/home/mendel/tinyml_autopilot/models/labelmap.txt\"\ninput_path  = \"/home/mendel/tinyml_autopilot/data//sheeps.mp4\"\noutput_path  = \"/home/mendel/tinyml_autopilot/results/sheeps_detections.mp4\"\nconfidence_threshold  = 0.5\n\n# Load labels\nwith open(label_path, 'r') as f:\n    labels = [line.strip() for line in f.readlines()]\n\n# Load Interpreter with EdgeTPU\ntry:\n    interpreter = Interpreter(model_path=model_path,\n                              experimental_delegates=[load_delegate('libedgetpu.so.1.0')])\nexcept Exception as e:\n    print(f\"Failed to load libedgetpu.so.1.0: {e}\")\n    try:\n        interpreter = Interpreter(model_path=model_path,\n                                  experimental_delegates=[load_delegate('/usr/lib/aarch64-linux-gnu/libedgetpu.so.1.0')])\n    except Exception as e:\n        print(f\"Failed to load /usr/lib/aarch64-linux-gnu/libedgetpu.so.1.0: {e}\")\n        raise\n\ninterpreter.allocate_tensors()\n\n# Get Model Details\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\n\nfloating_model = (input_details[0]['dtype'] == np.float32)\n\n# Phase 2: Input Acquisition & Preprocessing Loop\ncap = cv2.VideoCapture(input_path)\nif not cap.isOpened():\n    raise IOError(\"Cannot open video file\")\n\nframe_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\nframe_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\nfps = cap.get(cv2.CAP_PROP_FPS)\n\nout = cv2.VideoWriter(output_path, cv2.VideoWriter_fourcc(*'mp4v'), fps, (frame_width, frame_height))\n\nwhile True:\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    # Preprocess Data\n    input_data = cv2.resize(frame, (input_details[0]['shape'][1], input_details[0]['shape'][2]))\n    input_data = np.expand_dims(input_data, axis=0)\n\n    if floating_model:\n        input_data = (np.float32(input_data) - 127.5) / 127.5\n\n    # Phase 3: Inference\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n    interpreter.invoke()\n\n    # Phase 4: Output Interpretation & Handling Loop\n    output_data = interpreter.get_tensor(output_details[0]['index'])\n    num_detections = int(interpreter.get_tensor(output_details[1]['index']))  # Directly convert to int\n    detection_boxes = interpreter.get_tensor(output_details[2]['index'])[0]\n    detection_classes = interpreter.get_tensor(output_details[3]['index'])[0].astype(int)\n    detection_scores = interpreter.get_tensor(output_details[4]['index'])[0]\n\n    for i in range(num_detections):\n        if detection_scores[i] > confidence_threshold:\n            box = detection_boxes[i]\n            class_id = detection_classes[i]\n            score = detection_scores[i]\n\n            # Scale and clip bounding boxes\n            ymin, xmin, ymax, xmax = box\n            (left, right, top, bottom) = (xmin * frame_width, xmax * frame_width,\n                                          ymin * frame_height, ymax * frame_height)\n\n            cv2.rectangle(frame, (int(left), int(top)), (int(right), int(bottom)), (0, 255, 0), 2)\n            label = f'{labels[class_id]}: {score:.2f}'\n            cv2.putText(frame, label, (int(left), int(top) - 10),\n                        cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n\n    # Handle Output\n    out.write(frame)\n\n# Phase 5: Cleanup\ncap.release()\nout.release()\ncv2.destroyAllWindows()",
        "last_error": "Traceback (most recent call last):\n  File \"script_25c6b5a7_1754308264.py\", line 66, in <module>\n    num_detections = int(interpreter.get_tensor(output_details[1]['index']))  # Directly convert to int\nTypeError: only size-1 arrays can be converted to Python scalars"
      },
      "session_id": "qwen2.5-coder:32b_ee11_tpusg_batch",
      "metadata": {
        "num_run": 19
      },
      "tags": [
        "benchmark",
        "qwen2.5-coder:32b",
        "tpu_sketch_generator"
      ],
      "latency": 195.393,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-14-47-57-769862_chatcmpl-a00ef69f-9c2d-4f4d-8a73-d349446ba61a",
          "traceId": "cde56864",
          "type": "GENERATION",
          "name": "cde5_tpusg_gen_attempt#1",
          "startTime": "2025-08-04T11:47:57.769000+00:00",
          "endTime": "2025-08-04T11:48:23.669000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 25900.0,
          "costDetails": {},
          "completionTokens": 876,
          "promptTokens": 1833,
          "totalTokens": 2709,
          "environment": "default",
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-14-48-31-745495_chatcmpl-15a4d412-41fc-4a70-a766-db8bf2235e2c",
          "traceId": "cde56864",
          "type": "GENERATION",
          "name": "cde5_tpusg_gen_attempt#2",
          "startTime": "2025-08-04T11:48:31.745000+00:00",
          "endTime": "2025-08-04T11:49:03.160000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 31415.0,
          "costDetails": {},
          "completionTokens": 1079,
          "promptTokens": 2048,
          "totalTokens": 3127,
          "environment": "default",
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-14-49-11-167716_chatcmpl-daa88f5c-0ad6-4da7-a06f-e0bb855a493c",
          "traceId": "cde56864",
          "type": "GENERATION",
          "name": "cde5_tpusg_gen_attempt#3",
          "startTime": "2025-08-04T11:49:11.167000+00:00",
          "endTime": "2025-08-04T11:49:43.464000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 32297.0,
          "costDetails": {},
          "completionTokens": 1112,
          "promptTokens": 2048,
          "totalTokens": 3160,
          "environment": "default",
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-14-49-51-559576_chatcmpl-4a3ef3f2-b9b1-46f8-ad5f-2aa45e1288bf",
          "traceId": "cde56864",
          "type": "GENERATION",
          "name": "cde5_tpusg_gen_attempt#4",
          "startTime": "2025-08-04T11:49:51.559000+00:00",
          "endTime": "2025-08-04T11:50:23.126000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 31567.0,
          "costDetails": {},
          "completionTokens": 1070,
          "promptTokens": 2048,
          "totalTokens": 3118,
          "environment": "default",
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-14-50-31-216241_chatcmpl-cffe60e1-eaeb-477e-8c99-04eb282e70ec",
          "traceId": "cde56864",
          "type": "GENERATION",
          "name": "cde5_tpusg_gen_attempt#5",
          "startTime": "2025-08-04T11:50:31.216000+00:00",
          "endTime": "2025-08-04T11:51:04.935000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 33719.0,
          "costDetails": {},
          "completionTokens": 1161,
          "promptTokens": 2048,
          "totalTokens": 3209,
          "environment": "default",
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "318c8b5f-3c0b-464e-b826-9bfe0d24defb",
          "traceId": "cde56864",
          "type": "SPAN",
          "name": "error_cd_tpusg_failure_signal_tpu_sketch_generator",
          "startTime": "2025-08-04T11:51:13.162000+00:00",
          "level": "ERROR",
          "statusMessage": "Failed. Last error: Traceback (most recent call last):\n  File \"script_25c6b5a7_1754308264.py\", line 66, in <module>\n    num_detections = int(interpreter.get_tensor(output_details[1]['index']))  # Directly convert to int\nTypeError: only size-1 arrays can be converted to Python scalars",
          "calculatedTotalCost": 0.0,
          "costDetails": {},
          "completionTokens": 0,
          "promptTokens": 0,
          "totalTokens": 0,
          "environment": "default",
          "endTime": null,
          "model": null,
          "modelParameters": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null,
          "latency": null
        }
      ],
      "createdAt": "2025-08-04T11:47:58.290Z",
      "updatedAt": "2025-08-04T11:51:18.495Z",
      "environment": "default"
    },
    {
      "id": "8d05046f",
      "timestamp": "2025-08-04T11:44:49.230000+00:00",
      "name": "8d05_tpu_sketch_generator",
      "input": null,
      "output": {
        "status": "success",
        "sketch": "import numpy as np\nfrom PIL import Image\nimport cv2\n\n# Phase 1: Setup and Initialization\ntry:\n    from tflite_runtime.interpreter import Interpreter, load_delegate\nexcept ImportError:\n    from tensorflow.lite import Interpreter\n    from tensorflow.lite.experimental import load_delegate\n\n# Paths/Parameters\nmodel_path  = \"/home/mendel/tinyml_autopilot/models/edgetpu_detect.tflite\"\ninput_path  = \"/home/mendel/tinyml_autopilot/data//sheeps.mp4\"\nlabel_path  = \"/home/mendel/tinyml_autopilot/models/labelmap.txt\"\noutput_path  = \"/home/mendel/tinyml_autopilot/results/sheeps_detections.mp4\"\n\n# Load Labels (Conditional)\nwith open(label_path, 'r') as f:\n    labels = [line.strip() for line in f.readlines()]\n\n# Load Interpreter with EdgeTPU\ntry:\n    interpreter = Interpreter(model_path=model_path, experimental_delegates=[load_delegate('libedgetpu.so.1.0')])\nexcept Exception as e:\n    interpreter = Interpreter(model_path=model_path, experimental_delegates=[load_delegate('/usr/lib/aarch64-linux-gnu/libedgetpu.so.1.0')])\n\ninterpreter.allocate_tensors()\n\n# Get Model Details\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\n\n# Phase 2: Input Acquisition & Preprocessing Loop\ncap = cv2.VideoCapture(input_path)\nfourcc = cv2.VideoWriter_fourcc(*'mp4v')\nout = cv2.VideoWriter(output_path, fourcc, 30.0, (int(cap.get(3)), int(cap.get(4))))\n\nwhile cap.isOpened():\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    # Preprocess Data\n    input_shape = input_details[0]['shape']\n    image_resized = cv2.resize(frame, (input_shape[1], input_shape[2]))\n    input_data = np.expand_dims(image_resized, axis=0)\n\n    # Quantization Handling\n    floating_model = (input_details[0]['dtype'] == np.float32)\n    if floating_model:\n        input_data = (np.float32(input_data) - 127.5) / 127.5\n\n    # Phase 3: Inference\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n    interpreter.invoke()\n\n    # Phase 4: Output Interpretation & Handling Loop\n    boxes = interpreter.get_tensor(output_details[0]['index'])[0]\n    classes = interpreter.get_tensor(output_details[1]['index'])[0]\n    scores = interpreter.get_tensor(output_details[2]['index'])[0]\n    num_detections = int(interpreter.get_tensor(output_details[3]['index']))\n\n    # Interpret Results\n    for i in range(num_detections):\n        if scores[i] > 0.5:\n            ymin, xmin, ymax, xmax = boxes[i]\n            (left, right, top, bottom) = (xmin * cap.get(3), xmax * cap.get(3),\n                                          ymin * cap.get(4), ymax * cap.get(4))\n            cv2.rectangle(frame, (int(left), int(top)), (int(right), int(bottom)), (0, 255, 0), 2)\n            label = f'{labels[int(classes[i])]}: {scores[i]:.2f}'\n            cv2.putText(frame, label, (int(left), int(top) - 10),\n                        cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n\n    # Handle Output\n    out.write(frame)\n\n# Phase 5: Cleanup\ncap.release()\nout.release()\ncv2.destroyAllWindows()"
      },
      "session_id": "qwen2.5-coder:32b_ee11_tpusg_batch",
      "metadata": {
        "num_run": 18
      },
      "tags": [
        "benchmark",
        "qwen2.5-coder:32b",
        "tpu_sketch_generator"
      ],
      "latency": 129.984,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-14-44-49-231955_chatcmpl-11336c22-9783-4dc6-b1a8-2bb0ca3b3f5f",
          "traceId": "8d05046f",
          "type": "GENERATION",
          "name": "8d05_tpusg_gen_attempt#1",
          "startTime": "2025-08-04T11:44:49.231000+00:00",
          "endTime": "2025-08-04T11:45:15.517000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 26286.0,
          "costDetails": {},
          "completionTokens": 893,
          "promptTokens": 1833,
          "totalTokens": 2726,
          "environment": "default",
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-14-45-23-669648_chatcmpl-a4f4391c-16a5-4ae6-af84-3f0094c03422",
          "traceId": "8d05046f",
          "type": "GENERATION",
          "name": "8d05_tpusg_gen_attempt#2",
          "startTime": "2025-08-04T11:45:23.669000+00:00",
          "endTime": "2025-08-04T11:45:55.029000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 31360.0,
          "costDetails": {},
          "completionTokens": 1078,
          "promptTokens": 2048,
          "totalTokens": 3126,
          "environment": "default",
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-14-46-03-121774_chatcmpl-738c9625-9edb-4cdb-99d3-fe2b74c94c01",
          "traceId": "8d05046f",
          "type": "GENERATION",
          "name": "8d05_tpusg_gen_attempt#3",
          "startTime": "2025-08-04T11:46:03.121000+00:00",
          "endTime": "2025-08-04T11:46:33.891000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 30770.0,
          "costDetails": {},
          "completionTokens": 1055,
          "promptTokens": 2048,
          "totalTokens": 3103,
          "environment": "default",
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-14-46-33-897974_chatcmpl-b019a9e7-d3bd-416e-b49e-8bbfdcbbd463",
          "traceId": "8d05046f",
          "type": "GENERATION",
          "name": "8d05_tpusg_gen_attempt#4",
          "startTime": "2025-08-04T11:46:33.897000+00:00",
          "endTime": "2025-08-04T11:46:59.215000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 25318.0,
          "costDetails": {},
          "completionTokens": 855,
          "promptTokens": 2002,
          "totalTokens": 2857,
          "environment": "default",
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        }
      ],
      "createdAt": "2025-08-04T11:44:49.752Z",
      "updatedAt": "2025-08-04T11:47:57.115Z",
      "environment": "default"
    },
    {
      "id": "53c0da84",
      "timestamp": "2025-08-04T11:41:31.555000+00:00",
      "name": "53c0_tpu_sketch_generator",
      "input": null,
      "output": {
        "status": "failed",
        "last_code": "import numpy as np\nfrom tflite_runtime.interpreter import Interpreter, load_delegate\n\n# Phase 1: Setup\nmodel_path  = \"/home/mendel/tinyml_autopilot/models/edgetpu_detect.tflite\"\nlabel_path  = \"/home/mendel/tinyml_autopilot/models/labelmap.txt\"\ninput_path  = \"/home/mendel/tinyml_autopilot/data//sheeps.mp4\"\noutput_path  = \"/home/mendel/tinyml_autopilot/results/sheeps_detections.mp4\"\nconfidence_threshold  = 0.5\n\n# Load labels\nwith open(label_path, 'r') as f:\n    labels = [line.strip() for line in f.readlines()]\n\n# Load Interpreter with EdgeTPU\ntry:\n    interpreter = Interpreter(model_path=model_path,\n                              experimental_delegates=[load_delegate('libedgetpu.so.1.0')])\nexcept Exception as e:\n    print(f\"Failed to load libedgetpu.so.1.0: {e}\")\n    try:\n        interpreter = Interpreter(model_path=model_path,\n                                  experimental_delegates=[load_delegate('/usr/lib/aarch64-linux-gnu/libedgetpu.so.1.0')])\n    except Exception as e:\n        print(f\"Failed to load /usr/lib/aarch64-linux-gnu/libedgetpu.so.1.0: {e}\")\n        raise\n\ninterpreter.allocate_tensors()\n\n# Get Model Details\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\n\nfloating_model = (input_details[0]['dtype'] == np.float32)\n\n# Phase 2: Input Acquisition & Preprocessing Loop\nimport cv2\n\ncap = cv2.VideoCapture(input_path)\nif not cap.isOpened():\n    raise IOError(\"Cannot open video file\")\n\nframe_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\nframe_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\nfps = cap.get(cv2.CAP_PROP_FPS)\n\nout = cv2.VideoWriter(output_path, cv2.VideoWriter_fourcc(*'mp4v'), fps, (frame_width, frame_height))\n\nwhile True:\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    # Preprocess Data\n    input_data = cv2.resize(frame, (input_details[0]['shape'][1], input_details[0]['shape'][2]))\n    input_data = np.expand_dims(input_data, axis=0)\n\n    if floating_model:\n        input_data = (np.float32(input_data) - 127.5) / 127.5\n\n    # Phase 3: Inference\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n    interpreter.invoke()\n\n    # Phase 4: Output Interpretation & Handling Loop\n    output_data = interpreter.get_tensor(output_details[0]['index'])\n    num_detections = int(interpreter.get_tensor(output_details[1]['index']).item())  # Correctly extract the scalar value\n    detection_boxes = interpreter.get_tensor(output_details[2]['index'])[0]\n    detection_classes = interpreter.get_tensor(output_details[3]['index'])[0].astype(int)\n    detection_scores = interpreter.get_tensor(output_details[4]['index'])[0]\n\n    for i in range(num_detections):\n        if detection_scores[i] > confidence_threshold:\n            box = detection_boxes[i]\n            class_id = detection_classes[i]\n            score = detection_scores[i]\n\n            # Scale and clip bounding boxes\n            ymin, xmin, ymax, xmax = box\n            (left, right, top, bottom) = (xmin * frame_width, xmax * frame_width,\n                                          ymin * frame_height, ymax * frame_height)\n\n            cv2.rectangle(frame, (int(left), int(top)), (int(right), int(bottom)), (0, 255, 0), 2)\n            label = f'{labels[class_id]}: {score:.2f}'\n            cv2.putText(frame, label, (int(left), int(top) - 10),\n                        cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n\n    # Write the frame to the output video\n    out.write(frame)\n\n# Release resources\ncap.release()\nout.release()\ncv2.destroyAllWindows()",
        "last_error": "Traceback (most recent call last):\n  File \"script_8439c871_1754307875.py\", line 67, in <module>\n    num_detections = int(interpreter.get_tensor(output_details[1]['index']).item())  # Correctly extract the scalar value\nValueError: can only convert an array of size 1 to a Python scalar"
      },
      "session_id": "qwen2.5-coder:32b_ee11_tpusg_batch",
      "metadata": {
        "num_run": 17
      },
      "tags": [
        "benchmark",
        "qwen2.5-coder:32b",
        "tpu_sketch_generator"
      ],
      "latency": 191.911,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-14-41-31-556622_chatcmpl-21ae02c0-fe5e-4306-b181-98fa9da9484d",
          "traceId": "53c0da84",
          "type": "GENERATION",
          "name": "53c0_tpusg_gen_attempt#1",
          "startTime": "2025-08-04T11:41:31.556000+00:00",
          "endTime": "2025-08-04T11:41:57.347000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 25791.0,
          "costDetails": {},
          "completionTokens": 876,
          "promptTokens": 1833,
          "totalTokens": 2709,
          "environment": "default",
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-14-42-05-442358_chatcmpl-aad2bfbd-44c9-4e41-82e1-e45aa00611a7",
          "traceId": "53c0da84",
          "type": "GENERATION",
          "name": "53c0_tpusg_gen_attempt#2",
          "startTime": "2025-08-04T11:42:05.442000+00:00",
          "endTime": "2025-08-04T11:42:38.718000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 33276.0,
          "costDetails": {},
          "completionTokens": 1150,
          "promptTokens": 2048,
          "totalTokens": 3198,
          "environment": "default",
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-14-42-46-836592_chatcmpl-c784705b-a364-46eb-9dae-56758129368a",
          "traceId": "53c0da84",
          "type": "GENERATION",
          "name": "53c0_tpusg_gen_attempt#3",
          "startTime": "2025-08-04T11:42:46.836000+00:00",
          "endTime": "2025-08-04T11:43:17.526000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 30690.0,
          "costDetails": {},
          "completionTokens": 1045,
          "promptTokens": 2048,
          "totalTokens": 3093,
          "environment": "default",
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-14-43-25-656566_chatcmpl-e188d583-b233-4283-9005-87c58b13b77b",
          "traceId": "53c0da84",
          "type": "GENERATION",
          "name": "53c0_tpusg_gen_attempt#4",
          "startTime": "2025-08-04T11:43:25.656000+00:00",
          "endTime": "2025-08-04T11:43:55.990000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 30334.0,
          "costDetails": {},
          "completionTokens": 1035,
          "promptTokens": 2048,
          "totalTokens": 3083,
          "environment": "default",
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-14-44-04-132327_chatcmpl-1a3e0758-c0b3-4cf0-a229-ad29b6ed9e8a",
          "traceId": "53c0da84",
          "type": "GENERATION",
          "name": "53c0_tpusg_gen_attempt#5",
          "startTime": "2025-08-04T11:44:04.132000+00:00",
          "endTime": "2025-08-04T11:44:35.420000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 31288.0,
          "costDetails": {},
          "completionTokens": 1073,
          "promptTokens": 2048,
          "totalTokens": 3121,
          "environment": "default",
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "0c53e9ef-66b0-48a3-b0d1-d5243d7de3a9",
          "traceId": "53c0da84",
          "type": "SPAN",
          "name": "error_53_tpusg_failure_signal_tpu_sketch_generator",
          "startTime": "2025-08-04T11:44:43.467000+00:00",
          "level": "ERROR",
          "statusMessage": "Failed. Last error: Traceback (most recent call last):\n  File \"script_8439c871_1754307875.py\", line 67, in <module>\n    num_detections = int(interpreter.get_tensor(output_details[1]['index']).item())  # Correctly extract the scalar value\nValueError: can only convert an array of size 1 to a Python scalar",
          "calculatedTotalCost": 0.0,
          "costDetails": {},
          "completionTokens": 0,
          "promptTokens": 0,
          "totalTokens": 0,
          "environment": "default",
          "endTime": null,
          "model": null,
          "modelParameters": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null,
          "latency": null
        }
      ],
      "createdAt": "2025-08-04T11:41:32.089Z",
      "updatedAt": "2025-08-04T11:44:48.778Z",
      "environment": "default"
    },
    {
      "id": "fdb8ed8c",
      "timestamp": "2025-08-04T11:38:11.021000+00:00",
      "name": "fdb8_tpu_sketch_generator",
      "input": null,
      "output": {
        "status": "failed",
        "last_code": "import numpy as np\nfrom tflite_runtime.interpreter import Interpreter, load_delegate\n\n# Phase 1: Setup\nmodel_path  = \"/home/mendel/tinyml_autopilot/models/edgetpu_detect.tflite\"\nlabel_path  = \"/home/mendel/tinyml_autopilot/models/labelmap.txt\"\ninput_path  = \"/home/mendel/tinyml_autopilot/data//sheeps.mp4\"\noutput_path  = \"/home/mendel/tinyml_autopilot/results/sheeps_detections.mp4\"\nconfidence_threshold  = 0.5\n\n# Load labels\nwith open(label_path, 'r') as f:\n    labels = [line.strip() for line in f.readlines()]\n\n# Load Interpreter with EdgeTPU\ntry:\n    interpreter = Interpreter(model_path=model_path,\n                              experimental_delegates=[load_delegate('libedgetpu.so.1.0')])\nexcept Exception as e:\n    print(f\"Failed to load libedgetpu.so.1.0: {e}\")\n    try:\n        interpreter = Interpreter(model_path=model_path,\n                                  experimental_delegates=[load_delegate('/usr/lib/aarch64-linux-gnu/libedgetpu.so.1.0')])\n    except Exception as e:\n        print(f\"Failed to load /usr/lib/aarch64-linux-gnu/libedgetpu.so.1.0: {e}\")\n        raise\n\ninterpreter.allocate_tensors()\n\n# Get Model Details\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\n\nfloating_model = (input_details[0]['dtype'] == np.float32)\n\n# Phase 2: Input Acquisition & Preprocessing Loop\nimport cv2\n\ncap = cv2.VideoCapture(input_path)\nif not cap.isOpened():\n    raise IOError(\"Cannot open video file\")\n\nframe_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\nframe_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\nfps = cap.get(cv2.CAP_PROP_FPS)\n\nout = cv2.VideoWriter(output_path, cv2.VideoWriter_fourcc(*'mp4v'), fps, (frame_width, frame_height))\n\nwhile True:\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    # Preprocess Data\n    input_data = cv2.resize(frame, (input_details[0]['shape'][1], input_details[0]['shape'][2]))\n    input_data = np.expand_dims(input_data, axis=0)\n\n    if floating_model:\n        input_data = (np.float32(input_data) - 127.5) / 127.5\n\n    # Phase 3: Inference\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n    interpreter.invoke()\n\n    # Phase 4: Output Interpretation & Handling Loop\n    output_data = interpreter.get_tensor(output_details[0]['index'])\n    num_detections = int(interpreter.get_tensor(output_details[1]['index'])[0])  # Access the first element of the array\n    detection_boxes = interpreter.get_tensor(output_details[2]['index'])[0]\n    detection_classes = interpreter.get_tensor(output_details[3]['index'])[0].astype(int)\n    detection_scores = interpreter.get_tensor(output_details[4]['index'])[0]\n\n    for i in range(num_detections):\n        if detection_scores[i] > confidence_threshold:\n            box = detection_boxes[i]\n            class_id = detection_classes[i]\n            score = detection_scores[i]\n\n            # Scale and clip bounding boxes\n            ymin, xmin, ymax, xmax = box\n            (left, right, top, bottom) = (xmin * frame_width, xmax * frame_width,\n                                          ymin * frame_height, ymax * frame_height)\n\n            cv2.rectangle(frame, (int(left), int(top)), (int(right), int(bottom)), (0, 255, 0), 2)\n            label = f'{labels[class_id]}: {score:.2f}'\n            cv2.putText(frame, label, (int(left), int(top) - 10),\n                        cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n\n    # Handle Output\n    out.write(frame)\n\n# Phase 5: Cleanup\ncap.release()\nout.release()\ncv2.destroyAllWindows()",
        "last_error": "Traceback (most recent call last):\n  File \"script_0a68ccf1_1754307677.py\", line 67, in <module>\n    num_detections = int(interpreter.get_tensor(output_details[1]['index'])[0])  # Access the first element of the array\nTypeError: only size-1 arrays can be converted to Python scalars"
      },
      "session_id": "qwen2.5-coder:32b_ee11_tpusg_batch",
      "metadata": {
        "num_run": 16
      },
      "tags": [
        "benchmark",
        "qwen2.5-coder:32b",
        "tpu_sketch_generator"
      ],
      "latency": 194.849,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-14-38-11-022566_chatcmpl-929262b4-27bd-4962-9e1b-f4c896a4bf99",
          "traceId": "fdb8ed8c",
          "type": "GENERATION",
          "name": "fdb8_tpusg_gen_attempt#1",
          "startTime": "2025-08-04T11:38:11.022000+00:00",
          "endTime": "2025-08-04T11:38:36.840000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 25818.0,
          "costDetails": {},
          "completionTokens": 876,
          "promptTokens": 1833,
          "totalTokens": 2709,
          "environment": "default",
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-14-38-44-953469_chatcmpl-3a3e3984-f416-4dce-a2ec-f2ceb654bd13",
          "traceId": "fdb8ed8c",
          "type": "GENERATION",
          "name": "fdb8_tpusg_gen_attempt#2",
          "startTime": "2025-08-04T11:38:44.953000+00:00",
          "endTime": "2025-08-04T11:39:17.420000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 32467.0,
          "costDetails": {},
          "completionTokens": 1118,
          "promptTokens": 2048,
          "totalTokens": 3166,
          "environment": "default",
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-14-39-25-456599_chatcmpl-fa05a132-f083-456d-8784-3266ac5a113a",
          "traceId": "fdb8ed8c",
          "type": "GENERATION",
          "name": "fdb8_tpusg_gen_attempt#3",
          "startTime": "2025-08-04T11:39:25.456000+00:00",
          "endTime": "2025-08-04T11:39:59.104000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 33648.0,
          "costDetails": {},
          "completionTokens": 1158,
          "promptTokens": 2048,
          "totalTokens": 3206,
          "environment": "default",
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-14-40-07-184304_chatcmpl-3ac9d519-d8ed-4878-8a3b-4731d4190888",
          "traceId": "fdb8ed8c",
          "type": "GENERATION",
          "name": "fdb8_tpusg_gen_attempt#4",
          "startTime": "2025-08-04T11:40:07.184000+00:00",
          "endTime": "2025-08-04T11:40:38.961000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 31777.0,
          "costDetails": {},
          "completionTokens": 1088,
          "promptTokens": 2048,
          "totalTokens": 3136,
          "environment": "default",
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-14-40-47-034307_chatcmpl-83f76374-829f-4aa0-ba4d-5dc68a55f29a",
          "traceId": "fdb8ed8c",
          "type": "GENERATION",
          "name": "fdb8_tpusg_gen_attempt#5",
          "startTime": "2025-08-04T11:40:47.034000+00:00",
          "endTime": "2025-08-04T11:41:17.757000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 30723.0,
          "costDetails": {},
          "completionTokens": 1053,
          "promptTokens": 2048,
          "totalTokens": 3101,
          "environment": "default",
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "9dd9ea37-7ade-4c31-aa85-a2b2f7f45901",
          "traceId": "fdb8ed8c",
          "type": "SPAN",
          "name": "error_fd_tpusg_failure_signal_tpu_sketch_generator",
          "startTime": "2025-08-04T11:41:25.871000+00:00",
          "level": "ERROR",
          "statusMessage": "Failed. Last error: Traceback (most recent call last):\n  File \"script_0a68ccf1_1754307677.py\", line 67, in <module>\n    num_detections = int(interpreter.get_tensor(output_details[1]['index'])[0])  # Access the first element of the array\nTypeError: only size-1 arrays can be converted to Python scalars",
          "calculatedTotalCost": 0.0,
          "costDetails": {},
          "completionTokens": 0,
          "promptTokens": 0,
          "totalTokens": 0,
          "environment": "default",
          "endTime": null,
          "model": null,
          "modelParameters": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null,
          "latency": null
        }
      ],
      "createdAt": "2025-08-04T11:38:11.542Z",
      "updatedAt": "2025-08-04T11:41:31.309Z",
      "environment": "default"
    },
    {
      "id": "effd2b5b",
      "timestamp": "2025-08-04T11:34:06.372000+00:00",
      "name": "effd_tpu_sketch_generator",
      "input": null,
      "output": {
        "status": "success",
        "sketch": "import numpy as np\nfrom tflite_runtime.interpreter import Interpreter, load_delegate\nimport cv2\n\n# Phase 1: Setup\nmodel_path  = \"/home/mendel/tinyml_autopilot/models/edgetpu_detect.tflite\"\nlabel_path  = \"/home/mendel/tinyml_autopilot/models/labelmap.txt\"\ninput_path  = \"/home/mendel/tinyml_autopilot/data//sheeps.mp4\"\noutput_path  = \"/home/mendel/tinyml_autopilot/results/sheeps_detections.mp4\"\nconfidence_threshold  = 0.5\n\n# Load labels\nwith open(label_path, 'r') as f:\n    labels = [line.strip() for line in f.readlines()]\n\n# Load Interpreter with EdgeTPU\ntry:\n    interpreter = Interpreter(model_path=model_path,\n                              experimental_delegates=[load_delegate('libedgetpu.so.1.0')])\nexcept Exception as e:\n    print(f\"Failed to load libedgetpu.so.1.0: {e}\")\n    try:\n        interpreter = Interpreter(model_path=model_path,\n                                  experimental_delegates=[load_delegate('/usr/lib/aarch64-linux-gnu/libedgetpu.so.1.0')])\n    except Exception as e:\n        print(f\"Failed to load /usr/lib/aarch64-linux-gnu/libedgetpu.so.1.0: {e}\")\n        raise\n\ninterpreter.allocate_tensors()\n\n# Get Model Details\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\n\nfloating_model = (input_details[0]['dtype'] == np.float32)\n\n# Phase 2: Input Acquisition & Preprocessing Loop\ncap = cv2.VideoCapture(input_path)\nif not cap.isOpened():\n    raise IOError(\"Cannot open video file\")\n\nframe_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\nframe_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\nfps = cap.get(cv2.CAP_PROP_FPS)\n\nout = cv2.VideoWriter(output_path, cv2.VideoWriter_fourcc(*'mp4v'), fps, (frame_width, frame_height))\n\nwhile True:\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    # Preprocess Data\n    input_data = cv2.resize(frame, (input_details[0]['shape'][1], input_details[0]['shape'][2]))\n    input_data = np.expand_dims(input_data, axis=0)\n\n    if floating_model:\n        input_data = (np.float32(input_data) - 127.5) / 127.5\n\n    # Phase 3: Inference\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n    interpreter.invoke()\n\n    # Phase 4: Output Interpretation & Handling Loop\n    detection_boxes = interpreter.get_tensor(output_details[0]['index'])[0]\n    detection_classes = interpreter.get_tensor(output_details[1]['index'])[0].astype(int)\n    detection_scores = interpreter.get_tensor(output_details[2]['index'])[0]\n\n    num_detections = len(detection_scores)  # Assuming the number of detections is the length of scores\n\n    for i in range(num_detections):\n        if detection_scores[i] > confidence_threshold:\n            box = detection_boxes[i]\n            class_id = detection_classes[i]\n            score = detection_scores[i]\n\n            # Scale and clip bounding boxes\n            ymin, xmin, ymax, xmax = box\n            (left, right, top, bottom) = (xmin * frame_width, xmax * frame_width,\n                                          ymin * frame_height, ymax * frame_height)\n\n            cv2.rectangle(frame, (int(left), int(top)), (int(right), int(bottom)), (0, 255, 0), 2)\n            label = f'{labels[class_id]}: {score:.2f}'\n            cv2.putText(frame, label, (int(left), int(top) - 10),\n                        cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n\n    # Write the frame to the output video\n    out.write(frame)\n\n# Phase 5: Cleanup\ncap.release()\nout.release()\ncv2.destroyAllWindows()"
      },
      "session_id": "qwen2.5-coder:32b_ee11_tpusg_batch",
      "metadata": {
        "num_run": 15
      },
      "tags": [
        "benchmark",
        "qwen2.5-coder:32b",
        "tpu_sketch_generator"
      ],
      "latency": 186.31,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-14-34-06-374346_chatcmpl-3d279fd8-c7dc-444b-89af-d9ca549e402c",
          "traceId": "effd2b5b",
          "type": "GENERATION",
          "name": "effd_tpusg_gen_attempt#1",
          "startTime": "2025-08-04T11:34:06.374000+00:00",
          "endTime": "2025-08-04T11:34:32.167000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 25793.0,
          "costDetails": {},
          "completionTokens": 876,
          "promptTokens": 1833,
          "totalTokens": 2709,
          "environment": "default",
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-14-34-40-232645_chatcmpl-b189bc9f-8fcb-40f3-93b3-f4824b425610",
          "traceId": "effd2b5b",
          "type": "GENERATION",
          "name": "effd_tpusg_gen_attempt#2",
          "startTime": "2025-08-04T11:34:40.232000+00:00",
          "endTime": "2025-08-04T11:35:13.406000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 33174.0,
          "costDetails": {},
          "completionTokens": 1144,
          "promptTokens": 2048,
          "totalTokens": 3192,
          "environment": "default",
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-14-35-21-476001_chatcmpl-c4aa32f0-f9d4-4734-8cf0-76dab1c809bb",
          "traceId": "effd2b5b",
          "type": "GENERATION",
          "name": "effd_tpusg_gen_attempt#3",
          "startTime": "2025-08-04T11:35:21.476000+00:00",
          "endTime": "2025-08-04T11:35:52.320000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 30844.0,
          "costDetails": {},
          "completionTokens": 1055,
          "promptTokens": 2048,
          "totalTokens": 3103,
          "environment": "default",
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-14-36-00-412150_chatcmpl-12db7fac-5483-4beb-8758-557c1cdc642f",
          "traceId": "effd2b5b",
          "type": "GENERATION",
          "name": "effd_tpusg_gen_attempt#4",
          "startTime": "2025-08-04T11:36:00.412000+00:00",
          "endTime": "2025-08-04T11:36:31.721000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 31309.0,
          "costDetails": {},
          "completionTokens": 1056,
          "promptTokens": 2048,
          "totalTokens": 3104,
          "environment": "default",
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-14-36-39-808625_chatcmpl-a769c310-f58f-4a4b-a474-2561fd3c3f0d",
          "traceId": "effd2b5b",
          "type": "GENERATION",
          "name": "effd_tpusg_gen_attempt#5",
          "startTime": "2025-08-04T11:36:39.808000+00:00",
          "endTime": "2025-08-04T11:37:12.684000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 32876.0,
          "costDetails": {},
          "completionTokens": 1113,
          "promptTokens": 2048,
          "totalTokens": 3161,
          "environment": "default",
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        }
      ],
      "createdAt": "2025-08-04T11:34:06.894Z",
      "updatedAt": "2025-08-04T11:38:10.115Z",
      "environment": "default"
    },
    {
      "id": "a4484241",
      "timestamp": "2025-08-04T11:30:46.810000+00:00",
      "name": "a448_tpu_sketch_generator",
      "input": null,
      "output": {
        "status": "failed",
        "last_code": "import numpy as np\nfrom tflite_runtime.interpreter import Interpreter, load_delegate\nimport cv2\n\n# Phase 1: Setup\nmodel_path  = \"/home/mendel/tinyml_autopilot/models/edgetpu_detect.tflite\"\nlabel_path  = \"/home/mendel/tinyml_autopilot/models/labelmap.txt\"\ninput_path  = \"/home/mendel/tinyml_autopilot/data//sheeps.mp4\"\noutput_path  = \"/home/mendel/tinyml_autopilot/results/sheeps_detections.mp4\"\nconfidence_threshold  = 0.5\n\n# Load labels\nwith open(label_path, 'r') as f:\n    labels = [line.strip() for line in f.readlines()]\n\n# Load Interpreter with EdgeTPU\ntry:\n    interpreter = Interpreter(model_path=model_path,\n                              experimental_delegates=[load_delegate('libedgetpu.so.1.0')])\nexcept Exception as e:\n    print(f\"Failed to load libedgetpu.so.1.0: {e}\")\n    try:\n        interpreter = Interpreter(model_path=model_path,\n                                  experimental_delegates=[load_delegate('/usr/lib/aarch64-linux-gnu/libedgetpu.so.1.0')])\n    except Exception as e:\n        print(f\"Failed to load /usr/lib/aarch64-linux-gnu/libedgetpu.so.1.0: {e}\")\n        raise\n\ninterpreter.allocate_tensors()\n\n# Get Model Details\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\n\nfloating_model = (input_details[0]['dtype'] == np.float32)\n\n# Phase 2: Input Acquisition & Preprocessing Loop\ncap = cv2.VideoCapture(input_path)\nif not cap.isOpened():\n    raise IOError(\"Cannot open video file\")\n\nframe_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\nframe_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\nfps = cap.get(cv2.CAP_PROP_FPS)\n\nout = cv2.VideoWriter(output_path, cv2.VideoWriter_fourcc(*'mp4v'), fps, (frame_width, frame_height))\n\nwhile True:\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    # Preprocess Data\n    input_data = cv2.resize(frame, (input_details[0]['shape'][1], input_details[0]['shape'][2]))\n    input_data = np.expand_dims(input_data, axis=0)\n\n    if floating_model:\n        input_data = (np.float32(input_data) - 127.5) / 127.5\n\n    # Phase 3: Inference\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n    interpreter.invoke()\n\n    # Phase 4: Output Interpretation & Handling Loop\n    output_data = interpreter.get_tensor(output_details[0]['index'])\n    \n    # Correctly access the number of detections\n    num_detections = int(interpreter.get_tensor(output_details[1]['index'])[0])\n    detection_boxes = interpreter.get_tensor(output_details[2]['index'])[0]\n    detection_classes = interpreter.get_tensor(output_details[3]['index'])[0].astype(int)\n    detection_scores = interpreter.get_tensor(output_details[4]['index'])[0]\n\n    for i in range(num_detections):\n        if detection_scores[i] > confidence_threshold:\n            box = detection_boxes[i]\n            class_id = detection_classes[i]\n            score = detection_scores[i]\n\n            # Scale and clip bounding boxes\n            ymin, xmin, ymax, xmax = box\n            (left, right, top, bottom) = (xmin * frame_width, xmax * frame_width,\n                                          ymin * frame_height, ymax * frame_height)\n\n            cv2.rectangle(frame, (int(left), int(top)), (int(right), int(bottom)), (0, 255, 0), 2)\n            label = f'{labels[class_id]}: {score:.2f}'\n            cv2.putText(frame, label, (int(left), int(top) - 10),\n                        cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n\n    # Handle Output\n    out.write(frame)\n\n# Phase 5: Cleanup\ncap.release()\nout.release()\ncv2.destroyAllWindows()",
        "last_error": "Traceback (most recent call last):\n  File \"script_d06a11ef_1754307232.py\", line 68, in <module>\n    num_detections = int(interpreter.get_tensor(output_details[1]['index'])[0])\nTypeError: only size-1 arrays can be converted to Python scalars"
      },
      "session_id": "qwen2.5-coder:32b_ee11_tpusg_batch",
      "metadata": {
        "num_run": 14
      },
      "tags": [
        "benchmark",
        "qwen2.5-coder:32b",
        "tpu_sketch_generator"
      ],
      "latency": 193.553,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-14-30-46-812309_chatcmpl-9313b26e-7c75-412f-a5c8-5a946418d059",
          "traceId": "a4484241",
          "type": "GENERATION",
          "name": "a448_tpusg_gen_attempt#1",
          "startTime": "2025-08-04T11:30:46.812000+00:00",
          "endTime": "2025-08-04T11:31:12.620000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 25808.0,
          "costDetails": {},
          "completionTokens": 876,
          "promptTokens": 1833,
          "totalTokens": 2709,
          "environment": "default",
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-14-31-20-715142_chatcmpl-2582bd3d-cd55-42ad-a461-4adfd45d38ad",
          "traceId": "a4484241",
          "type": "GENERATION",
          "name": "a448_tpusg_gen_attempt#2",
          "startTime": "2025-08-04T11:31:20.715000+00:00",
          "endTime": "2025-08-04T11:31:53.762000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 33047.0,
          "costDetails": {},
          "completionTokens": 1141,
          "promptTokens": 2048,
          "totalTokens": 3189,
          "environment": "default",
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-14-32-01-837073_chatcmpl-0cc5e221-e898-49d5-9e7c-44ce6869b0d8",
          "traceId": "a4484241",
          "type": "GENERATION",
          "name": "a448_tpusg_gen_attempt#3",
          "startTime": "2025-08-04T11:32:01.837000+00:00",
          "endTime": "2025-08-04T11:32:33.372000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 31535.0,
          "costDetails": {},
          "completionTokens": 1084,
          "promptTokens": 2048,
          "totalTokens": 3132,
          "environment": "default",
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-14-32-41-437888_chatcmpl-22a93b4f-88fa-443b-a1ae-126a75db03da",
          "traceId": "a4484241",
          "type": "GENERATION",
          "name": "a448_tpusg_gen_attempt#4",
          "startTime": "2025-08-04T11:32:41.437000+00:00",
          "endTime": "2025-08-04T11:33:12.820000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 31383.0,
          "costDetails": {},
          "completionTokens": 1078,
          "promptTokens": 2048,
          "totalTokens": 3126,
          "environment": "default",
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-14-33-20-951670_chatcmpl-f409cfef-ec42-43a0-b89f-070ddd00b5b1",
          "traceId": "a4484241",
          "type": "GENERATION",
          "name": "a448_tpusg_gen_attempt#5",
          "startTime": "2025-08-04T11:33:20.951000+00:00",
          "endTime": "2025-08-04T11:33:52.325000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 31374.0,
          "costDetails": {},
          "completionTokens": 1078,
          "promptTokens": 2048,
          "totalTokens": 3126,
          "environment": "default",
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "d8eccb6a-4eda-49cf-a91a-a5e9dbe319eb",
          "traceId": "a4484241",
          "type": "SPAN",
          "name": "error_a4_tpusg_failure_signal_tpu_sketch_generator",
          "startTime": "2025-08-04T11:34:00.365000+00:00",
          "level": "ERROR",
          "statusMessage": "Failed. Last error: Traceback (most recent call last):\n  File \"script_d06a11ef_1754307232.py\", line 68, in <module>\n    num_detections = int(interpreter.get_tensor(output_details[1]['index'])[0])\nTypeError: only size-1 arrays can be converted to Python scalars",
          "calculatedTotalCost": 0.0,
          "costDetails": {},
          "completionTokens": 0,
          "promptTokens": 0,
          "totalTokens": 0,
          "environment": "default",
          "endTime": null,
          "model": null,
          "modelParameters": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null,
          "latency": null
        }
      ],
      "createdAt": "2025-08-04T11:30:47.333Z",
      "updatedAt": "2025-08-04T11:34:05.586Z",
      "environment": "default"
    },
    {
      "id": "3e82cbae",
      "timestamp": "2025-08-04T11:27:29.252000+00:00",
      "name": "3e82_tpu_sketch_generator",
      "input": null,
      "output": {
        "status": "failed",
        "last_code": "import numpy as np\nfrom tflite_runtime.interpreter import Interpreter, load_delegate\nimport cv2\n\n# Phase 1: Setup\nmodel_path  = \"/home/mendel/tinyml_autopilot/models/edgetpu_detect.tflite\"\nlabel_path  = \"/home/mendel/tinyml_autopilot/models/labelmap.txt\"\ninput_path  = \"/home/mendel/tinyml_autopilot/data//sheeps.mp4\"\noutput_path  = \"/home/mendel/tinyml_autopilot/results/sheeps_detections.mp4\"\nconfidence_threshold  = 0.5\n\n# Load labels\nwith open(label_path, 'r') as f:\n    labels = [line.strip() for line in f.readlines()]\n\n# Load Interpreter with EdgeTPU\ntry:\n    interpreter = Interpreter(model_path=model_path,\n                              experimental_delegates=[load_delegate('libedgetpu.so.1.0')])\nexcept Exception as e:\n    print(f\"Failed to load libedgetpu.so.1.0: {e}\")\n    try:\n        interpreter = Interpreter(model_path=model_path,\n                                  experimental_delegates=[load_delegate('/usr/lib/aarch64-linux-gnu/libedgetpu.so.1.0')])\n    except Exception as e:\n        print(f\"Failed to load /usr/lib/aarch64-linux-gnu/libedgetpu.so.1.0: {e}\")\n        raise\n\ninterpreter.allocate_tensors()\n\n# Get Model Details\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\n\nfloating_model = (input_details[0]['dtype'] == np.float32)\n\n# Phase 2: Input Acquisition & Preprocessing Loop\ncap = cv2.VideoCapture(input_path)\nif not cap.isOpened():\n    raise IOError(\"Cannot open video file\")\n\nframe_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\nframe_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\nfps = cap.get(cv2.CAP_PROP_FPS)\n\nout = cv2.VideoWriter(output_path, cv2.VideoWriter_fourcc(*'mp4v'), fps, (frame_width, frame_height))\n\nwhile True:\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    # Preprocess Data\n    input_data = cv2.resize(frame, (input_details[0]['shape'][1], input_details[0]['shape'][2]))\n    input_data = np.expand_dims(input_data, axis=0)\n\n    if floating_model:\n        input_data = (np.float32(input_data) - 127.5) / 127.5\n\n    # Phase 3: Inference\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n    interpreter.invoke()\n\n    # Phase 4: Output Interpretation & Handling Loop\n    output_data = interpreter.get_tensor(output_details[0]['index'])\n    num_detections = int(interpreter.get_tensor(output_details[1]['index']))  # Correctly extract the scalar value\n    detection_boxes = interpreter.get_tensor(output_details[2]['index'])[0]\n    detection_classes = interpreter.get_tensor(output_details[3]['index'])[0].astype(int)\n    detection_scores = interpreter.get_tensor(output_details[4]['index'])[0]\n\n    for i in range(num_detections):\n        if detection_scores[i] > confidence_threshold:\n            box = detection_boxes[i]\n            class_id = detection_classes[i]\n            score = detection_scores[i]\n\n            # Scale and clip bounding boxes\n            ymin, xmin, ymax, xmax = box\n            (left, right, top, bottom) = (xmin * frame_width, xmax * frame_width,\n                                          ymin * frame_height, ymax * frame_height)\n\n            cv2.rectangle(frame, (int(left), int(top)), (int(right), int(bottom)), (0, 255, 0), 2)\n            label = f'{labels[class_id]}: {score:.2f}'\n            cv2.putText(frame, label, (int(left), int(top) - 10),\n                        cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n\n    # Handle Output\n    out.write(frame)\n\n# Phase 5: Cleanup\ncap.release()\nout.release()\ncv2.destroyAllWindows()",
        "last_error": "Traceback (most recent call last):\n  File \"script_8672116f_1754307032.py\", line 66, in <module>\n    num_detections = int(interpreter.get_tensor(output_details[1]['index']))  # Correctly extract the scalar value\nTypeError: only size-1 arrays can be converted to Python scalars"
      },
      "session_id": "qwen2.5-coder:32b_ee11_tpusg_batch",
      "metadata": {
        "num_run": 13
      },
      "tags": [
        "benchmark",
        "qwen2.5-coder:32b",
        "tpu_sketch_generator"
      ],
      "latency": 191.471,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-14-27-29-254252_chatcmpl-3cd629ce-3825-4b00-bb2c-9fa122f49b83",
          "traceId": "3e82cbae",
          "type": "GENERATION",
          "name": "3e82_tpusg_gen_attempt#1",
          "startTime": "2025-08-04T11:27:29.254000+00:00",
          "endTime": "2025-08-04T11:27:55.164000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 25910.0,
          "costDetails": {},
          "completionTokens": 876,
          "promptTokens": 1833,
          "totalTokens": 2709,
          "environment": "default",
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-14-28-03-285179_chatcmpl-775407dc-3407-42ec-9268-79ce935f7957",
          "traceId": "3e82cbae",
          "type": "GENERATION",
          "name": "3e82_tpusg_gen_attempt#2",
          "startTime": "2025-08-04T11:28:03.285000+00:00",
          "endTime": "2025-08-04T11:28:35.489000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 32204.0,
          "costDetails": {},
          "completionTokens": 1102,
          "promptTokens": 2048,
          "totalTokens": 3150,
          "environment": "default",
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-14-28-43-599038_chatcmpl-1bfec034-1336-4934-a2fe-e1af2523ed2e",
          "traceId": "3e82cbae",
          "type": "GENERATION",
          "name": "3e82_tpusg_gen_attempt#3",
          "startTime": "2025-08-04T11:28:43.599000+00:00",
          "endTime": "2025-08-04T11:29:14.659000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 31060.0,
          "costDetails": {},
          "completionTokens": 1065,
          "promptTokens": 2048,
          "totalTokens": 3113,
          "environment": "default",
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-14-29-22-748463_chatcmpl-4fc09c67-cf9f-42b5-8252-0cd1254e1a0b",
          "traceId": "3e82cbae",
          "type": "GENERATION",
          "name": "3e82_tpusg_gen_attempt#4",
          "startTime": "2025-08-04T11:29:22.748000+00:00",
          "endTime": "2025-08-04T11:29:54.308000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 31560.0,
          "costDetails": {},
          "completionTokens": 1085,
          "promptTokens": 2048,
          "totalTokens": 3133,
          "environment": "default",
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-14-30-02-547506_chatcmpl-e4df1b7d-fb26-4153-af4c-e7642fc2b2ae",
          "traceId": "3e82cbae",
          "type": "GENERATION",
          "name": "3e82_tpusg_gen_attempt#5",
          "startTime": "2025-08-04T11:30:02.547000+00:00",
          "endTime": "2025-08-04T11:30:32.638000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 30091.0,
          "costDetails": {},
          "completionTokens": 1029,
          "promptTokens": 2048,
          "totalTokens": 3077,
          "environment": "default",
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "3aacd51d-fd4c-481e-84fe-c956c089028f",
          "traceId": "3e82cbae",
          "type": "SPAN",
          "name": "error_3e_tpusg_failure_signal_tpu_sketch_generator",
          "startTime": "2025-08-04T11:30:40.725000+00:00",
          "level": "ERROR",
          "statusMessage": "Failed. Last error: Traceback (most recent call last):\n  File \"script_8672116f_1754307032.py\", line 66, in <module>\n    num_detections = int(interpreter.get_tensor(output_details[1]['index']))  # Correctly extract the scalar value\nTypeError: only size-1 arrays can be converted to Python scalars",
          "calculatedTotalCost": 0.0,
          "costDetails": {},
          "completionTokens": 0,
          "promptTokens": 0,
          "totalTokens": 0,
          "environment": "default",
          "endTime": null,
          "model": null,
          "modelParameters": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null,
          "latency": null
        }
      ],
      "createdAt": "2025-08-04T11:27:29.774Z",
      "updatedAt": "2025-08-04T11:30:46.006Z",
      "environment": "default"
    },
    {
      "id": "dc27d14b",
      "timestamp": "2025-08-04T11:24:01.635000+00:00",
      "name": "dc27_tpu_sketch_generator",
      "input": null,
      "output": {
        "status": "success",
        "sketch": "import numpy as np\nfrom tflite_runtime.interpreter import Interpreter, load_delegate\nimport cv2\n\n# Phase 1: Setup\nmodel_path  = \"/home/mendel/tinyml_autopilot/models/edgetpu_detect.tflite\"\nlabel_path  = \"/home/mendel/tinyml_autopilot/models/labelmap.txt\"\ninput_path  = \"/home/mendel/tinyml_autopilot/data//sheeps.mp4\"\noutput_path  = \"/home/mendel/tinyml_autopilot/results/sheeps_detections.mp4\"\nconfidence_threshold  = 0.5\n\n# Load labels\nwith open(label_path, 'r') as f:\n    labels = [line.strip() for line in f.readlines()]\n\n# Load Interpreter with EdgeTPU\ntry:\n    interpreter = Interpreter(model_path=model_path,\n                              experimental_delegates=[load_delegate('libedgetpu.so.1.0')])\nexcept Exception as e:\n    print(f\"Failed to load libedgetpu.so.1.0: {e}\")\n    try:\n        interpreter = Interpreter(model_path=model_path,\n                                  experimental_delegates=[load_delegate('/usr/lib/aarch64-linux-gnu/libedgetpu.so.1.0')])\n    except Exception as e:\n        print(f\"Failed to load /usr/lib/aarch64-linux-gnu/libedgetpu.so.1.0: {e}\")\n        raise\n\ninterpreter.allocate_tensors()\n\n# Get Model Details\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\n\nfloating_model = (input_details[0]['dtype'] == np.float32)\n\n# Phase 2: Input Acquisition & Preprocessing Loop\ncap = cv2.VideoCapture(input_path)\nif not cap.isOpened():\n    raise IOError(\"Cannot open video file\")\n\nframe_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\nframe_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\nfps = cap.get(cv2.CAP_PROP_FPS)\n\nout = cv2.VideoWriter(output_path, cv2.VideoWriter_fourcc(*'mp4v'), fps, (frame_width, frame_height))\n\nwhile True:\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    # Preprocess Data\n    input_data = cv2.resize(frame, (input_details[0]['shape'][1], input_details[0]['shape'][2]))\n    input_data = np.expand_dims(input_data, axis=0)\n\n    if floating_model:\n        input_data = (np.float32(input_data) - 127.5) / 127.5\n\n    # Phase 3: Inference\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n    interpreter.invoke()\n\n    # Phase 4: Output Interpretation & Handling Loop\n    detection_boxes = interpreter.get_tensor(output_details[0]['index'])[0]\n    detection_classes = interpreter.get_tensor(output_details[1]['index'])[0].astype(int)\n    detection_scores = interpreter.get_tensor(output_details[2]['index'])[0]\n    num_detections = int(interpreter.get_tensor(output_details[3]['index']))  # Access the scalar value directly\n\n    for i in range(num_detections):\n        if detection_scores[i] > confidence_threshold:\n            box = detection_boxes[i]\n            class_id = detection_classes[i]\n            score = detection_scores[i]\n\n            # Scale and clip bounding boxes\n            ymin, xmin, ymax, xmax = box\n            (left, right, top, bottom) = (xmin * frame_width, xmax * frame_width,\n                                          ymin * frame_height, ymax * frame_height)\n\n            cv2.rectangle(frame, (int(left), int(top)), (int(right), int(bottom)), (0, 255, 0), 2)\n            label = f'{labels[class_id]}: {score:.2f}'\n            cv2.putText(frame, label, (int(left), int(top) - 10),\n                        cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n\n    # Write the frame with detections to the output video\n    out.write(frame)\n\n# Release resources\ncap.release()\nout.release()\ncv2.destroyAllWindows()"
      },
      "session_id": "qwen2.5-coder:32b_ee11_tpusg_batch",
      "metadata": {
        "num_run": 12
      },
      "tags": [
        "benchmark",
        "qwen2.5-coder:32b",
        "tpu_sketch_generator"
      ],
      "latency": 149.018,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-14-24-01-637460_chatcmpl-32e24217-3c4f-4c88-9d8a-f9e156cdf774",
          "traceId": "dc27d14b",
          "type": "GENERATION",
          "name": "dc27_tpusg_gen_attempt#1",
          "startTime": "2025-08-04T11:24:01.637000+00:00",
          "endTime": "2025-08-04T11:24:27.571000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 25934.0,
          "costDetails": {},
          "completionTokens": 876,
          "promptTokens": 1833,
          "totalTokens": 2709,
          "environment": "default",
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-14-24-35-923691_chatcmpl-097c8845-b266-4880-a74d-baa7ba16af6c",
          "traceId": "dc27d14b",
          "type": "GENERATION",
          "name": "dc27_tpusg_gen_attempt#2",
          "startTime": "2025-08-04T11:24:35.923000+00:00",
          "endTime": "2025-08-04T11:25:08.369000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 32446.0,
          "costDetails": {},
          "completionTokens": 1118,
          "promptTokens": 2048,
          "totalTokens": 3166,
          "environment": "default",
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-14-25-16-831041_chatcmpl-8d1818bd-d5cc-4eaf-b6b9-36d93afcc87a",
          "traceId": "dc27d14b",
          "type": "GENERATION",
          "name": "dc27_tpusg_gen_attempt#3",
          "startTime": "2025-08-04T11:25:16.831000+00:00",
          "endTime": "2025-08-04T11:25:50.136000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 33305.0,
          "costDetails": {},
          "completionTokens": 1151,
          "promptTokens": 2048,
          "totalTokens": 3199,
          "environment": "default",
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-14-25-58-133243_chatcmpl-321f6e0f-9485-4e45-b325-79718f5c1db5",
          "traceId": "dc27d14b",
          "type": "GENERATION",
          "name": "dc27_tpusg_gen_attempt#4",
          "startTime": "2025-08-04T11:25:58.133000+00:00",
          "endTime": "2025-08-04T11:26:30.655000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 32522.0,
          "costDetails": {},
          "completionTokens": 1121,
          "promptTokens": 2048,
          "totalTokens": 3169,
          "environment": "default",
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        }
      ],
      "createdAt": "2025-08-04T11:24:02.157Z",
      "updatedAt": "2025-08-04T11:27:28.844Z",
      "environment": "default"
    },
    {
      "id": "52202468",
      "timestamp": "2025-08-04T11:20:40.044000+00:00",
      "name": "5220_tpu_sketch_generator",
      "input": null,
      "output": {
        "status": "failed",
        "last_code": "import numpy as np\nfrom tflite_runtime.interpreter import Interpreter, load_delegate\nimport cv2\n\n# Phase 1: Setup\nmodel_path  = \"/home/mendel/tinyml_autopilot/models/edgetpu_detect.tflite\"\nlabel_path  = \"/home/mendel/tinyml_autopilot/models/labelmap.txt\"\ninput_path  = \"/home/mendel/tinyml_autopilot/data//sheeps.mp4\"\noutput_path  = \"/home/mendel/tinyml_autopilot/results/sheeps_detections.mp4\"\nconfidence_threshold  = 0.5\n\n# Load labels\nwith open(label_path, 'r') as f:\n    labels = [line.strip() for line in f.readlines()]\n\n# Load Interpreter with EdgeTPU\ntry:\n    interpreter = Interpreter(model_path=model_path,\n                              experimental_delegates=[load_delegate('libedgetpu.so.1.0')])\nexcept Exception as e:\n    print(f\"Failed to load libedgetpu.so.1.0: {e}\")\n    try:\n        interpreter = Interpreter(model_path=model_path,\n                                  experimental_delegates=[load_delegate('/usr/lib/aarch64-linux-gnu/libedgetpu.so.1.0')])\n    except Exception as e:\n        print(f\"Failed to load /usr/lib/aarch64-linux-gnu/libedgetpu.so.1.0: {e}\")\n        raise\n\ninterpreter.allocate_tensors()\n\n# Get Model Details\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\n\nfloating_model = (input_details[0]['dtype'] == np.float32)\n\n# Phase 2: Input Acquisition & Preprocessing Loop\ncap = cv2.VideoCapture(input_path)\nif not cap.isOpened():\n    raise IOError(\"Cannot open video file\")\n\nframe_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\nframe_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\nfps = cap.get(cv2.CAP_PROP_FPS)\n\nout = cv2.VideoWriter(output_path, cv2.VideoWriter_fourcc(*'mp4v'), fps, (frame_width, frame_height))\n\nwhile True:\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    # Preprocess Data\n    input_data = cv2.resize(frame, (input_details[0]['shape'][1], input_details[0]['shape'][2]))\n    input_data = np.expand_dims(input_data, axis=0)\n\n    if floating_model:\n        input_data = (np.float32(input_data) - 127.5) / 127.5\n\n    # Phase 3: Inference\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n    interpreter.invoke()\n\n    # Phase 4: Output Interpretation & Handling Loop\n    output_data = interpreter.get_tensor(output_details[0]['index'])\n    num_detections = int(interpreter.get_tensor(output_details[1]['index'])[0])  # Access the first element of the array\n\n    detection_boxes = interpreter.get_tensor(output_details[2]['index'])[0]\n    detection_classes = interpreter.get_tensor(output_details[3]['index'])[0].astype(int)\n    detection_scores = interpreter.get_tensor(output_details[4]['index'])[0]\n\n    for i in range(num_detections):\n        if detection_scores[i] > confidence_threshold:\n            box = detection_boxes[i]\n            class_id = detection_classes[i]\n            score = detection_scores[i]\n\n            # Scale and clip bounding boxes\n            ymin, xmin, ymax, xmax = box\n            (left, right, top, bottom) = (xmin * frame_width, xmax * frame_width,\n                                          ymin * frame_height, ymax * frame_height)\n\n            cv2.rectangle(frame, (int(left), int(top)), (int(right), int(bottom)), (0, 255, 0), 2)\n            label = f'{labels[class_id]}: {score:.2f}'\n            cv2.putText(frame, label, (int(left), int(top) - 10),\n                        cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n\n    # Handle Output\n    out.write(frame)\n\n# Phase 5: Cleanup\ncap.release()\nout.release()\ncv2.destroyAllWindows()",
        "last_error": "Traceback (most recent call last):\n  File \"script_fb2bbc8c_1754306627.py\", line 66, in <module>\n    num_detections = int(interpreter.get_tensor(output_details[1]['index'])[0])  # Access the first element of the array\nTypeError: only size-1 arrays can be converted to Python scalars"
      },
      "session_id": "qwen2.5-coder:32b_ee11_tpusg_batch",
      "metadata": {
        "num_run": 11
      },
      "tags": [
        "benchmark",
        "qwen2.5-coder:32b",
        "tpu_sketch_generator"
      ],
      "latency": 195.48,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-14-20-40-046527_chatcmpl-125fb138-31a3-41cf-9f6d-515121149cde",
          "traceId": "52202468",
          "type": "GENERATION",
          "name": "5220_tpusg_gen_attempt#1",
          "startTime": "2025-08-04T11:20:40.046000+00:00",
          "endTime": "2025-08-04T11:21:05.843000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 25797.0,
          "costDetails": {},
          "completionTokens": 876,
          "promptTokens": 1833,
          "totalTokens": 2709,
          "environment": "default",
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-14-21-14-245994_chatcmpl-a475e34d-3f29-4edd-bc1b-09fb817bca0b",
          "traceId": "52202468",
          "type": "GENERATION",
          "name": "5220_tpusg_gen_attempt#2",
          "startTime": "2025-08-04T11:21:14.245000+00:00",
          "endTime": "2025-08-04T11:21:46.697000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 32452.0,
          "costDetails": {},
          "completionTokens": 1118,
          "promptTokens": 2048,
          "totalTokens": 3166,
          "environment": "default",
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-14-21-54-794180_chatcmpl-9f041fed-7bad-4133-bf20-c93439555f09",
          "traceId": "52202468",
          "type": "GENERATION",
          "name": "5220_tpusg_gen_attempt#3",
          "startTime": "2025-08-04T11:21:54.794000+00:00",
          "endTime": "2025-08-04T11:22:26.850000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 32056.0,
          "costDetails": {},
          "completionTokens": 1104,
          "promptTokens": 2048,
          "totalTokens": 3152,
          "environment": "default",
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-14-22-35-152920_chatcmpl-b4fe7735-21a8-4aee-867a-6ef086d9de80",
          "traceId": "52202468",
          "type": "GENERATION",
          "name": "5220_tpusg_gen_attempt#4",
          "startTime": "2025-08-04T11:22:35.152000+00:00",
          "endTime": "2025-08-04T11:23:07.105000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 31953.0,
          "costDetails": {},
          "completionTokens": 1097,
          "promptTokens": 2048,
          "totalTokens": 3145,
          "environment": "default",
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-14-23-15-323347_chatcmpl-1e58eeaa-99fc-4e7c-ad76-3b9a396932b1",
          "traceId": "52202468",
          "type": "GENERATION",
          "name": "5220_tpusg_gen_attempt#5",
          "startTime": "2025-08-04T11:23:15.323000+00:00",
          "endTime": "2025-08-04T11:23:47.279000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 31956.0,
          "costDetails": {},
          "completionTokens": 1098,
          "promptTokens": 2048,
          "totalTokens": 3146,
          "environment": "default",
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "a2e613ca-ac80-42b8-8cf4-e9ec22877362",
          "traceId": "52202468",
          "type": "SPAN",
          "name": "error_52_tpusg_failure_signal_tpu_sketch_generator",
          "startTime": "2025-08-04T11:23:55.526000+00:00",
          "level": "ERROR",
          "statusMessage": "Failed. Last error: Traceback (most recent call last):\n  File \"script_fb2bbc8c_1754306627.py\", line 66, in <module>\n    num_detections = int(interpreter.get_tensor(output_details[1]['index'])[0])  # Access the first element of the array\nTypeError: only size-1 arrays can be converted to Python scalars",
          "calculatedTotalCost": 0.0,
          "costDetails": {},
          "completionTokens": 0,
          "promptTokens": 0,
          "totalTokens": 0,
          "environment": "default",
          "endTime": null,
          "model": null,
          "modelParameters": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null,
          "latency": null
        }
      ],
      "createdAt": "2025-08-04T11:20:40.566Z",
      "updatedAt": "2025-08-04T11:24:00.866Z",
      "environment": "default"
    },
    {
      "id": "edb48c7e",
      "timestamp": "2025-08-04T11:17:18.121000+00:00",
      "name": "edb4_tpu_sketch_generator",
      "input": null,
      "output": {
        "status": "failed",
        "last_code": "import numpy as np\nfrom tflite_runtime.interpreter import Interpreter, load_delegate\n\n# Phase 1: Setup\nmodel_path  = \"/home/mendel/tinyml_autopilot/models/edgetpu_detect.tflite\"\nlabel_path  = \"/home/mendel/tinyml_autopilot/models/labelmap.txt\"\ninput_path  = \"/home/mendel/tinyml_autopilot/data//sheeps.mp4\"\noutput_path  = \"/home/mendel/tinyml_autopilot/results/sheeps_detections.mp4\"\nconfidence_threshold  = 0.5\n\n# Load labels\nwith open(label_path, 'r') as f:\n    labels = [line.strip() for line in f.readlines()]\n\n# Load Interpreter with EdgeTPU\ntry:\n    interpreter = Interpreter(model_path=model_path,\n                              experimental_delegates=[load_delegate('libedgetpu.so.1.0')])\nexcept Exception as e:\n    print(f\"Failed to load libedgetpu.so.1.0: {e}\")\n    try:\n        interpreter = Interpreter(model_path=model_path,\n                                  experimental_delegates=[load_delegate('/usr/lib/aarch64-linux-gnu/libedgetpu.so.1.0')])\n    except Exception as e:\n        print(f\"Failed to load /usr/lib/aarch64-linux-gnu/libedgetpu.so.1.0: {e}\")\n        raise\n\ninterpreter.allocate_tensors()\n\n# Get Model Details\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\n\nfloating_model = (input_details[0]['dtype'] == np.float32)\n\n# Phase 2: Input Acquisition & Preprocessing Loop\nimport cv2\n\ncap = cv2.VideoCapture(input_path)\nif not cap.isOpened():\n    raise IOError(\"Cannot open video file\")\n\nframe_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\nframe_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\nfps = cap.get(cv2.CAP_PROP_FPS)\n\nout = cv2.VideoWriter(output_path, cv2.VideoWriter_fourcc(*'mp4v'), fps, (frame_width, frame_height))\n\nwhile True:\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    # Preprocess Data\n    input_data = cv2.resize(frame, (input_details[0]['shape'][1], input_details[0]['shape'][2]))\n    input_data = np.expand_dims(input_data, axis=0)\n\n    if floating_model:\n        input_data = (np.float32(input_data) - 127.5) / 127.5\n\n    # Phase 3: Inference\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n    interpreter.invoke()\n\n    # Phase 4: Output Interpretation & Handling Loop\n    output_data = interpreter.get_tensor(output_details[0]['index'])\n    num_detections = int(interpreter.get_tensor(output_details[1]['index'])[0])  # Access the first element of the array\n\n    detection_boxes = interpreter.get_tensor(output_details[2]['index'])[0]\n    detection_classes = interpreter.get_tensor(output_details[3]['index'])[0].astype(int)\n    detection_scores = interpreter.get_tensor(output_details[4]['index'])[0]\n\n    for i in range(num_detections):\n        if detection_scores[i] > confidence_threshold:\n            box = detection_boxes[i]\n            class_id = detection_classes[i]\n            score = detection_scores[i]\n\n            # Scale and clip bounding boxes\n            ymin, xmin, ymax, xmax = box\n            (left, right, top, bottom) = (xmin * frame_width, xmax * frame_width,\n                                          ymin * frame_height, ymax * frame_height)\n\n            cv2.rectangle(frame, (int(left), int(top)), (int(right), int(bottom)), (0, 255, 0), 2)\n            label = f'{labels[class_id]}: {score:.2f}'\n            cv2.putText(frame, label, (int(left), int(top) - 10),\n                        cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n\n    # Handle Output\n    out.write(frame)\n\n# Phase 5: Cleanup\ncap.release()\nout.release()\ncv2.destroyAllWindows()",
        "last_error": "Traceback (most recent call last):\n  File \"script_1942fbe4_1754306425.py\", line 67, in <module>\n    num_detections = int(interpreter.get_tensor(output_details[1]['index'])[0])  # Access the first element of the array\nTypeError: only size-1 arrays can be converted to Python scalars"
      },
      "session_id": "qwen2.5-coder:32b_ee11_tpusg_batch",
      "metadata": {
        "num_run": 10
      },
      "tags": [
        "benchmark",
        "qwen2.5-coder:32b",
        "tpu_sketch_generator"
      ],
      "latency": 195.323,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-14-17-18-123137_chatcmpl-07474404-c7e0-46ca-afab-2c3f62af9563",
          "traceId": "edb48c7e",
          "type": "GENERATION",
          "name": "edb4_tpusg_gen_attempt#1",
          "startTime": "2025-08-04T11:17:18.123000+00:00",
          "endTime": "2025-08-04T11:17:43.967000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 25844.0,
          "costDetails": {},
          "completionTokens": 876,
          "promptTokens": 1833,
          "totalTokens": 2709,
          "environment": "default",
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-14-17-52-196706_chatcmpl-9d23856f-7af8-4470-b721-7b1e0bf4ad4d",
          "traceId": "edb48c7e",
          "type": "GENERATION",
          "name": "edb4_tpusg_gen_attempt#2",
          "startTime": "2025-08-04T11:17:52.196000+00:00",
          "endTime": "2025-08-04T11:18:25.244000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 33048.0,
          "costDetails": {},
          "completionTokens": 1141,
          "promptTokens": 2048,
          "totalTokens": 3189,
          "environment": "default",
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-14-18-33-495755_chatcmpl-2bf85976-6584-4290-b3c2-17ce8d90f673",
          "traceId": "edb48c7e",
          "type": "GENERATION",
          "name": "edb4_tpusg_gen_attempt#3",
          "startTime": "2025-08-04T11:18:33.495000+00:00",
          "endTime": "2025-08-04T11:19:05.145000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 31650.0,
          "costDetails": {},
          "completionTokens": 1088,
          "promptTokens": 2048,
          "totalTokens": 3136,
          "environment": "default",
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-14-19-13-624007_chatcmpl-9db7c8e7-8a65-4856-9823-f700c3182bac",
          "traceId": "edb48c7e",
          "type": "GENERATION",
          "name": "edb4_tpusg_gen_attempt#4",
          "startTime": "2025-08-04T11:19:13.624000+00:00",
          "endTime": "2025-08-04T11:19:44.688000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 31064.0,
          "costDetails": {},
          "completionTokens": 1066,
          "promptTokens": 2048,
          "totalTokens": 3114,
          "environment": "default",
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-14-19-53-134535_chatcmpl-56bcc5ca-4a92-45e0-b887-d01e5b63b861",
          "traceId": "edb48c7e",
          "type": "GENERATION",
          "name": "edb4_tpusg_gen_attempt#5",
          "startTime": "2025-08-04T11:19:53.134000+00:00",
          "endTime": "2025-08-04T11:20:25.155000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 32021.0,
          "costDetails": {},
          "completionTokens": 1102,
          "promptTokens": 2048,
          "totalTokens": 3150,
          "environment": "default",
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "dc96a5c9-0262-4248-a70d-872029170ac6",
          "traceId": "edb48c7e",
          "type": "SPAN",
          "name": "error_ed_tpusg_failure_signal_tpu_sketch_generator",
          "startTime": "2025-08-04T11:20:33.446000+00:00",
          "level": "ERROR",
          "statusMessage": "Failed. Last error: Traceback (most recent call last):\n  File \"script_1942fbe4_1754306425.py\", line 67, in <module>\n    num_detections = int(interpreter.get_tensor(output_details[1]['index'])[0])  # Access the first element of the array\nTypeError: only size-1 arrays can be converted to Python scalars",
          "calculatedTotalCost": 0.0,
          "costDetails": {},
          "completionTokens": 0,
          "promptTokens": 0,
          "totalTokens": 0,
          "environment": "default",
          "endTime": null,
          "model": null,
          "modelParameters": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null,
          "latency": null
        }
      ],
      "createdAt": "2025-08-04T11:17:18.642Z",
      "updatedAt": "2025-08-04T11:20:38.900Z",
      "environment": "default"
    },
    {
      "id": "4164e79a",
      "timestamp": "2025-08-04T11:13:58.559000+00:00",
      "name": "4164_tpu_sketch_generator",
      "input": null,
      "output": {
        "status": "failed",
        "last_code": "import numpy as np\nfrom tflite_runtime.interpreter import Interpreter, load_delegate\nimport cv2\n\n# Phase 1: Setup\nmodel_path  = \"/home/mendel/tinyml_autopilot/models/edgetpu_detect.tflite\"\nlabel_path  = \"/home/mendel/tinyml_autopilot/models/labelmap.txt\"\ninput_path  = \"/home/mendel/tinyml_autopilot/data//sheeps.mp4\"\noutput_path  = \"/home/mendel/tinyml_autopilot/results/sheeps_detections.mp4\"\nconfidence_threshold  = 0.5\n\n# Load labels\nwith open(label_path, 'r') as f:\n    labels = [line.strip() for line in f.readlines()]\n\n# Load Interpreter with EdgeTPU\ntry:\n    interpreter = Interpreter(model_path=model_path,\n                              experimental_delegates=[load_delegate('libedgetpu.so.1.0')])\nexcept Exception as e:\n    print(f\"Failed to load libedgetpu.so.1.0: {e}\")\n    try:\n        interpreter = Interpreter(model_path=model_path,\n                                  experimental_delegates=[load_delegate('/usr/lib/aarch64-linux-gnu/libedgetpu.so.1.0')])\n    except Exception as e:\n        print(f\"Failed to load /usr/lib/aarch64-linux-gnu/libedgetpu.so.1.0: {e}\")\n        raise\n\ninterpreter.allocate_tensors()\n\n# Get Model Details\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\n\nfloating_model = (input_details[0]['dtype'] == np.float32)\n\n# Phase 2: Input Acquisition & Preprocessing Loop\ncap = cv2.VideoCapture(input_path)\nif not cap.isOpened():\n    raise IOError(\"Cannot open video file\")\n\nframe_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\nframe_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\nfps = cap.get(cv2.CAP_PROP_FPS)\n\nout = cv2.VideoWriter(output_path, cv2.VideoWriter_fourcc(*'mp4v'), fps, (frame_width, frame_height))\n\nwhile True:\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    # Preprocess Data\n    input_data = cv2.resize(frame, (input_details[0]['shape'][1], input_details[0]['shape'][2]))\n    input_data = np.expand_dims(input_data, axis=0)\n\n    if floating_model:\n        input_data = (np.float32(input_data) - 127.5) / 127.5\n\n    # Phase 3: Inference\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n    interpreter.invoke()\n\n    # Phase 4: Output Interpretation & Handling Loop\n    output_data = interpreter.get_tensor(output_details[0]['index'])\n    num_detections = int(interpreter.get_tensor(output_details[1]['index'])[0])  # Extract the scalar value from array\n    detection_boxes = interpreter.get_tensor(output_details[2]['index'])[0]\n    detection_classes = interpreter.get_tensor(output_details[3]['index'])[0].astype(int)\n    detection_scores = interpreter.get_tensor(output_details[4]['index'])[0]\n\n    for i in range(num_detections):\n        if detection_scores[i] > confidence_threshold:\n            box = detection_boxes[i]\n            class_id = detection_classes[i]\n            score = detection_scores[i]\n\n            # Scale and clip bounding boxes\n            ymin, xmin, ymax, xmax = box\n            (left, right, top, bottom) = (xmin * frame_width, xmax * frame_width,\n                                          ymin * frame_height, ymax * frame_height)\n\n            cv2.rectangle(frame, (int(left), int(top)), (int(right), int(bottom)), (0, 255, 0), 2)\n            label = f'{labels[class_id]}: {score:.2f}'\n            cv2.putText(frame, label, (int(left), int(top) - 10),\n                        cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n\n    # Handle Output\n    out.write(frame)\n\n# Phase 5: Cleanup\ncap.release()\nout.release()\ncv2.destroyAllWindows()",
        "last_error": "Traceback (most recent call last):\n  File \"script_8ec7bc77_1754306223.py\", line 66, in <module>\n    num_detections = int(interpreter.get_tensor(output_details[1]['index'])[0])  # Extract the scalar value from array\nTypeError: only size-1 arrays can be converted to Python scalars"
      },
      "session_id": "qwen2.5-coder:32b_ee11_tpusg_batch",
      "metadata": {
        "num_run": 9
      },
      "tags": [
        "benchmark",
        "qwen2.5-coder:32b",
        "tpu_sketch_generator"
      ],
      "latency": 193.434,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-14-13-58-561826_chatcmpl-1e3fea0d-5964-4a78-97f3-55714d376357",
          "traceId": "4164e79a",
          "type": "GENERATION",
          "name": "4164_tpusg_gen_attempt#1",
          "startTime": "2025-08-04T11:13:58.561000+00:00",
          "endTime": "2025-08-04T11:14:24.455000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 25894.0,
          "costDetails": {},
          "completionTokens": 876,
          "promptTokens": 1833,
          "totalTokens": 2709,
          "environment": "default",
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-14-14-32-707276_chatcmpl-26da7022-f275-4180-b724-7989c41e1ebd",
          "traceId": "4164e79a",
          "type": "GENERATION",
          "name": "4164_tpusg_gen_attempt#2",
          "startTime": "2025-08-04T11:14:32.707000+00:00",
          "endTime": "2025-08-04T11:15:04.253000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 31546.0,
          "costDetails": {},
          "completionTokens": 1084,
          "promptTokens": 2048,
          "totalTokens": 3132,
          "environment": "default",
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-14-15-12-542143_chatcmpl-59469f53-a89f-4f22-8acb-255f8b475d3a",
          "traceId": "4164e79a",
          "type": "GENERATION",
          "name": "4164_tpusg_gen_attempt#3",
          "startTime": "2025-08-04T11:15:12.542000+00:00",
          "endTime": "2025-08-04T11:15:43.138000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 30596.0,
          "costDetails": {},
          "completionTokens": 1046,
          "promptTokens": 2048,
          "totalTokens": 3094,
          "environment": "default",
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-14-15-51-344799_chatcmpl-9dfc1aed-6015-4663-9302-a6fec5c7badb",
          "traceId": "4164e79a",
          "type": "GENERATION",
          "name": "4164_tpusg_gen_attempt#4",
          "startTime": "2025-08-04T11:15:51.344000+00:00",
          "endTime": "2025-08-04T11:16:23.473000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 32129.0,
          "costDetails": {},
          "completionTokens": 1105,
          "promptTokens": 2048,
          "totalTokens": 3153,
          "environment": "default",
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-14-16-31-730276_chatcmpl-363cff64-1a54-4cf0-8596-af1a193b6df4",
          "traceId": "4164e79a",
          "type": "GENERATION",
          "name": "4164_tpusg_gen_attempt#5",
          "startTime": "2025-08-04T11:16:31.730000+00:00",
          "endTime": "2025-08-04T11:17:03.442000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 31712.0,
          "costDetails": {},
          "completionTokens": 1090,
          "promptTokens": 2048,
          "totalTokens": 3138,
          "environment": "default",
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "0a804b53-54df-45be-89f9-39c0b43773f7",
          "traceId": "4164e79a",
          "type": "SPAN",
          "name": "error_41_tpusg_failure_signal_tpu_sketch_generator",
          "startTime": "2025-08-04T11:17:11.995000+00:00",
          "level": "ERROR",
          "statusMessage": "Failed. Last error: Traceback (most recent call last):\n  File \"script_8ec7bc77_1754306223.py\", line 66, in <module>\n    num_detections = int(interpreter.get_tensor(output_details[1]['index'])[0])  # Extract the scalar value from array\nTypeError: only size-1 arrays can be converted to Python scalars",
          "calculatedTotalCost": 0.0,
          "costDetails": {},
          "completionTokens": 0,
          "promptTokens": 0,
          "totalTokens": 0,
          "environment": "default",
          "endTime": null,
          "model": null,
          "modelParameters": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null,
          "latency": null
        }
      ],
      "createdAt": "2025-08-04T11:13:59.080Z",
      "updatedAt": "2025-08-04T11:17:17.316Z",
      "environment": "default"
    },
    {
      "id": "30f74dc5",
      "timestamp": "2025-08-04T11:10:35.941000+00:00",
      "name": "30f7_tpu_sketch_generator",
      "input": null,
      "output": {
        "status": "failed",
        "last_code": "import numpy as np\nfrom tflite_runtime.interpreter import Interpreter, load_delegate\nimport cv2\n\n# Phase 1: Setup\nmodel_path  = \"/home/mendel/tinyml_autopilot/models/edgetpu_detect.tflite\"\nlabel_path  = \"/home/mendel/tinyml_autopilot/models/labelmap.txt\"\ninput_path  = \"/home/mendel/tinyml_autopilot/data//sheeps.mp4\"\noutput_path  = \"/home/mendel/tinyml_autopilot/results/sheeps_detections.mp4\"\nconfidence_threshold  = 0.5\n\n# Load labels\nwith open(label_path, 'r') as f:\n    labels = [line.strip() for line in f.readlines()]\n\n# Load Interpreter with EdgeTPU\ntry:\n    interpreter = Interpreter(model_path=model_path,\n                              experimental_delegates=[load_delegate('libedgetpu.so.1.0')])\nexcept Exception as e:\n    print(f\"Failed to load libedgetpu.so.1.0: {e}\")\n    try:\n        interpreter = Interpreter(model_path=model_path,\n                                  experimental_delegates=[load_delegate('/usr/lib/aarch64-linux-gnu/libedgetpu.so.1.0')])\n    except Exception as e:\n        print(f\"Failed to load /usr/lib/aarch64-linux-gnu/libedgetpu.so.1.0: {e}\")\n        raise\n\ninterpreter.allocate_tensors()\n\n# Get Model Details\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\n\nfloating_model = (input_details[0]['dtype'] == np.float32)\n\n# Phase 2: Input Acquisition & Preprocessing Loop\ncap = cv2.VideoCapture(input_path)\nif not cap.isOpened():\n    raise IOError(\"Cannot open video file\")\n\nframe_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\nframe_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\nfps = cap.get(cv2.CAP_PROP_FPS)\n\nout = cv2.VideoWriter(output_path, cv2.VideoWriter_fourcc(*'mp4v'), fps, (frame_width, frame_height))\n\nwhile True:\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    # Preprocess Data\n    input_data = cv2.resize(frame, (input_details[0]['shape'][1], input_details[0]['shape'][2]))\n    input_data = np.expand_dims(input_data, axis=0)\n\n    if floating_model:\n        input_data = (np.float32(input_data) - 127.5) / 127.5\n\n    # Phase 3: Inference\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n    interpreter.invoke()\n\n    # Phase 4: Output Interpretation & Handling Loop\n    output_data = interpreter.get_tensor(output_details[0]['index'])\n    num_detections = int(interpreter.get_tensor(output_details[1]['index']))  # Directly convert to int\n\n    detection_boxes = interpreter.get_tensor(output_details[2]['index'])[0]\n    detection_classes = interpreter.get_tensor(output_details[3]['index'])[0].astype(int)\n    detection_scores = interpreter.get_tensor(output_details[4]['index'])[0]\n\n    for i in range(num_detections):\n        if detection_scores[i] > confidence_threshold:\n            box = detection_boxes[i]\n            class_id = detection_classes[i]\n            score = detection_scores[i]\n\n            # Scale and clip bounding boxes\n            ymin, xmin, ymax, xmax = box\n            (left, right, top, bottom) = (xmin * frame_width, xmax * frame_width,\n                                          ymin * frame_height, ymax * frame_height)\n\n            cv2.rectangle(frame, (int(left), int(top)), (int(right), int(bottom)), (0, 255, 0), 2)\n            label = f'{labels[class_id]}: {score:.2f}'\n            cv2.putText(frame, label, (int(left), int(top) - 10),\n                        cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n\n    # Write the frame with detections to the output video\n    out.write(frame)\n\n# Release resources\ncap.release()\nout.release()\ncv2.destroyAllWindows()",
        "last_error": "Traceback (most recent call last):\n  File \"script_bcde7720_1754306024.py\", line 66, in <module>\n    num_detections = int(interpreter.get_tensor(output_details[1]['index']))  # Directly convert to int\nTypeError: only size-1 arrays can be converted to Python scalars"
      },
      "session_id": "qwen2.5-coder:32b_ee11_tpusg_batch",
      "metadata": {
        "num_run": 8
      },
      "tags": [
        "benchmark",
        "qwen2.5-coder:32b",
        "tpu_sketch_generator"
      ],
      "latency": 196.81,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-14-10-35-943366_chatcmpl-b0073703-7f72-4512-8f44-73eaab9e07c6",
          "traceId": "30f74dc5",
          "type": "GENERATION",
          "name": "30f7_tpusg_gen_attempt#1",
          "startTime": "2025-08-04T11:10:35.943000+00:00",
          "endTime": "2025-08-04T11:11:01.876000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 25933.0,
          "costDetails": {},
          "completionTokens": 876,
          "promptTokens": 1833,
          "totalTokens": 2709,
          "environment": "default",
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-14-11-10-085717_chatcmpl-83212c96-3705-4ec8-807e-00ec79658ef7",
          "traceId": "30f74dc5",
          "type": "GENERATION",
          "name": "30f7_tpusg_gen_attempt#2",
          "startTime": "2025-08-04T11:11:10.085000+00:00",
          "endTime": "2025-08-04T11:11:41.819000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 31734.0,
          "costDetails": {},
          "completionTokens": 1090,
          "promptTokens": 2048,
          "totalTokens": 3138,
          "environment": "default",
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-14-11-49-981108_chatcmpl-d2763202-1b3b-4fcb-a5a6-26e5f9ac2b0f",
          "traceId": "30f74dc5",
          "type": "GENERATION",
          "name": "30f7_tpusg_gen_attempt#3",
          "startTime": "2025-08-04T11:11:49.981000+00:00",
          "endTime": "2025-08-04T11:12:23.705000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 33724.0,
          "costDetails": {},
          "completionTokens": 1166,
          "promptTokens": 2048,
          "totalTokens": 3214,
          "environment": "default",
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-14-12-31-929089_chatcmpl-8c7c6fe1-cd09-4f0a-99c7-673e8c8325c4",
          "traceId": "30f74dc5",
          "type": "GENERATION",
          "name": "30f7_tpusg_gen_attempt#4",
          "startTime": "2025-08-04T11:12:31.929000+00:00",
          "endTime": "2025-08-04T11:13:02.702000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 30773.0,
          "costDetails": {},
          "completionTokens": 1054,
          "promptTokens": 2048,
          "totalTokens": 3102,
          "environment": "default",
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-14-13-10-960935_chatcmpl-5c8f0d56-efe4-4da0-9bc4-ffe83b8b6c83",
          "traceId": "30f74dc5",
          "type": "GENERATION",
          "name": "30f7_tpusg_gen_attempt#5",
          "startTime": "2025-08-04T11:13:10.960000+00:00",
          "endTime": "2025-08-04T11:13:44.459000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 33499.0,
          "costDetails": {},
          "completionTokens": 1158,
          "promptTokens": 2048,
          "totalTokens": 3206,
          "environment": "default",
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "d49bda4c-381e-45da-b044-b2c0c3d207b2",
          "traceId": "30f74dc5",
          "type": "SPAN",
          "name": "error_30_tpusg_failure_signal_tpu_sketch_generator",
          "startTime": "2025-08-04T11:13:52.753000+00:00",
          "level": "ERROR",
          "statusMessage": "Failed. Last error: Traceback (most recent call last):\n  File \"script_bcde7720_1754306024.py\", line 66, in <module>\n    num_detections = int(interpreter.get_tensor(output_details[1]['index']))  # Directly convert to int\nTypeError: only size-1 arrays can be converted to Python scalars",
          "calculatedTotalCost": 0.0,
          "costDetails": {},
          "completionTokens": 0,
          "promptTokens": 0,
          "totalTokens": 0,
          "environment": "default",
          "endTime": null,
          "model": null,
          "modelParameters": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null,
          "latency": null
        }
      ],
      "createdAt": "2025-08-04T11:10:36.461Z",
      "updatedAt": "2025-08-04T11:13:58.236Z",
      "environment": "default"
    },
    {
      "id": "2cc63f75",
      "timestamp": "2025-08-04T11:07:10.357000+00:00",
      "name": "2cc6_tpu_sketch_generator",
      "input": null,
      "output": {
        "status": "failed",
        "last_code": "import numpy as np\nfrom tflite_runtime.interpreter import Interpreter, load_delegate\nimport cv2\n\n# Phase 1: Setup\nmodel_path  = \"/home/mendel/tinyml_autopilot/models/edgetpu_detect.tflite\"\nlabel_path  = \"/home/mendel/tinyml_autopilot/models/labelmap.txt\"\ninput_path  = \"/home/mendel/tinyml_autopilot/data//sheeps.mp4\"\noutput_path  = \"/home/mendel/tinyml_autopilot/results/sheeps_detections.mp4\"\nconfidence_threshold  = 0.5\n\n# Load labels\nwith open(label_path, 'r') as f:\n    labels = [line.strip() for line in f.readlines()]\n\n# Load Interpreter with EdgeTPU\ntry:\n    interpreter = Interpreter(model_path=model_path,\n                              experimental_delegates=[load_delegate('libedgetpu.so.1.0')])\nexcept Exception as e:\n    print(f\"Failed to load libedgetpu.so.1.0: {e}\")\n    try:\n        interpreter = Interpreter(model_path=model_path,\n                                  experimental_delegates=[load_delegate('/usr/lib/aarch64-linux-gnu/libedgetpu.so.1.0')])\n    except Exception as e:\n        print(f\"Failed to load /usr/lib/aarch64-linux-gnu/libedgetpu.so.1.0: {e}\")\n        raise\n\ninterpreter.allocate_tensors()\n\n# Get Model Details\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\n\nfloating_model = (input_details[0]['dtype'] == np.float32)\n\n# Phase 2: Input Acquisition & Preprocessing Loop\ncap = cv2.VideoCapture(input_path)\nif not cap.isOpened():\n    raise IOError(\"Cannot open video file\")\n\nframe_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\nframe_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\nfps = cap.get(cv2.CAP_PROP_FPS)\n\nout = cv2.VideoWriter(output_path, cv2.VideoWriter_fourcc(*'mp4v'), fps, (frame_width, frame_height))\n\nwhile True:\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    # Preprocess Data\n    input_data = cv2.resize(frame, (input_details[0]['shape'][1], input_details[0]['shape'][2]))\n    input_data = np.expand_dims(input_data, axis=0)\n\n    if floating_model:\n        input_data = (np.float32(input_data) - 127.5) / 127.5\n\n    # Phase 3: Inference\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n    interpreter.invoke()\n\n    # Phase 4: Output Interpretation & Handling Loop\n    output_data = interpreter.get_tensor(output_details[0]['index'])\n    num_detections = int(interpreter.get_tensor(output_details[1]['index']))  # Directly convert to int\n    detection_boxes = interpreter.get_tensor(output_details[2]['index'])[0]\n    detection_classes = interpreter.get_tensor(output_details[3]['index'])[0].astype(int)\n    detection_scores = interpreter.get_tensor(output_details[4]['index'])[0]\n\n    for i in range(num_detections):\n        if detection_scores[i] > confidence_threshold:\n            box = detection_boxes[i]\n            class_id = detection_classes[i]\n            score = detection_scores[i]\n\n            # Scale the bounding box coordinates\n            ymin, xmin, ymax, xmax = box\n            (left, right, top, bottom) = (xmin * frame_width, xmax * frame_width,\n                                          ymin * frame_height, ymax * frame_height)\n\n            # Draw the bounding box and label on the frame\n            cv2.rectangle(frame, (int(left), int(top)), (int(right), int(bottom)), (0, 255, 0), 2)\n            label = f'{labels[class_id]}: {score:.2f}'\n            cv2.putText(frame, label, (int(left), int(top) - 10),\n                        cv2.FONT_HERSHEY_SIMPLEX, 0.9, (36, 255, 12), 2)\n\n    # Write the frame to the output video\n    out.write(frame)\n\n# Release resources\ncap.release()\nout.release()\ncv2.destroyAllWindows()",
        "last_error": "Traceback (most recent call last):\n  File \"script_56b72eb5_1754305821.py\", line 66, in <module>\n    num_detections = int(interpreter.get_tensor(output_details[1]['index']))  # Directly convert to int\nTypeError: only size-1 arrays can be converted to Python scalars"
      },
      "session_id": "qwen2.5-coder:32b_ee11_tpusg_batch",
      "metadata": {
        "num_run": 7
      },
      "tags": [
        "benchmark",
        "qwen2.5-coder:32b",
        "tpu_sketch_generator"
      ],
      "latency": 199.707,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-14-07-10-358939_chatcmpl-3a0a3607-5da1-4305-aca3-ee20019f9029",
          "traceId": "2cc63f75",
          "type": "GENERATION",
          "name": "2cc6_tpusg_gen_attempt#1",
          "startTime": "2025-08-04T11:07:10.358000+00:00",
          "endTime": "2025-08-04T11:07:36.957000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 26599.0,
          "costDetails": {},
          "completionTokens": 893,
          "promptTokens": 1833,
          "totalTokens": 2726,
          "environment": "default",
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-14-07-45-193993_chatcmpl-6003fea7-8db0-4b63-b865-f1e7c49ed252",
          "traceId": "2cc63f75",
          "type": "GENERATION",
          "name": "2cc6_tpusg_gen_attempt#2",
          "startTime": "2025-08-04T11:07:45.193000+00:00",
          "endTime": "2025-08-04T11:08:18.631000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 33438.0,
          "costDetails": {},
          "completionTokens": 1144,
          "promptTokens": 2048,
          "totalTokens": 3192,
          "environment": "default",
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-14-08-27-100485_chatcmpl-33d7ef5a-237d-4bc9-8117-b251f0ec4a1b",
          "traceId": "2cc63f75",
          "type": "GENERATION",
          "name": "2cc6_tpusg_gen_attempt#3",
          "startTime": "2025-08-04T11:08:27.100000+00:00",
          "endTime": "2025-08-04T11:09:01.803000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 34703.0,
          "costDetails": {},
          "completionTokens": 1201,
          "promptTokens": 2048,
          "totalTokens": 3249,
          "environment": "default",
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-14-09-10-010907_chatcmpl-2f699b3b-a046-4329-9b81-7edce47bc501",
          "traceId": "2cc63f75",
          "type": "GENERATION",
          "name": "2cc6_tpusg_gen_attempt#4",
          "startTime": "2025-08-04T11:09:10.010000+00:00",
          "endTime": "2025-08-04T11:09:40.755000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 30745.0,
          "costDetails": {},
          "completionTokens": 1054,
          "promptTokens": 2048,
          "totalTokens": 3102,
          "environment": "default",
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-14-09-49-097019_chatcmpl-f12cc561-f56f-4d5e-bb89-4c6d4bad6b86",
          "traceId": "2cc63f75",
          "type": "GENERATION",
          "name": "2cc6_tpusg_gen_attempt#5",
          "startTime": "2025-08-04T11:09:49.097000+00:00",
          "endTime": "2025-08-04T11:10:21.846000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 32749.0,
          "costDetails": {},
          "completionTokens": 1129,
          "promptTokens": 2048,
          "totalTokens": 3177,
          "environment": "default",
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "5917c1df-edbb-4ec0-a640-3d272bcac4ff",
          "traceId": "2cc63f75",
          "type": "SPAN",
          "name": "error_2c_tpusg_failure_signal_tpu_sketch_generator",
          "startTime": "2025-08-04T11:10:30.065000+00:00",
          "level": "ERROR",
          "statusMessage": "Failed. Last error: Traceback (most recent call last):\n  File \"script_56b72eb5_1754305821.py\", line 66, in <module>\n    num_detections = int(interpreter.get_tensor(output_details[1]['index']))  # Directly convert to int\nTypeError: only size-1 arrays can be converted to Python scalars",
          "calculatedTotalCost": 0.0,
          "costDetails": {},
          "completionTokens": 0,
          "promptTokens": 0,
          "totalTokens": 0,
          "environment": "default",
          "endTime": null,
          "model": null,
          "modelParameters": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null,
          "latency": null
        }
      ],
      "createdAt": "2025-08-04T11:07:10.876Z",
      "updatedAt": "2025-08-04T11:10:35.644Z",
      "environment": "default"
    },
    {
      "id": "72dd1e4e",
      "timestamp": "2025-08-04T11:03:44.668000+00:00",
      "name": "72dd_tpu_sketch_generator",
      "input": null,
      "output": {
        "status": "failed",
        "last_code": "import numpy as np\nfrom tflite_runtime.interpreter import Interpreter, load_delegate\n\n# Phase 1: Setup\nmodel_path  = \"/home/mendel/tinyml_autopilot/models/edgetpu_detect.tflite\"\nlabel_path  = \"/home/mendel/tinyml_autopilot/models/labelmap.txt\"\ninput_path  = \"/home/mendel/tinyml_autopilot/data//sheeps.mp4\"\noutput_path  = \"/home/mendel/tinyml_autopilot/results/sheeps_detections.mp4\"\nconfidence_threshold  = 0.5\n\n# Load labels\nwith open(label_path, 'r') as f:\n    labels = [line.strip() for line in f.readlines()]\n\n# Load Interpreter with EdgeTPU\ntry:\n    interpreter = Interpreter(model_path=model_path,\n                              experimental_delegates=[load_delegate('libedgetpu.so.1.0')])\nexcept Exception as e:\n    print(f\"Failed to load libedgetpu.so.1.0: {e}\")\n    try:\n        interpreter = Interpreter(model_path=model_path,\n                                  experimental_delegates=[load_delegate('/usr/lib/aarch64-linux-gnu/libedgetpu.so.1.0')])\n    except Exception as e:\n        print(f\"Failed to load /usr/lib/aarch64-linux-gnu/libedgetpu.so.1.0: {e}\")\n        raise\n\ninterpreter.allocate_tensors()\n\n# Get Model Details\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\n\nfloating_model = (input_details[0]['dtype'] == np.float32)\n\n# Phase 2: Input Acquisition & Preprocessing Loop\nimport cv2\n\ncap = cv2.VideoCapture(input_path)\nif not cap.isOpened():\n    raise IOError(\"Cannot open video file\")\n\nframe_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\nframe_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\nfps = cap.get(cv2.CAP_PROP_FPS)\n\nout = cv2.VideoWriter(output_path, cv2.VideoWriter_fourcc(*'mp4v'), fps, (frame_width, frame_height))\n\nwhile True:\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    # Preprocess Data\n    input_data = cv2.resize(frame, (input_details[0]['shape'][1], input_details[0]['shape'][2]))\n    input_data = np.expand_dims(input_data, axis=0)\n\n    if floating_model:\n        input_data = (np.float32(input_data) - 127.5) / 127.5\n\n    # Phase 3: Inference\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n    interpreter.invoke()\n\n    # Phase 4: Output Interpretation & Handling Loop\n    output_data = interpreter.get_tensor(output_details[0]['index'])\n    num_detections = int(interpreter.get_tensor(output_details[1]['index']))  # Directly convert to int\n\n    detection_boxes = interpreter.get_tensor(output_details[2]['index'])\n    detection_classes = interpreter.get_tensor(output_details[3]['index']).astype(int)\n    detection_scores = interpreter.get_tensor(output_details[4]['index'])\n\n    for i in range(num_detections):\n        if detection_scores[i] > confidence_threshold:\n            box = detection_boxes[i]\n            class_id = detection_classes[i]\n            score = detection_scores[i]\n\n            # Scale and clip bounding boxes\n            ymin, xmin, ymax, xmax = box\n            (left, right, top, bottom) = (xmin * frame_width, xmax * frame_width,\n                                          ymin * frame_height, ymax * frame_height)\n\n            cv2.rectangle(frame, (int(left), int(top)), (int(right), int(bottom)), (0, 255, 0), 2)\n            label = f'{labels[class_id]}: {score:.2f}'\n            cv2.putText(frame, label, (int(left), int(top) - 10),\n                        cv2.FONT_HERSHEY_SIMPLEX, 0.9, (36, 255, 12), 2)\n\n    # Write the frame with detections to the output video\n    out.write(frame)\n\n# Release resources\ncap.release()\nout.release()\ncv2.destroyAllWindows()",
        "last_error": "Traceback (most recent call last):\n  File \"script_e350e846_1754305615.py\", line 67, in <module>\n    num_detections = int(interpreter.get_tensor(output_details[1]['index']))  # Directly convert to int\nTypeError: only size-1 arrays can be converted to Python scalars"
      },
      "session_id": "qwen2.5-coder:32b_ee11_tpusg_batch",
      "metadata": {
        "num_run": 6
      },
      "tags": [
        "benchmark",
        "qwen2.5-coder:32b",
        "tpu_sketch_generator"
      ],
      "latency": 199.242,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-14-03-44-670427_chatcmpl-b1395d22-c09d-4d31-b36b-485c1cb599da",
          "traceId": "72dd1e4e",
          "type": "GENERATION",
          "name": "72dd_tpusg_gen_attempt#1",
          "startTime": "2025-08-04T11:03:44.670000+00:00",
          "endTime": "2025-08-04T11:04:10.498000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 25828.0,
          "costDetails": {},
          "completionTokens": 876,
          "promptTokens": 1833,
          "totalTokens": 2709,
          "environment": "default",
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-14-04-18-747305_chatcmpl-373f5183-a5df-47c0-ada7-18c29f4afec1",
          "traceId": "72dd1e4e",
          "type": "GENERATION",
          "name": "72dd_tpusg_gen_attempt#2",
          "startTime": "2025-08-04T11:04:18.747000+00:00",
          "endTime": "2025-08-04T11:04:51.206000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 32459.0,
          "costDetails": {},
          "completionTokens": 1118,
          "promptTokens": 2048,
          "totalTokens": 3166,
          "environment": "default",
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-14-04-59-795200_chatcmpl-8b682d8f-76c5-42e8-92f4-b5490f9e6673",
          "traceId": "72dd1e4e",
          "type": "GENERATION",
          "name": "72dd_tpusg_gen_attempt#3",
          "startTime": "2025-08-04T11:04:59.795000+00:00",
          "endTime": "2025-08-04T11:05:32.646000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 32851.0,
          "costDetails": {},
          "completionTokens": 1133,
          "promptTokens": 2048,
          "totalTokens": 3181,
          "environment": "default",
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-14-05-40-817311_chatcmpl-743e65cd-f9aa-464d-a887-a6ed1570545c",
          "traceId": "72dd1e4e",
          "type": "GENERATION",
          "name": "72dd_tpusg_gen_attempt#4",
          "startTime": "2025-08-04T11:05:40.817000+00:00",
          "endTime": "2025-08-04T11:06:14.032000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 33215.0,
          "costDetails": {},
          "completionTokens": 1147,
          "promptTokens": 2048,
          "totalTokens": 3195,
          "environment": "default",
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-14-06-22-430355_chatcmpl-eb986c49-1731-44fe-a8bc-a27eb7f38f74",
          "traceId": "72dd1e4e",
          "type": "GENERATION",
          "name": "72dd_tpusg_gen_attempt#5",
          "startTime": "2025-08-04T11:06:22.430000+00:00",
          "endTime": "2025-08-04T11:06:55.748000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 33318.0,
          "costDetails": {},
          "completionTokens": 1149,
          "promptTokens": 2048,
          "totalTokens": 3197,
          "environment": "default",
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "a963e6f4-217e-43aa-9326-f6a2d9a40e57",
          "traceId": "72dd1e4e",
          "type": "SPAN",
          "name": "error_72_tpusg_failure_signal_tpu_sketch_generator",
          "startTime": "2025-08-04T11:07:03.912000+00:00",
          "level": "ERROR",
          "statusMessage": "Failed. Last error: Traceback (most recent call last):\n  File \"script_e350e846_1754305615.py\", line 67, in <module>\n    num_detections = int(interpreter.get_tensor(output_details[1]['index']))  # Directly convert to int\nTypeError: only size-1 arrays can be converted to Python scalars",
          "calculatedTotalCost": 0.0,
          "costDetails": {},
          "completionTokens": 0,
          "promptTokens": 0,
          "totalTokens": 0,
          "environment": "default",
          "endTime": null,
          "model": null,
          "modelParameters": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null,
          "latency": null
        }
      ],
      "createdAt": "2025-08-04T11:03:45.189Z",
      "updatedAt": "2025-08-04T11:07:09.448Z",
      "environment": "default"
    },
    {
      "id": "c090659e",
      "timestamp": "2025-08-04T11:00:24.110000+00:00",
      "name": "c090_tpu_sketch_generator",
      "input": null,
      "output": {
        "status": "failed",
        "last_code": "import numpy as np\nfrom tflite_runtime.interpreter import Interpreter, load_delegate\nimport cv2\n\n# Phase 1: Setup\nmodel_path  = \"/home/mendel/tinyml_autopilot/models/edgetpu_detect.tflite\"\nlabel_path  = \"/home/mendel/tinyml_autopilot/models/labelmap.txt\"\ninput_path  = \"/home/mendel/tinyml_autopilot/data//sheeps.mp4\"\noutput_path  = \"/home/mendel/tinyml_autopilot/results/sheeps_detections.mp4\"\nconfidence_threshold  = 0.5\n\n# Load labels\nwith open(label_path, 'r') as f:\n    labels = [line.strip() for line in f.readlines()]\n\n# Load Interpreter with EdgeTPU\ntry:\n    interpreter = Interpreter(model_path=model_path,\n                              experimental_delegates=[load_delegate('libedgetpu.so.1.0')])\nexcept Exception as e:\n    print(f\"Failed to load libedgetpu.so.1.0: {e}\")\n    try:\n        interpreter = Interpreter(model_path=model_path,\n                                  experimental_delegates=[load_delegate('/usr/lib/aarch64-linux-gnu/libedgetpu.so.1.0')])\n    except Exception as e:\n        print(f\"Failed to load /usr/lib/aarch64-linux-gnu/libedgetpu.so.1.0: {e}\")\n        raise\n\ninterpreter.allocate_tensors()\n\n# Get Model Details\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\n\nfloating_model = (input_details[0]['dtype'] == np.float32)\n\n# Phase 2: Input Acquisition & Preprocessing Loop\ncap = cv2.VideoCapture(input_path)\nif not cap.isOpened():\n    raise IOError(\"Cannot open video file\")\n\nframe_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\nframe_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\nfps = cap.get(cv2.CAP_PROP_FPS)\n\nout = cv2.VideoWriter(output_path, cv2.VideoWriter_fourcc(*'mp4v'), fps, (frame_width, frame_height))\n\nwhile True:\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    # Preprocess Data\n    input_data = cv2.resize(frame, (input_details[0]['shape'][1], input_details[0]['shape'][2]))\n    input_data = np.expand_dims(input_data, axis=0)\n\n    if floating_model:\n        input_data = (np.float32(input_data) - 127.5) / 127.5\n\n    # Phase 3: Inference\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n    interpreter.invoke()\n\n    # Phase 4: Output Interpretation & Handling Loop\n    output_data = interpreter.get_tensor(output_details[0]['index'])\n    num_detections = int(interpreter.get_tensor(output_details[1]['index']))  # Correctly extract the scalar value\n    detection_boxes = interpreter.get_tensor(output_details[2]['index'])[0]\n    detection_classes = interpreter.get_tensor(output_details[3]['index'])[0].astype(int)\n    detection_scores = interpreter.get_tensor(output_details[4]['index'])[0]\n\n    for i in range(num_detections):\n        if detection_scores[i] > confidence_threshold:\n            box = detection_boxes[i]\n            class_id = detection_classes[i]\n            score = detection_scores[i]\n\n            # Scale and clip bounding boxes\n            ymin, xmin, ymax, xmax = box\n            (left, right, top, bottom) = (xmin * frame_width, xmax * frame_width,\n                                          ymin * frame_height, ymax * frame_height)\n\n            cv2.rectangle(frame, (int(left), int(top)), (int(right), int(bottom)), (0, 255, 0), 2)\n            label = f'{labels[class_id]}: {score:.2f}'\n            cv2.putText(frame, label, (int(left), int(top) - 10),\n                        cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n\n    # Write the frame to the output video\n    out.write(frame)\n\n# Release resources\ncap.release()\nout.release()\ncv2.destroyAllWindows()",
        "last_error": "Traceback (most recent call last):\n  File \"script_12885ef7_1754305410.py\", line 66, in <module>\n    num_detections = int(interpreter.get_tensor(output_details[1]['index']))  # Correctly extract the scalar value\nTypeError: only size-1 arrays can be converted to Python scalars"
      },
      "session_id": "qwen2.5-coder:32b_ee11_tpusg_batch",
      "metadata": {
        "num_run": 5
      },
      "tags": [
        "benchmark",
        "qwen2.5-coder:32b",
        "tpu_sketch_generator"
      ],
      "latency": 194.622,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-14-00-24-111762_chatcmpl-7505a247-3af7-41db-ab5a-5a96443a7f2b",
          "traceId": "c090659e",
          "type": "GENERATION",
          "name": "c090_tpusg_gen_attempt#1",
          "startTime": "2025-08-04T11:00:24.111000+00:00",
          "endTime": "2025-08-04T11:00:50.501000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 26390.0,
          "costDetails": {},
          "completionTokens": 876,
          "promptTokens": 1833,
          "totalTokens": 2709,
          "environment": "default",
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-14-00-58-707740_chatcmpl-1eda72d0-8845-4b05-ae29-2a23d68d0242",
          "traceId": "c090659e",
          "type": "GENERATION",
          "name": "c090_tpusg_gen_attempt#2",
          "startTime": "2025-08-04T11:00:58.707000+00:00",
          "endTime": "2025-08-04T11:01:32.102000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 33395.0,
          "costDetails": {},
          "completionTokens": 1150,
          "promptTokens": 2048,
          "totalTokens": 3198,
          "environment": "default",
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-14-01-40-325967_chatcmpl-5a0b3b0a-6e17-4d73-b228-9e36c9e59695",
          "traceId": "c090659e",
          "type": "GENERATION",
          "name": "c090_tpusg_gen_attempt#3",
          "startTime": "2025-08-04T11:01:40.325000+00:00",
          "endTime": "2025-08-04T11:02:11.040000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 30715.0,
          "costDetails": {},
          "completionTokens": 1052,
          "promptTokens": 2048,
          "totalTokens": 3100,
          "environment": "default",
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-14-02-19-370831_chatcmpl-aee6672a-2b3a-40b0-a939-5146a5ed3d2c",
          "traceId": "c090659e",
          "type": "GENERATION",
          "name": "c090_tpusg_gen_attempt#4",
          "startTime": "2025-08-04T11:02:19.370000+00:00",
          "endTime": "2025-08-04T11:02:50.697000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 31327.0,
          "costDetails": {},
          "completionTokens": 1073,
          "promptTokens": 2048,
          "totalTokens": 3121,
          "environment": "default",
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-14-02-58-951635_chatcmpl-69981b18-c740-4474-b84e-a2e219f8e7bd",
          "traceId": "c090659e",
          "type": "GENERATION",
          "name": "c090_tpusg_gen_attempt#5",
          "startTime": "2025-08-04T11:02:58.951000+00:00",
          "endTime": "2025-08-04T11:03:30.545000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 31594.0,
          "costDetails": {},
          "completionTokens": 1085,
          "promptTokens": 2048,
          "totalTokens": 3133,
          "environment": "default",
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "1778c318-84af-41cc-8c3e-b3f570e2532e",
          "traceId": "c090659e",
          "type": "SPAN",
          "name": "error_c0_tpusg_failure_signal_tpu_sketch_generator",
          "startTime": "2025-08-04T11:03:38.733000+00:00",
          "level": "ERROR",
          "statusMessage": "Failed. Last error: Traceback (most recent call last):\n  File \"script_12885ef7_1754305410.py\", line 66, in <module>\n    num_detections = int(interpreter.get_tensor(output_details[1]['index']))  # Correctly extract the scalar value\nTypeError: only size-1 arrays can be converted to Python scalars",
          "calculatedTotalCost": 0.0,
          "costDetails": {},
          "completionTokens": 0,
          "promptTokens": 0,
          "totalTokens": 0,
          "environment": "default",
          "endTime": null,
          "model": null,
          "modelParameters": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null,
          "latency": null
        }
      ],
      "createdAt": "2025-08-04T11:00:24.629Z",
      "updatedAt": "2025-08-04T11:03:43.939Z",
      "environment": "default"
    },
    {
      "id": "cfc4f3bc",
      "timestamp": "2025-08-04T10:56:12.505000+00:00",
      "name": "cfc4_tpu_sketch_generator",
      "input": null,
      "output": {
        "status": "success",
        "sketch": "import numpy as np\nfrom tflite_runtime.interpreter import Interpreter, load_delegate\nimport cv2\n\n# Phase 1: Setup\nmodel_path  = \"/home/mendel/tinyml_autopilot/models/edgetpu_detect.tflite\"\nlabel_path  = \"/home/mendel/tinyml_autopilot/models/labelmap.txt\"\ninput_path  = \"/home/mendel/tinyml_autopilot/data//sheeps.mp4\"\noutput_path  = \"/home/mendel/tinyml_autopilot/results/sheeps_detections.mp4\"\nconfidence_threshold  = 0.5\n\n# Load labels\nwith open(label_path, 'r') as f:\n    labels = [line.strip() for line in f.readlines()]\n\n# Load Interpreter with EdgeTPU\ntry:\n    interpreter = Interpreter(model_path=model_path,\n                              experimental_delegates=[load_delegate('libedgetpu.so.1.0')])\nexcept Exception as e:\n    print(f\"Failed to load libedgetpu.so.1.0: {e}\")\n    try:\n        interpreter = Interpreter(model_path=model_path,\n                                  experimental_delegates=[load_delegate('/usr/lib/aarch64-linux-gnu/libedgetpu.so.1.0')])\n    except Exception as e:\n        print(f\"Failed to load /usr/lib/aarch64-linux-gnu/libedgetpu.so.1.0: {e}\")\n        raise\n\ninterpreter.allocate_tensors()\n\n# Get Model Details\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\n\nfloating_model = (input_details[0]['dtype'] == np.float32)\n\n# Print output details for debugging\nprint(\"Output Details:\", output_details)\n\n# Phase 2: Input Acquisition & Preprocessing Loop\ncap = cv2.VideoCapture(input_path)\nif not cap.isOpened():\n    raise IOError(\"Cannot open video file\")\n\nframe_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\nframe_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\nfps = cap.get(cv2.CAP_PROP_FPS)\n\nout = cv2.VideoWriter(output_path, cv2.VideoWriter_fourcc(*'mp4v'), fps, (frame_width, frame_height))\n\nwhile True:\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    # Preprocess Data\n    input_data = cv2.resize(frame, (input_details[0]['shape'][1], input_details[0]['shape'][2]))\n    input_data = np.expand_dims(input_data, axis=0)\n\n    if floating_model:\n        input_data = (np.float32(input_data) - 127.5) / 127.5\n\n    # Phase 3: Inference\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n    interpreter.invoke()\n\n    # Phase 4: Output Interpretation & Handling Loop\n    detection_boxes = interpreter.get_tensor(output_details[0]['index'])[0]\n    detection_classes = interpreter.get_tensor(output_details[1]['index'])[0].astype(int)\n    detection_scores = interpreter.get_tensor(output_details[2]['index'])[0]\n\n    # Infer the number of detections from scores\n    num_detections = np.sum(detection_scores > confidence_threshold)\n\n    for i in range(num_detections):\n        if detection_scores[i] > confidence_threshold:\n            box = detection_boxes[i]\n            class_id = detection_classes[i]\n            score = detection_scores[i]\n\n            # Scale the bounding box coordinates\n            ymin, xmin, ymax, xmax = box\n            (left, right, top, bottom) = (xmin * frame_width, xmax * frame_width,\n                                          ymin * frame_height, ymax * frame_height)\n\n            # Draw the bounding box and label on the frame\n            cv2.rectangle(frame, (int(left), int(top)), (int(right), int(bottom)), (0, 255, 0), 2)\n            label = f'{labels[class_id]}: {score:.2f}'\n            cv2.putText(frame, label, (int(left), int(top) - 10),\n                        cv2.FONT_HERSHEY_SIMPLEX, 0.9, (36, 255, 12), 2)\n\n    # Write the frame to the output video\n    out.write(frame)\n\n# Release resources\ncap.release()\nout.release()\ncv2.destroyAllWindows()"
      },
      "session_id": "qwen2.5-coder:32b_ee11_tpusg_batch",
      "metadata": {
        "num_run": 4
      },
      "tags": [
        "benchmark",
        "qwen2.5-coder:32b",
        "tpu_sketch_generator"
      ],
      "latency": 192.789,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-13-56-12-507116_chatcmpl-8bfbfcb8-bfa1-420e-9f87-0f9f7bd485d3",
          "traceId": "cfc4f3bc",
          "type": "GENERATION",
          "name": "cfc4_tpusg_gen_attempt#1",
          "startTime": "2025-08-04T10:56:12.507000+00:00",
          "endTime": "2025-08-04T10:56:38.792000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 26285.0,
          "costDetails": {},
          "completionTokens": 893,
          "promptTokens": 1833,
          "totalTokens": 2726,
          "environment": "default",
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-13-56-47-121047_chatcmpl-fb1460d8-75f4-4931-80cc-ef8a117fa2db",
          "traceId": "cfc4f3bc",
          "type": "GENERATION",
          "name": "cfc4_tpusg_gen_attempt#2",
          "startTime": "2025-08-04T10:56:47.121000+00:00",
          "endTime": "2025-08-04T10:57:18.514000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 31393.0,
          "costDetails": {},
          "completionTokens": 1078,
          "promptTokens": 2048,
          "totalTokens": 3126,
          "environment": "default",
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-13-57-26-746625_chatcmpl-24385e98-53bf-4aaf-a143-f5824aee00af",
          "traceId": "cfc4f3bc",
          "type": "GENERATION",
          "name": "cfc4_tpusg_gen_attempt#3",
          "startTime": "2025-08-04T10:57:26.746000+00:00",
          "endTime": "2025-08-04T10:58:00.549000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 33803.0,
          "costDetails": {},
          "completionTokens": 1170,
          "promptTokens": 2048,
          "totalTokens": 3218,
          "environment": "default",
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-13-58-08-722192_chatcmpl-be86d86c-2138-4cef-aa61-863861c24a85",
          "traceId": "cfc4f3bc",
          "type": "GENERATION",
          "name": "cfc4_tpusg_gen_attempt#4",
          "startTime": "2025-08-04T10:58:08.722000+00:00",
          "endTime": "2025-08-04T10:58:43.760000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 35038.0,
          "costDetails": {},
          "completionTokens": 1216,
          "promptTokens": 2048,
          "totalTokens": 3264,
          "environment": "default",
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-13-58-52-314909_chatcmpl-2fcc511d-fd60-4042-abf1-9908e0cb981c",
          "traceId": "cfc4f3bc",
          "type": "GENERATION",
          "name": "cfc4_tpusg_gen_attempt#5",
          "startTime": "2025-08-04T10:58:52.314000+00:00",
          "endTime": "2025-08-04T10:59:25.296000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 32982.0,
          "costDetails": {},
          "completionTokens": 1077,
          "promptTokens": 2048,
          "totalTokens": 3125,
          "environment": "default",
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        }
      ],
      "createdAt": "2025-08-04T10:56:13.024Z",
      "updatedAt": "2025-08-04T11:00:22.760Z",
      "environment": "default"
    },
    {
      "id": "30f5bf96",
      "timestamp": "2025-08-04T10:52:48.880000+00:00",
      "name": "30f5_tpu_sketch_generator",
      "input": null,
      "output": {
        "status": "failed",
        "last_code": "import numpy as np\nfrom tflite_runtime.interpreter import Interpreter, load_delegate\nimport cv2\n\n# Phase 1: Setup\nmodel_path  = \"/home/mendel/tinyml_autopilot/models/edgetpu_detect.tflite\"\nlabel_path  = \"/home/mendel/tinyml_autopilot/models/labelmap.txt\"\ninput_path  = \"/home/mendel/tinyml_autopilot/data//sheeps.mp4\"\noutput_path  = \"/home/mendel/tinyml_autopilot/results/sheeps_detections.mp4\"\nconfidence_threshold  = 0.5\n\n# Load labels\nwith open(label_path, 'r') as f:\n    labels = [line.strip() for line in f.readlines()]\n\n# Load Interpreter with EdgeTPU\ntry:\n    interpreter = Interpreter(model_path=model_path,\n                              experimental_delegates=[load_delegate('libedgetpu.so.1.0')])\nexcept Exception as e:\n    print(f\"Failed to load libedgetpu.so.1.0: {e}\")\n    try:\n        interpreter = Interpreter(model_path=model_path,\n                                  experimental_delegates=[load_delegate('/usr/lib/aarch64-linux-gnu/libedgetpu.so.1.0')])\n    except Exception as e:\n        print(f\"Failed to load /usr/lib/aarch64-linux-gnu/libedgetpu.so.1.0: {e}\")\n        raise\n\ninterpreter.allocate_tensors()\n\n# Get Model Details\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\n\nfloating_model = (input_details[0]['dtype'] == np.float32)\n\n# Phase 2: Input Acquisition & Preprocessing Loop\ncap = cv2.VideoCapture(input_path)\nif not cap.isOpened():\n    raise IOError(\"Cannot open video file\")\n\nframe_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\nframe_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\nfps = cap.get(cv2.CAP_PROP_FPS)\n\nout = cv2.VideoWriter(output_path, cv2.VideoWriter_fourcc(*'mp4v'), fps, (frame_width, frame_height))\n\nwhile True:\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    # Preprocess Data\n    input_data = cv2.resize(frame, (input_details[0]['shape'][1], input_details[0]['shape'][2]))\n    input_data = np.expand_dims(input_data, axis=0)\n\n    if floating_model:\n        input_data = (np.float32(input_data) - 127.5) / 127.5\n\n    # Phase 3: Inference\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n    interpreter.invoke()\n\n    # Phase 4: Output Interpretation & Handling Loop\n    output_data = interpreter.get_tensor(output_details[0]['index'])\n    \n    # Correctly access the first element of num_detections array\n    num_detections = int(interpreter.get_tensor(output_details[1]['index'])[0])\n        \n    detection_boxes = interpreter.get_tensor(output_details[2]['index'])[0]\n    detection_classes = interpreter.get_tensor(output_details[3]['index'])[0].astype(int)\n    detection_scores = interpreter.get_tensor(output_details[4]['index'])[0]\n\n    for i in range(num_detections):\n        if detection_scores[i] > confidence_threshold:\n            box = detection_boxes[i]\n            class_id = detection_classes[i]\n            score = detection_scores[i]\n\n            # Scale the bounding box coordinates\n            ymin, xmin, ymax, xmax = box\n            (left, right, top, bottom) = (xmin * frame_width, xmax * frame_width,\n                                          ymin * frame_height, ymax * frame_height)\n\n            # Draw the bounding box and label on the frame\n            cv2.rectangle(frame, (int(left), int(top)), (int(right), int(bottom)), (0, 255, 0), 2)\n            label = f'{labels[class_id]}: {score:.2f}'\n            cv2.putText(frame, label, (int(left), int(top) - 10),\n                        cv2.FONT_HERSHEY_SIMPLEX, 0.9, (36, 255, 12), 2)\n\n    # Write the frame to the output video\n    out.write(frame)\n\n# Release resources\ncap.release()\nout.release()\ncv2.destroyAllWindows()",
        "last_error": "Traceback (most recent call last):\n  File \"script_7c3baf02_1754304957.py\", line 68, in <module>\n    num_detections = int(interpreter.get_tensor(output_details[1]['index'])[0])\nTypeError: only size-1 arrays can be converted to Python scalars"
      },
      "session_id": "qwen2.5-coder:32b_ee11_tpusg_batch",
      "metadata": {
        "num_run": 3
      },
      "tags": [
        "benchmark",
        "qwen2.5-coder:32b",
        "tpu_sketch_generator"
      ],
      "latency": 197.325,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-13-52-48-881858_chatcmpl-463299ee-2ab6-44d0-a88b-4c1dc3c0ea5e",
          "traceId": "30f5bf96",
          "type": "GENERATION",
          "name": "30f5_tpusg_gen_attempt#1",
          "startTime": "2025-08-04T10:52:48.881000+00:00",
          "endTime": "2025-08-04T10:53:15.157000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 26276.0,
          "costDetails": {},
          "completionTokens": 893,
          "promptTokens": 1833,
          "totalTokens": 2726,
          "environment": "default",
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-13-53-23-433508_chatcmpl-55049101-7e58-4daf-a105-6e7cced098e3",
          "traceId": "30f5bf96",
          "type": "GENERATION",
          "name": "30f5_tpusg_gen_attempt#2",
          "startTime": "2025-08-04T10:53:23.433000+00:00",
          "endTime": "2025-08-04T10:53:56.989000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 33556.0,
          "costDetails": {},
          "completionTokens": 1160,
          "promptTokens": 2048,
          "totalTokens": 3208,
          "environment": "default",
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-13-54-05-263445_chatcmpl-26251be6-674a-4531-9807-3f4c5c491bad",
          "traceId": "30f5bf96",
          "type": "GENERATION",
          "name": "30f5_tpusg_gen_attempt#3",
          "startTime": "2025-08-04T10:54:05.263000+00:00",
          "endTime": "2025-08-04T10:54:38.263000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 33000.0,
          "costDetails": {},
          "completionTokens": 1139,
          "promptTokens": 2048,
          "totalTokens": 3187,
          "environment": "default",
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-13-54-46-743277_chatcmpl-0b3aef3c-2892-4e9e-bd07-f5c0b5984408",
          "traceId": "30f5bf96",
          "type": "GENERATION",
          "name": "30f5_tpusg_gen_attempt#4",
          "startTime": "2025-08-04T10:54:46.743000+00:00",
          "endTime": "2025-08-04T10:55:18.100000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 31357.0,
          "costDetails": {},
          "completionTokens": 1077,
          "promptTokens": 2048,
          "totalTokens": 3125,
          "environment": "default",
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-13-55-26-364934_chatcmpl-589d3ca6-0ed2-4420-9fef-8e403189975b",
          "traceId": "30f5bf96",
          "type": "GENERATION",
          "name": "30f5_tpusg_gen_attempt#5",
          "startTime": "2025-08-04T10:55:26.364000+00:00",
          "endTime": "2025-08-04T10:55:57.955000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 31591.0,
          "costDetails": {},
          "completionTokens": 1086,
          "promptTokens": 2048,
          "totalTokens": 3134,
          "environment": "default",
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "5a08eab6-7877-4ad5-8e24-3f9e03ca5843",
          "traceId": "30f5bf96",
          "type": "SPAN",
          "name": "error_30_tpusg_failure_signal_tpu_sketch_generator",
          "startTime": "2025-08-04T10:56:06.206000+00:00",
          "level": "ERROR",
          "statusMessage": "Failed. Last error: Traceback (most recent call last):\n  File \"script_7c3baf02_1754304957.py\", line 68, in <module>\n    num_detections = int(interpreter.get_tensor(output_details[1]['index'])[0])\nTypeError: only size-1 arrays can be converted to Python scalars",
          "calculatedTotalCost": 0.0,
          "costDetails": {},
          "completionTokens": 0,
          "promptTokens": 0,
          "totalTokens": 0,
          "environment": "default",
          "endTime": null,
          "model": null,
          "modelParameters": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null,
          "latency": null
        }
      ],
      "createdAt": "2025-08-04T10:52:49.398Z",
      "updatedAt": "2025-08-04T10:56:11.633Z",
      "environment": "default"
    },
    {
      "id": "69cd1e77",
      "timestamp": "2025-08-04T10:49:36.323000+00:00",
      "name": "69cd_tpu_sketch_generator",
      "input": null,
      "output": {
        "status": "failed",
        "last_code": "num_detections = int(interpreter.get_tensor(output_details[1]['index'])[0])  # Directly access the scalar value",
        "last_error": "Unexpected error during generation: Generated script is not complete. Please ensure to generate a complete Python script."
      },
      "session_id": "qwen2.5-coder:32b_ee11_tpusg_batch",
      "metadata": {
        "num_run": 2
      },
      "tags": [
        "benchmark",
        "qwen2.5-coder:32b",
        "tpu_sketch_generator"
      ],
      "latency": 185.604,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-13-49-36-325243_chatcmpl-f2d2a919-720d-4dbb-a2e5-3bf8cb0466be",
          "traceId": "69cd1e77",
          "type": "GENERATION",
          "name": "69cd_tpusg_gen_attempt#1",
          "startTime": "2025-08-04T10:49:36.325000+00:00",
          "endTime": "2025-08-04T10:50:02.135000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 25810.0,
          "costDetails": {},
          "completionTokens": 876,
          "promptTokens": 1833,
          "totalTokens": 2709,
          "environment": "default",
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-13-50-10-399175_chatcmpl-380f70b1-55f3-4d53-9236-07f52d18b474",
          "traceId": "69cd1e77",
          "type": "GENERATION",
          "name": "69cd_tpusg_gen_attempt#2",
          "startTime": "2025-08-04T10:50:10.399000+00:00",
          "endTime": "2025-08-04T10:50:42.887000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 32488.0,
          "costDetails": {},
          "completionTokens": 1118,
          "promptTokens": 2048,
          "totalTokens": 3166,
          "environment": "default",
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-13-50-51-237013_chatcmpl-c08daaee-a2cc-419d-bcd3-3716b241ad00",
          "traceId": "69cd1e77",
          "type": "GENERATION",
          "name": "69cd_tpusg_gen_attempt#3",
          "startTime": "2025-08-04T10:50:51.237000+00:00",
          "endTime": "2025-08-04T10:51:22.464000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 31227.0,
          "costDetails": {},
          "completionTokens": 1072,
          "promptTokens": 2048,
          "totalTokens": 3120,
          "environment": "default",
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-13-51-30-830422_chatcmpl-fd1cd2b2-ca51-421f-9af5-91f81af4db2d",
          "traceId": "69cd1e77",
          "type": "GENERATION",
          "name": "69cd_tpusg_gen_attempt#4",
          "startTime": "2025-08-04T10:51:30.830000+00:00",
          "endTime": "2025-08-04T10:52:01.849000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 31019.0,
          "costDetails": {},
          "completionTokens": 1064,
          "promptTokens": 2048,
          "totalTokens": 3112,
          "environment": "default",
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-13-52-10-112883_chatcmpl-a4bd5f18-e3c1-4ec1-af7b-35d9304fa23f",
          "traceId": "69cd1e77",
          "type": "GENERATION",
          "name": "69cd_tpusg_gen_attempt#5",
          "startTime": "2025-08-04T10:52:10.112000+00:00",
          "endTime": "2025-08-04T10:52:41.921000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 31809.0,
          "costDetails": {},
          "completionTokens": 1094,
          "promptTokens": 2048,
          "totalTokens": 3142,
          "environment": "default",
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "c648bf39-8489-4d2d-8b48-3bb824bd8c89",
          "traceId": "69cd1e77",
          "type": "SPAN",
          "name": "error_69_tpusg_failure_signal_tpu_sketch_generator",
          "startTime": "2025-08-04T10:52:41.929000+00:00",
          "level": "ERROR",
          "statusMessage": "Failed. Last error: Unexpected error during generation: Generated script is not complete. Please ensure to generate a complete Python script.",
          "calculatedTotalCost": 0.0,
          "costDetails": {},
          "completionTokens": 0,
          "promptTokens": 0,
          "totalTokens": 0,
          "environment": "default",
          "endTime": null,
          "model": null,
          "modelParameters": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null,
          "latency": null
        }
      ],
      "createdAt": "2025-08-04T10:49:36.842Z",
      "updatedAt": "2025-08-04T10:52:47.950Z",
      "environment": "default"
    },
    {
      "id": "fcbbeeb8",
      "timestamp": "2025-08-04T10:44:40.400000+00:00",
      "name": "fcbb_tpu_sketch_generator",
      "input": null,
      "output": {
        "status": "success",
        "sketch": "import numpy as np\nfrom tflite_runtime.interpreter import Interpreter, load_delegate\nimport cv2\n\n# Phase 1: Setup\nmodel_path  = \"/home/mendel/tinyml_autopilot/models/edgetpu_detect.tflite\"\nlabel_path  = \"/home/mendel/tinyml_autopilot/models/labelmap.txt\"\ninput_path  = \"/home/mendel/tinyml_autopilot/data//sheeps.mp4\"\noutput_path  = \"/home/mendel/tinyml_autopilot/results/sheeps_detections.mp4\"\nconfidence_threshold  = 0.5\n\n# Load labels\nwith open(label_path, 'r') as f:\n    labels = [line.strip() for line in f.readlines()]\n\n# Load Interpreter with EdgeTPU\ntry:\n    interpreter = Interpreter(model_path=model_path,\n                              experimental_delegates=[load_delegate('libedgetpu.so.1.0')])\nexcept Exception as e:\n    try:\n        interpreter = Interpreter(model_path=model_path,\n                                  experimental_delegates=[load_delegate('/usr/lib/aarch64-linux-gnu/libedgetpu.so.1.0')])\n    except Exception as e:\n        raise RuntimeError(\"Failed to load EdgeTPU delegate\") from e\n\ninterpreter.allocate_tensors()\n\n# Get Model Details\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\n\nprint(\"Input details:\", input_details)\nprint(\"Output details:\", output_details)\n\nfloating_model = (input_details[0]['dtype'] == np.float32)\n\n# Phase 2: Input Acquisition & Preprocessing Loop\ncap = cv2.VideoCapture(input_path)\nif not cap.isOpened():\n    raise RuntimeError(\"Failed to open video file\")\n\nframe_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\nframe_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\nfps = cap.get(cv2.CAP_PROP_FPS)\n\nout = cv2.VideoWriter(output_path, cv2.VideoWriter_fourcc(*'mp4v'), fps, (frame_width, frame_height))\n\nwhile cap.isOpened():\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    # Preprocess Data\n    input_data = cv2.resize(frame, (input_details[0]['shape'][1], input_details[0]['shape'][2]))\n    input_data = np.expand_dims(input_data, axis=0)\n\n    if floating_model:\n        input_data = (np.float32(input_data) - 127.5) / 127.5\n\n    # Phase 3: Inference\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n    interpreter.invoke()\n\n    # Phase 4: Output Interpretation & Handling Loop\n    output_data = interpreter.get_tensor(output_details[0]['index'])\n    \n    # Correctly access num_detections as a scalar\n    if len(output_details) > 1:\n        num_detections = int(interpreter.get_tensor(output_details[3]['index'])[0])\n        detection_boxes = interpreter.get_tensor(output_details[0]['index'])[0]\n        detection_classes = interpreter.get_tensor(output_details[1]['index'])[0].astype(int)\n        detection_scores = interpreter.get_tensor(output_details[2]['index'])[0]\n\n        for i in range(num_detections):\n            if detection_scores[i] > confidence_threshold:\n                box = detection_boxes[i]\n                class_id = detection_classes[i]\n                score = detection_scores[i]\n\n                # Scale and clip bounding boxes\n                ymin, xmin, ymax, xmax = box\n                (left, right, top, bottom) = (xmin * frame_width, xmax * frame_width,\n                                              ymin * frame_height, ymax * frame_height)\n\n                cv2.rectangle(frame, (int(left), int(top)), (int(right), int(bottom)), (0, 255, 0), 2)\n                label = f'{labels[class_id]}: {score:.2f}'\n                cv2.putText(frame, label, (int(left), int(top) - 10),\n                            cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n\n    # Handle Output\n    out.write(frame)\n\n# Phase 5: Cleanup\ncap.release()\nout.release()\ncv2.destroyAllWindows()"
      },
      "session_id": "qwen2.5-coder:32b_ee11_tpusg_batch",
      "metadata": {
        "num_run": 1
      },
      "tags": [
        "benchmark",
        "qwen2.5-coder:32b",
        "tpu_sketch_generator"
      ],
      "latency": 237.539,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-13-44-40-402680_chatcmpl-22fecbc8-b398-47bf-8cfb-c2f0966025b1",
          "traceId": "fcbbeeb8",
          "type": "GENERATION",
          "name": "fcbb_tpusg_gen_attempt#1",
          "startTime": "2025-08-04T10:44:40.402000+00:00",
          "endTime": "2025-08-04T10:45:57.148000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 76746.0,
          "costDetails": {},
          "completionTokens": 842,
          "promptTokens": 1833,
          "totalTokens": 2675,
          "environment": "default",
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-13-46-05-617128_chatcmpl-faa139f6-7b71-4081-b497-99e99eb55ceb",
          "traceId": "fcbbeeb8",
          "type": "GENERATION",
          "name": "fcbb_tpusg_gen_attempt#2",
          "startTime": "2025-08-04T10:46:05.617000+00:00",
          "endTime": "2025-08-04T10:46:37.192000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 31575.0,
          "costDetails": {},
          "completionTokens": 1084,
          "promptTokens": 2048,
          "totalTokens": 3132,
          "environment": "default",
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-13-46-45-669219_chatcmpl-7370cabc-8107-4aed-9d56-ee58ef0cdfb4",
          "traceId": "fcbbeeb8",
          "type": "GENERATION",
          "name": "fcbb_tpusg_gen_attempt#3",
          "startTime": "2025-08-04T10:46:45.669000+00:00",
          "endTime": "2025-08-04T10:47:16.323000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 30654.0,
          "costDetails": {},
          "completionTokens": 1049,
          "promptTokens": 2048,
          "totalTokens": 3097,
          "environment": "default",
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-13-47-24-559134_chatcmpl-5928c34b-1edf-40de-8ae5-d3dccf50e2b3",
          "traceId": "fcbbeeb8",
          "type": "GENERATION",
          "name": "fcbb_tpusg_gen_attempt#4",
          "startTime": "2025-08-04T10:47:24.559000+00:00",
          "endTime": "2025-08-04T10:47:57.979000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 33420.0,
          "costDetails": {},
          "completionTokens": 1155,
          "promptTokens": 2048,
          "totalTokens": 3203,
          "environment": "default",
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-13-48-06-370169_chatcmpl-3d529493-af5e-4ae5-9bcf-21a0ee75e959",
          "traceId": "fcbbeeb8",
          "type": "GENERATION",
          "name": "fcbb_tpusg_gen_attempt#5",
          "startTime": "2025-08-04T10:48:06.370000+00:00",
          "endTime": "2025-08-04T10:48:37.941000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 31571.0,
          "costDetails": {},
          "completionTokens": 1085,
          "promptTokens": 2048,
          "totalTokens": 3133,
          "environment": "default",
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        }
      ],
      "createdAt": "2025-08-04T10:44:41.086Z",
      "updatedAt": "2025-08-04T10:49:35.413Z",
      "environment": "default"
    }
  ],
  "meta": {
    "total_items": 30
  }
}
{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setting up\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ref: https://langfuse.com/docs/query-traces\n",
    "import os\n",
    "import json\n",
    "from langfuse import Langfuse\n",
    "import json\n",
    "import os\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "LOCAL_HOST = True\n",
    "\n",
    "\"\"\"Define session_id\"\"\"\n",
    "# session_id=\"qwen2.5-coder_f4d4_dp_batch\"\n",
    "session_id_list = [\n",
    "    # \"qwen2.5-coder:32b_4e11_tpsg_batch\",\n",
    "    # \"qwen2.5-coder:32b_ae24_tpsg_batch\"\n",
    "    \"qwen2.5-coder:14b_3193_psg_batch\",\n",
    "    \"qwen2.5-coder:14b_3193_tpusg_batch\"\n",
    "]\n",
    "\n",
    "\n",
    "\"\"\"Define paths\"\"\"\n",
    " \n",
    "parent_dir = os.path.dirname(os.getcwd())\n",
    "\n",
    " \n",
    "# date = os.path.basename(parent_dir)\n",
    "tex_dir = os.path.join(parent_dir, \"tex\")\n",
    "processed_data_dir = os.path.join(parent_dir, \"processed_data\")\n",
    "raw_export_dir = os.path.join(parent_dir, \"raw_export\")\n",
    "ipynb_dir = os.path.join(parent_dir, \"ipynb\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Export raw data\n",
    "\n",
    "Langfuse added a limit of 20 API invocations per minute. https://langfuse.com/faq/all/api-limits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching traces for session qwen2.5-coder:14b_3193_psg_batch...\n",
      "Fetching observation data for time-03-13-03-168932_chatcmpl-d562e76c-9c8d-4d55-bfe4-3596ae6117bf...\n",
      "Fetching observation data for time-03-13-14-233607_chatcmpl-e1a700d6-2445-43ef-a688-eff9af18fa1c...\n",
      "Fetching observation data for time-03-13-23-134551_chatcmpl-1e656cb1-cd97-4eac-9f22-d71f69783d65...\n",
      "Fetching observation data for time-03-13-31-483434_chatcmpl-fd37f2f6-b7cd-4163-ab37-dabec25c9acf...\n",
      "Fetching observation data for time-03-13-39-369336_chatcmpl-1a0c4c1f-567b-4ed3-8f47-4950f2af0ea1...\n",
      "Fetching observation data for a78f607d-39d9-44e2-8208-9e0e959de99e...\n",
      "Fetching observation data for time-03-12-13-657311_chatcmpl-5f2ee267-5e0b-4df6-8251-9bab4fcc1fb6...\n",
      "Fetching observation data for time-03-12-24-747942_chatcmpl-deb4ea69-3909-4e2c-9ad6-3cc26eaa601a...\n",
      "Fetching observation data for time-03-12-32-259655_chatcmpl-801e0ae3-ae95-45e8-8f41-3b0193054456...\n",
      "Fetching observation data for time-03-12-40-412646_chatcmpl-4354b64e-7102-461f-bc47-106390d7e1a0...\n",
      "Fetching observation data for time-03-12-48-973240_chatcmpl-3abc5abe-09d3-454e-9a6a-7fdeb7b4d5f3...\n",
      "Fetching observation data for 1d2a3713-9bd4-4229-a0e3-fea43950f83e...\n",
      "Fetching observation data for time-03-11-48-112439_chatcmpl-69dbb6e6-7d5c-482f-a14f-4f024d10393b...\n",
      "Fetching observation data for time-03-11-59-384282_chatcmpl-aba0d28f-72d3-40d3-96aa-fa2431bcd76e...\n",
      "Fetching observation data for time-03-11-03-585526_chatcmpl-24ea4a84-7575-4237-b994-0615a90d6bda...\n",
      "Fetching observation data for time-03-11-14-645981_chatcmpl-8d54126d-7f07-4674-b451-0b56b04e1b81...\n",
      "Fetching observation data for time-03-11-21-138315_chatcmpl-f02a4737-2d9a-4c1c-ba06-82884b2aa35e...\n",
      "Fetching observation data for time-03-11-27-571074_chatcmpl-b5c91d4a-ae5b-4522-8655-1675d2502a63...\n",
      "Fetching observation data for time-03-11-34-518997_chatcmpl-405ae555-d2c5-4296-9eac-cf829dd1b839...\n",
      "Fetching observation data for 1acf3735-303f-4751-94ec-3c2d7c282c18...\n",
      "Fetching observation data for time-03-10-15-014754_chatcmpl-f80b6e04-fb75-4815-882e-ad3eef6aa2bf...\n",
      "Fetching observation data for time-03-10-26-282549_chatcmpl-46534955-f350-482a-b394-d9817a26da88...\n",
      "Fetching observation data for time-03-10-33-486687_chatcmpl-a9162a13-2453-476f-bdcc-d9cd71398886...\n",
      "Fetching observation data for time-03-10-40-864101_chatcmpl-e7e33727-0a94-4f84-b4c1-7152e03afb3a...\n",
      "Fetching observation data for time-03-10-49-784629_chatcmpl-852fcfc6-e6f4-4d1b-9a15-cb8f5c331f82...\n",
      "Fetching observation data for 8ce28cb1-f2a2-4c44-aa5d-478b37d08b70...\n",
      "Fetching observation data for time-03-09-28-498199_chatcmpl-779cd1b7-7e31-49ed-bf44-5a1fe3bc9bf7...\n",
      "Fetching observation data for time-03-09-39-767504_chatcmpl-837375d4-5200-42cf-af40-f16704766e0d...\n",
      "Fetching observation data for time-03-09-46-367690_chatcmpl-91e8acbc-b1aa-4a27-ae70-19a72ecc95f0...\n",
      "Fetching observation data for time-03-09-53-298600_chatcmpl-870e9673-2014-4110-bf3c-0ab4cc3514ac...\n",
      "Fetching observation data for time-03-10-00-361557_chatcmpl-9f2ddfb6-b37c-446c-bd26-f71a6d0d72e1...\n",
      "Fetching observation data for d8cbd55c-ce48-4c50-8799-45e7e803cfa6...\n",
      "Fetching observation data for time-03-08-39-964410_chatcmpl-072b2d1a-6568-45ff-b06e-25d9db7fe0e4...\n",
      "Fetching observation data for time-03-08-51-259995_chatcmpl-83d55f52-a48c-41c6-831b-5718ddd803ea...\n",
      "Fetching observation data for time-03-08-57-871798_chatcmpl-b1be4b06-5370-41c1-8af8-b1d4b72962f4...\n",
      "Fetching observation data for time-03-09-05-030338_chatcmpl-2aea2880-2276-4efa-9d1d-0e3460d7ea9b...\n",
      "Fetching observation data for time-03-09-14-147914_chatcmpl-76ddd9e6-13ad-4958-b978-4a1a4fd7e933...\n",
      "Fetching observation data for b8a2ecfb-ffd4-41dd-ba63-a8e7321e968f...\n",
      "Fetching observation data for time-03-07-47-172109_chatcmpl-a788b4c6-501a-49bf-9232-c1e85a41a3a8...\n",
      "Fetching observation data for time-03-07-58-251062_chatcmpl-1d69a8b6-4d4b-4672-921e-68b111ee53df...\n",
      "Fetching observation data for time-03-08-05-748839_chatcmpl-fdc44d58-7044-4038-8100-5eb9df392cb5...\n",
      "Fetching observation data for time-03-08-14-318219_chatcmpl-890160f2-9678-4e0d-8aec-e51e052c4862...\n",
      "Fetching observation data for time-03-08-24-714275_chatcmpl-883309ec-f9c2-463b-b87e-8f53532afb35...\n",
      "Fetching observation data for 06a4c0fb-93cd-4800-9bfa-0b0fc665d9e5...\n",
      "Fetching observation data for time-03-06-55-544908_chatcmpl-078438a8-4642-4d24-beee-327425ace133...\n",
      "Fetching observation data for time-03-07-06-810163_chatcmpl-aabaa339-c357-45c1-8596-8e88db22df3a...\n",
      "Fetching observation data for time-03-07-13-683200_chatcmpl-7ab4b544-f7d7-4ba0-b573-ce37870634b6...\n",
      "Fetching observation data for time-03-07-21-431076_chatcmpl-b8cff8e6-83ed-4b2f-8e2c-ec607b04025b...\n",
      "Fetching observation data for time-03-07-30-165103_chatcmpl-78c556e6-eacb-4898-bc92-d9264a946592...\n",
      "Fetching observation data for f5a89c91-abde-4e6d-b68b-508ff025a817...\n",
      "Fetching observation data for time-03-06-06-971467_chatcmpl-739831b9-557b-4f29-8f6b-b29d9403ad2e...\n",
      "Fetching observation data for time-03-06-18-256508_chatcmpl-2d1a62e3-8a8f-4f94-9149-9c829259d0a5...\n",
      "Fetching observation data for time-03-06-24-852268_chatcmpl-c5438c8d-9554-4ca6-ba25-21501be6640d...\n",
      "Fetching observation data for time-03-06-31-992091_chatcmpl-1017f166-9cbb-4946-bc16-14b97c8fe256...\n",
      "Fetching observation data for time-03-06-41-113943_chatcmpl-ebc4c560-3f18-4c2e-ba10-04e664f47ebb...\n",
      "Fetching observation data for 7ab5e71a-073b-4217-ba95-1c85e14e571a...\n",
      "Fetching observation data for time-03-05-18-361922_chatcmpl-350faebe-d1a4-4a9f-a63a-956ea2aeeb1b...\n",
      "Fetching observation data for time-03-05-29-632964_chatcmpl-cc8af62a-b14a-47bc-89b4-55c979122e4c...\n",
      "Fetching observation data for time-03-05-36-224566_chatcmpl-d94ac8e8-b3e5-477d-a309-6ca5d9bf2a1a...\n",
      "Fetching observation data for time-03-05-43-241808_chatcmpl-17225373-cd94-41e0-9515-d367ab18e03f...\n",
      "Fetching observation data for time-03-05-52-130639_chatcmpl-c4d3e2b9-1a83-4177-844e-5b382f0b0740...\n",
      "Fetching observation data for 2eccab09-c68c-48cb-9e10-044fbb56a138...\n",
      "Fetching observation data for time-03-04-32-829200_chatcmpl-50548d9b-c50c-495d-9b4d-def4ae2311e1...\n",
      "Fetching observation data for time-03-04-44-104024_chatcmpl-f79b6554-40de-405c-bc01-e4307e7cfa51...\n",
      "Fetching observation data for time-03-04-50-705595_chatcmpl-ad200158-a3d8-41ad-b0d6-e8227b5ba077...\n",
      "Fetching observation data for time-03-04-57-658932_chatcmpl-2813f618-166f-4261-a084-f5df534e8528...\n",
      "Fetching observation data for time-03-05-04-691902_chatcmpl-104e5bba-1f5e-4484-9106-0d36d8448e36...\n",
      "Fetching observation data for 167dcbb6-a559-48f4-bee9-98b6c3e1c32f...\n",
      "Fetching observation data for time-03-03-44-293332_chatcmpl-c6c0fd54-bb3e-41a1-988f-c1e3da383eb8...\n",
      "Fetching observation data for time-03-03-55-735699_chatcmpl-37efbf5b-46be-404d-84fd-362541b9770b...\n",
      "Fetching observation data for time-03-04-02-340055_chatcmpl-3f377ac1-e993-4cdf-8918-59d1f3efa6e4...\n",
      "Fetching observation data for time-03-04-09-325256_chatcmpl-eb954536-0951-4a40-972b-58ec12285622...\n",
      "Fetching observation data for time-03-04-18-395532_chatcmpl-cfdf3633-c121-46c1-aad8-7ade49e2563a...\n",
      "Fetching observation data for 2f7783fe-7416-48f1-b5b3-8ab999719355...\n",
      "Fetching observation data for time-03-02-59-738213_chatcmpl-782bc1dd-b69f-424c-8549-10b1000911d4...\n",
      "Fetching observation data for time-03-03-10-804047_chatcmpl-9fdbf988-d0b6-4e07-b9be-4480c1ecc3a5...\n",
      "Fetching observation data for time-03-03-17-316961_chatcmpl-5fe726aa-1541-4fdb-9aa5-646fcb7c07d1...\n",
      "Fetching observation data for time-03-03-23-752364_chatcmpl-c366dbb7-f22c-42c0-8362-7ca0cd83108c...\n",
      "Fetching observation data for time-03-03-30-698088_chatcmpl-bcef689a-ff64-4227-b236-1e765277c757...\n",
      "Fetching observation data for 8792e608-c2dc-4ce1-a514-c82e43826b62...\n",
      "Fetching observation data for time-03-02-10-199073_chatcmpl-e89a622a-f7e1-44d2-8ad0-50dd2a71e9d0...\n",
      "Fetching observation data for time-03-02-21-259214_chatcmpl-a91aeae0-5309-45e8-ab28-54b491473d71...\n",
      "Fetching observation data for time-03-02-28-760770_chatcmpl-5db33f96-4413-43ed-891a-976c44808ccb...\n",
      "Fetching observation data for time-03-02-37-300265_chatcmpl-01b3b1af-2cc1-41ea-93ee-e40454999a98...\n",
      "Fetching observation data for time-03-02-46-102190_chatcmpl-a149f439-3df2-45f8-977c-fc32740db104...\n",
      "Fetching observation data for 80e8e839-eb8b-4d36-95eb-d10319debecb...\n",
      "Fetching observation data for time-03-01-17-590787_chatcmpl-e6157422-d35c-4cdf-8b7d-1000d83ab828...\n",
      "Fetching observation data for time-03-01-28-663043_chatcmpl-c3c4759f-70bc-4488-a813-a5ca5ea832d2...\n",
      "Fetching observation data for time-03-01-37-593286_chatcmpl-72f20710-3268-4ac8-bfe2-382507977ef5...\n",
      "Fetching observation data for time-03-01-46-642437_chatcmpl-6f98c4fc-df7d-4663-afb2-288917f273fe...\n",
      "Fetching observation data for time-03-01-52-458142_chatcmpl-0c286a58-b2ea-4a43-9c31-078906f021d9...\n",
      "Fetching observation data for 1a00ddea-8b09-4fc6-9980-faf708076902...\n",
      "Fetching observation data for time-03-00-28-414065_chatcmpl-38da44ea-4a0e-4ec6-b1b7-85b49c0fd6b9...\n",
      "Fetching observation data for time-03-00-39-491572_chatcmpl-cccfdbb2-7411-41fe-b45d-302fa25c0b09...\n",
      "Fetching observation data for time-03-00-47-036399_chatcmpl-8d9e9f0a-027a-4b5f-9360-52ace41ec8fb...\n",
      "Fetching observation data for time-03-00-55-763301_chatcmpl-969b2125-0f3a-420c-b77d-1cdb6106b4b4...\n",
      "Fetching observation data for time-03-01-03-396196_chatcmpl-1b3359dc-602a-4c9c-a642-03d08906b82f...\n",
      "Fetching observation data for c1181009-ed86-47d3-a169-2a112e984d07...\n",
      "Fetching observation data for time-02-59-33-838997_chatcmpl-1467e4fa-eef2-466d-b099-5c6ec58eb711...\n",
      "Fetching observation data for time-02-59-45-127084_chatcmpl-d43d7366-b3f2-456a-9090-80d40ba03ae2...\n",
      "Fetching observation data for time-02-59-52-374087_chatcmpl-0acb4f87-faf6-415c-ba82-9e1d67b86b51...\n",
      "Fetching observation data for time-03-00-03-232092_chatcmpl-3d49849a-8281-46cf-a06e-e33942552432...\n",
      "Fetching observation data for time-03-00-13-689326_chatcmpl-67256d3e-d6a8-42ed-a554-6f696946edb6...\n",
      "Fetching observation data for 0ddc32a9-bcc7-4531-b3ba-1b633e691fc4...\n",
      "Fetching observation data for time-02-58-42-261856_chatcmpl-778a2f57-094f-4c47-af5a-0a9fbf144ac9...\n",
      "Fetching observation data for time-02-58-53-539553_chatcmpl-cba22fcc-f320-4969-b0a0-fcde38a3a6ec...\n",
      "Fetching observation data for time-02-59-01-043090_chatcmpl-9eab4d74-4bba-49fc-88ba-0d9d2f33ff3b...\n",
      "Fetching observation data for time-02-59-09-581174_chatcmpl-233075a3-00cb-4de2-9883-217a9b5bc01b...\n",
      "Fetching observation data for time-02-59-19-957089_chatcmpl-1f9c673e-e868-473d-be8e-b35d3d2eab64...\n",
      "Fetching observation data for 6f415a74-3ed8-4cd9-a91f-a32a2ab30265...\n",
      "Fetching observation data for time-02-57-52-721556_chatcmpl-95420120-ea82-419e-8d6a-fc5cfe11cb31...\n",
      "Fetching observation data for time-02-58-03-774194_chatcmpl-4c2ef4b4-e45b-4717-86f4-5566626f8382...\n",
      "Fetching observation data for time-02-58-11-279095_chatcmpl-42103946-88fd-4d8b-b724-99c7d27ddecd...\n",
      "Fetching observation data for time-02-58-19-979055_chatcmpl-07560300-e9a2-4821-9f63-86e9dea2ccd8...\n",
      "Fetching observation data for time-02-58-28-526085_chatcmpl-f1816751-3e20-49f9-90fd-84d83936a108...\n",
      "Fetching observation data for 2d155d80-2732-4f3e-b300-9b42bbee2386...\n",
      "Fetching observation data for time-02-57-03-139215_chatcmpl-2e970035-5248-411a-851e-b6a6c3145d37...\n",
      "Fetching observation data for time-02-57-14-411409_chatcmpl-fd51da4d-eb0f-4739-b9df-8fdf3211ac82...\n",
      "Fetching observation data for time-02-57-22-168857_chatcmpl-2f084132-4db2-4540-99d9-6cb2045a455a...\n",
      "Fetching observation data for time-02-57-29-870063_chatcmpl-a8cef660-7619-4776-9048-be4c4be51710...\n",
      "Fetching observation data for time-02-57-37-468498_chatcmpl-45b50402-da06-42cc-bd6d-db25c8af67e5...\n",
      "Fetching observation data for 73d08951-9cce-40b0-8ada-2313e20c0452...\n",
      "Fetching observation data for time-02-56-11-598799_chatcmpl-ec2a26ca-1bbb-40b5-98f2-e866bca44fc9...\n",
      "Fetching observation data for time-02-56-22-653556_chatcmpl-bb9d5e1f-568c-41a3-8e3d-620483a7b3a8...\n",
      "Fetching observation data for time-02-56-30-159707_chatcmpl-3c769403-bffd-4ff8-9c0f-fbef0fdfea5e...\n",
      "Fetching observation data for time-02-56-38-685087_chatcmpl-9cf5ea1f-f53c-48f1-9b40-e7eb2af48606...\n",
      "Fetching observation data for time-02-56-49-011320_chatcmpl-6d578058-e592-4581-a55a-74953f0910c0...\n",
      "Fetching observation data for 0762e1a2-349d-48ab-bcfa-fffe84b22661...\n",
      "Fetching observation data for time-02-55-20-006895_chatcmpl-66d37333-960f-4b37-9000-f771eeabe378...\n",
      "Fetching observation data for time-02-55-31-084063_chatcmpl-c55425fd-8c50-49c9-9273-e4a4f338f8bb...\n",
      "Fetching observation data for time-02-55-38-588694_chatcmpl-0c0aa6d0-4472-4c76-b0ce-852bce0b982d...\n",
      "Fetching observation data for time-02-55-47-116319_chatcmpl-52494e6a-6ee4-4b10-8692-b931275adda2...\n",
      "Fetching observation data for time-02-55-56-200755_chatcmpl-2c80b094-b62e-4571-8e89-e0a91a320891...\n",
      "Fetching observation data for e6c03dc6-1909-40fb-81c0-9cb994cda158...\n",
      "Fetching observation data for time-02-54-30-457133_chatcmpl-0d9b1135-41cb-4ada-9422-b869ad58559c...\n",
      "Fetching observation data for time-02-54-41-510891_chatcmpl-ae07459a-986d-4c90-8b22-35bc8e9c416a...\n",
      "Fetching observation data for time-02-54-49-013045_chatcmpl-29a4f4ad-1dbd-400b-bb37-6be4b481d68d...\n",
      "Fetching observation data for time-02-54-57-562203_chatcmpl-855317cf-2bf3-43d6-9c4b-4ac71a450144...\n",
      "Fetching observation data for time-02-55-06-385096_chatcmpl-1319afe9-1df3-4ca2-ab4d-44a01098b12f...\n",
      "Fetching observation data for 1884a829-da0c-46df-a087-9a369d713c81...\n",
      "Fetching observation data for time-02-53-39-542768_chatcmpl-b2add89d-4344-4cac-b57c-e0c303e1eecc...\n",
      "Fetching observation data for time-02-53-51-002684_chatcmpl-8be194c3-e5e3-4430-a9a4-e956601f1148...\n",
      "Fetching observation data for time-02-53-57-890727_chatcmpl-eb69f8da-f6ed-485c-b151-39714dc36acc...\n",
      "Fetching observation data for time-02-54-05-655118_chatcmpl-49125c22-bfb3-420d-9adf-a62b04aaecda...\n",
      "Fetching observation data for time-02-54-15-593991_chatcmpl-4f16d027-7ff7-4a12-803b-efd1eeaedc99...\n",
      "Fetching observation data for dd4e2eaf-abe8-4a15-b787-bc0a8ee8dc3e...\n",
      "Fetching observation data for time-02-52-48-911361_chatcmpl-5f9b34e5-fe03-4e43-832c-f59d82ff17ff...\n",
      "Fetching observation data for time-02-52-59-973909_chatcmpl-76caa6b8-b341-40c6-b506-3aef1d2d4f31...\n",
      "Fetching observation data for time-02-53-07-481613_chatcmpl-90db6df2-50a1-4a00-bf3a-ea76bf82db19...\n",
      "Fetching observation data for time-02-53-16-191660_chatcmpl-cdf05740-12ae-496f-84d6-500a99928889...\n",
      "Fetching observation data for time-02-53-24-740811_chatcmpl-62b685f2-6ef3-4a7c-bc2b-a37c37b08bc0...\n",
      "Fetching observation data for bac837bd-003a-4f1b-a8b9-e8f8bb85b3e1...\n",
      "Fetching observation data for time-02-52-03-365736_chatcmpl-9b2d8940-5158-453f-9b43-0ed5c0e05cea...\n",
      "Fetching observation data for time-02-52-14-661432_chatcmpl-aaef102f-ffe1-4e8b-a85f-86f399062772...\n",
      "Fetching observation data for time-02-52-21-250808_chatcmpl-e2ea7296-c04e-4c4d-a9c0-be3c0f06296c...\n",
      "Fetching observation data for time-02-52-28-195070_chatcmpl-f140b66a-1f10-4a4f-bf24-5f17e20e76bd...\n",
      "Fetching observation data for time-02-52-35-237304_chatcmpl-c5aea9f0-6a67-4b00-98df-087fc506ff56...\n",
      "Fetching observation data for 0c2aa54a-0cc6-46fa-9651-73c6b891666d...\n",
      "Fetching observation data for time-02-51-17-489583_chatcmpl-a03d7a24-0d45-4651-92dc-21af8a8482f1...\n",
      "Fetching observation data for time-02-51-28-773448_chatcmpl-cb9ce0db-4b25-4e7c-8bef-7acabc6c6428...\n",
      "Fetching observation data for time-02-51-35-392110_chatcmpl-9bacedb4-d1ed-40ed-bafc-76e5e9941268...\n",
      "Fetching observation data for time-02-51-42-527848_chatcmpl-85e5f059-5bc6-4ce2-98ee-d9212527999f...\n",
      "Fetching observation data for time-02-51-49-377258_chatcmpl-09616b2a-edde-4af9-a200-0933ed22ebbd...\n",
      "Fetching observation data for fe4de47f-88bc-43d9-ba8e-7ddad341d16c...\n",
      "Fetching observation data for time-02-50-38-910021_chatcmpl-e644235b-6352-4461-908b-fe14b5083d99...\n",
      "Fetching observation data for time-02-50-49-969137_chatcmpl-edff53b3-e508-4942-bbad-2a0966ef0242...\n",
      "Fetching observation data for time-02-50-56-477741_chatcmpl-a99ace75-3718-445d-af44-e98952d1b700...\n",
      "Fetching observation data for time-02-51-02-873283_chatcmpl-2c8cf26a-fdd7-4066-8946-955559ced239...\n",
      "Fetching observation data for time-02-49-50-912277_chatcmpl-23dfa901-687e-476c-a0df-15acdddedb29...\n",
      "Fetching observation data for time-02-50-02-073676_chatcmpl-0a8eea56-6a39-426b-a2c8-dbd8d26fa3e6...\n",
      "Fetching observation data for time-02-50-10-977148_chatcmpl-876aaa5b-30f5-45b3-87dc-9332d2f2204f...\n",
      "Fetching observation data for time-02-50-18-075247_chatcmpl-70386bd2-3b86-43d6-987a-ff0ca6a58c6b...\n",
      "Fetching observation data for time-02-50-24-957935_chatcmpl-284a3a97-1fc6-4c5e-8b24-456ba0533f59...\n",
      "Fetching observation data for df87104d-d65d-459d-a622-48bf7bbc3173...\n",
      "Raw JSON saved to: /Users/hann/Projects/reference-benchmark-tinyml_llm/data_analysis/2025/08.04/raw_export/raw_qwen2.5-coder:14b_3193_psg_batch.json\n",
      "Fetching traces for session qwen2.5-coder:14b_3193_tpusg_batch...\n",
      "Fetching observation data for time-02-48-42-267001_chatcmpl-1b21b172-afaa-4413-9d82-6167e9023f75...\n",
      "Fetching observation data for time-02-47-33-448363_chatcmpl-487f39f6-590d-4afe-adfd-fc8c62ad5342...\n",
      "Fetching observation data for time-02-46-24-863710_chatcmpl-6b0b5d47-0c16-47c0-880e-0f766fd5f4a6...\n",
      "Fetching observation data for time-02-45-16-302644_chatcmpl-45c80f15-74e5-4fcb-9c39-d2513242dc11...\n",
      "Fetching observation data for time-02-44-07-626611_chatcmpl-13713e91-ebe4-408d-97ac-fc3a2f4e3bda...\n",
      "Fetching observation data for time-02-42-58-861854_chatcmpl-13329f30-fe07-463b-9f4a-74ecf23342ee...\n",
      "Fetching observation data for time-02-41-49-975534_chatcmpl-8016b344-1162-45fe-94c9-5df4e53d6785...\n",
      "Fetching observation data for time-02-40-41-250321_chatcmpl-2593631c-4eb8-4401-8877-dd30c12b948c...\n",
      "Fetching observation data for time-02-39-32-663434_chatcmpl-45ca28b2-203f-4078-96df-5fba34809967...\n",
      "Fetching observation data for time-02-38-23-743252_chatcmpl-ae769d8c-ddd6-4057-b853-774aab17f83e...\n",
      "Fetching observation data for time-02-37-14-618201_chatcmpl-24a0f770-3e47-4546-bbde-8d601852f096...\n",
      "Fetching observation data for time-02-36-05-712265_chatcmpl-e80d1e8e-0086-4026-a65a-27c843cc4a8e...\n",
      "Fetching observation data for time-02-34-57-047847_chatcmpl-40ff81d1-025a-4bcc-b409-3d02cd227609...\n",
      "Fetching observation data for time-02-33-48-166551_chatcmpl-27fbba7a-7822-413c-95bd-ff178f545ff5...\n",
      "Fetching observation data for time-02-32-39-588782_chatcmpl-93544e28-f341-4f38-b197-85c149ef92f2...\n",
      "Fetching observation data for time-02-31-31-066784_chatcmpl-a26ea865-66a3-45bc-8d6c-75b9f1354543...\n",
      "Fetching observation data for time-02-30-22-158611_chatcmpl-f790f6b1-1e76-415e-9ada-611d47557ceb...\n",
      "Fetching observation data for time-02-29-13-630151_chatcmpl-ae30fe9a-7985-4d7c-841c-23c7a6420b44...\n",
      "Fetching observation data for time-02-28-05-125910_chatcmpl-9b4d3cef-c3d3-4c97-b141-9d33805ba713...\n",
      "Fetching observation data for time-02-26-56-576512_chatcmpl-9b3fc4bd-7b1c-4741-a30a-92f13a59d60b...\n",
      "Fetching observation data for time-02-25-47-706778_chatcmpl-7927d7ac-573d-4499-8e71-6a7a74f5fa77...\n",
      "Fetching observation data for time-02-24-38-840715_chatcmpl-0222fd51-41b5-442a-a991-ab60817f72b0...\n",
      "Fetching observation data for time-02-23-29-826866_chatcmpl-d61545fe-546e-4483-ad24-e0a58b2796b1...\n",
      "Fetching observation data for time-02-22-20-599106_chatcmpl-549804a8-d6eb-4218-8098-083c8ebd109d...\n",
      "Fetching observation data for time-02-21-12-018660_chatcmpl-312a4423-837f-4892-9134-34201ebfb1ad...\n",
      "Fetching observation data for time-02-20-03-089205_chatcmpl-ba1ff1c5-9717-4764-8bdb-854e6e8bd6cc...\n",
      "Fetching observation data for time-02-18-54-296813_chatcmpl-57c77c0d-818d-4b05-9724-1d7a4fffaec0...\n",
      "Fetching observation data for time-02-17-45-659906_chatcmpl-cc6ae575-dee3-4d32-a4d2-b37e0c350839...\n",
      "Fetching observation data for time-02-16-36-882942_chatcmpl-cd191103-4e78-439a-97c6-eace2d77f77d...\n",
      "Fetching observation data for time-02-15-13-311694_chatcmpl-8c0545b2-9f48-48b4-9b00-ea082b88e9a5...\n",
      "Raw JSON saved to: /Users/hann/Projects/reference-benchmark-tinyml_llm/data_analysis/2025/08.04/raw_export/raw_qwen2.5-coder:14b_3193_tpusg_batch.json\n"
     ]
    }
   ],
   "source": [
    "# ALTERNATIVE TO 2.\n",
    "import os\n",
    "import json\n",
    "from time import sleep\n",
    "from langfuse import Langfuse\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "\n",
    "# LANGFUSE_SERVICE_PUBLIC_KEY = \"pk-lf-559a2c0f-ee29-4c32-944c-bf73b5f0ce28\"\n",
    "# LANGFUSE_SERVICE_SECRET_KEY = \"sk-lf-75f8bf7f-a5db-4756-b0dd-d758a2a292c8\"\n",
    "# LANGFUSE_SERVICE_HOST = \"https://langfuse.hann.fi\"\n",
    "\n",
    "\n",
    "if LOCAL_HOST:\n",
    "    langfuse = Langfuse(\n",
    "        secret_key=\"sk-lf-75f8bf7f-a5db-4756-b0dd-d758a2a292c8\",\n",
    "        public_key=\"pk-lf-559a2c0f-ee29-4c32-944c-bf73b5f0ce28\",\n",
    "        host=\"https://langfuse.hann.fi\",\n",
    "    )\n",
    "else:\n",
    "    langfuse = Langfuse(\n",
    "        secret_key=LANGFUSE_SERVICE_SECRET_KEY,\n",
    "        public_key=LANGFUSE_SERVICE_PUBLIC_KEY,\n",
    "        host=LANGFUSE_SERVICE_HOST,\n",
    "    )\n",
    "\n",
    "API_invok_count = 0\n",
    "query_range_num_run = {\"start\": 0, \"end\": 1}\n",
    "\n",
    "\n",
    "class CustomJSONEncoder(json.JSONEncoder):\n",
    "    def __init__(self, *args, LOCAL_HOST=True, **kwargs):\n",
    "        self.LOCAL_HOST = LOCAL_HOST\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "    def default(self, obj):\n",
    "        if isinstance(obj, datetime):\n",
    "            return obj.isoformat()\n",
    "        if hasattr(obj, \"__dict__\"):\n",
    "            data = obj.__dict__.copy()\n",
    "            if \"observations\" in data:\n",
    "                data[\"observations\"] = [\n",
    "                    fetch_observation_data(obs, self.LOCAL_HOST)\n",
    "                    for obs in data[\"observations\"]\n",
    "                ]\n",
    "\n",
    "            return data\n",
    "        return super().default(obj)\n",
    "\n",
    "\n",
    "def fetch_observation_data(observation_id, LOCAL_HOST):\n",
    "    \"\"\"\n",
    "    Fetches observation data from Langfuse and returns its dictionary representation.\n",
    "    \"\"\"\n",
    "    print(f\"Fetching observation data for {observation_id}...\")\n",
    "    global API_invok_count\n",
    "    if API_invok_count >= 0 and not LOCAL_HOST:\n",
    "        print(\"Waiting for 3 seconds to fetch observation data...\")\n",
    "        for _ in tqdm(range(3), desc=\"Progress\", unit=\"s\"):\n",
    "            sleep(1)\n",
    "        API_invok_count = 0\n",
    "\n",
    "    observation_response = langfuse.fetch_observation(observation_id)\n",
    "    API_invok_count += 1\n",
    "\n",
    "    return observation_response.data.dict()\n",
    "\n",
    "\n",
    "def fetch_and_save_complete_data(session_id_list, raw_export_dir, LOCAL_HOST):\n",
    "    \"\"\"\n",
    "    Fetches complete trace data for each session ID and saves it to JSON files.\n",
    "\n",
    "    Parameters:\n",
    "        session_id_list (list): List of session IDs to process.\n",
    "        raw_export_dir (str): Directory path to save raw JSON files.\n",
    "    \"\"\"\n",
    "\n",
    "    def save_complete_data(session_id):\n",
    "        global API_invok_count\n",
    "        if API_invok_count >= 0 and not LOCAL_HOST:\n",
    "            print(\"Waiting for 4 seconds to fetch traces...\")\n",
    "            for _ in tqdm(range(4), desc=\"Progress\", unit=\"s\"):\n",
    "                sleep(1)\n",
    "            API_invok_count = 0\n",
    "\n",
    "        fetch_traces_response = langfuse.fetch_traces(session_id=session_id)\n",
    "        API_invok_count += 1\n",
    "\n",
    "        print(f\"Fetching traces for session {session_id}...\")\n",
    "        # Create directories if they don't exist\n",
    "        os.makedirs(raw_export_dir, exist_ok=True)\n",
    "\n",
    "        # Save complete data to JSON file\n",
    "        # if session_id.startswith(\"da0a\"):\n",
    "        #     session_id = \"phi4_\" + session_id\n",
    "        if \"tpsg\" in session_id:\n",
    "            session_id_ = session_id.replace(\"tpsg\", \"tpusg\")\n",
    "        else:\n",
    "            session_id_ = session_id\n",
    "            \n",
    "        raw_path = os.path.join(raw_export_dir, f\"raw_{session_id_}.json\")\n",
    "        with open(raw_path, \"w\") as f:\n",
    "            json.dump(fetch_traces_response, f, cls=CustomJSONEncoder, indent=2)\n",
    "\n",
    "        print(f\"Raw JSON saved to: {raw_path}\")\n",
    "\n",
    "    for session_id in session_id_list:\n",
    "        save_complete_data(session_id)\n",
    "\n",
    "\n",
    "fetch_and_save_complete_data(session_id_list, raw_export_dir, LOCAL_HOST)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Trim data\n",
    "\n",
    "Here also intercept the runs with fatal errors that need to be excluded from the analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPAN error_f2_psg_failure_signal_py_sketch_generator: Failed. Last error: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "OpenCV: FFMPEG: tag 0x47504a4d/'MJPG' is not supported with codec id 7 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n",
      "OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250805031348_psg_qwen2.5-coder:14b/tmp_20250805031348_psg_qwen2.5-coder:14b.py\", line 53, in <module>\n",
      "    class_id = int(detection[1])\n",
      "TypeError: only length-1 arrays can be converted to Python scalars\n",
      "\n",
      "SPAN error_96_psg_failure_signal_py_sketch_generator: Failed. Last error: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250805031256_psg_qwen2.5-coder:14b/tmp_20250805031256_psg_qwen2.5-coder:14b.py\", line 28, in <module>\n",
      "    img = np.array(Image.open(input_path).resize((input_details[0]['shape'][1], input_details[0]['shape'][2])), dtype=np.float32)\n",
      "NameError: name 'Image' is not defined\n",
      "\n",
      "SPAN error_4f_psg_failure_signal_py_sketch_generator: Failed. Last error: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250805031141_psg_qwen2.5-coder:14b/tmp_20250805031141_psg_qwen2.5-coder:14b.py\", line 32, in <module>\n",
      "    input_data = np.frombuffer(raw_data, dtype=input_dtype).reshape(input_shape)\n",
      "ValueError: cannot reshape array of size 564314 into shape (1,300,300,3)\n",
      "\n",
      "SPAN error_e0_psg_failure_signal_py_sketch_generator: Failed. Last error: Traceback (most recent call last):\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250805031056_psg_qwen2.5-coder:14b/tmp_20250805031056_psg_qwen2.5-coder:14b.py\", line 16, in <module>\n",
      "    interpreter = Interpreter(model_path=model_path)\n",
      "NameError: name 'Interpreter' is not defined\n",
      "\n",
      "SPAN error_e3_psg_failure_signal_py_sketch_generator: Failed. Last error: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250805031008_psg_qwen2.5-coder:14b/tmp_20250805031008_psg_qwen2.5-coder:14b.py\", line 35, in <module>\n",
      "    input_data = input_data.reshape(input_shape)\n",
      "ValueError: cannot reshape array of size 564314 into shape (1,300,300,3)\n",
      "\n",
      "SPAN error_be_psg_failure_signal_py_sketch_generator: Failed. Last error: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250805030921_psg_qwen2.5-coder:14b/tmp_20250805030921_psg_qwen2.5-coder:14b.py\", line 35, in <module>\n",
      "    input_data = np.frombuffer(raw_data, dtype=input_dtype).reshape(input_shape)\n",
      "ValueError: cannot reshape array of size 564314 into shape (1,300,300,3)\n",
      "\n",
      "SPAN error_af_psg_failure_signal_py_sketch_generator: Failed. Last error: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250805030832_psg_qwen2.5-coder:14b/tmp_20250805030832_psg_qwen2.5-coder:14b.py\", line 32, in <module>\n",
      "    img = cv2.resize(img, (input_details[0]['shape'][1], input_details[0]['shape'][2]))\n",
      "cv2.error: OpenCV(4.10.0) /io/opencv/modules/imgproc/src/resize.cpp:4152: error: (-215:Assertion failed) !ssize.empty() in function 'resize'\n",
      "\n",
      "\n",
      "SPAN error_f6_psg_failure_signal_py_sketch_generator: Failed. Last error: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250805030739_psg_qwen2.5-coder:14b/tmp_20250805030739_psg_qwen2.5-coder:14b.py\", line 42, in <module>\n",
      "    if input_dtype == np.float32:\n",
      "NameError: name 'np' is not defined\n",
      "\n",
      "SPAN error_45_psg_failure_signal_py_sketch_generator: Failed. Last error: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250805030648_psg_qwen2.5-coder:14b/tmp_20250805030648_psg_qwen2.5-coder:14b.py\", line 35, in <module>\n",
      "    input_data = np.frombuffer(raw_data, dtype=input_dtype).reshape(input_shape)\n",
      "ValueError: cannot reshape array of size 564314 into shape (1,300,300,3)\n",
      "\n",
      "SPAN error_d1_psg_failure_signal_py_sketch_generator: Failed. Last error: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250805030559_psg_qwen2.5-coder:14b/tmp_20250805030559_psg_qwen2.5-coder:14b.py\", line 35, in <module>\n",
      "    input_data = np.frombuffer(raw_data, dtype=input_dtype).reshape(input_shape)\n",
      "ValueError: cannot reshape array of size 564314 into shape (1,300,300,3)\n",
      "\n",
      "SPAN error_2e_psg_failure_signal_py_sketch_generator: Failed. Last error: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250805030511_psg_qwen2.5-coder:14b/tmp_20250805030511_psg_qwen2.5-coder:14b.py\", line 32, in <module>\n",
      "    input_data = np.frombuffer(raw_data, dtype=input_dtype).reshape(input_shape)\n",
      "ValueError: cannot reshape array of size 564314 into shape (1,300,300,3)\n",
      "\n",
      "SPAN error_ed_psg_failure_signal_py_sketch_generator: Failed. Last error: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250805030425_psg_qwen2.5-coder:14b/tmp_20250805030425_psg_qwen2.5-coder:14b.py\", line 35, in <module>\n",
      "    input_data = np.frombuffer(raw_data, dtype=input_dtype).reshape(input_shape)\n",
      "ValueError: cannot reshape array of size 564314 into shape (1,300,300,3)\n",
      "\n",
      "SPAN error_ab_psg_failure_signal_py_sketch_generator: Failed. Last error: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250805030337_psg_qwen2.5-coder:14b/tmp_20250805030337_psg_qwen2.5-coder:14b.py\", line 32, in <module>\n",
      "    input_data = np.frombuffer(raw_data, dtype=input_dtype).reshape(input_shape)\n",
      "ValueError: cannot reshape array of size 564314 into shape (1,300,300,3)\n",
      "\n",
      "SPAN error_ea_psg_failure_signal_py_sketch_generator: Failed. Last error: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250805030252_psg_qwen2.5-coder:14b/tmp_20250805030252_psg_qwen2.5-coder:14b.py\", line 28, in <module>\n",
      "    image = cv2.resize(image, (input_details[0]['shape'][1], input_details[0]['shape'][2]))\n",
      "cv2.error: OpenCV(4.10.0) /io/opencv/modules/imgproc/src/resize.cpp:4152: error: (-215:Assertion failed) !ssize.empty() in function 'resize'\n",
      "\n",
      "\n",
      "SPAN error_20_psg_failure_signal_py_sketch_generator: Failed. Last error: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250805030202_psg_qwen2.5-coder:14b/tmp_20250805030202_psg_qwen2.5-coder:14b.py\", line 50, in <module>\n",
      "    class_id = int(detection[1])\n",
      "TypeError: only length-1 arrays can be converted to Python scalars\n",
      "\n",
      "SPAN error_7d_psg_failure_signal_py_sketch_generator: Failed. Last error: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250805030110_psg_qwen2.5-coder:14b/tmp_20250805030110_psg_qwen2.5-coder:14b.py\", line 28, in <module>\n",
      "    image = cv2.resize(image, (input_details[0]['shape'][1], input_details[0]['shape'][2]))\n",
      "cv2.error: OpenCV(4.10.0) /io/opencv/modules/imgproc/src/resize.cpp:4152: error: (-215:Assertion failed) !ssize.empty() in function 'resize'\n",
      "\n",
      "\n",
      "SPAN error_45_psg_failure_signal_py_sketch_generator: Failed. Last error: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250805030021_psg_qwen2.5-coder:14b/tmp_20250805030021_psg_qwen2.5-coder:14b.py\", line 37, in <module>\n",
      "    input_data = np.expand_dims(input_data, axis=0)\n",
      "NameError: name 'np' is not defined\n",
      "\n",
      "SPAN error_28_psg_failure_signal_py_sketch_generator: Failed. Last error: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250805025926_psg_qwen2.5-coder:14b/tmp_20250805025926_psg_qwen2.5-coder:14b.py\", line 31, in <module>\n",
      "    input_data = np.reshape(input_data, input_details[0]['shape'])\n",
      "  File \"/home/wuguangh/.conda/envs/tinyml/lib/python3.10/site-packages/numpy/core/fromnumeric.py\", line 285, in reshape\n",
      "    return _wrapfunc(a, 'reshape', newshape, order=order)\n",
      "  File \"/home/wuguangh/.conda/envs/tinyml/lib/python3.10/site-packages/numpy/core/fromnumeric.py\", line 59, in _wrapfunc\n",
      "    return bound(*args, **kwds)\n",
      "ValueError: cannot reshape array of size 564314 into shape (1,300,300,3)\n",
      "\n",
      "SPAN error_96_psg_failure_signal_py_sketch_generator: Failed. Last error: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250805025835_psg_qwen2.5-coder:14b/tmp_20250805025835_psg_qwen2.5-coder:14b.py\", line 28, in <module>\n",
      "    image = cv2.resize(image, (input_details[0]['shape'][1], input_details[0]['shape'][2]))\n",
      "cv2.error: OpenCV(4.10.0) /io/opencv/modules/imgproc/src/resize.cpp:4152: error: (-215:Assertion failed) !ssize.empty() in function 'resize'\n",
      "\n",
      "\n",
      "SPAN error_e0_psg_failure_signal_py_sketch_generator: Failed. Last error: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250805025745_psg_qwen2.5-coder:14b/tmp_20250805025745_psg_qwen2.5-coder:14b.py\", line 36, in <module>\n",
      "    input_data = np.frombuffer(raw_data, dtype=input_dtype).reshape(input_shape)\n",
      "ValueError: cannot reshape array of size 564314 into shape (1,300,300,3)\n",
      "\n",
      "SPAN error_5d_psg_failure_signal_py_sketch_generator: Failed. Last error: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250805025655_psg_qwen2.5-coder:14b/tmp_20250805025655_psg_qwen2.5-coder:14b.py\", line 27, in <module>\n",
      "    raw_data = np.load(input_path)  # Example loading data from a file\n",
      "  File \"/home/wuguangh/.conda/envs/tinyml/lib/python3.10/site-packages/numpy/lib/npyio.py\", line 462, in load\n",
      "    raise ValueError(\"Cannot load file containing pickled data \"\n",
      "ValueError: Cannot load file containing pickled data when allow_pickle=False\n",
      "\n",
      "SPAN error_eb_psg_failure_signal_py_sketch_generator: Failed. Last error: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250805025604_psg_qwen2.5-coder:14b/tmp_20250805025604_psg_qwen2.5-coder:14b.py\", line 33, in <module>\n",
      "    resized_image = cv2.resize(image, (input_shape[1], input_shape[2]))\n",
      "cv2.error: OpenCV(4.10.0) /io/opencv/modules/imgproc/src/resize.cpp:4152: error: (-215:Assertion failed) !ssize.empty() in function 'resize'\n",
      "\n",
      "\n",
      "SPAN error_ee_psg_failure_signal_py_sketch_generator: Failed. Last error: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250805025513_psg_qwen2.5-coder:14b/tmp_20250805025513_psg_qwen2.5-coder:14b.py\", line 27, in <module>\n",
      "    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
      "cv2.error: OpenCV(4.10.0) /io/opencv/modules/imgproc/src/color.cpp:196: error: (-215:Assertion failed) !_src.empty() in function 'cvtColor'\n",
      "\n",
      "\n",
      "SPAN error_9a_psg_failure_signal_py_sketch_generator: Failed. Last error: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250805025423_psg_qwen2.5-coder:14b/tmp_20250805025423_psg_qwen2.5-coder:14b.py\", line 35, in <module>\n",
      "    resized_image = cv2.resize(image, (input_shape[1], input_shape[2]))\n",
      "cv2.error: OpenCV(4.10.0) /io/opencv/modules/imgproc/src/resize.cpp:4152: error: (-215:Assertion failed) !ssize.empty() in function 'resize'\n",
      "\n",
      "\n",
      "SPAN error_21_psg_failure_signal_py_sketch_generator: Failed. Last error: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250805025332_psg_qwen2.5-coder:14b/tmp_20250805025332_psg_qwen2.5-coder:14b.py\", line 46, in <module>\n",
      "    class_id = int(detection[1])\n",
      "TypeError: only length-1 arrays can be converted to Python scalars\n",
      "\n",
      "SPAN error_58_psg_failure_signal_py_sketch_generator: Failed. Last error: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250805025242_psg_qwen2.5-coder:14b/tmp_20250805025242_psg_qwen2.5-coder:14b.py\", line 32, in <module>\n",
      "    input_data = np.frombuffer(raw_data, dtype=input_dtype).reshape(input_shape)\n",
      "ValueError: cannot reshape array of size 564314 into shape (1,300,300,3)\n",
      "\n",
      "SPAN error_77_psg_failure_signal_py_sketch_generator: Failed. Last error: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250805025156_psg_qwen2.5-coder:14b/tmp_20250805025156_psg_qwen2.5-coder:14b.py\", line 32, in <module>\n",
      "    input_data = np.frombuffer(raw_data, dtype=input_dtype).reshape(input_shape)\n",
      "ValueError: cannot reshape array of size 564314 into shape (1,300,300,3)\n",
      "\n",
      "SPAN error_7a_psg_failure_signal_py_sketch_generator: Failed. Last error: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250805025031_psg_qwen2.5-coder:14b/tmp_20250805025031_psg_qwen2.5-coder:14b.py\", line 32, in <module>\n",
      "    input_data = np.frombuffer(raw_data, dtype=input_dtype).reshape(input_shape)\n",
      "ValueError: cannot reshape array of size 564314 into shape (1,300,300,3)\n",
      "\n",
      "Successfully processed and saved trimmed data for session qwen2.5-coder:14b_3193_psg_batch\n",
      "Successfully processed and saved trimmed data for session qwen2.5-coder:14b_3193_tpusg_batch\n",
      "Total 0 traces skipped. They are []\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "skipped_traces = []\n",
    "\n",
    "\n",
    "def process_existing_observation(observation):\n",
    "    \"\"\"\n",
    "    Processes an existing observation dictionary by trimming unwanted keys.\n",
    "    \"\"\"\n",
    "    unwanted_observation_keys = [\n",
    "        \"completionStartTime\",\n",
    "        \"metadata\",\n",
    "        \"timeToFirstToken\",\n",
    "        \"createdAt\",\n",
    "        \"usageDetails\",\n",
    "        \"usage\",\n",
    "        \"projectId\",\n",
    "        \"unit\",\n",
    "        \"updatedAt\",\n",
    "        \"version\",\n",
    "        \"parentObservationId\",\n",
    "        \"promptId\",\n",
    "        \"promptName\",\n",
    "        \"promptVersion\",\n",
    "        \"modelId\",\n",
    "        \"inputPrice\",\n",
    "        \"outputPrice\",\n",
    "        \"totalPrice\",\n",
    "        # \"modelParameters\",\n",
    "        \"input\",\n",
    "        \"output\",\n",
    "    ]\n",
    "\n",
    "    # If observation is a dictionary containing observation data\n",
    "    if isinstance(observation, dict):\n",
    "        trimmed_observation = {\n",
    "            k: v for k, v in observation.items() if k not in unwanted_observation_keys\n",
    "        }\n",
    "        return trimmed_observation\n",
    "    return observation\n",
    "\n",
    "\n",
    "def trim_data(data):\n",
    "    \"\"\"\n",
    "    Recursively trims the data structure.\n",
    "    \"\"\"\n",
    "\n",
    "    if isinstance(data, dict):\n",
    "        # Process the current dictionary\n",
    "        unwanted_trace_keys = [\n",
    "            \"release\",\n",
    "            \"version\",\n",
    "            \"user_id\",\n",
    "            \"public\",\n",
    "            \"html_path\",\n",
    "            \"scores\",\n",
    "            \"bookmarked\",\n",
    "            \"projectId\",\n",
    "            \"externalId\",\n",
    "            \"page\",\n",
    "            \"limit\",\n",
    "            \"total_pages\",\n",
    "        ]\n",
    "\n",
    "        # If this is a trace that contains observations, check for fatal errors\n",
    "        if \"observations\" in data:\n",
    "            # Check for SPAN observations with fatal errors before processing\n",
    "            skip_trace = False\n",
    "            for obs in data[\"observations\"]:\n",
    "                if isinstance(obs, dict) and obs.get(\"name\").startswith(\"error\"):\n",
    "                    status_message = obs.get(\"statusMessage\", \"\")\n",
    "                    ob_name = obs.get(\"name\")\n",
    "                    print(f\"SPAN {ob_name}: {status_message}\")\n",
    "\n",
    "                    if \"Fatal error\" in status_message:\n",
    "                        print(f\"Found Fatal error in SPAN observation, skipping trace\")\n",
    "                        skip_trace = True\n",
    "                        skipped_traces.append(data[\"name\"])\n",
    "                        break\n",
    "\n",
    "            if skip_trace:\n",
    "                return None  # Signal to skip this trace\n",
    "\n",
    "        # Create a new dictionary with wanted keys and recursively process values\n",
    "        trimmed_data = {}\n",
    "        for key, value in data.items():\n",
    "            if key not in unwanted_trace_keys:\n",
    "                if key == \"observations\":\n",
    "                    # Special handling for observations\n",
    "                    trimmed_data[key] = [\n",
    "                        process_existing_observation(obs) for obs in value\n",
    "                    ]\n",
    "                elif isinstance(value, (dict, list)):\n",
    "                    # Recursively process nested structures\n",
    "                    trimmed_data[key] = trim_data(value)\n",
    "                else:\n",
    "                    trimmed_data[key] = value\n",
    "\n",
    "        return trimmed_data\n",
    "\n",
    "    elif isinstance(data, list):\n",
    "        # Recursively process each item in the list\n",
    "        processed_items = []\n",
    "        for item in data:\n",
    "            processed_item = trim_data(item)\n",
    "            if processed_item is not None:  # Only add items that weren't filtered out\n",
    "                processed_items.append(processed_item)\n",
    "        return processed_items\n",
    "\n",
    "    else:\n",
    "        # Return non-dict, non-list values as is\n",
    "        return data\n",
    "\n",
    "\n",
    "def read_and_trim_data(session_id_list, raw_export_dir, trimmed_export_dir):\n",
    "    \"\"\"\n",
    "    Reads complete data from JSON files, trims the data, and saves the trimmed data to new JSON files.\n",
    "    \"\"\"\n",
    "    os.makedirs(trimmed_export_dir, exist_ok=True)\n",
    "\n",
    "    for session_id in session_id_list:\n",
    "        try:\n",
    "            if session_id.startswith(\"da0a\"):\n",
    "                session_id = \"phi4_\" + session_id\n",
    "            # Read raw data\n",
    "            if \"tpsg\" in session_id:\n",
    "                session_id_ = session_id.replace(\"tpsg\", \"tpusg\")\n",
    "            else:\n",
    "                session_id_ = session_id\n",
    "            raw_path = os.path.join(raw_export_dir, f\"raw_{session_id_}.json\")\n",
    "            with open(raw_path, \"r\") as f:\n",
    "                data = json.load(f)\n",
    "\n",
    "            # Process and trim the data\n",
    "            trimmed_data = trim_data(data)\n",
    "\n",
    "            # If the entire data was filtered out (unlikely but possible)\n",
    "            if trimmed_data is None:\n",
    "                print(\n",
    "                    f\"All traces in session {session_id} were filtered due to fatal errors\"\n",
    "                )\n",
    "                continue\n",
    "\n",
    "            # Save trimmed data\n",
    "            if \"tpsg\" in session_id:\n",
    "                session_id_ = session_id.replace(\"tpsg\", \"tpusg\")\n",
    "            else:\n",
    "                session_id_ = session_id\n",
    "            trimmed_path = os.path.join(\n",
    "                trimmed_export_dir, f\"trimmed_{session_id_}.json\"\n",
    "            )\n",
    "            with open(trimmed_path, \"w\") as f:\n",
    "                json.dump(trimmed_data, f, indent=2)\n",
    "\n",
    "            print(\n",
    "                f\"Successfully processed and saved trimmed data for session {session_id}\"\n",
    "            )\n",
    "\n",
    "            # Optional: Verify trimming worked\n",
    "            # print(f\"Verifying trimmed data for session {session_id}...\")\n",
    "            # verify_trimming(trimmed_path)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing session {session_id}: {str(e)}\")\n",
    "\n",
    "\n",
    "def verify_trimming(trimmed_path):\n",
    "    \"\"\"\n",
    "    Verifies that the trimmed data doesn't contain unwanted keys.\n",
    "    \"\"\"\n",
    "    with open(trimmed_path, \"r\") as f:\n",
    "        trimmed_data = json.load(f)\n",
    "\n",
    "    unwanted_keys = [\n",
    "        \"release\",\n",
    "        \"version\",\n",
    "        \"user_id\",\n",
    "        \"public\",\n",
    "        \"html_path\",\n",
    "        \"scores\",\n",
    "        \"bookmarked\",\n",
    "        \"projectId\",\n",
    "        \"externalId\",\n",
    "        \"page\",\n",
    "        \"limit\",\n",
    "        \"total_pages\",\n",
    "        \"completionStartTime\",\n",
    "        \"metadata\",\n",
    "        \"usageDetails\",\n",
    "        \"timeToFirstToken\",\n",
    "        \"createdAt\",\n",
    "        \"completionTokens\",\n",
    "        \"promptTokens\",\n",
    "        \"projectId\",\n",
    "        \"unit\",\n",
    "        \"updatedAt\",\n",
    "        \"version\",\n",
    "        # \"statusMessage\",\n",
    "        \"parentObservationId\",\n",
    "        \"promptId\",\n",
    "        \"promptName\",\n",
    "        \"promptVersion\",\n",
    "        \"modelId\",\n",
    "        \"inputPrice\",\n",
    "        \"outputPrice\",\n",
    "        \"totalPrice\",\n",
    "        \"calculatedInputCost\",\n",
    "        \"calculatedOutputCost\",\n",
    "        \"calculatedTotalCost\",\n",
    "    ]\n",
    "\n",
    "    def check_keys(obj):\n",
    "        if isinstance(obj, dict):\n",
    "            for key in obj.keys():\n",
    "                if key in unwanted_keys:\n",
    "                    print(f\"Warning: Found unwanted key '{key}' in trimmed data\")\n",
    "            for value in obj.values():\n",
    "                check_keys(value)\n",
    "        elif isinstance(obj, list):\n",
    "            for item in obj:\n",
    "                check_keys(item)\n",
    "\n",
    "    check_keys(trimmed_data)\n",
    "    print(\"Verification complete\")\n",
    "\n",
    "\n",
    "# Usage example:\n",
    "read_and_trim_data(session_id_list, raw_export_dir, raw_export_dir)\n",
    "print(f\"Total {len(skipped_traces)} traces skipped. They are {skipped_traces}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Generate CSV files from JSON\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing session qwen2.5-coder:14b_3193_psg_batch, simple id qwen2.5-coder:14b_3193. Look for /Users/hann/Projects/reference-benchmark-tinyml_llm/data_analysis/2025/08.04/raw_export/trimmed_qwen2.5-coder:14b_3193_psg_batch.json\n",
      "/Users/hann/Projects/reference-benchmark-tinyml_llm/data_analysis/2025/08.04/processed_data/qwen2.5-coder:14b_3193/clean_qwen2.5-coder:14b_3193_psg_batch.csv\n",
      "Successfully saved CSV to: /Users/hann/Projects/reference-benchmark-tinyml_llm/data_analysis/2025/08.04/processed_data/qwen2.5-coder:14b_3193/clean_qwen2.5-coder:14b_3193_psg_batch.csv\n",
      "Processing session qwen2.5-coder:14b_3193_tpusg_batch, simple id qwen2.5-coder:14b_3193. Look for /Users/hann/Projects/reference-benchmark-tinyml_llm/data_analysis/2025/08.04/raw_export/trimmed_qwen2.5-coder:14b_3193_tpusg_batch.json\n",
      "/Users/hann/Projects/reference-benchmark-tinyml_llm/data_analysis/2025/08.04/processed_data/qwen2.5-coder:14b_3193/clean_qwen2.5-coder:14b_3193_tpusg_batch.csv\n",
      "Successfully saved CSV to: /Users/hann/Projects/reference-benchmark-tinyml_llm/data_analysis/2025/08.04/processed_data/qwen2.5-coder:14b_3193/clean_qwen2.5-coder:14b_3193_tpusg_batch.csv\n"
     ]
    }
   ],
   "source": [
    "import traceback\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from dateutil import parser\n",
    "\n",
    "\n",
    "def json_to_csv(session_id):\n",
    "    \"\"\"\n",
    "    Convert JSON trace data to CSV format with aggregated metrics.\n",
    "\n",
    "    Args:\n",
    "        session_id (str): Identifier for the session to process\n",
    "    \"\"\"\n",
    "\n",
    "    def extract_observation_details(observations, trace_id):\n",
    "        \"\"\"Extract and aggregate metrics from observations\"\"\"\n",
    "        metrics = {\n",
    "            \"status\": None,\n",
    "            \"latency\": 0,\n",
    "            \"total_tokens\": 0,\n",
    "            \"prompt_tokens\": 0,\n",
    "            \"completion_tokens\": 0,\n",
    "            \"total_cost\": 0,\n",
    "            \"input_cost\": 0,\n",
    "            \"output_cost\": 0,\n",
    "            \"parameters\": set(),\n",
    "        }\n",
    "\n",
    "        # Process GENERATION observations\n",
    "        for obs in (o for o in observations if o[\"type\"] == \"GENERATION\"):\n",
    "            metrics[\"total_tokens\"] += obs[\"totalTokens\"]\n",
    "            metrics[\"prompt_tokens\"] += obs[\"promptTokens\"]\n",
    "            metrics[\"completion_tokens\"] += obs[\"completionTokens\"]\n",
    "            metrics[\"latency\"] += obs[\"latency\"]\n",
    "            for key, value in obs[\"modelParameters\"].items():\n",
    "                metrics[\"parameters\"].add(key + \":\" + value)\n",
    "\n",
    "            # Add costs if present\n",
    "            for cost_type in [\"Total\", \"Input\", \"Output\"]:\n",
    "                key = f\"calculated{cost_type}Cost\"\n",
    "                metric_key = cost_type.lower() + \"_cost\"\n",
    "                if obs.get(key) is not None:\n",
    "                    metrics[metric_key] += obs[key]\n",
    "        if len(metrics[\"parameters\"]) == 0:\n",
    "            metrics[\"parameters\"] = \"N/A\"\n",
    "        # Process SPAN observations for status\n",
    "        status_indicators = [\n",
    "            obs[\"name\"]\n",
    "            for obs in observations\n",
    "            if obs[\"type\"] == \"SPAN\" and \"start_\" not in obs[\"name\"]\n",
    "        ]\n",
    "\n",
    "        #  if later than 2025-05-19, use status_signal_from_output\n",
    "        if datetime.now() > datetime(2025, 5, 19):\n",
    "            pass\n",
    "        else:\n",
    "            # Determine status\n",
    "            success_signals = sum(\"end_\" in name for name in status_indicators)\n",
    "            failure_signals = sum(\n",
    "                \"failure_signal\" in name for name in status_indicators\n",
    "            )\n",
    "\n",
    "            if success_signals + failure_signals > 1:\n",
    "                raise ValueError(\n",
    "                    f\"Multiple status indicators found in trace {trace_id}\"\n",
    "                )\n",
    "\n",
    "            metrics[\"status\"] = (\n",
    "                \"success\"\n",
    "                if success_signals\n",
    "                else \"failure\" if failure_signals else \"unknown\"\n",
    "            )\n",
    "\n",
    "        metrics[\"prompt_cost\"] = metrics.pop(\"input_cost\")\n",
    "        metrics[\"completion_cost\"] = metrics.pop(\"output_cost\")\n",
    "        metrics[\"latency\"] = round(metrics[\"latency\"] / 1000, 2)\n",
    "        return metrics\n",
    "\n",
    "    def cal_time(trace):\n",
    "        time_diff = datetime.fromisoformat(\n",
    "            trace[\"updatedAt\"].replace(\"Z\", \"+00:00\")\n",
    "        ) - datetime.fromisoformat(trace[\"createdAt\"].replace(\"Z\", \"+00:00\"))\n",
    "        seconds_diff = time_diff.total_seconds()\n",
    "        return seconds_diff\n",
    "\n",
    "    try:\n",
    "\n",
    "        if session_id.startswith(\"da0a\"):\n",
    "            session_id = \"phi4_\" + session_id\n",
    "        simple_session_id = session_id.rsplit(\"_\", 2)[0]\n",
    "\n",
    "        \n",
    "        # Load JSON data\n",
    "        if \"tpsg\" in session_id:\n",
    "                session_id_ = session_id.replace(\"tpsg\", \"tpusg\")\n",
    "        else:\n",
    "                session_id_ = session_id\n",
    "        trimmed_path = os.path.join(raw_export_dir, f\"trimmed_{session_id_}.json\")\n",
    "        print(\n",
    "            f\"Processing session {session_id}, simple id {simple_session_id}. Look for {trimmed_path}\"\n",
    "        )\n",
    "        with open(trimmed_path, \"r\") as file:\n",
    "            traces = json.load(file)[\"data\"]\n",
    "\n",
    "        # Process traces\n",
    "        rows = [\n",
    "            {\n",
    "                \"num_run\": trace[\"metadata\"][\"num_run\"],\n",
    "                \"name\": trace[\"name\"],\n",
    "                \"trace_id\": trace[\"id\"],\n",
    "                \"batch_id\": trace[\"session_id\"],\n",
    "                # \"latency\": cal_time(trace),\n",
    "                # \"latency\": round(trace[\"latency\"], 2),\n",
    "                **extract_observation_details(\n",
    "                    trace[\"observations\"],\n",
    "                    trace[\"id\"],\n",
    "                ),\n",
    "                \"status\": (\n",
    "                    \"failure\"\n",
    "                    if trace[\"output\"][\"status\"].lower() == \"failed\"\n",
    "                    else \"success\"\n",
    "                ),\n",
    "                \"tags\": trace[\"tags\"],\n",
    "                \"timestamp\": int(parser.isoparse(trace[\"timestamp\"]).timestamp()),\n",
    "            }\n",
    "            for trace in traces\n",
    "        ]\n",
    "        # print(rows)\n",
    "        # print(rows)\n",
    "        # Create and save DataFrame\n",
    "        df = pd.DataFrame(rows).sort_values(\"num_run\")\n",
    "\n",
    "        output_dir = os.path.join(processed_data_dir, f\"{simple_session_id}\")\n",
    "        if not os.path.exists(output_dir):\n",
    "            os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "        output_path = os.path.join(output_dir, f\"clean_{session_id_}.csv\")\n",
    "\n",
    "        print(output_path)\n",
    "        df.to_csv(output_path, index=False)\n",
    "        print(f\"Successfully saved CSV to: {output_path}\")\n",
    "\n",
    "    except FileNotFoundError as e:\n",
    "        print(\n",
    "            f\"FileNotFoundError: For session {session_id} not found. Looked for {trimmed_path}\\nError info: \\n{e}\\n\\nTraceback: {traceback.format_exc()}\"\n",
    "        )\n",
    "    except json.JSONDecodeError:\n",
    "        print(f\"Error: Invalid JSON format in input file for session {session_id}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing session {session_id}: {str(e)}\")\n",
    "\n",
    "\n",
    "# Example usage\n",
    "for session_id in session_id_list:\n",
    "    json_to_csv(session_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code below is archived\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"\"\"Simply calculate success rate\"\"\"\n",
    "\n",
    "\n",
    "# def cal_success_rate(session_id):\n",
    "\n",
    "#     end_signal_count = 0\n",
    "#     failure_signal_count = 0\n",
    "#     # Function to print the name of each observation\n",
    "#     with open(f\"{raw_export_dir}/trimmed_{session_id}.json\", \"r\") as file:\n",
    "#         data = json.load(file)[\"data\"]\n",
    "#     for i in data:\n",
    "\n",
    "#         observations = i[\"observations\"]\n",
    "\n",
    "#         for observation in observations:\n",
    "#             # print(type(observation))\n",
    "#             for key, value in observation.items():\n",
    "#                 # print(f\"{key}: {value}\")\n",
    "#                 for key, value in value.items():\n",
    "#                     # print(f\"{key}: {value}\")\n",
    "#                     if key == \"name\":\n",
    "#                         if \"end_\" in value:\n",
    "\n",
    "#                             end_signal_count += 1\n",
    "#                         if \"failure_signal\" in value:\n",
    "\n",
    "#                             failure_signal_count += 1\n",
    "\n",
    "#     print(f\"Session ID: {session_id}\")\n",
    "#     total_count = end_signal_count + failure_signal_count\n",
    "#     if total_count > 0:\n",
    "#         success_rate = end_signal_count / total_count\n",
    "#         print(f\"Success rate: {success_rate:.4f}\")\n",
    "#     else:\n",
    "#         print(\"Success rate: N/A (no signals found)\")\n",
    "#     print(f\"Passed:\\t{end_signal_count}\\nFailed:\\t{failure_signal_count}\")\n",
    "#     print(\n",
    "#         \"\"\n",
    "#         if total_count == 30\n",
    "#         else \"Number of ending signals does not match the expected number!\"\n",
    "#     )\n",
    "#     print(\"-\" * 50)\n",
    "\n",
    "\n",
    "# for session_id in session_id_list:\n",
    "#     cal_success_rate(session_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def cal_time(start_time, end_time):\n",
    "#     time_diff = datetime.fromisoformat(\n",
    "#         end_time.replace(\"Z\", \"+00:00\")\n",
    "#     ) - datetime.fromisoformat(start_time.replace(\"Z\", \"+00:00\"))\n",
    "#     seconds_diff = time_diff.total_seconds()\n",
    "#     return seconds_diff\n",
    "\n",
    "\n",
    "# print(cal_time(\"2025-01-15T03:31:56.150000+00:00\", \"2025-01-15T03:32:59.384Z\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"\"\"Print the complete structure of exported json file\"\"\"\n",
    "# def print_keys(d, parent_key=''):\n",
    "#     if isinstance(d, dict):\n",
    "#         for key, value in d.items():\n",
    "#             full_key = f\"{parent_key}.{key}\" if parent_key else key\n",
    "#             print(full_key)\n",
    "#             print_keys(value, full_key)\n",
    "#     elif isinstance(d, list):\n",
    "#         for i, item in enumerate(d):\n",
    "#             full_key = f\"{parent_key}[{i}]\"\n",
    "#             print_keys(item, full_key)\n",
    "\n",
    "# # Load JSON data from a file\n",
    "# with open('fetch_traces_response.json', 'r') as file:\n",
    "#     data = json.load(file)['data'][0]\n",
    "# # Print all keys\n",
    "# print_keys(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1747226053\n",
      "1747226053.1\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "from dateutil import parser\n",
    "\n",
    "timestamp_str = \"2025-05-14T12:34:13.100000+00:00\"\n",
    "dt = parser.isoparse(\n",
    "    timestamp_str\n",
    ")  # Or datetime.fromisoformat(timestamp_str) if no timezone offset\n",
    "unix_ts = int(dt.timestamp())\n",
    "\n",
    "print(unix_ts)  # This will print the integer Unix timestamp\n",
    "print(datetime.fromisoformat(timestamp_str).timestamp())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datasci2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

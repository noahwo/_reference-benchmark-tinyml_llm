{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setting up\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ref: https://langfuse.com/docs/query-traces\n",
    "import os\n",
    "import json\n",
    "from langfuse import Langfuse\n",
    "import json\n",
    "import os\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "LOCAL_HOST = True\n",
    "\n",
    "\"\"\"Define session_id\"\"\"\n",
    "# session_id=\"qwen2.5-coder_f4d4_dp_batch\"\n",
    "session_id_list = [\n",
    "    \"qwen2.5-coder:14b_33b8_psg_batch\",\n",
    "    \"qwen2.5-coder:14b_33b8_tpusg_batch\"\n",
    "]\n",
    "\n",
    "\n",
    "\"\"\"Define paths\"\"\"\n",
    " \n",
    "parent_dir = os.path.dirname(os.getcwd())\n",
    "\n",
    " \n",
    "# date = os.path.basename(parent_dir)\n",
    "tex_dir = os.path.join(parent_dir, \"tex\")\n",
    "processed_data_dir = os.path.join(parent_dir, \"processed_data\")\n",
    "raw_export_dir = os.path.join(parent_dir, \"raw_export\")\n",
    "ipynb_dir = os.path.join(parent_dir, \"ipynb\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Export raw data\n",
    "\n",
    "Langfuse added a limit of 20 API invocations per minute. https://langfuse.com/faq/all/api-limits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching traces for session qwen2.5-coder:14b_33b8_psg_batch...\n",
      "Fetching observation data for time-13-52-21-935537_chatcmpl-55136b17-0f0f-45a4-bda1-357b5787cb35...\n",
      "Fetching observation data for time-13-52-37-367086_chatcmpl-f5163dbb-2913-4b88-8f4f-3398cacf0ea6...\n",
      "Fetching observation data for time-13-52-46-407867_chatcmpl-3bda849a-8a94-4ba7-be24-f5cc60d00801...\n",
      "Fetching observation data for time-13-52-55-339252_chatcmpl-e197c86b-71bf-4441-abb5-37386c8e7f74...\n",
      "Fetching observation data for time-13-53-04-954588_chatcmpl-d1bfc9de-0590-42a6-a278-80926cb8c51b...\n",
      "Fetching observation data for 239283a5-10cf-4d39-ae50-db6eef4aa514...\n",
      "Fetching observation data for time-13-51-16-368450_chatcmpl-50194ca4-3ea7-4d72-93f8-cce0fa72e162...\n",
      "Fetching observation data for time-13-51-31-805301_chatcmpl-207e55a2-d86e-45df-8ec6-c66f5de7462d...\n",
      "Fetching observation data for time-13-51-42-207109_chatcmpl-5c12463f-6c37-4abe-bf20-fec6e61e83ac...\n",
      "Fetching observation data for time-13-51-53-174534_chatcmpl-0008b11f-476d-40fb-95ed-c3539475f0db...\n",
      "Fetching observation data for time-13-52-05-051102_chatcmpl-1f892908-efc0-48c9-8b2a-1ff8b743f850...\n",
      "Fetching observation data for 8594947e-eaea-4c4b-9df0-4b2b14c7f275...\n",
      "Fetching observation data for time-13-50-14-451506_chatcmpl-b7855efb-e58a-431c-9d14-26f3949671ea...\n",
      "Fetching observation data for time-13-50-29-898801_chatcmpl-8b891938-7785-4dfd-b68b-0ead0be5a55d...\n",
      "Fetching observation data for time-13-50-38-935691_chatcmpl-bb215a66-dbd1-4beb-bcd5-4de104548888...\n",
      "Fetching observation data for time-13-50-47-828120_chatcmpl-ed2f9f7b-cdeb-4751-9106-fe07b650d8c6...\n",
      "Fetching observation data for time-13-50-57-736408_chatcmpl-7398cfb9-bb0c-4b22-ab06-193daf354fec...\n",
      "Fetching observation data for ba829d5f-29d0-4eb2-be4d-c20df107d73e...\n",
      "Fetching observation data for time-13-49-12-411964_chatcmpl-e0ab5023-74bf-4858-ba93-33c2761d6601...\n",
      "Fetching observation data for time-13-49-27-991182_chatcmpl-d09a10b1-2093-481f-ba74-d0493e02fbf3...\n",
      "Fetching observation data for time-13-49-37-874274_chatcmpl-10cbbdcb-4995-4741-b4e1-c5614af9894e...\n",
      "Fetching observation data for time-13-49-47-556055_chatcmpl-3ee197eb-2ae5-4ee4-a727-a2c8d32edd1d...\n",
      "Fetching observation data for time-13-49-57-386349_chatcmpl-48caf069-2938-485f-9771-6d1a5212726b...\n",
      "Fetching observation data for 5bc88b1f-270e-4533-b4ff-b37df5d0b1b9...\n",
      "Fetching observation data for time-13-48-05-882878_chatcmpl-9c20e2ba-6074-496b-881b-b3d9b53455d2...\n",
      "Fetching observation data for time-13-48-21-647826_chatcmpl-132f32dc-05c1-439e-bd47-0910fb7821df...\n",
      "Fetching observation data for time-13-48-31-397434_chatcmpl-6bccbeee-9ff3-4fb2-abb4-24d1193bfa00...\n",
      "Fetching observation data for time-13-48-46-663081_chatcmpl-22f805b1-9cce-4338-94b4-24c8d3224a38...\n",
      "Fetching observation data for time-13-48-56-340045_chatcmpl-551f10ae-5bec-4778-8481-aa60b731819c...\n",
      "Fetching observation data for ff3ea5a6-d11e-4973-9b00-d301e51dd92f...\n",
      "Fetching observation data for time-13-47-04-325493_chatcmpl-0b15b399-3e02-4868-b8a5-c105b7305827...\n",
      "Fetching observation data for time-13-47-19-844740_chatcmpl-ef43a780-6470-4ea1-be43-710b542b420d...\n",
      "Fetching observation data for time-13-47-29-672799_chatcmpl-8461c14d-ba67-4e08-8659-22aff94d7e78...\n",
      "Fetching observation data for time-13-47-39-391554_chatcmpl-052b5557-ace3-4c2e-99e5-2a91b57b061a...\n",
      "Fetching observation data for time-13-47-49-372527_chatcmpl-89578d7a-87a4-4f5f-954d-95ff91b27a9d...\n",
      "Fetching observation data for dd88ff92-2fee-485c-8e2a-764f42379ac8...\n",
      "Fetching observation data for time-13-45-51-490616_chatcmpl-b7e30979-e1ea-4433-8686-46a8e383da0d...\n",
      "Fetching observation data for time-13-46-07-159721_chatcmpl-62191e49-27b7-4784-973c-f3810a27e414...\n",
      "Fetching observation data for time-13-46-16-781551_chatcmpl-7e4b50f3-c129-4c26-af6c-d0612d77c500...\n",
      "Fetching observation data for time-13-46-27-401935_chatcmpl-5da3d42b-04f9-4990-9622-bff36bb367c5...\n",
      "Fetching observation data for time-13-46-43-489232_chatcmpl-80d9fa29-4a92-4e65-a373-a8214d24d4c7...\n",
      "Fetching observation data for 2b774cb8-71d3-481f-8fc7-1433d075ced7...\n",
      "Fetching observation data for time-13-44-46-930978_chatcmpl-2042a90d-c15c-4ca5-93db-a1b48896117e...\n",
      "Fetching observation data for time-13-45-02-650398_chatcmpl-e25f2ad9-9fdc-4181-bea3-e8b3701c1fcc...\n",
      "Fetching observation data for time-13-45-11-849071_chatcmpl-021aef7c-bbfd-4ba5-ae69-3a204d27642a...\n",
      "Fetching observation data for time-13-45-21-834205_chatcmpl-2a4023b2-f754-4fc7-8494-f6ab9bfb3698...\n",
      "Fetching observation data for time-13-45-35-391461_chatcmpl-e5251073-6c3f-4898-86c6-72729e899547...\n",
      "Fetching observation data for bd603ecd-3323-45e8-9844-6687778b9107...\n",
      "Fetching observation data for time-13-43-42-366801_chatcmpl-96d9b70c-4308-4c97-aa09-ad7aa2d95315...\n",
      "Fetching observation data for time-13-43-57-787074_chatcmpl-bbb077b8-7ec0-42aa-b320-2289d2c8e649...\n",
      "Fetching observation data for time-13-44-08-252107_chatcmpl-b6210905-f251-4bc3-93f4-fbd6ae9828b2...\n",
      "Fetching observation data for time-13-44-20-332083_chatcmpl-e3d60f7b-fc62-4294-9c08-0549b7f11f72...\n",
      "Fetching observation data for time-13-44-30-928560_chatcmpl-2ee4af89-43fd-48eb-870f-393fd6d03de7...\n",
      "Fetching observation data for 96e7ead7-400c-4289-a6a4-96b7b83271e2...\n",
      "Fetching observation data for time-13-42-40-766010_chatcmpl-9f25b719-d8b0-464d-8d31-c2295b1ab741...\n",
      "Fetching observation data for time-13-42-56-512274_chatcmpl-fc774c8a-fe2a-4c06-8563-ab70254a773c...\n",
      "Fetching observation data for time-13-43-06-091934_chatcmpl-ff70203f-38d2-4e4f-a02f-f12670a60421...\n",
      "Fetching observation data for time-13-43-15-779885_chatcmpl-2fa1f65d-2178-4db6-b0fe-e7ad558d2b56...\n",
      "Fetching observation data for time-13-43-25-650745_chatcmpl-9effed91-419d-44e4-89d9-7d0949a67de2...\n",
      "Fetching observation data for fa8f658e-ffc2-4ca0-8798-d1b291e4d179...\n",
      "Fetching observation data for time-13-41-39-176728_chatcmpl-fec68682-e34a-447d-9950-5e4f3e889e6a...\n",
      "Fetching observation data for time-13-41-54-912074_chatcmpl-244539a4-fe28-449c-8ac6-d7a3f18dead1...\n",
      "Fetching observation data for time-13-42-04-109728_chatcmpl-126ee58e-e726-46ff-ac3a-a71908b3d510...\n",
      "Fetching observation data for time-13-42-14-093177_chatcmpl-88d18b05-124d-480b-b211-943f3e3aba95...\n",
      "Fetching observation data for time-13-42-24-468821_chatcmpl-c296bac8-d71b-4e7c-895d-10ac03d57273...\n",
      "Fetching observation data for 4c2e1f8b-6146-4faf-86fa-ab9b1fe865a0...\n",
      "Fetching observation data for time-13-40-37-136954_chatcmpl-62706fd4-8fe5-482b-b70b-948802f7a26c...\n",
      "Fetching observation data for time-13-40-52-878944_chatcmpl-5f180ccb-4dad-4752-8ee3-c046389f8bd3...\n",
      "Fetching observation data for time-13-41-02-064067_chatcmpl-1843c8e8-4d2d-47e1-8281-6b400e97c44d...\n",
      "Fetching observation data for time-13-41-11-986891_chatcmpl-a8ee0734-8c69-4b2a-9fcf-b4d2334025cc...\n",
      "Fetching observation data for time-13-41-21-975600_chatcmpl-4a9e59fb-d0fe-4c20-89ea-d949c35ef861...\n",
      "Fetching observation data for f0f34183-302c-4c7a-8d92-05d615ca0c51...\n",
      "Fetching observation data for time-13-39-36-023254_chatcmpl-eb6090d2-954d-46b9-ba92-4569dfcb480b...\n",
      "Fetching observation data for time-13-39-51-484299_chatcmpl-f8267e66-904e-495f-b8a9-7ff064ee2d94...\n",
      "Fetching observation data for time-13-40-00-649107_chatcmpl-8d731e00-d911-48f6-a3cf-b686feb18122...\n",
      "Fetching observation data for time-13-40-10-334438_chatcmpl-d54105be-e12c-45bd-a976-d1d8842b716f...\n",
      "Fetching observation data for time-13-40-20-150198_chatcmpl-21120f92-6392-4e23-9d02-34aea92367b7...\n",
      "Fetching observation data for 917ceb16-f982-4834-b546-ba7e2e40edcb...\n",
      "Fetching observation data for time-13-38-27-341989_chatcmpl-1adf77ab-b019-4755-95bc-06989685c619...\n",
      "Fetching observation data for time-13-38-43-122245_chatcmpl-57cf99a8-2109-433a-8a74-f72058da5aaf...\n",
      "Fetching observation data for time-13-38-52-713037_chatcmpl-4424ca17-e959-48b5-969b-ad99d9cebbf7...\n",
      "Fetching observation data for time-13-39-03-276113_chatcmpl-55ff1098-1897-4e5e-8f46-750f3b3347e3...\n",
      "Fetching observation data for time-13-39-15-083249_chatcmpl-7010df49-0ebf-4861-91c3-858dea508f45...\n",
      "Fetching observation data for f041a085-3224-4c85-a7a5-4d8d2485a312...\n",
      "Fetching observation data for time-13-37-26-538643_chatcmpl-655f70df-9233-4b0c-b8e8-52dfe5e38e53...\n",
      "Fetching observation data for time-13-37-42-263209_chatcmpl-d0fda566-e4e8-475d-97cb-7c29cf0527ac...\n",
      "Fetching observation data for time-13-37-51-439854_chatcmpl-ad4782a5-4496-49ae-aa4a-498fbbfdb6c9...\n",
      "Fetching observation data for time-13-38-01-193669_chatcmpl-a4ebc2c4-95a0-4488-a7bf-e1946f035330...\n",
      "Fetching observation data for time-13-38-10-885721_chatcmpl-ce45697c-b79a-43b6-8268-4cefcdffd973...\n",
      "Fetching observation data for 436aac9f-bc89-4ef5-9783-4fed438973ed...\n",
      "Fetching observation data for time-13-36-25-905170_chatcmpl-26ae8a42-cc2d-4205-b182-f0e1af42a4f7...\n",
      "Fetching observation data for time-13-36-41-320122_chatcmpl-73ea2083-d5c1-4fbd-a61b-9e18a611ded7...\n",
      "Fetching observation data for time-13-36-50-497753_chatcmpl-1202fc37-8b48-402f-bf8a-519179306d5e...\n",
      "Fetching observation data for time-13-37-00-180107_chatcmpl-f3c1066e-e1eb-4b88-bf80-839bcb6ecc9f...\n",
      "Fetching observation data for time-13-37-09-952294_chatcmpl-535b99b3-b54d-4766-abe7-414a8457d73e...\n",
      "Fetching observation data for 39d215b8-9bda-44b9-b209-b7bb5a70de05...\n",
      "Fetching observation data for time-13-35-14-314949_chatcmpl-1f4e11fe-c94d-4a9b-890f-f4c415856f6b...\n",
      "Fetching observation data for time-13-35-29-765355_chatcmpl-a08d8977-b07e-4a13-a359-36a224c1941b...\n",
      "Fetching observation data for time-13-35-40-170523_chatcmpl-45780506-31be-4642-818d-177d646142bd...\n",
      "Fetching observation data for time-13-35-52-029005_chatcmpl-8c5208d6-8536-4bdc-9276-e1fba8667ed8...\n",
      "Fetching observation data for time-13-36-04-228719_chatcmpl-7dde48c8-7b57-4be0-ae5b-372833bf2cee...\n",
      "Fetching observation data for 47ec8ef7-d636-448d-87f6-4ab77d03d865...\n",
      "Fetching observation data for time-13-34-05-331787_chatcmpl-72aba407-2d84-42f0-8710-a534b394db07...\n",
      "Fetching observation data for time-13-34-21-017810_chatcmpl-a2b5e4ac-2059-4858-a738-742b287f0427...\n",
      "Fetching observation data for time-13-34-30-564193_chatcmpl-a5c46d0e-fad3-45e6-85a1-760a14d1152f...\n",
      "Fetching observation data for time-13-34-41-114440_chatcmpl-7c6ccbff-8a50-4087-8112-dbae57ade86e...\n",
      "Fetching observation data for time-13-34-53-131228_chatcmpl-bb40ab34-dc91-49ef-b515-d3636ae4bfa2...\n",
      "Fetching observation data for 77ce1fa9-9a08-4450-9702-4252728fb4f0...\n",
      "Fetching observation data for time-13-33-02-720275_chatcmpl-371f04fc-e182-4505-ae68-95ca2239db07...\n",
      "Fetching observation data for time-13-33-18-514119_chatcmpl-3fde23ff-c495-4d72-b3ed-6ba1bbc7cf9b...\n",
      "Fetching observation data for time-13-33-28-573678_chatcmpl-68658b73-afa1-46ff-b7b2-7cb8c753c3b8...\n",
      "Fetching observation data for time-13-33-38-091116_chatcmpl-48cfcf91-62d6-4790-88b7-85c953b24271...\n",
      "Fetching observation data for time-13-33-48-324104_chatcmpl-fa9160a7-0bbb-46ae-8fc7-9b4ab25eeab4...\n",
      "Fetching observation data for a7523ce7-1536-4169-be4d-8a6e5e927cd5...\n",
      "Fetching observation data for time-13-31-56-006857_chatcmpl-9b327386-d280-4b2a-97e2-f8f4bc111e34...\n",
      "Fetching observation data for time-13-32-11-646422_chatcmpl-29f0a005-dadc-49bd-9eeb-ba2738daf3a1...\n",
      "Fetching observation data for time-13-32-22-175421_chatcmpl-a6f94d98-16e7-4e7c-9723-89935f2f9e12...\n",
      "Fetching observation data for time-13-32-34-251811_chatcmpl-be92574f-2a20-46a8-a01c-1a6a4d21f81e...\n",
      "Fetching observation data for time-13-32-45-980280_chatcmpl-b54d4d29-50cf-46b4-9a59-526193405e55...\n",
      "Fetching observation data for 5dad5178-f6ad-4e15-af44-9dd769716717...\n",
      "Fetching observation data for time-13-30-54-440061_chatcmpl-95d11faf-7056-47fe-b2a6-d70e60f442c9...\n",
      "Fetching observation data for time-13-31-09-908109_chatcmpl-c49b8b87-bb09-4ee4-b897-390e27114c26...\n",
      "Fetching observation data for time-13-31-19-074134_chatcmpl-28e7dc5a-186c-4a0d-931d-3c742b635b99...\n",
      "Fetching observation data for time-13-31-28-787151_chatcmpl-458b7d26-b0e7-43e7-8635-ef3bcc7d443d...\n",
      "Fetching observation data for time-13-31-38-758209_chatcmpl-86196ad4-9c59-4890-a8aa-f2bd796ece37...\n",
      "Fetching observation data for beb8ea20-a6bb-45b2-9067-34ba9aaff28d...\n",
      "Fetching observation data for time-13-29-48-897009_chatcmpl-718fb50d-4a6c-40e2-b114-d6b5677a0813...\n",
      "Fetching observation data for time-13-30-04-344087_chatcmpl-00d7329a-8f6d-4a28-8fa7-8a6a545787a7...\n",
      "Fetching observation data for time-13-30-14-130066_chatcmpl-2821b657-141b-486c-a818-e4656fe081b5...\n",
      "Fetching observation data for time-13-30-24-006242_chatcmpl-2b766608-9784-4971-9f93-0baa2f395e5a...\n",
      "Fetching observation data for time-13-30-36-707477_chatcmpl-32a9f0b1-61cd-43c2-bb47-2abd94a44a03...\n",
      "Fetching observation data for bf980bf5-acac-4e79-8465-e837871bd5b1...\n",
      "Fetching observation data for time-13-28-49-370831_chatcmpl-694824fe-9528-4b16-938e-e540fed32d9f...\n",
      "Fetching observation data for time-13-29-04-814080_chatcmpl-4c03f633-374f-4663-8996-85bb888ec0ff...\n",
      "Fetching observation data for time-13-29-13-866212_chatcmpl-fb43bac8-c3d0-434e-8e33-c02f4da152cb...\n",
      "Fetching observation data for time-13-29-22-833188_chatcmpl-f5a904ad-b5d4-4c0d-965b-94b8b7a4a4a6...\n",
      "Fetching observation data for time-13-29-32-563684_chatcmpl-d7234ca0-96d7-430e-85bf-c0f274377b2f...\n",
      "Fetching observation data for 70113df7-4c33-4f08-ad39-b5a3662408dd...\n",
      "Fetching observation data for time-13-27-43-789344_chatcmpl-50ae4aad-01cd-4dd9-b543-cc4a771f38ed...\n",
      "Fetching observation data for time-13-27-59-262828_chatcmpl-3cd2f10d-758a-442d-81c9-80106a10f0c2...\n",
      "Fetching observation data for time-13-28-09-661929_chatcmpl-810dddca-138f-4d88-b776-f04e0916f4e3...\n",
      "Fetching observation data for time-13-28-21-360792_chatcmpl-35de9a29-10aa-4142-afa0-285c9d8d7fec...\n",
      "Fetching observation data for time-13-28-33-280654_chatcmpl-13532e5a-0046-4583-bfbb-e4ff4206c5b5...\n",
      "Fetching observation data for 49531d7f-949d-49f0-97fe-f27c0dd9c88d...\n",
      "Fetching observation data for time-13-26-31-577907_chatcmpl-40b6dca2-5d10-47b6-868c-dc106177e74d...\n",
      "Fetching observation data for time-13-26-47-356070_chatcmpl-ec90df33-8a3d-4928-be71-8930f391361f...\n",
      "Fetching observation data for time-13-26-56-541263_chatcmpl-1eeb4ed3-0164-4d20-bd76-6c42b5ac8ea4...\n",
      "Fetching observation data for time-13-27-06-491502_chatcmpl-24fe05d6-9ca9-4844-9d26-70839bc10dae...\n",
      "Fetching observation data for time-13-27-20-551360_chatcmpl-f3ee0d26-3f0d-4043-a184-726a91020575...\n",
      "Fetching observation data for 577b7b88-181b-4fe7-aec2-ad4da6720982...\n",
      "Fetching observation data for time-13-25-29-792259_chatcmpl-419a785e-b5cc-409c-a338-130028627099...\n",
      "Fetching observation data for time-13-25-45-562079_chatcmpl-b54a0088-982b-48f0-84f3-60f0e4a50b88...\n",
      "Fetching observation data for time-13-25-54-728575_chatcmpl-792d29ce-cc5d-48ee-9f4c-1f5b6bc77ff0...\n",
      "Fetching observation data for time-13-26-04-668643_chatcmpl-39fa28e4-635a-4e50-83ee-d64594568514...\n",
      "Fetching observation data for time-13-26-14-634070_chatcmpl-50f48710-2bd2-4169-b3e7-5ec3136ea03f...\n",
      "Fetching observation data for 61a7a10f-9078-4f8f-bb4d-21a6b8867553...\n",
      "Fetching observation data for time-13-24-20-204455_chatcmpl-618ef2ee-c319-4b6e-a4bc-67abc134f617...\n",
      "Fetching observation data for time-13-24-35-568568_chatcmpl-0ecc3226-5872-468d-a3e7-f2343de3e3a4...\n",
      "Fetching observation data for time-13-24-45-991358_chatcmpl-0fff62c2-5ccd-497f-a16b-9ab7daa8c938...\n",
      "Fetching observation data for time-13-24-57-843366_chatcmpl-be583fe2-c2c1-4287-8999-4bbe304f7bf9...\n",
      "Fetching observation data for time-13-25-14-259201_chatcmpl-80ce309d-4623-41d1-b54f-547bc691771c...\n",
      "Fetching observation data for 279d21e6-7296-402f-ad23-d93bf949851a...\n",
      "Fetching observation data for time-13-23-18-243637_chatcmpl-bad456ad-802d-4a7d-bace-2cebed4862d0...\n",
      "Fetching observation data for time-13-23-33-546157_chatcmpl-2fce4bca-2af5-4ad7-8232-367d9f4fd1fc...\n",
      "Fetching observation data for time-13-23-43-385073_chatcmpl-9149eba9-ed4a-44b2-914c-50acf6356e45...\n",
      "Fetching observation data for time-13-23-53-064174_chatcmpl-db07362f-3264-4ed7-8bb3-e261de035c41...\n",
      "Fetching observation data for time-13-24-02-856271_chatcmpl-2e838c56-39c5-4006-b515-f93622c04010...\n",
      "Fetching observation data for 540aa264-2c7c-4625-896b-20cc06a59493...\n",
      "Fetching observation data for time-13-22-11-682598_chatcmpl-bca97cbd-93d3-445e-8bee-7f73d07b6d9c...\n",
      "Fetching observation data for time-13-22-27-117021_chatcmpl-6c1b0f16-f923-4035-84dc-3aa19ef51e28...\n",
      "Fetching observation data for time-13-22-37-039676_chatcmpl-d78bce9e-8ba3-4103-ae77-4c595ab8d226...\n",
      "Fetching observation data for time-13-22-47-295644_chatcmpl-cc6348a9-a205-4edc-b954-da65f363eeac...\n",
      "Fetching observation data for time-13-23-02-705469_chatcmpl-414c172a-74a2-40a9-a3b2-c511a10f938c...\n",
      "Fetching observation data for 2128a1eb-52d6-46a2-8e5e-3e297f32aec0...\n",
      "Fetching observation data for time-13-21-04-031528_chatcmpl-64a0418b-6e3e-4594-8ab6-bdec71f46f8b...\n",
      "Fetching observation data for time-13-21-19-473554_chatcmpl-8939266a-bcf4-4189-b4f5-0ef5f7d763c3...\n",
      "Fetching observation data for time-13-21-29-172947_chatcmpl-b8e9e708-eaae-4e53-bb73-f00ab09f665e...\n",
      "Fetching observation data for time-13-21-39-796107_chatcmpl-3db22d9b-10f8-4d93-b990-2c41350f6000...\n",
      "Fetching observation data for time-13-21-55-427075_chatcmpl-d53d6175-a4bb-4a84-8e6f-ffee6d8cd564...\n",
      "Fetching observation data for c8113523-96e0-4ee5-b605-39371a752cb6...\n",
      "Raw JSON saved to: /Users/hann/Projects/reference-benchmark-tinyml_llm/data_analysis/2025/08.05/raw_export/raw_qwen2.5-coder:14b_33b8_psg_batch.json\n",
      "Fetching traces for session qwen2.5-coder:14b_33b8_tpusg_batch...\n",
      "Fetching observation data for time-13-19-46-471740_chatcmpl-b4df7045-1c89-49d6-95c0-00097291fb78...\n",
      "Fetching observation data for time-13-18-28-372481_chatcmpl-03cd3452-e590-463f-80df-d8c6451d01ea...\n",
      "Fetching observation data for time-13-17-10-463292_chatcmpl-1e628a92-0c25-4bfc-a24a-a7e0b262eca9...\n",
      "Fetching observation data for time-13-15-51-513530_chatcmpl-97397b1e-31be-4419-b6b3-98b42000fb7a...\n",
      "Fetching observation data for time-13-14-32-892721_chatcmpl-c2e4200c-9fea-47bc-8577-216ce52b64a0...\n",
      "Fetching observation data for time-13-13-14-141757_chatcmpl-af42d3a3-b9c6-4fc9-b041-48867ec6f614...\n",
      "Fetching observation data for time-13-11-54-584879_chatcmpl-e629ccf6-ba3f-4540-b925-c5fe14735583...\n",
      "Fetching observation data for time-13-10-35-570403_chatcmpl-cf61b726-a803-4493-a63b-2115dd56a7f9...\n",
      "Fetching observation data for time-13-09-16-799420_chatcmpl-3c9a4ae9-eab3-4498-9f38-0602bb07a604...\n",
      "Fetching observation data for time-13-07-56-456335_chatcmpl-f9eb4efe-523a-4d79-b66f-eb2211b5c29c...\n",
      "Fetching observation data for time-13-06-37-673834_chatcmpl-d3fe0120-c376-4383-95e0-85aa02676b21...\n",
      "Fetching observation data for time-13-05-19-815026_chatcmpl-d6ac5039-fdbb-4bbb-a0e5-d8446df2b99f...\n",
      "Fetching observation data for time-13-03-59-441530_chatcmpl-1c2a4abc-022d-4112-97f0-0868553d61e0...\n",
      "Fetching observation data for time-13-02-40-628741_chatcmpl-b5f30e69-92b1-4e1e-8d15-0b73e3d729b3...\n",
      "Fetching observation data for time-13-01-21-921934_chatcmpl-fb6cb4bd-c7f3-40c2-b176-3ba23678aa30...\n",
      "Fetching observation data for time-13-00-02-834300_chatcmpl-2bd0e819-c144-4039-a852-961f2069440b...\n",
      "Fetching observation data for time-12-58-44-006770_chatcmpl-e6289325-a568-4efa-9fdd-33098a903d19...\n",
      "Fetching observation data for time-12-57-24-582161_chatcmpl-61ed4f07-0c19-45c9-b593-6ec3da175719...\n",
      "Fetching observation data for time-12-56-05-835096_chatcmpl-632125e9-10e5-4605-9390-24b606329468...\n",
      "Fetching observation data for time-12-54-47-115399_chatcmpl-d6653e06-8e9b-43f5-b9ec-207e62a26bc6...\n",
      "Fetching observation data for time-12-53-28-156957_chatcmpl-b248e2d6-676b-4bd2-a674-2f7f03e09c09...\n",
      "Fetching observation data for time-12-52-09-313833_chatcmpl-e808a059-2f9c-4028-aff5-783c3ee81b15...\n",
      "Fetching observation data for time-12-50-50-555612_chatcmpl-f47b5e90-8140-48ac-85ef-ad67c4b0c37d...\n",
      "Fetching observation data for time-12-49-32-725237_chatcmpl-18fda9a8-43a6-45be-9962-d9c62ce46471...\n",
      "Fetching observation data for time-12-48-13-871611_chatcmpl-4a8dbd86-0778-48a2-88c2-0cafbcb3a73d...\n",
      "Fetching observation data for time-12-46-54-458861_chatcmpl-d4f6f3d6-e058-4b5a-84e7-1a601644195a...\n",
      "Fetching observation data for time-12-45-35-492497_chatcmpl-155df944-18c9-4475-af04-a07e41326c62...\n",
      "Fetching observation data for time-12-44-17-667733_chatcmpl-b50fdcb2-487d-4872-9548-ed92bd40f8cf...\n",
      "Fetching observation data for time-12-42-56-895240_chatcmpl-1c4a5e89-10b1-4a8a-aa26-80bff059aa15...\n",
      "Fetching observation data for time-12-41-25-199002_chatcmpl-3a2ead4f-0254-46fa-a21b-f9348efa733a...\n",
      "Raw JSON saved to: /Users/hann/Projects/reference-benchmark-tinyml_llm/data_analysis/2025/08.05/raw_export/raw_qwen2.5-coder:14b_33b8_tpusg_batch.json\n"
     ]
    }
   ],
   "source": [
    "# ALTERNATIVE TO 2.\n",
    "import os\n",
    "import json\n",
    "from time import sleep\n",
    "from langfuse import Langfuse\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "\n",
    "# LANGFUSE_SERVICE_PUBLIC_KEY = \"pk-lf-559a2c0f-ee29-4c32-944c-bf73b5f0ce28\"\n",
    "# LANGFUSE_SERVICE_SECRET_KEY = \"sk-lf-75f8bf7f-a5db-4756-b0dd-d758a2a292c8\"\n",
    "# LANGFUSE_SERVICE_HOST = \"https://langfuse.hann.fi\"\n",
    "\n",
    "\n",
    "if LOCAL_HOST:\n",
    "    langfuse = Langfuse(\n",
    "        secret_key=\"sk-lf-75f8bf7f-a5db-4756-b0dd-d758a2a292c8\",\n",
    "        public_key=\"pk-lf-559a2c0f-ee29-4c32-944c-bf73b5f0ce28\",\n",
    "        host=\"https://langfuse.hann.fi\",\n",
    "    )\n",
    "else:\n",
    "    langfuse = Langfuse(\n",
    "        secret_key=LANGFUSE_SERVICE_SECRET_KEY,\n",
    "        public_key=LANGFUSE_SERVICE_PUBLIC_KEY,\n",
    "        host=LANGFUSE_SERVICE_HOST,\n",
    "    )\n",
    "\n",
    "API_invok_count = 0\n",
    "query_range_num_run = {\"start\": 0, \"end\": 1}\n",
    "\n",
    "\n",
    "class CustomJSONEncoder(json.JSONEncoder):\n",
    "    def __init__(self, *args, LOCAL_HOST=True, **kwargs):\n",
    "        self.LOCAL_HOST = LOCAL_HOST\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "    def default(self, obj):\n",
    "        if isinstance(obj, datetime):\n",
    "            return obj.isoformat()\n",
    "        if hasattr(obj, \"__dict__\"):\n",
    "            data = obj.__dict__.copy()\n",
    "            if \"observations\" in data:\n",
    "                data[\"observations\"] = [\n",
    "                    fetch_observation_data(obs, self.LOCAL_HOST)\n",
    "                    for obs in data[\"observations\"]\n",
    "                ]\n",
    "\n",
    "            return data\n",
    "        return super().default(obj)\n",
    "\n",
    "\n",
    "def fetch_observation_data(observation_id, LOCAL_HOST):\n",
    "    \"\"\"\n",
    "    Fetches observation data from Langfuse and returns its dictionary representation.\n",
    "    \"\"\"\n",
    "    print(f\"Fetching observation data for {observation_id}...\")\n",
    "    global API_invok_count\n",
    "    if API_invok_count >= 0 and not LOCAL_HOST:\n",
    "        print(\"Waiting for 3 seconds to fetch observation data...\")\n",
    "        for _ in tqdm(range(3), desc=\"Progress\", unit=\"s\"):\n",
    "            sleep(1)\n",
    "        API_invok_count = 0\n",
    "\n",
    "    observation_response = langfuse.fetch_observation(observation_id)\n",
    "    API_invok_count += 1\n",
    "\n",
    "    return observation_response.data.dict()\n",
    "\n",
    "\n",
    "def fetch_and_save_complete_data(session_id_list, raw_export_dir, LOCAL_HOST):\n",
    "    \"\"\"\n",
    "    Fetches complete trace data for each session ID and saves it to JSON files.\n",
    "\n",
    "    Parameters:\n",
    "        session_id_list (list): List of session IDs to process.\n",
    "        raw_export_dir (str): Directory path to save raw JSON files.\n",
    "    \"\"\"\n",
    "\n",
    "    def save_complete_data(session_id):\n",
    "        global API_invok_count\n",
    "        if API_invok_count >= 0 and not LOCAL_HOST:\n",
    "            print(\"Waiting for 4 seconds to fetch traces...\")\n",
    "            for _ in tqdm(range(4), desc=\"Progress\", unit=\"s\"):\n",
    "                sleep(1)\n",
    "            API_invok_count = 0\n",
    "\n",
    "        fetch_traces_response = langfuse.fetch_traces(session_id=session_id)\n",
    "        API_invok_count += 1\n",
    "\n",
    "        print(f\"Fetching traces for session {session_id}...\")\n",
    "        # Create directories if they don't exist\n",
    "        os.makedirs(raw_export_dir, exist_ok=True)\n",
    "\n",
    "        # Save complete data to JSON file\n",
    "        # if session_id.startswith(\"da0a\"):\n",
    "        #     session_id = \"phi4_\" + session_id\n",
    "        if \"tpsg\" in session_id:\n",
    "            session_id_ = session_id.replace(\"tpsg\", \"tpusg\")\n",
    "        else:\n",
    "            session_id_ = session_id\n",
    "            \n",
    "        raw_path = os.path.join(raw_export_dir, f\"raw_{session_id_}.json\")\n",
    "        with open(raw_path, \"w\") as f:\n",
    "            json.dump(fetch_traces_response, f, cls=CustomJSONEncoder, indent=2)\n",
    "\n",
    "        print(f\"Raw JSON saved to: {raw_path}\")\n",
    "\n",
    "    for session_id in session_id_list:\n",
    "        save_complete_data(session_id)\n",
    "\n",
    "\n",
    "fetch_and_save_complete_data(session_id_list, raw_export_dir, LOCAL_HOST)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Trim data\n",
    "\n",
    "Here also intercept the runs with fatal errors that need to be excluded from the analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPAN error_c5_psg_failure_signal_py_sketch_generator: Failed. Last error: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250805135314_psg_qwen2.5-coder:14b/tmp_20250805135314_psg_qwen2.5-coder:14b.py\", line 32, in <module>\n",
      "    input_data = np.frombuffer(raw_data, dtype=input_dtype).reshape(input_shape)\n",
      "ValueError: cannot reshape array of size 564314 into shape (1,300,300,3)\n",
      "\n",
      "SPAN error_d3_psg_failure_signal_py_sketch_generator: Failed. Last error: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250805135214_psg_qwen2.5-coder:14b/tmp_20250805135214_psg_qwen2.5-coder:14b.py\", line 28, in <module>\n",
      "    img = np.array(Image.open(input_path).resize((input_details[0]['shape'][1], input_details[0]['shape'][2])))\n",
      "NameError: name 'Image' is not defined\n",
      "\n",
      "SPAN error_99_psg_failure_signal_py_sketch_generator: Failed. Last error: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250805135108_psg_qwen2.5-coder:14b/tmp_20250805135108_psg_qwen2.5-coder:14b.py\", line 37, in <module>\n",
      "    input_data = input_data.reshape(input_shape)\n",
      "ValueError: cannot reshape array of size 564314 into shape (1,300,300,3)\n",
      "\n",
      "SPAN error_d9_psg_failure_signal_py_sketch_generator: Failed. Last error: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250805135007_psg_qwen2.5-coder:14b/tmp_20250805135007_psg_qwen2.5-coder:14b.py\", line 32, in <module>\n",
      "    input_data = np.frombuffer(raw_data, dtype=input_dtype).reshape(input_shape)\n",
      "ValueError: cannot reshape array of size 564314 into shape (1,300,300,3)\n",
      "\n",
      "SPAN error_1b_psg_failure_signal_py_sketch_generator: Failed. Last error: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250805134905_psg_qwen2.5-coder:14b/tmp_20250805134905_psg_qwen2.5-coder:14b.py\", line 32, in <module>\n",
      "    input_data = np.frombuffer(raw_data, dtype=input_dtype).reshape(input_shape)\n",
      "ValueError: cannot reshape array of size 564314 into shape (1,300,300,3)\n",
      "\n",
      "SPAN error_96_psg_failure_signal_py_sketch_generator: Failed. Last error: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250805134759_psg_qwen2.5-coder:14b/tmp_20250805134759_psg_qwen2.5-coder:14b.py\", line 32, in <module>\n",
      "    input_data = np.frombuffer(raw_data, dtype=input_dtype).reshape(input_shape)\n",
      "ValueError: cannot reshape array of size 564314 into shape (1,300,300,3)\n",
      "\n",
      "SPAN error_3d_psg_failure_signal_py_sketch_generator: Failed. Last error: Traceback (most recent call last):\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250805134657_psg_qwen2.5-coder:14b/tmp_20250805134657_psg_qwen2.5-coder:14b.py\", line 17, in <module>\n",
      "    interpreter = Interpreter(model_path=model_path)\n",
      "NameError: name 'Interpreter' is not defined\n",
      "\n",
      "SPAN error_bd_psg_failure_signal_py_sketch_generator: Failed. Last error: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250805134544_psg_qwen2.5-coder:14b/tmp_20250805134544_psg_qwen2.5-coder:14b.py\", line 28, in <module>\n",
      "    image = cv2.resize(image, (input_details[0]['shape'][1], input_details[0]['shape'][2]))\n",
      "cv2.error: OpenCV(4.10.0) /io/opencv/modules/imgproc/src/resize.cpp:4152: error: (-215:Assertion failed) !ssize.empty() in function 'resize'\n",
      "\n",
      "\n",
      "SPAN error_81_psg_failure_signal_py_sketch_generator: Failed. Last error: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250805134440_psg_qwen2.5-coder:14b/tmp_20250805134440_psg_qwen2.5-coder:14b.py\", line 28, in <module>\n",
      "    image = cv2.resize(image, (input_details[0]['shape'][1], input_details[0]['shape'][2]))\n",
      "cv2.error: OpenCV(4.10.0) /io/opencv/modules/imgproc/src/resize.cpp:4152: error: (-215:Assertion failed) !ssize.empty() in function 'resize'\n",
      "\n",
      "\n",
      "SPAN error_33_psg_failure_signal_py_sketch_generator: Failed. Last error: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250805134335_psg_qwen2.5-coder:14b/tmp_20250805134335_psg_qwen2.5-coder:14b.py\", line 32, in <module>\n",
      "    input_data = np.frombuffer(raw_data, dtype=input_dtype).reshape(input_shape)\n",
      "ValueError: cannot reshape array of size 564314 into shape (1,300,300,3)\n",
      "\n",
      "SPAN error_02_psg_failure_signal_py_sketch_generator: Failed. Last error: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250805134234_psg_qwen2.5-coder:14b/tmp_20250805134234_psg_qwen2.5-coder:14b.py\", line 39, in <module>\n",
      "    interpreter.set_tensor(input_details[0]['index'], input_data)\n",
      "  File \"/home/wuguangh/.conda/envs/tinyml/lib/python3.10/site-packages/tflite_runtime/interpreter.py\", line 720, in set_tensor\n",
      "    self._interpreter.SetTensor(tensor_index, value)\n",
      "ValueError: Cannot set tensor: Got value of type FLOAT32 but expected type UINT8 for input 175, name: normalized_input_image_tensor \n",
      "\n",
      "SPAN error_43_psg_failure_signal_py_sketch_generator: Failed. Last error: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250805134132_psg_qwen2.5-coder:14b/tmp_20250805134132_psg_qwen2.5-coder:14b.py\", line 32, in <module>\n",
      "    input_data = np.frombuffer(raw_data, dtype=input_dtype).reshape(input_shape)\n",
      "ValueError: cannot reshape array of size 564314 into shape (1,300,300,3)\n",
      "\n",
      "SPAN error_04_psg_failure_signal_py_sketch_generator: Failed. Last error: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250805134029_psg_qwen2.5-coder:14b/tmp_20250805134029_psg_qwen2.5-coder:14b.py\", line 32, in <module>\n",
      "    input_data = np.frombuffer(raw_data, dtype=input_dtype).reshape(input_shape)\n",
      "ValueError: cannot reshape array of size 564314 into shape (1,300,300,3)\n",
      "\n",
      "SPAN error_2f_psg_failure_signal_py_sketch_generator: Failed. Last error: Traceback (most recent call last):\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250805133929_psg_qwen2.5-coder:14b/tmp_20250805133929_psg_qwen2.5-coder:14b.py\", line 16, in <module>\n",
      "    interpreter = Interpreter(model_path=model_path)\n",
      "NameError: name 'Interpreter' is not defined\n",
      "\n",
      "SPAN error_b9_psg_failure_signal_py_sketch_generator: Failed. Last error: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250805133820_psg_qwen2.5-coder:14b/tmp_20250805133820_psg_qwen2.5-coder:14b.py\", line 32, in <module>\n",
      "    input_data = np.frombuffer(raw_data, dtype=input_dtype).reshape(input_shape)\n",
      "ValueError: cannot reshape array of size 564314 into shape (1,300,300,3)\n",
      "\n",
      "SPAN error_94_psg_failure_signal_py_sketch_generator: Failed. Last error: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250805133719_psg_qwen2.5-coder:14b/tmp_20250805133719_psg_qwen2.5-coder:14b.py\", line 32, in <module>\n",
      "    input_data = np.frombuffer(raw_data, dtype=input_dtype).reshape(input_shape)\n",
      "ValueError: cannot reshape array of size 564314 into shape (1,300,300,3)\n",
      "\n",
      "SPAN error_bb_psg_failure_signal_py_sketch_generator: Failed. Last error: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "qt.qpa.xcb: could not connect to display \n",
      "qt.qpa.plugin: Could not load the Qt platform plugin \"xcb\" in \"/home/wuguangh/.conda/envs/tinyml/lib/python3.10/site-packages/cv2/qt/plugins\" even though it was found.\n",
      "This application failed to start because no Qt platform plugin could be initialized. Reinstalling the application may fix this problem.\n",
      "\n",
      "Available platform plugins are: xcb.\n",
      "\n",
      "\n",
      "SPAN error_10_psg_failure_signal_py_sketch_generator: Failed. Last error: Traceback (most recent call last):\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250805133507_psg_qwen2.5-coder:14b/tmp_20250805133507_psg_qwen2.5-coder:14b.py\", line 16, in <module>\n",
      "    interpreter = Interpreter(model_path=model_path)\n",
      "NameError: name 'Interpreter' is not defined\n",
      "\n",
      "SPAN error_9e_psg_failure_signal_py_sketch_generator: Failed. Last error: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250805133358_psg_qwen2.5-coder:14b/tmp_20250805133358_psg_qwen2.5-coder:14b.py\", line 32, in <module>\n",
      "    input_data = np.frombuffer(raw_data, dtype=input_dtype).reshape(input_shape)\n",
      "ValueError: cannot reshape array of size 564314 into shape (1,300,300,3)\n",
      "\n",
      "SPAN error_b6_psg_failure_signal_py_sketch_generator: Failed. Last error: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250805133255_psg_qwen2.5-coder:14b/tmp_20250805133255_psg_qwen2.5-coder:14b.py\", line 28, in <module>\n",
      "    image = cv2.resize(image, (input_details[0]['shape'][1], input_details[0]['shape'][2]))\n",
      "cv2.error: OpenCV(4.10.0) /io/opencv/modules/imgproc/src/resize.cpp:4152: error: (-215:Assertion failed) !ssize.empty() in function 'resize'\n",
      "\n",
      "\n",
      "SPAN error_e5_psg_failure_signal_py_sketch_generator: Failed. Last error: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250805133148_psg_qwen2.5-coder:14b/tmp_20250805133148_psg_qwen2.5-coder:14b.py\", line 32, in <module>\n",
      "    input_data = np.frombuffer(raw_data, dtype=input_dtype).reshape(input_shape)\n",
      "ValueError: cannot reshape array of size 564314 into shape (1,300,300,3)\n",
      "\n",
      "SPAN error_de_psg_failure_signal_py_sketch_generator: Failed. Last error: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250805133047_psg_qwen2.5-coder:14b/tmp_20250805133047_psg_qwen2.5-coder:14b.py\", line 35, in <module>\n",
      "    input_data = np.frombuffer(raw_data, dtype=input_dtype).reshape(input_shape)\n",
      "ValueError: cannot reshape array of size 564314 into shape (1,300,300,3)\n",
      "\n",
      "SPAN error_1e_psg_failure_signal_py_sketch_generator: Failed. Last error: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250805132942_psg_qwen2.5-coder:14b/tmp_20250805132942_psg_qwen2.5-coder:14b.py\", line 32, in <module>\n",
      "    input_data = np.frombuffer(raw_data, dtype=input_dtype).reshape(input_shape)\n",
      "ValueError: cannot reshape array of size 564314 into shape (1,300,300,3)\n",
      "\n",
      "SPAN error_ac_psg_failure_signal_py_sketch_generator: Failed. Last error: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250805132843_psg_qwen2.5-coder:14b/tmp_20250805132843_psg_qwen2.5-coder:14b.py\", line 28, in <module>\n",
      "    img = np.array(Image.open(input_path).resize((input_details[0]['shape'][1], input_details[0]['shape'][2])), dtype=np.float32)\n",
      "NameError: name 'Image' is not defined\n",
      "\n",
      "SPAN error_2b_psg_failure_signal_py_sketch_generator: Failed. Last error: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250805132736_psg_qwen2.5-coder:14b/tmp_20250805132736_psg_qwen2.5-coder:14b.py\", line 32, in <module>\n",
      "    input_data = preprocess_frame(frame, input_details)\n",
      "NameError: name 'preprocess_frame' is not defined\n",
      "\n",
      "SPAN error_87_psg_failure_signal_py_sketch_generator: Failed. Last error: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250805132624_psg_qwen2.5-coder:14b/tmp_20250805132624_psg_qwen2.5-coder:14b.py\", line 32, in <module>\n",
      "    input_data = np.frombuffer(raw_data, dtype=input_dtype).reshape(input_shape)\n",
      "ValueError: cannot reshape array of size 564314 into shape (1,300,300,3)\n",
      "\n",
      "SPAN error_de_psg_failure_signal_py_sketch_generator: Failed. Last error: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250805132523_psg_qwen2.5-coder:14b/tmp_20250805132523_psg_qwen2.5-coder:14b.py\", line 30, in <module>\n",
      "    input_data = np.frombuffer(raw_data, dtype=np.uint8).reshape(input_details[0]['shape'])\n",
      "ValueError: cannot reshape array of size 564314 into shape (1,300,300,3)\n",
      "\n",
      "SPAN error_7e_psg_failure_signal_py_sketch_generator: Failed. Last error: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250805132412_psg_qwen2.5-coder:14b/tmp_20250805132412_psg_qwen2.5-coder:14b.py\", line 32, in <module>\n",
      "    input_data = np.frombuffer(raw_data, dtype=input_dtype).reshape(input_shape)\n",
      "ValueError: cannot reshape array of size 564314 into shape (1,300,300,3)\n",
      "\n",
      "SPAN error_c4_psg_failure_signal_py_sketch_generator: Failed. Last error: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250805132311_psg_qwen2.5-coder:14b/tmp_20250805132311_psg_qwen2.5-coder:14b.py\", line 28, in <module>\n",
      "    img = np.load(input_path)  # Example loading, replace with actual image loading\n",
      "  File \"/home/wuguangh/.conda/envs/tinyml/lib/python3.10/site-packages/numpy/lib/npyio.py\", line 462, in load\n",
      "    raise ValueError(\"Cannot load file containing pickled data \"\n",
      "ValueError: Cannot load file containing pickled data when allow_pickle=False\n",
      "\n",
      "SPAN error_1d_psg_failure_signal_py_sketch_generator: Failed. Last error: Traceback (most recent call last):\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250805132205_psg_qwen2.5-coder:14b/tmp_20250805132205_psg_qwen2.5-coder:14b.py\", line 16, in <module>\n",
      "    interpreter = Interpreter(model_path=model_path)\n",
      "NameError: name 'Interpreter' is not defined\n",
      "\n",
      "Successfully processed and saved trimmed data for session qwen2.5-coder:14b_33b8_psg_batch\n",
      "Successfully processed and saved trimmed data for session qwen2.5-coder:14b_33b8_tpusg_batch\n",
      "Total 0 traces skipped. They are []\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "skipped_traces = []\n",
    "\n",
    "\n",
    "def process_existing_observation(observation):\n",
    "    \"\"\"\n",
    "    Processes an existing observation dictionary by trimming unwanted keys.\n",
    "    \"\"\"\n",
    "    unwanted_observation_keys = [\n",
    "        \"completionStartTime\",\n",
    "        \"metadata\",\n",
    "        \"timeToFirstToken\",\n",
    "        \"createdAt\",\n",
    "        \"usageDetails\",\n",
    "        \"usage\",\n",
    "        \"projectId\",\n",
    "        \"unit\",\n",
    "        \"updatedAt\",\n",
    "        \"version\",\n",
    "        \"parentObservationId\",\n",
    "        \"promptId\",\n",
    "        \"promptName\",\n",
    "        \"promptVersion\",\n",
    "        \"modelId\",\n",
    "        \"inputPrice\",\n",
    "        \"outputPrice\",\n",
    "        \"totalPrice\",\n",
    "        # \"modelParameters\",\n",
    "        \"input\",\n",
    "        \"output\",\n",
    "    ]\n",
    "\n",
    "    # If observation is a dictionary containing observation data\n",
    "    if isinstance(observation, dict):\n",
    "        trimmed_observation = {\n",
    "            k: v for k, v in observation.items() if k not in unwanted_observation_keys\n",
    "        }\n",
    "        return trimmed_observation\n",
    "    return observation\n",
    "\n",
    "\n",
    "def trim_data(data):\n",
    "    \"\"\"\n",
    "    Recursively trims the data structure.\n",
    "    \"\"\"\n",
    "\n",
    "    if isinstance(data, dict):\n",
    "        # Process the current dictionary\n",
    "        unwanted_trace_keys = [\n",
    "            \"release\",\n",
    "            \"version\",\n",
    "            \"user_id\",\n",
    "            \"public\",\n",
    "            \"html_path\",\n",
    "            \"scores\",\n",
    "            \"bookmarked\",\n",
    "            \"projectId\",\n",
    "            \"externalId\",\n",
    "            \"page\",\n",
    "            \"limit\",\n",
    "            \"total_pages\",\n",
    "        ]\n",
    "\n",
    "        # If this is a trace that contains observations, check for fatal errors\n",
    "        if \"observations\" in data:\n",
    "            # Check for SPAN observations with fatal errors before processing\n",
    "            skip_trace = False\n",
    "            for obs in data[\"observations\"]:\n",
    "                if isinstance(obs, dict) and obs.get(\"name\").startswith(\"error\"):\n",
    "                    status_message = obs.get(\"statusMessage\", \"\")\n",
    "                    ob_name = obs.get(\"name\")\n",
    "                    print(f\"SPAN {ob_name}: {status_message}\")\n",
    "\n",
    "                    if \"Fatal error\" in status_message:\n",
    "                        print(f\"Found Fatal error in SPAN observation, skipping trace\")\n",
    "                        skip_trace = True\n",
    "                        skipped_traces.append(data[\"name\"])\n",
    "                        break\n",
    "\n",
    "            if skip_trace:\n",
    "                return None  # Signal to skip this trace\n",
    "\n",
    "        # Create a new dictionary with wanted keys and recursively process values\n",
    "        trimmed_data = {}\n",
    "        for key, value in data.items():\n",
    "            if key not in unwanted_trace_keys:\n",
    "                if key == \"observations\":\n",
    "                    # Special handling for observations\n",
    "                    trimmed_data[key] = [\n",
    "                        process_existing_observation(obs) for obs in value\n",
    "                    ]\n",
    "                elif isinstance(value, (dict, list)):\n",
    "                    # Recursively process nested structures\n",
    "                    trimmed_data[key] = trim_data(value)\n",
    "                else:\n",
    "                    trimmed_data[key] = value\n",
    "\n",
    "        return trimmed_data\n",
    "\n",
    "    elif isinstance(data, list):\n",
    "        # Recursively process each item in the list\n",
    "        processed_items = []\n",
    "        for item in data:\n",
    "            processed_item = trim_data(item)\n",
    "            if processed_item is not None:  # Only add items that weren't filtered out\n",
    "                processed_items.append(processed_item)\n",
    "        return processed_items\n",
    "\n",
    "    else:\n",
    "        # Return non-dict, non-list values as is\n",
    "        return data\n",
    "\n",
    "\n",
    "def read_and_trim_data(session_id_list, raw_export_dir, trimmed_export_dir):\n",
    "    \"\"\"\n",
    "    Reads complete data from JSON files, trims the data, and saves the trimmed data to new JSON files.\n",
    "    \"\"\"\n",
    "    os.makedirs(trimmed_export_dir, exist_ok=True)\n",
    "\n",
    "    for session_id in session_id_list:\n",
    "        try:\n",
    "            if session_id.startswith(\"da0a\"):\n",
    "                session_id = \"phi4_\" + session_id\n",
    "            # Read raw data\n",
    "            if \"tpsg\" in session_id:\n",
    "                session_id_ = session_id.replace(\"tpsg\", \"tpusg\")\n",
    "            else:\n",
    "                session_id_ = session_id\n",
    "            raw_path = os.path.join(raw_export_dir, f\"raw_{session_id_}.json\")\n",
    "            with open(raw_path, \"r\") as f:\n",
    "                data = json.load(f)\n",
    "\n",
    "            # Process and trim the data\n",
    "            trimmed_data = trim_data(data)\n",
    "\n",
    "            # If the entire data was filtered out (unlikely but possible)\n",
    "            if trimmed_data is None:\n",
    "                print(\n",
    "                    f\"All traces in session {session_id} were filtered due to fatal errors\"\n",
    "                )\n",
    "                continue\n",
    "\n",
    "            # Save trimmed data\n",
    "            if \"tpsg\" in session_id:\n",
    "                session_id_ = session_id.replace(\"tpsg\", \"tpusg\")\n",
    "            else:\n",
    "                session_id_ = session_id\n",
    "            trimmed_path = os.path.join(\n",
    "                trimmed_export_dir, f\"trimmed_{session_id_}.json\"\n",
    "            )\n",
    "            with open(trimmed_path, \"w\") as f:\n",
    "                json.dump(trimmed_data, f, indent=2)\n",
    "\n",
    "            print(\n",
    "                f\"Successfully processed and saved trimmed data for session {session_id}\"\n",
    "            )\n",
    "\n",
    "            # Optional: Verify trimming worked\n",
    "            # print(f\"Verifying trimmed data for session {session_id}...\")\n",
    "            # verify_trimming(trimmed_path)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing session {session_id}: {str(e)}\")\n",
    "\n",
    "\n",
    "def verify_trimming(trimmed_path):\n",
    "    \"\"\"\n",
    "    Verifies that the trimmed data doesn't contain unwanted keys.\n",
    "    \"\"\"\n",
    "    with open(trimmed_path, \"r\") as f:\n",
    "        trimmed_data = json.load(f)\n",
    "\n",
    "    unwanted_keys = [\n",
    "        \"release\",\n",
    "        \"version\",\n",
    "        \"user_id\",\n",
    "        \"public\",\n",
    "        \"html_path\",\n",
    "        \"scores\",\n",
    "        \"bookmarked\",\n",
    "        \"projectId\",\n",
    "        \"externalId\",\n",
    "        \"page\",\n",
    "        \"limit\",\n",
    "        \"total_pages\",\n",
    "        \"completionStartTime\",\n",
    "        \"metadata\",\n",
    "        \"usageDetails\",\n",
    "        \"timeToFirstToken\",\n",
    "        \"createdAt\",\n",
    "        \"completionTokens\",\n",
    "        \"promptTokens\",\n",
    "        \"projectId\",\n",
    "        \"unit\",\n",
    "        \"updatedAt\",\n",
    "        \"version\",\n",
    "        # \"statusMessage\",\n",
    "        \"parentObservationId\",\n",
    "        \"promptId\",\n",
    "        \"promptName\",\n",
    "        \"promptVersion\",\n",
    "        \"modelId\",\n",
    "        \"inputPrice\",\n",
    "        \"outputPrice\",\n",
    "        \"totalPrice\",\n",
    "        \"calculatedInputCost\",\n",
    "        \"calculatedOutputCost\",\n",
    "        \"calculatedTotalCost\",\n",
    "    ]\n",
    "\n",
    "    def check_keys(obj):\n",
    "        if isinstance(obj, dict):\n",
    "            for key in obj.keys():\n",
    "                if key in unwanted_keys:\n",
    "                    print(f\"Warning: Found unwanted key '{key}' in trimmed data\")\n",
    "            for value in obj.values():\n",
    "                check_keys(value)\n",
    "        elif isinstance(obj, list):\n",
    "            for item in obj:\n",
    "                check_keys(item)\n",
    "\n",
    "    check_keys(trimmed_data)\n",
    "    print(\"Verification complete\")\n",
    "\n",
    "\n",
    "# Usage example:\n",
    "read_and_trim_data(session_id_list, raw_export_dir, raw_export_dir)\n",
    "print(f\"Total {len(skipped_traces)} traces skipped. They are {skipped_traces}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Generate CSV files from JSON\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing session qwen2.5-coder:14b_33b8_psg_batch, simple id qwen2.5-coder:14b_33b8. Look for /Users/hann/Projects/reference-benchmark-tinyml_llm/data_analysis/2025/08.05/raw_export/trimmed_qwen2.5-coder:14b_33b8_psg_batch.json\n",
      "/Users/hann/Projects/reference-benchmark-tinyml_llm/data_analysis/2025/08.05/processed_data/qwen2.5-coder:14b_33b8/clean_qwen2.5-coder:14b_33b8_psg_batch.csv\n",
      "Successfully saved CSV to: /Users/hann/Projects/reference-benchmark-tinyml_llm/data_analysis/2025/08.05/processed_data/qwen2.5-coder:14b_33b8/clean_qwen2.5-coder:14b_33b8_psg_batch.csv\n",
      "Processing session qwen2.5-coder:14b_33b8_tpusg_batch, simple id qwen2.5-coder:14b_33b8. Look for /Users/hann/Projects/reference-benchmark-tinyml_llm/data_analysis/2025/08.05/raw_export/trimmed_qwen2.5-coder:14b_33b8_tpusg_batch.json\n",
      "/Users/hann/Projects/reference-benchmark-tinyml_llm/data_analysis/2025/08.05/processed_data/qwen2.5-coder:14b_33b8/clean_qwen2.5-coder:14b_33b8_tpusg_batch.csv\n",
      "Successfully saved CSV to: /Users/hann/Projects/reference-benchmark-tinyml_llm/data_analysis/2025/08.05/processed_data/qwen2.5-coder:14b_33b8/clean_qwen2.5-coder:14b_33b8_tpusg_batch.csv\n"
     ]
    }
   ],
   "source": [
    "import traceback\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from dateutil import parser\n",
    "\n",
    "\n",
    "def json_to_csv(session_id):\n",
    "    \"\"\"\n",
    "    Convert JSON trace data to CSV format with aggregated metrics.\n",
    "\n",
    "    Args:\n",
    "        session_id (str): Identifier for the session to process\n",
    "    \"\"\"\n",
    "\n",
    "    def extract_observation_details(observations, trace_id):\n",
    "        \"\"\"Extract and aggregate metrics from observations\"\"\"\n",
    "        metrics = {\n",
    "            \"status\": None,\n",
    "            \"latency\": 0,\n",
    "            \"total_tokens\": 0,\n",
    "            \"prompt_tokens\": 0,\n",
    "            \"completion_tokens\": 0,\n",
    "            \"total_cost\": 0,\n",
    "            \"input_cost\": 0,\n",
    "            \"output_cost\": 0,\n",
    "            \"parameters\": set(),\n",
    "        }\n",
    "\n",
    "        # Process GENERATION observations\n",
    "        for obs in (o for o in observations if o[\"type\"] == \"GENERATION\"):\n",
    "            metrics[\"total_tokens\"] += obs[\"totalTokens\"]\n",
    "            metrics[\"prompt_tokens\"] += obs[\"promptTokens\"]\n",
    "            metrics[\"completion_tokens\"] += obs[\"completionTokens\"]\n",
    "            metrics[\"latency\"] += obs[\"latency\"]\n",
    "            for key, value in obs[\"modelParameters\"].items():\n",
    "                metrics[\"parameters\"].add(key + \":\" + value)\n",
    "\n",
    "            # Add costs if present\n",
    "            for cost_type in [\"Total\", \"Input\", \"Output\"]:\n",
    "                key = f\"calculated{cost_type}Cost\"\n",
    "                metric_key = cost_type.lower() + \"_cost\"\n",
    "                if obs.get(key) is not None:\n",
    "                    metrics[metric_key] += obs[key]\n",
    "        if len(metrics[\"parameters\"]) == 0:\n",
    "            metrics[\"parameters\"] = \"N/A\"\n",
    "        # Process SPAN observations for status\n",
    "        status_indicators = [\n",
    "            obs[\"name\"]\n",
    "            for obs in observations\n",
    "            if obs[\"type\"] == \"SPAN\" and \"start_\" not in obs[\"name\"]\n",
    "        ]\n",
    "\n",
    "        #  if later than 2025-05-19, use status_signal_from_output\n",
    "        if datetime.now() > datetime(2025, 5, 19):\n",
    "            pass\n",
    "        else:\n",
    "            # Determine status\n",
    "            success_signals = sum(\"end_\" in name for name in status_indicators)\n",
    "            failure_signals = sum(\n",
    "                \"failure_signal\" in name for name in status_indicators\n",
    "            )\n",
    "\n",
    "            if success_signals + failure_signals > 1:\n",
    "                raise ValueError(\n",
    "                    f\"Multiple status indicators found in trace {trace_id}\"\n",
    "                )\n",
    "\n",
    "            metrics[\"status\"] = (\n",
    "                \"success\"\n",
    "                if success_signals\n",
    "                else \"failure\" if failure_signals else \"unknown\"\n",
    "            )\n",
    "\n",
    "        metrics[\"prompt_cost\"] = metrics.pop(\"input_cost\")\n",
    "        metrics[\"completion_cost\"] = metrics.pop(\"output_cost\")\n",
    "        metrics[\"latency\"] = round(metrics[\"latency\"] / 1000, 2)\n",
    "        return metrics\n",
    "\n",
    "    def cal_time(trace):\n",
    "        time_diff = datetime.fromisoformat(\n",
    "            trace[\"updatedAt\"].replace(\"Z\", \"+00:00\")\n",
    "        ) - datetime.fromisoformat(trace[\"createdAt\"].replace(\"Z\", \"+00:00\"))\n",
    "        seconds_diff = time_diff.total_seconds()\n",
    "        return seconds_diff\n",
    "\n",
    "    try:\n",
    "\n",
    "        if session_id.startswith(\"da0a\"):\n",
    "            session_id = \"phi4_\" + session_id\n",
    "        simple_session_id = session_id.rsplit(\"_\", 2)[0]\n",
    "\n",
    "        \n",
    "        # Load JSON data\n",
    "        if \"tpsg\" in session_id:\n",
    "                session_id_ = session_id.replace(\"tpsg\", \"tpusg\")\n",
    "        else:\n",
    "                session_id_ = session_id\n",
    "        trimmed_path = os.path.join(raw_export_dir, f\"trimmed_{session_id_}.json\")\n",
    "        print(\n",
    "            f\"Processing session {session_id}, simple id {simple_session_id}. Look for {trimmed_path}\"\n",
    "        )\n",
    "        with open(trimmed_path, \"r\") as file:\n",
    "            traces = json.load(file)[\"data\"]\n",
    "\n",
    "        # Process traces\n",
    "        rows = [\n",
    "            {\n",
    "                \"num_run\": trace[\"metadata\"][\"num_run\"],\n",
    "                \"name\": trace[\"name\"],\n",
    "                \"trace_id\": trace[\"id\"],\n",
    "                \"batch_id\": trace[\"session_id\"],\n",
    "                # \"latency\": cal_time(trace),\n",
    "                # \"latency\": round(trace[\"latency\"], 2),\n",
    "                **extract_observation_details(\n",
    "                    trace[\"observations\"],\n",
    "                    trace[\"id\"],\n",
    "                ),\n",
    "                \"status\": (\n",
    "                    \"failure\"\n",
    "                    if trace[\"output\"][\"status\"].lower() == \"failed\"\n",
    "                    else \"success\"\n",
    "                ),\n",
    "                \"tags\": trace[\"tags\"],\n",
    "                \"timestamp\": int(parser.isoparse(trace[\"timestamp\"]).timestamp()),\n",
    "            }\n",
    "            for trace in traces\n",
    "        ]\n",
    "        # print(rows)\n",
    "        # print(rows)\n",
    "        # Create and save DataFrame\n",
    "        df = pd.DataFrame(rows).sort_values(\"num_run\")\n",
    "\n",
    "        output_dir = os.path.join(processed_data_dir, f\"{simple_session_id}\")\n",
    "        if not os.path.exists(output_dir):\n",
    "            os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "        output_path = os.path.join(output_dir, f\"clean_{session_id_}.csv\")\n",
    "\n",
    "        print(output_path)\n",
    "        df.to_csv(output_path, index=False)\n",
    "        print(f\"Successfully saved CSV to: {output_path}\")\n",
    "\n",
    "    except FileNotFoundError as e:\n",
    "        print(\n",
    "            f\"FileNotFoundError: For session {session_id} not found. Looked for {trimmed_path}\\nError info: \\n{e}\\n\\nTraceback: {traceback.format_exc()}\"\n",
    "        )\n",
    "    except json.JSONDecodeError:\n",
    "        print(f\"Error: Invalid JSON format in input file for session {session_id}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing session {session_id}: {str(e)}\")\n",
    "\n",
    "\n",
    "# Example usage\n",
    "for session_id in session_id_list:\n",
    "    json_to_csv(session_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code below is archived\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"\"\"Simply calculate success rate\"\"\"\n",
    "\n",
    "\n",
    "# def cal_success_rate(session_id):\n",
    "\n",
    "#     end_signal_count = 0\n",
    "#     failure_signal_count = 0\n",
    "#     # Function to print the name of each observation\n",
    "#     with open(f\"{raw_export_dir}/trimmed_{session_id}.json\", \"r\") as file:\n",
    "#         data = json.load(file)[\"data\"]\n",
    "#     for i in data:\n",
    "\n",
    "#         observations = i[\"observations\"]\n",
    "\n",
    "#         for observation in observations:\n",
    "#             # print(type(observation))\n",
    "#             for key, value in observation.items():\n",
    "#                 # print(f\"{key}: {value}\")\n",
    "#                 for key, value in value.items():\n",
    "#                     # print(f\"{key}: {value}\")\n",
    "#                     if key == \"name\":\n",
    "#                         if \"end_\" in value:\n",
    "\n",
    "#                             end_signal_count += 1\n",
    "#                         if \"failure_signal\" in value:\n",
    "\n",
    "#                             failure_signal_count += 1\n",
    "\n",
    "#     print(f\"Session ID: {session_id}\")\n",
    "#     total_count = end_signal_count + failure_signal_count\n",
    "#     if total_count > 0:\n",
    "#         success_rate = end_signal_count / total_count\n",
    "#         print(f\"Success rate: {success_rate:.4f}\")\n",
    "#     else:\n",
    "#         print(\"Success rate: N/A (no signals found)\")\n",
    "#     print(f\"Passed:\\t{end_signal_count}\\nFailed:\\t{failure_signal_count}\")\n",
    "#     print(\n",
    "#         \"\"\n",
    "#         if total_count == 30\n",
    "#         else \"Number of ending signals does not match the expected number!\"\n",
    "#     )\n",
    "#     print(\"-\" * 50)\n",
    "\n",
    "\n",
    "# for session_id in session_id_list:\n",
    "#     cal_success_rate(session_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def cal_time(start_time, end_time):\n",
    "#     time_diff = datetime.fromisoformat(\n",
    "#         end_time.replace(\"Z\", \"+00:00\")\n",
    "#     ) - datetime.fromisoformat(start_time.replace(\"Z\", \"+00:00\"))\n",
    "#     seconds_diff = time_diff.total_seconds()\n",
    "#     return seconds_diff\n",
    "\n",
    "\n",
    "# print(cal_time(\"2025-01-15T03:31:56.150000+00:00\", \"2025-01-15T03:32:59.384Z\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"\"\"Print the complete structure of exported json file\"\"\"\n",
    "# def print_keys(d, parent_key=''):\n",
    "#     if isinstance(d, dict):\n",
    "#         for key, value in d.items():\n",
    "#             full_key = f\"{parent_key}.{key}\" if parent_key else key\n",
    "#             print(full_key)\n",
    "#             print_keys(value, full_key)\n",
    "#     elif isinstance(d, list):\n",
    "#         for i, item in enumerate(d):\n",
    "#             full_key = f\"{parent_key}[{i}]\"\n",
    "#             print_keys(item, full_key)\n",
    "\n",
    "# # Load JSON data from a file\n",
    "# with open('fetch_traces_response.json', 'r') as file:\n",
    "#     data = json.load(file)['data'][0]\n",
    "# # Print all keys\n",
    "# print_keys(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1747226053\n",
      "1747226053.1\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "from dateutil import parser\n",
    "\n",
    "timestamp_str = \"2025-05-14T12:34:13.100000+00:00\"\n",
    "dt = parser.isoparse(\n",
    "    timestamp_str\n",
    ")  # Or datetime.fromisoformat(timestamp_str) if no timezone offset\n",
    "unix_ts = int(dt.timestamp())\n",
    "\n",
    "print(unix_ts)  # This will print the integer Unix timestamp\n",
    "print(datetime.fromisoformat(timestamp_str).timestamp())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datasci2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setting up\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ref: https://langfuse.com/docs/query-traces\n",
    "import os\n",
    "import json\n",
    "from langfuse import Langfuse\n",
    "import json\n",
    "import os\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "LOCAL_HOST = True\n",
    "\n",
    "\"\"\"Define session_id\"\"\"\n",
    "# session_id=\"qwen2.5-coder_f4d4_dp_batch\"\n",
    "session_id_list = [\n",
    "    # \"qwen2.5-coder:32b_4e11_tpsg_batch\",\n",
    "    # \"qwen2.5-coder:32b_ae24_tpsg_batch\"\n",
    "    \"qwen2.5-coder:32b_c8a6_tpusg_batch\",\n",
    "    \"qwen2.5-coder:32b_57d5_psg_batch\"\n",
    "]\n",
    "\n",
    "\n",
    "\"\"\"Define paths\"\"\"\n",
    " \n",
    "parent_dir = os.path.dirname(os.getcwd())\n",
    "\n",
    " \n",
    "# date = os.path.basename(parent_dir)\n",
    "tex_dir = os.path.join(parent_dir, \"tex\")\n",
    "processed_data_dir = os.path.join(parent_dir, \"processed_data\")\n",
    "raw_export_dir = os.path.join(parent_dir, \"raw_export\")\n",
    "ipynb_dir = os.path.join(parent_dir, \"ipynb\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Export raw data\n",
    "\n",
    "Langfuse added a limit of 20 API invocations per minute. https://langfuse.com/faq/all/api-limits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching traces for session qwen2.5-coder:32b_c8a6_tpusg_batch...\n",
      "Fetching observation data for time-05-44-21-817331_chatcmpl-54d43908-60cf-467b-878c-9a4bc79f8348...\n",
      "Fetching observation data for time-05-44-55-412961_chatcmpl-05b5f5ba-9a2d-4429-a209-c1c17211b72a...\n",
      "Fetching observation data for time-05-45-35-133966_chatcmpl-2af6b957-6fc8-4c37-a2c5-255d4d4c8c89...\n",
      "Fetching observation data for time-05-46-15-341151_chatcmpl-5546cb3e-a1ab-4560-92d1-952a87c74ff1...\n",
      "Fetching observation data for time-05-46-54-813023_chatcmpl-dcf7539c-cbf9-421c-8dc7-5d1f1ce85bb4...\n",
      "Fetching observation data for d3a4a7f3-3b42-4e3f-96eb-8c64b0db115d...\n",
      "Fetching observation data for time-05-41-01-230099_chatcmpl-e68009e1-531b-4faf-9000-bac327e88ca7...\n",
      "Fetching observation data for time-05-41-34-732818_chatcmpl-310d926c-4e06-458b-b32f-ac2fdd7f867f...\n",
      "Fetching observation data for time-05-42-15-333418_chatcmpl-07145d05-85e7-44af-86e0-bec968016f68...\n",
      "Fetching observation data for time-05-42-56-048823_chatcmpl-d8c7c835-fae1-4c7a-9137-8c6364ef69ed...\n",
      "Fetching observation data for time-05-43-36-238968_chatcmpl-d89f0378-76a2-49a3-acac-e581cafcd88c...\n",
      "Fetching observation data for d5436049-eda9-49d5-9959-ddddf9735417...\n",
      "Fetching observation data for time-05-37-42-658874_chatcmpl-3d7ff1e7-2f09-4f5f-99c5-201fa2a17a38...\n",
      "Fetching observation data for time-05-38-16-805502_chatcmpl-8bd83262-0b00-49e0-ae95-b8d3b2109a93...\n",
      "Fetching observation data for time-05-38-55-938580_chatcmpl-b32b4a74-90f7-47e8-a9c0-c6f4d31748e1...\n",
      "Fetching observation data for time-05-39-35-995449_chatcmpl-f89f776d-30a9-4472-911c-564ef67e0196...\n",
      "Fetching observation data for time-05-40-15-309521_chatcmpl-494c5f24-728e-4005-af25-cc91eec2d614...\n",
      "Fetching observation data for 05c54ca2-9883-4eca-af97-7cd4c73f1bd4...\n",
      "Fetching observation data for time-05-34-07-966482_chatcmpl-baa8b294-f2d6-4f11-b51e-3733fc9f1729...\n",
      "Fetching observation data for time-05-34-41-489765_chatcmpl-ffbd3c96-b302-4f82-b927-3fe6304ab97f...\n",
      "Fetching observation data for time-05-35-22-480338_chatcmpl-7eb45ecc-a9d8-43cf-bcd6-59065bf53928...\n",
      "Fetching observation data for time-05-36-00-373730_chatcmpl-9e205609-9f59-4f51-adaf-d3a6e8d40823...\n",
      "Fetching observation data for time-05-36-39-904271_chatcmpl-f1a9dc36-679d-4533-b632-d39b8e15c0b6...\n",
      "Fetching observation data for ab19396c-b16f-488c-84a5-23b521020daf...\n",
      "Fetching observation data for time-05-30-48-170275_chatcmpl-e3399915-e6d6-49d0-aa0f-cc8b827d3465...\n",
      "Fetching observation data for time-05-31-21-725153_chatcmpl-62a49f10-c501-4ae2-9cdf-72028e9cdd56...\n",
      "Fetching observation data for time-05-32-00-830745_chatcmpl-ed0f72b6-2fd9-4ab7-9faa-c79db69192b1...\n",
      "Fetching observation data for time-05-32-40-841052_chatcmpl-68f31812-d3e8-4b95-aa36-b339590915a1...\n",
      "Fetching observation data for time-05-33-21-627895_chatcmpl-e13f42e0-0428-4e7a-80dd-75d9e1b802f0...\n",
      "Fetching observation data for e46032d9-e575-408e-a6bc-5cde5369c38e...\n",
      "Fetching observation data for time-05-27-36-534257_chatcmpl-669fd40f-d112-4c2a-8bbc-cc4ba26b13cc...\n",
      "Fetching observation data for time-05-28-10-022876_chatcmpl-e4f34b9f-4cf3-41f3-aa17-c554c6672ab2...\n",
      "Fetching observation data for time-05-28-50-830703_chatcmpl-ba52704d-d367-4c93-9a21-ec43c91a1a48...\n",
      "Fetching observation data for time-05-29-28-776790_chatcmpl-8ca9e034-b235-4231-a240-acf28be14951...\n",
      "Fetching observation data for time-05-30-08-798550_chatcmpl-026063a1-0294-4d6b-a7d4-6b4a666c6ecd...\n",
      "Fetching observation data for 5b7e2750-b584-42cb-a51a-9c18754e8ec3...\n",
      "Fetching observation data for time-05-24-11-587956_chatcmpl-3e311dc5-1faf-4d56-92b4-3a266293fd14...\n",
      "Fetching observation data for time-05-24-45-180424_chatcmpl-04b8535c-57eb-4235-acbd-02dcf0bd6248...\n",
      "Fetching observation data for time-05-25-25-766642_chatcmpl-2a0bd875-87bf-40ba-8ab8-d0f29eb58551...\n",
      "Fetching observation data for time-05-26-05-884363_chatcmpl-14c60eea-4236-4981-af28-9644075f724b...\n",
      "Fetching observation data for time-05-20-53-786026_chatcmpl-3df540a4-c1c5-4438-942c-7db6c99bd31a...\n",
      "Fetching observation data for time-05-21-27-347965_chatcmpl-ef6ccf2a-647b-460c-8037-474df06ab57a...\n",
      "Fetching observation data for time-05-22-07-867717_chatcmpl-191e5f67-1d6a-4ebe-85c9-f48b55d0e1dc...\n",
      "Fetching observation data for time-05-22-47-007138_chatcmpl-7afe4f9b-e07a-460d-b055-5e613f6c36f4...\n",
      "Fetching observation data for time-05-23-25-964848_chatcmpl-4f28963c-a653-4422-aa6a-9f4ca8726926...\n",
      "Fetching observation data for 3e6b330f-17ed-42ff-a07a-633b5b06a668...\n",
      "Fetching observation data for time-05-18-09-021239_chatcmpl-d7e6d341-e2e8-4266-acbf-a7cc660d89ec...\n",
      "Fetching observation data for time-05-18-42-630731_chatcmpl-18d6a864-b137-4d9f-b667-6d86872093d9...\n",
      "Fetching observation data for time-05-19-23-006281_chatcmpl-52158358-023c-42f6-a891-1561c479d544...\n",
      "Fetching observation data for time-05-14-51-199693_chatcmpl-85c3fbd8-bdc4-4e98-b208-ccedc6660119...\n",
      "Fetching observation data for time-05-15-25-284290_chatcmpl-d0e59c44-924d-445d-bbe6-ab405147d685...\n",
      "Fetching observation data for time-05-16-05-216026_chatcmpl-79360fb6-3091-46cc-b183-63dd6c1bfb9e...\n",
      "Fetching observation data for time-05-16-44-000298_chatcmpl-78965f55-dc33-4b14-9c90-153f437ae60f...\n",
      "Fetching observation data for time-05-17-23-309716_chatcmpl-aa953368-a189-4136-8c1a-7f5dc7f9a88b...\n",
      "Fetching observation data for a9e0b8e2-745e-4b6e-b115-99f8069f26d7...\n",
      "Fetching observation data for time-05-10-21-912108_chatcmpl-4d34ebe3-7b47-4ac2-a31f-70bd4f000a78...\n",
      "Fetching observation data for time-05-10-55-884353_chatcmpl-21c8821d-6079-4010-866b-3984c0939487...\n",
      "Fetching observation data for time-05-11-36-626510_chatcmpl-4b2a021b-261c-4f27-8f9a-28617e14c8bc...\n",
      "Fetching observation data for time-05-12-18-148242_chatcmpl-cf136741-8d9f-4ec7-9f60-6d27881cf602...\n",
      "Fetching observation data for time-05-13-20-546978_chatcmpl-45810518-733d-489d-a7b6-e970e4bee3e3...\n",
      "Fetching observation data for time-05-07-00-380666_chatcmpl-cd9e450f-3782-43c0-b5ca-655f60ffcb25...\n",
      "Fetching observation data for time-05-07-34-268345_chatcmpl-b57f3206-b5ac-4931-a435-f460bb513074...\n",
      "Fetching observation data for time-05-08-15-196594_chatcmpl-e27a3bfe-ca31-4828-bddd-1a0d2fd3ef9b...\n",
      "Fetching observation data for time-05-08-55-810239_chatcmpl-b14246a9-7471-45b3-ae63-e85e7ea8ed8c...\n",
      "Fetching observation data for time-05-09-36-650032_chatcmpl-feb22a53-15a7-44e5-bc7e-d800874b6b78...\n",
      "Fetching observation data for 53a9cea1-2509-410b-aab5-efdb202b2cd5...\n",
      "Fetching observation data for time-05-04-17-722470_chatcmpl-b8c82b94-b706-431d-ae9b-1b7a5bf18489...\n",
      "Fetching observation data for time-05-04-51-314560_chatcmpl-2d00edd9-6226-47a4-8f62-7efc0cb61943...\n",
      "Fetching observation data for time-05-05-31-432096_chatcmpl-aebb0ed3-24b1-4c14-b37a-d2631dff8d01...\n",
      "Fetching observation data for time-05-01-31-870499_chatcmpl-6daddcfd-d9de-40b1-aa3a-861ff525e1ad...\n",
      "Fetching observation data for time-05-02-05-402204_chatcmpl-c1a47dde-095a-46ff-9124-cbf2f88f862e...\n",
      "Fetching observation data for time-05-02-46-688227_chatcmpl-cbd5411c-baa4-4297-9e00-9e55ecdbf4f8...\n",
      "Fetching observation data for time-04-58-11-164017_chatcmpl-7c0d7f89-30ae-44b8-ab29-f16588893164...\n",
      "Fetching observation data for time-04-58-44-767486_chatcmpl-7d5d8072-40a5-41b1-ae2a-e2fbac161a14...\n",
      "Fetching observation data for time-04-59-24-155434_chatcmpl-076e9af4-c44d-4dd2-9686-ca91ba9fcf5f...\n",
      "Fetching observation data for time-05-00-05-569670_chatcmpl-b6171808-7e15-438e-8d69-856c3102d0e5...\n",
      "Fetching observation data for time-05-00-45-652102_chatcmpl-ebebb425-8e3d-4874-86c1-03f205199bb0...\n",
      "Fetching observation data for 31668bda-cb2b-431f-b71b-5679ffdc3275...\n",
      "Fetching observation data for time-04-54-50-475789_chatcmpl-9473a5dc-8d02-49b8-9cef-83400154d011...\n",
      "Fetching observation data for time-04-55-24-596500_chatcmpl-150f7ce9-b65f-418b-8361-63cb851867e0...\n",
      "Fetching observation data for time-04-56-03-630411_chatcmpl-f05f16f3-84cb-450d-9aa5-c4b0bfd55253...\n",
      "Fetching observation data for time-04-56-44-187229_chatcmpl-d9bfcf04-dcf6-489e-af57-4ece98d06f88...\n",
      "Fetching observation data for time-04-57-23-523732_chatcmpl-2fe13bce-9249-4ec9-9fb6-16de532f983e...\n",
      "Fetching observation data for 7386cc64-b005-4f25-9c6a-c898e4fab12a...\n",
      "Fetching observation data for time-04-50-51-665429_chatcmpl-8077c45c-3034-4728-8c8d-565aadcaee04...\n",
      "Fetching observation data for time-04-51-25-805512_chatcmpl-d093cc31-2d07-48ec-90f6-cb3743605d67...\n",
      "Fetching observation data for time-04-52-04-997067_chatcmpl-dcd045bc-449f-4fde-a659-594459d0db66...\n",
      "Fetching observation data for time-04-52-44-465372_chatcmpl-fc0eaa07-a221-483a-954b-1c158865dddf...\n",
      "Fetching observation data for time-04-53-25-860109_chatcmpl-5b6559dd-172d-4087-885a-c87d8e9f4226...\n",
      "Fetching observation data for time-04-47-31-115444_chatcmpl-e9b28ee9-50a4-45b8-aa09-e145a7b90c9d...\n",
      "Fetching observation data for time-04-48-04-850938_chatcmpl-2c1e443a-9d92-4257-bca8-ca6ca65544fd...\n",
      "Fetching observation data for time-04-48-46-872444_chatcmpl-1731ff29-9a4f-45ef-bc1d-0485efa4c5f2...\n",
      "Fetching observation data for time-04-49-25-473314_chatcmpl-4e3582b8-248b-4cbe-a35e-ce17fa5d43a7...\n",
      "Fetching observation data for time-04-50-06-519916_chatcmpl-07f2b7fc-b5a5-46ea-85d3-05cf30ea0bfd...\n",
      "Fetching observation data for 477c80ab-a0e7-49bc-9aec-3bdf968f9b0e...\n",
      "Fetching observation data for time-04-44-48-082294_chatcmpl-9f446855-d246-4ad3-8a12-adcfa3992bd3...\n",
      "Fetching observation data for time-04-45-21-750399_chatcmpl-1e5c600f-1e43-49de-bc7c-470641655b3b...\n",
      "Fetching observation data for time-04-46-01-766015_chatcmpl-b9b2dbce-bd9c-4703-91a9-5f4315caae4e...\n",
      "Fetching observation data for time-04-41-26-479493_chatcmpl-bbf014d8-a9d7-4b47-a5b2-ef1bed6a223d...\n",
      "Fetching observation data for time-04-42-00-156037_chatcmpl-a1cfa061-6ceb-40da-81df-123e97ad5023...\n",
      "Fetching observation data for time-04-42-40-283525_chatcmpl-4572b569-171e-43d0-9255-8efc42ee0787...\n",
      "Fetching observation data for time-04-43-22-174677_chatcmpl-aac051da-c098-4379-97f3-6906f37f6184...\n",
      "Fetching observation data for time-04-44-01-848803_chatcmpl-be18af81-f6fd-41a9-8159-214274365701...\n",
      "Fetching observation data for 3dec3895-b3a2-4879-9431-85b28ff2827c...\n",
      "Fetching observation data for time-04-38-06-937189_chatcmpl-006b15ae-bc06-4860-aa73-b45c9428123f...\n",
      "Fetching observation data for time-04-38-40-889196_chatcmpl-252d3b4c-e04f-4411-b248-9cbe0a99e589...\n",
      "Fetching observation data for time-04-39-19-919103_chatcmpl-7ed397e7-c7d9-4a55-87fc-40db19036113...\n",
      "Fetching observation data for time-04-39-58-962529_chatcmpl-5364c09f-9ba1-46b4-ae89-90e029c27a44...\n",
      "Fetching observation data for time-04-40-38-408360_chatcmpl-c33fd280-e297-4159-a0c8-f8a4873035db...\n",
      "Fetching observation data for 8ae57014-6349-437e-9588-3a1e2d30b6a3...\n",
      "Fetching observation data for time-04-34-46-278007_chatcmpl-1b721192-ea86-409a-ba00-6b929cff5b56...\n",
      "Fetching observation data for time-04-35-20-249428_chatcmpl-09c8838f-a832-41f8-a964-8a38c96a5c29...\n",
      "Fetching observation data for time-04-36-00-846449_chatcmpl-4f2dabdd-0b7f-4779-b3d1-f77d1ea05547...\n",
      "Fetching observation data for time-04-36-39-069957_chatcmpl-2c2a9ef7-1db1-4df2-91d6-d55874075b27...\n",
      "Fetching observation data for time-04-37-19-499635_chatcmpl-9558af89-c5ef-408e-9eec-9755a09edfad...\n",
      "Fetching observation data for cf85fa60-bcb2-457c-ba39-384ffd8c9b87...\n",
      "Fetching observation data for time-04-31-27-733866_chatcmpl-1da676fb-34f3-4fc8-b9f7-1c9e1c849d80...\n",
      "Fetching observation data for time-04-32-01-780546_chatcmpl-87f7dff5-77cc-46d0-ba59-75034d12eeaf...\n",
      "Fetching observation data for time-04-32-41-731501_chatcmpl-430f6c1d-ae82-4fa5-8765-9e92a7e54a26...\n",
      "Fetching observation data for time-04-33-22-372279_chatcmpl-58457450-992e-40ab-b987-8b0b268d7e4d...\n",
      "Fetching observation data for time-04-34-00-683626_chatcmpl-841d403b-f42b-40e2-b261-26898a0e5704...\n",
      "Fetching observation data for 43920f41-3dd0-455d-8914-2d385ec8eb2b...\n",
      "Fetching observation data for time-04-28-09-346926_chatcmpl-9b49acc5-e1c6-43dd-8fc3-94b2bb9d9afd...\n",
      "Fetching observation data for time-04-28-42-967159_chatcmpl-b1955572-f339-4f13-a351-61d2b2f42b1a...\n",
      "Fetching observation data for time-04-29-23-816104_chatcmpl-a03e675d-23a6-459a-882b-285dbb6dc046...\n",
      "Fetching observation data for time-04-30-02-183029_chatcmpl-76cfec5c-9327-4b67-956d-c2714bcd629e...\n",
      "Fetching observation data for time-04-30-41-327237_chatcmpl-560a2126-b731-4a59-a813-51435e544d57...\n",
      "Fetching observation data for 27005ef6-bbd3-4232-b51d-508200c6ff51...\n",
      "Fetching observation data for time-04-25-25-794405_chatcmpl-9fdefaab-97e9-4536-8e92-ac7170d88005...\n",
      "Fetching observation data for time-04-25-59-450259_chatcmpl-81892c48-56a5-40f0-9c60-388457ab142f...\n",
      "Fetching observation data for time-04-26-40-105781_chatcmpl-291168ab-cde8-40b1-b84f-30d1f0360feb...\n",
      "Fetching observation data for time-04-22-44-773679_chatcmpl-5eeba7f0-bad8-473d-9fd4-953b0df05e70...\n",
      "Fetching observation data for time-04-23-18-874969_chatcmpl-e364df99-96d6-472f-8651-275d1c560930...\n",
      "Fetching observation data for time-04-23-58-093486_chatcmpl-a75552ba-a714-4370-a740-b7b0e664d6eb...\n",
      "Fetching observation data for time-04-19-23-215033_chatcmpl-61637eb4-6165-4940-9239-57b82063288a...\n",
      "Fetching observation data for time-04-19-56-915641_chatcmpl-0beb9973-8a06-40f6-b864-26cc2b38857e...\n",
      "Fetching observation data for time-04-20-36-709478_chatcmpl-67f8586d-d0c7-4d87-9085-38938f2c825a...\n",
      "Fetching observation data for time-04-21-19-839428_chatcmpl-0add01fe-0fdb-4120-9491-ed537f717954...\n",
      "Fetching observation data for time-04-22-00-365491_chatcmpl-20fda290-232b-48d8-9c9f-195ae7005769...\n",
      "Fetching observation data for deea5c41-c6e7-47dd-ba50-f2c1e40ccdd5...\n",
      "Fetching observation data for time-04-16-02-102634_chatcmpl-5b6babfa-024d-4424-bb9c-93200199a963...\n",
      "Fetching observation data for time-04-16-35-661481_chatcmpl-49379187-9b52-48d9-9197-7e19bafc935c...\n",
      "Fetching observation data for time-04-17-16-158581_chatcmpl-d1c40a13-80e6-42db-8f1d-15e89294b0e1...\n",
      "Fetching observation data for time-04-17-56-902763_chatcmpl-09816634-e8a5-4262-af83-987e24dd0e9e...\n",
      "Fetching observation data for time-04-18-37-426595_chatcmpl-9a58fce4-8793-4d84-96ae-275d26d412f7...\n",
      "Fetching observation data for 21e67735-2897-46fd-8edb-4225a63e8899...\n",
      "Fetching observation data for time-04-12-46-566163_chatcmpl-0316c066-baf1-40ec-8a7b-f77e88690e04...\n",
      "Fetching observation data for time-04-13-20-335676_chatcmpl-096e790a-e961-49d8-accb-3871f0a45745...\n",
      "Fetching observation data for time-04-14-00-969911_chatcmpl-ee31b349-6a00-44a9-9c58-4984ce82a4b2...\n",
      "Fetching observation data for time-04-14-39-761607_chatcmpl-a7b9c501-a5bd-4487-9541-911d06037290...\n",
      "Fetching observation data for time-04-15-18-324209_chatcmpl-cb154c2d-f4e1-4a4a-b26a-6f5296656618...\n",
      "Fetching observation data for 06b4c00f-5696-4f2c-b384-f0cf360f79d7...\n",
      "Fetching observation data for time-04-09-27-967307_chatcmpl-7040731c-62a4-4fed-8bb2-2e88e78c10fc...\n",
      "Fetching observation data for time-04-10-01-534042_chatcmpl-c68ecd91-bbff-4fdf-8d7a-8b110cabe16b...\n",
      "Fetching observation data for time-04-10-40-600589_chatcmpl-90f55403-3c56-4f96-8a0a-6e6745e7e065...\n",
      "Fetching observation data for time-04-11-20-717107_chatcmpl-2ed0c24a-8089-4101-949b-b81f878a3c0a...\n",
      "Fetching observation data for time-04-12-00-626608_chatcmpl-b9232538-2a7e-494c-9cab-3a9a7dc1ffc6...\n",
      "Fetching observation data for c470c0f3-b8c8-4129-8ce1-f440e4631359...\n",
      "Raw JSON saved to: /Users/hann/Projects/reference-benchmark-tinyml_llm/data_analysis/2025/08.06/raw_export/raw_qwen2.5-coder:32b_c8a6_tpusg_batch.json\n",
      "Fetching traces for session qwen2.5-coder:32b_57d5_psg_batch...\n",
      "Fetching observation data for time-23-27-55-741595_chatcmpl-a6ff744d-43ef-45a7-a2d5-03c1cbdbda26...\n",
      "Fetching observation data for time-23-28-14-925348_chatcmpl-556bc454-32e3-4273-8ce5-dfe76f4d22c2...\n",
      "Fetching observation data for time-23-28-40-610515_chatcmpl-396319dc-34e4-4c2e-835e-f7f00939324a...\n",
      "Fetching observation data for time-23-29-57-952102_chatcmpl-d92fd2a4-ac86-41cc-8578-2bfe221b122b...\n",
      "Fetching observation data for time-23-30-26-156793_chatcmpl-4095e824-277d-446f-8846-9f4454e7574b...\n",
      "Fetching observation data for 878923b8-5621-48fe-85ab-e72f36105234...\n",
      "Fetching observation data for time-23-25-46-098604_chatcmpl-3f05db89-4ee8-49a9-9b7e-78de74939e86...\n",
      "Fetching observation data for time-23-26-05-279894_chatcmpl-b69892fb-2d21-4c10-a28e-418b103fac83...\n",
      "Fetching observation data for time-23-26-31-262876_chatcmpl-36acab63-e75d-4a03-96a2-1805c873e7c1...\n",
      "Fetching observation data for time-23-26-54-880348_chatcmpl-e306c56b-5ee7-4461-af9c-7a9729ce0017...\n",
      "Fetching observation data for time-23-27-20-805147_chatcmpl-6b257e21-e4f2-444e-bf9c-9104d7bdb87c...\n",
      "Fetching observation data for dbb6423b-4032-4c75-a021-854fb35923ad...\n",
      "Fetching observation data for time-23-23-30-984683_chatcmpl-6dafde16-664c-41f0-8c96-a6cd2e154557...\n",
      "Fetching observation data for time-23-23-50-188729_chatcmpl-288678be-dd30-45a5-ba4f-d450a1358885...\n",
      "Fetching observation data for time-23-24-13-238917_chatcmpl-eea2c4ea-cd9d-4580-b441-9dae45a19502...\n",
      "Fetching observation data for time-23-24-39-699722_chatcmpl-092ea201-b1b6-4601-bbb6-cee48aca6ff4...\n",
      "Fetching observation data for time-23-20-51-358796_chatcmpl-022aad66-bb27-4d64-b830-9d00504e3394...\n",
      "Fetching observation data for time-23-21-10-552064_chatcmpl-d6d3ce88-265d-40bd-a924-0e17b1b6aa51...\n",
      "Fetching observation data for time-23-21-38-284325_chatcmpl-062a8d15-5064-4f10-b64b-058526f53435...\n",
      "Fetching observation data for time-23-22-02-001350_chatcmpl-3ecf01ef-2302-47a8-80ea-73fe9b0f26f8...\n",
      "Fetching observation data for time-23-22-29-217023_chatcmpl-d2966039-8e34-4940-9cbc-abbdbb55e623...\n",
      "Fetching observation data for time-23-18-31-393002_chatcmpl-2e6509a4-5a63-4eac-80d1-ae73a92d7390...\n",
      "Fetching observation data for time-23-18-50-590645_chatcmpl-75a40d30-caf6-45ff-b3b4-0dc2a5118cd3...\n",
      "Fetching observation data for time-23-19-15-737750_chatcmpl-5147a392-cf13-4dd3-a98c-f9982c7bfc6b...\n",
      "Fetching observation data for time-23-19-40-148870_chatcmpl-d87f0a3d-5898-4df1-be5a-5259e8795441...\n",
      "Fetching observation data for time-23-16-15-042462_chatcmpl-792be6b1-c0e6-434c-9b5e-4fd1e4565f7f...\n",
      "Fetching observation data for time-23-16-34-241144_chatcmpl-bedd7454-ac1b-427b-b4e3-48246c23edb6...\n",
      "Fetching observation data for time-23-16-59-693077_chatcmpl-ed9e21c1-a8c5-422c-861d-f5f37fc42ccd...\n",
      "Fetching observation data for time-23-17-24-126672_chatcmpl-a38ed2df-5447-4a78-a756-1cfb17bc0141...\n",
      "Fetching observation data for time-23-17-53-538372_chatcmpl-f067065f-f58a-4918-9664-e5891ee79d80...\n",
      "Fetching observation data for d9e47ab4-eae9-407c-8448-602336eba872...\n",
      "Fetching observation data for time-23-13-18-199994_chatcmpl-5438764f-3333-48d1-b8ed-02bcedb5dae6...\n",
      "Fetching observation data for time-23-13-37-379849_chatcmpl-ea4c79d4-67b6-4d9a-8190-eb44230914ae...\n",
      "Fetching observation data for time-23-14-01-360943_chatcmpl-21003092-a7ec-4fec-9bc4-6e529fd216f7...\n",
      "Fetching observation data for time-23-15-17-661828_chatcmpl-287b6cc6-d01b-4019-a4ec-55870648fe2d...\n",
      "Fetching observation data for time-23-15-42-182110_chatcmpl-57fa0b0b-a59f-467a-b924-ef253c2a1397...\n",
      "Fetching observation data for 52f604ac-0db6-4f4c-8d60-0e26ac28c228...\n",
      "Fetching observation data for time-23-11-04-304883_chatcmpl-6c98fde3-716f-4eb5-a576-430c0e0b2413...\n",
      "Fetching observation data for time-23-11-23-518785_chatcmpl-6899a604-4a0e-45d7-aa43-3f869115d94b...\n",
      "Fetching observation data for time-23-11-46-906330_chatcmpl-b61b132f-def5-4ca0-85d5-6a141e593d37...\n",
      "Fetching observation data for time-23-12-14-398503_chatcmpl-bf7ad286-2dcd-4263-9d81-8c66da29b6e9...\n",
      "Fetching observation data for time-23-09-00-486970_chatcmpl-ae69bf33-953c-4dfe-a2c0-f0fd1db8611f...\n",
      "Fetching observation data for time-23-09-19-671743_chatcmpl-fde7f4ac-ed2d-4a52-a3e6-bb6bccaabf61...\n",
      "Fetching observation data for time-23-09-43-043067_chatcmpl-5133508d-2b9f-41fa-bc9a-045d112492f7...\n",
      "Fetching observation data for time-23-10-07-809811_chatcmpl-c32b0cc9-3b08-4b77-a4d3-78143bac1bb9...\n",
      "Fetching observation data for time-23-10-30-864598_chatcmpl-9fe2c80b-d195-43a5-9937-32f76923fd5e...\n",
      "Fetching observation data for 152fa6de-fff6-4f75-a7e6-eeccb0e28b27...\n",
      "Fetching observation data for time-23-06-49-917443_chatcmpl-9713f3b5-0443-42a9-9869-2c0f7b4b341c...\n",
      "Fetching observation data for time-23-07-09-122889_chatcmpl-81dc7912-7873-45d4-a23a-992f5b9b7719...\n",
      "Fetching observation data for time-23-07-32-987022_chatcmpl-ff6c16c2-12de-45fc-bb75-441940f0cac6...\n",
      "Fetching observation data for time-23-07-58-667865_chatcmpl-b7dfea7d-987a-49e4-adf3-4d83ff0da8be...\n",
      "Fetching observation data for time-23-08-24-631630_chatcmpl-9e4bbcbb-42fc-4f1e-ba24-78fdcc93e7bf...\n",
      "Fetching observation data for bdd7c627-b6b1-4334-9210-aee8748d90bd...\n",
      "Fetching observation data for time-23-04-35-707532_chatcmpl-c7879e9d-cf1f-4b3f-b989-beb395e1af25...\n",
      "Fetching observation data for time-23-04-54-877985_chatcmpl-a7ee6202-4dca-4e84-982e-299269ed0c67...\n",
      "Fetching observation data for time-23-05-21-037061_chatcmpl-7e11eb1f-77bd-4b50-ac10-98b12687e9bc...\n",
      "Fetching observation data for time-23-05-45-450793_chatcmpl-6770e639-d2e7-45cb-b2c2-f3aad343028f...\n",
      "Fetching observation data for time-23-06-14-825011_chatcmpl-e4612560-61e3-47ad-b880-7b5c9c58d7f5...\n",
      "Fetching observation data for f01d9b16-220b-4772-8987-0170e5d4aa4b...\n",
      "Fetching observation data for time-23-02-28-777064_chatcmpl-d83b2d77-6155-4d54-b066-e72b9029e820...\n",
      "Fetching observation data for time-23-02-47-957014_chatcmpl-e2b31b5b-193e-49e4-9609-1169f6170e4c...\n",
      "Fetching observation data for time-23-03-11-552041_chatcmpl-2fa64217-fa85-45e3-bcc8-1680b18eb0a7...\n",
      "Fetching observation data for time-23-03-37-244176_chatcmpl-f0d2c57c-2003-4395-a600-b5d5956b0a4f...\n",
      "Fetching observation data for time-23-04-01-596585_chatcmpl-23cb28ec-e49b-404a-8045-8cc5f6b520cd...\n",
      "Fetching observation data for 2d967365-c30a-447a-b735-7b79da4f2569...\n",
      "Fetching observation data for time-23-00-15-078853_chatcmpl-e7859ee9-b5d7-415a-901d-e7574bcf93dc...\n",
      "Fetching observation data for time-23-00-34-252848_chatcmpl-6e888327-c718-4744-9d9c-35f62b2abe1c...\n",
      "Fetching observation data for time-23-00-59-711070_chatcmpl-ef2c96b7-daef-464b-9bd1-ab6e86a7d00a...\n",
      "Fetching observation data for time-23-01-24-592712_chatcmpl-22bec572-6ec8-4ccb-b655-7204ad1e0812...\n",
      "Fetching observation data for time-23-01-54-768571_chatcmpl-bd89be59-3abe-4e93-ad29-93c67cc90677...\n",
      "Fetching observation data for dd9e435d-554f-47a5-aa5d-fc0cd36b8b1b...\n",
      "Fetching observation data for time-22-58-06-547807_chatcmpl-e1efefde-c7da-4785-8bed-68fe0eaada13...\n",
      "Fetching observation data for time-22-58-25-733991_chatcmpl-7d4af788-e54a-4c64-8a3a-3b6b42849bc1...\n",
      "Fetching observation data for time-22-58-50-865433_chatcmpl-d80743c2-045c-41a8-8e73-6a55ef6f5902...\n",
      "Fetching observation data for time-22-59-15-466686_chatcmpl-83593719-a1b3-4e2c-8b89-945dba789d5e...\n",
      "Fetching observation data for time-22-59-39-763544_chatcmpl-dc3f8d39-c410-48fa-9c13-6cd4f26351ce...\n",
      "Fetching observation data for 28eb2287-4774-422c-ad8b-eee4fa15f055...\n",
      "Fetching observation data for time-22-55-52-934627_chatcmpl-49362e46-c8e2-44fe-af58-a692a746aa64...\n",
      "Fetching observation data for time-22-56-12-130919_chatcmpl-b8064027-10f5-4492-bed5-4d96c2c46081...\n",
      "Fetching observation data for time-22-56-36-891501_chatcmpl-7ab71936-89ed-4f6f-ad52-22bea55018b2...\n",
      "Fetching observation data for time-22-57-02-393616_chatcmpl-c67fc48f-89b7-41ac-9935-5c0230d1f281...\n",
      "Fetching observation data for time-22-57-28-200196_chatcmpl-b8ea92ab-fa0b-48fe-afb1-e108fcc5b68a...\n",
      "Fetching observation data for 36407fc2-0fbb-4f75-9a4b-646ce07aa836...\n",
      "Fetching observation data for time-22-52-53-947954_chatcmpl-fd712d01-08d8-4296-8350-9d4ad88b8770...\n",
      "Fetching observation data for time-22-53-13-126545_chatcmpl-3181eec5-f7bd-4771-9539-53329735fe14...\n",
      "Fetching observation data for time-22-53-36-155650_chatcmpl-92e95074-69e5-497e-ab05-092645b96f37...\n",
      "Fetching observation data for time-22-54-01-767113_chatcmpl-864e3bde-f2a4-4c2d-8a25-43192743e56c...\n",
      "Fetching observation data for time-22-55-15-317483_chatcmpl-8d29da27-2196-43ff-a175-790c9859447b...\n",
      "Fetching observation data for time-22-50-38-033031_chatcmpl-f1b018a6-04df-4f46-b0d6-9d3e86f83b1c...\n",
      "Fetching observation data for time-22-50-57-252603_chatcmpl-0ea72188-a54a-4ea7-9bc1-cbb0dc79c534...\n",
      "Fetching observation data for time-22-51-21-920265_chatcmpl-c7875776-149c-4e20-a44f-1fef8269cbba...\n",
      "Fetching observation data for time-22-51-47-589076_chatcmpl-f897046b-830f-4e27-80a2-50a2cafd13c6...\n",
      "Fetching observation data for time-22-48-36-406193_chatcmpl-b9b66133-3172-47ff-8aaf-23adb241fbc7...\n",
      "Fetching observation data for time-22-48-55-583442_chatcmpl-1d2deb6e-41a8-44c7-b1d7-ee923567d8a5...\n",
      "Fetching observation data for time-22-49-18-561891_chatcmpl-b47be481-db0e-4577-82dd-21e5763a5bad...\n",
      "Fetching observation data for time-22-49-41-078668_chatcmpl-2a4ca7a9-e1c3-48e9-ad91-df81fb1660e5...\n",
      "Fetching observation data for time-22-50-06-990091_chatcmpl-96b546a7-fe84-47b3-93b9-cf70433c0fa8...\n",
      "Fetching observation data for 9a3a439f-ce96-4df7-8738-b61145b2eba9...\n",
      "Fetching observation data for time-22-45-52-400116_chatcmpl-c4a41881-e748-4530-86b0-c1905ddc61f6...\n",
      "Fetching observation data for time-22-46-11-595789_chatcmpl-943f8fba-abfb-49f4-822a-b1c5b3776e6a...\n",
      "Fetching observation data for time-22-46-35-763171_chatcmpl-441624ce-e660-4a9e-adce-4745f0c11669...\n",
      "Fetching observation data for time-22-47-01-105579_chatcmpl-f89c3181-6a4d-4a2b-a58b-e9e3f174ae8f...\n",
      "Fetching observation data for time-22-47-32-165789_chatcmpl-242cd325-945e-4420-a7d5-70b264fd793f...\n",
      "Fetching observation data for time-22-43-39-548804_chatcmpl-e3315665-1da4-4b06-8ed2-663874ed0078...\n",
      "Fetching observation data for time-22-43-58-717610_chatcmpl-bc675aef-31b2-4352-bf44-7ff7586bbd3b...\n",
      "Fetching observation data for time-22-44-24-254067_chatcmpl-caad4097-cfbb-45a1-a812-0ae8b7b27073...\n",
      "Fetching observation data for time-22-44-50-336076_chatcmpl-94413c6e-583e-42be-9e0c-d7e60bd69248...\n",
      "Fetching observation data for time-22-45-20-392196_chatcmpl-a8f9f0db-06cd-45bf-a23a-ee56a56bd74b...\n",
      "Fetching observation data for 7dfdd966-db5b-4cbb-a081-3ff75476c1f9...\n",
      "Fetching observation data for time-22-41-25-913401_chatcmpl-ec11b4f4-410a-4edc-b315-dba860dbb7c6...\n",
      "Fetching observation data for time-22-41-45-106882_chatcmpl-41047061-fa47-4569-be67-6a5e3f72f4c0...\n",
      "Fetching observation data for time-22-42-13-986198_chatcmpl-64365dd4-9046-492d-8343-41cc0a943388...\n",
      "Fetching observation data for time-22-42-36-974390_chatcmpl-82695af7-052d-49e5-8d86-0f8fd228dc73...\n",
      "Fetching observation data for time-22-43-07-914813_chatcmpl-f3cf530d-8d0f-401a-a0d9-4e52d048c971...\n",
      "Fetching observation data for 3ca8bc68-dd94-42dd-b2c5-3e03ca2cc173...\n",
      "Fetching observation data for time-22-39-36-713907_chatcmpl-15c79c97-7181-4807-8bc6-737933e4893b...\n",
      "Fetching observation data for time-22-39-56-122293_chatcmpl-df75c165-9dcb-44f1-ba19-303a602c956c...\n",
      "Fetching observation data for time-22-40-21-587263_chatcmpl-474672cd-1c8a-460f-9db4-db879db3b255...\n",
      "Fetching observation data for time-20-57-51-852437_chatcmpl-ab9e26b0-c284-4016-a04a-cb17f00e651a...\n",
      "Fetching observation data for time-20-58-11-055469_chatcmpl-acff3cf1-8fa6-4341-ab0f-a196b5719c17...\n",
      "Fetching observation data for time-20-58-36-490320_chatcmpl-bc267e7c-ae8a-4b24-9535-6e4d4ce18dce...\n",
      "Fetching observation data for time-20-59-00-148071_chatcmpl-c4925972-205b-4f30-83a3-17933c1f7d06...\n",
      "Fetching observation data for 583d3188-7d0c-45c1-bdb7-efb3d677eba5...\n",
      "Fetching observation data for time-20-55-45-298067_chatcmpl-49fa0996-1e08-46a0-b39c-5d778390e8bd...\n",
      "Fetching observation data for time-20-56-04-480401_chatcmpl-a0153fa2-ea50-4dad-8e20-d9c8d1783f87...\n",
      "Fetching observation data for time-20-56-29-135806_chatcmpl-8f5b3440-55be-415f-8343-e3c8f10a37e1...\n",
      "Fetching observation data for time-20-56-54-574073_chatcmpl-3e8d5df1-d349-411d-bf25-6e82bd87d9c5...\n",
      "Fetching observation data for time-20-57-18-046440_chatcmpl-1b83c0d4-7176-4f52-bbb1-744fb326d6e6...\n",
      "Fetching observation data for 6de1e139-2d1a-434a-a608-14b40a875530...\n",
      "Fetching observation data for time-20-53-21-715842_chatcmpl-58f261ff-4b98-4543-899b-a4dae48c84a2...\n",
      "Fetching observation data for time-20-53-40-885905_chatcmpl-12d91676-9018-4bd3-a302-2ef4ed86920e...\n",
      "Fetching observation data for time-20-54-04-435522_chatcmpl-1a67165f-235e-454e-913e-6f3add865364...\n",
      "Fetching observation data for time-20-54-33-676047_chatcmpl-abe9b5ce-98d4-458d-a676-22bee236c9a8...\n",
      "Fetching observation data for time-20-50-48-163283_chatcmpl-fcfb2cad-91bb-4b2d-8f49-185012555dc6...\n",
      "Fetching observation data for time-20-51-07-337517_chatcmpl-b644868e-e787-49d2-9d34-ba2d1d3cfe6f...\n",
      "Fetching observation data for time-20-51-30-318052_chatcmpl-29e176de-626a-4d7f-abfa-e232c0ac841b...\n",
      "Fetching observation data for time-20-51-52-243071_chatcmpl-d193871c-557f-4921-907b-3d2dbe36ccee...\n",
      "Fetching observation data for time-20-52-21-986036_chatcmpl-38d61f49-3623-4ba3-92b8-d954d678f86b...\n",
      "Fetching observation data for time-20-48-43-362185_chatcmpl-0a5ae22a-a631-47eb-a4b6-30c33076cc7f...\n",
      "Fetching observation data for time-20-49-02-573211_chatcmpl-bed200a7-ef47-4bb7-be6d-e4138db68db6...\n",
      "Fetching observation data for time-20-49-27-198482_chatcmpl-fe1cf56e-b007-4bc1-960b-bffb4ea9caaf...\n",
      "Fetching observation data for time-20-49-52-979502_chatcmpl-4c61a18a-e7de-4e76-9012-b13e8ce49f9a...\n",
      "Fetching observation data for time-20-50-18-187949_chatcmpl-ae313732-3277-4e7d-b1f4-2a98d8ba1330...\n",
      "Fetching observation data for d7b0918a-e2e8-4c98-8a1c-f2196c101d76...\n",
      "Fetching observation data for time-20-46-27-824177_chatcmpl-da4b78c5-c0ed-4785-9036-12b370fdee7a...\n",
      "Fetching observation data for time-20-46-47-016159_chatcmpl-53110560-bfcb-4400-9dbf-dbbe003fd48f...\n",
      "Fetching observation data for time-20-47-12-453043_chatcmpl-75fd0826-8709-4344-a8e7-518674d2a253...\n",
      "Fetching observation data for time-20-47-36-945240_chatcmpl-29bdcdd0-cdac-42e1-bcbb-2e57c5929faa...\n",
      "Fetching observation data for time-20-48-06-396314_chatcmpl-2be5291d-f83d-4f57-9924-e38f8fd05119...\n",
      "Fetching observation data for 95a2f12f-1235-4462-8305-43230b2fc5c2...\n",
      "Fetching observation data for time-20-44-13-097037_chatcmpl-5273247a-5ba1-4ef5-af17-b2fc03c01798...\n",
      "Fetching observation data for time-20-44-32-343095_chatcmpl-aef52cf7-bdbb-4d20-908a-be95d072fbf2...\n",
      "Fetching observation data for time-20-44-55-780566_chatcmpl-f8ca6779-030e-4037-9833-cb6ff59f1d3d...\n",
      "Fetching observation data for time-20-45-25-505149_chatcmpl-f7917eda-9064-47aa-89f0-7f6a4a1a7b19...\n",
      "Fetching observation data for time-20-45-56-963218_chatcmpl-31fcd079-0fb3-4e57-a880-06e2e3b40615...\n",
      "Fetching observation data for 819877cc-8cef-4c7a-8dc9-de770d84798f...\n",
      "Fetching observation data for time-20-41-25-552615_chatcmpl-e0ede8d7-51e4-49eb-a043-fb07384c16fe...\n",
      "Fetching observation data for time-20-42-16-054056_chatcmpl-f7b61903-e63d-46fe-9426-99426b067cc4...\n",
      "Fetching observation data for time-20-42-46-293940_chatcmpl-62d97f2a-db3a-4f34-89ec-623f4260417a...\n",
      "Fetching observation data for time-20-43-09-919522_chatcmpl-e5f43590-903d-4e90-bf08-7840ee1f82f9...\n",
      "Fetching observation data for time-20-43-41-801955_chatcmpl-62478571-b4a5-4f5b-a30d-9a07f6b2e086...\n",
      "Fetching observation data for b266edd6-4217-4821-b546-6499c0fe81c0...\n",
      "Raw JSON saved to: /Users/hann/Projects/reference-benchmark-tinyml_llm/data_analysis/2025/08.06/raw_export/raw_qwen2.5-coder:32b_57d5_psg_batch.json\n"
     ]
    }
   ],
   "source": [
    "# ALTERNATIVE TO 2.\n",
    "import os\n",
    "import json\n",
    "from time import sleep\n",
    "from langfuse import Langfuse\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "\n",
    "# LANGFUSE_SERVICE_PUBLIC_KEY = \"pk-lf-559a2c0f-ee29-4c32-944c-bf73b5f0ce28\"\n",
    "# LANGFUSE_SERVICE_SECRET_KEY = \"sk-lf-75f8bf7f-a5db-4756-b0dd-d758a2a292c8\"\n",
    "# LANGFUSE_SERVICE_HOST = \"https://langfuse.hann.fi\"\n",
    "\n",
    "\n",
    "if LOCAL_HOST:\n",
    "    langfuse = Langfuse(\n",
    "        secret_key=\"sk-lf-75f8bf7f-a5db-4756-b0dd-d758a2a292c8\",\n",
    "        public_key=\"pk-lf-559a2c0f-ee29-4c32-944c-bf73b5f0ce28\",\n",
    "        host=\"https://langfuse.hann.fi\",\n",
    "    )\n",
    "else:\n",
    "    langfuse = Langfuse(\n",
    "        secret_key=LANGFUSE_SERVICE_SECRET_KEY,\n",
    "        public_key=LANGFUSE_SERVICE_PUBLIC_KEY,\n",
    "        host=LANGFUSE_SERVICE_HOST,\n",
    "    )\n",
    "\n",
    "API_invok_count = 0\n",
    "query_range_num_run = {\"start\": 0, \"end\": 1}\n",
    "\n",
    "\n",
    "class CustomJSONEncoder(json.JSONEncoder):\n",
    "    def __init__(self, *args, LOCAL_HOST=True, **kwargs):\n",
    "        self.LOCAL_HOST = LOCAL_HOST\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "    def default(self, obj):\n",
    "        if isinstance(obj, datetime):\n",
    "            return obj.isoformat()\n",
    "        if hasattr(obj, \"__dict__\"):\n",
    "            data = obj.__dict__.copy()\n",
    "            if \"observations\" in data:\n",
    "                data[\"observations\"] = [\n",
    "                    fetch_observation_data(obs, self.LOCAL_HOST)\n",
    "                    for obs in data[\"observations\"]\n",
    "                ]\n",
    "\n",
    "            return data\n",
    "        return super().default(obj)\n",
    "\n",
    "\n",
    "def fetch_observation_data(observation_id, LOCAL_HOST):\n",
    "    \"\"\"\n",
    "    Fetches observation data from Langfuse and returns its dictionary representation.\n",
    "    \"\"\"\n",
    "    print(f\"Fetching observation data for {observation_id}...\")\n",
    "    global API_invok_count\n",
    "    if API_invok_count >= 0 and not LOCAL_HOST:\n",
    "        print(\"Waiting for 3 seconds to fetch observation data...\")\n",
    "        for _ in tqdm(range(3), desc=\"Progress\", unit=\"s\"):\n",
    "            sleep(1)\n",
    "        API_invok_count = 0\n",
    "\n",
    "    observation_response = langfuse.fetch_observation(observation_id)\n",
    "    API_invok_count += 1\n",
    "\n",
    "    return observation_response.data.dict()\n",
    "\n",
    "\n",
    "def fetch_and_save_complete_data(session_id_list, raw_export_dir, LOCAL_HOST):\n",
    "    \"\"\"\n",
    "    Fetches complete trace data for each session ID and saves it to JSON files.\n",
    "\n",
    "    Parameters:\n",
    "        session_id_list (list): List of session IDs to process.\n",
    "        raw_export_dir (str): Directory path to save raw JSON files.\n",
    "    \"\"\"\n",
    "\n",
    "    def save_complete_data(session_id):\n",
    "        global API_invok_count\n",
    "        if API_invok_count >= 0 and not LOCAL_HOST:\n",
    "            print(\"Waiting for 4 seconds to fetch traces...\")\n",
    "            for _ in tqdm(range(4), desc=\"Progress\", unit=\"s\"):\n",
    "                sleep(1)\n",
    "            API_invok_count = 0\n",
    "\n",
    "        fetch_traces_response = langfuse.fetch_traces(session_id=session_id)\n",
    "        API_invok_count += 1\n",
    "\n",
    "        print(f\"Fetching traces for session {session_id}...\")\n",
    "        # Create directories if they don't exist\n",
    "        os.makedirs(raw_export_dir, exist_ok=True)\n",
    "\n",
    "        # Save complete data to JSON file\n",
    "        # if session_id.startswith(\"da0a\"):\n",
    "        #     session_id = \"phi4_\" + session_id\n",
    "        if \"tpsg\" in session_id:\n",
    "            session_id_ = session_id.replace(\"tpsg\", \"tpusg\")\n",
    "        else:\n",
    "            session_id_ = session_id\n",
    "            \n",
    "        raw_path = os.path.join(raw_export_dir, f\"raw_{session_id_}.json\")\n",
    "        with open(raw_path, \"w\") as f:\n",
    "            json.dump(fetch_traces_response, f, cls=CustomJSONEncoder, indent=2)\n",
    "\n",
    "        print(f\"Raw JSON saved to: {raw_path}\")\n",
    "\n",
    "    for session_id in session_id_list:\n",
    "        save_complete_data(session_id)\n",
    "\n",
    "\n",
    "fetch_and_save_complete_data(session_id_list, raw_export_dir, LOCAL_HOST)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Trim data\n",
    "\n",
    "Here also intercept the runs with fatal errors that need to be excluded from the analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPAN error_26_tpusg_failure_signal_tpu_sketch_generator: Failed. Last error: Traceback (most recent call last):\n",
      "  File \"script_8638f51f_1754275645.py\", line 70, in <module>\n",
      "    num_detections = int(num_detections_array[0])\n",
      "TypeError: only size-1 arrays can be converted to Python scalars\n",
      "SPAN error_5b_tpusg_failure_signal_tpu_sketch_generator: Failed. Last error: Traceback (most recent call last):\n",
      "  File \"script_f360e89e_1754275447.py\", line 67, in <module>\n",
      "    num_detections = int(interpreter.get_tensor(output_details[1]['index']))  # Access the scalar value directly\n",
      "TypeError: only size-1 arrays can be converted to Python scalars\n",
      "SPAN error_ba_tpusg_failure_signal_tpu_sketch_generator: Failed. Last error: Traceback (most recent call last):\n",
      "  File \"script_cb1c38a0_1754275248.py\", line 66, in <module>\n",
      "    num_detections = int(interpreter.get_tensor(output_details[1]['index']))  # Directly convert to int\n",
      "TypeError: only size-1 arrays can be converted to Python scalars\n",
      "SPAN error_70_tpusg_failure_signal_tpu_sketch_generator: Failed. Last error: Unexpected error during generation: Generated script is not complete. Please ensure to generate a complete Python script.\n",
      "SPAN error_1c_tpusg_failure_signal_tpu_sketch_generator: Failed. Last error: Traceback (most recent call last):\n",
      "  File \"script_82ec7d55_1754274833.py\", line 66, in <module>\n",
      "    num_detections = int(interpreter.get_tensor(output_details[1]['index'])[0])  # Access the first element directly\n",
      "TypeError: only size-1 arrays can be converted to Python scalars\n",
      "SPAN error_35_tpusg_failure_signal_tpu_sketch_generator: Failed. Last error: Unexpected error during generation: Generated script is not complete. Please ensure to generate a complete Python script.\n",
      "SPAN error_ae_tpusg_failure_signal_tpu_sketch_generator: Failed. Last error: Traceback (most recent call last):\n",
      "  File \"script_e3eb43f2_1754274236.py\", line 66, in <module>\n",
      "    num_detections = int(interpreter.get_tensor(output_details[1]['index']))  # Access the scalar value directly from array\n",
      "TypeError: only size-1 arrays can be converted to Python scalars\n",
      "SPAN error_3a_tpusg_failure_signal_tpu_sketch_generator: Failed. Last error: Traceback (most recent call last):\n",
      "  File \"script_3c00ef11_1754273874.py\", line 68, in <module>\n",
      "    num_detections = int(interpreter.get_tensor(output_details[1]['index'])[0])\n",
      "TypeError: only size-1 arrays can be converted to Python scalars\n",
      "SPAN error_09_tpusg_failure_signal_tpu_sketch_generator: Failed. Last error: Traceback (most recent call last):\n",
      "  File \"script_c3257492_1754273407.py\", line 71, in <module>\n",
      "    num_detections = len(detection_scores)\n",
      "TypeError: object of type 'numpy.float32' has no len()\n",
      "SPAN error_5b_tpusg_failure_signal_tpu_sketch_generator: Failed. Last error: Traceback (most recent call last):\n",
      "  File \"script_1666b2bb_1754272877.py\", line 65, in <module>\n",
      "    num_detections = int(interpreter.get_tensor(output_details[0]['index'])[0])  # Access the first element of the array\n",
      "TypeError: only size-1 arrays can be converted to Python scalars\n",
      "SPAN error_79_tpusg_failure_signal_tpu_sketch_generator: Failed. Last error: Traceback (most recent call last):\n",
      "  File \"script_2e9540a1_1754272677.py\", line 66, in <module>\n",
      "    num_detections = int(interpreter.get_tensor(output_details[1]['index']))  # Directly convert to int\n",
      "TypeError: only size-1 arrays can be converted to Python scalars\n",
      "SPAN error_4a_tpusg_failure_signal_tpu_sketch_generator: Failed. Last error: Output 0: {'name': 'TFLite_Detection_PostProcess', 'index': 167, 'shape': array([ 1, 10,  4], dtype=int32), 'shape_signature': array([ 1, 10,  4], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}\n",
      "Output 1: {'name': 'TFLite_Detection_PostProcess:1', 'index': 168, 'shape': array([ 1, 10], dtype=int32), 'shape_signature': array([ 1, 10], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}\n",
      "Output 2: {'name': 'TFLite_Detection_PostProcess:2', 'index': 169, 'shape': array([ 1, 10], dtype=int32), 'shape_signature': array([ 1, 10], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}\n",
      "Output 3: {'name': 'TFLite_Detection_PostProcess:3', 'index': 170, 'shape': array([1], dtype=int32), 'shape_signature': array([1], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}\n",
      "Shape of num_detections tensor: (1, 10, 4)\n",
      "Traceback (most recent call last):\n",
      "  File \"script_fa9852bf_1754272237.py\", line 73, in <module>\n",
      "    num_detections = int(num_detections_tensor[0])\n",
      "TypeError: only size-1 arrays can be converted to Python scalars\n",
      "SPAN error_9e_tpusg_failure_signal_tpu_sketch_generator: Failed. Last error: Traceback (most recent call last):\n",
      "  File \"script_5388c33d_1754271873.py\", line 72, in <module>\n",
      "    detection_scores = interpreter.get_tensor(output_details[4]['index'])[0]\n",
      "IndexError: list index out of range\n",
      "SPAN error_71_tpusg_failure_signal_tpu_sketch_generator: Failed. Last error: Traceback (most recent call last):\n",
      "  File \"script_7e92c244_1754271671.py\", line 66, in <module>\n",
      "    num_detections = int(interpreter.get_tensor(output_details[1]['index']))  # Access the scalar value directly\n",
      "TypeError: only size-1 arrays can be converted to Python scalars\n",
      "SPAN error_c1_tpusg_failure_signal_tpu_sketch_generator: Failed. Last error: Input details: [{'name': 'normalized_input_image_tensor', 'index': 175, 'shape': array([  1, 300, 300,   3], dtype=int32), 'shape_signature': array([  1, 300, 300,   3], dtype=int32), 'dtype': <class 'numpy.uint8'>, 'quantization': (0.0078125, 128), 'quantization_parameters': {'scales': array([0.0078125], dtype=float32), 'zero_points': array([128], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}]\n",
      "Output details: [{'name': 'TFLite_Detection_PostProcess', 'index': 167, 'shape': array([ 1, 10,  4], dtype=int32), 'shape_signature': array([ 1, 10,  4], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'TFLite_Detection_PostProcess:1', 'index': 168, 'shape': array([ 1, 10], dtype=int32), 'shape_signature': array([ 1, 10], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'TFLite_Detection_PostProcess:2', 'index': 169, 'shape': array([ 1, 10], dtype=int32), 'shape_signature': array([ 1, 10], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'TFLite_Detection_PostProcess:3', 'index': 170, 'shape': array([1], dtype=int32), 'shape_signature': array([1], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}]\n",
      "Traceback (most recent call last):\n",
      "  File \"script_9b7737f3_1754271472.py\", line 76, in <module>\n",
      "    for i in range(len(detection_scores)):\n",
      "TypeError: object of type 'numpy.float32' has no len()\n",
      "SPAN error_00_tpusg_failure_signal_tpu_sketch_generator: Failed. Last error: Traceback (most recent call last):\n",
      "  File \"script_3d33c886_1754271271.py\", line 66, in <module>\n",
      "    num_detections = int(interpreter.get_tensor(output_details[1]['index']))  # Access the scalar value directly\n",
      "TypeError: only size-1 arrays can be converted to Python scalars\n",
      "SPAN error_fd_tpusg_failure_signal_tpu_sketch_generator: Failed. Last error: Traceback (most recent call last):\n",
      "  File \"script_0fc93243_1754271072.py\", line 66, in <module>\n",
      "    num_detections = interpreter.get_tensor(output_details[1]['index']).item()  # Correctly extract the scalar value\n",
      "ValueError: can only convert an array of size 1 to a Python scalar\n",
      "SPAN error_9a_tpusg_failure_signal_tpu_sketch_generator: Failed. Last error: Traceback (most recent call last):\n",
      "  File \"script_fa1c3eaa_1754270551.py\", line 68, in <module>\n",
      "    num_detections = int(interpreter.get_tensor(output_details[1]['index']))  # Corrected line\n",
      "TypeError: only size-1 arrays can be converted to Python scalars\n",
      "SPAN error_ea_tpusg_failure_signal_tpu_sketch_generator: Failed. Last error: Traceback (most recent call last):\n",
      "  File \"script_7f252661_1754270349.py\", line 67, in <module>\n",
      "    num_detections = int(interpreter.get_tensor(output_details[1]['index'])[0])  # Access the scalar value directly from the array\n",
      "TypeError: only size-1 arrays can be converted to Python scalars\n",
      "SPAN error_ca_tpusg_failure_signal_tpu_sketch_generator: Failed. Last error: Traceback (most recent call last):\n",
      "  File \"script_4d73c7c2_1754270148.py\", line 66, in <module>\n",
      "    num_detections = int(interpreter.get_tensor(output_details[1]['index']))  # Correctly extract the scalar value\n",
      "TypeError: only size-1 arrays can be converted to Python scalars\n",
      "SPAN error_e6_tpusg_failure_signal_tpu_sketch_generator: Failed. Last error: Traceback (most recent call last):\n",
      "  File \"script_037414af_1754269952.py\", line 66, in <module>\n",
      "    num_detections = int(interpreter.get_tensor(output_details[1]['index'])[0])  # Access the first element directly\n",
      "TypeError: only size-1 arrays can be converted to Python scalars\n",
      "Successfully processed and saved trimmed data for session qwen2.5-coder:32b_c8a6_tpusg_batch\n",
      "SPAN error_fe_psg_failure_signal_py_sketch_generator: Failed. Last error: Traceback (most recent call last):\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250804233147_psg_qwen2.5-coder:32b/tmp_20250804233147_psg_qwen2.5-coder:32b.py\", line 152, in <module>\n",
      "    interpreter = tf.lite.Interpreter(model_path=model_path)\n",
      "NameError: name 'tf' is not defined\n",
      "\n",
      "SPAN error_e8_psg_failure_signal_py_sketch_generator: Failed. Last error: Traceback (most recent call last):\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250804232748_psg_qwen2.5-coder:32b/tmp_20250804232748_psg_qwen2.5-coder:32b.py\", line 20, in <module>\n",
      "    with open(label_path, 'r') as f:\n",
      "FileNotFoundError: [Errno 2] No such file or directory: '/path/to/labelmap.txt'\n",
      "\n",
      "SPAN error_cd_psg_failure_signal_py_sketch_generator: Failed. Last error: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "OpenCV: FFMPEG: tag 0x44495658/'XVID' is not supported with codec id 12 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n",
      "OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250804231824_psg_qwen2.5-coder:32b/tmp_20250804231824_psg_qwen2.5-coder:32b.py\", line 63, in <module>\n",
      "    num_detections = int(output_data[0][0])\n",
      "TypeError: only length-1 arrays can be converted to Python scalars\n",
      "\n",
      "SPAN error_3f_psg_failure_signal_py_sketch_generator: Failed. Last error: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250804231608_psg_qwen2.5-coder:32b/tmp_20250804231608_psg_qwen2.5-coder:32b.py\", line 60, in <module>\n",
      "    label = labels[i]\n",
      "TypeError: only integer scalar arrays can be converted to a scalar index\n",
      "\n",
      "SPAN error_12_psg_failure_signal_py_sketch_generator: Failed. Last error: Traceback (most recent call last):\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250804231057_psg_qwen2.5-coder:32b/tmp_20250804231057_psg_qwen2.5-coder:32b.py\", line 21, in <module>\n",
      "    with open(label_path, 'r') as f:\n",
      "FileNotFoundError: [Errno 2] No such file or directory: '/path/to/labelmap.txt'\n",
      "\n",
      "SPAN error_08_psg_failure_signal_py_sketch_generator: Failed. Last error: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "OpenCV: FFMPEG: tag 0x44495658/'XVID' is not supported with codec id 12 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n",
      "OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250804230853_psg_qwen2.5-coder:32b/tmp_20250804230853_psg_qwen2.5-coder:32b.py\", line 70, in <module>\n",
      "    class_index = int(output_data[0])\n",
      "TypeError: only length-1 arrays can be converted to Python scalars\n",
      "\n",
      "SPAN error_ea_psg_failure_signal_py_sketch_generator: Failed. Last error: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250804230642_psg_qwen2.5-coder:32b/tmp_20250804230642_psg_qwen2.5-coder:32b.py\", line 62, in <module>\n",
      "    bbox, class_id, score = detection[:4], int(detection[5]), float(detection[4])\n",
      "TypeError: only length-1 arrays can be converted to Python scalars\n",
      "\n",
      "SPAN error_e0_psg_failure_signal_py_sketch_generator: Failed. Last error: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250804230428_psg_qwen2.5-coder:32b/tmp_20250804230428_psg_qwen2.5-coder:32b.py\", line 49, in <module>\n",
      "    interpreter.set_tensor(input_details[0]['index'], input_data)\n",
      "  File \"/home/wuguangh/.conda/envs/tinyml/lib/python3.10/site-packages/tflite_runtime/interpreter.py\", line 720, in set_tensor\n",
      "    self._interpreter.SetTensor(tensor_index, value)\n",
      "ValueError: Cannot set tensor: Got value of type FLOAT32 but expected type UINT8 for input 175, name: normalized_input_image_tensor \n",
      "\n",
      "SPAN error_3b_psg_failure_signal_py_sketch_generator: Failed. Last error: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250804230222_psg_qwen2.5-coder:32b/tmp_20250804230222_psg_qwen2.5-coder:32b.py\", line 62, in <module>\n",
      "    bbox, class_id, score = detection[:4], int(detection[5]), float(detection[4])\n",
      "TypeError: only length-1 arrays can be converted to Python scalars\n",
      "\n",
      "SPAN error_d0_psg_failure_signal_py_sketch_generator: Failed. Last error: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250804230008_psg_qwen2.5-coder:32b/tmp_20250804230008_psg_qwen2.5-coder:32b.py\", line 49, in <module>\n",
      "    interpreter.set_tensor(input_details[0]['index'], input_data)\n",
      "  File \"/home/wuguangh/.conda/envs/tinyml/lib/python3.10/site-packages/tflite_runtime/interpreter.py\", line 720, in set_tensor\n",
      "    self._interpreter.SetTensor(tensor_index, value)\n",
      "ValueError: Cannot set tensor: Got value of type FLOAT32 but expected type UINT8 for input 175, name: normalized_input_image_tensor \n",
      "\n",
      "SPAN error_83_psg_failure_signal_py_sketch_generator: Failed. Last error: Traceback (most recent call last):\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250804225759_psg_qwen2.5-coder:32b/tmp_20250804225759_psg_qwen2.5-coder:32b.py\", line 21, in <module>\n",
      "    with open(label_path, 'r') as f:\n",
      "FileNotFoundError: [Errno 2] No such file or directory: '/path/to/labelmap.txt'\n",
      "\n",
      "SPAN error_93_psg_failure_signal_py_sketch_generator: Failed. Last error: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250804225031_psg_qwen2.5-coder:32b/tmp_20250804225031_psg_qwen2.5-coder:32b.py\", line 47, in <module>\n",
      "    interpreter.set_tensor(input_details[0]['index'], frame_normalized)\n",
      "  File \"/home/wuguangh/.conda/envs/tinyml/lib/python3.10/site-packages/tflite_runtime/interpreter.py\", line 720, in set_tensor\n",
      "    self._interpreter.SetTensor(tensor_index, value)\n",
      "ValueError: Cannot set tensor: Got value of type FLOAT32 but expected type UINT8 for input 175, name: normalized_input_image_tensor \n",
      "\n",
      "SPAN error_60_psg_failure_signal_py_sketch_generator: Failed. Last error: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250804224545_psg_qwen2.5-coder:32b/tmp_20250804224545_psg_qwen2.5-coder:32b.py\", line 65, in <module>\n",
      "    confidence_score = scores[predicted_class_index]\n",
      "IndexError: index 19 is out of bounds for axis 0 with size 10\n",
      "\n",
      "SPAN error_c2_psg_failure_signal_py_sketch_generator: Failed. Last error: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250804224332_psg_qwen2.5-coder:32b/tmp_20250804224332_psg_qwen2.5-coder:32b.py\", line 66, in <module>\n",
      "    label = labels[index]\n",
      "TypeError: only integer scalar arrays can be converted to a scalar index\n",
      "\n",
      "SPAN error_9b_psg_failure_signal_py_sketch_generator: Failed. Last error: Unexpected error during generation: litellm.Timeout: OllamaException: HTTPConnectionPool(host='10.251.36.228', port=11434): Read timed out. (read timeout=6000)\n",
      "SPAN error_1f_psg_failure_signal_py_sketch_generator: Failed. Last error: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250804205744_psg_qwen2.5-coder:32b/tmp_20250804205744_psg_qwen2.5-coder:32b.py\", line 49, in <module>\n",
      "    interpreter.set_tensor(input_details[0]['index'], input_data)\n",
      "  File \"/home/wuguangh/.conda/envs/tinyml/lib/python3.10/site-packages/tflite_runtime/interpreter.py\", line 720, in set_tensor\n",
      "    self._interpreter.SetTensor(tensor_index, value)\n",
      "ValueError: Cannot set tensor: Got value of type FLOAT32 but expected type UINT8 for input 175, name: normalized_input_image_tensor \n",
      "\n",
      "SPAN error_31_psg_failure_signal_py_sketch_generator: Failed. Last error: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "OpenCV: FFMPEG: tag 0x44495658/'XVID' is not supported with codec id 12 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n",
      "OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250804205040_psg_qwen2.5-coder:32b/tmp_20250804205040_psg_qwen2.5-coder:32b.py\", line 49, in <module>\n",
      "    interpreter.set_tensor(input_details[0]['index'], input_data)\n",
      "  File \"/home/wuguangh/.conda/envs/tinyml/lib/python3.10/site-packages/tflite_runtime/interpreter.py\", line 720, in set_tensor\n",
      "    self._interpreter.SetTensor(tensor_index, value)\n",
      "ValueError: Cannot set tensor: Got value of type FLOAT32 but expected type UINT8 for input 175, name: normalized_input_image_tensor \n",
      "\n",
      "SPAN error_25_psg_failure_signal_py_sketch_generator: Failed. Last error: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "OpenCV: FFMPEG: tag 0x44495658/'XVID' is not supported with codec id 12 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n",
      "OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250804204837_psg_qwen2.5-coder:32b/tmp_20250804204837_psg_qwen2.5-coder:32b.py\", line 63, in <module>\n",
      "    num_detections = int(output_data[0][0])\n",
      "TypeError: only length-1 arrays can be converted to Python scalars\n",
      "\n",
      "SPAN error_e3_psg_failure_signal_py_sketch_generator: Failed. Last error: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250804204620_psg_qwen2.5-coder:32b/tmp_20250804204620_psg_qwen2.5-coder:32b.py\", line 49, in <module>\n",
      "    interpreter.set_tensor(input_details[0]['index'], input_data)\n",
      "  File \"/home/wuguangh/.conda/envs/tinyml/lib/python3.10/site-packages/tflite_runtime/interpreter.py\", line 720, in set_tensor\n",
      "    self._interpreter.SetTensor(tensor_index, value)\n",
      "ValueError: Cannot set tensor: Got value of type FLOAT32 but expected type UINT8 for input 175, name: normalized_input_image_tensor \n",
      "\n",
      "SPAN error_cd_psg_failure_signal_py_sketch_generator: Failed. Last error: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250804204406_psg_qwen2.5-coder:32b/tmp_20250804204406_psg_qwen2.5-coder:32b.py\", line 66, in <module>\n",
      "    label = labels[top_k[i]]\n",
      "TypeError: only integer scalar arrays can be converted to a scalar index\n",
      "\n",
      "Successfully processed and saved trimmed data for session qwen2.5-coder:32b_57d5_psg_batch\n",
      "Total 0 traces skipped. They are []\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "skipped_traces = []\n",
    "\n",
    "\n",
    "def process_existing_observation(observation):\n",
    "    \"\"\"\n",
    "    Processes an existing observation dictionary by trimming unwanted keys.\n",
    "    \"\"\"\n",
    "    unwanted_observation_keys = [\n",
    "        \"completionStartTime\",\n",
    "        \"metadata\",\n",
    "        \"timeToFirstToken\",\n",
    "        \"createdAt\",\n",
    "        \"usageDetails\",\n",
    "        \"usage\",\n",
    "        \"projectId\",\n",
    "        \"unit\",\n",
    "        \"updatedAt\",\n",
    "        \"version\",\n",
    "        \"parentObservationId\",\n",
    "        \"promptId\",\n",
    "        \"promptName\",\n",
    "        \"promptVersion\",\n",
    "        \"modelId\",\n",
    "        \"inputPrice\",\n",
    "        \"outputPrice\",\n",
    "        \"totalPrice\",\n",
    "        # \"modelParameters\",\n",
    "        \"input\",\n",
    "        \"output\",\n",
    "    ]\n",
    "\n",
    "    # If observation is a dictionary containing observation data\n",
    "    if isinstance(observation, dict):\n",
    "        trimmed_observation = {\n",
    "            k: v for k, v in observation.items() if k not in unwanted_observation_keys\n",
    "        }\n",
    "        return trimmed_observation\n",
    "    return observation\n",
    "\n",
    "\n",
    "def trim_data(data):\n",
    "    \"\"\"\n",
    "    Recursively trims the data structure.\n",
    "    \"\"\"\n",
    "\n",
    "    if isinstance(data, dict):\n",
    "        # Process the current dictionary\n",
    "        unwanted_trace_keys = [\n",
    "            \"release\",\n",
    "            \"version\",\n",
    "            \"user_id\",\n",
    "            \"public\",\n",
    "            \"html_path\",\n",
    "            \"scores\",\n",
    "            \"bookmarked\",\n",
    "            \"projectId\",\n",
    "            \"externalId\",\n",
    "            \"page\",\n",
    "            \"limit\",\n",
    "            \"total_pages\",\n",
    "        ]\n",
    "\n",
    "        # If this is a trace that contains observations, check for fatal errors\n",
    "        if \"observations\" in data:\n",
    "            # Check for SPAN observations with fatal errors before processing\n",
    "            skip_trace = False\n",
    "            for obs in data[\"observations\"]:\n",
    "                if isinstance(obs, dict) and obs.get(\"name\").startswith(\"error\"):\n",
    "                    status_message = obs.get(\"statusMessage\", \"\")\n",
    "                    ob_name = obs.get(\"name\")\n",
    "                    print(f\"SPAN {ob_name}: {status_message}\")\n",
    "\n",
    "                    if \"Fatal error\" in status_message:\n",
    "                        print(f\"Found Fatal error in SPAN observation, skipping trace\")\n",
    "                        skip_trace = True\n",
    "                        skipped_traces.append(data[\"name\"])\n",
    "                        break\n",
    "\n",
    "            if skip_trace:\n",
    "                return None  # Signal to skip this trace\n",
    "\n",
    "        # Create a new dictionary with wanted keys and recursively process values\n",
    "        trimmed_data = {}\n",
    "        for key, value in data.items():\n",
    "            if key not in unwanted_trace_keys:\n",
    "                if key == \"observations\":\n",
    "                    # Special handling for observations\n",
    "                    trimmed_data[key] = [\n",
    "                        process_existing_observation(obs) for obs in value\n",
    "                    ]\n",
    "                elif isinstance(value, (dict, list)):\n",
    "                    # Recursively process nested structures\n",
    "                    trimmed_data[key] = trim_data(value)\n",
    "                else:\n",
    "                    trimmed_data[key] = value\n",
    "\n",
    "        return trimmed_data\n",
    "\n",
    "    elif isinstance(data, list):\n",
    "        # Recursively process each item in the list\n",
    "        processed_items = []\n",
    "        for item in data:\n",
    "            processed_item = trim_data(item)\n",
    "            if processed_item is not None:  # Only add items that weren't filtered out\n",
    "                processed_items.append(processed_item)\n",
    "        return processed_items\n",
    "\n",
    "    else:\n",
    "        # Return non-dict, non-list values as is\n",
    "        return data\n",
    "\n",
    "\n",
    "def read_and_trim_data(session_id_list, raw_export_dir, trimmed_export_dir):\n",
    "    \"\"\"\n",
    "    Reads complete data from JSON files, trims the data, and saves the trimmed data to new JSON files.\n",
    "    \"\"\"\n",
    "    os.makedirs(trimmed_export_dir, exist_ok=True)\n",
    "\n",
    "    for session_id in session_id_list:\n",
    "        try:\n",
    "            if session_id.startswith(\"da0a\"):\n",
    "                session_id = \"phi4_\" + session_id\n",
    "            # Read raw data\n",
    "            if \"tpsg\" in session_id:\n",
    "                session_id_ = session_id.replace(\"tpsg\", \"tpusg\")\n",
    "            else:\n",
    "                session_id_ = session_id\n",
    "            raw_path = os.path.join(raw_export_dir, f\"raw_{session_id_}.json\")\n",
    "            with open(raw_path, \"r\") as f:\n",
    "                data = json.load(f)\n",
    "\n",
    "            # Process and trim the data\n",
    "            trimmed_data = trim_data(data)\n",
    "\n",
    "            # If the entire data was filtered out (unlikely but possible)\n",
    "            if trimmed_data is None:\n",
    "                print(\n",
    "                    f\"All traces in session {session_id} were filtered due to fatal errors\"\n",
    "                )\n",
    "                continue\n",
    "\n",
    "            # Save trimmed data\n",
    "            if \"tpsg\" in session_id:\n",
    "                session_id_ = session_id.replace(\"tpsg\", \"tpusg\")\n",
    "            else:\n",
    "                session_id_ = session_id\n",
    "            trimmed_path = os.path.join(\n",
    "                trimmed_export_dir, f\"trimmed_{session_id_}.json\"\n",
    "            )\n",
    "            with open(trimmed_path, \"w\") as f:\n",
    "                json.dump(trimmed_data, f, indent=2)\n",
    "\n",
    "            print(\n",
    "                f\"Successfully processed and saved trimmed data for session {session_id}\"\n",
    "            )\n",
    "\n",
    "            # Optional: Verify trimming worked\n",
    "            # print(f\"Verifying trimmed data for session {session_id}...\")\n",
    "            # verify_trimming(trimmed_path)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing session {session_id}: {str(e)}\")\n",
    "\n",
    "\n",
    "def verify_trimming(trimmed_path):\n",
    "    \"\"\"\n",
    "    Verifies that the trimmed data doesn't contain unwanted keys.\n",
    "    \"\"\"\n",
    "    with open(trimmed_path, \"r\") as f:\n",
    "        trimmed_data = json.load(f)\n",
    "\n",
    "    unwanted_keys = [\n",
    "        \"release\",\n",
    "        \"version\",\n",
    "        \"user_id\",\n",
    "        \"public\",\n",
    "        \"html_path\",\n",
    "        \"scores\",\n",
    "        \"bookmarked\",\n",
    "        \"projectId\",\n",
    "        \"externalId\",\n",
    "        \"page\",\n",
    "        \"limit\",\n",
    "        \"total_pages\",\n",
    "        \"completionStartTime\",\n",
    "        \"metadata\",\n",
    "        \"usageDetails\",\n",
    "        \"timeToFirstToken\",\n",
    "        \"createdAt\",\n",
    "        \"completionTokens\",\n",
    "        \"promptTokens\",\n",
    "        \"projectId\",\n",
    "        \"unit\",\n",
    "        \"updatedAt\",\n",
    "        \"version\",\n",
    "        # \"statusMessage\",\n",
    "        \"parentObservationId\",\n",
    "        \"promptId\",\n",
    "        \"promptName\",\n",
    "        \"promptVersion\",\n",
    "        \"modelId\",\n",
    "        \"inputPrice\",\n",
    "        \"outputPrice\",\n",
    "        \"totalPrice\",\n",
    "        \"calculatedInputCost\",\n",
    "        \"calculatedOutputCost\",\n",
    "        \"calculatedTotalCost\",\n",
    "    ]\n",
    "\n",
    "    def check_keys(obj):\n",
    "        if isinstance(obj, dict):\n",
    "            for key in obj.keys():\n",
    "                if key in unwanted_keys:\n",
    "                    print(f\"Warning: Found unwanted key '{key}' in trimmed data\")\n",
    "            for value in obj.values():\n",
    "                check_keys(value)\n",
    "        elif isinstance(obj, list):\n",
    "            for item in obj:\n",
    "                check_keys(item)\n",
    "\n",
    "    check_keys(trimmed_data)\n",
    "    print(\"Verification complete\")\n",
    "\n",
    "\n",
    "# Usage example:\n",
    "read_and_trim_data(session_id_list, raw_export_dir, raw_export_dir)\n",
    "print(f\"Total {len(skipped_traces)} traces skipped. They are {skipped_traces}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Generate CSV files from JSON\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing session qwen2.5-coder:32b_c8a6_tpusg_batch, simple id qwen2.5-coder:32b_c8a6. Look for /Users/hann/Projects/reference-benchmark-tinyml_llm/data_analysis/2025/08.06/raw_export/trimmed_qwen2.5-coder:32b_c8a6_tpusg_batch.json\n",
      "/Users/hann/Projects/reference-benchmark-tinyml_llm/data_analysis/2025/08.06/processed_data/qwen2.5-coder:32b_c8a6/clean_qwen2.5-coder:32b_c8a6_tpusg_batch.csv\n",
      "Successfully saved CSV to: /Users/hann/Projects/reference-benchmark-tinyml_llm/data_analysis/2025/08.06/processed_data/qwen2.5-coder:32b_c8a6/clean_qwen2.5-coder:32b_c8a6_tpusg_batch.csv\n",
      "Processing session qwen2.5-coder:32b_57d5_psg_batch, simple id qwen2.5-coder:32b_57d5. Look for /Users/hann/Projects/reference-benchmark-tinyml_llm/data_analysis/2025/08.06/raw_export/trimmed_qwen2.5-coder:32b_57d5_psg_batch.json\n",
      "/Users/hann/Projects/reference-benchmark-tinyml_llm/data_analysis/2025/08.06/processed_data/qwen2.5-coder:32b_57d5/clean_qwen2.5-coder:32b_57d5_psg_batch.csv\n",
      "Successfully saved CSV to: /Users/hann/Projects/reference-benchmark-tinyml_llm/data_analysis/2025/08.06/processed_data/qwen2.5-coder:32b_57d5/clean_qwen2.5-coder:32b_57d5_psg_batch.csv\n"
     ]
    }
   ],
   "source": [
    "import traceback\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from dateutil import parser\n",
    "\n",
    "\n",
    "def json_to_csv(session_id):\n",
    "    \"\"\"\n",
    "    Convert JSON trace data to CSV format with aggregated metrics.\n",
    "\n",
    "    Args:\n",
    "        session_id (str): Identifier for the session to process\n",
    "    \"\"\"\n",
    "\n",
    "    def extract_observation_details(observations, trace_id):\n",
    "        \"\"\"Extract and aggregate metrics from observations\"\"\"\n",
    "        metrics = {\n",
    "            \"status\": None,\n",
    "            \"latency\": 0,\n",
    "            \"total_tokens\": 0,\n",
    "            \"prompt_tokens\": 0,\n",
    "            \"completion_tokens\": 0,\n",
    "            \"total_cost\": 0,\n",
    "            \"input_cost\": 0,\n",
    "            \"output_cost\": 0,\n",
    "            \"parameters\": set(),\n",
    "        }\n",
    "\n",
    "        # Process GENERATION observations\n",
    "        for obs in (o for o in observations if o[\"type\"] == \"GENERATION\"):\n",
    "            metrics[\"total_tokens\"] += obs[\"totalTokens\"]\n",
    "            metrics[\"prompt_tokens\"] += obs[\"promptTokens\"]\n",
    "            metrics[\"completion_tokens\"] += obs[\"completionTokens\"]\n",
    "            metrics[\"latency\"] += obs[\"latency\"]\n",
    "            for key, value in obs[\"modelParameters\"].items():\n",
    "                metrics[\"parameters\"].add(key + \":\" + value)\n",
    "\n",
    "            # Add costs if present\n",
    "            for cost_type in [\"Total\", \"Input\", \"Output\"]:\n",
    "                key = f\"calculated{cost_type}Cost\"\n",
    "                metric_key = cost_type.lower() + \"_cost\"\n",
    "                if obs.get(key) is not None:\n",
    "                    metrics[metric_key] += obs[key]\n",
    "        if len(metrics[\"parameters\"]) == 0:\n",
    "            metrics[\"parameters\"] = \"N/A\"\n",
    "        # Process SPAN observations for status\n",
    "        status_indicators = [\n",
    "            obs[\"name\"]\n",
    "            for obs in observations\n",
    "            if obs[\"type\"] == \"SPAN\" and \"start_\" not in obs[\"name\"]\n",
    "        ]\n",
    "\n",
    "        #  if later than 2025-05-19, use status_signal_from_output\n",
    "        if datetime.now() > datetime(2025, 5, 19):\n",
    "            pass\n",
    "        else:\n",
    "            # Determine status\n",
    "            success_signals = sum(\"end_\" in name for name in status_indicators)\n",
    "            failure_signals = sum(\n",
    "                \"failure_signal\" in name for name in status_indicators\n",
    "            )\n",
    "\n",
    "            if success_signals + failure_signals > 1:\n",
    "                raise ValueError(\n",
    "                    f\"Multiple status indicators found in trace {trace_id}\"\n",
    "                )\n",
    "\n",
    "            metrics[\"status\"] = (\n",
    "                \"success\"\n",
    "                if success_signals\n",
    "                else \"failure\" if failure_signals else \"unknown\"\n",
    "            )\n",
    "\n",
    "        metrics[\"prompt_cost\"] = metrics.pop(\"input_cost\")\n",
    "        metrics[\"completion_cost\"] = metrics.pop(\"output_cost\")\n",
    "        metrics[\"latency\"] = round(metrics[\"latency\"] / 1000, 2)\n",
    "        return metrics\n",
    "\n",
    "    def cal_time(trace):\n",
    "        time_diff = datetime.fromisoformat(\n",
    "            trace[\"updatedAt\"].replace(\"Z\", \"+00:00\")\n",
    "        ) - datetime.fromisoformat(trace[\"createdAt\"].replace(\"Z\", \"+00:00\"))\n",
    "        seconds_diff = time_diff.total_seconds()\n",
    "        return seconds_diff\n",
    "\n",
    "    try:\n",
    "\n",
    "        if session_id.startswith(\"da0a\"):\n",
    "            session_id = \"phi4_\" + session_id\n",
    "        simple_session_id = session_id.rsplit(\"_\", 2)[0]\n",
    "\n",
    "        \n",
    "        # Load JSON data\n",
    "        if \"tpsg\" in session_id:\n",
    "                session_id_ = session_id.replace(\"tpsg\", \"tpusg\")\n",
    "        else:\n",
    "                session_id_ = session_id\n",
    "        trimmed_path = os.path.join(raw_export_dir, f\"trimmed_{session_id_}.json\")\n",
    "        print(\n",
    "            f\"Processing session {session_id}, simple id {simple_session_id}. Look for {trimmed_path}\"\n",
    "        )\n",
    "        with open(trimmed_path, \"r\") as file:\n",
    "            traces = json.load(file)[\"data\"]\n",
    "\n",
    "        # Process traces\n",
    "        rows = [\n",
    "            {\n",
    "                \"num_run\": trace[\"metadata\"][\"num_run\"],\n",
    "                \"name\": trace[\"name\"],\n",
    "                \"trace_id\": trace[\"id\"],\n",
    "                \"batch_id\": trace[\"session_id\"],\n",
    "                # \"latency\": cal_time(trace),\n",
    "                # \"latency\": round(trace[\"latency\"], 2),\n",
    "                **extract_observation_details(\n",
    "                    trace[\"observations\"],\n",
    "                    trace[\"id\"],\n",
    "                ),\n",
    "                \"status\": (\n",
    "                    \"failure\"\n",
    "                    if trace[\"output\"][\"status\"].lower() == \"failed\"\n",
    "                    else \"success\"\n",
    "                ),\n",
    "                \"tags\": trace[\"tags\"],\n",
    "                \"timestamp\": int(parser.isoparse(trace[\"timestamp\"]).timestamp()),\n",
    "            }\n",
    "            for trace in traces\n",
    "        ]\n",
    "        # print(rows)\n",
    "        # print(rows)\n",
    "        # Create and save DataFrame\n",
    "        df = pd.DataFrame(rows).sort_values(\"num_run\")\n",
    "\n",
    "        output_dir = os.path.join(processed_data_dir, f\"{simple_session_id}\")\n",
    "        if not os.path.exists(output_dir):\n",
    "            os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "        output_path = os.path.join(output_dir, f\"clean_{session_id_}.csv\")\n",
    "\n",
    "        print(output_path)\n",
    "        df.to_csv(output_path, index=False)\n",
    "        print(f\"Successfully saved CSV to: {output_path}\")\n",
    "\n",
    "    except FileNotFoundError as e:\n",
    "        print(\n",
    "            f\"FileNotFoundError: For session {session_id} not found. Looked for {trimmed_path}\\nError info: \\n{e}\\n\\nTraceback: {traceback.format_exc()}\"\n",
    "        )\n",
    "    except json.JSONDecodeError:\n",
    "        print(f\"Error: Invalid JSON format in input file for session {session_id}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing session {session_id}: {str(e)}\")\n",
    "\n",
    "\n",
    "# Example usage\n",
    "for session_id in session_id_list:\n",
    "    json_to_csv(session_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code below is archived\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"\"\"Simply calculate success rate\"\"\"\n",
    "\n",
    "\n",
    "# def cal_success_rate(session_id):\n",
    "\n",
    "#     end_signal_count = 0\n",
    "#     failure_signal_count = 0\n",
    "#     # Function to print the name of each observation\n",
    "#     with open(f\"{raw_export_dir}/trimmed_{session_id}.json\", \"r\") as file:\n",
    "#         data = json.load(file)[\"data\"]\n",
    "#     for i in data:\n",
    "\n",
    "#         observations = i[\"observations\"]\n",
    "\n",
    "#         for observation in observations:\n",
    "#             # print(type(observation))\n",
    "#             for key, value in observation.items():\n",
    "#                 # print(f\"{key}: {value}\")\n",
    "#                 for key, value in value.items():\n",
    "#                     # print(f\"{key}: {value}\")\n",
    "#                     if key == \"name\":\n",
    "#                         if \"end_\" in value:\n",
    "\n",
    "#                             end_signal_count += 1\n",
    "#                         if \"failure_signal\" in value:\n",
    "\n",
    "#                             failure_signal_count += 1\n",
    "\n",
    "#     print(f\"Session ID: {session_id}\")\n",
    "#     total_count = end_signal_count + failure_signal_count\n",
    "#     if total_count > 0:\n",
    "#         success_rate = end_signal_count / total_count\n",
    "#         print(f\"Success rate: {success_rate:.4f}\")\n",
    "#     else:\n",
    "#         print(\"Success rate: N/A (no signals found)\")\n",
    "#     print(f\"Passed:\\t{end_signal_count}\\nFailed:\\t{failure_signal_count}\")\n",
    "#     print(\n",
    "#         \"\"\n",
    "#         if total_count == 30\n",
    "#         else \"Number of ending signals does not match the expected number!\"\n",
    "#     )\n",
    "#     print(\"-\" * 50)\n",
    "\n",
    "\n",
    "# for session_id in session_id_list:\n",
    "#     cal_success_rate(session_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def cal_time(start_time, end_time):\n",
    "#     time_diff = datetime.fromisoformat(\n",
    "#         end_time.replace(\"Z\", \"+00:00\")\n",
    "#     ) - datetime.fromisoformat(start_time.replace(\"Z\", \"+00:00\"))\n",
    "#     seconds_diff = time_diff.total_seconds()\n",
    "#     return seconds_diff\n",
    "\n",
    "\n",
    "# print(cal_time(\"2025-01-15T03:31:56.150000+00:00\", \"2025-01-15T03:32:59.384Z\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"\"\"Print the complete structure of exported json file\"\"\"\n",
    "# def print_keys(d, parent_key=''):\n",
    "#     if isinstance(d, dict):\n",
    "#         for key, value in d.items():\n",
    "#             full_key = f\"{parent_key}.{key}\" if parent_key else key\n",
    "#             print(full_key)\n",
    "#             print_keys(value, full_key)\n",
    "#     elif isinstance(d, list):\n",
    "#         for i, item in enumerate(d):\n",
    "#             full_key = f\"{parent_key}[{i}]\"\n",
    "#             print_keys(item, full_key)\n",
    "\n",
    "# # Load JSON data from a file\n",
    "# with open('fetch_traces_response.json', 'r') as file:\n",
    "#     data = json.load(file)['data'][0]\n",
    "# # Print all keys\n",
    "# print_keys(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1747226053\n",
      "1747226053.1\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "from dateutil import parser\n",
    "\n",
    "timestamp_str = \"2025-05-14T12:34:13.100000+00:00\"\n",
    "dt = parser.isoparse(\n",
    "    timestamp_str\n",
    ")  # Or datetime.fromisoformat(timestamp_str) if no timezone offset\n",
    "unix_ts = int(dt.timestamp())\n",
    "\n",
    "print(unix_ts)  # This will print the integer Unix timestamp\n",
    "print(datetime.fromisoformat(timestamp_str).timestamp())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datasci2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

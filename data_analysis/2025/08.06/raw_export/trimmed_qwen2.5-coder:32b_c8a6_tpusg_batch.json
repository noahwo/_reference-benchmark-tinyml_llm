{
  "data": [
    {
      "id": "26571fe8",
      "timestamp": "2025-08-04T02:44:21.815000+00:00",
      "name": "2657_tpu_sketch_generator",
      "input": null,
      "output": {
        "status": "failed",
        "last_code": "import numpy as np\nfrom tflite_runtime.interpreter import Interpreter, load_delegate\nimport cv2\n\n# Phase 1: Setup\nmodel_path  = \"/home/mendel/tinyml_autopilot/models/edgetpu_detect.tflite\"\nlabel_path  = \"/home/mendel/tinyml_autopilot/models/labelmap.txt\"\ninput_path  = \"/home/mendel/tinyml_autopilot/data//sheeps.mp4\"\noutput_path  = \"/home/mendel/tinyml_autopilot/results/sheeps_detections.mp4\"\nconfidence_threshold  = 0.5\n\n# Load labels\nwith open(label_path, 'r') as f:\n    labels = [line.strip() for line in f.readlines()]\n\n# Load Interpreter with EdgeTPU\ntry:\n    interpreter = Interpreter(model_path=model_path,\n                              experimental_delegates=[load_delegate('libedgetpu.so.1.0')])\nexcept Exception as e:\n    print(f\"Failed to load libedgetpu.so.1.0: {e}\")\n    try:\n        interpreter = Interpreter(model_path=model_path,\n                                  experimental_delegates=[load_delegate('/usr/lib/aarch64-linux-gnu/libedgetpu.so.1.0')])\n    except Exception as e:\n        print(f\"Failed to load /usr/lib/aarch64-linux-gnu/libedgetpu.so.1.0: {e}\")\n        raise\n\ninterpreter.allocate_tensors()\n\n# Get Model Details\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\n\nfloating_model = (input_details[0]['dtype'] == np.float32)\n\n# Phase 2: Input Acquisition & Preprocessing Loop\ncap = cv2.VideoCapture(input_path)\nif not cap.isOpened():\n    raise IOError(\"Cannot open video file\")\n\nframe_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\nframe_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\nfps = cap.get(cv2.CAP_PROP_FPS)\n\nout = cv2.VideoWriter(output_path, cv2.VideoWriter_fourcc(*'mp4v'), fps, (frame_width, frame_height))\n\nwhile True:\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    # Preprocess Data\n    input_data = cv2.resize(frame, (input_details[0]['shape'][1], input_details[0]['shape'][2]))\n    input_data = np.expand_dims(input_data, axis=0)\n\n    if floating_model:\n        input_data = (np.float32(input_data) - 127.5) / 127.5\n\n    # Phase 3: Inference\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n    interpreter.invoke()\n\n    # Phase 4: Output Interpretation & Handling Loop\n    output_data = interpreter.get_tensor(output_details[0]['index'])\n    \n    # Ensure num_detections is a scalar value\n    num_detections_array = interpreter.get_tensor(output_details[1]['index'])\n    if isinstance(num_detections_array, np.ndarray):\n        num_detections = int(num_detections_array[0])\n    else:\n        num_detections = int(num_detections_array)\n\n    detection_boxes = interpreter.get_tensor(output_details[2]['index'])[0]\n    detection_classes = interpreter.get_tensor(output_details[3]['index'])[0].astype(int)\n    detection_scores = interpreter.get_tensor(output_details[4]['index'])[0]\n\n    for i in range(num_detections):\n        if detection_scores[i] > confidence_threshold:\n            box = detection_boxes[i]\n            class_id = detection_classes[i]\n            score = detection_scores[i]\n\n            # Scale and clip bounding boxes\n            ymin, xmin, ymax, xmax = box\n            (left, right, top, bottom) = (xmin * frame_width, xmax * frame_width,\n                                          ymin * frame_height, ymax * frame_height)\n\n            cv2.rectangle(frame, (int(left), int(top)), (int(right), int(bottom)), (0, 255, 0), 2)\n            label = f'{labels[class_id]}: {score:.2f}'\n            cv2.putText(frame, label, (int(left), int(top) - 10),\n                        cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n\n    # Handle Output\n    out.write(frame)\n\n# Phase 5: Cleanup\ncap.release()\nout.release()\ncv2.destroyAllWindows()",
        "last_error": "Traceback (most recent call last):\n  File \"script_8638f51f_1754275645.py\", line 70, in <module>\n    num_detections = int(num_detections_array[0])\nTypeError: only size-1 arrays can be converted to Python scalars"
      },
      "session_id": "qwen2.5-coder:32b_c8a6_tpusg_batch",
      "metadata": {
        "num_run": 30
      },
      "tags": [
        "benchmark",
        "qwen2.5-coder:32b",
        "tpu_sketch_generator"
      ],
      "latency": 192.179,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-05-44-21-817331_chatcmpl-54d43908-60cf-467b-878c-9a4bc79f8348",
          "traceId": "26571fe8",
          "type": "GENERATION",
          "name": "2657_tpusg_gen_attempt#1",
          "startTime": "2025-08-04T02:44:21.817000+00:00",
          "endTime": "2025-08-04T02:44:47.271000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 25454.0,
          "environment": "default",
          "promptTokens": 1833,
          "totalTokens": 2709,
          "costDetails": {},
          "completionTokens": 876,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-05-44-55-412961_chatcmpl-05b5f5ba-9a2d-4429-a209-c1c17211b72a",
          "traceId": "26571fe8",
          "type": "GENERATION",
          "name": "2657_tpusg_gen_attempt#2",
          "startTime": "2025-08-04T02:44:55.412000+00:00",
          "endTime": "2025-08-04T02:45:27.075000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 31663.0,
          "environment": "default",
          "promptTokens": 2048,
          "totalTokens": 3154,
          "costDetails": {},
          "completionTokens": 1106,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-05-45-35-133966_chatcmpl-2af6b957-6fc8-4c37-a2c5-255d4d4c8c89",
          "traceId": "26571fe8",
          "type": "GENERATION",
          "name": "2657_tpusg_gen_attempt#3",
          "startTime": "2025-08-04T02:45:35.133000+00:00",
          "endTime": "2025-08-04T02:46:07.057000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 31924.0,
          "environment": "default",
          "promptTokens": 2048,
          "totalTokens": 3163,
          "costDetails": {},
          "completionTokens": 1115,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-05-46-15-341151_chatcmpl-5546cb3e-a1ab-4560-92d1-952a87c74ff1",
          "traceId": "26571fe8",
          "type": "GENERATION",
          "name": "2657_tpusg_gen_attempt#4",
          "startTime": "2025-08-04T02:46:15.341000+00:00",
          "endTime": "2025-08-04T02:46:46.778000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 31437.0,
          "environment": "default",
          "promptTokens": 2048,
          "totalTokens": 3144,
          "costDetails": {},
          "completionTokens": 1096,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-05-46-54-813023_chatcmpl-dcf7539c-cbf9-421c-8dc7-5d1f1ce85bb4",
          "traceId": "26571fe8",
          "type": "GENERATION",
          "name": "2657_tpusg_gen_attempt#5",
          "startTime": "2025-08-04T02:46:54.813000+00:00",
          "endTime": "2025-08-04T02:47:25.894000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 31081.0,
          "environment": "default",
          "promptTokens": 2048,
          "totalTokens": 3126,
          "costDetails": {},
          "completionTokens": 1078,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "d3a4a7f3-3b42-4e3f-96eb-8c64b0db115d",
          "traceId": "26571fe8",
          "type": "SPAN",
          "name": "error_26_tpusg_failure_signal_tpu_sketch_generator",
          "startTime": "2025-08-04T02:47:33.996000+00:00",
          "level": "ERROR",
          "statusMessage": "Failed. Last error: Traceback (most recent call last):\n  File \"script_8638f51f_1754275645.py\", line 70, in <module>\n    num_detections = int(num_detections_array[0])\nTypeError: only size-1 arrays can be converted to Python scalars",
          "calculatedTotalCost": 0.0,
          "environment": "default",
          "promptTokens": 0,
          "totalTokens": 0,
          "costDetails": {},
          "completionTokens": 0,
          "endTime": null,
          "model": null,
          "modelParameters": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null,
          "latency": null
        }
      ],
      "createdAt": "2025-08-04T02:44:22.342Z",
      "environment": "default",
      "updatedAt": "2025-08-04T02:47:39.631Z"
    },
    {
      "id": "5bedd87c",
      "timestamp": "2025-08-04T02:41:01.228000+00:00",
      "name": "5bed_tpu_sketch_generator",
      "input": null,
      "output": {
        "status": "failed",
        "last_code": "import numpy as np\nfrom tflite_runtime.interpreter import Interpreter, load_delegate\n\n# Phase 1: Setup\nmodel_path  = \"/home/mendel/tinyml_autopilot/models/edgetpu_detect.tflite\"\nlabel_path  = \"/home/mendel/tinyml_autopilot/models/labelmap.txt\"\ninput_path  = \"/home/mendel/tinyml_autopilot/data//sheeps.mp4\"\noutput_path  = \"/home/mendel/tinyml_autopilot/results/sheeps_detections.mp4\"\nconfidence_threshold  = 0.5\n\n# Load labels\nwith open(label_path, 'r') as f:\n    labels = [line.strip() for line in f.readlines()]\n\n# Load Interpreter with EdgeTPU\ntry:\n    interpreter = Interpreter(model_path=model_path,\n                              experimental_delegates=[load_delegate('libedgetpu.so.1.0')])\nexcept Exception as e:\n    print(f\"Failed to load libedgetpu.so.1.0: {e}\")\n    try:\n        interpreter = Interpreter(model_path=model_path,\n                                  experimental_delegates=[load_delegate('/usr/lib/aarch64-linux-gnu/libedgetpu.so.1.0')])\n    except Exception as e:\n        print(f\"Failed to load /usr/lib/aarch64-linux-gnu/libedgetpu.so.1.0: {e}\")\n        raise\n\ninterpreter.allocate_tensors()\n\n# Get Model Details\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\n\nfloating_model = (input_details[0]['dtype'] == np.float32)\n\n# Phase 2: Input Acquisition & Preprocessing Loop\nimport cv2\n\ncap = cv2.VideoCapture(input_path)\nif not cap.isOpened():\n    raise IOError(\"Cannot open video file\")\n\nframe_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\nframe_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\nfps = cap.get(cv2.CAP_PROP_FPS)\n\nout = cv2.VideoWriter(output_path, cv2.VideoWriter_fourcc(*'mp4v'), fps, (frame_width, frame_height))\n\nwhile True:\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    # Preprocess Data\n    input_data = cv2.resize(frame, (input_details[0]['shape'][1], input_details[0]['shape'][2]))\n    input_data = np.expand_dims(input_data, axis=0)\n\n    if floating_model:\n        input_data = (np.float32(input_data) - 127.5) / 127.5\n\n    # Phase 3: Inference\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n    interpreter.invoke()\n\n    # Phase 4: Output Interpretation & Handling Loop\n    output_data = interpreter.get_tensor(output_details[0]['index'])\n    num_detections = int(interpreter.get_tensor(output_details[1]['index']))  # Access the scalar value directly\n\n    detection_boxes = interpreter.get_tensor(output_details[2]['index'])[0]\n    detection_classes = interpreter.get_tensor(output_details[3]['index'])[0].astype(int)\n    detection_scores = interpreter.get_tensor(output_details[4]['index'])[0]\n\n    for i in range(num_detections):\n        if detection_scores[i] > confidence_threshold:\n            box = detection_boxes[i]\n            class_id = detection_classes[i]\n            score = detection_scores[i]\n\n            # Scale and clip bounding boxes\n            ymin, xmin, ymax, xmax = box\n            (left, right, top, bottom) = (xmin * frame_width, xmax * frame_width,\n                                          ymin * frame_height, ymax * frame_height)\n\n            cv2.rectangle(frame, (int(left), int(top)), (int(right), int(bottom)), (0, 255, 0), 2)\n            label = f'{labels[class_id]}: {score:.2f}'\n            cv2.putText(frame, label, (int(left), int(top) - 10),\n                        cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n\n    # Handle Output\n    out.write(frame)\n\n# Phase 5: Cleanup\ncap.release()\nout.release()\ncv2.destroyAllWindows()",
        "last_error": "Traceback (most recent call last):\n  File \"script_f360e89e_1754275447.py\", line 67, in <module>\n    num_detections = int(interpreter.get_tensor(output_details[1]['index']))  # Access the scalar value directly\nTypeError: only size-1 arrays can be converted to Python scalars"
      },
      "session_id": "qwen2.5-coder:32b_c8a6_tpusg_batch",
      "metadata": {
        "num_run": 29
      },
      "tags": [
        "benchmark",
        "qwen2.5-coder:32b",
        "tpu_sketch_generator"
      ],
      "latency": 194.705,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-05-41-01-230099_chatcmpl-e68009e1-531b-4faf-9000-bac327e88ca7",
          "traceId": "5bedd87c",
          "type": "GENERATION",
          "name": "5bed_tpusg_gen_attempt#1",
          "startTime": "2025-08-04T02:41:01.230000+00:00",
          "endTime": "2025-08-04T02:41:26.668000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 25438.0,
          "environment": "default",
          "promptTokens": 1833,
          "totalTokens": 2709,
          "costDetails": {},
          "completionTokens": 876,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-05-41-34-732818_chatcmpl-310d926c-4e06-458b-b32f-ac2fdd7f867f",
          "traceId": "5bedd87c",
          "type": "GENERATION",
          "name": "5bed_tpusg_gen_attempt#2",
          "startTime": "2025-08-04T02:41:34.732000+00:00",
          "endTime": "2025-08-04T02:42:07.059000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 32327.0,
          "environment": "default",
          "promptTokens": 2048,
          "totalTokens": 3178,
          "costDetails": {},
          "completionTokens": 1130,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-05-42-15-333418_chatcmpl-07145d05-85e7-44af-86e0-bec968016f68",
          "traceId": "5bedd87c",
          "type": "GENERATION",
          "name": "5bed_tpusg_gen_attempt#3",
          "startTime": "2025-08-04T02:42:15.333000+00:00",
          "endTime": "2025-08-04T02:42:47.952000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 32619.0,
          "environment": "default",
          "promptTokens": 2048,
          "totalTokens": 3190,
          "costDetails": {},
          "completionTokens": 1142,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-05-42-56-048823_chatcmpl-d8c7c835-fae1-4c7a-9137-8c6364ef69ed",
          "traceId": "5bedd87c",
          "type": "GENERATION",
          "name": "5bed_tpusg_gen_attempt#4",
          "startTime": "2025-08-04T02:42:56.048000+00:00",
          "endTime": "2025-08-04T02:43:28.071000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 32023.0,
          "environment": "default",
          "promptTokens": 2048,
          "totalTokens": 3168,
          "costDetails": {},
          "completionTokens": 1120,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-05-43-36-238968_chatcmpl-d89f0378-76a2-49a3-acac-e581cafcd88c",
          "traceId": "5bedd87c",
          "type": "GENERATION",
          "name": "5bed_tpusg_gen_attempt#5",
          "startTime": "2025-08-04T02:43:36.238000+00:00",
          "endTime": "2025-08-04T02:44:07.691000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 31453.0,
          "environment": "default",
          "promptTokens": 2048,
          "totalTokens": 3145,
          "costDetails": {},
          "completionTokens": 1097,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "d5436049-eda9-49d5-9959-ddddf9735417",
          "traceId": "5bedd87c",
          "type": "SPAN",
          "name": "error_5b_tpusg_failure_signal_tpu_sketch_generator",
          "startTime": "2025-08-04T02:44:15.935000+00:00",
          "level": "ERROR",
          "statusMessage": "Failed. Last error: Traceback (most recent call last):\n  File \"script_f360e89e_1754275447.py\", line 67, in <module>\n    num_detections = int(interpreter.get_tensor(output_details[1]['index']))  # Access the scalar value directly\nTypeError: only size-1 arrays can be converted to Python scalars",
          "calculatedTotalCost": 0.0,
          "environment": "default",
          "promptTokens": 0,
          "totalTokens": 0,
          "costDetails": {},
          "completionTokens": 0,
          "endTime": null,
          "model": null,
          "modelParameters": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null,
          "latency": null
        }
      ],
      "createdAt": "2025-08-04T02:41:01.751Z",
      "environment": "default",
      "updatedAt": "2025-08-04T02:44:21.492Z"
    },
    {
      "id": "ba5ae0bb",
      "timestamp": "2025-08-04T02:37:42.657000+00:00",
      "name": "ba5a_tpu_sketch_generator",
      "input": null,
      "output": {
        "status": "failed",
        "last_code": "import numpy as np\nfrom tflite_runtime.interpreter import Interpreter, load_delegate\nimport cv2\n\n# Phase 1: Setup\nmodel_path  = \"/home/mendel/tinyml_autopilot/models/edgetpu_detect.tflite\"\nlabel_path  = \"/home/mendel/tinyml_autopilot/models/labelmap.txt\"\ninput_path  = \"/home/mendel/tinyml_autopilot/data//sheeps.mp4\"\noutput_path  = \"/home/mendel/tinyml_autopilot/results/sheeps_detections.mp4\"\nconfidence_threshold  = 0.5\n\n# Load labels\nwith open(label_path, 'r') as f:\n    labels = [line.strip() for line in f.readlines()]\n\n# Load Interpreter with EdgeTPU\ntry:\n    interpreter = Interpreter(model_path=model_path,\n                              experimental_delegates=[load_delegate('libedgetpu.so.1.0')])\nexcept Exception as e:\n    print(f\"Failed to load libedgetpu.so.1.0: {e}\")\n    try:\n        interpreter = Interpreter(model_path=model_path,\n                                  experimental_delegates=[load_delegate('/usr/lib/aarch64-linux-gnu/libedgetpu.so.1.0')])\n    except Exception as e:\n        print(f\"Failed to load /usr/lib/aarch64-linux-gnu/libedgetpu.so.1.0: {e}\")\n        raise\n\ninterpreter.allocate_tensors()\n\n# Get Model Details\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\n\nfloating_model = (input_details[0]['dtype'] == np.float32)\n\n# Phase 2: Input Acquisition & Preprocessing Loop\ncap = cv2.VideoCapture(input_path)\nif not cap.isOpened():\n    raise IOError(\"Cannot open video file\")\n\nframe_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\nframe_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\nfps = cap.get(cv2.CAP_PROP_FPS)\n\nout = cv2.VideoWriter(output_path, cv2.VideoWriter_fourcc(*'mp4v'), fps, (frame_width, frame_height))\n\nwhile True:\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    # Preprocess Data\n    input_data = cv2.resize(frame, (input_details[0]['shape'][1], input_details[0]['shape'][2]))\n    input_data = np.expand_dims(input_data, axis=0)\n\n    if floating_model:\n        input_data = (np.float32(input_data) - 127.5) / 127.5\n\n    # Phase 3: Inference\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n    interpreter.invoke()\n\n    # Phase 4: Output Interpretation & Handling Loop\n    output_data = interpreter.get_tensor(output_details[0]['index'])\n    num_detections = int(interpreter.get_tensor(output_details[1]['index']))  # Directly convert to int\n    detection_boxes = interpreter.get_tensor(output_details[2]['index'])[0]\n    detection_classes = interpreter.get_tensor(output_details[3]['index'])[0].astype(int)\n    detection_scores = interpreter.get_tensor(output_details[4]['index'])[0]\n\n    for i in range(num_detections):\n        if detection_scores[i] > confidence_threshold:\n            box = detection_boxes[i]\n            class_id = detection_classes[i]\n            score = detection_scores[i]\n\n            # Scale the bounding box coordinates\n            ymin, xmin, ymax, xmax = box\n            (left, right, top, bottom) = (xmin * frame_width, xmax * frame_width,\n                                          ymin * frame_height, ymax * frame_height)\n\n            # Draw the bounding box and label on the frame\n            cv2.rectangle(frame, (int(left), int(top)), (int(right), int(bottom)), (0, 255, 0), 2)\n            label = f'{labels[class_id]}: {score:.2f}'\n            cv2.putText(frame, label, (int(left), int(top) - 10),\n                        cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n\n    # Write the frame to the output video\n    out.write(frame)\n\n# Phase 5: Cleanup\ncap.release()\nout.release()\ncv2.destroyAllWindows()",
        "last_error": "Traceback (most recent call last):\n  File \"script_cb1c38a0_1754275248.py\", line 66, in <module>\n    num_detections = int(interpreter.get_tensor(output_details[1]['index']))  # Directly convert to int\nTypeError: only size-1 arrays can be converted to Python scalars"
      },
      "session_id": "qwen2.5-coder:32b_c8a6_tpusg_batch",
      "metadata": {
        "num_run": 28
      },
      "tags": [
        "benchmark",
        "qwen2.5-coder:32b",
        "tpu_sketch_generator"
      ],
      "latency": 193.5,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-05-37-42-658874_chatcmpl-3d7ff1e7-2f09-4f5f-99c5-201fa2a17a38",
          "traceId": "ba5ae0bb",
          "type": "GENERATION",
          "name": "ba5a_tpusg_gen_attempt#1",
          "startTime": "2025-08-04T02:37:42.658000+00:00",
          "endTime": "2025-08-04T02:38:08.553000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 25895.0,
          "environment": "default",
          "promptTokens": 1833,
          "totalTokens": 2726,
          "costDetails": {},
          "completionTokens": 893,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-05-38-16-805502_chatcmpl-8bd83262-0b00-49e0-ae95-b8d3b2109a93",
          "traceId": "ba5ae0bb",
          "type": "GENERATION",
          "name": "ba5a_tpusg_gen_attempt#2",
          "startTime": "2025-08-04T02:38:16.805000+00:00",
          "endTime": "2025-08-04T02:38:47.759000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 30954.0,
          "environment": "default",
          "promptTokens": 2048,
          "totalTokens": 3126,
          "costDetails": {},
          "completionTokens": 1078,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-05-38-55-938580_chatcmpl-b32b4a74-90f7-47e8-a9c0-c6f4d31748e1",
          "traceId": "ba5ae0bb",
          "type": "GENERATION",
          "name": "ba5a_tpusg_gen_attempt#3",
          "startTime": "2025-08-04T02:38:55.938000+00:00",
          "endTime": "2025-08-04T02:39:27.903000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 31965.0,
          "environment": "default",
          "promptTokens": 2048,
          "totalTokens": 3165,
          "costDetails": {},
          "completionTokens": 1117,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-05-39-35-995449_chatcmpl-f89f776d-30a9-4472-911c-564ef67e0196",
          "traceId": "ba5ae0bb",
          "type": "GENERATION",
          "name": "ba5a_tpusg_gen_attempt#4",
          "startTime": "2025-08-04T02:39:35.995000+00:00",
          "endTime": "2025-08-04T02:40:06.990000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 30995.0,
          "environment": "default",
          "promptTokens": 2048,
          "totalTokens": 3128,
          "costDetails": {},
          "completionTokens": 1080,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-05-40-15-309521_chatcmpl-494c5f24-728e-4005-af25-cc91eec2d614",
          "traceId": "ba5ae0bb",
          "type": "GENERATION",
          "name": "ba5a_tpusg_gen_attempt#5",
          "startTime": "2025-08-04T02:40:15.309000+00:00",
          "endTime": "2025-08-04T02:40:48.013000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 32704.0,
          "environment": "default",
          "promptTokens": 2048,
          "totalTokens": 3192,
          "costDetails": {},
          "completionTokens": 1144,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "05c54ca2-9883-4eca-af97-7cd4c73f1bd4",
          "traceId": "ba5ae0bb",
          "type": "SPAN",
          "name": "error_ba_tpusg_failure_signal_tpu_sketch_generator",
          "startTime": "2025-08-04T02:40:56.158000+00:00",
          "level": "ERROR",
          "statusMessage": "Failed. Last error: Traceback (most recent call last):\n  File \"script_cb1c38a0_1754275248.py\", line 66, in <module>\n    num_detections = int(interpreter.get_tensor(output_details[1]['index']))  # Directly convert to int\nTypeError: only size-1 arrays can be converted to Python scalars",
          "calculatedTotalCost": 0.0,
          "environment": "default",
          "promptTokens": 0,
          "totalTokens": 0,
          "costDetails": {},
          "completionTokens": 0,
          "endTime": null,
          "model": null,
          "modelParameters": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null,
          "latency": null
        }
      ],
      "createdAt": "2025-08-04T02:37:43.179Z",
      "environment": "default",
      "updatedAt": "2025-08-04T02:41:01.452Z"
    },
    {
      "id": "70473163",
      "timestamp": "2025-08-04T02:34:07.964000+00:00",
      "name": "7047_tpu_sketch_generator",
      "input": null,
      "output": {
        "status": "failed",
        "last_code": "num_detections = int(interpreter.get_tensor(output_details[1]['index'])[0])  # Extract the scalar value from the array",
        "last_error": "Unexpected error during generation: Generated script is not complete. Please ensure to generate a complete Python script."
      },
      "session_id": "qwen2.5-coder:32b_c8a6_tpusg_batch",
      "metadata": {
        "num_run": 27
      },
      "tags": [
        "benchmark",
        "qwen2.5-coder:32b",
        "tpu_sketch_generator"
      ],
      "latency": 208.928,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-05-34-07-966482_chatcmpl-baa8b294-f2d6-4f11-b51e-3733fc9f1729",
          "traceId": "70473163",
          "type": "GENERATION",
          "name": "7047_tpusg_gen_attempt#1",
          "startTime": "2025-08-04T02:34:07.966000+00:00",
          "endTime": "2025-08-04T02:34:33.428000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 25462.0,
          "environment": "default",
          "promptTokens": 1833,
          "totalTokens": 2709,
          "costDetails": {},
          "completionTokens": 876,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-05-34-41-489765_chatcmpl-ffbd3c96-b302-4f82-b927-3fe6304ab97f",
          "traceId": "70473163",
          "type": "GENERATION",
          "name": "7047_tpusg_gen_attempt#2",
          "startTime": "2025-08-04T02:34:41.489000+00:00",
          "endTime": "2025-08-04T02:35:14.111000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 32622.0,
          "environment": "default",
          "promptTokens": 2048,
          "totalTokens": 3190,
          "costDetails": {},
          "completionTokens": 1142,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-05-35-22-480338_chatcmpl-7eb45ecc-a9d8-43cf-bcd6-59065bf53928",
          "traceId": "70473163",
          "type": "GENERATION",
          "name": "7047_tpusg_gen_attempt#3",
          "startTime": "2025-08-04T02:35:22.480000+00:00",
          "endTime": "2025-08-04T02:35:52.257000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 29777.0,
          "environment": "default",
          "promptTokens": 2048,
          "totalTokens": 3081,
          "costDetails": {},
          "completionTokens": 1033,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-05-36-00-373730_chatcmpl-9e205609-9f59-4f51-adaf-d3a6e8d40823",
          "traceId": "70473163",
          "type": "GENERATION",
          "name": "7047_tpusg_gen_attempt#4",
          "startTime": "2025-08-04T02:36:00.373000+00:00",
          "endTime": "2025-08-04T02:36:31.798000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 31425.0,
          "environment": "default",
          "promptTokens": 2048,
          "totalTokens": 3144,
          "costDetails": {},
          "completionTokens": 1096,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-05-36-39-904271_chatcmpl-f1a9dc36-679d-4533-b632-d39b8e15c0b6",
          "traceId": "70473163",
          "type": "GENERATION",
          "name": "7047_tpusg_gen_attempt#5",
          "startTime": "2025-08-04T02:36:39.904000+00:00",
          "endTime": "2025-08-04T02:37:36.887000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 56983.0,
          "environment": "default",
          "promptTokens": 2048,
          "totalTokens": 4104,
          "costDetails": {},
          "completionTokens": 2056,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "ab19396c-b16f-488c-84a5-23b521020daf",
          "traceId": "70473163",
          "type": "SPAN",
          "name": "error_70_tpusg_failure_signal_tpu_sketch_generator",
          "startTime": "2025-08-04T02:37:36.894000+00:00",
          "level": "ERROR",
          "statusMessage": "Failed. Last error: Unexpected error during generation: Generated script is not complete. Please ensure to generate a complete Python script.",
          "calculatedTotalCost": 0.0,
          "environment": "default",
          "promptTokens": 0,
          "totalTokens": 0,
          "costDetails": {},
          "completionTokens": 0,
          "endTime": null,
          "model": null,
          "modelParameters": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null,
          "latency": null
        }
      ],
      "createdAt": "2025-08-04T02:34:08.486Z",
      "environment": "default",
      "updatedAt": "2025-08-04T02:37:42.516Z"
    },
    {
      "id": "1c0a7ecc",
      "timestamp": "2025-08-04T02:30:48.168000+00:00",
      "name": "1c0a_tpu_sketch_generator",
      "input": null,
      "output": {
        "status": "failed",
        "last_code": "import numpy as np\nfrom tflite_runtime.interpreter import Interpreter, load_delegate\nimport cv2\n\n# Phase 1: Setup\nmodel_path  = \"/home/mendel/tinyml_autopilot/models/edgetpu_detect.tflite\"\nlabel_path  = \"/home/mendel/tinyml_autopilot/models/labelmap.txt\"\ninput_path  = \"/home/mendel/tinyml_autopilot/data//sheeps.mp4\"\noutput_path  = \"/home/mendel/tinyml_autopilot/results/sheeps_detections.mp4\"\nconfidence_threshold  = 0.5\n\n# Load labels\nwith open(label_path, 'r') as f:\n    labels = [line.strip() for line in f.readlines()]\n\n# Load Interpreter with EdgeTPU\ntry:\n    interpreter = Interpreter(model_path=model_path,\n                              experimental_delegates=[load_delegate('libedgetpu.so.1.0')])\nexcept Exception as e:\n    print(f\"Failed to load libedgetpu.so.1.0: {e}\")\n    try:\n        interpreter = Interpreter(model_path=model_path,\n                                  experimental_delegates=[load_delegate('/usr/lib/aarch64-linux-gnu/libedgetpu.so.1.0')])\n    except Exception as e:\n        print(f\"Failed to load /usr/lib/aarch64-linux-gnu/libedgetpu.so.1.0: {e}\")\n        raise\n\ninterpreter.allocate_tensors()\n\n# Get Model Details\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\n\nfloating_model = (input_details[0]['dtype'] == np.float32)\n\n# Phase 2: Input Acquisition & Preprocessing Loop\ncap = cv2.VideoCapture(input_path)\nif not cap.isOpened():\n    raise IOError(\"Cannot open video file\")\n\nframe_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\nframe_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\nfps = cap.get(cv2.CAP_PROP_FPS)\n\nout = cv2.VideoWriter(output_path, cv2.VideoWriter_fourcc(*'mp4v'), fps, (frame_width, frame_height))\n\nwhile True:\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    # Preprocess Data\n    input_data = cv2.resize(frame, (input_details[0]['shape'][1], input_details[0]['shape'][2]))\n    input_data = np.expand_dims(input_data, axis=0)\n\n    if floating_model:\n        input_data = (np.float32(input_data) - 127.5) / 127.5\n\n    # Phase 3: Inference\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n    interpreter.invoke()\n\n    # Phase 4: Output Interpretation & Handling Loop\n    output_data = interpreter.get_tensor(output_details[0]['index'])\n    num_detections = int(interpreter.get_tensor(output_details[1]['index'])[0])  # Access the first element directly\n\n    detection_boxes = interpreter.get_tensor(output_details[2]['index'])[0]\n    detection_classes = interpreter.get_tensor(output_details[3]['index'])[0].astype(int)\n    detection_scores = interpreter.get_tensor(output_details[4]['index'])[0]\n\n    for i in range(num_detections):\n        if detection_scores[i] > confidence_threshold:\n            box = detection_boxes[i]\n            class_id = detection_classes[i]\n            score = detection_scores[i]\n\n            # Scale and clip bounding boxes\n            ymin, xmin, ymax, xmax = box\n            (left, right, top, bottom) = (xmin * frame_width, xmax * frame_width,\n                                          ymin * frame_height, ymax * frame_height)\n\n            cv2.rectangle(frame, (int(left), int(top)), (int(right), int(bottom)), (0, 255, 0), 2)\n            label = f'{labels[class_id]}: {score:.2f}'\n            cv2.putText(frame, label, (int(left), int(top) - 10),\n                        cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n\n    # Handle Output\n    out.write(frame)\n\n# Phase 5: Cleanup\ncap.release()\nout.release()\ncv2.destroyAllWindows()",
        "last_error": "Traceback (most recent call last):\n  File \"script_82ec7d55_1754274833.py\", line 66, in <module>\n    num_detections = int(interpreter.get_tensor(output_details[1]['index'])[0])  # Access the first element directly\nTypeError: only size-1 arrays can be converted to Python scalars"
      },
      "session_id": "qwen2.5-coder:32b_c8a6_tpusg_batch",
      "metadata": {
        "num_run": 26
      },
      "tags": [
        "benchmark",
        "qwen2.5-coder:32b",
        "tpu_sketch_generator"
      ],
      "latency": 193.257,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-05-30-48-170275_chatcmpl-e3399915-e6d6-49d0-aa0f-cc8b827d3465",
          "traceId": "1c0a7ecc",
          "type": "GENERATION",
          "name": "1c0a_tpusg_gen_attempt#1",
          "startTime": "2025-08-04T02:30:48.170000+00:00",
          "endTime": "2025-08-04T02:31:13.638000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 25468.0,
          "environment": "default",
          "promptTokens": 1833,
          "totalTokens": 2709,
          "costDetails": {},
          "completionTokens": 876,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-05-31-21-725153_chatcmpl-62a49f10-c501-4ae2-9cdf-72028e9cdd56",
          "traceId": "1c0a7ecc",
          "type": "GENERATION",
          "name": "1c0a_tpusg_gen_attempt#2",
          "startTime": "2025-08-04T02:31:21.725000+00:00",
          "endTime": "2025-08-04T02:31:52.714000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 30989.0,
          "environment": "default",
          "promptTokens": 2048,
          "totalTokens": 3127,
          "costDetails": {},
          "completionTokens": 1079,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-05-32-00-830745_chatcmpl-ed0f72b6-2fd9-4ab7-9faa-c79db69192b1",
          "traceId": "1c0a7ecc",
          "type": "GENERATION",
          "name": "1c0a_tpusg_gen_attempt#3",
          "startTime": "2025-08-04T02:32:00.830000+00:00",
          "endTime": "2025-08-04T02:32:32.772000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 31942.0,
          "environment": "default",
          "promptTokens": 2048,
          "totalTokens": 3157,
          "costDetails": {},
          "completionTokens": 1109,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-05-32-40-841052_chatcmpl-68f31812-d3e8-4b95-aa36-b339590915a1",
          "traceId": "1c0a7ecc",
          "type": "GENERATION",
          "name": "1c0a_tpusg_gen_attempt#4",
          "startTime": "2025-08-04T02:32:40.841000+00:00",
          "endTime": "2025-08-04T02:33:13.086000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 32245.0,
          "environment": "default",
          "promptTokens": 2048,
          "totalTokens": 3173,
          "costDetails": {},
          "completionTokens": 1125,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-05-33-21-627895_chatcmpl-e13f42e0-0428-4e7a-80dd-75d9e1b802f0",
          "traceId": "1c0a7ecc",
          "type": "GENERATION",
          "name": "1c0a_tpusg_gen_attempt#5",
          "startTime": "2025-08-04T02:33:21.627000+00:00",
          "endTime": "2025-08-04T02:33:53.298000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 31671.0,
          "environment": "default",
          "promptTokens": 2048,
          "totalTokens": 3154,
          "costDetails": {},
          "completionTokens": 1106,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "e46032d9-e575-408e-a6bc-5cde5369c38e",
          "traceId": "1c0a7ecc",
          "type": "SPAN",
          "name": "error_1c_tpusg_failure_signal_tpu_sketch_generator",
          "startTime": "2025-08-04T02:34:01.427000+00:00",
          "level": "ERROR",
          "statusMessage": "Failed. Last error: Traceback (most recent call last):\n  File \"script_82ec7d55_1754274833.py\", line 66, in <module>\n    num_detections = int(interpreter.get_tensor(output_details[1]['index'])[0])  # Access the first element directly\nTypeError: only size-1 arrays can be converted to Python scalars",
          "calculatedTotalCost": 0.0,
          "environment": "default",
          "promptTokens": 0,
          "totalTokens": 0,
          "costDetails": {},
          "completionTokens": 0,
          "endTime": null,
          "model": null,
          "modelParameters": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null,
          "latency": null
        }
      ],
      "createdAt": "2025-08-04T02:30:48.690Z",
      "environment": "default",
      "updatedAt": "2025-08-04T02:34:06.920Z"
    },
    {
      "id": "358a1f5a",
      "timestamp": "2025-08-04T02:27:36.532000+00:00",
      "name": "358a_tpu_sketch_generator",
      "input": null,
      "output": {
        "status": "failed",
        "last_code": "num_detections = int(interpreter.get_tensor(output_details[1]['index'])[0])  # Correctly extract the scalar value from the array",
        "last_error": "Unexpected error during generation: Generated script is not complete. Please ensure to generate a complete Python script."
      },
      "session_id": "qwen2.5-coder:32b_c8a6_tpusg_batch",
      "metadata": {
        "num_run": 25
      },
      "tags": [
        "benchmark",
        "qwen2.5-coder:32b",
        "tpu_sketch_generator"
      ],
      "latency": 185.125,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-05-27-36-534257_chatcmpl-669fd40f-d112-4c2a-8bbc-cc4ba26b13cc",
          "traceId": "358a1f5a",
          "type": "GENERATION",
          "name": "358a_tpusg_gen_attempt#1",
          "startTime": "2025-08-04T02:27:36.534000+00:00",
          "endTime": "2025-08-04T02:28:01.990000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 25456.0,
          "environment": "default",
          "promptTokens": 1833,
          "totalTokens": 2709,
          "costDetails": {},
          "completionTokens": 876,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-05-28-10-022876_chatcmpl-e4f34b9f-4cf3-41f3-aa17-c554c6672ab2",
          "traceId": "358a1f5a",
          "type": "GENERATION",
          "name": "358a_tpusg_gen_attempt#2",
          "startTime": "2025-08-04T02:28:10.022000+00:00",
          "endTime": "2025-08-04T02:28:42.727000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 32705.0,
          "environment": "default",
          "promptTokens": 2048,
          "totalTokens": 3193,
          "costDetails": {},
          "completionTokens": 1145,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-05-28-50-830703_chatcmpl-ba52704d-d367-4c93-9a21-ec43c91a1a48",
          "traceId": "358a1f5a",
          "type": "GENERATION",
          "name": "358a_tpusg_gen_attempt#3",
          "startTime": "2025-08-04T02:28:50.830000+00:00",
          "endTime": "2025-08-04T02:29:20.614000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 29784.0,
          "environment": "default",
          "promptTokens": 2048,
          "totalTokens": 3081,
          "costDetails": {},
          "completionTokens": 1033,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-05-29-28-776790_chatcmpl-8ca9e034-b235-4231-a240-acf28be14951",
          "traceId": "358a1f5a",
          "type": "GENERATION",
          "name": "358a_tpusg_gen_attempt#4",
          "startTime": "2025-08-04T02:29:28.776000+00:00",
          "endTime": "2025-08-04T02:30:00.079000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 31303.0,
          "environment": "default",
          "promptTokens": 2048,
          "totalTokens": 3137,
          "costDetails": {},
          "completionTokens": 1089,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-05-30-08-798550_chatcmpl-026063a1-0294-4d6b-a7d4-6b4a666c6ecd",
          "traceId": "358a1f5a",
          "type": "GENERATION",
          "name": "358a_tpusg_gen_attempt#5",
          "startTime": "2025-08-04T02:30:08.798000+00:00",
          "endTime": "2025-08-04T02:30:41.652000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 32854.0,
          "environment": "default",
          "promptTokens": 2048,
          "totalTokens": 3195,
          "costDetails": {},
          "completionTokens": 1147,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "5b7e2750-b584-42cb-a51a-9c18754e8ec3",
          "traceId": "358a1f5a",
          "type": "SPAN",
          "name": "error_35_tpusg_failure_signal_tpu_sketch_generator",
          "startTime": "2025-08-04T02:30:41.659000+00:00",
          "level": "ERROR",
          "statusMessage": "Failed. Last error: Unexpected error during generation: Generated script is not complete. Please ensure to generate a complete Python script.",
          "calculatedTotalCost": 0.0,
          "environment": "default",
          "promptTokens": 0,
          "totalTokens": 0,
          "costDetails": {},
          "completionTokens": 0,
          "endTime": null,
          "model": null,
          "modelParameters": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null,
          "latency": null
        }
      ],
      "createdAt": "2025-08-04T02:27:37.052Z",
      "environment": "default",
      "updatedAt": "2025-08-04T02:30:47.207Z"
    },
    {
      "id": "0c12284a",
      "timestamp": "2025-08-04T02:24:11.586000+00:00",
      "name": "0c12_tpu_sketch_generator",
      "input": null,
      "output": {
        "status": "success",
        "sketch": "import numpy as np\nfrom tflite_runtime.interpreter import Interpreter, load_delegate\nimport cv2\n\n# Phase 1: Setup\nmodel_path  = \"/home/mendel/tinyml_autopilot/models/edgetpu_detect.tflite\"\nlabel_path  = \"/home/mendel/tinyml_autopilot/models/labelmap.txt\"\ninput_path  = \"/home/mendel/tinyml_autopilot/data//sheeps.mp4\"\noutput_path  = \"/home/mendel/tinyml_autopilot/results/sheeps_detections.mp4\"\nconfidence_threshold  = 0.5\n\n# Load labels\nwith open(label_path, 'r') as f:\n    labels = [line.strip() for line in f.readlines()]\n\n# Load Interpreter with EdgeTPU\ntry:\n    interpreter = Interpreter(model_path=model_path,\n                              experimental_delegates=[load_delegate('libedgetpu.so.1.0')])\nexcept Exception as e:\n    print(f\"Failed to load libedgetpu.so.1.0: {e}\")\n    try:\n        interpreter = Interpreter(model_path=model_path,\n                                  experimental_delegates=[load_delegate('/usr/lib/aarch64-linux-gnu/libedgetpu.so.1.0')])\n    except Exception as e:\n        print(f\"Failed to load /usr/lib/aarch64-linux-gnu/libedgetpu.so.1.0: {e}\")\n        raise\n\ninterpreter.allocate_tensors()\n\n# Get Model Details\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\n\nfloating_model = (input_details[0]['dtype'] == np.float32)\n\n# Phase 2: Input Acquisition & Preprocessing Loop\ncap = cv2.VideoCapture(input_path)\nif not cap.isOpened():\n    raise IOError(\"Cannot open video file\")\n\nframe_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\nframe_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\nfps = cap.get(cv2.CAP_PROP_FPS)\n\nout = cv2.VideoWriter(output_path, cv2.VideoWriter_fourcc(*'mp4v'), fps, (frame_width, frame_height))\n\nwhile True:\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    # Preprocess Data\n    input_data = cv2.resize(frame, (input_details[0]['shape'][1], input_details[0]['shape'][2]))\n    input_data = np.expand_dims(input_data, axis=0)\n\n    if floating_model:\n        input_data = (np.float32(input_data) - 127.5) / 127.5\n\n    # Phase 3: Inference\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n    interpreter.invoke()\n\n    # Phase 4: Output Interpretation & Handling Loop\n    detection_boxes = interpreter.get_tensor(output_details[0]['index'])[0]\n    detection_classes = interpreter.get_tensor(output_details[1]['index'])[0].astype(int)\n    detection_scores = interpreter.get_tensor(output_details[2]['index'])[0]\n\n    num_detections = len(detection_scores)\n\n    for i in range(num_detections):\n        if detection_scores[i] > confidence_threshold:\n            box = detection_boxes[i]\n            class_id = detection_classes[i]\n            score = detection_scores[i]\n\n            # Scale and clip bounding boxes\n            ymin, xmin, ymax, xmax = box\n            (left, right, top, bottom) = (xmin * frame_width, xmax * frame_width,\n                                          ymin * frame_height, ymax * frame_height)\n\n            cv2.rectangle(frame, (int(left), int(top)), (int(right), int(bottom)), (0, 255, 0), 2)\n            label = f'{labels[class_id]}: {score:.2f}'\n            cv2.putText(frame, label, (int(left), int(top) - 10),\n                        cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n\n    # Handle Output\n    out.write(frame)\n\n# Phase 5: Cleanup\ncap.release()\nout.release()\ncv2.destroyAllWindows()"
      },
      "session_id": "qwen2.5-coder:32b_c8a6_tpusg_batch",
      "metadata": {
        "num_run": 24
      },
      "tags": [
        "benchmark",
        "qwen2.5-coder:32b",
        "tpu_sketch_generator"
      ],
      "latency": 146.813,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-05-24-11-587956_chatcmpl-3e311dc5-1faf-4d56-92b4-3a266293fd14",
          "traceId": "0c12284a",
          "type": "GENERATION",
          "name": "0c12_tpusg_gen_attempt#1",
          "startTime": "2025-08-04T02:24:11.587000+00:00",
          "endTime": "2025-08-04T02:24:37.022000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 25435.0,
          "environment": "default",
          "promptTokens": 1833,
          "totalTokens": 2709,
          "costDetails": {},
          "completionTokens": 876,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-05-24-45-180424_chatcmpl-04b8535c-57eb-4235-acbd-02dcf0bd6248",
          "traceId": "0c12284a",
          "type": "GENERATION",
          "name": "0c12_tpusg_gen_attempt#2",
          "startTime": "2025-08-04T02:24:45.180000+00:00",
          "endTime": "2025-08-04T02:25:17.685000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 32505.0,
          "environment": "default",
          "promptTokens": 2048,
          "totalTokens": 3187,
          "costDetails": {},
          "completionTokens": 1139,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-05-25-25-766642_chatcmpl-2a0bd875-87bf-40ba-8ab8-d0f29eb58551",
          "traceId": "0c12284a",
          "type": "GENERATION",
          "name": "0c12_tpusg_gen_attempt#3",
          "startTime": "2025-08-04T02:25:25.766000+00:00",
          "endTime": "2025-08-04T02:25:57.651000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 31885.0,
          "environment": "default",
          "promptTokens": 2048,
          "totalTokens": 3160,
          "costDetails": {},
          "completionTokens": 1112,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-05-26-05-884363_chatcmpl-14c60eea-4236-4981-af28-9644075f724b",
          "traceId": "0c12284a",
          "type": "GENERATION",
          "name": "0c12_tpusg_gen_attempt#4",
          "startTime": "2025-08-04T02:26:05.884000+00:00",
          "endTime": "2025-08-04T02:26:38.400000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 32516.0,
          "environment": "default",
          "promptTokens": 2048,
          "totalTokens": 3185,
          "costDetails": {},
          "completionTokens": 1137,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        }
      ],
      "createdAt": "2025-08-04T02:24:12.108Z",
      "environment": "default",
      "updatedAt": "2025-08-04T02:27:35.859Z"
    },
    {
      "id": "ae74e72b",
      "timestamp": "2025-08-04T02:20:53.784000+00:00",
      "name": "ae74_tpu_sketch_generator",
      "input": null,
      "output": {
        "status": "failed",
        "last_code": "import numpy as np\nfrom tflite_runtime.interpreter import Interpreter, load_delegate\nimport cv2\n\n# Phase 1: Setup\nmodel_path  = \"/home/mendel/tinyml_autopilot/models/edgetpu_detect.tflite\"\nlabel_path  = \"/home/mendel/tinyml_autopilot/models/labelmap.txt\"\ninput_path  = \"/home/mendel/tinyml_autopilot/data//sheeps.mp4\"\noutput_path  = \"/home/mendel/tinyml_autopilot/results/sheeps_detections.mp4\"\nconfidence_threshold  = 0.5\n\n# Load labels\nwith open(label_path, 'r') as f:\n    labels = [line.strip() for line in f.readlines()]\n\n# Load Interpreter with EdgeTPU\ntry:\n    interpreter = Interpreter(model_path=model_path,\n                              experimental_delegates=[load_delegate('libedgetpu.so.1.0')])\nexcept Exception as e:\n    print(f\"Failed to load libedgetpu.so.1.0: {e}\")\n    try:\n        interpreter = Interpreter(model_path=model_path,\n                                  experimental_delegates=[load_delegate('/usr/lib/aarch64-linux-gnu/libedgetpu.so.1.0')])\n    except Exception as e:\n        print(f\"Failed to load /usr/lib/aarch64-linux-gnu/libedgetpu.so.1.0: {e}\")\n        raise\n\ninterpreter.allocate_tensors()\n\n# Get Model Details\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\n\nfloating_model = (input_details[0]['dtype'] == np.float32)\n\n# Phase 2: Input Acquisition & Preprocessing Loop\ncap = cv2.VideoCapture(input_path)\nif not cap.isOpened():\n    raise IOError(\"Cannot open video file\")\n\nframe_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\nframe_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\nfps = cap.get(cv2.CAP_PROP_FPS)\n\nout = cv2.VideoWriter(output_path, cv2.VideoWriter_fourcc(*'mp4v'), fps, (frame_width, frame_height))\n\nwhile True:\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    # Preprocess Data\n    input_data = cv2.resize(frame, (input_details[0]['shape'][1], input_details[0]['shape'][2]))\n    input_data = np.expand_dims(input_data, axis=0)\n\n    if floating_model:\n        input_data = (np.float32(input_data) - 127.5) / 127.5\n\n    # Phase 3: Inference\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n    interpreter.invoke()\n\n    # Phase 4: Output Interpretation & Handling Loop\n    output_data = interpreter.get_tensor(output_details[0]['index'])\n    num_detections = int(interpreter.get_tensor(output_details[1]['index']))  # Access the scalar value directly from array\n    detection_boxes = interpreter.get_tensor(output_details[2]['index'])[0]\n    detection_classes = interpreter.get_tensor(output_details[3]['index'])[0].astype(int)\n    detection_scores = interpreter.get_tensor(output_details[4]['index'])[0]\n\n    for i in range(num_detections):\n        if detection_scores[i] > confidence_threshold:\n            box = detection_boxes[i]\n            class_id = detection_classes[i]\n            score = detection_scores[i]\n\n            # Scale and clip bounding boxes\n            ymin, xmin, ymax, xmax = box\n            (left, right, top, bottom) = (xmin * frame_width, xmax * frame_width,\n                                          ymin * frame_height, ymax * frame_height)\n\n            cv2.rectangle(frame, (int(left), int(top)), (int(right), int(bottom)), (0, 255, 0), 2)\n            label = f'{labels[class_id]}: {score:.2f}'\n            cv2.putText(frame, label, (int(left), int(top) - 10),\n                        cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n\n    # Handle Output\n    out.write(frame)\n\n# Phase 5: Cleanup\ncap.release()\nout.release()\n\nprint(\"Video processing complete.\")",
        "last_error": "Traceback (most recent call last):\n  File \"script_e3eb43f2_1754274236.py\", line 66, in <module>\n    num_detections = int(interpreter.get_tensor(output_details[1]['index']))  # Access the scalar value directly from array\nTypeError: only size-1 arrays can be converted to Python scalars"
      },
      "session_id": "qwen2.5-coder:32b_c8a6_tpusg_batch",
      "metadata": {
        "num_run": 23
      },
      "tags": [
        "benchmark",
        "qwen2.5-coder:32b",
        "tpu_sketch_generator"
      ],
      "latency": 191.059,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-05-20-53-786026_chatcmpl-3df540a4-c1c5-4438-942c-7db6c99bd31a",
          "traceId": "ae74e72b",
          "type": "GENERATION",
          "name": "ae74_tpusg_gen_attempt#1",
          "startTime": "2025-08-04T02:20:53.786000+00:00",
          "endTime": "2025-08-04T02:21:19.235000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 25449.0,
          "environment": "default",
          "promptTokens": 1833,
          "totalTokens": 2709,
          "costDetails": {},
          "completionTokens": 876,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-05-21-27-347965_chatcmpl-ef6ccf2a-647b-460c-8037-474df06ab57a",
          "traceId": "ae74e72b",
          "type": "GENERATION",
          "name": "ae74_tpusg_gen_attempt#2",
          "startTime": "2025-08-04T02:21:27.347000+00:00",
          "endTime": "2025-08-04T02:21:59.766000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 32419.0,
          "environment": "default",
          "promptTokens": 2048,
          "totalTokens": 3183,
          "costDetails": {},
          "completionTokens": 1135,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-05-22-07-867717_chatcmpl-191e5f67-1d6a-4ebe-85c9-f48b55d0e1dc",
          "traceId": "ae74e72b",
          "type": "GENERATION",
          "name": "ae74_tpusg_gen_attempt#3",
          "startTime": "2025-08-04T02:22:07.867000+00:00",
          "endTime": "2025-08-04T02:22:38.900000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 31033.0,
          "environment": "default",
          "promptTokens": 2048,
          "totalTokens": 3130,
          "costDetails": {},
          "completionTokens": 1082,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-05-22-47-007138_chatcmpl-7afe4f9b-e07a-460d-b055-5e613f6c36f4",
          "traceId": "ae74e72b",
          "type": "GENERATION",
          "name": "ae74_tpusg_gen_attempt#4",
          "startTime": "2025-08-04T02:22:47.007000+00:00",
          "endTime": "2025-08-04T02:23:17.825000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 30818.0,
          "environment": "default",
          "promptTokens": 2048,
          "totalTokens": 3121,
          "costDetails": {},
          "completionTokens": 1073,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-05-23-25-964848_chatcmpl-4f28963c-a653-4422-aa6a-9f4ca8726926",
          "traceId": "ae74e72b",
          "type": "GENERATION",
          "name": "ae74_tpusg_gen_attempt#5",
          "startTime": "2025-08-04T02:23:25.964000+00:00",
          "endTime": "2025-08-04T02:23:56.736000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 30772.0,
          "environment": "default",
          "promptTokens": 2048,
          "totalTokens": 3119,
          "costDetails": {},
          "completionTokens": 1071,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "3e6b330f-17ed-42ff-a07a-633b5b06a668",
          "traceId": "ae74e72b",
          "type": "SPAN",
          "name": "error_ae_tpusg_failure_signal_tpu_sketch_generator",
          "startTime": "2025-08-04T02:24:04.845000+00:00",
          "level": "ERROR",
          "statusMessage": "Failed. Last error: Traceback (most recent call last):\n  File \"script_e3eb43f2_1754274236.py\", line 66, in <module>\n    num_detections = int(interpreter.get_tensor(output_details[1]['index']))  # Access the scalar value directly from array\nTypeError: only size-1 arrays can be converted to Python scalars",
          "calculatedTotalCost": 0.0,
          "environment": "default",
          "promptTokens": 0,
          "totalTokens": 0,
          "costDetails": {},
          "completionTokens": 0,
          "endTime": null,
          "model": null,
          "modelParameters": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null,
          "latency": null
        }
      ],
      "createdAt": "2025-08-04T02:20:54.305Z",
      "environment": "default",
      "updatedAt": "2025-08-04T02:24:10.005Z"
    },
    {
      "id": "e8337c0b",
      "timestamp": "2025-08-04T02:18:09.019000+00:00",
      "name": "e833_tpu_sketch_generator",
      "input": null,
      "output": {
        "status": "success",
        "sketch": "import numpy as np\nfrom tflite_runtime.interpreter import Interpreter, load_delegate\nimport cv2\n\n# Phase 1: Setup\nmodel_path  = \"/home/mendel/tinyml_autopilot/models/edgetpu_detect.tflite\"\nlabel_path  = \"/home/mendel/tinyml_autopilot/models/labelmap.txt\"\ninput_path  = \"/home/mendel/tinyml_autopilot/data//sheeps.mp4\"\noutput_path  = \"/home/mendel/tinyml_autopilot/results/sheeps_detections.mp4\"\nconfidence_threshold  = 0.5\n\n# Load labels\nwith open(label_path, 'r') as f:\n    labels = [line.strip() for line in f.readlines()]\n\n# Load Interpreter with EdgeTPU\ntry:\n    interpreter = Interpreter(model_path=model_path,\n                              experimental_delegates=[load_delegate('libedgetpu.so.1.0')])\nexcept Exception as e:\n    print(f\"Failed to load libedgetpu.so.1.0: {e}\")\n    try:\n        interpreter = Interpreter(model_path=model_path,\n                                  experimental_delegates=[load_delegate('/usr/lib/aarch64-linux-gnu/libedgetpu.so.1.0')])\n    except Exception as e:\n        print(f\"Failed to load /usr/lib/aarch64-linux-gnu/libedgetpu.so.1.0: {e}\")\n        raise\n\ninterpreter.allocate_tensors()\n\n# Get Model Details\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\n\nfloating_model = (input_details[0]['dtype'] == np.float32)\n\n# Phase 2: Input Acquisition & Preprocessing Loop\ncap = cv2.VideoCapture(input_path)\nif not cap.isOpened():\n    raise IOError(\"Cannot open video file\")\n\nframe_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\nframe_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\nfps = cap.get(cv2.CAP_PROP_FPS)\n\nout = cv2.VideoWriter(output_path, cv2.VideoWriter_fourcc(*'mp4v'), fps, (frame_width, frame_height))\n\nwhile True:\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    # Preprocess Data\n    input_data = cv2.resize(frame, (input_details[0]['shape'][1], input_details[0]['shape'][2]))\n    input_data = np.expand_dims(input_data, axis=0)\n\n    if floating_model:\n        input_data = (np.float32(input_data) - 127.5) / 127.5\n\n    # Phase 3: Inference\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n    interpreter.invoke()\n\n    # Phase 4: Output Interpretation & Handling Loop\n    detection_boxes = interpreter.get_tensor(output_details[0]['index'])[0]\n    detection_classes = interpreter.get_tensor(output_details[1]['index'])[0].astype(int)\n    detection_scores = interpreter.get_tensor(output_details[2]['index'])[0]\n\n    num_detections = len(detection_scores)  # Infer number of detections from scores array\n\n    for i in range(num_detections):\n        if detection_scores[i] > confidence_threshold:\n            box = detection_boxes[i]\n            class_id = detection_classes[i]\n            score = detection_scores[i]\n\n            # Scale and clip bounding boxes\n            ymin, xmin, ymax, xmax = box\n            (left, right, top, bottom) = (xmin * frame_width, xmax * frame_width,\n                                          ymin * frame_height, ymax * frame_height)\n\n            cv2.rectangle(frame, (int(left), int(top)), (int(right), int(bottom)), (0, 255, 0), 2)\n            label = f'{labels[class_id]}: {score:.2f}'\n            cv2.putText(frame, label, (int(left), int(top) - 10),\n                        cv2.FONT_HERSHEY_SIMPLEX, 0.9, (36, 255, 12), 2)\n\n    # Write the frame with detections to the output video\n    out.write(frame)\n\n# Release resources\ncap.release()\nout.release()\ncv2.destroyAllWindows()"
      },
      "session_id": "qwen2.5-coder:32b_c8a6_tpusg_batch",
      "metadata": {
        "num_run": 22
      },
      "tags": [
        "benchmark",
        "qwen2.5-coder:32b",
        "tpu_sketch_generator"
      ],
      "latency": 106.276,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-05-18-09-021239_chatcmpl-d7e6d341-e2e8-4266-acbf-a7cc660d89ec",
          "traceId": "e8337c0b",
          "type": "GENERATION",
          "name": "e833_tpusg_gen_attempt#1",
          "startTime": "2025-08-04T02:18:09.021000+00:00",
          "endTime": "2025-08-04T02:18:34.475000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 25454.0,
          "environment": "default",
          "promptTokens": 1833,
          "totalTokens": 2709,
          "costDetails": {},
          "completionTokens": 876,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-05-18-42-630731_chatcmpl-18d6a864-b137-4d9f-b667-6d86872093d9",
          "traceId": "e8337c0b",
          "type": "GENERATION",
          "name": "e833_tpusg_gen_attempt#2",
          "startTime": "2025-08-04T02:18:42.630000+00:00",
          "endTime": "2025-08-04T02:19:14.626000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 31996.0,
          "environment": "default",
          "promptTokens": 2048,
          "totalTokens": 3166,
          "costDetails": {},
          "completionTokens": 1118,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-05-19-23-006281_chatcmpl-52158358-023c-42f6-a891-1561c479d544",
          "traceId": "e8337c0b",
          "type": "GENERATION",
          "name": "e833_tpusg_gen_attempt#3",
          "startTime": "2025-08-04T02:19:23.006000+00:00",
          "endTime": "2025-08-04T02:19:55.297000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 32291.0,
          "environment": "default",
          "promptTokens": 2048,
          "totalTokens": 3178,
          "costDetails": {},
          "completionTokens": 1130,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        }
      ],
      "createdAt": "2025-08-04T02:18:09.540Z",
      "environment": "default",
      "updatedAt": "2025-08-04T02:20:52.762Z"
    },
    {
      "id": "3a420609",
      "timestamp": "2025-08-04T02:14:51.197000+00:00",
      "name": "3a42_tpu_sketch_generator",
      "input": null,
      "output": {
        "status": "failed",
        "last_code": "import numpy as np\nfrom tflite_runtime.interpreter import Interpreter, load_delegate\nimport cv2\n\n# Phase 1: Setup\nmodel_path  = \"/home/mendel/tinyml_autopilot/models/edgetpu_detect.tflite\"\nlabel_path  = \"/home/mendel/tinyml_autopilot/models/labelmap.txt\"\ninput_path  = \"/home/mendel/tinyml_autopilot/data//sheeps.mp4\"\noutput_path  = \"/home/mendel/tinyml_autopilot/results/sheeps_detections.mp4\"\nconfidence_threshold  = 0.5\n\n# Load labels\nwith open(label_path, 'r') as f:\n    labels = [line.strip() for line in f.readlines()]\n\n# Load Interpreter with EdgeTPU\ntry:\n    interpreter = Interpreter(model_path=model_path,\n                              experimental_delegates=[load_delegate('libedgetpu.so.1.0')])\nexcept Exception as e:\n    print(f\"Failed to load libedgetpu.so.1.0: {e}\")\n    try:\n        interpreter = Interpreter(model_path=model_path,\n                                  experimental_delegates=[load_delegate('/usr/lib/aarch64-linux-gnu/libedgetpu.so.1.0')])\n    except Exception as e:\n        print(f\"Failed to load /usr/lib/aarch64-linux-gnu/libedgetpu.so.1.0: {e}\")\n        raise\n\ninterpreter.allocate_tensors()\n\n# Get Model Details\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\n\nfloating_model = (input_details[0]['dtype'] == np.float32)\n\n# Phase 2: Input Acquisition & Preprocessing Loop\ncap = cv2.VideoCapture(input_path)\nif not cap.isOpened():\n    raise IOError(\"Cannot open video file\")\n\nframe_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\nframe_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\nfps = cap.get(cv2.CAP_PROP_FPS)\n\nout = cv2.VideoWriter(output_path, cv2.VideoWriter_fourcc(*'mp4v'), fps, (frame_width, frame_height))\n\nwhile True:\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    # Preprocess Data\n    input_data = cv2.resize(frame, (input_details[0]['shape'][1], input_details[0]['shape'][2]))\n    input_data = np.expand_dims(input_data, axis=0)\n\n    if floating_model:\n        input_data = (np.float32(input_data) - 127.5) / 127.5\n\n    # Phase 3: Inference\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n    interpreter.invoke()\n\n    # Phase 4: Output Interpretation & Handling Loop\n    output_data = interpreter.get_tensor(output_details[0]['index'])\n    \n    # Ensure num_detections is a scalar value using indexing\n    num_detections = int(interpreter.get_tensor(output_details[1]['index'])[0])\n    detection_boxes = interpreter.get_tensor(output_details[2]['index'])[0]\n    detection_classes = interpreter.get_tensor(output_details[3]['index'])[0].astype(int)\n    detection_scores = interpreter.get_tensor(output_details[4]['index'])[0]\n\n    for i in range(num_detections):\n        if detection_scores[i] > confidence_threshold:\n            box = detection_boxes[i]\n            class_id = detection_classes[i]\n            score = detection_scores[i]\n\n            # Scale and clip bounding boxes\n            ymin, xmin, ymax, xmax = box\n            (left, right, top, bottom) = (xmin * frame_width, xmax * frame_width,\n                                          ymin * frame_height, ymax * frame_height)\n\n            cv2.rectangle(frame, (int(left), int(top)), (int(right), int(bottom)), (0, 255, 0), 2)\n            label = f'{labels[class_id]}: {score:.2f}'\n            cv2.putText(frame, label, (int(left), int(top) - 10),\n                        cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n\n    # Handle Output\n    out.write(frame)\n\n# Phase 5: Cleanup\ncap.release()\nout.release()\ncv2.destroyAllWindows()",
        "last_error": "Traceback (most recent call last):\n  File \"script_3c00ef11_1754273874.py\", line 68, in <module>\n    num_detections = int(interpreter.get_tensor(output_details[1]['index'])[0])\nTypeError: only size-1 arrays can be converted to Python scalars"
      },
      "session_id": "qwen2.5-coder:32b_c8a6_tpusg_batch",
      "metadata": {
        "num_run": 21
      },
      "tags": [
        "benchmark",
        "qwen2.5-coder:32b",
        "tpu_sketch_generator"
      ],
      "latency": 191.567,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-05-14-51-199693_chatcmpl-85c3fbd8-bdc4-4e98-b208-ccedc6660119",
          "traceId": "3a420609",
          "type": "GENERATION",
          "name": "3a42_tpusg_gen_attempt#1",
          "startTime": "2025-08-04T02:14:51.199000+00:00",
          "endTime": "2025-08-04T02:15:17.160000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 25961.0,
          "environment": "default",
          "promptTokens": 1833,
          "totalTokens": 2709,
          "costDetails": {},
          "completionTokens": 876,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-05-15-25-284290_chatcmpl-d0e59c44-924d-445d-bbe6-ab405147d685",
          "traceId": "3a420609",
          "type": "GENERATION",
          "name": "3a42_tpusg_gen_attempt#2",
          "startTime": "2025-08-04T02:15:25.284000+00:00",
          "endTime": "2025-08-04T02:15:57.008000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 31724.0,
          "environment": "default",
          "promptTokens": 2048,
          "totalTokens": 3154,
          "costDetails": {},
          "completionTokens": 1106,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-05-16-05-216026_chatcmpl-79360fb6-3091-46cc-b183-63dd6c1bfb9e",
          "traceId": "3a420609",
          "type": "GENERATION",
          "name": "3a42_tpusg_gen_attempt#3",
          "startTime": "2025-08-04T02:16:05.216000+00:00",
          "endTime": "2025-08-04T02:16:35.717000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 30501.0,
          "environment": "default",
          "promptTokens": 2048,
          "totalTokens": 3109,
          "costDetails": {},
          "completionTokens": 1061,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-05-16-44-000298_chatcmpl-78965f55-dc33-4b14-9c90-153f437ae60f",
          "traceId": "3a420609",
          "type": "GENERATION",
          "name": "3a42_tpusg_gen_attempt#4",
          "startTime": "2025-08-04T02:16:44+00:00",
          "endTime": "2025-08-04T02:17:15.016000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 31016.0,
          "environment": "default",
          "promptTokens": 2048,
          "totalTokens": 3125,
          "costDetails": {},
          "completionTokens": 1077,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-05-17-23-309716_chatcmpl-aa953368-a189-4136-8c1a-7f5dc7f9a88b",
          "traceId": "3a420609",
          "type": "GENERATION",
          "name": "3a42_tpusg_gen_attempt#5",
          "startTime": "2025-08-04T02:17:23.309000+00:00",
          "endTime": "2025-08-04T02:17:54.703000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 31394.0,
          "environment": "default",
          "promptTokens": 2048,
          "totalTokens": 3140,
          "costDetails": {},
          "completionTokens": 1092,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "a9e0b8e2-745e-4b6e-b115-99f8069f26d7",
          "traceId": "3a420609",
          "type": "SPAN",
          "name": "error_3a_tpusg_failure_signal_tpu_sketch_generator",
          "startTime": "2025-08-04T02:18:02.766000+00:00",
          "level": "ERROR",
          "statusMessage": "Failed. Last error: Traceback (most recent call last):\n  File \"script_3c00ef11_1754273874.py\", line 68, in <module>\n    num_detections = int(interpreter.get_tensor(output_details[1]['index'])[0])\nTypeError: only size-1 arrays can be converted to Python scalars",
          "calculatedTotalCost": 0.0,
          "environment": "default",
          "promptTokens": 0,
          "totalTokens": 0,
          "costDetails": {},
          "completionTokens": 0,
          "endTime": null,
          "model": null,
          "modelParameters": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null,
          "latency": null
        }
      ],
      "createdAt": "2025-08-04T02:14:51.709Z",
      "environment": "default",
      "updatedAt": "2025-08-04T02:18:07.927Z"
    },
    {
      "id": "9675ade3",
      "timestamp": "2025-08-04T02:10:21.910000+00:00",
      "name": "9675_tpu_sketch_generator",
      "input": null,
      "output": {
        "status": "success",
        "sketch": "import numpy as np\nfrom tflite_runtime.interpreter import Interpreter, load_delegate\n\n# Phase 1: Setup\nmodel_path  = \"/home/mendel/tinyml_autopilot/models/edgetpu_detect.tflite\"\nlabel_path  = \"/home/mendel/tinyml_autopilot/models/labelmap.txt\"\ninput_path  = \"/home/mendel/tinyml_autopilot/data//sheeps.mp4\"\noutput_path  = \"/home/mendel/tinyml_autopilot/results/sheeps_detections.mp4\"\nconfidence_threshold  = 0.5\n\n# Load labels\nwith open(label_path, 'r') as f:\n    labels = [line.strip() for line in f.readlines()]\n\n# Load Interpreter with EdgeTPU\ntry:\n    interpreter = Interpreter(model_path=model_path,\n                              experimental_delegates=[load_delegate('libedgetpu.so.1.0')])\nexcept Exception as e:\n    print(f\"Failed to load libedgetpu.so.1.0: {e}\")\n    try:\n        interpreter = Interpreter(model_path=model_path,\n                                  experimental_delegates=[load_delegate('/usr/lib/aarch64-linux-gnu/libedgetpu.so.1.0')])\n    except Exception as e:\n        print(f\"Failed to load /usr/lib/aarch64-linux-gnu/libedgetpu.so.1.0: {e}\")\n        raise\n\ninterpreter.allocate_tensors()\n\n# Get Model Details\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\n\nfloating_model = (input_details[0]['dtype'] == np.float32)\n\n# Phase 2: Input Acquisition & Preprocessing Loop\nimport cv2\n\ncap = cv2.VideoCapture(input_path)\nif not cap.isOpened():\n    raise IOError(\"Cannot open video file\")\n\nframe_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\nframe_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\nfps = cap.get(cv2.CAP_PROP_FPS)\n\nout = cv2.VideoWriter(output_path, cv2.VideoWriter_fourcc(*'mp4v'), fps, (frame_width, frame_height))\n\nwhile True:\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    # Preprocess Data\n    input_data = cv2.resize(frame, (input_details[0]['shape'][1], input_details[0]['shape'][2]))\n    input_data = np.expand_dims(input_data, axis=0)\n\n    if floating_model:\n        input_data = (np.float32(input_data) - 127.5) / 127.5\n\n    # Phase 3: Inference\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n    interpreter.invoke()\n\n    # Phase 4: Output Interpretation & Handling Loop\n    detection_boxes = interpreter.get_tensor(output_details[0]['index'])[0]\n    detection_classes = interpreter.get_tensor(output_details[1]['index'])[0].astype(int)\n    detection_scores = interpreter.get_tensor(output_details[2]['index'])[0]\n\n    num_detections = len(detection_scores)  # Infer number of detections from scores array\n\n    for i in range(num_detections):\n        if detection_scores[i] > confidence_threshold:\n            box = detection_boxes[i]\n            class_id = detection_classes[i]\n            score = detection_scores[i]\n\n            # Scale and clip bounding boxes\n            ymin, xmin, ymax, xmax = box\n            (left, right, top, bottom) = (xmin * frame_width, xmax * frame_width,\n                                          ymin * frame_height, ymax * frame_height)\n\n            cv2.rectangle(frame, (int(left), int(top)), (int(right), int(bottom)), (0, 255, 0), 2)\n            label = f'{labels[class_id]}: {score:.2f}'\n            cv2.putText(frame, label, (int(left), int(top) - 10),\n                        cv2.FONT_HERSHEY_SIMPLEX, 0.9, (36, 255, 12), 2)\n\n    out.write(frame)\n\ncap.release()\nout.release()\ncv2.destroyAllWindows()"
      },
      "session_id": "qwen2.5-coder:32b_c8a6_tpusg_batch",
      "metadata": {
        "num_run": 20
      },
      "tags": [
        "benchmark",
        "qwen2.5-coder:32b",
        "tpu_sketch_generator"
      ],
      "latency": 210.619,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-05-10-21-912108_chatcmpl-4d34ebe3-7b47-4ac2-a31f-70bd4f000a78",
          "traceId": "9675ade3",
          "type": "GENERATION",
          "name": "9675_tpusg_gen_attempt#1",
          "startTime": "2025-08-04T02:10:21.912000+00:00",
          "endTime": "2025-08-04T02:10:47.588000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 25676.0,
          "environment": "default",
          "promptTokens": 1833,
          "totalTokens": 2709,
          "costDetails": {},
          "completionTokens": 876,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-05-10-55-884353_chatcmpl-21c8821d-6079-4010-866b-3984c0939487",
          "traceId": "9675ade3",
          "type": "GENERATION",
          "name": "9675_tpusg_gen_attempt#2",
          "startTime": "2025-08-04T02:10:55.884000+00:00",
          "endTime": "2025-08-04T02:11:28.519000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 32635.0,
          "environment": "default",
          "promptTokens": 2048,
          "totalTokens": 3189,
          "costDetails": {},
          "completionTokens": 1141,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-05-11-36-626510_chatcmpl-4b2a021b-261c-4f27-8f9a-28617e14c8bc",
          "traceId": "9675ade3",
          "type": "GENERATION",
          "name": "9675_tpusg_gen_attempt#3",
          "startTime": "2025-08-04T02:11:36.626000+00:00",
          "endTime": "2025-08-04T02:12:09.738000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 33112.0,
          "environment": "default",
          "promptTokens": 2048,
          "totalTokens": 3208,
          "costDetails": {},
          "completionTokens": 1160,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-05-12-18-148242_chatcmpl-cf136741-8d9f-4ec7-9f60-6d27881cf602",
          "traceId": "9675ade3",
          "type": "GENERATION",
          "name": "9675_tpusg_gen_attempt#4",
          "startTime": "2025-08-04T02:12:18.148000+00:00",
          "endTime": "2025-08-04T02:13:12.447000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 54299.0,
          "environment": "default",
          "promptTokens": 2048,
          "totalTokens": 4003,
          "costDetails": {},
          "completionTokens": 1955,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-05-13-20-546978_chatcmpl-45810518-733d-489d-a7b6-e970e4bee3e3",
          "traceId": "9675ade3",
          "type": "GENERATION",
          "name": "9675_tpusg_gen_attempt#5",
          "startTime": "2025-08-04T02:13:20.546000+00:00",
          "endTime": "2025-08-04T02:13:52.531000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 31985.0,
          "environment": "default",
          "promptTokens": 2048,
          "totalTokens": 3166,
          "costDetails": {},
          "completionTokens": 1118,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        }
      ],
      "createdAt": "2025-08-04T02:10:22.429Z",
      "environment": "default",
      "updatedAt": "2025-08-04T02:14:50.198Z"
    },
    {
      "id": "0931951a",
      "timestamp": "2025-08-04T02:07:00.379000+00:00",
      "name": "0931_tpu_sketch_generator",
      "input": null,
      "output": {
        "status": "failed",
        "last_code": "import numpy as np\nfrom tflite_runtime.interpreter import Interpreter, load_delegate\nimport cv2\n\n# Phase 1: Setup\nmodel_path  = \"/home/mendel/tinyml_autopilot/models/edgetpu_detect.tflite\"\nlabel_path  = \"/home/mendel/tinyml_autopilot/models/labelmap.txt\"\ninput_path  = \"/home/mendel/tinyml_autopilot/data//sheeps.mp4\"\noutput_path  = \"/home/mendel/tinyml_autopilot/results/sheeps_detections.mp4\"\nconfidence_threshold  = 0.5\n\n# Load labels\nwith open(label_path, 'r') as f:\n    labels = [line.strip() for line in f.readlines()]\n\n# Load Interpreter with EdgeTPU\ntry:\n    interpreter = Interpreter(model_path=model_path,\n                              experimental_delegates=[load_delegate('libedgetpu.so.1.0')])\nexcept Exception as e:\n    print(f\"Failed to load libedgetpu.so.1.0: {e}\")\n    try:\n        interpreter = Interpreter(model_path=model_path,\n                                  experimental_delegates=[load_delegate('/usr/lib/aarch64-linux-gnu/libedgetpu.so.1.0')])\n    except Exception as e:\n        print(f\"Failed to load /usr/lib/aarch64-linux-gnu/libedgetpu.so.1.0: {e}\")\n        raise\n\ninterpreter.allocate_tensors()\n\n# Get Model Details\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\n\nfloating_model = (input_details[0]['dtype'] == np.float32)\n\n# Phase 2: Input Acquisition & Preprocessing Loop\ncap = cv2.VideoCapture(input_path)\nif not cap.isOpened():\n    raise IOError(\"Cannot open video file\")\n\nframe_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\nframe_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\nfps = cap.get(cv2.CAP_PROP_FPS)\n\nout = cv2.VideoWriter(output_path, cv2.VideoWriter_fourcc(*'mp4v'), fps, (frame_width, frame_height))\n\nwhile True:\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    # Preprocess Data\n    input_data = cv2.resize(frame, (input_details[0]['shape'][1], input_details[0]['shape'][2]))\n    input_data = np.expand_dims(input_data, axis=0)\n\n    if floating_model:\n        input_data = (np.float32(input_data) - 127.5) / 127.5\n\n    # Phase 3: Inference\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n    interpreter.invoke()\n\n    # Phase 4: Output Interpretation & Handling Loop\n    output_data = interpreter.get_tensor(output_details[0]['index'])\n    detection_boxes = interpreter.get_tensor(output_details[1]['index'])[0]\n    detection_classes = interpreter.get_tensor(output_details[2]['index'])[0].astype(int)\n    detection_scores = interpreter.get_tensor(output_details[3]['index'])[0]\n\n    # Check if there are any detections\n    num_detections = len(detection_scores)\n\n    for i in range(num_detections):\n        if detection_scores[i] > confidence_threshold:\n            box = detection_boxes[i]\n            class_id = detection_classes[i]\n            score = detection_scores[i]\n\n            # Scale and clip bounding boxes\n            ymin, xmin, ymax, xmax = box\n            (left, right, top, bottom) = (xmin * frame_width, xmax * frame_width,\n                                          ymin * frame_height, ymax * frame_height)\n\n            cv2.rectangle(frame, (int(left), int(top)), (int(right), int(bottom)), (0, 255, 0), 2)\n            label = f'{labels[class_id]}: {score:.2f}'\n            cv2.putText(frame, label, (int(left), int(top) - 10),\n                        cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n\n    # Write the frame to the output video\n    out.write(frame)\n\n# Release resources\ncap.release()\nout.release()\ncv2.destroyAllWindows()",
        "last_error": "Traceback (most recent call last):\n  File \"script_c3257492_1754273407.py\", line 71, in <module>\n    num_detections = len(detection_scores)\nTypeError: object of type 'numpy.float32' has no len()"
      },
      "session_id": "qwen2.5-coder:32b_c8a6_tpusg_batch",
      "metadata": {
        "num_run": 19
      },
      "tags": [
        "benchmark",
        "qwen2.5-coder:32b",
        "tpu_sketch_generator"
      ],
      "latency": 195.825,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-05-07-00-380666_chatcmpl-cd9e450f-3782-43c0-b5ca-655f60ffcb25",
          "traceId": "0931951a",
          "type": "GENERATION",
          "name": "0931_tpusg_gen_attempt#1",
          "startTime": "2025-08-04T02:07:00.380000+00:00",
          "endTime": "2025-08-04T02:07:26.139000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 25759.0,
          "environment": "default",
          "promptTokens": 1833,
          "totalTokens": 2709,
          "costDetails": {},
          "completionTokens": 876,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-05-07-34-268345_chatcmpl-b57f3206-b5ac-4931-a435-f460bb513074",
          "traceId": "0931951a",
          "type": "GENERATION",
          "name": "0931_tpusg_gen_attempt#2",
          "startTime": "2025-08-04T02:07:34.268000+00:00",
          "endTime": "2025-08-04T02:08:06.947000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 32679.0,
          "environment": "default",
          "promptTokens": 2048,
          "totalTokens": 3193,
          "costDetails": {},
          "completionTokens": 1145,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-05-08-15-196594_chatcmpl-e27a3bfe-ca31-4828-bddd-1a0d2fd3ef9b",
          "traceId": "0931951a",
          "type": "GENERATION",
          "name": "0931_tpusg_gen_attempt#3",
          "startTime": "2025-08-04T02:08:15.196000+00:00",
          "endTime": "2025-08-04T02:08:47.653000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 32457.0,
          "environment": "default",
          "promptTokens": 2048,
          "totalTokens": 3183,
          "costDetails": {},
          "completionTokens": 1135,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-05-08-55-810239_chatcmpl-b14246a9-7471-45b3-ae63-e85e7ea8ed8c",
          "traceId": "0931951a",
          "type": "GENERATION",
          "name": "0931_tpusg_gen_attempt#4",
          "startTime": "2025-08-04T02:08:55.810000+00:00",
          "endTime": "2025-08-04T02:09:28.501000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 32691.0,
          "environment": "default",
          "promptTokens": 2048,
          "totalTokens": 3193,
          "costDetails": {},
          "completionTokens": 1145,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-05-09-36-650032_chatcmpl-feb22a53-15a7-44e5-bc7e-d800874b6b78",
          "traceId": "0931951a",
          "type": "GENERATION",
          "name": "0931_tpusg_gen_attempt#5",
          "startTime": "2025-08-04T02:09:36.650000+00:00",
          "endTime": "2025-08-04T02:10:07.900000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 31250.0,
          "environment": "default",
          "promptTokens": 2048,
          "totalTokens": 3138,
          "costDetails": {},
          "completionTokens": 1090,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "53a9cea1-2509-410b-aab5-efdb202b2cd5",
          "traceId": "0931951a",
          "type": "SPAN",
          "name": "error_09_tpusg_failure_signal_tpu_sketch_generator",
          "startTime": "2025-08-04T02:10:16.205000+00:00",
          "level": "ERROR",
          "statusMessage": "Failed. Last error: Traceback (most recent call last):\n  File \"script_c3257492_1754273407.py\", line 71, in <module>\n    num_detections = len(detection_scores)\nTypeError: object of type 'numpy.float32' has no len()",
          "calculatedTotalCost": 0.0,
          "environment": "default",
          "promptTokens": 0,
          "totalTokens": 0,
          "costDetails": {},
          "completionTokens": 0,
          "endTime": null,
          "model": null,
          "modelParameters": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null,
          "latency": null
        }
      ],
      "createdAt": "2025-08-04T02:07:00.899Z",
      "environment": "default",
      "updatedAt": "2025-08-04T02:10:21.635Z"
    },
    {
      "id": "56632124",
      "timestamp": "2025-08-04T02:04:17.720000+00:00",
      "name": "5663_tpu_sketch_generator",
      "input": null,
      "output": {
        "status": "success",
        "sketch": "import numpy as np\nfrom tflite_runtime.interpreter import Interpreter, load_delegate\nimport cv2\n\n# Phase 1: Setup\nmodel_path  = \"/home/mendel/tinyml_autopilot/models/edgetpu_detect.tflite\"\nlabel_path  = \"/home/mendel/tinyml_autopilot/models/labelmap.txt\"\ninput_path  = \"/home/mendel/tinyml_autopilot/data//sheeps.mp4\"\noutput_path  = \"/home/mendel/tinyml_autopilot/results/sheeps_detections.mp4\"\nconfidence_threshold  = 0.5\n\n# Load labels\nwith open(label_path, 'r') as f:\n    labels = [line.strip() for line in f.readlines()]\n\n# Load Interpreter with EdgeTPU\ntry:\n    interpreter = Interpreter(model_path=model_path,\n                              experimental_delegates=[load_delegate('libedgetpu.so.1.0')])\nexcept Exception as e:\n    print(f\"Failed to load libedgetpu.so.1.0: {e}\")\n    try:\n        interpreter = Interpreter(model_path=model_path,\n                                  experimental_delegates=[load_delegate('/usr/lib/aarch64-linux-gnu/libedgetpu.so.1.0')])\n    except Exception as e:\n        print(f\"Failed to load /usr/lib/aarch64-linux-gnu/libedgetpu.so.1.0: {e}\")\n        raise\n\ninterpreter.allocate_tensors()\n\n# Get Model Details\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\n\nfloating_model = (input_details[0]['dtype'] == np.float32)\n\n# Phase 2: Input Acquisition & Preprocessing Loop\ncap = cv2.VideoCapture(input_path)\nif not cap.isOpened():\n    raise IOError(\"Cannot open video file\")\n\nframe_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\nframe_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\nfps = cap.get(cv2.CAP_PROP_FPS)\n\nout = cv2.VideoWriter(output_path, cv2.VideoWriter_fourcc(*'mp4v'), fps, (frame_width, frame_height))\n\nwhile True:\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    # Preprocess Data\n    input_data = cv2.resize(frame, (input_details[0]['shape'][1], input_details[0]['shape'][2]))\n    input_data = np.expand_dims(input_data, axis=0)\n\n    if floating_model:\n        input_data = (np.float32(input_data) - 127.5) / 127.5\n\n    # Phase 3: Inference\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n    interpreter.invoke()\n\n    # Phase 4: Output Interpretation & Handling Loop\n    detection_boxes = interpreter.get_tensor(output_details[0]['index'])[0]\n    detection_classes = interpreter.get_tensor(output_details[1]['index'])[0].astype(int)\n    detection_scores = interpreter.get_tensor(output_details[2]['index'])[0]\n\n    num_detections = len(detection_scores)  # Assuming the number of detections is the length of scores\n\n    for i in range(num_detections):\n        if detection_scores[i] > confidence_threshold:\n            box = detection_boxes[i]\n            class_id = detection_classes[i]\n            score = detection_scores[i]\n\n            # Scale and clip bounding boxes\n            ymin, xmin, ymax, xmax = box\n            (left, right, top, bottom) = (xmin * frame_width, xmax * frame_width,\n                                          ymin * frame_height, ymax * frame_height)\n\n            cv2.rectangle(frame, (int(left), int(top)), (int(right), int(bottom)), (0, 255, 0), 2)\n            label = f'{labels[class_id]}: {score:.2f}'\n            cv2.putText(frame, label, (int(left), int(top) - 10),\n                        cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n\n    # Handle Output\n    out.write(frame)\n\n# Phase 5: Cleanup\ncap.release()\nout.release()\ncv2.destroyAllWindows()"
      },
      "session_id": "qwen2.5-coder:32b_c8a6_tpusg_batch",
      "metadata": {
        "num_run": 18
      },
      "tags": [
        "benchmark",
        "qwen2.5-coder:32b",
        "tpu_sketch_generator"
      ],
      "latency": 104.323,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-05-04-17-722470_chatcmpl-b8c82b94-b706-431d-ae9b-1b7a5bf18489",
          "traceId": "56632124",
          "type": "GENERATION",
          "name": "5663_tpusg_gen_attempt#1",
          "startTime": "2025-08-04T02:04:17.722000+00:00",
          "endTime": "2025-08-04T02:04:43.235000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 25513.0,
          "environment": "default",
          "promptTokens": 1833,
          "totalTokens": 2709,
          "costDetails": {},
          "completionTokens": 876,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-05-04-51-314560_chatcmpl-2d00edd9-6226-47a4-8f62-7efc0cb61943",
          "traceId": "56632124",
          "type": "GENERATION",
          "name": "5663_tpusg_gen_attempt#2",
          "startTime": "2025-08-04T02:04:51.314000+00:00",
          "endTime": "2025-08-04T02:05:23.342000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 32028.0,
          "environment": "default",
          "promptTokens": 2048,
          "totalTokens": 3166,
          "costDetails": {},
          "completionTokens": 1118,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-05-05-31-432096_chatcmpl-aebb0ed3-24b1-4c14-b37a-d2631dff8d01",
          "traceId": "56632124",
          "type": "GENERATION",
          "name": "5663_tpusg_gen_attempt#3",
          "startTime": "2025-08-04T02:05:31.432000+00:00",
          "endTime": "2025-08-04T02:06:02.045000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 30613.0,
          "environment": "default",
          "promptTokens": 2048,
          "totalTokens": 3113,
          "costDetails": {},
          "completionTokens": 1065,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        }
      ],
      "createdAt": "2025-08-04T02:04:18.246Z",
      "environment": "default",
      "updatedAt": "2025-08-04T02:06:59.577Z"
    },
    {
      "id": "1905c54c",
      "timestamp": "2025-08-04T02:01:31.797000+00:00",
      "name": "1905_tpu_sketch_generator",
      "input": null,
      "output": {
        "status": "success",
        "sketch": "import numpy as np\nfrom tflite_runtime.interpreter import Interpreter, load_delegate\nimport cv2\n\n# Phase 1: Setup\nmodel_path  = \"/home/mendel/tinyml_autopilot/models/edgetpu_detect.tflite\"\nlabel_path  = \"/home/mendel/tinyml_autopilot/models/labelmap.txt\"\ninput_path  = \"/home/mendel/tinyml_autopilot/data//sheeps.mp4\"\noutput_path  = \"/home/mendel/tinyml_autopilot/results/sheeps_detections.mp4\"\nconfidence_threshold  = 0.5\n\n# Load labels\nwith open(label_path, 'r') as f:\n    labels = [line.strip() for line in f.readlines()]\n\n# Load Interpreter with EdgeTPU\ntry:\n    interpreter = Interpreter(model_path=model_path,\n                              experimental_delegates=[load_delegate('libedgetpu.so.1.0')])\nexcept Exception as e:\n    print(f\"Failed to load libedgetpu.so.1.0: {e}\")\n    try:\n        interpreter = Interpreter(model_path=model_path,\n                                  experimental_delegates=[load_delegate('/usr/lib/aarch64-linux-gnu/libedgetpu.so.1.0')])\n    except Exception as e:\n        print(f\"Failed to load /usr/lib/aarch64-linux-gnu/libedgetpu.so.1.0: {e}\")\n        raise\n\ninterpreter.allocate_tensors()\n\n# Get Model Details\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\n\nfloating_model = (input_details[0]['dtype'] == np.float32)\n\n# Phase 2: Input Acquisition & Preprocessing Loop\ncap = cv2.VideoCapture(input_path)\nif not cap.isOpened():\n    raise IOError(\"Cannot open video file\")\n\nframe_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\nframe_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\nfps = cap.get(cv2.CAP_PROP_FPS)\n\nout = cv2.VideoWriter(output_path, cv2.VideoWriter_fourcc(*'mp4v'), fps, (frame_width, frame_height))\n\nwhile True:\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    # Preprocess Data\n    input_data = cv2.resize(frame, (input_details[0]['shape'][1], input_details[0]['shape'][2]))\n    input_data = np.expand_dims(input_data, axis=0)\n\n    if floating_model:\n        input_data = (np.float32(input_data) - 127.5) / 127.5\n\n    # Phase 3: Inference\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n    interpreter.invoke()\n\n    # Phase 4: Output Interpretation & Handling Loop\n    detection_boxes = interpreter.get_tensor(output_details[0]['index'])[0]\n    detection_classes = interpreter.get_tensor(output_details[1]['index'])[0].astype(int)\n    detection_scores = interpreter.get_tensor(output_details[2]['index'])[0]\n    num_detections = int(interpreter.get_tensor(output_details[3]['index']))  # Access the scalar value directly\n\n    for i in range(num_detections):\n        if detection_scores[i] > confidence_threshold:\n            box = detection_boxes[i]\n            class_id = detection_classes[i]\n            score = detection_scores[i]\n\n            # Scale and clip bounding boxes\n            ymin, xmin, ymax, xmax = box\n            (left, right, top, bottom) = (xmin * frame_width, xmax * frame_width,\n                                          ymin * frame_height, ymax * frame_height)\n\n            cv2.rectangle(frame, (int(left), int(top)), (int(right), int(bottom)), (0, 255, 0), 2)\n            label = f'{labels[class_id]}: {score:.2f}'\n            cv2.putText(frame, label, (int(left), int(top) - 10),\n                        cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n\n    # Handle Output\n    out.write(frame)\n\n# Phase 5: Cleanup\ncap.release()\nout.release()\ncv2.destroyAllWindows()"
      },
      "session_id": "qwen2.5-coder:32b_c8a6_tpusg_batch",
      "metadata": {
        "num_run": 17
      },
      "tags": [
        "benchmark",
        "qwen2.5-coder:32b",
        "tpu_sketch_generator"
      ],
      "latency": 106.585,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-05-01-31-870499_chatcmpl-6daddcfd-d9de-40b1-aa3a-861ff525e1ad",
          "traceId": "1905c54c",
          "type": "GENERATION",
          "name": "1905_tpusg_gen_attempt#1",
          "startTime": "2025-08-04T02:01:31.870000+00:00",
          "endTime": "2025-08-04T02:01:57.329000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 25459.0,
          "environment": "default",
          "promptTokens": 1833,
          "totalTokens": 2709,
          "costDetails": {},
          "completionTokens": 876,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-05-02-05-402204_chatcmpl-c1a47dde-095a-46ff-9124-cbf2f88f862e",
          "traceId": "1905c54c",
          "type": "GENERATION",
          "name": "1905_tpusg_gen_attempt#2",
          "startTime": "2025-08-04T02:02:05.402000+00:00",
          "endTime": "2025-08-04T02:02:38.542000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 33140.0,
          "environment": "default",
          "promptTokens": 2048,
          "totalTokens": 3210,
          "costDetails": {},
          "completionTokens": 1162,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-05-02-46-688227_chatcmpl-cbd5411c-baa4-4297-9e00-9e55ecdbf4f8",
          "traceId": "1905c54c",
          "type": "GENERATION",
          "name": "1905_tpusg_gen_attempt#3",
          "startTime": "2025-08-04T02:02:46.688000+00:00",
          "endTime": "2025-08-04T02:03:18.455000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 31767.0,
          "environment": "default",
          "promptTokens": 2048,
          "totalTokens": 3153,
          "costDetails": {},
          "completionTokens": 1105,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        }
      ],
      "createdAt": "2025-08-04T02:01:32.317Z",
      "environment": "default",
      "updatedAt": "2025-08-04T02:04:16.048Z"
    },
    {
      "id": "5b3f978f",
      "timestamp": "2025-08-04T01:58:11.163000+00:00",
      "name": "5b3f_tpu_sketch_generator",
      "input": null,
      "output": {
        "status": "failed",
        "last_code": "import numpy as np\nfrom tflite_runtime.interpreter import Interpreter, load_delegate\nimport cv2\n\n# Phase 1: Setup\nmodel_path  = \"/home/mendel/tinyml_autopilot/models/edgetpu_detect.tflite\"\nlabel_path  = \"/home/mendel/tinyml_autopilot/models/labelmap.txt\"\ninput_path  = \"/home/mendel/tinyml_autopilot/data//sheeps.mp4\"\noutput_path  = \"/home/mendel/tinyml_autopilot/results/sheeps_detections.mp4\"\nconfidence_threshold  = 0.5\n\n# Load labels\nwith open(label_path, 'r') as f:\n    labels = [line.strip() for line in f.readlines()]\n\n# Load Interpreter with EdgeTPU\ntry:\n    interpreter = Interpreter(model_path=model_path,\n                              experimental_delegates=[load_delegate('libedgetpu.so.1.0')])\nexcept Exception as e:\n    print(f\"Failed to load libedgetpu.so.1.0: {e}\")\n    try:\n        interpreter = Interpreter(model_path=model_path,\n                                  experimental_delegates=[load_delegate('/usr/lib/aarch64-linux-gnu/libedgetpu.so.1.0')])\n    except Exception as e:\n        print(f\"Failed to load /usr/lib/aarch64-linux-gnu/libedgetpu.so.1.0: {e}\")\n        raise\n\ninterpreter.allocate_tensors()\n\n# Get Model Details\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\n\nfloating_model = (input_details[0]['dtype'] == np.float32)\n\n# Phase 2: Input Acquisition & Preprocessing Loop\ncap = cv2.VideoCapture(input_path)\nif not cap.isOpened():\n    raise IOError(\"Cannot open video file\")\n\nframe_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\nframe_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\nfps = cap.get(cv2.CAP_PROP_FPS)\n\nout = cv2.VideoWriter(output_path, cv2.VideoWriter_fourcc(*'mp4v'), fps, (frame_width, frame_height))\n\nwhile True:\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    # Preprocess Data\n    input_data = cv2.resize(frame, (input_details[0]['shape'][1], input_details[0]['shape'][2]))\n    input_data = np.expand_dims(input_data, axis=0)\n\n    if floating_model:\n        input_data = (np.float32(input_data) - 127.5) / 127.5\n\n    # Phase 3: Inference\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n    interpreter.invoke()\n\n    # Phase 4: Output Interpretation & Handling Loop\n    num_detections = int(interpreter.get_tensor(output_details[0]['index'])[0])  # Access the first element of the array\n\n    detection_boxes = interpreter.get_tensor(output_details[1]['index'])[0]\n    detection_classes = interpreter.get_tensor(output_details[2]['index'])[0].astype(int)\n    detection_scores = interpreter.get_tensor(output_details[3]['index'])[0]\n\n    for i in range(num_detections):\n        if detection_scores[i] > confidence_threshold:\n            box = detection_boxes[i]\n            class_id = detection_classes[i]\n            score = detection_scores[i]\n\n            # Scale and clip bounding boxes\n            ymin, xmin, ymax, xmax = box\n            (left, right, top, bottom) = (xmin * frame_width, xmax * frame_width,\n                                          ymin * frame_height, ymax * frame_height)\n\n            cv2.rectangle(frame, (int(left), int(top)), (int(right), int(bottom)), (0, 255, 0), 2)\n            label = f'{labels[class_id]}: {score:.2f}'\n            cv2.putText(frame, label, (int(left), int(top) - 10),\n                        cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n\n    # Phase 5: Write the frame to the output video\n    out.write(frame)\n\n# Release resources\ncap.release()\nout.release()\ncv2.destroyAllWindows()",
        "last_error": "Traceback (most recent call last):\n  File \"script_1666b2bb_1754272877.py\", line 65, in <module>\n    num_detections = int(interpreter.get_tensor(output_details[0]['index'])[0])  # Access the first element of the array\nTypeError: only size-1 arrays can be converted to Python scalars"
      },
      "session_id": "qwen2.5-coder:32b_c8a6_tpusg_batch",
      "metadata": {
        "num_run": 16
      },
      "tags": [
        "benchmark",
        "qwen2.5-coder:32b",
        "tpu_sketch_generator"
      ],
      "latency": 194.081,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-04-58-11-164017_chatcmpl-7c0d7f89-30ae-44b8-ab29-f16588893164",
          "traceId": "5b3f978f",
          "type": "GENERATION",
          "name": "5b3f_tpusg_gen_attempt#1",
          "startTime": "2025-08-04T01:58:11.164000+00:00",
          "endTime": "2025-08-04T01:58:36.591000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 25427.0,
          "environment": "default",
          "promptTokens": 1833,
          "totalTokens": 2709,
          "costDetails": {},
          "completionTokens": 876,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-04-58-44-767486_chatcmpl-7d5d8072-40a5-41b1-ae2a-e2fbac161a14",
          "traceId": "5b3f978f",
          "type": "GENERATION",
          "name": "5b3f_tpusg_gen_attempt#2",
          "startTime": "2025-08-04T01:58:44.767000+00:00",
          "endTime": "2025-08-04T01:59:15.945000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 31178.0,
          "environment": "default",
          "promptTokens": 2048,
          "totalTokens": 3135,
          "costDetails": {},
          "completionTokens": 1087,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-04-59-24-155434_chatcmpl-076e9af4-c44d-4dd2-9686-ca91ba9fcf5f",
          "traceId": "5b3f978f",
          "type": "GENERATION",
          "name": "5b3f_tpusg_gen_attempt#3",
          "startTime": "2025-08-04T01:59:24.155000+00:00",
          "endTime": "2025-08-04T01:59:57.476000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 33321.0,
          "environment": "default",
          "promptTokens": 2048,
          "totalTokens": 3217,
          "costDetails": {},
          "completionTokens": 1169,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-05-00-05-569670_chatcmpl-b6171808-7e15-438e-8d69-856c3102d0e5",
          "traceId": "5b3f978f",
          "type": "GENERATION",
          "name": "5b3f_tpusg_gen_attempt#4",
          "startTime": "2025-08-04T02:00:05.569000+00:00",
          "endTime": "2025-08-04T02:00:37.560000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 31991.0,
          "environment": "default",
          "promptTokens": 2048,
          "totalTokens": 3166,
          "costDetails": {},
          "completionTokens": 1118,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-05-00-45-652102_chatcmpl-ebebb425-8e3d-4874-86c1-03f205199bb0",
          "traceId": "5b3f978f",
          "type": "GENERATION",
          "name": "5b3f_tpusg_gen_attempt#5",
          "startTime": "2025-08-04T02:00:45.652000+00:00",
          "endTime": "2025-08-04T02:01:17.118000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 31466.0,
          "environment": "default",
          "promptTokens": 2048,
          "totalTokens": 3144,
          "costDetails": {},
          "completionTokens": 1096,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "31668bda-cb2b-431f-b71b-5679ffdc3275",
          "traceId": "5b3f978f",
          "type": "SPAN",
          "name": "error_5b_tpusg_failure_signal_tpu_sketch_generator",
          "startTime": "2025-08-04T02:01:25.245000+00:00",
          "level": "ERROR",
          "statusMessage": "Failed. Last error: Traceback (most recent call last):\n  File \"script_1666b2bb_1754272877.py\", line 65, in <module>\n    num_detections = int(interpreter.get_tensor(output_details[0]['index'])[0])  # Access the first element of the array\nTypeError: only size-1 arrays can be converted to Python scalars",
          "calculatedTotalCost": 0.0,
          "environment": "default",
          "promptTokens": 0,
          "totalTokens": 0,
          "costDetails": {},
          "completionTokens": 0,
          "endTime": null,
          "model": null,
          "modelParameters": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null,
          "latency": null
        }
      ],
      "createdAt": "2025-08-04T01:58:11.683Z",
      "environment": "default",
      "updatedAt": "2025-08-04T02:01:30.437Z"
    },
    {
      "id": "79813ea0",
      "timestamp": "2025-08-04T01:54:50.473000+00:00",
      "name": "7981_tpu_sketch_generator",
      "input": null,
      "output": {
        "status": "failed",
        "last_code": "import numpy as np\nfrom tflite_runtime.interpreter import Interpreter, load_delegate\nimport cv2\n\n# Phase 1: Setup\nmodel_path  = \"/home/mendel/tinyml_autopilot/models/edgetpu_detect.tflite\"\nlabel_path  = \"/home/mendel/tinyml_autopilot/models/labelmap.txt\"\ninput_path  = \"/home/mendel/tinyml_autopilot/data//sheeps.mp4\"\noutput_path  = \"/home/mendel/tinyml_autopilot/results/sheeps_detections.mp4\"\nconfidence_threshold  = 0.5\n\n# Load labels\nwith open(label_path, 'r') as f:\n    labels = [line.strip() for line in f.readlines()]\n\n# Load Interpreter with EdgeTPU\ntry:\n    interpreter = Interpreter(model_path=model_path,\n                              experimental_delegates=[load_delegate('libedgetpu.so.1.0')])\nexcept Exception as e:\n    print(f\"Failed to load libedgetpu.so.1.0: {e}\")\n    try:\n        interpreter = Interpreter(model_path=model_path,\n                                  experimental_delegates=[load_delegate('/usr/lib/aarch64-linux-gnu/libedgetpu.so.1.0')])\n    except Exception as e:\n        print(f\"Failed to load /usr/lib/aarch64-linux-gnu/libedgetpu.so.1.0: {e}\")\n        raise\n\ninterpreter.allocate_tensors()\n\n# Get Model Details\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\n\nfloating_model = (input_details[0]['dtype'] == np.float32)\n\n# Phase 2: Input Acquisition & Preprocessing Loop\ncap = cv2.VideoCapture(input_path)\nif not cap.isOpened():\n    raise IOError(\"Cannot open video file\")\n\nframe_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\nframe_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\nfps = cap.get(cv2.CAP_PROP_FPS)\n\nout = cv2.VideoWriter(output_path, cv2.VideoWriter_fourcc(*'mp4v'), fps, (frame_width, frame_height))\n\nwhile True:\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    # Preprocess Data\n    input_data = cv2.resize(frame, (input_details[0]['shape'][1], input_details[0]['shape'][2]))\n    input_data = np.expand_dims(input_data, axis=0)\n\n    if floating_model:\n        input_data = (np.float32(input_data) - 127.5) / 127.5\n\n    # Phase 3: Inference\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n    interpreter.invoke()\n\n    # Phase 4: Output Interpretation & Handling Loop\n    output_data = interpreter.get_tensor(output_details[0]['index'])\n    num_detections = int(interpreter.get_tensor(output_details[1]['index']))  # Directly convert to int\n    detection_boxes = interpreter.get_tensor(output_details[2]['index'])[0]\n    detection_classes = interpreter.get_tensor(output_details[3]['index'])[0].astype(int)\n    detection_scores = interpreter.get_tensor(output_details[4]['index'])[0]\n\n    for i in range(num_detections):\n        if detection_scores[i] > confidence_threshold:\n            box = detection_boxes[i]\n            class_id = detection_classes[i]\n            score = detection_scores[i]\n\n            # Scale the bounding box coordinates\n            ymin, xmin, ymax, xmax = box\n            (left, right, top, bottom) = (xmin * frame_width, xmax * frame_width,\n                                          ymin * frame_height, ymax * frame_height)\n\n            # Draw the bounding box and label on the frame\n            cv2.rectangle(frame, (int(left), int(top)), (int(right), int(bottom)), (0, 255, 0), 2)\n            label = f'{labels[class_id]}: {score:.2f}'\n            cv2.putText(frame, label, (int(left), int(top) - 10),\n                        cv2.FONT_HERSHEY_SIMPLEX, 0.9, (36, 255, 12), 2)\n\n    # Write the frame to the output video\n    out.write(frame)\n\n# Release resources\ncap.release()\nout.release()\ncv2.destroyAllWindows()",
        "last_error": "Traceback (most recent call last):\n  File \"script_2e9540a1_1754272677.py\", line 66, in <module>\n    num_detections = int(interpreter.get_tensor(output_details[1]['index']))  # Directly convert to int\nTypeError: only size-1 arrays can be converted to Python scalars"
      },
      "session_id": "qwen2.5-coder:32b_c8a6_tpusg_batch",
      "metadata": {
        "num_run": 15
      },
      "tags": [
        "benchmark",
        "qwen2.5-coder:32b",
        "tpu_sketch_generator"
      ],
      "latency": 195.018,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-04-54-50-475789_chatcmpl-9473a5dc-8d02-49b8-9cef-83400154d011",
          "traceId": "79813ea0",
          "type": "GENERATION",
          "name": "7981_tpusg_gen_attempt#1",
          "startTime": "2025-08-04T01:54:50.475000+00:00",
          "endTime": "2025-08-04T01:55:16.409000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 25934.0,
          "environment": "default",
          "promptTokens": 1833,
          "totalTokens": 2726,
          "costDetails": {},
          "completionTokens": 893,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-04-55-24-596500_chatcmpl-150f7ce9-b65f-418b-8361-63cb851867e0",
          "traceId": "79813ea0",
          "type": "GENERATION",
          "name": "7981_tpusg_gen_attempt#2",
          "startTime": "2025-08-04T01:55:24.596000+00:00",
          "endTime": "2025-08-04T01:55:55.530000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 30934.0,
          "environment": "default",
          "promptTokens": 2048,
          "totalTokens": 3126,
          "costDetails": {},
          "completionTokens": 1078,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-04-56-03-630411_chatcmpl-f05f16f3-84cb-450d-9aa5-c4b0bfd55253",
          "traceId": "79813ea0",
          "type": "GENERATION",
          "name": "7981_tpusg_gen_attempt#3",
          "startTime": "2025-08-04T01:56:03.630000+00:00",
          "endTime": "2025-08-04T01:56:36.108000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 32478.0,
          "environment": "default",
          "promptTokens": 2048,
          "totalTokens": 3173,
          "costDetails": {},
          "completionTokens": 1125,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-04-56-44-187229_chatcmpl-d9bfcf04-dcf6-489e-af57-4ece98d06f88",
          "traceId": "79813ea0",
          "type": "GENERATION",
          "name": "7981_tpusg_gen_attempt#4",
          "startTime": "2025-08-04T01:56:44.187000+00:00",
          "endTime": "2025-08-04T01:57:15.210000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 31023.0,
          "environment": "default",
          "promptTokens": 2048,
          "totalTokens": 3129,
          "costDetails": {},
          "completionTokens": 1081,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-04-57-23-523732_chatcmpl-2fe13bce-9249-4ec9-9fb6-16de532f983e",
          "traceId": "79813ea0",
          "type": "GENERATION",
          "name": "7981_tpusg_gen_attempt#5",
          "startTime": "2025-08-04T01:57:23.523000+00:00",
          "endTime": "2025-08-04T01:57:57.348000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 33825.0,
          "environment": "default",
          "promptTokens": 2048,
          "totalTokens": 3236,
          "costDetails": {},
          "completionTokens": 1188,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "7386cc64-b005-4f25-9c6a-c898e4fab12a",
          "traceId": "79813ea0",
          "type": "SPAN",
          "name": "error_79_tpusg_failure_signal_tpu_sketch_generator",
          "startTime": "2025-08-04T01:58:05.493000+00:00",
          "level": "ERROR",
          "statusMessage": "Failed. Last error: Traceback (most recent call last):\n  File \"script_2e9540a1_1754272677.py\", line 66, in <module>\n    num_detections = int(interpreter.get_tensor(output_details[1]['index']))  # Directly convert to int\nTypeError: only size-1 arrays can be converted to Python scalars",
          "calculatedTotalCost": 0.0,
          "environment": "default",
          "promptTokens": 0,
          "totalTokens": 0,
          "costDetails": {},
          "completionTokens": 0,
          "endTime": null,
          "model": null,
          "modelParameters": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null,
          "latency": null
        }
      ],
      "createdAt": "2025-08-04T01:54:50.994Z",
      "environment": "default",
      "updatedAt": "2025-08-04T01:58:10.777Z"
    },
    {
      "id": "d8434420",
      "timestamp": "2025-08-04T01:50:51.663000+00:00",
      "name": "d843_tpu_sketch_generator",
      "input": null,
      "output": {
        "status": "success",
        "sketch": "import numpy as np\nfrom tflite_runtime.interpreter import Interpreter, load_delegate\n\n# Phase 1: Setup\nmodel_path  = \"/home/mendel/tinyml_autopilot/models/edgetpu_detect.tflite\"\nlabel_path  = \"/home/mendel/tinyml_autopilot/models/labelmap.txt\"\ninput_path  = \"/home/mendel/tinyml_autopilot/data//sheeps.mp4\"\noutput_path  = \"/home/mendel/tinyml_autopilot/results/sheeps_detections.mp4\"\nconfidence_threshold  = 0.5\n\n# Load labels\nwith open(label_path, 'r') as f:\n    labels = [line.strip() for line in f.readlines()]\n\n# Load Interpreter with EdgeTPU\ntry:\n    interpreter = Interpreter(model_path=model_path,\n                              experimental_delegates=[load_delegate('libedgetpu.so.1.0')])\nexcept Exception as e:\n    print(f\"Failed to load libedgetpu.so.1.0: {e}\")\n    try:\n        interpreter = Interpreter(model_path=model_path,\n                                  experimental_delegates=[load_delegate('/usr/lib/aarch64-linux-gnu/libedgetpu.so.1.0')])\n    except Exception as e:\n        print(f\"Failed to load /usr/lib/aarch64-linux-gnu/libedgetpu.so.1.0: {e}\")\n        raise\n\ninterpreter.allocate_tensors()\n\n# Get Model Details\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\n\nfloating_model = (input_details[0]['dtype'] == np.float32)\n\n# Phase 2: Input Acquisition & Preprocessing Loop\nimport cv2\n\ncap = cv2.VideoCapture(input_path)\nif not cap.isOpened():\n    raise IOError(\"Cannot open video file\")\n\nframe_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\nframe_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\nfps = cap.get(cv2.CAP_PROP_FPS)\n\nout = cv2.VideoWriter(output_path, cv2.VideoWriter_fourcc(*'mp4v'), fps, (frame_width, frame_height))\n\nwhile True:\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    # Preprocess Data\n    input_data = cv2.resize(frame, (input_details[0]['shape'][1], input_details[0]['shape'][2]))\n    input_data = np.expand_dims(input_data, axis=0)\n\n    if floating_model:\n        input_data = (np.float32(input_data) - 127.5) / 127.5\n\n    # Phase 3: Inference\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n    interpreter.invoke()\n\n    # Phase 4: Output Interpretation & Handling Loop\n    output_data = interpreter.get_tensor(output_details[0]['index'])\n    \n    # Ensure the number of detections tensor is a single value\n    num_detections_tensor = interpreter.get_tensor(output_details[1]['index'])\n    if num_detections_tensor.size == 1:\n        num_detections = int(num_detections_tensor[0])\n    else:\n        print(\"Unexpected shape for num_detections tensor:\", num_detections_tensor.shape)\n        continue\n    \n    detection_boxes = interpreter.get_tensor(output_details[2]['index'])[0]\n    detection_classes = interpreter.get_tensor(output_details[3]['index'])[0].astype(int)\n    detection_scores = interpreter.get_tensor(output_details[4]['index'])[0]\n\n    for i in range(num_detections):\n        if detection_scores[i] > confidence_threshold:\n            box = detection_boxes[i]\n            class_id = detection_classes[i]\n            score = detection_scores[i]\n\n            # Scale the bounding box coordinates\n            ymin, xmin, ymax, xmax = box\n            (left, right, top, bottom) = (xmin * frame_width, xmax * frame_width,\n                                          ymin * frame_height, ymax * frame_height)\n\n            # Draw the bounding box and label on the frame\n            cv2.rectangle(frame, (int(left), int(top)), (int(right), int(bottom)), (0, 255, 0), 2)\n            label = f'{labels[class_id]}: {score:.2f}'\n            cv2.putText(frame, label, (int(left), int(top) - 10),\n                        cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n\n    out.write(frame)\n\n# Release resources\ncap.release()\nout.release()\ncv2.destroyAllWindows()"
      },
      "session_id": "qwen2.5-coder:32b_c8a6_tpusg_batch",
      "metadata": {
        "num_run": 14
      },
      "tags": [
        "benchmark",
        "qwen2.5-coder:32b",
        "tpu_sketch_generator"
      ],
      "latency": 185.939,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-04-50-51-665429_chatcmpl-8077c45c-3034-4728-8c8d-565aadcaee04",
          "traceId": "d8434420",
          "type": "GENERATION",
          "name": "d843_tpusg_gen_attempt#1",
          "startTime": "2025-08-04T01:50:51.665000+00:00",
          "endTime": "2025-08-04T01:51:17.655000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 25990.0,
          "environment": "default",
          "promptTokens": 1833,
          "totalTokens": 2726,
          "costDetails": {},
          "completionTokens": 893,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-04-51-25-805512_chatcmpl-d093cc31-2d07-48ec-90f6-cb3743605d67",
          "traceId": "d8434420",
          "type": "GENERATION",
          "name": "d843_tpusg_gen_attempt#2",
          "startTime": "2025-08-04T01:51:25.805000+00:00",
          "endTime": "2025-08-04T01:51:56.897000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 31092.0,
          "environment": "default",
          "promptTokens": 2048,
          "totalTokens": 3126,
          "costDetails": {},
          "completionTokens": 1078,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-04-52-04-997067_chatcmpl-dcd045bc-449f-4fde-a659-594459d0db66",
          "traceId": "d8434420",
          "type": "GENERATION",
          "name": "d843_tpusg_gen_attempt#3",
          "startTime": "2025-08-04T01:52:04.997000+00:00",
          "endTime": "2025-08-04T01:52:36.357000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 31360.0,
          "environment": "default",
          "promptTokens": 2048,
          "totalTokens": 3142,
          "costDetails": {},
          "completionTokens": 1094,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-04-52-44-465372_chatcmpl-fc0eaa07-a221-483a-954b-1c158865dddf",
          "traceId": "d8434420",
          "type": "GENERATION",
          "name": "d843_tpusg_gen_attempt#4",
          "startTime": "2025-08-04T01:52:44.465000+00:00",
          "endTime": "2025-08-04T01:53:17.728000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 33263.0,
          "environment": "default",
          "promptTokens": 2048,
          "totalTokens": 3214,
          "costDetails": {},
          "completionTokens": 1166,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-04-53-25-860109_chatcmpl-5b6559dd-172d-4087-885a-c87d8e9f4226",
          "traceId": "d8434420",
          "type": "GENERATION",
          "name": "d843_tpusg_gen_attempt#5",
          "startTime": "2025-08-04T01:53:25.860000+00:00",
          "endTime": "2025-08-04T01:53:57.604000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 31744.0,
          "environment": "default",
          "promptTokens": 2048,
          "totalTokens": 3157,
          "costDetails": {},
          "completionTokens": 1109,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        }
      ],
      "createdAt": "2025-08-04T01:50:52.183Z",
      "environment": "default",
      "updatedAt": "2025-08-04T01:54:50.426Z"
    },
    {
      "id": "4ac70288",
      "timestamp": "2025-08-04T01:47:31.113000+00:00",
      "name": "4ac7_tpu_sketch_generator",
      "input": null,
      "output": {
        "status": "failed",
        "last_code": "import numpy as np\nfrom tflite_runtime.interpreter import Interpreter, load_delegate\nimport cv2\n\n# Phase 1: Setup\nmodel_path     = \"/home/mendel/tinyml_autopilot/models/edgetpu_detect.tflite\"\nlabel_path     = \"/home/mendel/tinyml_autopilot/models/labelmap.txt\"\ninput_path     = \"/home/mendel/tinyml_autopilot/data//sheeps.mp4\"\noutput_path    = \"/home/mendel/tinyml_autopilot/results/sheeps_detections.mp4\"\nconfidence_threshold   = 0.5\n\n# Load labels\nwith open(label_path, 'r') as f:\n    labels = [line.strip() for line in f.readlines()]\n\n# Load Interpreter with EdgeTPU\ntry:\n    interpreter = Interpreter(model_path=model_path,\n                              experimental_delegates=[load_delegate('libedgetpu.so.1.0')])\nexcept Exception as e:\n    print(f\"Failed to load libedgetpu.so.1.0: {e}\")\n    try:\n        interpreter = Interpreter(model_path=model_path,\n                                  experimental_delegates=[load_delegate('/usr/lib/aarch64-linux-gnu/libedgetpu.so.1.0')])\n    except Exception as e:\n        print(f\"Failed to load /usr/lib/aarch64-linux-gnu/libedgetpu.so.1.0: {e}\")\n        raise\n\ninterpreter.allocate_tensors()\n\n# Get Model Details\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\n\nfloating_model = (input_details[0]['dtype'] == np.float32)\n\n# Print output details for debugging\nfor i, detail in enumerate(output_details):\n    print(f\"Output {i}: {detail}\")\n\n# Phase 2: Input Acquisition & Preprocessing Loop\ncap = cv2.VideoCapture(input_path)\nif not cap.isOpened():\n    raise IOError(\"Cannot open video file\")\n\nframe_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\nframe_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\nfps = cap.get(cv2.CAP_PROP_FPS)\n\nout = cv2.VideoWriter(output_path, cv2.VideoWriter_fourcc(*'mp4v'), fps, (frame_width, frame_height))\n\nwhile True:\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    # Preprocess Data\n    input_data = cv2.resize(frame, (input_details[0]['shape'][1], input_details[0]['shape'][2]))\n    input_data = np.expand_dims(input_data, axis=0)\n\n    if floating_model:\n        input_data = (np.float32(input_data) - 127.5) / 127.5\n\n    # Phase 3: Inference\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n    interpreter.invoke()\n\n    # Phase 4: Output Interpretation & Handling Loop\n    num_detections_tensor = interpreter.get_tensor(output_details[0]['index'])\n    print(f\"Shape of num_detections tensor: {num_detections_tensor.shape}\")\n    \n    # Correctly access the number of detections\n    num_detections = int(num_detections_tensor[0])\n        \n    detection_boxes = interpreter.get_tensor(output_details[1]['index'])[0]\n    detection_classes = interpreter.get_tensor(output_details[2]['index'])[0].astype(int)\n    detection_scores = interpreter.get_tensor(output_details[3]['index'])[0]\n\n    for i in range(num_detections):\n        if detection_scores[i] > confidence_threshold:\n            box = detection_boxes[i]\n            class_id = detection_classes[i]\n            score = detection_scores[i]\n\n            # Scale and clip bounding boxes\n            ymin, xmin, ymax, xmax = box\n            (left, right, top, bottom) = (xmin * frame_width, xmax * frame_width,\n                                          ymin * frame_height, ymax * frame_height)\n\n            cv2.rectangle(frame, (int(left), int(top)), (int(right), int(bottom)), (0, 255, 0), 2)\n            label = f'{labels[class_id]}: {score:.2f}'\n            cv2.putText(frame, label, (int(left), int(top) - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (36, 255, 12), 2)\n\n    # Write the frame with detections to the output video\n    out.write(frame)\n\n# Release resources\ncap.release()\nout.release()\ncv2.destroyAllWindows()",
        "last_error": "Output 0: {'name': 'TFLite_Detection_PostProcess', 'index': 167, 'shape': array([ 1, 10,  4], dtype=int32), 'shape_signature': array([ 1, 10,  4], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}\nOutput 1: {'name': 'TFLite_Detection_PostProcess:1', 'index': 168, 'shape': array([ 1, 10], dtype=int32), 'shape_signature': array([ 1, 10], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}\nOutput 2: {'name': 'TFLite_Detection_PostProcess:2', 'index': 169, 'shape': array([ 1, 10], dtype=int32), 'shape_signature': array([ 1, 10], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}\nOutput 3: {'name': 'TFLite_Detection_PostProcess:3', 'index': 170, 'shape': array([1], dtype=int32), 'shape_signature': array([1], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}\nShape of num_detections tensor: (1, 10, 4)\nTraceback (most recent call last):\n  File \"script_fa9852bf_1754272237.py\", line 73, in <module>\n    num_detections = int(num_detections_tensor[0])\nTypeError: only size-1 arrays can be converted to Python scalars"
      },
      "session_id": "qwen2.5-coder:32b_c8a6_tpusg_batch",
      "metadata": {
        "num_run": 13
      },
      "tags": [
        "benchmark",
        "qwen2.5-coder:32b",
        "tpu_sketch_generator"
      ],
      "latency": 195.052,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-04-47-31-115444_chatcmpl-e9b28ee9-50a4-45b8-aa09-e145a7b90c9d",
          "traceId": "4ac70288",
          "type": "GENERATION",
          "name": "4ac7_tpusg_gen_attempt#1",
          "startTime": "2025-08-04T01:47:31.115000+00:00",
          "endTime": "2025-08-04T01:47:56.634000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 25519.0,
          "environment": "default",
          "promptTokens": 1833,
          "totalTokens": 2709,
          "costDetails": {},
          "completionTokens": 876,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-04-48-04-850938_chatcmpl-2c1e443a-9d92-4257-bca8-ca6ca65544fd",
          "traceId": "4ac70288",
          "type": "GENERATION",
          "name": "4ac7_tpusg_gen_attempt#2",
          "startTime": "2025-08-04T01:48:04.850000+00:00",
          "endTime": "2025-08-04T01:48:38.605000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 33755.0,
          "environment": "default",
          "promptTokens": 2048,
          "totalTokens": 3231,
          "costDetails": {},
          "completionTokens": 1183,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-04-48-46-872444_chatcmpl-1731ff29-9a4f-45ef-bc1d-0485efa4c5f2",
          "traceId": "4ac70288",
          "type": "GENERATION",
          "name": "4ac7_tpusg_gen_attempt#3",
          "startTime": "2025-08-04T01:48:46.872000+00:00",
          "endTime": "2025-08-04T01:49:17.186000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 30314.0,
          "environment": "default",
          "promptTokens": 2048,
          "totalTokens": 3101,
          "costDetails": {},
          "completionTokens": 1053,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-04-49-25-473314_chatcmpl-4e3582b8-248b-4cbe-a35e-ce17fa5d43a7",
          "traceId": "4ac70288",
          "type": "GENERATION",
          "name": "4ac7_tpusg_gen_attempt#4",
          "startTime": "2025-08-04T01:49:25.473000+00:00",
          "endTime": "2025-08-04T01:49:58.166000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 32693.0,
          "environment": "default",
          "promptTokens": 2048,
          "totalTokens": 3191,
          "costDetails": {},
          "completionTokens": 1143,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-04-50-06-519916_chatcmpl-07f2b7fc-b5a5-46ea-85d3-05cf30ea0bfd",
          "traceId": "4ac70288",
          "type": "GENERATION",
          "name": "4ac7_tpusg_gen_attempt#5",
          "startTime": "2025-08-04T01:50:06.519000+00:00",
          "endTime": "2025-08-04T01:50:37.793000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 31274.0,
          "environment": "default",
          "promptTokens": 2048,
          "totalTokens": 3135,
          "costDetails": {},
          "completionTokens": 1087,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "477c80ab-a0e7-49bc-9aec-3bdf968f9b0e",
          "traceId": "4ac70288",
          "type": "SPAN",
          "name": "error_4a_tpusg_failure_signal_tpu_sketch_generator",
          "startTime": "2025-08-04T01:50:46.167000+00:00",
          "level": "ERROR",
          "statusMessage": "Failed. Last error: Output 0: {'name': 'TFLite_Detection_PostProcess', 'index': 167, 'shape': array([ 1, 10,  4], dtype=int32), 'shape_signature': array([ 1, 10,  4], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}\nOutput 1: {'name': 'TFLite_Detection_PostProcess:1', 'index': 168, 'shape': array([ 1, 10], dtype=int32), 'shape_signature': array([ 1, 10], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}\nOutput 2: {'name': 'TFLite_Detection_PostProcess:2', 'index': 169, 'shape': array([ 1, 10], dtype=int32), 'shape_signature': array([ 1, 10], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}\nOutput 3: {'name': 'TFLite_Detection_PostProcess:3', 'index': 170, 'shape': array([1], dtype=int32), 'shape_signature': array([1], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}\nShape of num_detections tensor: (1, 10, 4)\nTraceback (most recent call last):\n  File \"script_fa9852bf_1754272237.py\", line 73, in <module>\n    num_detections = int(num_detections_tensor[0])\nTypeError: only size-1 arrays can be converted to Python scalars",
          "calculatedTotalCost": 0.0,
          "environment": "default",
          "promptTokens": 0,
          "totalTokens": 0,
          "costDetails": {},
          "completionTokens": 0,
          "endTime": null,
          "model": null,
          "modelParameters": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null,
          "latency": null
        }
      ],
      "createdAt": "2025-08-04T01:47:31.633Z",
      "environment": "default",
      "updatedAt": "2025-08-04T01:50:51.357Z"
    },
    {
      "id": "db2d539b",
      "timestamp": "2025-08-04T01:44:48.080000+00:00",
      "name": "db2d_tpu_sketch_generator",
      "input": null,
      "output": {
        "status": "success",
        "sketch": "import numpy as np\nfrom tflite_runtime.interpreter import Interpreter, load_delegate\nimport cv2\n\n# Phase 1: Setup\nmodel_path  = \"/home/mendel/tinyml_autopilot/models/edgetpu_detect.tflite\"\nlabel_path  = \"/home/mendel/tinyml_autopilot/models/labelmap.txt\"\ninput_path  = \"/home/mendel/tinyml_autopilot/data//sheeps.mp4\"\noutput_path  = \"/home/mendel/tinyml_autopilot/results/sheeps_detections.mp4\"\nconfidence_threshold  = 0.5\n\n# Load labels\nwith open(label_path, 'r') as f:\n    labels = [line.strip() for line in f.readlines()]\n\n# Load Interpreter with EdgeTPU\ntry:\n    interpreter = Interpreter(model_path=model_path,\n                              experimental_delegates=[load_delegate('libedgetpu.so.1.0')])\nexcept Exception as e:\n    print(f\"Failed to load libedgetpu.so.1.0: {e}\")\n    try:\n        interpreter = Interpreter(model_path=model_path,\n                                  experimental_delegates=[load_delegate('/usr/lib/aarch64-linux-gnu/libedgetpu.so.1.0')])\n    except Exception as e:\n        print(f\"Failed to load /usr/lib/aarch64-linux-gnu/libedgetpu.so.1.0: {e}\")\n        raise\n\ninterpreter.allocate_tensors()\n\n# Get Model Details\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\n\nfloating_model = (input_details[0]['dtype'] == np.float32)\n\n# Phase 2: Input Acquisition & Preprocessing Loop\ncap = cv2.VideoCapture(input_path)\nif not cap.isOpened():\n    raise IOError(\"Cannot open video file\")\n\nframe_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\nframe_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\nfps = cap.get(cv2.CAP_PROP_FPS)\n\nout = cv2.VideoWriter(output_path, cv2.VideoWriter_fourcc(*'mp4v'), fps, (frame_width, frame_height))\n\nwhile True:\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    # Preprocess Data\n    input_data = cv2.resize(frame, (input_details[0]['shape'][1], input_details[0]['shape'][2]))\n    input_data = np.expand_dims(input_data, axis=0)\n\n    if floating_model:\n        input_data = (np.float32(input_data) - 127.5) / 127.5\n\n    # Phase 3: Inference\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n    interpreter.invoke()\n\n    # Phase 4: Output Interpretation & Handling Loop\n    detection_boxes = interpreter.get_tensor(output_details[0]['index'])[0]\n    detection_classes = interpreter.get_tensor(output_details[1]['index'])[0].astype(int)\n    detection_scores = interpreter.get_tensor(output_details[2]['index'])[0]\n\n    for i in range(len(detection_scores)):\n        if detection_scores[i] > confidence_threshold:\n            box = detection_boxes[i]\n            class_id = detection_classes[i]\n            score = detection_scores[i]\n\n            # Scale and clip bounding boxes\n            ymin, xmin, ymax, xmax = box\n            (left, right, top, bottom) = (xmin * frame_width, xmax * frame_width,\n                                          ymin * frame_height, ymax * frame_height)\n\n            cv2.rectangle(frame, (int(left), int(top)), (int(right), int(bottom)), (0, 255, 0), 2)\n            label = f'{labels[class_id]}: {score:.2f}'\n            cv2.putText(frame, label, (int(left), int(top) - 10),\n                        cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n\n    # Handle Output\n    out.write(frame)\n\n# Phase 5: Cleanup\ncap.release()\nout.release()\ncv2.destroyAllWindows()"
      },
      "session_id": "qwen2.5-coder:32b_c8a6_tpusg_batch",
      "metadata": {
        "num_run": 12
      },
      "tags": [
        "benchmark",
        "qwen2.5-coder:32b",
        "tpu_sketch_generator"
      ],
      "latency": 104.227,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-04-44-48-082294_chatcmpl-9f446855-d246-4ad3-8a12-adcfa3992bd3",
          "traceId": "db2d539b",
          "type": "GENERATION",
          "name": "db2d_tpusg_gen_attempt#1",
          "startTime": "2025-08-04T01:44:48.082000+00:00",
          "endTime": "2025-08-04T01:45:13.516000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 25434.0,
          "environment": "default",
          "promptTokens": 1833,
          "totalTokens": 2709,
          "costDetails": {},
          "completionTokens": 876,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-04-45-21-750399_chatcmpl-1e5c600f-1e43-49de-bc7c-470641655b3b",
          "traceId": "db2d539b",
          "type": "GENERATION",
          "name": "db2d_tpusg_gen_attempt#2",
          "startTime": "2025-08-04T01:45:21.750000+00:00",
          "endTime": "2025-08-04T01:45:53.533000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 31783.0,
          "environment": "default",
          "promptTokens": 2048,
          "totalTokens": 3157,
          "costDetails": {},
          "completionTokens": 1109,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-04-46-01-766015_chatcmpl-b9b2dbce-bd9c-4703-91a9-5f4315caae4e",
          "traceId": "db2d539b",
          "type": "GENERATION",
          "name": "db2d_tpusg_gen_attempt#3",
          "startTime": "2025-08-04T01:46:01.766000+00:00",
          "endTime": "2025-08-04T01:46:32.309000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 30543.0,
          "environment": "default",
          "promptTokens": 2048,
          "totalTokens": 3110,
          "costDetails": {},
          "completionTokens": 1062,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        }
      ],
      "createdAt": "2025-08-04T01:44:48.598Z",
      "environment": "default",
      "updatedAt": "2025-08-04T01:47:29.799Z"
    },
    {
      "id": "9e0f1709",
      "timestamp": "2025-08-04T01:41:26.477000+00:00",
      "name": "9e0f_tpu_sketch_generator",
      "input": null,
      "output": {
        "status": "failed",
        "last_code": "import numpy as np\nfrom tflite_runtime.interpreter import Interpreter, load_delegate\nimport cv2\n\n# Phase 1: Setup\nmodel_path  = \"/home/mendel/tinyml_autopilot/models/edgetpu_detect.tflite\"\nlabel_path  = \"/home/mendel/tinyml_autopilot/models/labelmap.txt\"\ninput_path  = \"/home/mendel/tinyml_autopilot/data//sheeps.mp4\"\noutput_path  = \"/home/mendel/tinyml_autopilot/results/sheeps_detections.mp4\"\nconfidence_threshold  = 0.5\n\n# Load labels\nwith open(label_path, 'r') as f:\n    labels = [line.strip() for line in f.readlines()]\n\n# Load Interpreter with EdgeTPU\ntry:\n    interpreter = Interpreter(model_path=model_path,\n                              experimental_delegates=[load_delegate('libedgetpu.so.1.0')])\nexcept Exception as e:\n    print(f\"Failed to load libedgetpu.so.1.0: {e}\")\n    try:\n        interpreter = Interpreter(model_path=model_path,\n                                  experimental_delegates=[load_delegate('/usr/lib/aarch64-linux-gnu/libedgetpu.so.1.0')])\n    except Exception as e:\n        print(f\"Failed to load /usr/lib/aarch64-linux-gnu/libedgetpu.so.1.0: {e}\")\n        raise\n\ninterpreter.allocate_tensors()\n\n# Get Model Details\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\n\nfloating_model = (input_details[0]['dtype'] == np.float32)\n\n# Phase 2: Input Acquisition & Preprocessing Loop\ncap = cv2.VideoCapture(input_path)\nif not cap.isOpened():\n    raise IOError(\"Cannot open video file\")\n\nframe_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\nframe_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\nfps = cap.get(cv2.CAP_PROP_FPS)\n\nout = cv2.VideoWriter(output_path, cv2.VideoWriter_fourcc(*'mp4v'), fps, (frame_width, frame_height))\n\nwhile True:\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    # Preprocess Data\n    input_data = cv2.resize(frame, (input_details[0]['shape'][1], input_details[0]['shape'][2]))\n    input_data = np.expand_dims(input_data, axis=0)\n\n    if floating_model:\n        input_data = (np.float32(input_data) - 127.5) / 127.5\n\n    # Phase 3: Inference\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n    interpreter.invoke()\n\n    # Phase 4: Output Interpretation & Handling Loop\n    output_data = interpreter.get_tensor(output_details[0]['index'])\n    \n    # Ensure we are getting a single integer value for num_detections\n    num_detections = int(interpreter.get_tensor(output_details[1]['index']).flatten()[0])\n    \n    detection_boxes = interpreter.get_tensor(output_details[2]['index'])[0]\n    detection_classes = interpreter.get_tensor(output_details[3]['index'])[0].astype(int)\n    detection_scores = interpreter.get_tensor(output_details[4]['index'])[0]\n\n    for i in range(num_detections):\n        if detection_scores[i] > confidence_threshold:\n            box = detection_boxes[i]\n            class_id = detection_classes[i]\n            score = detection_scores[i]\n\n            # Scale and clip bounding boxes\n            ymin, xmin, ymax, xmax = box\n            (left, right, top, bottom) = (xmin * frame_width, xmax * frame_width,\n                                          ymin * frame_height, ymax * frame_height)\n\n            cv2.rectangle(frame, (int(left), int(top)), (int(right), int(bottom)), (0, 255, 0), 2)\n            label = f'{labels[class_id]}: {score:.2f}'\n            cv2.putText(frame, label, (int(left), int(top) - 10),\n                        cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n\n    # Handle Output\n    out.write(frame)\n\n# Phase 5: Cleanup\ncap.release()\nout.release()\ncv2.destroyAllWindows()",
        "last_error": "Traceback (most recent call last):\n  File \"script_5388c33d_1754271873.py\", line 72, in <module>\n    detection_scores = interpreter.get_tensor(output_details[4]['index'])[0]\nIndexError: list index out of range"
      },
      "session_id": "qwen2.5-coder:32b_c8a6_tpusg_batch",
      "metadata": {
        "num_run": 11
      },
      "tags": [
        "benchmark",
        "qwen2.5-coder:32b",
        "tpu_sketch_generator"
      ],
      "latency": 195.782,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-04-41-26-479493_chatcmpl-bbf014d8-a9d7-4b47-a5b2-ef1bed6a223d",
          "traceId": "9e0f1709",
          "type": "GENERATION",
          "name": "9e0f_tpusg_gen_attempt#1",
          "startTime": "2025-08-04T01:41:26.479000+00:00",
          "endTime": "2025-08-04T01:41:52.054000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 25575.0,
          "environment": "default",
          "promptTokens": 1833,
          "totalTokens": 2709,
          "costDetails": {},
          "completionTokens": 876,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-04-42-00-156037_chatcmpl-a1cfa061-6ceb-40da-81df-123e97ad5023",
          "traceId": "9e0f1709",
          "type": "GENERATION",
          "name": "9e0f_tpusg_gen_attempt#2",
          "startTime": "2025-08-04T01:42:00.156000+00:00",
          "endTime": "2025-08-04T01:42:32.164000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 32008.0,
          "environment": "default",
          "promptTokens": 2048,
          "totalTokens": 3166,
          "costDetails": {},
          "completionTokens": 1118,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-04-42-40-283525_chatcmpl-4572b569-171e-43d0-9255-8efc42ee0787",
          "traceId": "9e0f1709",
          "type": "GENERATION",
          "name": "9e0f_tpusg_gen_attempt#3",
          "startTime": "2025-08-04T01:42:40.283000+00:00",
          "endTime": "2025-08-04T01:43:13.775000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 33492.0,
          "environment": "default",
          "promptTokens": 2048,
          "totalTokens": 3222,
          "costDetails": {},
          "completionTokens": 1174,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-04-43-22-174677_chatcmpl-aac051da-c098-4379-97f3-6906f37f6184",
          "traceId": "9e0f1709",
          "type": "GENERATION",
          "name": "9e0f_tpusg_gen_attempt#4",
          "startTime": "2025-08-04T01:43:22.174000+00:00",
          "endTime": "2025-08-04T01:43:53.755000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 31581.0,
          "environment": "default",
          "promptTokens": 2048,
          "totalTokens": 3150,
          "costDetails": {},
          "completionTokens": 1102,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-04-44-01-848803_chatcmpl-be18af81-f6fd-41a9-8159-214274365701",
          "traceId": "9e0f1709",
          "type": "GENERATION",
          "name": "9e0f_tpusg_gen_attempt#5",
          "startTime": "2025-08-04T01:44:01.848000+00:00",
          "endTime": "2025-08-04T01:44:33.964000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 32116.0,
          "environment": "default",
          "promptTokens": 2048,
          "totalTokens": 3171,
          "costDetails": {},
          "completionTokens": 1123,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "3dec3895-b3a2-4879-9431-85b28ff2827c",
          "traceId": "9e0f1709",
          "type": "SPAN",
          "name": "error_9e_tpusg_failure_signal_tpu_sketch_generator",
          "startTime": "2025-08-04T01:44:42.261000+00:00",
          "level": "ERROR",
          "statusMessage": "Failed. Last error: Traceback (most recent call last):\n  File \"script_5388c33d_1754271873.py\", line 72, in <module>\n    detection_scores = interpreter.get_tensor(output_details[4]['index'])[0]\nIndexError: list index out of range",
          "calculatedTotalCost": 0.0,
          "environment": "default",
          "promptTokens": 0,
          "totalTokens": 0,
          "costDetails": {},
          "completionTokens": 0,
          "endTime": null,
          "model": null,
          "modelParameters": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null,
          "latency": null
        }
      ],
      "createdAt": "2025-08-04T01:41:26.998Z",
      "environment": "default",
      "updatedAt": "2025-08-04T01:44:47.777Z"
    },
    {
      "id": "718ed850",
      "timestamp": "2025-08-04T01:38:06.935000+00:00",
      "name": "718e_tpu_sketch_generator",
      "input": null,
      "output": {
        "status": "failed",
        "last_code": "import numpy as np\nfrom tflite_runtime.interpreter import Interpreter, load_delegate\nimport cv2\n\n# Phase 1: Setup\nmodel_path  = \"/home/mendel/tinyml_autopilot/models/edgetpu_detect.tflite\"\nlabel_path  = \"/home/mendel/tinyml_autopilot/models/labelmap.txt\"\ninput_path  = \"/home/mendel/tinyml_autopilot/data//sheeps.mp4\"\noutput_path  = \"/home/mendel/tinyml_autopilot/results/sheeps_detections.mp4\"\nconfidence_threshold  = 0.5\n\n# Load labels\nwith open(label_path, 'r') as f:\n    labels = [line.strip() for line in f.readlines()]\n\n# Load Interpreter with EdgeTPU\ntry:\n    interpreter = Interpreter(model_path=model_path,\n                              experimental_delegates=[load_delegate('libedgetpu.so.1.0')])\nexcept Exception as e:\n    print(f\"Failed to load libedgetpu.so.1.0: {e}\")\n    try:\n        interpreter = Interpreter(model_path=model_path,\n                                  experimental_delegates=[load_delegate('/usr/lib/aarch64-linux-gnu/libedgetpu.so.1.0')])\n    except Exception as e:\n        print(f\"Failed to load /usr/lib/aarch64-linux-gnu/libedgetpu.so.1.0: {e}\")\n        raise\n\ninterpreter.allocate_tensors()\n\n# Get Model Details\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\n\nfloating_model = (input_details[0]['dtype'] == np.float32)\n\n# Phase 2: Input Acquisition & Preprocessing Loop\ncap = cv2.VideoCapture(input_path)\nif not cap.isOpened():\n    raise IOError(\"Cannot open video file\")\n\nframe_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\nframe_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\nfps = cap.get(cv2.CAP_PROP_FPS)\n\nout = cv2.VideoWriter(output_path, cv2.VideoWriter_fourcc(*'mp4v'), fps, (frame_width, frame_height))\n\nwhile True:\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    # Preprocess Data\n    input_data = cv2.resize(frame, (input_details[0]['shape'][1], input_details[0]['shape'][2]))\n    input_data = np.expand_dims(input_data, axis=0)\n\n    if floating_model:\n        input_data = (np.float32(input_data) - 127.5) / 127.5\n\n    # Phase 3: Inference\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n    interpreter.invoke()\n\n    # Phase 4: Output Interpretation & Handling Loop\n    output_data = interpreter.get_tensor(output_details[0]['index'])\n    num_detections = int(interpreter.get_tensor(output_details[1]['index']))  # Access the scalar value directly\n    detection_boxes = interpreter.get_tensor(output_details[2]['index'])[0]\n    detection_classes = interpreter.get_tensor(output_details[3]['index'])[0].astype(int)\n    detection_scores = interpreter.get_tensor(output_details[4]['index'])[0]\n\n    for i in range(num_detections):\n        if detection_scores[i] > confidence_threshold:\n            box = detection_boxes[i]\n            class_id = detection_classes[i]\n            score = detection_scores[i]\n\n            # Scale the bounding box coordinates\n            ymin, xmin, ymax, xmax = box\n            (left, right, top, bottom) = (xmin * frame_width, xmax * frame_width,\n                                          ymin * frame_height, ymax * frame_height)\n\n            # Draw the bounding box and label on the frame\n            cv2.rectangle(frame, (int(left), int(top)), (int(right), int(bottom)), (0, 255, 0), 2)\n            label = f'{labels[class_id]}: {score:.2f}'\n            cv2.putText(frame, label, (int(left), int(top) - 10),\n                        cv2.FONT_HERSHEY_SIMPLEX, 0.9, (36, 255, 12), 2)\n\n    # Write the frame to the output video\n    out.write(frame)\n\n# Release resources\ncap.release()\nout.release()\ncv2.destroyAllWindows()",
        "last_error": "Traceback (most recent call last):\n  File \"script_7e92c244_1754271671.py\", line 66, in <module>\n    num_detections = int(interpreter.get_tensor(output_details[1]['index']))  # Access the scalar value directly\nTypeError: only size-1 arrays can be converted to Python scalars"
      },
      "session_id": "qwen2.5-coder:32b_c8a6_tpusg_batch",
      "metadata": {
        "num_run": 10
      },
      "tags": [
        "benchmark",
        "qwen2.5-coder:32b",
        "tpu_sketch_generator"
      ],
      "latency": 193.283,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-04-38-06-937189_chatcmpl-006b15ae-bc06-4860-aa73-b45c9428123f",
          "traceId": "718ed850",
          "type": "GENERATION",
          "name": "718e_tpusg_gen_attempt#1",
          "startTime": "2025-08-04T01:38:06.937000+00:00",
          "endTime": "2025-08-04T01:38:32.847000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 25910.0,
          "environment": "default",
          "promptTokens": 1833,
          "totalTokens": 2726,
          "costDetails": {},
          "completionTokens": 893,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-04-38-40-889196_chatcmpl-252d3b4c-e04f-4411-b248-9cbe0a99e589",
          "traceId": "718ed850",
          "type": "GENERATION",
          "name": "718e_tpusg_gen_attempt#2",
          "startTime": "2025-08-04T01:38:40.889000+00:00",
          "endTime": "2025-08-04T01:39:11.517000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 30628.0,
          "environment": "default",
          "promptTokens": 2048,
          "totalTokens": 3114,
          "costDetails": {},
          "completionTokens": 1066,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-04-39-19-919103_chatcmpl-7ed397e7-c7d9-4a55-87fc-40db19036113",
          "traceId": "718ed850",
          "type": "GENERATION",
          "name": "718e_tpusg_gen_attempt#3",
          "startTime": "2025-08-04T01:39:19.919000+00:00",
          "endTime": "2025-08-04T01:39:50.665000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 30746.0,
          "environment": "default",
          "promptTokens": 2048,
          "totalTokens": 3119,
          "costDetails": {},
          "completionTokens": 1071,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-04-39-58-962529_chatcmpl-5364c09f-9ba1-46b4-ae89-90e029c27a44",
          "traceId": "718ed850",
          "type": "GENERATION",
          "name": "718e_tpusg_gen_attempt#4",
          "startTime": "2025-08-04T01:39:58.962000+00:00",
          "endTime": "2025-08-04T01:40:30.338000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 31376.0,
          "environment": "default",
          "promptTokens": 2048,
          "totalTokens": 3142,
          "costDetails": {},
          "completionTokens": 1094,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-04-40-38-408360_chatcmpl-c33fd280-e297-4159-a0c8-f8a4873035db",
          "traceId": "718ed850",
          "type": "GENERATION",
          "name": "718e_tpusg_gen_attempt#5",
          "startTime": "2025-08-04T01:40:38.408000+00:00",
          "endTime": "2025-08-04T01:41:11.848000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 33440.0,
          "environment": "default",
          "promptTokens": 2048,
          "totalTokens": 3218,
          "costDetails": {},
          "completionTokens": 1170,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "8ae57014-6349-437e-9588-3a1e2d30b6a3",
          "traceId": "718ed850",
          "type": "SPAN",
          "name": "error_71_tpusg_failure_signal_tpu_sketch_generator",
          "startTime": "2025-08-04T01:41:20.220000+00:00",
          "level": "ERROR",
          "statusMessage": "Failed. Last error: Traceback (most recent call last):\n  File \"script_7e92c244_1754271671.py\", line 66, in <module>\n    num_detections = int(interpreter.get_tensor(output_details[1]['index']))  # Access the scalar value directly\nTypeError: only size-1 arrays can be converted to Python scalars",
          "calculatedTotalCost": 0.0,
          "environment": "default",
          "promptTokens": 0,
          "totalTokens": 0,
          "costDetails": {},
          "completionTokens": 0,
          "endTime": null,
          "model": null,
          "modelParameters": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null,
          "latency": null
        }
      ],
      "createdAt": "2025-08-04T01:38:07.457Z",
      "environment": "default",
      "updatedAt": "2025-08-04T01:41:25.734Z"
    },
    {
      "id": "c12fbe3a",
      "timestamp": "2025-08-04T01:34:46.276000+00:00",
      "name": "c12f_tpu_sketch_generator",
      "input": null,
      "output": {
        "status": "failed",
        "last_code": "import numpy as np\nfrom tflite_runtime.interpreter import Interpreter, load_delegate\nimport cv2\n\n# Phase 1: Setup\nmodel_path  = \"/home/mendel/tinyml_autopilot/models/edgetpu_detect.tflite\"\nlabel_path  = \"/home/mendel/tinyml_autopilot/models/labelmap.txt\"\ninput_path  = \"/home/mendel/tinyml_autopilot/data//sheeps.mp4\"\noutput_path  = \"/home/mendel/tinyml_autopilot/results/sheeps_detections.mp4\"\nconfidence_threshold  = 0.5\n\n# Load labels\nwith open(label_path, 'r') as f:\n    labels = [line.strip() for line in f.readlines()]\n\n# Load Interpreter with EdgeTPU\ntry:\n    interpreter = Interpreter(model_path=model_path,\n                              experimental_delegates=[load_delegate('libedgetpu.so.1.0')])\nexcept Exception as e:\n    print(f\"Failed to load libedgetpu.so.1.0: {e}\")\n    try:\n        interpreter = Interpreter(model_path=model_path,\n                                  experimental_delegates=[load_delegate('/usr/lib/aarch64-linux-gnu/libedgetpu.so.1.0')])\n    except Exception as e:\n        print(f\"Failed to load /usr/lib/aarch64-linux-gnu/libedgetpu.so.1.0: {e}\")\n        raise\n\ninterpreter.allocate_tensors()\n\n# Get Model Details\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\n\nprint(\"Input details:\", input_details)\nprint(\"Output details:\", output_details)\n\nfloating_model = (input_details[0]['dtype'] == np.float32)\n\n# Phase 2: Input Acquisition & Preprocessing Loop\ncap = cv2.VideoCapture(input_path)\nif not cap.isOpened():\n    raise IOError(\"Cannot open video file\")\n\nframe_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\nframe_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\nfps = cap.get(cv2.CAP_PROP_FPS)\n\nout = cv2.VideoWriter(output_path, cv2.VideoWriter_fourcc(*'mp4v'), fps, (frame_width, frame_height))\n\nwhile True:\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    # Preprocess Data\n    input_data = cv2.resize(frame, (input_details[0]['shape'][1], input_details[0]['shape'][2]))\n    input_data = np.expand_dims(input_data, axis=0)\n\n    if floating_model:\n        input_data = (np.float32(input_data) - 127.5) / 127.5\n\n    # Phase 3: Inference\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n    interpreter.invoke()\n\n    # Phase 4: Output Interpretation & Handling Loop\n    output_data = interpreter.get_tensor(output_details[0]['index'])\n    \n    if len(output_details) > 2:\n        detection_boxes = interpreter.get_tensor(output_details[1]['index'])[0]\n        detection_classes = interpreter.get_tensor(output_details[2]['index'])[0].astype(int)\n        detection_scores = interpreter.get_tensor(output_details[3]['index'])[0]\n\n        # Assuming a fixed number of detections, filter based on confidence threshold\n        for i in range(len(detection_scores)):\n            if detection_scores[i] > confidence_threshold:\n                box = detection_boxes[i]\n                class_id = detection_classes[i]\n                score = detection_scores[i]\n\n                # Scale and clip bounding boxes\n                ymin, xmin, ymax, xmax = box\n                (left, right, top, bottom) = (xmin * frame_width, xmax * frame_width,\n                                              ymin * frame_height, ymax * frame_height)\n\n                cv2.rectangle(frame, (int(left), int(top)), (int(right), int(bottom)), (0, 255, 0), 2)\n                label = f'{labels[class_id]}: {score:.2f}'\n                cv2.putText(frame, label, (int(left), int(top) - 10),\n                            cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n\n    # Write the frame with detections to the output video\n    out.write(frame)\n\n# Phase 5: Cleanup\ncap.release()\nout.release()\ncv2.destroyAllWindows()",
        "last_error": "Input details: [{'name': 'normalized_input_image_tensor', 'index': 175, 'shape': array([  1, 300, 300,   3], dtype=int32), 'shape_signature': array([  1, 300, 300,   3], dtype=int32), 'dtype': <class 'numpy.uint8'>, 'quantization': (0.0078125, 128), 'quantization_parameters': {'scales': array([0.0078125], dtype=float32), 'zero_points': array([128], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}]\nOutput details: [{'name': 'TFLite_Detection_PostProcess', 'index': 167, 'shape': array([ 1, 10,  4], dtype=int32), 'shape_signature': array([ 1, 10,  4], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'TFLite_Detection_PostProcess:1', 'index': 168, 'shape': array([ 1, 10], dtype=int32), 'shape_signature': array([ 1, 10], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'TFLite_Detection_PostProcess:2', 'index': 169, 'shape': array([ 1, 10], dtype=int32), 'shape_signature': array([ 1, 10], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'TFLite_Detection_PostProcess:3', 'index': 170, 'shape': array([1], dtype=int32), 'shape_signature': array([1], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}]\nTraceback (most recent call last):\n  File \"script_9b7737f3_1754271472.py\", line 76, in <module>\n    for i in range(len(detection_scores)):\nTypeError: object of type 'numpy.float32' has no len()"
      },
      "session_id": "qwen2.5-coder:32b_c8a6_tpusg_batch",
      "metadata": {
        "num_run": 9
      },
      "tags": [
        "benchmark",
        "qwen2.5-coder:32b",
        "tpu_sketch_generator"
      ],
      "latency": 194.065,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-04-34-46-278007_chatcmpl-1b721192-ea86-409a-ba00-6b929cff5b56",
          "traceId": "c12fbe3a",
          "type": "GENERATION",
          "name": "c12f_tpusg_gen_attempt#1",
          "startTime": "2025-08-04T01:34:46.278000+00:00",
          "endTime": "2025-08-04T01:35:11.833000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 25555.0,
          "environment": "default",
          "promptTokens": 1833,
          "totalTokens": 2709,
          "costDetails": {},
          "completionTokens": 876,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-04-35-20-249428_chatcmpl-09c8838f-a832-41f8-a964-8a38c96a5c29",
          "traceId": "c12fbe3a",
          "type": "GENERATION",
          "name": "c12f_tpusg_gen_attempt#2",
          "startTime": "2025-08-04T01:35:20.249000+00:00",
          "endTime": "2025-08-04T01:35:52.793000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 32544.0,
          "environment": "default",
          "promptTokens": 2048,
          "totalTokens": 3187,
          "costDetails": {},
          "completionTokens": 1139,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-04-36-00-846449_chatcmpl-4f2dabdd-0b7f-4779-b3d1-f77d1ea05547",
          "traceId": "c12fbe3a",
          "type": "GENERATION",
          "name": "c12f_tpusg_gen_attempt#3",
          "startTime": "2025-08-04T01:36:00.846000+00:00",
          "endTime": "2025-08-04T01:36:31.010000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 30164.0,
          "environment": "default",
          "promptTokens": 2048,
          "totalTokens": 3094,
          "costDetails": {},
          "completionTokens": 1046,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-04-36-39-069957_chatcmpl-2c2a9ef7-1db1-4df2-91d6-d55874075b27",
          "traceId": "c12fbe3a",
          "type": "GENERATION",
          "name": "c12f_tpusg_gen_attempt#4",
          "startTime": "2025-08-04T01:36:39.069000+00:00",
          "endTime": "2025-08-04T01:37:11.170000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 32101.0,
          "environment": "default",
          "promptTokens": 2048,
          "totalTokens": 3166,
          "costDetails": {},
          "completionTokens": 1118,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-04-37-19-499635_chatcmpl-9558af89-c5ef-408e-9eec-9755a09edfad",
          "traceId": "c12fbe3a",
          "type": "GENERATION",
          "name": "c12f_tpusg_gen_attempt#5",
          "startTime": "2025-08-04T01:37:19.499000+00:00",
          "endTime": "2025-08-04T01:37:52.231000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 32732.0,
          "environment": "default",
          "promptTokens": 2048,
          "totalTokens": 3194,
          "costDetails": {},
          "completionTokens": 1146,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "cf85fa60-bcb2-457c-ba39-384ffd8c9b87",
          "traceId": "c12fbe3a",
          "type": "SPAN",
          "name": "error_c1_tpusg_failure_signal_tpu_sketch_generator",
          "startTime": "2025-08-04T01:38:00.343000+00:00",
          "level": "ERROR",
          "statusMessage": "Failed. Last error: Input details: [{'name': 'normalized_input_image_tensor', 'index': 175, 'shape': array([  1, 300, 300,   3], dtype=int32), 'shape_signature': array([  1, 300, 300,   3], dtype=int32), 'dtype': <class 'numpy.uint8'>, 'quantization': (0.0078125, 128), 'quantization_parameters': {'scales': array([0.0078125], dtype=float32), 'zero_points': array([128], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}]\nOutput details: [{'name': 'TFLite_Detection_PostProcess', 'index': 167, 'shape': array([ 1, 10,  4], dtype=int32), 'shape_signature': array([ 1, 10,  4], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'TFLite_Detection_PostProcess:1', 'index': 168, 'shape': array([ 1, 10], dtype=int32), 'shape_signature': array([ 1, 10], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'TFLite_Detection_PostProcess:2', 'index': 169, 'shape': array([ 1, 10], dtype=int32), 'shape_signature': array([ 1, 10], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'TFLite_Detection_PostProcess:3', 'index': 170, 'shape': array([1], dtype=int32), 'shape_signature': array([1], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}]\nTraceback (most recent call last):\n  File \"script_9b7737f3_1754271472.py\", line 76, in <module>\n    for i in range(len(detection_scores)):\nTypeError: object of type 'numpy.float32' has no len()",
          "calculatedTotalCost": 0.0,
          "environment": "default",
          "promptTokens": 0,
          "totalTokens": 0,
          "costDetails": {},
          "completionTokens": 0,
          "endTime": null,
          "model": null,
          "modelParameters": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null,
          "latency": null
        }
      ],
      "createdAt": "2025-08-04T01:34:46.797Z",
      "environment": "default",
      "updatedAt": "2025-08-04T01:38:05.484Z"
    },
    {
      "id": "00b800ec",
      "timestamp": "2025-08-04T01:31:27.732000+00:00",
      "name": "00b8_tpu_sketch_generator",
      "input": null,
      "output": {
        "status": "failed",
        "last_code": "import numpy as np\nfrom tflite_runtime.interpreter import Interpreter, load_delegate\nimport cv2\n\n# Phase 1: Setup\nmodel_path  = \"/home/mendel/tinyml_autopilot/models/edgetpu_detect.tflite\"\nlabel_path  = \"/home/mendel/tinyml_autopilot/models/labelmap.txt\"\ninput_path  = \"/home/mendel/tinyml_autopilot/data//sheeps.mp4\"\noutput_path  = \"/home/mendel/tinyml_autopilot/results/sheeps_detections.mp4\"\nconfidence_threshold  = 0.5\n\n# Load labels\nwith open(label_path, 'r') as f:\n    labels = [line.strip() for line in f.readlines()]\n\n# Load Interpreter with EdgeTPU\ntry:\n    interpreter = Interpreter(model_path=model_path,\n                              experimental_delegates=[load_delegate('libedgetpu.so.1.0')])\nexcept Exception as e:\n    print(f\"Failed to load libedgetpu.so.1.0: {e}\")\n    try:\n        interpreter = Interpreter(model_path=model_path,\n                                  experimental_delegates=[load_delegate('/usr/lib/aarch64-linux-gnu/libedgetpu.so.1.0')])\n    except Exception as e:\n        print(f\"Failed to load /usr/lib/aarch64-linux-gnu/libedgetpu.so.1.0: {e}\")\n        raise\n\ninterpreter.allocate_tensors()\n\n# Get Model Details\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\n\nfloating_model = (input_details[0]['dtype'] == np.float32)\n\n# Phase 2: Input Acquisition & Preprocessing Loop\ncap = cv2.VideoCapture(input_path)\nif not cap.isOpened():\n    raise IOError(\"Cannot open video file\")\n\nframe_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\nframe_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\nfps = cap.get(cv2.CAP_PROP_FPS)\n\nout = cv2.VideoWriter(output_path, cv2.VideoWriter_fourcc(*'mp4v'), fps, (frame_width, frame_height))\n\nwhile True:\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    # Preprocess Data\n    input_data = cv2.resize(frame, (input_details[0]['shape'][1], input_details[0]['shape'][2]))\n    input_data = np.expand_dims(input_data, axis=0)\n\n    if floating_model:\n        input_data = (np.float32(input_data) - 127.5) / 127.5\n\n    # Phase 3: Inference\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n    interpreter.invoke()\n\n    # Phase 4: Output Interpretation & Handling Loop\n    output_data = interpreter.get_tensor(output_details[0]['index'])\n    num_detections = int(interpreter.get_tensor(output_details[1]['index']))  # Access the scalar value directly\n    detection_boxes = interpreter.get_tensor(output_details[2]['index'])[0]\n    detection_classes = interpreter.get_tensor(output_details[3]['index'])[0].astype(int)\n    detection_scores = interpreter.get_tensor(output_details[4]['index'])[0]\n\n    for i in range(num_detections):\n        if detection_scores[i] > confidence_threshold:\n            box = detection_boxes[i]\n            class_id = detection_classes[i]\n            score = detection_scores[i]\n\n            # Scale the bounding box coordinates\n            ymin, xmin, ymax, xmax = box\n            (left, right, top, bottom) = (xmin * frame_width, xmax * frame_width,\n                                          ymin * frame_height, ymax * frame_height)\n\n            # Draw the bounding box and label on the frame\n            cv2.rectangle(frame, (int(left), int(top)), (int(right), int(bottom)), (0, 255, 0), 2)\n            label = f'{labels[class_id]}: {score:.2f}'\n            cv2.putText(frame, label, (int(left), int(top) - 10),\n                        cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n\n    # Write the frame to the output video\n    out.write(frame)\n\n# Phase 5: Cleanup\ncap.release()\nout.release()\ncv2.destroyAllWindows()",
        "last_error": "Traceback (most recent call last):\n  File \"script_3d33c886_1754271271.py\", line 66, in <module>\n    num_detections = int(interpreter.get_tensor(output_details[1]['index']))  # Access the scalar value directly\nTypeError: only size-1 arrays can be converted to Python scalars"
      },
      "session_id": "qwen2.5-coder:32b_c8a6_tpusg_batch",
      "metadata": {
        "num_run": 8
      },
      "tags": [
        "benchmark",
        "qwen2.5-coder:32b",
        "tpu_sketch_generator"
      ],
      "latency": 192.302,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-04-31-27-733866_chatcmpl-1da676fb-34f3-4fc8-b9f7-1c9e1c849d80",
          "traceId": "00b800ec",
          "type": "GENERATION",
          "name": "00b8_tpusg_gen_attempt#1",
          "startTime": "2025-08-04T01:31:27.733000+00:00",
          "endTime": "2025-08-04T01:31:53.676000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 25943.0,
          "environment": "default",
          "promptTokens": 1833,
          "totalTokens": 2726,
          "costDetails": {},
          "completionTokens": 893,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-04-32-01-780546_chatcmpl-87f7dff5-77cc-46d0-ba59-75034d12eeaf",
          "traceId": "00b800ec",
          "type": "GENERATION",
          "name": "00b8_tpusg_gen_attempt#2",
          "startTime": "2025-08-04T01:32:01.780000+00:00",
          "endTime": "2025-08-04T01:32:33.451000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 31671.0,
          "environment": "default",
          "promptTokens": 2048,
          "totalTokens": 3150,
          "costDetails": {},
          "completionTokens": 1102,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-04-32-41-731501_chatcmpl-430f6c1d-ae82-4fa5-8765-9e92a7e54a26",
          "traceId": "00b800ec",
          "type": "GENERATION",
          "name": "00b8_tpusg_gen_attempt#3",
          "startTime": "2025-08-04T01:32:41.731000+00:00",
          "endTime": "2025-08-04T01:33:13.959000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 32228.0,
          "environment": "default",
          "promptTokens": 2048,
          "totalTokens": 3169,
          "costDetails": {},
          "completionTokens": 1121,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-04-33-22-372279_chatcmpl-58457450-992e-40ab-b987-8b0b268d7e4d",
          "traceId": "00b800ec",
          "type": "GENERATION",
          "name": "00b8_tpusg_gen_attempt#4",
          "startTime": "2025-08-04T01:33:22.372000+00:00",
          "endTime": "2025-08-04T01:33:52.522000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 30150.0,
          "environment": "default",
          "promptTokens": 2048,
          "totalTokens": 3095,
          "costDetails": {},
          "completionTokens": 1047,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-04-34-00-683626_chatcmpl-841d403b-f42b-40e2-b261-26898a0e5704",
          "traceId": "00b800ec",
          "type": "GENERATION",
          "name": "00b8_tpusg_gen_attempt#5",
          "startTime": "2025-08-04T01:34:00.683000+00:00",
          "endTime": "2025-08-04T01:34:31.935000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 31252.0,
          "environment": "default",
          "promptTokens": 2048,
          "totalTokens": 3132,
          "costDetails": {},
          "completionTokens": 1084,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "43920f41-3dd0-455d-8914-2d385ec8eb2b",
          "traceId": "00b800ec",
          "type": "SPAN",
          "name": "error_00_tpusg_failure_signal_tpu_sketch_generator",
          "startTime": "2025-08-04T01:34:40.035000+00:00",
          "level": "ERROR",
          "statusMessage": "Failed. Last error: Traceback (most recent call last):\n  File \"script_3d33c886_1754271271.py\", line 66, in <module>\n    num_detections = int(interpreter.get_tensor(output_details[1]['index']))  # Access the scalar value directly\nTypeError: only size-1 arrays can be converted to Python scalars",
          "calculatedTotalCost": 0.0,
          "environment": "default",
          "promptTokens": 0,
          "totalTokens": 0,
          "costDetails": {},
          "completionTokens": 0,
          "endTime": null,
          "model": null,
          "modelParameters": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null,
          "latency": null
        }
      ],
      "createdAt": "2025-08-04T01:31:28.253Z",
      "environment": "default",
      "updatedAt": "2025-08-04T01:34:45.443Z"
    },
    {
      "id": "fdca041e",
      "timestamp": "2025-08-04T01:28:09.345000+00:00",
      "name": "fdca_tpu_sketch_generator",
      "input": null,
      "output": {
        "status": "failed",
        "last_code": "import numpy as np\nfrom tflite_runtime.interpreter import Interpreter, load_delegate\nimport cv2\n\n# Phase 1: Setup\nmodel_path  = \"/home/mendel/tinyml_autopilot/models/edgetpu_detect.tflite\"\nlabel_path  = \"/home/mendel/tinyml_autopilot/models/labelmap.txt\"\ninput_path  = \"/home/mendel/tinyml_autopilot/data//sheeps.mp4\"\noutput_path  = \"/home/mendel/tinyml_autopilot/results/sheeps_detections.mp4\"\nconfidence_threshold  = 0.5\n\n# Load labels\nwith open(label_path, 'r') as f:\n    labels = [line.strip() for line in f.readlines()]\n\n# Load Interpreter with EdgeTPU\ntry:\n    interpreter = Interpreter(model_path=model_path,\n                              experimental_delegates=[load_delegate('libedgetpu.so.1.0')])\nexcept Exception as e:\n    print(f\"Failed to load libedgetpu.so.1.0: {e}\")\n    try:\n        interpreter = Interpreter(model_path=model_path,\n                                  experimental_delegates=[load_delegate('/usr/lib/aarch64-linux-gnu/libedgetpu.so.1.0')])\n    except Exception as e:\n        print(f\"Failed to load /usr/lib/aarch64-linux-gnu/libedgetpu.so.1.0: {e}\")\n        raise\n\ninterpreter.allocate_tensors()\n\n# Get Model Details\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\n\nfloating_model = (input_details[0]['dtype'] == np.float32)\n\n# Phase 2: Input Acquisition & Preprocessing Loop\ncap = cv2.VideoCapture(input_path)\nif not cap.isOpened():\n    raise IOError(\"Cannot open video file\")\n\nframe_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\nframe_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\nfps = cap.get(cv2.CAP_PROP_FPS)\n\nout = cv2.VideoWriter(output_path, cv2.VideoWriter_fourcc(*'mp4v'), fps, (frame_width, frame_height))\n\nwhile True:\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    # Preprocess Data\n    input_data = cv2.resize(frame, (input_details[0]['shape'][1], input_details[0]['shape'][2]))\n    input_data = np.expand_dims(input_data, axis=0)\n\n    if floating_model:\n        input_data = (np.float32(input_data) - 127.5) / 127.5\n\n    # Phase 3: Inference\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n    interpreter.invoke()\n\n    # Phase 4: Output Interpretation & Handling Loop\n    output_data = interpreter.get_tensor(output_details[0]['index'])\n    num_detections = interpreter.get_tensor(output_details[1]['index']).item()  # Correctly extract the scalar value\n    detection_boxes = interpreter.get_tensor(output_details[2]['index'])[0]\n    detection_classes = interpreter.get_tensor(output_details[3]['index'])[0].astype(int)\n    detection_scores = interpreter.get_tensor(output_details[4]['index'])[0]\n\n    for i in range(num_detections):\n        if detection_scores[i] > confidence_threshold:\n            box = detection_boxes[i]\n            class_id = detection_classes[i]\n            score = detection_scores[i]\n\n            # Scale and clip bounding boxes\n            ymin, xmin, ymax, xmax = box\n            (left, right, top, bottom) = (xmin * frame_width, xmax * frame_width,\n                                          ymin * frame_height, ymax * frame_height)\n\n            cv2.rectangle(frame, (int(left), int(top)), (int(right), int(bottom)), (0, 255, 0), 2)\n            label = f'{labels[class_id]}: {score:.2f}'\n            cv2.putText(frame, label, (int(left), int(top) - 10),\n                        cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n\n    # Write the frame to the output video\n    out.write(frame)\n\n# Release resources\ncap.release()\nout.release()\ncv2.destroyAllWindows()",
        "last_error": "Traceback (most recent call last):\n  File \"script_0fc93243_1754271072.py\", line 66, in <module>\n    num_detections = interpreter.get_tensor(output_details[1]['index']).item()  # Correctly extract the scalar value\nValueError: can only convert an array of size 1 to a Python scalar"
      },
      "session_id": "qwen2.5-coder:32b_c8a6_tpusg_batch",
      "metadata": {
        "num_run": 7
      },
      "tags": [
        "benchmark",
        "qwen2.5-coder:32b",
        "tpu_sketch_generator"
      ],
      "latency": 191.996,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-04-28-09-346926_chatcmpl-9b49acc5-e1c6-43dd-8fc3-94b2bb9d9afd",
          "traceId": "fdca041e",
          "type": "GENERATION",
          "name": "fdca_tpusg_gen_attempt#1",
          "startTime": "2025-08-04T01:28:09.346000+00:00",
          "endTime": "2025-08-04T01:28:34.798000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 25452.0,
          "environment": "default",
          "promptTokens": 1833,
          "totalTokens": 2709,
          "costDetails": {},
          "completionTokens": 876,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-04-28-42-967159_chatcmpl-b1955572-f339-4f13-a351-61d2b2f42b1a",
          "traceId": "fdca041e",
          "type": "GENERATION",
          "name": "fdca_tpusg_gen_attempt#2",
          "startTime": "2025-08-04T01:28:42.967000+00:00",
          "endTime": "2025-08-04T01:29:15.595000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 32628.0,
          "environment": "default",
          "promptTokens": 2048,
          "totalTokens": 3190,
          "costDetails": {},
          "completionTokens": 1142,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-04-29-23-816104_chatcmpl-a03e675d-23a6-459a-882b-285dbb6dc046",
          "traceId": "fdca041e",
          "type": "GENERATION",
          "name": "fdca_tpusg_gen_attempt#3",
          "startTime": "2025-08-04T01:29:23.816000+00:00",
          "endTime": "2025-08-04T01:29:54.086000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 30270.0,
          "environment": "default",
          "promptTokens": 2048,
          "totalTokens": 3100,
          "costDetails": {},
          "completionTokens": 1052,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-04-30-02-183029_chatcmpl-76cfec5c-9327-4b67-956d-c2714bcd629e",
          "traceId": "fdca041e",
          "type": "GENERATION",
          "name": "fdca_tpusg_gen_attempt#4",
          "startTime": "2025-08-04T01:30:02.183000+00:00",
          "endTime": "2025-08-04T01:30:33.182000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 30999.0,
          "environment": "default",
          "promptTokens": 2048,
          "totalTokens": 3127,
          "costDetails": {},
          "completionTokens": 1079,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-04-30-41-327237_chatcmpl-560a2126-b731-4a59-a813-51435e544d57",
          "traceId": "fdca041e",
          "type": "GENERATION",
          "name": "fdca_tpusg_gen_attempt#5",
          "startTime": "2025-08-04T01:30:41.327000+00:00",
          "endTime": "2025-08-04T01:31:12.912000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 31585.0,
          "environment": "default",
          "promptTokens": 2048,
          "totalTokens": 3149,
          "costDetails": {},
          "completionTokens": 1101,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "27005ef6-bbd3-4232-b51d-508200c6ff51",
          "traceId": "fdca041e",
          "type": "SPAN",
          "name": "error_fd_tpusg_failure_signal_tpu_sketch_generator",
          "startTime": "2025-08-04T01:31:21.342000+00:00",
          "level": "ERROR",
          "statusMessage": "Failed. Last error: Traceback (most recent call last):\n  File \"script_0fc93243_1754271072.py\", line 66, in <module>\n    num_detections = interpreter.get_tensor(output_details[1]['index']).item()  # Correctly extract the scalar value\nValueError: can only convert an array of size 1 to a Python scalar",
          "calculatedTotalCost": 0.0,
          "environment": "default",
          "promptTokens": 0,
          "totalTokens": 0,
          "costDetails": {},
          "completionTokens": 0,
          "endTime": null,
          "model": null,
          "modelParameters": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null,
          "latency": null
        }
      ],
      "createdAt": "2025-08-04T01:28:09.867Z",
      "environment": "default",
      "updatedAt": "2025-08-04T01:31:26.602Z"
    },
    {
      "id": "3b1a466e",
      "timestamp": "2025-08-04T01:25:25.792000+00:00",
      "name": "3b1a_tpu_sketch_generator",
      "input": null,
      "output": {
        "status": "success",
        "sketch": "import numpy as np\nfrom tflite_runtime.interpreter import Interpreter, load_delegate\nimport cv2\n\n# Phase 1: Setup\nmodel_path  = \"/home/mendel/tinyml_autopilot/models/edgetpu_detect.tflite\"\nlabel_path  = \"/home/mendel/tinyml_autopilot/models/labelmap.txt\"\ninput_path  = \"/home/mendel/tinyml_autopilot/data//sheeps.mp4\"\noutput_path  = \"/home/mendel/tinyml_autopilot/results/sheeps_detections.mp4\"\nconfidence_threshold  = 0.5\n\n# Load labels\nwith open(label_path, 'r') as f:\n    labels = [line.strip() for line in f.readlines()]\n\n# Load Interpreter with EdgeTPU\ntry:\n    interpreter = Interpreter(model_path=model_path,\n                              experimental_delegates=[load_delegate('libedgetpu.so.1.0')])\nexcept Exception as e:\n    print(f\"Failed to load libedgetpu.so.1.0: {e}\")\n    try:\n        interpreter = Interpreter(model_path=model_path,\n                                  experimental_delegates=[load_delegate('/usr/lib/aarch64-linux-gnu/libedgetpu.so.1.0')])\n    except Exception as e:\n        print(f\"Failed to load /usr/lib/aarch64-linux-gnu/libedgetpu.so.1.0: {e}\")\n        raise\n\ninterpreter.allocate_tensors()\n\n# Get Model Details\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\n\nfloating_model = (input_details[0]['dtype'] == np.float32)\n\n# Phase 2: Input Acquisition & Preprocessing Loop\ncap = cv2.VideoCapture(input_path)\nif not cap.isOpened():\n    raise IOError(\"Cannot open video file\")\n\nframe_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\nframe_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\nfps = cap.get(cv2.CAP_PROP_FPS)\n\nout = cv2.VideoWriter(output_path, cv2.VideoWriter_fourcc(*'mp4v'), fps, (frame_width, frame_height))\n\nwhile True:\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    # Preprocess Data\n    input_data = cv2.resize(frame, (input_details[0]['shape'][1], input_details[0]['shape'][2]))\n    input_data = np.expand_dims(input_data, axis=0)\n\n    if floating_model:\n        input_data = (np.float32(input_data) - 127.5) / 127.5\n\n    # Phase 3: Inference\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n    interpreter.invoke()\n\n    # Phase 4: Output Interpretation & Handling Loop\n    detection_boxes = interpreter.get_tensor(output_details[0]['index'])[0]\n    detection_classes = interpreter.get_tensor(output_details[1]['index'])[0].astype(int)\n    detection_scores = interpreter.get_tensor(output_details[2]['index'])[0]\n\n    # Assuming the number of detections is the length of the scores array\n    num_detections = len(detection_scores)\n\n    for i in range(num_detections):\n        if detection_scores[i] > confidence_threshold:\n            box = detection_boxes[i]\n            class_id = detection_classes[i]\n            score = detection_scores[i]\n\n            # Scale and clip bounding boxes\n            ymin, xmin, ymax, xmax = box\n            (left, right, top, bottom) = (xmin * frame_width, xmax * frame_width,\n                                          ymin * frame_height, ymax * frame_height)\n\n            cv2.rectangle(frame, (int(left), int(top)), (int(right), int(bottom)), (0, 255, 0), 2)\n            label = f'{labels[class_id]}: {score:.2f}'\n            cv2.putText(frame, label, (int(left), int(top) - 10),\n                        cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n\n    # Handle Output\n    out.write(frame)\n\n# Phase 5: Cleanup\ncap.release()\nout.release()\ncv2.destroyAllWindows()"
      },
      "session_id": "qwen2.5-coder:32b_c8a6_tpusg_batch",
      "metadata": {
        "num_run": 6
      },
      "tags": [
        "benchmark",
        "qwen2.5-coder:32b",
        "tpu_sketch_generator"
      ],
      "latency": 104.846,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-04-25-25-794405_chatcmpl-9fdefaab-97e9-4536-8e92-ac7170d88005",
          "traceId": "3b1a466e",
          "type": "GENERATION",
          "name": "3b1a_tpusg_gen_attempt#1",
          "startTime": "2025-08-04T01:25:25.794000+00:00",
          "endTime": "2025-08-04T01:25:51.320000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 25526.0,
          "environment": "default",
          "promptTokens": 1833,
          "totalTokens": 2709,
          "costDetails": {},
          "completionTokens": 876,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-04-25-59-450259_chatcmpl-81892c48-56a5-40f0-9c60-388457ab142f",
          "traceId": "3b1a466e",
          "type": "GENERATION",
          "name": "3b1a_tpusg_gen_attempt#2",
          "startTime": "2025-08-04T01:25:59.450000+00:00",
          "endTime": "2025-08-04T01:26:32.003000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 32553.0,
          "environment": "default",
          "promptTokens": 2048,
          "totalTokens": 3183,
          "costDetails": {},
          "completionTokens": 1135,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-04-26-40-105781_chatcmpl-291168ab-cde8-40b1-b84f-30d1f0360feb",
          "traceId": "3b1a466e",
          "type": "GENERATION",
          "name": "3b1a_tpusg_gen_attempt#3",
          "startTime": "2025-08-04T01:26:40.105000+00:00",
          "endTime": "2025-08-04T01:27:10.640000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 30535.0,
          "environment": "default",
          "promptTokens": 2048,
          "totalTokens": 3110,
          "costDetails": {},
          "completionTokens": 1062,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        }
      ],
      "createdAt": "2025-08-04T01:25:26.315Z",
      "environment": "default",
      "updatedAt": "2025-08-04T01:28:08.561Z"
    },
    {
      "id": "540b7271",
      "timestamp": "2025-08-04T01:22:44.772000+00:00",
      "name": "540b_tpu_sketch_generator",
      "input": null,
      "output": {
        "status": "success",
        "sketch": "import numpy as np\nfrom tflite_runtime.interpreter import Interpreter, load_delegate\nimport cv2\n\n# Phase 1: Setup\nmodel_path  = \"/home/mendel/tinyml_autopilot/models/edgetpu_detect.tflite\"\nlabel_path  = \"/home/mendel/tinyml_autopilot/models/labelmap.txt\"\ninput_path  = \"/home/mendel/tinyml_autopilot/data//sheeps.mp4\"\noutput_path  = \"/home/mendel/tinyml_autopilot/results/sheeps_detections.mp4\"\nconfidence_threshold  = 0.5\n\n# Load labels\nwith open(label_path, 'r') as f:\n    labels = [line.strip() for line in f.readlines()]\n\n# Load Interpreter with EdgeTPU\ntry:\n    interpreter = Interpreter(model_path=model_path,\n                              experimental_delegates=[load_delegate('libedgetpu.so.1.0')])\nexcept Exception as e:\n    print(f\"Failed to load libedgetpu.so.1.0: {e}\")\n    try:\n        interpreter = Interpreter(model_path=model_path,\n                                  experimental_delegates=[load_delegate('/usr/lib/aarch64-linux-gnu/libedgetpu.so.1.0')])\n    except Exception as e:\n        print(f\"Failed to load /usr/lib/aarch64-linux-gnu/libedgetpu.so.1.0: {e}\")\n        raise\n\ninterpreter.allocate_tensors()\n\n# Get Model Details\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\n\nfloating_model = (input_details[0]['dtype'] == np.float32)\n\n# Print output details for debugging\nprint(\"Output Details:\")\nfor i, detail in enumerate(output_details):\n    print(f\"Output {i}: {detail}\")\n\n# Phase 2: Input Acquisition & Preprocessing Loop\ncap = cv2.VideoCapture(input_path)\nif not cap.isOpened():\n    raise IOError(\"Cannot open video file\")\n\nframe_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\nframe_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\nfps = cap.get(cv2.CAP_PROP_FPS)\n\nout = cv2.VideoWriter(output_path, cv2.VideoWriter_fourcc(*'mp4v'), fps, (frame_width, frame_height))\n\nwhile True:\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    # Preprocess Data\n    input_data = cv2.resize(frame, (input_details[0]['shape'][1], input_details[0]['shape'][2]))\n    input_data = np.expand_dims(input_data, axis=0)\n\n    if floating_model:\n        input_data = (np.float32(input_data) - 127.5) / 127.5\n\n    # Phase 3: Inference\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n    interpreter.invoke()\n\n    # Phase 4: Output Interpretation & Handling Loop\n    output_data = interpreter.get_tensor(output_details[0]['index'])\n    num_detections = np.squeeze(interpreter.get_tensor(output_details[1]['index']))  # Use np.squeeze to get a scalar value\n\n    if len(output_details) > 2:\n        detection_boxes = interpreter.get_tensor(output_details[2]['index'])[0]\n    else:\n        print(\"Detection boxes output not found.\")\n        continue\n\n    if len(output_details) > 3:\n        detection_classes = interpreter.get_tensor(output_details[3]['index'])[0].astype(int)\n    else:\n        print(\"Detection classes output not found.\")\n        continue\n\n    if len(output_details) > 4:\n        detection_scores = interpreter.get_tensor(output_details[4]['index'])[0]\n    else:\n        print(\"Detection scores output not found.\")\n        continue\n\n    for i in range(num_detections):\n        if detection_scores[i] > confidence_threshold:\n            box = detection_boxes[i]\n            class_id = detection_classes[i]\n            score = detection_scores[i]\n\n            # Scale the bounding box coordinates\n            ymin, xmin, ymax, xmax = box\n            (left, right, top, bottom) = (xmin * frame_width, xmax * frame_width,\n                                          ymin * frame_height, ymax * frame_height)\n\n            # Draw the bounding box and label on the frame\n            cv2.rectangle(frame, (int(left), int(top)), (int(right), int(bottom)), (0, 255, 0), 2)\n            label = f\"{labels[class_id]}: {score:.2f}\"\n            cv2.putText(frame, label, (int(left), int(top) - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n\n    # Write the frame to the output video\n    out.write(frame)\n\n# Release resources\ncap.release()\nout.release()\ncv2.destroyAllWindows()"
      },
      "session_id": "qwen2.5-coder:32b_c8a6_tpusg_batch",
      "metadata": {
        "num_run": 5
      },
      "tags": [
        "benchmark",
        "qwen2.5-coder:32b",
        "tpu_sketch_generator"
      ],
      "latency": 107.184,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-04-22-44-773679_chatcmpl-5eeba7f0-bad8-473d-9fd4-953b0df05e70",
          "traceId": "540b7271",
          "type": "GENERATION",
          "name": "540b_tpusg_gen_attempt#1",
          "startTime": "2025-08-04T01:22:44.773000+00:00",
          "endTime": "2025-08-04T01:23:10.672000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 25899.0,
          "environment": "default",
          "promptTokens": 1833,
          "totalTokens": 2726,
          "costDetails": {},
          "completionTokens": 893,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-04-23-18-874969_chatcmpl-e364df99-96d6-472f-8651-275d1c560930",
          "traceId": "540b7271",
          "type": "GENERATION",
          "name": "540b_tpusg_gen_attempt#2",
          "startTime": "2025-08-04T01:23:18.874000+00:00",
          "endTime": "2025-08-04T01:23:49.990000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 31116.0,
          "environment": "default",
          "promptTokens": 2048,
          "totalTokens": 3133,
          "costDetails": {},
          "completionTokens": 1085,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-04-23-58-093486_chatcmpl-a75552ba-a714-4370-a740-b7b0e664d6eb",
          "traceId": "540b7271",
          "type": "GENERATION",
          "name": "540b_tpusg_gen_attempt#3",
          "startTime": "2025-08-04T01:23:58.093000+00:00",
          "endTime": "2025-08-04T01:24:31.957000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 33864.0,
          "environment": "default",
          "promptTokens": 2048,
          "totalTokens": 3235,
          "costDetails": {},
          "completionTokens": 1187,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        }
      ],
      "createdAt": "2025-08-04T01:22:45.294Z",
      "environment": "default",
      "updatedAt": "2025-08-04T01:25:25.037Z"
    },
    {
      "id": "9a925c55",
      "timestamp": "2025-08-04T01:19:23.212000+00:00",
      "name": "9a92_tpu_sketch_generator",
      "input": null,
      "output": {
        "status": "failed",
        "last_code": "import numpy as np\nfrom tflite_runtime.interpreter import Interpreter, load_delegate\nimport cv2\n\n# Phase 1: Setup\nmodel_path  = \"/home/mendel/tinyml_autopilot/models/edgetpu_detect.tflite\"\nlabel_path  = \"/home/mendel/tinyml_autopilot/models/labelmap.txt\"\ninput_path  = \"/home/mendel/tinyml_autopilot/data//sheeps.mp4\"\noutput_path  = \"/home/mendel/tinyml_autopilot/results/sheeps_detections.mp4\"\nconfidence_threshold  = 0.5\n\n# Load labels\nwith open(label_path, 'r') as f:\n    labels = [line.strip() for line in f.readlines()]\n\n# Load Interpreter with EdgeTPU\ntry:\n    interpreter = Interpreter(model_path=model_path,\n                              experimental_delegates=[load_delegate('libedgetpu.so.1.0')])\nexcept Exception as e:\n    print(f\"Failed to load libedgetpu.so.1.0: {e}\")\n    try:\n        interpreter = Interpreter(model_path=model_path,\n                                  experimental_delegates=[load_delegate('/usr/lib/aarch64-linux-gnu/libedgetpu.so.1.0')])\n    except Exception as e:\n        print(f\"Failed to load /usr/lib/aarch64-linux-gnu/libedgetpu.so.1.0: {e}\")\n        raise\n\ninterpreter.allocate_tensors()\n\n# Get Model Details\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\n\nfloating_model = (input_details[0]['dtype'] == np.float32)\n\n# Phase 2: Input Acquisition & Preprocessing Loop\ncap = cv2.VideoCapture(input_path)\nif not cap.isOpened():\n    raise IOError(\"Cannot open video file\")\n\nframe_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\nframe_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\nfps = cap.get(cv2.CAP_PROP_FPS)\n\nout = cv2.VideoWriter(output_path, cv2.VideoWriter_fourcc(*'mp4v'), fps, (frame_width, frame_height))\n\nwhile True:\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    # Preprocess Data\n    input_data = cv2.resize(frame, (input_details[0]['shape'][1], input_details[0]['shape'][2]))\n    input_data = np.expand_dims(input_data, axis=0)\n\n    if floating_model:\n        input_data = (np.float32(input_data) - 127.5) / 127.5\n\n    # Phase 3: Inference\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n    interpreter.invoke()\n\n    # Phase 4: Output Interpretation & Handling Loop\n    output_data = interpreter.get_tensor(output_details[0]['index'])\n    \n    # Ensure num_detections is a scalar value\n    num_detections = int(interpreter.get_tensor(output_details[1]['index']))  # Corrected line\n\n    detection_boxes = interpreter.get_tensor(output_details[2]['index'])[0]\n    detection_classes = interpreter.get_tensor(output_details[3]['index'])[0].astype(int)\n    detection_scores = interpreter.get_tensor(output_details[4]['index'])[0]\n\n    for i in range(num_detections):\n        if detection_scores[i] > confidence_threshold:\n            box = detection_boxes[i]\n            class_id = detection_classes[i]\n            score = detection_scores[i]\n\n            # Scale and clip bounding boxes\n            ymin, xmin, ymax, xmax = box\n            (left, right, top, bottom) = (xmin * frame_width, xmax * frame_width,\n                                          ymin * frame_height, ymax * frame_height)\n\n            cv2.rectangle(frame, (int(left), int(top)), (int(right), int(bottom)), (0, 255, 0), 2)\n            label = f'{labels[class_id]}: {score:.2f}'\n            cv2.putText(frame, label, (int(left), int(top) - 10),\n                        cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n\n    # Handle Output\n    out.write(frame)\n\n# Phase 5: Cleanup\ncap.release()\nout.release()\ncv2.destroyAllWindows()",
        "last_error": "Traceback (most recent call last):\n  File \"script_fa1c3eaa_1754270551.py\", line 68, in <module>\n    num_detections = int(interpreter.get_tensor(output_details[1]['index']))  # Corrected line\nTypeError: only size-1 arrays can be converted to Python scalars"
      },
      "session_id": "qwen2.5-coder:32b_c8a6_tpusg_batch",
      "metadata": {
        "num_run": 4
      },
      "tags": [
        "benchmark",
        "qwen2.5-coder:32b",
        "tpu_sketch_generator"
      ],
      "latency": 195.915,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-04-19-23-215033_chatcmpl-61637eb4-6165-4940-9239-57b82063288a",
          "traceId": "9a925c55",
          "type": "GENERATION",
          "name": "9a92_tpusg_gen_attempt#1",
          "startTime": "2025-08-04T01:19:23.215000+00:00",
          "endTime": "2025-08-04T01:19:48.764000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 25549.0,
          "environment": "default",
          "promptTokens": 1833,
          "totalTokens": 2709,
          "costDetails": {},
          "completionTokens": 876,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-04-19-56-915641_chatcmpl-0beb9973-8a06-40f6-b864-26cc2b38857e",
          "traceId": "9a925c55",
          "type": "GENERATION",
          "name": "9a92_tpusg_gen_attempt#2",
          "startTime": "2025-08-04T01:19:56.915000+00:00",
          "endTime": "2025-08-04T01:20:28.638000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 31723.0,
          "environment": "default",
          "promptTokens": 2048,
          "totalTokens": 3154,
          "costDetails": {},
          "completionTokens": 1106,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-04-20-36-709478_chatcmpl-67f8586d-d0c7-4d87-9085-38938f2c825a",
          "traceId": "9a925c55",
          "type": "GENERATION",
          "name": "9a92_tpusg_gen_attempt#3",
          "startTime": "2025-08-04T01:20:36.709000+00:00",
          "endTime": "2025-08-04T01:21:11.362000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 34653.0,
          "environment": "default",
          "promptTokens": 2048,
          "totalTokens": 3268,
          "costDetails": {},
          "completionTokens": 1220,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-04-21-19-839428_chatcmpl-0add01fe-0fdb-4120-9491-ed537f717954",
          "traceId": "9a925c55",
          "type": "GENERATION",
          "name": "9a92_tpusg_gen_attempt#4",
          "startTime": "2025-08-04T01:21:19.839000+00:00",
          "endTime": "2025-08-04T01:21:52.298000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 32459.0,
          "environment": "default",
          "promptTokens": 2048,
          "totalTokens": 3181,
          "costDetails": {},
          "completionTokens": 1133,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-04-22-00-365491_chatcmpl-20fda290-232b-48d8-9c9f-195ae7005769",
          "traceId": "9a925c55",
          "type": "GENERATION",
          "name": "9a92_tpusg_gen_attempt#5",
          "startTime": "2025-08-04T01:22:00.365000+00:00",
          "endTime": "2025-08-04T01:22:31.065000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 30700.0,
          "environment": "default",
          "promptTokens": 2048,
          "totalTokens": 3117,
          "costDetails": {},
          "completionTokens": 1069,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "deea5c41-c6e7-47dd-ba50-f2c1e40ccdd5",
          "traceId": "9a925c55",
          "type": "SPAN",
          "name": "error_9a_tpusg_failure_signal_tpu_sketch_generator",
          "startTime": "2025-08-04T01:22:39.130000+00:00",
          "level": "ERROR",
          "statusMessage": "Failed. Last error: Traceback (most recent call last):\n  File \"script_fa1c3eaa_1754270551.py\", line 68, in <module>\n    num_detections = int(interpreter.get_tensor(output_details[1]['index']))  # Corrected line\nTypeError: only size-1 arrays can be converted to Python scalars",
          "calculatedTotalCost": 0.0,
          "environment": "default",
          "promptTokens": 0,
          "totalTokens": 0,
          "costDetails": {},
          "completionTokens": 0,
          "endTime": null,
          "model": null,
          "modelParameters": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null,
          "latency": null
        }
      ],
      "createdAt": "2025-08-04T01:19:23.735Z",
      "environment": "default",
      "updatedAt": "2025-08-04T01:22:44.426Z"
    },
    {
      "id": "ea340b98",
      "timestamp": "2025-08-04T01:16:02.101000+00:00",
      "name": "ea34_tpu_sketch_generator",
      "input": null,
      "output": {
        "status": "failed",
        "last_code": "import numpy as np\nfrom tflite_runtime.interpreter import Interpreter, load_delegate\n\n# Phase 1: Setup\nmodel_path  = \"/home/mendel/tinyml_autopilot/models/edgetpu_detect.tflite\"\nlabel_path  = \"/home/mendel/tinyml_autopilot/models/labelmap.txt\"\ninput_path  = \"/home/mendel/tinyml_autopilot/data//sheeps.mp4\"\noutput_path  = \"/home/mendel/tinyml_autopilot/results/sheeps_detections.mp4\"\nconfidence_threshold  = 0.5\n\n# Load labels\nwith open(label_path, 'r') as f:\n    labels = [line.strip() for line in f.readlines()]\n\n# Load Interpreter with EdgeTPU\ntry:\n    interpreter = Interpreter(model_path=model_path,\n                              experimental_delegates=[load_delegate('libedgetpu.so.1.0')])\nexcept Exception as e:\n    print(f\"Failed to load libedgetpu.so.1.0: {e}\")\n    try:\n        interpreter = Interpreter(model_path=model_path,\n                                  experimental_delegates=[load_delegate('/usr/lib/aarch64-linux-gnu/libedgetpu.so.1.0')])\n    except Exception as e:\n        print(f\"Failed to load /usr/lib/aarch64-linux-gnu/libedgetpu.so.1.0: {e}\")\n        raise\n\ninterpreter.allocate_tensors()\n\n# Get Model Details\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\n\nfloating_model = (input_details[0]['dtype'] == np.float32)\n\n# Phase 2: Input Acquisition & Preprocessing Loop\nimport cv2\n\ncap = cv2.VideoCapture(input_path)\nif not cap.isOpened():\n    raise IOError(\"Cannot open video file\")\n\nframe_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\nframe_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\nfps = cap.get(cv2.CAP_PROP_FPS)\n\nout = cv2.VideoWriter(output_path, cv2.VideoWriter_fourcc(*'mp4v'), fps, (frame_width, frame_height))\n\nwhile True:\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    # Preprocess Data\n    input_data = cv2.resize(frame, (input_details[0]['shape'][1], input_details[0]['shape'][2]))\n    input_data = np.expand_dims(input_data, axis=0)\n\n    if floating_model:\n        input_data = (np.float32(input_data) - 127.5) / 127.5\n\n    # Phase 3: Inference\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n    interpreter.invoke()\n\n    # Phase 4: Output Interpretation & Handling Loop\n    output_data = interpreter.get_tensor(output_details[0]['index'])\n    num_detections = int(interpreter.get_tensor(output_details[1]['index'])[0])  # Access the scalar value directly from the array\n    detection_boxes = interpreter.get_tensor(output_details[2]['index'])[0]\n    detection_classes = interpreter.get_tensor(output_details[3]['index'])[0].astype(int)\n    detection_scores = interpreter.get_tensor(output_details[4]['index'])[0]\n\n    for i in range(num_detections):\n        if detection_scores[i] > confidence_threshold:\n            box = detection_boxes[i]\n            class_id = detection_classes[i]\n            score = detection_scores[i]\n\n            # Scale and clip bounding boxes\n            ymin, xmin, ymax, xmax = box\n            (left, right, top, bottom) = (xmin * frame_width, xmax * frame_width,\n                                          ymin * frame_height, ymax * frame_height)\n\n            cv2.rectangle(frame, (int(left), int(top)), (int(right), int(bottom)), (0, 255, 0), 2)\n            label = f'{labels[class_id]}: {score:.2f}'\n            cv2.putText(frame, label, (int(left), int(top) - 10),\n                        cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n\n    # Handle Output\n    out.write(frame)\n\n# Phase 5: Cleanup\ncap.release()\nout.release()\ncv2.destroyAllWindows()",
        "last_error": "Traceback (most recent call last):\n  File \"script_7f252661_1754270349.py\", line 67, in <module>\n    num_detections = int(interpreter.get_tensor(output_details[1]['index'])[0])  # Access the scalar value directly from the array\nTypeError: only size-1 arrays can be converted to Python scalars"
      },
      "session_id": "qwen2.5-coder:32b_c8a6_tpusg_batch",
      "metadata": {
        "num_run": 3
      },
      "tags": [
        "benchmark",
        "qwen2.5-coder:32b",
        "tpu_sketch_generator"
      ],
      "latency": 195.318,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-04-16-02-102634_chatcmpl-5b6babfa-024d-4424-bb9c-93200199a963",
          "traceId": "ea340b98",
          "type": "GENERATION",
          "name": "ea34_tpusg_gen_attempt#1",
          "startTime": "2025-08-04T01:16:02.102000+00:00",
          "endTime": "2025-08-04T01:16:27.538000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 25436.0,
          "environment": "default",
          "promptTokens": 1833,
          "totalTokens": 2709,
          "costDetails": {},
          "completionTokens": 876,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-04-16-35-661481_chatcmpl-49379187-9b52-48d9-9197-7e19bafc935c",
          "traceId": "ea340b98",
          "type": "GENERATION",
          "name": "ea34_tpusg_gen_attempt#2",
          "startTime": "2025-08-04T01:16:35.661000+00:00",
          "endTime": "2025-08-04T01:17:07.949000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 32288.0,
          "environment": "default",
          "promptTokens": 2048,
          "totalTokens": 3172,
          "costDetails": {},
          "completionTokens": 1124,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-04-17-16-158581_chatcmpl-d1c40a13-80e6-42db-8f1d-15e89294b0e1",
          "traceId": "ea340b98",
          "type": "GENERATION",
          "name": "ea34_tpusg_gen_attempt#3",
          "startTime": "2025-08-04T01:17:16.158000+00:00",
          "endTime": "2025-08-04T01:17:48.780000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 32622.0,
          "environment": "default",
          "promptTokens": 2048,
          "totalTokens": 3188,
          "costDetails": {},
          "completionTokens": 1140,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-04-17-56-902763_chatcmpl-09816634-e8a5-4262-af83-987e24dd0e9e",
          "traceId": "ea340b98",
          "type": "GENERATION",
          "name": "ea34_tpusg_gen_attempt#4",
          "startTime": "2025-08-04T01:17:56.902000+00:00",
          "endTime": "2025-08-04T01:18:29.137000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 32235.0,
          "environment": "default",
          "promptTokens": 2048,
          "totalTokens": 3176,
          "costDetails": {},
          "completionTokens": 1128,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-04-18-37-426595_chatcmpl-9a58fce4-8793-4d84-96ae-275d26d412f7",
          "traceId": "ea340b98",
          "type": "GENERATION",
          "name": "ea34_tpusg_gen_attempt#5",
          "startTime": "2025-08-04T01:18:37.426000+00:00",
          "endTime": "2025-08-04T01:19:09.284000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 31858.0,
          "environment": "default",
          "promptTokens": 2048,
          "totalTokens": 3156,
          "costDetails": {},
          "completionTokens": 1108,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "21e67735-2897-46fd-8edb-4225a63e8899",
          "traceId": "ea340b98",
          "type": "SPAN",
          "name": "error_ea_tpusg_failure_signal_tpu_sketch_generator",
          "startTime": "2025-08-04T01:19:17.420000+00:00",
          "level": "ERROR",
          "statusMessage": "Failed. Last error: Traceback (most recent call last):\n  File \"script_7f252661_1754270349.py\", line 67, in <module>\n    num_detections = int(interpreter.get_tensor(output_details[1]['index'])[0])  # Access the scalar value directly from the array\nTypeError: only size-1 arrays can be converted to Python scalars",
          "calculatedTotalCost": 0.0,
          "environment": "default",
          "promptTokens": 0,
          "totalTokens": 0,
          "costDetails": {},
          "completionTokens": 0,
          "endTime": null,
          "model": null,
          "modelParameters": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null,
          "latency": null
        }
      ],
      "createdAt": "2025-08-04T01:16:02.623Z",
      "environment": "default",
      "updatedAt": "2025-08-04T01:19:22.878Z"
    },
    {
      "id": "cacc6bb9",
      "timestamp": "2025-08-04T01:12:46.565000+00:00",
      "name": "cacc_tpu_sketch_generator",
      "input": null,
      "output": {
        "status": "failed",
        "last_code": "import numpy as np\nfrom tflite_runtime.interpreter import Interpreter, load_delegate\nimport cv2\n\n# Phase 1: Setup\nmodel_path  = \"/home/mendel/tinyml_autopilot/models/edgetpu_detect.tflite\"\nlabel_path  = \"/home/mendel/tinyml_autopilot/models/labelmap.txt\"\ninput_path  = \"/home/mendel/tinyml_autopilot/data//sheeps.mp4\"\noutput_path  = \"/home/mendel/tinyml_autopilot/results/sheeps_detections.mp4\"\nconfidence_threshold  = 0.5\n\n# Load labels\nwith open(label_path, 'r') as f:\n    labels = [line.strip() for line in f.readlines()]\n\n# Load Interpreter with EdgeTPU\ntry:\n    interpreter = Interpreter(model_path=model_path,\n                              experimental_delegates=[load_delegate('libedgetpu.so.1.0')])\nexcept Exception as e:\n    print(f\"Failed to load libedgetpu.so.1.0: {e}\")\n    try:\n        interpreter = Interpreter(model_path=model_path,\n                                  experimental_delegates=[load_delegate('/usr/lib/aarch64-linux-gnu/libedgetpu.so.1.0')])\n    except Exception as e:\n        print(f\"Failed to load /usr/lib/aarch64-linux-gnu/libedgetpu.so.1.0: {e}\")\n        raise\n\ninterpreter.allocate_tensors()\n\n# Get Model Details\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\n\nfloating_model = (input_details[0]['dtype'] == np.float32)\n\n# Phase 2: Input Acquisition & Preprocessing Loop\ncap = cv2.VideoCapture(input_path)\nif not cap.isOpened():\n    raise IOError(\"Cannot open video file\")\n\nframe_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\nframe_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\nfps = cap.get(cv2.CAP_PROP_FPS)\n\nout = cv2.VideoWriter(output_path, cv2.VideoWriter_fourcc(*'mp4v'), fps, (frame_width, frame_height))\n\nwhile True:\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    # Preprocess Data\n    input_data = cv2.resize(frame, (input_details[0]['shape'][1], input_details[0]['shape'][2]))\n    input_data = np.expand_dims(input_data, axis=0)\n\n    if floating_model:\n        input_data = (np.float32(input_data) - 127.5) / 127.5\n\n    # Phase 3: Inference\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n    interpreter.invoke()\n\n    # Phase 4: Output Interpretation & Handling Loop\n    output_data = interpreter.get_tensor(output_details[0]['index'])\n    num_detections = int(interpreter.get_tensor(output_details[1]['index']))  # Correctly extract the scalar value\n    detection_boxes = interpreter.get_tensor(output_details[2]['index'])[0]\n    detection_classes = interpreter.get_tensor(output_details[3]['index'])[0].astype(int)\n    detection_scores = interpreter.get_tensor(output_details[4]['index'])[0]\n\n    for i in range(num_detections):\n        if detection_scores[i] > confidence_threshold:\n            box = detection_boxes[i]\n            class_id = detection_classes[i]\n            score = detection_scores[i]\n\n            # Scale and clip bounding boxes\n            ymin, xmin, ymax, xmax = box\n            (left, right, top, bottom) = (xmin * frame_width, xmax * frame_width,\n                                          ymin * frame_height, ymax * frame_height)\n\n            cv2.rectangle(frame, (int(left), int(top)), (int(right), int(bottom)), (0, 255, 0), 2)\n            label = f'{labels[class_id]}: {score:.2f}'\n            cv2.putText(frame, label, (int(left), int(top) - 10),\n                        cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n\n    # Write the frame to the output video\n    out.write(frame)\n\n# Phase 5: Cleanup\ncap.release()\nout.release()\ncv2.destroyAllWindows()",
        "last_error": "Traceback (most recent call last):\n  File \"script_4d73c7c2_1754270148.py\", line 66, in <module>\n    num_detections = int(interpreter.get_tensor(output_details[1]['index']))  # Correctly extract the scalar value\nTypeError: only size-1 arrays can be converted to Python scalars"
      },
      "session_id": "qwen2.5-coder:32b_c8a6_tpusg_batch",
      "metadata": {
        "num_run": 2
      },
      "tags": [
        "benchmark",
        "qwen2.5-coder:32b",
        "tpu_sketch_generator"
      ],
      "latency": 189.881,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-04-12-46-566163_chatcmpl-0316c066-baf1-40ec-8a7b-f77e88690e04",
          "traceId": "cacc6bb9",
          "type": "GENERATION",
          "name": "cacc_tpusg_gen_attempt#1",
          "startTime": "2025-08-04T01:12:46.566000+00:00",
          "endTime": "2025-08-04T01:13:11.996000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 25430.0,
          "environment": "default",
          "promptTokens": 1833,
          "totalTokens": 2709,
          "costDetails": {},
          "completionTokens": 876,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-04-13-20-335676_chatcmpl-096e790a-e961-49d8-accb-3871f0a45745",
          "traceId": "cacc6bb9",
          "type": "GENERATION",
          "name": "cacc_tpusg_gen_attempt#2",
          "startTime": "2025-08-04T01:13:20.335000+00:00",
          "endTime": "2025-08-04T01:13:52.877000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 32542.0,
          "environment": "default",
          "promptTokens": 2048,
          "totalTokens": 3187,
          "costDetails": {},
          "completionTokens": 1139,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-04-14-00-969911_chatcmpl-ee31b349-6a00-44a9-9c58-4984ce82a4b2",
          "traceId": "cacc6bb9",
          "type": "GENERATION",
          "name": "cacc_tpusg_gen_attempt#3",
          "startTime": "2025-08-04T01:14:00.969000+00:00",
          "endTime": "2025-08-04T01:14:31.662000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 30693.0,
          "environment": "default",
          "promptTokens": 2048,
          "totalTokens": 3116,
          "costDetails": {},
          "completionTokens": 1068,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-04-14-39-761607_chatcmpl-a7b9c501-a5bd-4487-9541-911d06037290",
          "traceId": "cacc6bb9",
          "type": "GENERATION",
          "name": "cacc_tpusg_gen_attempt#4",
          "startTime": "2025-08-04T01:14:39.761000+00:00",
          "endTime": "2025-08-04T01:15:10.216000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 30455.0,
          "environment": "default",
          "promptTokens": 2048,
          "totalTokens": 3107,
          "costDetails": {},
          "completionTokens": 1059,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-04-15-18-324209_chatcmpl-cb154c2d-f4e1-4a4a-b26a-6f5296656618",
          "traceId": "cacc6bb9",
          "type": "GENERATION",
          "name": "cacc_tpusg_gen_attempt#5",
          "startTime": "2025-08-04T01:15:18.324000+00:00",
          "endTime": "2025-08-04T01:15:48.344000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 30020.0,
          "environment": "default",
          "promptTokens": 2048,
          "totalTokens": 3091,
          "costDetails": {},
          "completionTokens": 1043,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "06b4c00f-5696-4f2c-b384-f0cf360f79d7",
          "traceId": "cacc6bb9",
          "type": "SPAN",
          "name": "error_ca_tpusg_failure_signal_tpu_sketch_generator",
          "startTime": "2025-08-04T01:15:56.447000+00:00",
          "level": "ERROR",
          "statusMessage": "Failed. Last error: Traceback (most recent call last):\n  File \"script_4d73c7c2_1754270148.py\", line 66, in <module>\n    num_detections = int(interpreter.get_tensor(output_details[1]['index']))  # Correctly extract the scalar value\nTypeError: only size-1 arrays can be converted to Python scalars",
          "calculatedTotalCost": 0.0,
          "environment": "default",
          "promptTokens": 0,
          "totalTokens": 0,
          "costDetails": {},
          "completionTokens": 0,
          "endTime": null,
          "model": null,
          "modelParameters": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null,
          "latency": null
        }
      ],
      "createdAt": "2025-08-04T01:12:47.090Z",
      "environment": "default",
      "updatedAt": "2025-08-04T01:16:01.827Z"
    },
    {
      "id": "e657d7a2",
      "timestamp": "2025-08-04T01:09:27.965000+00:00",
      "name": "e657_tpu_sketch_generator",
      "input": null,
      "output": {
        "status": "failed",
        "last_code": "import numpy as np\nfrom tflite_runtime.interpreter import Interpreter, load_delegate\nimport cv2\n\n# Phase 1: Setup\nmodel_path  = \"/home/mendel/tinyml_autopilot/models/edgetpu_detect.tflite\"\nlabel_path  = \"/home/mendel/tinyml_autopilot/models/labelmap.txt\"\ninput_path  = \"/home/mendel/tinyml_autopilot/data//sheeps.mp4\"\noutput_path  = \"/home/mendel/tinyml_autopilot/results/sheeps_detections.mp4\"\nconfidence_threshold  = 0.5\n\n# Load labels\nwith open(label_path, 'r') as f:\n    labels = [line.strip() for line in f.readlines()]\n\n# Load Interpreter with EdgeTPU\ntry:\n    interpreter = Interpreter(model_path=model_path,\n                              experimental_delegates=[load_delegate('libedgetpu.so.1.0')])\nexcept Exception as e:\n    print(f\"Failed to load libedgetpu.so.1.0: {e}\")\n    try:\n        interpreter = Interpreter(model_path=model_path,\n                                  experimental_delegates=[load_delegate('/usr/lib/aarch64-linux-gnu/libedgetpu.so.1.0')])\n    except Exception as e:\n        print(f\"Failed to load /usr/lib/aarch64-linux-gnu/libedgetpu.so.1.0: {e}\")\n        raise\n\ninterpreter.allocate_tensors()\n\n# Get Model Details\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\n\nfloating_model = (input_details[0]['dtype'] == np.float32)\n\n# Phase 2: Input Acquisition & Preprocessing Loop\ncap = cv2.VideoCapture(input_path)\nif not cap.isOpened():\n    raise IOError(\"Cannot open video file\")\n\nframe_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\nframe_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\nfps = cap.get(cv2.CAP_PROP_FPS)\n\nout = cv2.VideoWriter(output_path, cv2.VideoWriter_fourcc(*'mp4v'), fps, (frame_width, frame_height))\n\nwhile True:\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    # Preprocess Data\n    input_data = cv2.resize(frame, (input_details[0]['shape'][1], input_details[0]['shape'][2]))\n    input_data = np.expand_dims(input_data, axis=0)\n\n    if floating_model:\n        input_data = (np.float32(input_data) - 127.5) / 127.5\n\n    # Phase 3: Inference\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n    interpreter.invoke()\n\n    # Phase 4: Output Interpretation & Handling Loop\n    output_data = interpreter.get_tensor(output_details[0]['index'])\n    num_detections = int(interpreter.get_tensor(output_details[1]['index'])[0])  # Access the first element directly\n\n    detection_boxes = interpreter.get_tensor(output_details[2]['index'])[0]\n    detection_classes = interpreter.get_tensor(output_details[3]['index'])[0].astype(int)\n    detection_scores = interpreter.get_tensor(output_details[4]['index'])[0]\n\n    for i in range(num_detections):\n        if detection_scores[i] > confidence_threshold:\n            box = detection_boxes[i]\n            class_id = detection_classes[i]\n            score = detection_scores[i]\n\n            # Scale and clip bounding boxes\n            ymin, xmin, ymax, xmax = box\n            (left, right, top, bottom) = (xmin * frame_width, xmax * frame_width,\n                                          ymin * frame_height, ymax * frame_height)\n\n            cv2.rectangle(frame, (int(left), int(top)), (int(right), int(bottom)), (0, 255, 0), 2)\n            label = f'{labels[class_id]}: {score:.2f}'\n            cv2.putText(frame, label, (int(left), int(top) - 10),\n                        cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n\n    # Handle Output\n    out.write(frame)\n\n# Phase 5: Cleanup\ncap.release()\nout.release()\ncv2.destroyAllWindows()",
        "last_error": "Traceback (most recent call last):\n  File \"script_037414af_1754269952.py\", line 66, in <module>\n    num_detections = int(interpreter.get_tensor(output_details[1]['index'])[0])  # Access the first element directly\nTypeError: only size-1 arrays can be converted to Python scalars"
      },
      "session_id": "qwen2.5-coder:32b_c8a6_tpusg_batch",
      "metadata": {
        "num_run": 1
      },
      "tags": [
        "benchmark",
        "qwen2.5-coder:32b",
        "tpu_sketch_generator"
      ],
      "latency": 192.963,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-04-09-27-967307_chatcmpl-7040731c-62a4-4fed-8bb2-2e88e78c10fc",
          "traceId": "e657d7a2",
          "type": "GENERATION",
          "name": "e657_tpusg_gen_attempt#1",
          "startTime": "2025-08-04T01:09:27.967000+00:00",
          "endTime": "2025-08-04T01:09:53.421000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 25454.0,
          "environment": "default",
          "promptTokens": 1833,
          "totalTokens": 2709,
          "costDetails": {},
          "completionTokens": 876,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-04-10-01-534042_chatcmpl-c68ecd91-bbff-4fdf-8d7a-8b110cabe16b",
          "traceId": "e657d7a2",
          "type": "GENERATION",
          "name": "e657_tpusg_gen_attempt#2",
          "startTime": "2025-08-04T01:10:01.534000+00:00",
          "endTime": "2025-08-04T01:10:32.507000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 30973.0,
          "environment": "default",
          "promptTokens": 2048,
          "totalTokens": 3127,
          "costDetails": {},
          "completionTokens": 1079,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-04-10-40-600589_chatcmpl-90f55403-3c56-4f96-8a0a-6e6745e7e065",
          "traceId": "e657d7a2",
          "type": "GENERATION",
          "name": "e657_tpusg_gen_attempt#3",
          "startTime": "2025-08-04T01:10:40.600000+00:00",
          "endTime": "2025-08-04T01:11:12.290000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 31690.0,
          "environment": "default",
          "promptTokens": 2048,
          "totalTokens": 3155,
          "costDetails": {},
          "completionTokens": 1107,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-04-11-20-717107_chatcmpl-2ed0c24a-8089-4101-949b-b81f878a3c0a",
          "traceId": "e657d7a2",
          "type": "GENERATION",
          "name": "e657_tpusg_gen_attempt#4",
          "startTime": "2025-08-04T01:11:20.717000+00:00",
          "endTime": "2025-08-04T01:11:52.511000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 31794.0,
          "environment": "default",
          "promptTokens": 2048,
          "totalTokens": 3158,
          "costDetails": {},
          "completionTokens": 1110,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-04-12-00-626608_chatcmpl-b9232538-2a7e-494c-9cab-3a9a7dc1ffc6",
          "traceId": "e657d7a2",
          "type": "GENERATION",
          "name": "e657_tpusg_gen_attempt#5",
          "startTime": "2025-08-04T01:12:00.626000+00:00",
          "endTime": "2025-08-04T01:12:32.709000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 32083.0,
          "environment": "default",
          "promptTokens": 2048,
          "totalTokens": 3169,
          "costDetails": {},
          "completionTokens": 1121,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "c470c0f3-b8c8-4129-8ce1-f440e4631359",
          "traceId": "e657d7a2",
          "type": "SPAN",
          "name": "error_e6_tpusg_failure_signal_tpu_sketch_generator",
          "startTime": "2025-08-04T01:12:40.930000+00:00",
          "level": "ERROR",
          "statusMessage": "Failed. Last error: Traceback (most recent call last):\n  File \"script_037414af_1754269952.py\", line 66, in <module>\n    num_detections = int(interpreter.get_tensor(output_details[1]['index'])[0])  # Access the first element directly\nTypeError: only size-1 arrays can be converted to Python scalars",
          "calculatedTotalCost": 0.0,
          "environment": "default",
          "promptTokens": 0,
          "totalTokens": 0,
          "costDetails": {},
          "completionTokens": 0,
          "endTime": null,
          "model": null,
          "modelParameters": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null,
          "latency": null
        }
      ],
      "createdAt": "2025-08-04T01:09:28.487Z",
      "environment": "default",
      "updatedAt": "2025-08-04T01:12:46.292Z"
    }
  ],
  "meta": {
    "total_items": 30
  }
}
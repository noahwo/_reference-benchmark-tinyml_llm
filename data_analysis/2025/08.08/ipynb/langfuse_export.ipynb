{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setting up\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ref: https://langfuse.com/docs/query-traces\n",
    "import os\n",
    "import json\n",
    "from langfuse import Langfuse\n",
    "import json\n",
    "import os\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "LOCAL_HOST = True\n",
    "\n",
    "\"\"\"Define session_id\"\"\"\n",
    "# session_id=\"qwen2.5-coder_f4d4_dp_batch\"\n",
    "session_id_list = [\n",
    "    # \"qwen2.5-coder:32b_4e11_tpsg_batch\",\n",
    "    # \"qwen2.5-coder:32b_ae24_tpsg_batch\"\n",
    "    \"codestral_3adb_psg_batch\",\n",
    " \n",
    "]\n",
    "\n",
    "\n",
    "\"\"\"Define paths\"\"\"\n",
    " \n",
    "parent_dir = os.path.dirname(os.getcwd())\n",
    "\n",
    " \n",
    "# date = os.path.basename(parent_dir)\n",
    "tex_dir = os.path.join(parent_dir, \"tex\")\n",
    "processed_data_dir = os.path.join(parent_dir, \"processed_data\")\n",
    "raw_export_dir = os.path.join(parent_dir, \"raw_export\")\n",
    "ipynb_dir = os.path.join(parent_dir, \"ipynb\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Export raw data\n",
    "\n",
    "Langfuse added a limit of 20 API invocations per minute. https://langfuse.com/faq/all/api-limits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching traces for session codestral_3adb_psg_batch...\n",
      "Fetching observation data for time-17-50-41-732333_chatcmpl-3f3b034a-8c14-40c1-9b9c-a8eb2954be33...\n",
      "Fetching observation data for time-17-51-08-727585_chatcmpl-69ee3e0d-c2b3-4fd5-8ae9-c9051b48dcc5...\n",
      "Fetching observation data for time-17-51-24-737115_chatcmpl-4f7d5467-b365-4adc-8caa-467e445080b2...\n",
      "Fetching observation data for time-17-51-43-226294_chatcmpl-c6fe566b-5a23-4ac4-a1e1-ec2d58aaa4c0...\n",
      "Fetching observation data for time-17-51-51-217680_chatcmpl-9782f8af-a517-4b66-956b-c3c32e3f4b73...\n",
      "Fetching observation data for 2fd1558b-7faa-4970-883a-b0579c154643...\n",
      "Fetching observation data for time-17-48-42-978122_chatcmpl-7a90c13f-3ccf-4533-a034-d8b3d6f6cfd3...\n",
      "Fetching observation data for time-17-49-10-025224_chatcmpl-a48ae5a5-8e3e-4fdb-b5d4-009d0e5de13e...\n",
      "Fetching observation data for time-17-49-26-015356_chatcmpl-14bcd2e3-56c8-4b3b-93ca-4df40e75b987...\n",
      "Fetching observation data for time-17-49-50-288121_chatcmpl-0a193916-c652-490d-92f9-f72cdc0641b1...\n",
      "Fetching observation data for time-17-50-19-747131_chatcmpl-65844d4f-f345-49c9-a1ff-77ee0aac1435...\n",
      "Fetching observation data for 974c5b5d-079d-48c6-b71c-6f71c126340e...\n",
      "Fetching observation data for time-17-46-54-307899_chatcmpl-fb513907-07f6-4801-b714-6dd0da87b87d...\n",
      "Fetching observation data for time-17-47-20-480303_chatcmpl-154467be-fa35-4506-b56a-dbc3822cac85...\n",
      "Fetching observation data for time-17-47-33-055124_chatcmpl-2ae0856b-c20f-4cb3-8a3e-842f51a7dc9b...\n",
      "Fetching observation data for time-17-48-02-322993_chatcmpl-cec763c3-751a-458d-a4f5-435e5043000b...\n",
      "Fetching observation data for time-17-48-23-262084_chatcmpl-c38463d8-cf92-4df6-821f-3cd55a0ea580...\n",
      "Fetching observation data for c44151e1-09c7-4894-a9a7-621559b613e9...\n",
      "Fetching observation data for time-17-45-14-568629_chatcmpl-74a1d1ef-fbb2-47a6-b263-49232d1365eb...\n",
      "Fetching observation data for time-17-45-41-620962_chatcmpl-8c8f8e00-26b8-4146-a728-a8e8369b83eb...\n",
      "Fetching observation data for time-17-45-53-506812_chatcmpl-504b0fc4-d458-49c5-aebc-df1c39a39392...\n",
      "Fetching observation data for time-17-46-08-662141_chatcmpl-66403f20-0d9d-4e7e-a9d3-a1e6651fcc41...\n",
      "Fetching observation data for time-17-46-24-553499_chatcmpl-20d5f90e-8cd7-4f91-a6ec-33e9ff5c427f...\n",
      "Fetching observation data for 3cf1e704-cfb3-445b-af4a-178486d275b1...\n",
      "Fetching observation data for time-17-43-32-501623_chatcmpl-0a255764-e717-4d84-8819-4b956e97598f...\n",
      "Fetching observation data for time-17-43-59-558740_chatcmpl-f872e16d-d132-439e-ad77-b6286641234e...\n",
      "Fetching observation data for time-17-44-15-504809_chatcmpl-79ac2f1e-56fd-4b24-9c1b-d135b4908034...\n",
      "Fetching observation data for time-17-44-34-022004_chatcmpl-b25d9191-f65c-4950-8888-5dee64592c9a...\n",
      "Fetching observation data for time-17-44-50-288793_chatcmpl-96f618aa-4d04-4add-99b3-fe9af0c5cddd...\n",
      "Fetching observation data for 465dae5f-f708-46f4-b820-cc415cfcdc59...\n",
      "Fetching observation data for time-17-41-49-496537_chatcmpl-6c4bc150-b436-4c6d-a55d-2ad2dd805d7a...\n",
      "Fetching observation data for time-17-42-16-496774_chatcmpl-e56ec8cb-244a-408f-aacf-996c1f0a3944...\n",
      "Fetching observation data for time-17-42-32-465469_chatcmpl-afff0ffc-0d2f-4372-885e-5c8963a1dcbe...\n",
      "Fetching observation data for time-17-42-56-966364_chatcmpl-e7931666-7bde-4263-8297-f323d8ad382e...\n",
      "Fetching observation data for time-17-43-10-304278_chatcmpl-1886e6b0-ba8f-4ef3-a93a-7fcc820e23d2...\n",
      "Fetching observation data for b4e1603f-8f74-450b-bdf3-74135f9e865d...\n",
      "Fetching observation data for time-17-39-51-557031_chatcmpl-1f14eb35-2e5d-488e-b741-34fb0a131309...\n",
      "Fetching observation data for time-17-40-17-742853_chatcmpl-e6b92071-c7ed-4d66-88a0-5bcd27e66997...\n",
      "Fetching observation data for time-17-40-30-270539_chatcmpl-f19b2571-4a60-41d4-bb12-7195d4b94223...\n",
      "Fetching observation data for time-17-40-53-725023_chatcmpl-35362d30-3605-4981-8629-5b4bd8e9749c...\n",
      "Fetching observation data for time-17-41-06-449461_chatcmpl-437d5721-7283-4022-b8f2-5202bf60913a...\n",
      "Fetching observation data for 207b61b3-518d-4e24-8317-baa5d260b27e...\n",
      "Fetching observation data for time-17-38-24-706523_chatcmpl-92d8d14b-803d-43e9-a016-c04e3978393e...\n",
      "Fetching observation data for time-17-38-51-731039_chatcmpl-6eb55e9d-bc22-4d42-8077-49299e54c688...\n",
      "Fetching observation data for time-17-39-03-540345_chatcmpl-66cfbbb8-bf6c-4697-b6c7-5a5042556654...\n",
      "Fetching observation data for time-17-39-18-391274_chatcmpl-cbf9988a-394d-4e5f-a36f-bc0cbd0d6edc...\n",
      "Fetching observation data for time-17-39-32-539105_chatcmpl-b62dbbe3-06a0-4df9-8804-8a566bf49bc7...\n",
      "Fetching observation data for 0dc9ab57-f8b7-48ba-b05b-6530a4d4a4fb...\n",
      "Fetching observation data for time-17-36-34-045532_chatcmpl-186f7bcc-9d7a-47d5-83be-acb75b1d74ac...\n",
      "Fetching observation data for time-17-37-01-068268_chatcmpl-73f67e97-9441-49ca-916f-8cad0325fa9c...\n",
      "Fetching observation data for time-17-37-17-123781_chatcmpl-15a91052-7025-4dd9-845e-a9c31a6f0afd...\n",
      "Fetching observation data for time-17-37-49-674805_chatcmpl-2ebc68db-357a-456f-b167-cab13efe4302...\n",
      "Fetching observation data for time-17-38-02-831811_chatcmpl-2733a3af-7748-4000-a1a9-37ca6027ec32...\n",
      "Fetching observation data for 3ee292aa-7e28-42be-9e7f-29124ecafbca...\n",
      "Fetching observation data for time-17-34-35-242521_chatcmpl-94b2830e-7acc-49a8-8c87-438d5a58d44d...\n",
      "Fetching observation data for time-17-35-02-291078_chatcmpl-172d7371-1630-41a4-be08-4032a934e261...\n",
      "Fetching observation data for time-17-35-18-282183_chatcmpl-f6787170-fbb8-4a62-92d6-4b1f431bae85...\n",
      "Fetching observation data for time-17-35-50-559756_chatcmpl-27718716-9c66-410d-9118-75d6982fb37f...\n",
      "Fetching observation data for time-17-36-03-437146_chatcmpl-0b9306d2-38eb-4184-9e14-5e1bb893ef1c...\n",
      "Fetching observation data for b8a246d6-c457-461a-99c6-1da2b0e7fc5b...\n",
      "Fetching observation data for time-17-33-10-315983_chatcmpl-f824c5aa-10fd-46fa-83ad-681fa9a2a89a...\n",
      "Fetching observation data for time-17-33-37-362993_chatcmpl-68e7ec60-f241-406b-b184-525cbcff3258...\n",
      "Fetching observation data for time-17-33-49-187795_chatcmpl-b0ea6194-09e0-419c-bbd6-3927816cb1e3...\n",
      "Fetching observation data for time-17-34-03-253342_chatcmpl-5995ce3c-8494-409d-9353-9740174d805f...\n",
      "Fetching observation data for time-17-34-17-314352_chatcmpl-b44b630d-09a1-463b-b028-28f548dac8c3...\n",
      "Fetching observation data for a9303c72-33ee-4324-b6ff-4874ef443edf...\n",
      "Fetching observation data for time-17-31-09-612897_chatcmpl-a42e4c82-6dcf-4f14-88b3-fd337a123b5f...\n",
      "Fetching observation data for time-17-31-36-626719_chatcmpl-132e2ae3-0785-465a-9b87-69977e800559...\n",
      "Fetching observation data for time-17-31-48-467900_chatcmpl-6f0483a8-1d6a-45c4-9f1c-785b186418fb...\n",
      "Fetching observation data for time-17-32-14-706218_chatcmpl-13d1b503-d7b4-4a62-94e9-05f96cdda310...\n",
      "Fetching observation data for time-17-32-39-466261_chatcmpl-9a7f53b5-036f-4fe3-8047-e1a5373f4c05...\n",
      "Fetching observation data for 822d4514-4faa-4d8b-8abb-820893058f52...\n",
      "Fetching observation data for time-17-29-22-565086_chatcmpl-7dd3447c-46f1-43e4-b475-e95553163a8e...\n",
      "Fetching observation data for time-17-29-49-618035_chatcmpl-d102120a-2bda-4062-9c37-46a241185f4f...\n",
      "Fetching observation data for time-17-30-05-614202_chatcmpl-f370a793-70cf-46c1-8d7b-97d9cb52bb6e...\n",
      "Fetching observation data for time-17-30-25-644185_chatcmpl-d5ed645f-eda2-4071-b247-26ed870d3ead...\n",
      "Fetching observation data for time-17-30-49-809173_chatcmpl-db87d8ba-3e30-46c0-bcdd-1626b7ce1c18...\n",
      "Fetching observation data for e465bb3d-93f5-4edf-b121-001e192701ed...\n",
      "Fetching observation data for time-17-27-56-804878_chatcmpl-0b3d0878-b31d-4ea8-93eb-68f26b859cac...\n",
      "Fetching observation data for time-17-28-23-835942_chatcmpl-9d7e101c-c665-4af6-979e-e4d8e88aab12...\n",
      "Fetching observation data for time-17-28-36-028656_chatcmpl-84bcd595-a377-41db-8633-3399be2a5b40...\n",
      "Fetching observation data for time-17-28-50-456046_chatcmpl-52bab076-2652-4a31-a939-51513b72a7d5...\n",
      "Fetching observation data for time-17-29-04-130425_chatcmpl-cb778780-aa2e-47ae-ae35-51baab51cc42...\n",
      "Fetching observation data for 7257c9f9-2986-4d24-bfe9-d8a4bfc5e8cc...\n",
      "Fetching observation data for time-17-26-18-145977_chatcmpl-7b5ca928-1063-4015-a9ae-a31a782b9d27...\n",
      "Fetching observation data for time-17-26-44-322987_chatcmpl-da4130c5-d070-4086-b369-73685d0e537b...\n",
      "Fetching observation data for time-17-26-59-114292_chatcmpl-5d8bfc8b-824a-48e4-9080-3e9b574dfb45...\n",
      "Fetching observation data for time-17-27-24-913998_chatcmpl-c26658c3-e610-4548-a789-917fb0cd070b...\n",
      "Fetching observation data for time-17-27-38-230684_chatcmpl-ef90e3d5-9325-4dbb-980c-df3958a4fcdc...\n",
      "Fetching observation data for a402e9d0-0daa-4dc6-9d03-4d15dd50d52a...\n",
      "Fetching observation data for time-17-24-26-048652_chatcmpl-46b1aa57-5736-4179-a191-9a44bb31a15c...\n",
      "Fetching observation data for time-17-24-53-090621_chatcmpl-44ed3091-12d0-4eb0-a9e3-4abbe6db7040...\n",
      "Fetching observation data for time-17-25-09-110191_chatcmpl-90e0e71e-5523-4216-9254-5e83fba30011...\n",
      "Fetching observation data for time-17-25-29-683621_chatcmpl-37dd9cb1-aa6d-49de-be3a-ad5e17e47674...\n",
      "Fetching observation data for time-17-25-44-944894_chatcmpl-2e9fb2e8-6394-4bab-98e7-a360389ef627...\n",
      "Fetching observation data for 349993f9-d02d-4528-a6e6-fc1e517bf353...\n",
      "Fetching observation data for time-17-22-26-061775_chatcmpl-05380654-0c3f-4282-8a89-bdfc89d98b00...\n",
      "Fetching observation data for time-17-22-53-188818_chatcmpl-1e0c90b4-4586-4639-8269-3fbbf4d2b895...\n",
      "Fetching observation data for time-17-23-09-217356_chatcmpl-dcbb44e6-8fb1-4d5b-8d24-7e522f835e82...\n",
      "Fetching observation data for time-17-23-40-168545_chatcmpl-d44151c7-a3e6-4fec-bb27-438c1dcd8254...\n",
      "Fetching observation data for time-17-24-04-413867_chatcmpl-9774e6d1-eeee-4c5b-ac0c-ed2fc1885d04...\n",
      "Fetching observation data for time-17-20-59-060547_chatcmpl-1a9d4975-b1b8-4104-83cb-de5875670454...\n",
      "Fetching observation data for time-17-21-26-107970_chatcmpl-e4ea0d3b-29c7-4ffe-988b-c53fdee3869a...\n",
      "Fetching observation data for time-17-21-37-949115_chatcmpl-6a12eb71-cc69-4206-bbe1-8584d9d14e96...\n",
      "Fetching observation data for time-17-21-53-517081_chatcmpl-86b6f59f-54fa-4ca7-9217-d7b5d322e7eb...\n",
      "Fetching observation data for time-17-22-07-614349_chatcmpl-148907af-4b8a-4d8f-9f51-94f29ea50a2c...\n",
      "Fetching observation data for a6a0b9c7-2341-48b1-9074-d62d8500a5d4...\n",
      "Fetching observation data for time-17-19-27-427168_chatcmpl-75f6d67f-abf4-4ea1-88e2-78e15939827f...\n",
      "Fetching observation data for time-17-19-54-458029_chatcmpl-34148cc3-ce57-4203-9d36-5889ed9b5543...\n",
      "Fetching observation data for time-17-20-06-311323_chatcmpl-7d1bfda0-a191-4325-859e-e9149d92a665...\n",
      "Fetching observation data for time-17-20-21-840510_chatcmpl-750d3710-80c3-42f1-99fe-584f29a53fdd...\n",
      "Fetching observation data for time-17-20-37-712091_chatcmpl-83ca658b-f8d2-4f8d-b37f-3fc4e77799df...\n",
      "Fetching observation data for ea969ce3-eaa7-4b51-8442-d1beaf1db67c...\n",
      "Fetching observation data for time-17-18-05-273216_chatcmpl-913462cf-6d83-4de7-9b2a-2fe5bd776e8e...\n",
      "Fetching observation data for time-17-18-31-524773_chatcmpl-fbd0ffc8-d044-4808-a1eb-0f076c999c90...\n",
      "Fetching observation data for time-17-18-45-935926_chatcmpl-52208d0c-6df7-4cde-9e25-6c7a46f0805b...\n",
      "Fetching observation data for time-17-18-57-654592_chatcmpl-6744d60d-b150-464d-9d35-b9a7bb1603c9...\n",
      "Fetching observation data for time-17-19-11-937280_chatcmpl-af953790-5731-4df6-9a60-6137d9c71d84...\n",
      "Fetching observation data for 105441cd-1b29-4603-b55d-3db59d85d2eb...\n",
      "Fetching observation data for time-17-16-11-925812_chatcmpl-2985c37f-cc82-4507-8416-2c64976e121e...\n",
      "Fetching observation data for time-17-16-38-947281_chatcmpl-73eddb52-3d5e-450b-bfc2-f117969d6f66...\n",
      "Fetching observation data for time-17-16-54-937819_chatcmpl-2d434c2c-4bf5-4648-8847-e8042767f698...\n",
      "Fetching observation data for time-17-17-16-501114_chatcmpl-93a0e639-0d73-4b7d-90fd-ccbf1abceb67...\n",
      "Fetching observation data for time-17-17-25-894342_chatcmpl-f6fd2985-32e6-41ab-80e6-bbd6c21904ec...\n",
      "Fetching observation data for 9c590b78-876e-477e-8e77-483bbab55eb4...\n",
      "Fetching observation data for time-17-14-35-292050_chatcmpl-d3fc5379-0821-4e7c-9f6f-4cc806536f1a...\n",
      "Fetching observation data for time-17-15-02-310540_chatcmpl-a23b0587-69b9-4a48-9b29-04edc5b9b8c7...\n",
      "Fetching observation data for time-17-15-18-265246_chatcmpl-8f83f1d1-acdc-4843-95fb-97aa5ce7569e...\n",
      "Fetching observation data for time-17-15-37-652083_chatcmpl-2994ad93-6f5d-4f9b-a8de-2ab125c53cf2...\n",
      "Fetching observation data for time-17-15-44-523832_chatcmpl-a90748b8-a938-4b64-b0c9-8ebc4a4b2d89...\n",
      "Fetching observation data for 3c6cbc22-1dff-4a56-91e9-db74ef5d7e78...\n",
      "Fetching observation data for time-17-12-55-728445_chatcmpl-cde89e05-1f81-4452-9358-f49ef922cdee...\n",
      "Fetching observation data for time-17-13-22-691180_chatcmpl-bee6026d-15dd-4e20-9274-a244291fa30d...\n",
      "Fetching observation data for time-17-13-38-812504_chatcmpl-209bdfdf-16a4-434a-afaf-1d35ebf6d261...\n",
      "Fetching observation data for time-17-14-02-969059_chatcmpl-7a3fae84-d5c4-4eee-96dd-6f92066ea555...\n",
      "Fetching observation data for time-17-14-19-054296_chatcmpl-e1ece1f1-0b3f-42f7-877b-7e1786a2ebc0...\n",
      "Fetching observation data for 3340fe67-c46a-4345-8bc6-53f2aca1ef34...\n",
      "Fetching observation data for time-17-11-27-086360_chatcmpl-aa5a51d4-74d0-44a3-8e32-e56d75e7df63...\n",
      "Fetching observation data for time-17-11-54-171686_chatcmpl-684590af-2d0a-46ab-8f84-65761c0e3799...\n",
      "Fetching observation data for time-17-12-05-988663_chatcmpl-6f67f16e-fb7a-4ab1-ad68-00ef90a5a153...\n",
      "Fetching observation data for time-17-12-22-508460_chatcmpl-d29c469f-47be-4257-a184-9108c89984b8...\n",
      "Fetching observation data for time-17-12-36-644194_chatcmpl-46a062e6-6aaf-452d-84a6-ba92df14c2b6...\n",
      "Fetching observation data for c970191d-e9aa-4e40-b84b-2ddf5419d87c...\n",
      "Fetching observation data for time-17-09-39-489876_chatcmpl-d58e97ff-fa0b-4fde-b0b4-d36338200f8b...\n",
      "Fetching observation data for time-17-10-06-505241_chatcmpl-b99c1a86-534e-4660-8436-acee7c73e7ee...\n",
      "Fetching observation data for time-17-10-22-495583_chatcmpl-bc8b50b1-a08a-4a71-bef4-f6aceb46af83...\n",
      "Fetching observation data for time-17-10-40-452346_chatcmpl-ab07c193-c7cf-425c-b396-c53dd6e97f47...\n",
      "Fetching observation data for time-17-11-05-294242_chatcmpl-98b1bf17-6ab5-4506-9c3a-0029931d797c...\n",
      "Fetching observation data for 3491e7aa-2cef-4d0f-a30b-3d9d0fbf040c...\n",
      "Fetching observation data for time-17-07-48-823188_chatcmpl-2e5ef914-98e7-4080-97fd-b2a9070adfe8...\n",
      "Fetching observation data for time-17-08-15-083145_chatcmpl-e7b75246-dcd0-473c-a290-f626e4405252...\n",
      "Fetching observation data for time-17-08-29-802681_chatcmpl-1aa1dee2-8d64-43da-9a2e-5ab582b37980...\n",
      "Fetching observation data for time-17-08-53-489940_chatcmpl-a7991259-051f-47b1-9cda-bf578f59c262...\n",
      "Fetching observation data for time-17-09-16-661084_chatcmpl-1ab518be-8a5c-4f02-96f6-3d4f21871efc...\n",
      "Fetching observation data for a0a06393-2077-4803-bd27-bec277bfe015...\n",
      "Fetching observation data for time-17-06-06-544646_chatcmpl-266c4ea8-a4a9-459c-9ff5-d2d953069db0...\n",
      "Fetching observation data for time-17-06-33-545775_chatcmpl-7441aa9d-bc63-47e7-9a90-7a3c82a6797a...\n",
      "Fetching observation data for time-17-06-49-646197_chatcmpl-54587104-18a3-4990-8b45-ca4192566b6e...\n",
      "Fetching observation data for time-17-07-17-640049_chatcmpl-6a7de298-f350-41cc-9aa4-80aa294f032b...\n",
      "Fetching observation data for time-17-07-29-252207_chatcmpl-8901ee73-1456-4b61-9d96-d9afb64d335d...\n",
      "Fetching observation data for ad100f6b-bdec-4622-9d5e-8e123d8cd50e...\n",
      "Fetching observation data for time-17-04-14-351449_chatcmpl-984b46e0-a88d-4c8e-8eb1-adc37b19ec94...\n",
      "Fetching observation data for time-17-04-40-536315_chatcmpl-05a7307a-332a-4e6c-aed3-07b24d62bf1f...\n",
      "Fetching observation data for time-17-04-53-076136_chatcmpl-71e4b2a1-c11a-4868-8e05-281915ab85a2...\n",
      "Fetching observation data for time-17-05-23-789202_chatcmpl-d5b29d2e-cec4-417a-8e2f-4ac40628ebeb...\n",
      "Fetching observation data for time-17-05-36-931315_chatcmpl-0d8c4e8d-09bc-4905-a3eb-d419370e8727...\n",
      "Fetching observation data for time-17-02-28-182626_chatcmpl-32132cb2-bb7b-4530-a685-a505770b9a96...\n",
      "Fetching observation data for time-17-02-54-353192_chatcmpl-3bec884a-735e-4695-bb8a-02c422c7d501...\n",
      "Fetching observation data for time-17-03-06-927226_chatcmpl-f3df0b02-ceb1-45ef-89c2-f967bb9d537d...\n",
      "Fetching observation data for time-17-03-25-561082_chatcmpl-d1e3058a-20ca-47f2-b722-39102997b35b...\n",
      "Fetching observation data for time-17-03-53-782409_chatcmpl-ce4dce12-dc23-4ad4-b340-652cf91e4d11...\n",
      "Fetching observation data for 4a1dcaa7-8b2e-433a-a744-682a18bb9951...\n",
      "Fetching observation data for time-17-01-01-531479_chatcmpl-5d06badc-b8a0-41c0-99da-dc9321d16e0c...\n",
      "Fetching observation data for time-17-01-28-554410_chatcmpl-1bbfc1ac-f3f0-4595-b7c9-2d5c8b10570b...\n",
      "Fetching observation data for time-17-01-40-374100_chatcmpl-0d82931f-a511-44ef-8b84-bc15ca36ce0a...\n",
      "Fetching observation data for time-17-01-54-296210_chatcmpl-53214e9b-751c-45c1-9eb4-93f5403db081...\n",
      "Fetching observation data for time-17-02-08-587137_chatcmpl-06a6f0bf-b77e-4dc7-ab77-d7863c587f39...\n",
      "Fetching observation data for 0db3107d-7841-4987-b10d-fdf7ef64ade1...\n",
      "Raw JSON saved to: /Users/hann/Projects/reference-benchmark-tinyml_llm/data_analysis/2025/08.08/raw_export/raw_codestral_3adb_psg_batch.json\n"
     ]
    }
   ],
   "source": [
    "# ALTERNATIVE TO 2.\n",
    "import os\n",
    "import json\n",
    "from time import sleep\n",
    "from langfuse import Langfuse\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "\n",
    "# LANGFUSE_SERVICE_PUBLIC_KEY = \"pk-lf-559a2c0f-ee29-4c32-944c-bf73b5f0ce28\"\n",
    "# LANGFUSE_SERVICE_SECRET_KEY = \"sk-lf-75f8bf7f-a5db-4756-b0dd-d758a2a292c8\"\n",
    "# LANGFUSE_SERVICE_HOST = \"https://langfuse.hann.fi\"\n",
    "\n",
    "\n",
    "if LOCAL_HOST:\n",
    "    langfuse = Langfuse(\n",
    "        secret_key=\"sk-lf-75f8bf7f-a5db-4756-b0dd-d758a2a292c8\",\n",
    "        public_key=\"pk-lf-559a2c0f-ee29-4c32-944c-bf73b5f0ce28\",\n",
    "        host=\"https://langfuse.hann.fi\",\n",
    "    )\n",
    "else:\n",
    "    langfuse = Langfuse(\n",
    "        secret_key=LANGFUSE_SERVICE_SECRET_KEY,\n",
    "        public_key=LANGFUSE_SERVICE_PUBLIC_KEY,\n",
    "        host=LANGFUSE_SERVICE_HOST,\n",
    "    )\n",
    "\n",
    "API_invok_count = 0\n",
    "query_range_num_run = {\"start\": 0, \"end\": 1}\n",
    "\n",
    "\n",
    "class CustomJSONEncoder(json.JSONEncoder):\n",
    "    def __init__(self, *args, LOCAL_HOST=True, **kwargs):\n",
    "        self.LOCAL_HOST = LOCAL_HOST\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "    def default(self, obj):\n",
    "        if isinstance(obj, datetime):\n",
    "            return obj.isoformat()\n",
    "        if hasattr(obj, \"__dict__\"):\n",
    "            data = obj.__dict__.copy()\n",
    "            if \"observations\" in data:\n",
    "                data[\"observations\"] = [\n",
    "                    fetch_observation_data(obs, self.LOCAL_HOST)\n",
    "                    for obs in data[\"observations\"]\n",
    "                ]\n",
    "\n",
    "            return data\n",
    "        return super().default(obj)\n",
    "\n",
    "\n",
    "def fetch_observation_data(observation_id, LOCAL_HOST):\n",
    "    \"\"\"\n",
    "    Fetches observation data from Langfuse and returns its dictionary representation.\n",
    "    \"\"\"\n",
    "    print(f\"Fetching observation data for {observation_id}...\")\n",
    "    global API_invok_count\n",
    "    if API_invok_count >= 0 and not LOCAL_HOST:\n",
    "        print(\"Waiting for 3 seconds to fetch observation data...\")\n",
    "        for _ in tqdm(range(3), desc=\"Progress\", unit=\"s\"):\n",
    "            sleep(1)\n",
    "        API_invok_count = 0\n",
    "\n",
    "    observation_response = langfuse.fetch_observation(observation_id)\n",
    "    API_invok_count += 1\n",
    "\n",
    "    return observation_response.data.dict()\n",
    "\n",
    "\n",
    "def fetch_and_save_complete_data(session_id_list, raw_export_dir, LOCAL_HOST):\n",
    "    \"\"\"\n",
    "    Fetches complete trace data for each session ID and saves it to JSON files.\n",
    "\n",
    "    Parameters:\n",
    "        session_id_list (list): List of session IDs to process.\n",
    "        raw_export_dir (str): Directory path to save raw JSON files.\n",
    "    \"\"\"\n",
    "\n",
    "    def save_complete_data(session_id):\n",
    "        global API_invok_count\n",
    "        if API_invok_count >= 0 and not LOCAL_HOST:\n",
    "            print(\"Waiting for 4 seconds to fetch traces...\")\n",
    "            for _ in tqdm(range(4), desc=\"Progress\", unit=\"s\"):\n",
    "                sleep(1)\n",
    "            API_invok_count = 0\n",
    "\n",
    "        fetch_traces_response = langfuse.fetch_traces(session_id=session_id)\n",
    "        API_invok_count += 1\n",
    "\n",
    "        print(f\"Fetching traces for session {session_id}...\")\n",
    "        # Create directories if they don't exist\n",
    "        os.makedirs(raw_export_dir, exist_ok=True)\n",
    "\n",
    "        # Save complete data to JSON file\n",
    "        # if session_id.startswith(\"da0a\"):\n",
    "        #     session_id = \"phi4_\" + session_id\n",
    "        if \"tpsg\" in session_id:\n",
    "            session_id_ = session_id.replace(\"tpsg\", \"tpusg\")\n",
    "        else:\n",
    "            session_id_ = session_id\n",
    "            \n",
    "        raw_path = os.path.join(raw_export_dir, f\"raw_{session_id_}.json\")\n",
    "        with open(raw_path, \"w\") as f:\n",
    "            json.dump(fetch_traces_response, f, cls=CustomJSONEncoder, indent=2)\n",
    "\n",
    "        print(f\"Raw JSON saved to: {raw_path}\")\n",
    "\n",
    "    for session_id in session_id_list:\n",
    "        save_complete_data(session_id)\n",
    "\n",
    "\n",
    "fetch_and_save_complete_data(session_id_list, raw_export_dir, LOCAL_HOST)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Trim data\n",
    "\n",
    "Here also intercept the runs with fatal errors that need to be excluded from the analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPAN error_44_psg_failure_signal_py_sketch_generator: Failed. Last error: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250805175211_psg_codestral:latest/tmp_20250805175211_psg_codestral:latest.py\", line 23, in <module>\n",
      "    input_data = np.expand_dims(np.load(input_path), axis=0).astype(input_details[0]['dtype'])\n",
      "  File \"/home/wuguangh/.conda/envs/tinyml/lib/python3.10/site-packages/numpy/lib/npyio.py\", line 462, in load\n",
      "    raise ValueError(\"Cannot load file containing pickled data \"\n",
      "ValueError: Cannot load file containing pickled data when allow_pickle=False\n",
      "\n",
      "SPAN error_2f_psg_failure_signal_py_sketch_generator: Failed. Last error: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250805175034_psg_codestral:latest/tmp_20250805175034_psg_codestral:latest.py\", line 21, in <module>\n",
      "    resized_image = cv2.resize(image, (300, 300))\n",
      "cv2.error: OpenCV(4.10.0) /io/opencv/modules/imgproc/src/resize.cpp:4152: error: (-215:Assertion failed) !ssize.empty() in function 'resize'\n",
      "\n",
      "\n",
      "SPAN error_ca_psg_failure_signal_py_sketch_generator: Failed. Last error: Unexpected error during generation: The output is not a valid code block. Follow the instructions in the prompt return a complete, correct Python script enclosed in a single ```python\n",
      "<generated_code>\n",
      "``` block.\n",
      "SPAN error_c7_psg_failure_signal_py_sketch_generator: Failed. Last error: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250805174647_psg_codestral:latest/tmp_20250805174647_psg_codestral:latest.py\", line 29, in <module>\n",
      "    interpreter.set_tensor(input_details[0]['index'], input_data)\n",
      "  File \"/home/wuguangh/.conda/envs/tinyml/lib/python3.10/site-packages/ai_edge_litert/interpreter.py\", line 764, in set_tensor\n",
      "    self._interpreter.SetTensor(tensor_index, value)\n",
      "ValueError: Cannot set tensor: Got value of type FLOAT32 but expected type UINT8 for input 175, name: normalized_input_image_tensor \n",
      "\n",
      "SPAN error_71_psg_failure_signal_py_sketch_generator: Failed. Last error: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250805174507_psg_codestral:latest/tmp_20250805174507_psg_codestral:latest.py\", line 22, in <module>\n",
      "    input_data = np.load(input_path)  # Load input image or video frame\n",
      "  File \"/home/wuguangh/.conda/envs/tinyml/lib/python3.10/site-packages/numpy/lib/npyio.py\", line 462, in load\n",
      "    raise ValueError(\"Cannot load file containing pickled data \"\n",
      "ValueError: Cannot load file containing pickled data when allow_pickle=False\n",
      "\n",
      "SPAN error_3e_psg_failure_signal_py_sketch_generator: Failed. Last error: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250805174325_psg_codestral:latest/tmp_20250805174325_psg_codestral:latest.py\", line 22, in <module>\n",
      "    image = np.load(input_path)  # Assuming image is a numpy array saved as .npy file\n",
      "  File \"/home/wuguangh/.conda/envs/tinyml/lib/python3.10/site-packages/numpy/lib/npyio.py\", line 462, in load\n",
      "    raise ValueError(\"Cannot load file containing pickled data \"\n",
      "ValueError: Cannot load file containing pickled data when allow_pickle=False\n",
      "\n",
      "SPAN error_5a_psg_failure_signal_py_sketch_generator: Failed. Last error: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "OpenCV: FFMPEG: tag 0x44495658/'XVID' is not supported with codec id 12 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n",
      "OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250805174142_psg_codestral:latest/tmp_20250805174142_psg_codestral:latest.py\", line 43, in <module>\n",
      "    interpreter.set_tensor(input_details[0]['index'], input_data)\n",
      "  File \"/home/wuguangh/.conda/envs/tinyml/lib/python3.10/site-packages/ai_edge_litert/interpreter.py\", line 764, in set_tensor\n",
      "    self._interpreter.SetTensor(tensor_index, value)\n",
      "ValueError: Cannot set tensor: Got value of type FLOAT32 but expected type UINT8 for input 175, name: normalized_input_image_tensor \n",
      "\n",
      "SPAN error_a4_psg_failure_signal_py_sketch_generator: Failed. Last error: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250805173944_psg_codestral:latest/tmp_20250805173944_psg_codestral:latest.py\", line 22, in <module>\n",
      "    input_shape = input_details[0]['shape']\n",
      "TypeError: string indices must be integers\n",
      "\n",
      "SPAN error_25_psg_failure_signal_py_sketch_generator: Failed. Last error: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250805173817_psg_codestral:latest/tmp_20250805173817_psg_codestral:latest.py\", line 26, in <module>\n",
      "    input_data = np.frombuffer(raw_data, dtype=np.uint8).reshape(input_shape)  # This is a placeholder, replace with actual code to transform raw data into numpy array matching the shape and dtype specified in input_details\n",
      "ValueError: cannot reshape array of size 564314 into shape (1,300,300,3)\n",
      "\n",
      "SPAN error_99_psg_failure_signal_py_sketch_generator: Failed. Last error: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250805173627_psg_codestral:latest/tmp_20250805173627_psg_codestral:latest.py\", line 33, in <module>\n",
      "    input_data = preprocess_image(input_image_path)\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250805173627_psg_codestral:latest/tmp_20250805173627_psg_codestral:latest.py\", line 27, in preprocess_image\n",
      "    img = Image.open(image_path).resize((input_details[0]['shape'][1], input_details[0]['shape'][2]))\n",
      "  File \"/home/wuguangh/.conda/envs/tinyml/lib/python3.10/site-packages/PIL/Image.py\", line 3469, in open\n",
      "    fp = builtins.open(filename, \"rb\")\n",
      "FileNotFoundError: [Errno 2] No such file or directory: '/home/wuguangh/Projects/tinyml-autopilot/path/to/input_image.jpg'\n",
      "\n",
      "SPAN error_25_psg_failure_signal_py_sketch_generator: Failed. Last error: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250805173428_psg_codestral:latest/tmp_20250805173428_psg_codestral:latest.py\", line 20, in <module>\n",
      "    input_data = np.random.rand(*input_shape, 3).astype(np.float32)\n",
      "  File \"numpy/random/mtrand.pyx\", line 1219, in numpy.random.mtrand.RandomState.rand\n",
      "  File \"numpy/random/mtrand.pyx\", line 437, in numpy.random.mtrand.RandomState.random_sample\n",
      "  File \"_common.pyx\", line 307, in numpy.random._common.double_fill\n",
      "ValueError: maximum supported dimension for an ndarray is 32, found 33\n",
      "\n",
      "SPAN error_fc_psg_failure_signal_py_sketch_generator: Failed. Last error: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250805173303_psg_codestral:latest/tmp_20250805173303_psg_codestral:latest.py\", line 25, in <module>\n",
      "    for line in f:\n",
      "  File \"/home/wuguangh/.conda/envs/tinyml/lib/python3.10/codecs.py\", line 322, in decode\n",
      "    (result, consumed) = self._buffer_decode(data, self.errors, final)\n",
      "UnicodeDecodeError: 'utf-8' codec can't decode byte 0x92 in position 42: invalid start byte\n",
      "\n",
      "SPAN error_9b_psg_failure_signal_py_sketch_generator: Failed. Last error: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250805173102_psg_codestral:latest/tmp_20250805173102_psg_codestral:latest.py\", line 25, in <module>\n",
      "    interpreter.set_tensor(input_details[0]['index'], input_data)\n",
      "TypeError: string indices must be integers\n",
      "\n",
      "SPAN error_40_psg_failure_signal_py_sketch_generator: Failed. Last error: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250805172915_psg_codestral:latest/tmp_20250805172915_psg_codestral:latest.py\", line 25, in <module>\n",
      "    interpreter.set_tensor(input_details[0]['index'], dummy_input)\n",
      "TypeError: string indices must be integers\n",
      "\n",
      "SPAN error_1c_psg_failure_signal_py_sketch_generator: Failed. Last error: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250805172749_psg_codestral:latest/tmp_20250805172749_psg_codestral:latest.py\", line 22, in <module>\n",
      "    input_shape = input_details[0]['shape']\n",
      "TypeError: string indices must be integers\n",
      "\n",
      "SPAN error_9d_psg_failure_signal_py_sketch_generator: Failed. Last error: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "OpenCV: FFMPEG: tag 0x44495658/'XVID' is not supported with codec id 12 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n",
      "OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250805172611_psg_codestral:latest/tmp_20250805172611_psg_codestral:latest.py\", line 37, in <module>\n",
      "    interpreter.set_tensor(input_details[0]['index'], input_data)\n",
      "  File \"/home/wuguangh/.conda/envs/tinyml/lib/python3.10/site-packages/ai_edge_litert/interpreter.py\", line 764, in set_tensor\n",
      "    self._interpreter.SetTensor(tensor_index, value)\n",
      "ValueError: Cannot set tensor: Got value of type FLOAT32 but expected type UINT8 for input 175, name: normalized_input_image_tensor \n",
      "\n",
      "SPAN error_88_psg_failure_signal_py_sketch_generator: Failed. Last error: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250805172219_psg_codestral:latest/tmp_20250805172219_psg_codestral:latest.py\", line 20, in <module>\n",
      "    input_data = np.random.rand(*input_shape, 3).astype(np.float32)\n",
      "  File \"numpy/random/mtrand.pyx\", line 1219, in numpy.random.mtrand.RandomState.rand\n",
      "  File \"numpy/random/mtrand.pyx\", line 437, in numpy.random.mtrand.RandomState.random_sample\n",
      "  File \"_common.pyx\", line 307, in numpy.random._common.double_fill\n",
      "ValueError: maximum supported dimension for an ndarray is 32, found 33\n",
      "\n",
      "SPAN error_74_psg_failure_signal_py_sketch_generator: Failed. Last error: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250805172052_psg_codestral:latest/tmp_20250805172052_psg_codestral:latest.py\", line 17, in <module>\n",
      "    input_data = np.load(input_path)  # Replace with actual preprocessing code if needed\n",
      "  File \"/home/wuguangh/.conda/envs/tinyml/lib/python3.10/site-packages/numpy/lib/npyio.py\", line 462, in load\n",
      "    raise ValueError(\"Cannot load file containing pickled data \"\n",
      "ValueError: Cannot load file containing pickled data when allow_pickle=False\n",
      "\n",
      "SPAN error_54_psg_failure_signal_py_sketch_generator: Failed. Last error: Unexpected error during generation: The output is not a valid code block. Follow the instructions in the prompt return a complete, correct Python script enclosed in a single ```python\n",
      "<generated_code>\n",
      "``` block.\n",
      "SPAN error_2a_psg_failure_signal_py_sketch_generator: Failed. Last error: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250805171757_psg_codestral:latest/tmp_20250805171757_psg_codestral:latest.py\", line 23, in <module>\n",
      "    resized_image = cv2.resize(input_image, (input_width, input_height))\n",
      "cv2.error: OpenCV(4.10.0) /io/opencv/modules/imgproc/src/resize.cpp:4152: error: (-215:Assertion failed) !ssize.empty() in function 'resize'\n",
      "\n",
      "\n",
      "SPAN error_75_psg_failure_signal_py_sketch_generator: Failed. Last error: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250805171605_psg_codestral:latest/tmp_20250805171605_psg_codestral:latest.py\", line 38, in <module>\n",
      "    interpreter.set_tensor(input_details[0]['index'], input_data)\n",
      "  File \"/home/wuguangh/.conda/envs/tinyml/lib/python3.10/site-packages/ai_edge_litert/interpreter.py\", line 764, in set_tensor\n",
      "    self._interpreter.SetTensor(tensor_index, value)\n",
      "ValueError: Cannot set tensor: Got value of type FLOAT32 but expected type UINT8 for input 175, name: normalized_input_image_tensor \n",
      "\n",
      "SPAN error_c1_psg_failure_signal_py_sketch_generator: Failed. Last error: Unexpected error during generation: The output is not a valid code block. Follow the instructions in the prompt return a complete, correct Python script enclosed in a single ```python\n",
      "<generated_code>\n",
      "``` block.\n",
      "SPAN error_8e_psg_failure_signal_py_sketch_generator: Failed. Last error: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250805171248_psg_codestral:latest/tmp_20250805171248_psg_codestral:latest.py\", line 25, in <module>\n",
      "    interpreter.set_tensor(input_details[0]['index'], input_data)\n",
      "TypeError: string indices must be integers\n",
      "\n",
      "SPAN error_c4_psg_failure_signal_py_sketch_generator: Failed. Last error: Unexpected error during generation: The output is not a valid code block. Follow the instructions in the prompt return a complete, correct Python script enclosed in a single ```python\n",
      "<generated_code>\n",
      "``` block.\n",
      "SPAN error_6e_psg_failure_signal_py_sketch_generator: Failed. Last error: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250805170932_psg_codestral:latest/tmp_20250805170932_psg_codestral:latest.py\", line 26, in <module>\n",
      "    img = Image.open(input_path).resize((input_details[0]['shape'][1], input_details[0]['shape'][2]))\n",
      "  File \"/home/wuguangh/.conda/envs/tinyml/lib/python3.10/site-packages/PIL/Image.py\", line 3536, in open\n",
      "    raise UnidentifiedImageError(msg)\n",
      "PIL.UnidentifiedImageError: cannot identify image file '/home/wuguangh/Projects/tinyml-autopilot/data/object_detection/sheeps.mp4'\n",
      "\n",
      "SPAN error_e2_psg_failure_signal_py_sketch_generator: Failed. Last error: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250805170741_psg_codestral:latest/tmp_20250805170741_psg_codestral:latest.py\", line 21, in <module>\n",
      "    image = cv2.imread(image_path)\n",
      "NameError: name 'cv2' is not defined\n",
      "\n",
      "SPAN error_78_psg_failure_signal_py_sketch_generator: Failed. Last error: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250805170407_psg_codestral:latest/tmp_20250805170407_psg_codestral:latest.py\", line 28, in <module>\n",
      "    interpreter.set_tensor(input_details[0]['index'], input_data)\n",
      "  File \"/home/wuguangh/.conda/envs/tinyml/lib/python3.10/site-packages/ai_edge_litert/interpreter.py\", line 764, in set_tensor\n",
      "    self._interpreter.SetTensor(tensor_index, value)\n",
      "ValueError: Cannot set tensor: Got value of type FLOAT32 but expected type UINT8 for input 175, name: normalized_input_image_tensor \n",
      "\n",
      "SPAN error_24_psg_failure_signal_py_sketch_generator: Failed. Last error: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250805170221_psg_codestral:latest/tmp_20250805170221_psg_codestral:latest.py\", line 21, in <module>\n",
      "    input_data = np.expand_dims(np.array(Image.open(input_path).resize((224, 224))), axis=0)  # Resize and expand dimensions to match model's expected input shape\n",
      "NameError: name 'Image' is not defined\n",
      "\n",
      "Successfully processed and saved trimmed data for session codestral_3adb_psg_batch\n",
      "Total 0 traces skipped. They are []\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "skipped_traces = []\n",
    "\n",
    "\n",
    "def process_existing_observation(observation):\n",
    "    \"\"\"\n",
    "    Processes an existing observation dictionary by trimming unwanted keys.\n",
    "    \"\"\"\n",
    "    unwanted_observation_keys = [\n",
    "        \"completionStartTime\",\n",
    "        \"metadata\",\n",
    "        \"timeToFirstToken\",\n",
    "        \"createdAt\",\n",
    "        \"usageDetails\",\n",
    "        \"usage\",\n",
    "        \"projectId\",\n",
    "        \"unit\",\n",
    "        \"updatedAt\",\n",
    "        \"version\",\n",
    "        \"parentObservationId\",\n",
    "        \"promptId\",\n",
    "        \"promptName\",\n",
    "        \"promptVersion\",\n",
    "        \"modelId\",\n",
    "        \"inputPrice\",\n",
    "        \"outputPrice\",\n",
    "        \"totalPrice\",\n",
    "        # \"modelParameters\",\n",
    "        \"input\",\n",
    "        \"output\",\n",
    "    ]\n",
    "\n",
    "    # If observation is a dictionary containing observation data\n",
    "    if isinstance(observation, dict):\n",
    "        trimmed_observation = {\n",
    "            k: v for k, v in observation.items() if k not in unwanted_observation_keys\n",
    "        }\n",
    "        return trimmed_observation\n",
    "    return observation\n",
    "\n",
    "\n",
    "def trim_data(data):\n",
    "    \"\"\"\n",
    "    Recursively trims the data structure.\n",
    "    \"\"\"\n",
    "\n",
    "    if isinstance(data, dict):\n",
    "        # Process the current dictionary\n",
    "        unwanted_trace_keys = [\n",
    "            \"release\",\n",
    "            \"version\",\n",
    "            \"user_id\",\n",
    "            \"public\",\n",
    "            \"html_path\",\n",
    "            \"scores\",\n",
    "            \"bookmarked\",\n",
    "            \"projectId\",\n",
    "            \"externalId\",\n",
    "            \"page\",\n",
    "            \"limit\",\n",
    "            \"total_pages\",\n",
    "        ]\n",
    "\n",
    "        # If this is a trace that contains observations, check for fatal errors\n",
    "        if \"observations\" in data:\n",
    "            # Check for SPAN observations with fatal errors before processing\n",
    "            skip_trace = False\n",
    "            for obs in data[\"observations\"]:\n",
    "                if isinstance(obs, dict) and obs.get(\"name\").startswith(\"error\"):\n",
    "                    status_message = obs.get(\"statusMessage\", \"\")\n",
    "                    ob_name = obs.get(\"name\")\n",
    "                    print(f\"SPAN {ob_name}: {status_message}\")\n",
    "\n",
    "                    if \"Fatal error\" in status_message:\n",
    "                        print(f\"Found Fatal error in SPAN observation, skipping trace\")\n",
    "                        skip_trace = True\n",
    "                        skipped_traces.append(data[\"name\"])\n",
    "                        break\n",
    "\n",
    "            if skip_trace:\n",
    "                return None  # Signal to skip this trace\n",
    "\n",
    "        # Create a new dictionary with wanted keys and recursively process values\n",
    "        trimmed_data = {}\n",
    "        for key, value in data.items():\n",
    "            if key not in unwanted_trace_keys:\n",
    "                if key == \"observations\":\n",
    "                    # Special handling for observations\n",
    "                    trimmed_data[key] = [\n",
    "                        process_existing_observation(obs) for obs in value\n",
    "                    ]\n",
    "                elif isinstance(value, (dict, list)):\n",
    "                    # Recursively process nested structures\n",
    "                    trimmed_data[key] = trim_data(value)\n",
    "                else:\n",
    "                    trimmed_data[key] = value\n",
    "\n",
    "        return trimmed_data\n",
    "\n",
    "    elif isinstance(data, list):\n",
    "        # Recursively process each item in the list\n",
    "        processed_items = []\n",
    "        for item in data:\n",
    "            processed_item = trim_data(item)\n",
    "            if processed_item is not None:  # Only add items that weren't filtered out\n",
    "                processed_items.append(processed_item)\n",
    "        return processed_items\n",
    "\n",
    "    else:\n",
    "        # Return non-dict, non-list values as is\n",
    "        return data\n",
    "\n",
    "\n",
    "def read_and_trim_data(session_id_list, raw_export_dir, trimmed_export_dir):\n",
    "    \"\"\"\n",
    "    Reads complete data from JSON files, trims the data, and saves the trimmed data to new JSON files.\n",
    "    \"\"\"\n",
    "    os.makedirs(trimmed_export_dir, exist_ok=True)\n",
    "\n",
    "    for session_id in session_id_list:\n",
    "        try:\n",
    "            if session_id.startswith(\"da0a\"):\n",
    "                session_id = \"phi4_\" + session_id\n",
    "            # Read raw data\n",
    "            if \"tpsg\" in session_id:\n",
    "                session_id_ = session_id.replace(\"tpsg\", \"tpusg\")\n",
    "            else:\n",
    "                session_id_ = session_id\n",
    "            raw_path = os.path.join(raw_export_dir, f\"raw_{session_id_}.json\")\n",
    "            with open(raw_path, \"r\") as f:\n",
    "                data = json.load(f)\n",
    "\n",
    "            # Process and trim the data\n",
    "            trimmed_data = trim_data(data)\n",
    "\n",
    "            # If the entire data was filtered out (unlikely but possible)\n",
    "            if trimmed_data is None:\n",
    "                print(\n",
    "                    f\"All traces in session {session_id} were filtered due to fatal errors\"\n",
    "                )\n",
    "                continue\n",
    "\n",
    "            # Save trimmed data\n",
    "            if \"tpsg\" in session_id:\n",
    "                session_id_ = session_id.replace(\"tpsg\", \"tpusg\")\n",
    "            else:\n",
    "                session_id_ = session_id\n",
    "            trimmed_path = os.path.join(\n",
    "                trimmed_export_dir, f\"trimmed_{session_id_}.json\"\n",
    "            )\n",
    "            with open(trimmed_path, \"w\") as f:\n",
    "                json.dump(trimmed_data, f, indent=2)\n",
    "\n",
    "            print(\n",
    "                f\"Successfully processed and saved trimmed data for session {session_id}\"\n",
    "            )\n",
    "\n",
    "            # Optional: Verify trimming worked\n",
    "            # print(f\"Verifying trimmed data for session {session_id}...\")\n",
    "            # verify_trimming(trimmed_path)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing session {session_id}: {str(e)}\")\n",
    "\n",
    "\n",
    "def verify_trimming(trimmed_path):\n",
    "    \"\"\"\n",
    "    Verifies that the trimmed data doesn't contain unwanted keys.\n",
    "    \"\"\"\n",
    "    with open(trimmed_path, \"r\") as f:\n",
    "        trimmed_data = json.load(f)\n",
    "\n",
    "    unwanted_keys = [\n",
    "        \"release\",\n",
    "        \"version\",\n",
    "        \"user_id\",\n",
    "        \"public\",\n",
    "        \"html_path\",\n",
    "        \"scores\",\n",
    "        \"bookmarked\",\n",
    "        \"projectId\",\n",
    "        \"externalId\",\n",
    "        \"page\",\n",
    "        \"limit\",\n",
    "        \"total_pages\",\n",
    "        \"completionStartTime\",\n",
    "        \"metadata\",\n",
    "        \"usageDetails\",\n",
    "        \"timeToFirstToken\",\n",
    "        \"createdAt\",\n",
    "        \"completionTokens\",\n",
    "        \"promptTokens\",\n",
    "        \"projectId\",\n",
    "        \"unit\",\n",
    "        \"updatedAt\",\n",
    "        \"version\",\n",
    "        # \"statusMessage\",\n",
    "        \"parentObservationId\",\n",
    "        \"promptId\",\n",
    "        \"promptName\",\n",
    "        \"promptVersion\",\n",
    "        \"modelId\",\n",
    "        \"inputPrice\",\n",
    "        \"outputPrice\",\n",
    "        \"totalPrice\",\n",
    "        \"calculatedInputCost\",\n",
    "        \"calculatedOutputCost\",\n",
    "        \"calculatedTotalCost\",\n",
    "    ]\n",
    "\n",
    "    def check_keys(obj):\n",
    "        if isinstance(obj, dict):\n",
    "            for key in obj.keys():\n",
    "                if key in unwanted_keys:\n",
    "                    print(f\"Warning: Found unwanted key '{key}' in trimmed data\")\n",
    "            for value in obj.values():\n",
    "                check_keys(value)\n",
    "        elif isinstance(obj, list):\n",
    "            for item in obj:\n",
    "                check_keys(item)\n",
    "\n",
    "    check_keys(trimmed_data)\n",
    "    print(\"Verification complete\")\n",
    "\n",
    "\n",
    "# Usage example:\n",
    "read_and_trim_data(session_id_list, raw_export_dir, raw_export_dir)\n",
    "print(f\"Total {len(skipped_traces)} traces skipped. They are {skipped_traces}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Generate CSV files from JSON\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing session codestral_3adb_psg_batch, simple id codestral_3adb. Look for /Users/hann/Projects/reference-benchmark-tinyml_llm/data_analysis/2025/08.08/raw_export/trimmed_codestral_3adb_psg_batch.json\n",
      "/Users/hann/Projects/reference-benchmark-tinyml_llm/data_analysis/2025/08.08/processed_data/codestral_3adb/clean_codestral_3adb_psg_batch.csv\n",
      "Successfully saved CSV to: /Users/hann/Projects/reference-benchmark-tinyml_llm/data_analysis/2025/08.08/processed_data/codestral_3adb/clean_codestral_3adb_psg_batch.csv\n"
     ]
    }
   ],
   "source": [
    "import traceback\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from dateutil import parser\n",
    "\n",
    "\n",
    "def json_to_csv(session_id):\n",
    "    \"\"\"\n",
    "    Convert JSON trace data to CSV format with aggregated metrics.\n",
    "\n",
    "    Args:\n",
    "        session_id (str): Identifier for the session to process\n",
    "    \"\"\"\n",
    "\n",
    "    def extract_observation_details(observations, trace_id):\n",
    "        \"\"\"Extract and aggregate metrics from observations\"\"\"\n",
    "        metrics = {\n",
    "            \"status\": None,\n",
    "            \"latency\": 0,\n",
    "            \"total_tokens\": 0,\n",
    "            \"prompt_tokens\": 0,\n",
    "            \"completion_tokens\": 0,\n",
    "            \"total_cost\": 0,\n",
    "            \"input_cost\": 0,\n",
    "            \"output_cost\": 0,\n",
    "            \"parameters\": set(),\n",
    "        }\n",
    "\n",
    "        # Process GENERATION observations\n",
    "        for obs in (o for o in observations if o[\"type\"] == \"GENERATION\"):\n",
    "            metrics[\"total_tokens\"] += obs[\"totalTokens\"]\n",
    "            metrics[\"prompt_tokens\"] += obs[\"promptTokens\"]\n",
    "            metrics[\"completion_tokens\"] += obs[\"completionTokens\"]\n",
    "            metrics[\"latency\"] += obs[\"latency\"]\n",
    "            for key, value in obs[\"modelParameters\"].items():\n",
    "                metrics[\"parameters\"].add(key + \":\" + value)\n",
    "\n",
    "            # Add costs if present\n",
    "            for cost_type in [\"Total\", \"Input\", \"Output\"]:\n",
    "                key = f\"calculated{cost_type}Cost\"\n",
    "                metric_key = cost_type.lower() + \"_cost\"\n",
    "                if obs.get(key) is not None:\n",
    "                    metrics[metric_key] += obs[key]\n",
    "        if len(metrics[\"parameters\"]) == 0:\n",
    "            metrics[\"parameters\"] = \"N/A\"\n",
    "        # Process SPAN observations for status\n",
    "        status_indicators = [\n",
    "            obs[\"name\"]\n",
    "            for obs in observations\n",
    "            if obs[\"type\"] == \"SPAN\" and \"start_\" not in obs[\"name\"]\n",
    "        ]\n",
    "\n",
    "        #  if later than 2025-05-19, use status_signal_from_output\n",
    "        if datetime.now() > datetime(2025, 5, 19):\n",
    "            pass\n",
    "        else:\n",
    "            # Determine status\n",
    "            success_signals = sum(\"end_\" in name for name in status_indicators)\n",
    "            failure_signals = sum(\n",
    "                \"failure_signal\" in name for name in status_indicators\n",
    "            )\n",
    "\n",
    "            if success_signals + failure_signals > 1:\n",
    "                raise ValueError(\n",
    "                    f\"Multiple status indicators found in trace {trace_id}\"\n",
    "                )\n",
    "\n",
    "            metrics[\"status\"] = (\n",
    "                \"success\"\n",
    "                if success_signals\n",
    "                else \"failure\" if failure_signals else \"unknown\"\n",
    "            )\n",
    "\n",
    "        metrics[\"prompt_cost\"] = metrics.pop(\"input_cost\")\n",
    "        metrics[\"completion_cost\"] = metrics.pop(\"output_cost\")\n",
    "        metrics[\"latency\"] = round(metrics[\"latency\"] / 1000, 2)\n",
    "        return metrics\n",
    "\n",
    "    def cal_time(trace):\n",
    "        time_diff = datetime.fromisoformat(\n",
    "            trace[\"updatedAt\"].replace(\"Z\", \"+00:00\")\n",
    "        ) - datetime.fromisoformat(trace[\"createdAt\"].replace(\"Z\", \"+00:00\"))\n",
    "        seconds_diff = time_diff.total_seconds()\n",
    "        return seconds_diff\n",
    "\n",
    "    try:\n",
    "\n",
    "        if session_id.startswith(\"da0a\"):\n",
    "            session_id = \"phi4_\" + session_id\n",
    "        simple_session_id = session_id.rsplit(\"_\", 2)[0]\n",
    "\n",
    "        \n",
    "        # Load JSON data\n",
    "        if \"tpsg\" in session_id:\n",
    "                session_id_ = session_id.replace(\"tpsg\", \"tpusg\")\n",
    "        else:\n",
    "                session_id_ = session_id\n",
    "        trimmed_path = os.path.join(raw_export_dir, f\"trimmed_{session_id_}.json\")\n",
    "        print(\n",
    "            f\"Processing session {session_id}, simple id {simple_session_id}. Look for {trimmed_path}\"\n",
    "        )\n",
    "        with open(trimmed_path, \"r\") as file:\n",
    "            traces = json.load(file)[\"data\"]\n",
    "\n",
    "        # Process traces\n",
    "        rows = [\n",
    "            {\n",
    "                \"num_run\": trace[\"metadata\"][\"num_run\"],\n",
    "                \"name\": trace[\"name\"],\n",
    "                \"trace_id\": trace[\"id\"],\n",
    "                \"batch_id\": trace[\"session_id\"],\n",
    "                # \"latency\": cal_time(trace),\n",
    "                # \"latency\": round(trace[\"latency\"], 2),\n",
    "                **extract_observation_details(\n",
    "                    trace[\"observations\"],\n",
    "                    trace[\"id\"],\n",
    "                ),\n",
    "                \"status\": (\n",
    "                    \"failure\"\n",
    "                    if trace[\"output\"][\"status\"].lower() == \"failed\"\n",
    "                    else \"success\"\n",
    "                ),\n",
    "                \"tags\": trace[\"tags\"],\n",
    "                \"timestamp\": int(parser.isoparse(trace[\"timestamp\"]).timestamp()),\n",
    "            }\n",
    "            for trace in traces\n",
    "        ]\n",
    "        # print(rows)\n",
    "        # print(rows)\n",
    "        # Create and save DataFrame\n",
    "        df = pd.DataFrame(rows).sort_values(\"num_run\")\n",
    "\n",
    "        output_dir = os.path.join(processed_data_dir, f\"{simple_session_id}\")\n",
    "        if not os.path.exists(output_dir):\n",
    "            os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "        output_path = os.path.join(output_dir, f\"clean_{session_id_}.csv\")\n",
    "\n",
    "        print(output_path)\n",
    "        df.to_csv(output_path, index=False)\n",
    "        print(f\"Successfully saved CSV to: {output_path}\")\n",
    "\n",
    "    except FileNotFoundError as e:\n",
    "        print(\n",
    "            f\"FileNotFoundError: For session {session_id} not found. Looked for {trimmed_path}\\nError info: \\n{e}\\n\\nTraceback: {traceback.format_exc()}\"\n",
    "        )\n",
    "    except json.JSONDecodeError:\n",
    "        print(f\"Error: Invalid JSON format in input file for session {session_id}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing session {session_id}: {str(e)}\")\n",
    "\n",
    "\n",
    "# Example usage\n",
    "for session_id in session_id_list:\n",
    "    json_to_csv(session_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code below is archived\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"\"\"Simply calculate success rate\"\"\"\n",
    "\n",
    "\n",
    "# def cal_success_rate(session_id):\n",
    "\n",
    "#     end_signal_count = 0\n",
    "#     failure_signal_count = 0\n",
    "#     # Function to print the name of each observation\n",
    "#     with open(f\"{raw_export_dir}/trimmed_{session_id}.json\", \"r\") as file:\n",
    "#         data = json.load(file)[\"data\"]\n",
    "#     for i in data:\n",
    "\n",
    "#         observations = i[\"observations\"]\n",
    "\n",
    "#         for observation in observations:\n",
    "#             # print(type(observation))\n",
    "#             for key, value in observation.items():\n",
    "#                 # print(f\"{key}: {value}\")\n",
    "#                 for key, value in value.items():\n",
    "#                     # print(f\"{key}: {value}\")\n",
    "#                     if key == \"name\":\n",
    "#                         if \"end_\" in value:\n",
    "\n",
    "#                             end_signal_count += 1\n",
    "#                         if \"failure_signal\" in value:\n",
    "\n",
    "#                             failure_signal_count += 1\n",
    "\n",
    "#     print(f\"Session ID: {session_id}\")\n",
    "#     total_count = end_signal_count + failure_signal_count\n",
    "#     if total_count > 0:\n",
    "#         success_rate = end_signal_count / total_count\n",
    "#         print(f\"Success rate: {success_rate:.4f}\")\n",
    "#     else:\n",
    "#         print(\"Success rate: N/A (no signals found)\")\n",
    "#     print(f\"Passed:\\t{end_signal_count}\\nFailed:\\t{failure_signal_count}\")\n",
    "#     print(\n",
    "#         \"\"\n",
    "#         if total_count == 30\n",
    "#         else \"Number of ending signals does not match the expected number!\"\n",
    "#     )\n",
    "#     print(\"-\" * 50)\n",
    "\n",
    "\n",
    "# for session_id in session_id_list:\n",
    "#     cal_success_rate(session_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def cal_time(start_time, end_time):\n",
    "#     time_diff = datetime.fromisoformat(\n",
    "#         end_time.replace(\"Z\", \"+00:00\")\n",
    "#     ) - datetime.fromisoformat(start_time.replace(\"Z\", \"+00:00\"))\n",
    "#     seconds_diff = time_diff.total_seconds()\n",
    "#     return seconds_diff\n",
    "\n",
    "\n",
    "# print(cal_time(\"2025-01-15T03:31:56.150000+00:00\", \"2025-01-15T03:32:59.384Z\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"\"\"Print the complete structure of exported json file\"\"\"\n",
    "# def print_keys(d, parent_key=''):\n",
    "#     if isinstance(d, dict):\n",
    "#         for key, value in d.items():\n",
    "#             full_key = f\"{parent_key}.{key}\" if parent_key else key\n",
    "#             print(full_key)\n",
    "#             print_keys(value, full_key)\n",
    "#     elif isinstance(d, list):\n",
    "#         for i, item in enumerate(d):\n",
    "#             full_key = f\"{parent_key}[{i}]\"\n",
    "#             print_keys(item, full_key)\n",
    "\n",
    "# # Load JSON data from a file\n",
    "# with open('fetch_traces_response.json', 'r') as file:\n",
    "#     data = json.load(file)['data'][0]\n",
    "# # Print all keys\n",
    "# print_keys(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1747226053\n",
      "1747226053.1\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "from dateutil import parser\n",
    "\n",
    "timestamp_str = \"2025-05-14T12:34:13.100000+00:00\"\n",
    "dt = parser.isoparse(\n",
    "    timestamp_str\n",
    ")  # Or datetime.fromisoformat(timestamp_str) if no timezone offset\n",
    "unix_ts = int(dt.timestamp())\n",
    "\n",
    "print(unix_ts)  # This will print the integer Unix timestamp\n",
    "print(datetime.fromisoformat(timestamp_str).timestamp())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datasci2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

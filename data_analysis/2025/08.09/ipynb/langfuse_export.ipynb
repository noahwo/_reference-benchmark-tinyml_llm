{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setting up\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ref: https://langfuse.com/docs/query-traces\n",
    "import os\n",
    "import json\n",
    "from langfuse import Langfuse\n",
    "import json\n",
    "import os\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "LOCAL_HOST = True\n",
    "\n",
    "\"\"\"Define session_id\"\"\"\n",
    "# session_id=\"qwen2.5-coder_f4d4_dp_batch\"\n",
    "session_id_list = [\n",
    "    # \"qwen2.5-coder:32b_4e11_tpsg_batch\",\n",
    "    # \"qwen2.5-coder:32b_ae24_tpsg_batch\"\n",
    "    \"codestral_62f3_psg_batch\",\n",
    " \n",
    "]\n",
    "\n",
    "\n",
    "\"\"\"Define paths\"\"\"\n",
    " \n",
    "parent_dir = os.path.dirname(os.getcwd())\n",
    "\n",
    " \n",
    "# date = os.path.basename(parent_dir)\n",
    "tex_dir = os.path.join(parent_dir, \"tex\")\n",
    "processed_data_dir = os.path.join(parent_dir, \"processed_data\")\n",
    "raw_export_dir = os.path.join(parent_dir, \"raw_export\")\n",
    "ipynb_dir = os.path.join(parent_dir, \"ipynb\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Export raw data\n",
    "\n",
    "Langfuse added a limit of 20 API invocations per minute. https://langfuse.com/faq/all/api-limits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching traces for session codestral_62f3_psg_batch...\n",
      "Fetching observation data for time-12-07-37-894078_chatcmpl-c6823ffc-02c8-488a-8c3c-ca4879513a55...\n",
      "Fetching observation data for time-12-07-56-579563_chatcmpl-518b2ec9-7891-43c5-b67d-09f4f04acbc3...\n",
      "Fetching observation data for time-12-08-04-611891_chatcmpl-a2c7167e-b74a-481f-b349-e9bf5df01c59...\n",
      "Fetching observation data for time-12-08-16-461286_chatcmpl-2a644ceb-e882-4d62-9544-b23a55a82f14...\n",
      "Fetching observation data for time-12-08-27-001051_chatcmpl-f98b0bab-493a-47fa-b460-9286f53bba2f...\n",
      "Fetching observation data for b1fa6aba-daf7-4443-a6cb-9426442ac75b...\n",
      "Fetching observation data for time-12-06-14-177153_chatcmpl-beb9754e-0f3d-44ed-9aa3-89c0b805777c...\n",
      "Fetching observation data for time-12-06-32-857182_chatcmpl-55e31f0a-53fe-43b1-b8b5-1adc0e560252...\n",
      "Fetching observation data for time-12-06-43-845425_chatcmpl-04a02ec7-b261-423a-a00a-5c7a0d767fcf...\n",
      "Fetching observation data for time-12-07-07-184242_chatcmpl-254e92e5-3cdb-49d6-8c6e-5d57b51dbf76...\n",
      "Fetching observation data for time-12-07-15-858970_chatcmpl-a4d0a55c-9b1f-4891-a716-f9dd3b0a7e23...\n",
      "Fetching observation data for 167724fc-fc97-4856-8282-abdd9da5f21a...\n",
      "Fetching observation data for time-12-04-54-226867_chatcmpl-0424c34a-9833-4f4a-b372-fabe85338cd7...\n",
      "Fetching observation data for time-12-05-12-900858_chatcmpl-bb4c7455-9bd3-48ec-9d4c-f04dfc92ac86...\n",
      "Fetching observation data for time-12-05-24-455010_chatcmpl-6dc66145-105c-4658-ab12-83e800e3bcc6...\n",
      "Fetching observation data for time-12-05-41-680286_chatcmpl-2f059388-0c1c-471e-9e73-ead85446262e...\n",
      "Fetching observation data for time-12-05-51-562107_chatcmpl-a3b95469-6f23-4bd7-b860-4651d58c4aae...\n",
      "Fetching observation data for 5766e38b-876f-4b24-8208-56da288d3c1b...\n",
      "Fetching observation data for time-12-03-39-626703_chatcmpl-59f7b2ba-caef-424d-b846-ab5c8479727f...\n",
      "Fetching observation data for time-12-03-58-306984_chatcmpl-40a3ba0f-ba7f-42fe-959b-4047d448bd82...\n",
      "Fetching observation data for time-12-04-09-282657_chatcmpl-63c4eb88-3b6d-4b27-bb2b-c11c01ec88f2...\n",
      "Fetching observation data for time-12-04-31-637792_chatcmpl-f65c2764-62ae-46b8-bb93-567d4ffb0488...\n",
      "Fetching observation data for time-12-04-37-541764_chatcmpl-1274a6da-81b7-49e0-a712-05b82c674cad...\n",
      "Fetching observation data for 52d29feb-aade-43c8-bc15-72740bf9f6f6...\n",
      "Fetching observation data for time-12-02-15-039471_chatcmpl-84b06a7b-c855-480f-8fd2-059477958808...\n",
      "Fetching observation data for time-12-02-33-746855_chatcmpl-ab5d7c78-d60e-4145-9e37-347450cb12a7...\n",
      "Fetching observation data for time-12-02-44-741258_chatcmpl-1aefc457-4d2c-4611-9699-f3c7fa75f6ed...\n",
      "Fetching observation data for time-12-02-59-152572_chatcmpl-a628f970-b847-4345-ad09-c2a6537126d9...\n",
      "Fetching observation data for time-12-03-22-286321_chatcmpl-82312e4a-27c9-46f4-9a07-cd956437cb1b...\n",
      "Fetching observation data for f79a7c56-74a6-46b3-9eb2-d1b8d465d1d1...\n",
      "Fetching observation data for time-12-00-59-352995_chatcmpl-b8c3928f-15fb-484d-99b2-459b4d492c3f...\n",
      "Fetching observation data for time-12-01-17-481536_chatcmpl-99022f09-0335-4e94-9fca-78ec58a747f3...\n",
      "Fetching observation data for time-12-01-28-617746_chatcmpl-128c2940-741c-4f00-8fd0-424a674b9323...\n",
      "Fetching observation data for time-12-01-43-564751_chatcmpl-9a346d4d-4503-48da-a3de-fc5ee885e71c...\n",
      "Fetching observation data for time-12-01-53-448270_chatcmpl-e5ea637d-dc09-4128-b6bb-4d39993ed099...\n",
      "Fetching observation data for 3b64cb38-5ad0-4a1e-b72e-1f7bf3bac109...\n",
      "Fetching observation data for time-11-59-47-562262_chatcmpl-bb677ca9-30f6-4d5d-adb1-3518d158d84d...\n",
      "Fetching observation data for time-12-00-05-677684_chatcmpl-4babade6-9f79-4267-baca-d35ab67e58c5...\n",
      "Fetching observation data for time-12-00-14-267251_chatcmpl-58456ee9-b201-4011-bff2-2aa12e9ca0b3...\n",
      "Fetching observation data for time-12-00-35-687725_chatcmpl-45404376-657e-4e9f-aec7-2891849c6300...\n",
      "Fetching observation data for time-12-00-40-298341_chatcmpl-c7214def-e037-4a3a-b03c-23361400f4f3...\n",
      "Fetching observation data for d25ba585-2a70-4b30-a0a4-202aa720a3e5...\n",
      "Fetching observation data for time-11-58-36-635497_chatcmpl-0311fddd-536e-4330-b079-92c85129b942...\n",
      "Fetching observation data for time-11-58-55-536493_chatcmpl-244c2913-223a-484f-a565-12e7cfefb7e4...\n",
      "Fetching observation data for time-11-59-06-542414_chatcmpl-aaf9978e-2071-412e-a2d4-1656749ddeb5...\n",
      "Fetching observation data for time-11-59-18-473533_chatcmpl-ce713763-e0f2-4f9b-9dd5-50d3fb32286d...\n",
      "Fetching observation data for time-11-59-30-271260_chatcmpl-489966b1-5cda-4d74-aced-3cd4c3f9c163...\n",
      "Fetching observation data for 4ec555d5-15d0-488f-882f-27feac6ef82a...\n",
      "Fetching observation data for time-11-57-13-669470_chatcmpl-7547899d-97ac-47cf-9c5b-5b2465a90bbb...\n",
      "Fetching observation data for time-11-57-31-794566_chatcmpl-e2ba7ad9-d9d8-4e12-9538-bb56db748d5c...\n",
      "Fetching observation data for time-11-57-42-932303_chatcmpl-444fdac9-f4c0-487c-b8e0-2c83112d473a...\n",
      "Fetching observation data for time-11-57-51-462659_chatcmpl-3ead0b12-7b5d-465d-a1fa-05e15ae0dd00...\n",
      "Fetching observation data for time-11-58-06-358527_chatcmpl-a234dac3-90f5-41fb-b511-30e606ac89be...\n",
      "Fetching observation data for 820fce15-8096-40fe-ac31-b1880f42f1b7...\n",
      "Fetching observation data for time-11-55-59-932668_chatcmpl-ceebb961-8606-408f-9119-8f4b503e04c7...\n",
      "Fetching observation data for time-11-56-18-631832_chatcmpl-29312cab-c874-404b-9bc9-8c4cc872c8a9...\n",
      "Fetching observation data for time-11-56-26-643173_chatcmpl-a353d3a8-5bad-4bf4-8f7d-c6512104b835...\n",
      "Fetching observation data for time-11-56-42-434161_chatcmpl-b84710b2-873a-42f3-b9f2-ef87529fa1f9...\n",
      "Fetching observation data for time-11-56-50-878190_chatcmpl-7fc0fc02-9d68-4838-99cf-d26011bfcb45...\n",
      "Fetching observation data for 53508d3f-7155-48ee-a36d-36e123227181...\n",
      "Fetching observation data for time-11-54-40-271919_chatcmpl-6e8fe066-6050-4d39-b8dc-7631e634e313...\n",
      "Fetching observation data for time-11-54-58-964729_chatcmpl-ba415dc1-3e1e-4650-8109-b5625613da26...\n",
      "Fetching observation data for time-11-55-09-946096_chatcmpl-09c9f6b9-ce0b-4999-9082-e2453f91f934...\n",
      "Fetching observation data for time-11-55-26-429118_chatcmpl-f91ce2a2-4597-4ba2-901f-031a71b7d127...\n",
      "Fetching observation data for time-11-55-36-037122_chatcmpl-f3a96d67-7c30-4933-9c69-eae4829dd878...\n",
      "Fetching observation data for ab0a5854-afff-460f-94bd-9fc71e17f529...\n",
      "Fetching observation data for time-11-53-26-323645_chatcmpl-4faacdda-b5a7-409c-9264-535b902364f3...\n",
      "Fetching observation data for time-11-53-45-015112_chatcmpl-a50cfd78-e43b-448a-a30b-985e3039771a...\n",
      "Fetching observation data for time-11-53-53-038187_chatcmpl-1aceadf5-ffc9-47fc-b69f-61925da56d34...\n",
      "Fetching observation data for time-11-54-02-236503_chatcmpl-8dffcec5-9bcc-49f7-87af-73206993b42c...\n",
      "Fetching observation data for time-11-54-18-154619_chatcmpl-9d12bb4f-87cf-4084-af77-7ab7607da9c2...\n",
      "Fetching observation data for 1581f2f0-5cc9-4208-99dc-fc3d109d229a...\n",
      "Fetching observation data for time-11-52-13-630213_chatcmpl-1c5de990-7034-4759-b921-f32db85e9bd7...\n",
      "Fetching observation data for time-11-52-32-295872_chatcmpl-54745f3c-a8d5-445b-bc18-55d4cdfa2bde...\n",
      "Fetching observation data for time-11-52-43-278630_chatcmpl-9f52afc2-cd52-4228-b292-88016a07e965...\n",
      "Fetching observation data for time-11-52-54-267079_chatcmpl-63cab9da-b96d-4eb4-b05f-f14fb970bf69...\n",
      "Fetching observation data for time-11-53-12-164952_chatcmpl-95311c2f-8a58-4008-9b00-f40a838195d4...\n",
      "Fetching observation data for 894c5cf3-48fc-4fee-b0c8-748ffe283ce1...\n",
      "Fetching observation data for time-11-50-56-927916_chatcmpl-dc431974-c238-4504-8e93-e5f4934b034f...\n",
      "Fetching observation data for time-11-51-15-013085_chatcmpl-850de3c8-9e92-45be-8911-bde5015f2b4c...\n",
      "Fetching observation data for time-11-51-26-140119_chatcmpl-6845225f-5831-4db5-8054-dea5e54432f2...\n",
      "Fetching observation data for time-11-51-42-704523_chatcmpl-7e2339a8-54bb-42ae-b387-e02f6599c6ae...\n",
      "Fetching observation data for time-11-51-56-078207_chatcmpl-32e7f37d-b99a-42cb-9496-4f9df54c4fa5...\n",
      "Fetching observation data for 37a814bd-de50-4bfa-a9eb-378db307ee19...\n",
      "Fetching observation data for time-11-49-28-062621_chatcmpl-99884fae-5b53-4fc0-ae54-c6218c775618...\n",
      "Fetching observation data for time-11-49-46-747762_chatcmpl-503c17b1-4f26-4111-b9a7-dab3f4e86bad...\n",
      "Fetching observation data for time-11-49-57-723568_chatcmpl-b494d7c1-bd44-45d9-b861-fec4c0ddeed2...\n",
      "Fetching observation data for time-11-50-11-024576_chatcmpl-b147a378-60db-48b9-a317-8cc1650eabbe...\n",
      "Fetching observation data for time-11-50-26-423097_chatcmpl-175478ed-1522-4c8f-8866-d449a46696dc...\n",
      "Fetching observation data for 34bfecce-3cda-4a15-9247-1a3d7ed2a76f...\n",
      "Fetching observation data for time-11-48-04-168698_chatcmpl-2ee2a145-1959-4edd-8d66-551a150a4398...\n",
      "Fetching observation data for time-11-48-22-870116_chatcmpl-e73a5cb9-bf8d-4b88-b4fc-9ac6a416e46a...\n",
      "Fetching observation data for time-11-48-33-866278_chatcmpl-e2a6f262-bfb5-4dbc-95f6-acce33a67c34...\n",
      "Fetching observation data for time-11-48-56-619674_chatcmpl-63c10c8e-485c-4184-9f5d-836c9c3b7bbd...\n",
      "Fetching observation data for time-11-49-06-030511_chatcmpl-fae4da95-18a6-4eb9-ad90-02dba0b5f10b...\n",
      "Fetching observation data for 55b60cff-5f36-4c19-a632-6f22acf561ca...\n",
      "Fetching observation data for time-11-46-39-282652_chatcmpl-87623c99-4b61-4c87-9c57-70226ccb68a4...\n",
      "Fetching observation data for time-11-46-57-987669_chatcmpl-6bf69cbe-53ba-48a2-af43-f14948bf7595...\n",
      "Fetching observation data for time-11-47-08-973925_chatcmpl-dcd94e5b-dc56-4df1-8ac7-f37ca057b593...\n",
      "Fetching observation data for time-11-47-21-141306_chatcmpl-6adda989-a736-48bb-bdc7-b177f81c1a30...\n",
      "Fetching observation data for time-11-47-39-819553_chatcmpl-8ec7b62e-a32b-4dd3-bfda-29c35e618712...\n",
      "Fetching observation data for ce5e4ff7-f165-4164-8cc0-84789d06676d...\n",
      "Fetching observation data for time-11-45-23-315126_chatcmpl-240ef964-e842-4451-b602-f2d2ee7eb5de...\n",
      "Fetching observation data for time-11-45-41-427873_chatcmpl-0b7fdc31-79dd-4757-97fd-c285fffbc0c6...\n",
      "Fetching observation data for time-11-45-52-578567_chatcmpl-6bb88c3d-8230-4dbf-b79b-9ffa3671d796...\n",
      "Fetching observation data for time-11-46-07-180306_chatcmpl-5cfd892c-9924-4adc-9c53-46dbf34e9180...\n",
      "Fetching observation data for time-11-46-24-270785_chatcmpl-c237437d-474b-4a7e-bc43-d1d76090e071...\n",
      "Fetching observation data for bca46757-4819-4bd8-9a9f-b7aae3babcd3...\n",
      "Fetching observation data for time-11-44-10-630247_chatcmpl-d93d03c7-be9d-4386-bd3e-e3f62231206d...\n",
      "Fetching observation data for time-11-44-29-415666_chatcmpl-ee45bb0d-cb76-4692-8522-ca7464af258c...\n",
      "Fetching observation data for time-11-44-40-968964_chatcmpl-a82706a5-7a1d-4080-a62d-56af911edf21...\n",
      "Fetching observation data for time-11-44-55-689311_chatcmpl-f7189768-c7ee-419a-aef5-29e8dfdc87a2...\n",
      "Fetching observation data for time-11-45-09-398100_chatcmpl-05fb35ad-bab9-4de6-8ad7-45f3ccb4241d...\n",
      "Fetching observation data for 1f1b8f92-d825-4ed2-b1e3-8d8b49828358...\n",
      "Fetching observation data for time-11-42-57-827640_chatcmpl-869328cf-b6bf-4d04-b950-01818e932684...\n",
      "Fetching observation data for time-11-43-16-516996_chatcmpl-15834eb4-b316-4021-b731-12145ea4f89d...\n",
      "Fetching observation data for time-11-43-28-240971_chatcmpl-b43d9b35-9341-433a-8f32-26bb6d2bd54f...\n",
      "Fetching observation data for time-11-43-37-236156_chatcmpl-88bcbea5-7e1f-465b-98e2-9f46dddfa319...\n",
      "Fetching observation data for time-11-43-52-724235_chatcmpl-479c8c5f-e682-4865-be53-604fe13cf1ca...\n",
      "Fetching observation data for a60bfd32-4092-483b-ab5b-b91a87dcd997...\n",
      "Fetching observation data for time-11-41-35-008220_chatcmpl-3ca47724-e553-4000-bbe6-b48e10ed0f5e...\n",
      "Fetching observation data for time-11-41-53-731530_chatcmpl-47b87e44-d5e6-4e39-9d31-d5b3dc72e59d...\n",
      "Fetching observation data for time-11-42-04-723414_chatcmpl-12d0d527-ee75-4820-b19c-f8d2af0f8e84...\n",
      "Fetching observation data for time-11-42-17-292442_chatcmpl-1cb36a0c-921d-4b59-8765-d1aced6cf38b...\n",
      "Fetching observation data for time-11-42-29-047513_chatcmpl-52d1aaab-e217-4f5e-ba16-aebd1cc6ad57...\n",
      "Fetching observation data for dd198ebb-0e86-48e4-8bf7-8b63a7cd2125...\n",
      "Fetching observation data for time-11-40-19-173495_chatcmpl-8c967fe9-5390-4f19-a1f3-e932cd6a989c...\n",
      "Fetching observation data for time-11-40-37-311451_chatcmpl-1a2fa477-4b65-46ad-9695-95b7219a685f...\n",
      "Fetching observation data for time-11-40-47-698414_chatcmpl-2ae970a5-e0d5-4955-b28c-995bf202d1d2...\n",
      "Fetching observation data for time-11-41-02-517445_chatcmpl-33d354f4-95bc-4184-99cd-9226cc0ebddf...\n",
      "Fetching observation data for time-11-41-16-508642_chatcmpl-47d94a90-22b9-4e17-b087-2317a52dde52...\n",
      "Fetching observation data for e6a5f36a-2995-46cb-9d65-d72f15f4f7fd...\n",
      "Fetching observation data for time-11-39-02-071329_chatcmpl-b8082460-1efa-4281-8cc1-8a918a8d784c...\n",
      "Fetching observation data for time-11-39-20-762828_chatcmpl-7d10ee20-56c7-4b4e-8f25-e12bd008f150...\n",
      "Fetching observation data for time-11-39-28-794161_chatcmpl-4ca99ea1-681d-4341-a301-543e265cb5f7...\n",
      "Fetching observation data for time-11-39-37-435608_chatcmpl-4f0ff8b4-3bef-428d-818a-9e8603ce4c90...\n",
      "Fetching observation data for time-11-39-46-893769_chatcmpl-f78e3e8d-07b4-44cf-a761-60e779b56ac1...\n",
      "Fetching observation data for eca63711-42fb-4562-b8d6-f31c1dd689b1...\n",
      "Fetching observation data for time-11-38-00-205591_chatcmpl-cdf84ccb-a9ee-4add-b8d9-5fb6dfe352ae...\n",
      "Fetching observation data for time-11-38-18-908952_chatcmpl-3ab076a0-298a-469d-ba46-c40975cb6fe2...\n",
      "Fetching observation data for time-11-38-26-920926_chatcmpl-dc863db6-4ff2-40cd-95b2-e4df300b6224...\n",
      "Fetching observation data for time-11-38-31-384496_chatcmpl-1af55b5e-a46e-4ec3-b950-7cab091f40e2...\n",
      "Fetching observation data for time-11-38-44-694495_chatcmpl-ea71cd13-19e8-4751-a8cf-c146e9cbc94b...\n",
      "Fetching observation data for 851a812b-f139-4977-bd3f-433539bbf215...\n",
      "Fetching observation data for time-11-37-13-627237_chatcmpl-de5aac5f-08c6-4878-89f8-da145f805905...\n",
      "Fetching observation data for time-11-37-32-328250_chatcmpl-59d340e2-789b-4c44-9f4c-c918370eaad4...\n",
      "Fetching observation data for time-11-37-43-846527_chatcmpl-57f4d045-67c9-4b3b-839e-342ebbfd640c...\n",
      "Fetching observation data for time-11-36-04-745474_chatcmpl-452c2389-ab83-4aaf-a21f-d2ad4badd9e1...\n",
      "Fetching observation data for time-11-36-23-428080_chatcmpl-9bb2bcb8-9a86-494f-89a9-85c576182512...\n",
      "Fetching observation data for time-11-36-31-440218_chatcmpl-6c237977-73e1-49ab-8a4f-dd1909a0a8f7...\n",
      "Fetching observation data for time-11-36-39-960197_chatcmpl-cd46c3f9-d8b0-42fe-992b-4d263649b2ee...\n",
      "Fetching observation data for time-11-36-49-398111_chatcmpl-8f3a31ab-be5c-4246-9824-06fc1dc24dfe...\n",
      "Fetching observation data for 180ad7e9-4de1-4fdb-a1d7-ee106f5ebf79...\n",
      "Fetching observation data for time-11-34-36-186793_chatcmpl-81b927af-74bd-4189-9d11-a9b4eae4df77...\n",
      "Fetching observation data for time-11-34-54-284463_chatcmpl-3326c1d0-57da-41b5-bb55-76d155c5f753...\n",
      "Fetching observation data for time-11-35-02-165831_chatcmpl-d499ab6c-a89f-4eea-b3d6-74af54e4d9d9...\n",
      "Fetching observation data for time-11-35-20-103837_chatcmpl-46c6f98b-e93b-4526-8382-861561b715ca...\n",
      "Fetching observation data for time-11-35-32-928073_chatcmpl-0f2f82dc-2f90-4f4f-9abb-1541b420c24b...\n",
      "Fetching observation data for cc5e25d2-36b5-4208-9d4c-eee82086ceb6...\n",
      "Fetching observation data for time-11-33-13-427215_chatcmpl-5c16974a-cecc-4c04-ad48-cd85b476f5e3...\n",
      "Fetching observation data for time-11-33-32-138257_chatcmpl-6ad9b379-754a-4492-89cb-7151a353b51f...\n",
      "Fetching observation data for time-11-33-43-123362_chatcmpl-a9792e35-379c-41fd-9fe2-3f5162bd6f5f...\n",
      "Fetching observation data for time-11-33-56-179882_chatcmpl-bbc6585c-d9a3-4867-83e6-214a49a2ad73...\n",
      "Fetching observation data for time-11-34-16-811555_chatcmpl-4c5595d4-4f74-46e1-a477-19fefb92103a...\n",
      "Fetching observation data for 44a2dad0-720f-41f5-9acf-726818acbd79...\n",
      "Fetching observation data for time-11-31-56-556090_chatcmpl-e7b1c5e3-3be1-4a2d-afc9-17ecd36a0745...\n",
      "Fetching observation data for time-11-32-15-273007_chatcmpl-1fdb6a78-f959-4d8b-bff7-cf2dca4b6b72...\n",
      "Fetching observation data for time-11-32-26-832807_chatcmpl-48832521-c904-4553-979e-0b6ddb789f32...\n",
      "Fetching observation data for time-11-32-42-473227_chatcmpl-c1f6ab4f-77a0-47c8-9dd0-474489373665...\n",
      "Fetching observation data for time-11-32-54-339210_chatcmpl-678f1b44-20a9-49bd-9bff-cd07f2e7ff3b...\n",
      "Fetching observation data for bc2652cd-f46f-4c31-acba-c6c653029804...\n",
      "Fetching observation data for time-11-29-42-800082_chatcmpl-4fe18051-bbe9-4265-9167-b5a64e2fa60f...\n",
      "Fetching observation data for time-11-31-02-982028_chatcmpl-0bea2e68-872f-4d4e-895a-fdfd863ec95a...\n",
      "Fetching observation data for time-11-31-17-738090_chatcmpl-805d9c2e-a5a0-4879-84b6-f581e4e04f66...\n",
      "Fetching observation data for time-11-31-28-582240_chatcmpl-9d49b977-d23c-4f0a-b242-820cdc096121...\n",
      "Fetching observation data for time-11-31-39-730516_chatcmpl-3e0be303-9277-426c-82c9-13922d644391...\n",
      "Fetching observation data for 10939135-c78d-4146-8b32-6741b0db3e43...\n",
      "Raw JSON saved to: /Users/hann/Projects/reference-benchmark-tinyml_llm/data_analysis/2025/08.09/raw_export/raw_codestral_62f3_psg_batch.json\n"
     ]
    }
   ],
   "source": [
    "# ALTERNATIVE TO 2.\n",
    "import os\n",
    "import json\n",
    "from time import sleep\n",
    "from langfuse import Langfuse\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "\n",
    "# LANGFUSE_SERVICE_PUBLIC_KEY = \"pk-lf-559a2c0f-ee29-4c32-944c-bf73b5f0ce28\"\n",
    "# LANGFUSE_SERVICE_SECRET_KEY = \"sk-lf-75f8bf7f-a5db-4756-b0dd-d758a2a292c8\"\n",
    "# LANGFUSE_SERVICE_HOST = \"https://langfuse.hann.fi\"\n",
    "\n",
    "\n",
    "if LOCAL_HOST:\n",
    "    langfuse = Langfuse(\n",
    "        secret_key=\"sk-lf-75f8bf7f-a5db-4756-b0dd-d758a2a292c8\",\n",
    "        public_key=\"pk-lf-559a2c0f-ee29-4c32-944c-bf73b5f0ce28\",\n",
    "        host=\"https://langfuse.hann.fi\",\n",
    "    )\n",
    "else:\n",
    "    langfuse = Langfuse(\n",
    "        secret_key=LANGFUSE_SERVICE_SECRET_KEY,\n",
    "        public_key=LANGFUSE_SERVICE_PUBLIC_KEY,\n",
    "        host=LANGFUSE_SERVICE_HOST,\n",
    "    )\n",
    "\n",
    "API_invok_count = 0\n",
    "query_range_num_run = {\"start\": 0, \"end\": 1}\n",
    "\n",
    "\n",
    "class CustomJSONEncoder(json.JSONEncoder):\n",
    "    def __init__(self, *args, LOCAL_HOST=True, **kwargs):\n",
    "        self.LOCAL_HOST = LOCAL_HOST\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "    def default(self, obj):\n",
    "        if isinstance(obj, datetime):\n",
    "            return obj.isoformat()\n",
    "        if hasattr(obj, \"__dict__\"):\n",
    "            data = obj.__dict__.copy()\n",
    "            if \"observations\" in data:\n",
    "                data[\"observations\"] = [\n",
    "                    fetch_observation_data(obs, self.LOCAL_HOST)\n",
    "                    for obs in data[\"observations\"]\n",
    "                ]\n",
    "\n",
    "            return data\n",
    "        return super().default(obj)\n",
    "\n",
    "\n",
    "def fetch_observation_data(observation_id, LOCAL_HOST):\n",
    "    \"\"\"\n",
    "    Fetches observation data from Langfuse and returns its dictionary representation.\n",
    "    \"\"\"\n",
    "    print(f\"Fetching observation data for {observation_id}...\")\n",
    "    global API_invok_count\n",
    "    if API_invok_count >= 0 and not LOCAL_HOST:\n",
    "        print(\"Waiting for 3 seconds to fetch observation data...\")\n",
    "        for _ in tqdm(range(3), desc=\"Progress\", unit=\"s\"):\n",
    "            sleep(1)\n",
    "        API_invok_count = 0\n",
    "\n",
    "    observation_response = langfuse.fetch_observation(observation_id)\n",
    "    API_invok_count += 1\n",
    "\n",
    "    return observation_response.data.dict()\n",
    "\n",
    "\n",
    "def fetch_and_save_complete_data(session_id_list, raw_export_dir, LOCAL_HOST):\n",
    "    \"\"\"\n",
    "    Fetches complete trace data for each session ID and saves it to JSON files.\n",
    "\n",
    "    Parameters:\n",
    "        session_id_list (list): List of session IDs to process.\n",
    "        raw_export_dir (str): Directory path to save raw JSON files.\n",
    "    \"\"\"\n",
    "\n",
    "    def save_complete_data(session_id):\n",
    "        global API_invok_count\n",
    "        if API_invok_count >= 0 and not LOCAL_HOST:\n",
    "            print(\"Waiting for 4 seconds to fetch traces...\")\n",
    "            for _ in tqdm(range(4), desc=\"Progress\", unit=\"s\"):\n",
    "                sleep(1)\n",
    "            API_invok_count = 0\n",
    "\n",
    "        fetch_traces_response = langfuse.fetch_traces(session_id=session_id)\n",
    "        API_invok_count += 1\n",
    "\n",
    "        print(f\"Fetching traces for session {session_id}...\")\n",
    "        # Create directories if they don't exist\n",
    "        os.makedirs(raw_export_dir, exist_ok=True)\n",
    "\n",
    "        # Save complete data to JSON file\n",
    "        # if session_id.startswith(\"da0a\"):\n",
    "        #     session_id = \"phi4_\" + session_id\n",
    "        if \"tpsg\" in session_id:\n",
    "            session_id_ = session_id.replace(\"tpsg\", \"tpusg\")\n",
    "        else:\n",
    "            session_id_ = session_id\n",
    "            \n",
    "        raw_path = os.path.join(raw_export_dir, f\"raw_{session_id_}.json\")\n",
    "        with open(raw_path, \"w\") as f:\n",
    "            json.dump(fetch_traces_response, f, cls=CustomJSONEncoder, indent=2)\n",
    "\n",
    "        print(f\"Raw JSON saved to: {raw_path}\")\n",
    "\n",
    "    for session_id in session_id_list:\n",
    "        save_complete_data(session_id)\n",
    "\n",
    "\n",
    "fetch_and_save_complete_data(session_id_list, raw_export_dir, LOCAL_HOST)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Trim data\n",
    "\n",
    "Here also intercept the runs with fatal errors that need to be excluded from the analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPAN error_30_psg_failure_signal_py_sketch_generator: Failed. Last error: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250809120843_psg_codestral:latest/tmp_20250809120843_psg_codestral:latest.py\", line 28, in <module>\n",
      "    interpreter.set_tensor(input_details[0]['index'], input_data)\n",
      "  File \"/home/wuguangh/.conda/envs/tinyml/lib/python3.10/site-packages/ai_edge_litert/interpreter.py\", line 764, in set_tensor\n",
      "    self._interpreter.SetTensor(tensor_index, value)\n",
      "ValueError: Cannot set tensor: Got value of type FLOAT32 but expected type UINT8 for input 175, name: normalized_input_image_tensor \n",
      "\n",
      "SPAN error_4f_psg_failure_signal_py_sketch_generator: Failed. Last error: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250809120730_psg_codestral:latest/tmp_20250809120730_psg_codestral:latest.py\", line 32, in <module>\n",
      "    input_data = preprocess_frame(frame)\n",
      "NameError: name 'preprocess_frame' is not defined\n",
      "\n",
      "SPAN error_8c_psg_failure_signal_py_sketch_generator: Failed. Last error: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250809120607_psg_codestral:latest/tmp_20250809120607_psg_codestral:latest.py\", line 23, in <module>\n",
      "    image = np.fromfile('path/to/input_image.jpg', dtype=np.uint8)\n",
      "FileNotFoundError: [Errno 2] No such file or directory: 'path/to/input_image.jpg'\n",
      "\n",
      "SPAN error_b5_psg_failure_signal_py_sketch_generator: Failed. Last error: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250809120447_psg_codestral:latest/tmp_20250809120447_psg_codestral:latest.py\", line 21, in <module>\n",
      "    image = np.load(input_path)  # Assuming image is saved as a numpy array\n",
      "  File \"/home/wuguangh/.conda/envs/tinyml/lib/python3.10/site-packages/numpy/lib/npyio.py\", line 462, in load\n",
      "    raise ValueError(\"Cannot load file containing pickled data \"\n",
      "ValueError: Cannot load file containing pickled data when allow_pickle=False\n",
      "\n",
      "SPAN error_f2_psg_failure_signal_py_sketch_generator: Failed. Last error: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250809120332_psg_codestral:latest/tmp_20250809120332_psg_codestral:latest.py\", line 23, in <module>\n",
      "    image = np.load(input_path)  # Assuming image is a numpy array saved as .npy file\n",
      "  File \"/home/wuguangh/.conda/envs/tinyml/lib/python3.10/site-packages/numpy/lib/npyio.py\", line 462, in load\n",
      "    raise ValueError(\"Cannot load file containing pickled data \"\n",
      "ValueError: Cannot load file containing pickled data when allow_pickle=False\n",
      "\n",
      "SPAN error_81_psg_failure_signal_py_sketch_generator: Failed. Last error: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250809120208_psg_codestral:latest/tmp_20250809120208_psg_codestral:latest.py\", line 27, in <module>\n",
      "    interpreter.set_tensor(input_details[0]['index'], input_data)\n",
      "NameError: name 'input_data' is not defined. Did you mean: 'input_path'?\n",
      "\n",
      "SPAN error_74_psg_failure_signal_py_sketch_generator: Failed. Last error: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250809120052_psg_codestral:latest/tmp_20250809120052_psg_codestral:latest.py\", line 30, in <module>\n",
      "    input_data = preprocess_image(input_path)\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250809120052_psg_codestral:latest/tmp_20250809120052_psg_codestral:latest.py\", line 26, in preprocess_image\n",
      "    img = Image.open(image_path).resize((input_details[0]['shape'][1], input_details[0]['shape'][2]))\n",
      "  File \"/home/wuguangh/.conda/envs/tinyml/lib/python3.10/site-packages/PIL/Image.py\", line 3536, in open\n",
      "    raise UnidentifiedImageError(msg)\n",
      "PIL.UnidentifiedImageError: cannot identify image file '/home/wuguangh/Projects/tinyml-autopilot/data/object_detection/sheeps.mp4'\n",
      "\n",
      "SPAN error_bb_psg_failure_signal_py_sketch_generator: Failed. Last error: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250809115940_psg_codestral:latest/tmp_20250809115940_psg_codestral:latest.py\", line 24, in <module>\n",
      "    image = Image.open(input_path).resize((input_details[0]['shape'][1], input_details[0]['shape'][2]))\n",
      "  File \"/home/wuguangh/.conda/envs/tinyml/lib/python3.10/site-packages/PIL/Image.py\", line 3536, in open\n",
      "    raise UnidentifiedImageError(msg)\n",
      "PIL.UnidentifiedImageError: cannot identify image file '/home/wuguangh/Projects/tinyml-autopilot/data/object_detection/sheeps.mp4'\n",
      "\n",
      "SPAN error_92_psg_failure_signal_py_sketch_generator: Failed. Last error: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250809115829_psg_codestral:latest/tmp_20250809115829_psg_codestral:latest.py\", line 48, in <module>\n",
      "    interpreter.set_tensor(input_details[0]['index'], input_data)\n",
      "  File \"/home/wuguangh/.conda/envs/tinyml/lib/python3.10/site-packages/ai_edge_litert/interpreter.py\", line 764, in set_tensor\n",
      "    self._interpreter.SetTensor(tensor_index, value)\n",
      "ValueError: Cannot set tensor: Got value of type FLOAT32 but expected type UINT8 for input 175, name: normalized_input_image_tensor \n",
      "\n",
      "SPAN error_8b_psg_failure_signal_py_sketch_generator: Failed. Last error: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250809115706_psg_codestral:latest/tmp_20250809115706_psg_codestral:latest.py\", line 24, in <module>\n",
      "    for filename in os.listdir(input_dir):\n",
      "NotADirectoryError: [Errno 20] Not a directory: 'data/object_detection/sheeps.mp4'\n",
      "\n",
      "SPAN error_bc_psg_failure_signal_py_sketch_generator: Failed. Last error: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250809115552_psg_codestral:latest/tmp_20250809115552_psg_codestral:latest.py\", line 26, in <module>\n",
      "    interpreter.set_tensor(input_details[0]['index'], input_data)\n",
      "  File \"/home/wuguangh/.conda/envs/tinyml/lib/python3.10/site-packages/ai_edge_litert/interpreter.py\", line 764, in set_tensor\n",
      "    self._interpreter.SetTensor(tensor_index, value)\n",
      "ValueError: Cannot set tensor: Got value of type FLOAT32 but expected type UINT8 for input 175, name: normalized_input_image_tensor \n",
      "\n",
      "SPAN error_eb_psg_failure_signal_py_sketch_generator: Failed. Last error: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250809115433_psg_codestral:latest/tmp_20250809115433_psg_codestral:latest.py\", line 25, in <module>\n",
      "    for line in f:\n",
      "  File \"/home/wuguangh/.conda/envs/tinyml/lib/python3.10/codecs.py\", line 322, in decode\n",
      "    (result, consumed) = self._buffer_decode(data, self.errors, final)\n",
      "UnicodeDecodeError: 'utf-8' codec can't decode byte 0x92 in position 42: invalid start byte\n",
      "\n",
      "SPAN error_b1_psg_failure_signal_py_sketch_generator: Failed. Last error: Unexpected error during generation: The output is not a valid code block. Follow the instructions in the prompt return a complete, correct Python script enclosed in a single ```python\n",
      "<generated_code>\n",
      "``` block.\n",
      "SPAN error_de_psg_failure_signal_py_sketch_generator: Failed. Last error: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250809115207_psg_codestral:latest/tmp_20250809115207_psg_codestral:latest.py\", line 26, in <module>\n",
      "    for line in f:\n",
      "  File \"/home/wuguangh/.conda/envs/tinyml/lib/python3.10/codecs.py\", line 322, in decode\n",
      "    (result, consumed) = self._buffer_decode(data, self.errors, final)\n",
      "UnicodeDecodeError: 'utf-8' codec can't decode byte 0x92 in position 42: invalid start byte\n",
      "\n",
      "SPAN error_c6_psg_failure_signal_py_sketch_generator: Failed. Last error: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "OpenCV: FFMPEG: tag 0x44495658/'XVID' is not supported with codec id 12 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n",
      "OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250809115049_psg_codestral:latest/tmp_20250809115049_psg_codestral:latest.py\", line 42, in <module>\n",
      "    interpreter.set_tensor(input_details[0]['index'], input_data)\n",
      "  File \"/home/wuguangh/.conda/envs/tinyml/lib/python3.10/site-packages/ai_edge_litert/interpreter.py\", line 764, in set_tensor\n",
      "    self._interpreter.SetTensor(tensor_index, value)\n",
      "ValueError: Cannot set tensor: Got value of type FLOAT32 but expected type UINT8 for input 175, name: normalized_input_image_tensor \n",
      "\n",
      "SPAN error_58_psg_failure_signal_py_sketch_generator: Failed. Last error: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250809114920_psg_codestral:latest/tmp_20250809114920_psg_codestral:latest.py\", line 37, in <module>\n",
      "    interpreter.set_tensor(input_details[0]['index'], input_data)\n",
      "  File \"/home/wuguangh/.conda/envs/tinyml/lib/python3.10/site-packages/ai_edge_litert/interpreter.py\", line 764, in set_tensor\n",
      "    self._interpreter.SetTensor(tensor_index, value)\n",
      "ValueError: Cannot set tensor: Dimension mismatch. Got 640 but expected 300 for dimension 1 of input 175.\n",
      "\n",
      "SPAN error_4c_psg_failure_signal_py_sketch_generator: Failed. Last error: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250809114757_psg_codestral:latest/tmp_20250809114757_psg_codestral:latest.py\", line 24, in <module>\n",
      "    image = Image.open(input_path)\n",
      "  File \"/home/wuguangh/.conda/envs/tinyml/lib/python3.10/site-packages/PIL/Image.py\", line 3536, in open\n",
      "    raise UnidentifiedImageError(msg)\n",
      "PIL.UnidentifiedImageError: cannot identify image file '/home/wuguangh/Projects/tinyml-autopilot/data/object_detection/sheeps.mp4'\n",
      "\n",
      "SPAN error_50_psg_failure_signal_py_sketch_generator: Failed. Last error: Unexpected error during generation: The output is not a valid code block. Follow the instructions in the prompt return a complete, correct Python script enclosed in a single ```python\n",
      "<generated_code>\n",
      "``` block.\n",
      "SPAN error_f1_psg_failure_signal_py_sketch_generator: Failed. Last error: Unexpected error during generation: The output is not a valid code block. Follow the instructions in the prompt return a complete, correct Python script enclosed in a single ```python\n",
      "<generated_code>\n",
      "``` block.\n",
      "SPAN error_50_psg_failure_signal_py_sketch_generator: Failed. Last error: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250809114404_psg_codestral:latest/tmp_20250809114404_psg_codestral:latest.py\", line 20, in <module>\n",
      "    input_data = np.random.rand(*input_shape).astype(input_dtype)\n",
      "  File \"numpy/random/mtrand.pyx\", line 1219, in numpy.random.mtrand.RandomState.rand\n",
      "  File \"numpy/random/mtrand.pyx\", line 437, in numpy.random.mtrand.RandomState.random_sample\n",
      "  File \"_common.pyx\", line 307, in numpy.random._common.double_fill\n",
      "TypeError: 'str' object cannot be interpreted as an integer\n",
      "\n",
      "SPAN error_df_psg_failure_signal_py_sketch_generator: Failed. Last error: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "OpenCV: FFMPEG: tag 0x47504a4d/'MJPG' is not supported with codec id 7 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n",
      "OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250809114250_psg_codestral:latest/tmp_20250809114250_psg_codestral:latest.py\", line 39, in <module>\n",
      "    interpreter.set_tensor(input_details[0]['index'], input_data)\n",
      "  File \"/home/wuguangh/.conda/envs/tinyml/lib/python3.10/site-packages/ai_edge_litert/interpreter.py\", line 764, in set_tensor\n",
      "    self._interpreter.SetTensor(tensor_index, value)\n",
      "ValueError: Cannot set tensor: Got value of type FLOAT32 but expected type UINT8 for input 175, name: normalized_input_image_tensor \n",
      "\n",
      "SPAN error_60_psg_failure_signal_py_sketch_generator: Failed. Last error: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250809114127_psg_codestral:latest/tmp_20250809114127_psg_codestral:latest.py\", line 26, in <module>\n",
      "    image = Image.open(input_path).resize((input_details[0]['shape'][1], input_details[0]['shape'][2]))\n",
      "  File \"/home/wuguangh/.conda/envs/tinyml/lib/python3.10/site-packages/PIL/Image.py\", line 3536, in open\n",
      "    raise UnidentifiedImageError(msg)\n",
      "PIL.UnidentifiedImageError: cannot identify image file '/home/wuguangh/Projects/tinyml-autopilot/data/object_detection/sheeps.mp4'\n",
      "\n",
      "SPAN error_6c_psg_failure_signal_py_sketch_generator: Failed. Last error: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250809114011_psg_codestral:latest/tmp_20250809114011_psg_codestral:latest.py\", line 44, in <module>\n",
      "    interpreter.set_tensor(input_details[0]['index'], input_data)\n",
      "  File \"/home/wuguangh/.conda/envs/tinyml/lib/python3.10/site-packages/ai_edge_litert/interpreter.py\", line 764, in set_tensor\n",
      "    self._interpreter.SetTensor(tensor_index, value)\n",
      "ValueError: Cannot set tensor: Got value of type FLOAT32 but expected type UINT8 for input 175, name: normalized_input_image_tensor \n",
      "\n",
      "SPAN error_17_psg_failure_signal_py_sketch_generator: Failed. Last error: Unexpected error during generation: The output is not a valid code block. Follow the instructions in the prompt return a complete, correct Python script enclosed in a single ```python\n",
      "<generated_code>\n",
      "``` block.\n",
      "SPAN error_09_psg_failure_signal_py_sketch_generator: Failed. Last error: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250809113706_psg_codestral:latest/tmp_20250809113706_psg_codestral:latest.py\", line 38, in <module>\n",
      "    interpreter.set_tensor(input_details[0]['index'], input_data)\n",
      "  File \"/home/wuguangh/.conda/envs/tinyml/lib/python3.10/site-packages/ai_edge_litert/interpreter.py\", line 764, in set_tensor\n",
      "    self._interpreter.SetTensor(tensor_index, value)\n",
      "ValueError: Cannot set tensor: Got value of type FLOAT32 but expected type UINT8 for input 175, name: normalized_input_image_tensor \n",
      "\n",
      "SPAN error_cf_psg_failure_signal_py_sketch_generator: Failed. Last error: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "OpenCV: FFMPEG: tag 0x44495658/'XVID' is not supported with codec id 12 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n",
      "OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250809113557_psg_codestral:latest/tmp_20250809113557_psg_codestral:latest.py\", line 75, in <module>\n",
      "    boxes, classes, scores, num_detections = run_inference(input_data)\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250809113557_psg_codestral:latest/tmp_20250809113557_psg_codestral:latest.py\", line 35, in run_inference\n",
      "    interpreter.set_tensor(input_details[0]['index'], input_data)\n",
      "  File \"/home/wuguangh/.conda/envs/tinyml/lib/python3.10/site-packages/ai_edge_litert/interpreter.py\", line 764, in set_tensor\n",
      "    self._interpreter.SetTensor(tensor_index, value)\n",
      "ValueError: Cannot set tensor: Got value of type FLOAT32 but expected type UINT8 for input 175, name: normalized_input_image_tensor \n",
      "\n",
      "SPAN error_36_psg_failure_signal_py_sketch_generator: Failed. Last error: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250809113428_psg_codestral:latest/tmp_20250809113428_psg_codestral:latest.py\", line 24, in <module>\n",
      "    image = Image.open(input_image_path)\n",
      "  File \"/home/wuguangh/.conda/envs/tinyml/lib/python3.10/site-packages/PIL/Image.py\", line 3536, in open\n",
      "    raise UnidentifiedImageError(msg)\n",
      "PIL.UnidentifiedImageError: cannot identify image file '/home/wuguangh/Projects/tinyml-autopilot/data/object_detection/sheeps.mp4'\n",
      "\n",
      "SPAN error_da_psg_failure_signal_py_sketch_generator: Failed. Last error: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250809113306_psg_codestral:latest/tmp_20250809113306_psg_codestral:latest.py\", line 41, in <module>\n",
      "    interpreter.set_tensor(input_details[0]['index'], input_data)\n",
      "  File \"/home/wuguangh/.conda/envs/tinyml/lib/python3.10/site-packages/ai_edge_litert/interpreter.py\", line 764, in set_tensor\n",
      "    self._interpreter.SetTensor(tensor_index, value)\n",
      "ValueError: Cannot set tensor: Got value of type FLOAT32 but expected type UINT8 for input 175, name: normalized_input_image_tensor \n",
      "\n",
      "SPAN error_60_psg_failure_signal_py_sketch_generator: Failed. Last error: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250809113149_psg_codestral:latest/tmp_20250809113149_psg_codestral:latest.py\", line 21, in <module>\n",
      "    input_data = np.load(input_image_path).astype(np.float32)\n",
      "  File \"/home/wuguangh/.conda/envs/tinyml/lib/python3.10/site-packages/numpy/lib/npyio.py\", line 462, in load\n",
      "    raise ValueError(\"Cannot load file containing pickled data \"\n",
      "ValueError: Cannot load file containing pickled data when allow_pickle=False\n",
      "\n",
      "Successfully processed and saved trimmed data for session codestral_62f3_psg_batch\n",
      "Total 0 traces skipped. They are []\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "skipped_traces = []\n",
    "\n",
    "\n",
    "def process_existing_observation(observation):\n",
    "    \"\"\"\n",
    "    Processes an existing observation dictionary by trimming unwanted keys.\n",
    "    \"\"\"\n",
    "    unwanted_observation_keys = [\n",
    "        \"completionStartTime\",\n",
    "        \"metadata\",\n",
    "        \"timeToFirstToken\",\n",
    "        \"createdAt\",\n",
    "        \"usageDetails\",\n",
    "        \"usage\",\n",
    "        \"projectId\",\n",
    "        \"unit\",\n",
    "        \"updatedAt\",\n",
    "        \"version\",\n",
    "        \"parentObservationId\",\n",
    "        \"promptId\",\n",
    "        \"promptName\",\n",
    "        \"promptVersion\",\n",
    "        \"modelId\",\n",
    "        \"inputPrice\",\n",
    "        \"outputPrice\",\n",
    "        \"totalPrice\",\n",
    "        # \"modelParameters\",\n",
    "        \"input\",\n",
    "        \"output\",\n",
    "    ]\n",
    "\n",
    "    # If observation is a dictionary containing observation data\n",
    "    if isinstance(observation, dict):\n",
    "        trimmed_observation = {\n",
    "            k: v for k, v in observation.items() if k not in unwanted_observation_keys\n",
    "        }\n",
    "        return trimmed_observation\n",
    "    return observation\n",
    "\n",
    "\n",
    "def trim_data(data):\n",
    "    \"\"\"\n",
    "    Recursively trims the data structure.\n",
    "    \"\"\"\n",
    "\n",
    "    if isinstance(data, dict):\n",
    "        # Process the current dictionary\n",
    "        unwanted_trace_keys = [\n",
    "            \"release\",\n",
    "            \"version\",\n",
    "            \"user_id\",\n",
    "            \"public\",\n",
    "            \"html_path\",\n",
    "            \"scores\",\n",
    "            \"bookmarked\",\n",
    "            \"projectId\",\n",
    "            \"externalId\",\n",
    "            \"page\",\n",
    "            \"limit\",\n",
    "            \"total_pages\",\n",
    "        ]\n",
    "\n",
    "        # If this is a trace that contains observations, check for fatal errors\n",
    "        if \"observations\" in data:\n",
    "            # Check for SPAN observations with fatal errors before processing\n",
    "            skip_trace = False\n",
    "            for obs in data[\"observations\"]:\n",
    "                if isinstance(obs, dict) and obs.get(\"name\").startswith(\"error\"):\n",
    "                    status_message = obs.get(\"statusMessage\", \"\")\n",
    "                    ob_name = obs.get(\"name\")\n",
    "                    print(f\"SPAN {ob_name}: {status_message}\")\n",
    "\n",
    "                    if \"Fatal error\" in status_message:\n",
    "                        print(f\"Found Fatal error in SPAN observation, skipping trace\")\n",
    "                        skip_trace = True\n",
    "                        skipped_traces.append(data[\"name\"])\n",
    "                        break\n",
    "\n",
    "            if skip_trace:\n",
    "                return None  # Signal to skip this trace\n",
    "\n",
    "        # Create a new dictionary with wanted keys and recursively process values\n",
    "        trimmed_data = {}\n",
    "        for key, value in data.items():\n",
    "            if key not in unwanted_trace_keys:\n",
    "                if key == \"observations\":\n",
    "                    # Special handling for observations\n",
    "                    trimmed_data[key] = [\n",
    "                        process_existing_observation(obs) for obs in value\n",
    "                    ]\n",
    "                elif isinstance(value, (dict, list)):\n",
    "                    # Recursively process nested structures\n",
    "                    trimmed_data[key] = trim_data(value)\n",
    "                else:\n",
    "                    trimmed_data[key] = value\n",
    "\n",
    "        return trimmed_data\n",
    "\n",
    "    elif isinstance(data, list):\n",
    "        # Recursively process each item in the list\n",
    "        processed_items = []\n",
    "        for item in data:\n",
    "            processed_item = trim_data(item)\n",
    "            if processed_item is not None:  # Only add items that weren't filtered out\n",
    "                processed_items.append(processed_item)\n",
    "        return processed_items\n",
    "\n",
    "    else:\n",
    "        # Return non-dict, non-list values as is\n",
    "        return data\n",
    "\n",
    "\n",
    "def read_and_trim_data(session_id_list, raw_export_dir, trimmed_export_dir):\n",
    "    \"\"\"\n",
    "    Reads complete data from JSON files, trims the data, and saves the trimmed data to new JSON files.\n",
    "    \"\"\"\n",
    "    os.makedirs(trimmed_export_dir, exist_ok=True)\n",
    "\n",
    "    for session_id in session_id_list:\n",
    "        try:\n",
    "            if session_id.startswith(\"da0a\"):\n",
    "                session_id = \"phi4_\" + session_id\n",
    "            # Read raw data\n",
    "            if \"tpsg\" in session_id:\n",
    "                session_id_ = session_id.replace(\"tpsg\", \"tpusg\")\n",
    "            else:\n",
    "                session_id_ = session_id\n",
    "            raw_path = os.path.join(raw_export_dir, f\"raw_{session_id_}.json\")\n",
    "            with open(raw_path, \"r\") as f:\n",
    "                data = json.load(f)\n",
    "\n",
    "            # Process and trim the data\n",
    "            trimmed_data = trim_data(data)\n",
    "\n",
    "            # If the entire data was filtered out (unlikely but possible)\n",
    "            if trimmed_data is None:\n",
    "                print(\n",
    "                    f\"All traces in session {session_id} were filtered due to fatal errors\"\n",
    "                )\n",
    "                continue\n",
    "\n",
    "            # Save trimmed data\n",
    "            if \"tpsg\" in session_id:\n",
    "                session_id_ = session_id.replace(\"tpsg\", \"tpusg\")\n",
    "            else:\n",
    "                session_id_ = session_id\n",
    "            trimmed_path = os.path.join(\n",
    "                trimmed_export_dir, f\"trimmed_{session_id_}.json\"\n",
    "            )\n",
    "            with open(trimmed_path, \"w\") as f:\n",
    "                json.dump(trimmed_data, f, indent=2)\n",
    "\n",
    "            print(\n",
    "                f\"Successfully processed and saved trimmed data for session {session_id}\"\n",
    "            )\n",
    "\n",
    "            # Optional: Verify trimming worked\n",
    "            # print(f\"Verifying trimmed data for session {session_id}...\")\n",
    "            # verify_trimming(trimmed_path)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing session {session_id}: {str(e)}\")\n",
    "\n",
    "\n",
    "def verify_trimming(trimmed_path):\n",
    "    \"\"\"\n",
    "    Verifies that the trimmed data doesn't contain unwanted keys.\n",
    "    \"\"\"\n",
    "    with open(trimmed_path, \"r\") as f:\n",
    "        trimmed_data = json.load(f)\n",
    "\n",
    "    unwanted_keys = [\n",
    "        \"release\",\n",
    "        \"version\",\n",
    "        \"user_id\",\n",
    "        \"public\",\n",
    "        \"html_path\",\n",
    "        \"scores\",\n",
    "        \"bookmarked\",\n",
    "        \"projectId\",\n",
    "        \"externalId\",\n",
    "        \"page\",\n",
    "        \"limit\",\n",
    "        \"total_pages\",\n",
    "        \"completionStartTime\",\n",
    "        \"metadata\",\n",
    "        \"usageDetails\",\n",
    "        \"timeToFirstToken\",\n",
    "        \"createdAt\",\n",
    "        \"completionTokens\",\n",
    "        \"promptTokens\",\n",
    "        \"projectId\",\n",
    "        \"unit\",\n",
    "        \"updatedAt\",\n",
    "        \"version\",\n",
    "        # \"statusMessage\",\n",
    "        \"parentObservationId\",\n",
    "        \"promptId\",\n",
    "        \"promptName\",\n",
    "        \"promptVersion\",\n",
    "        \"modelId\",\n",
    "        \"inputPrice\",\n",
    "        \"outputPrice\",\n",
    "        \"totalPrice\",\n",
    "        \"calculatedInputCost\",\n",
    "        \"calculatedOutputCost\",\n",
    "        \"calculatedTotalCost\",\n",
    "    ]\n",
    "\n",
    "    def check_keys(obj):\n",
    "        if isinstance(obj, dict):\n",
    "            for key in obj.keys():\n",
    "                if key in unwanted_keys:\n",
    "                    print(f\"Warning: Found unwanted key '{key}' in trimmed data\")\n",
    "            for value in obj.values():\n",
    "                check_keys(value)\n",
    "        elif isinstance(obj, list):\n",
    "            for item in obj:\n",
    "                check_keys(item)\n",
    "\n",
    "    check_keys(trimmed_data)\n",
    "    print(\"Verification complete\")\n",
    "\n",
    "\n",
    "# Usage example:\n",
    "read_and_trim_data(session_id_list, raw_export_dir, raw_export_dir)\n",
    "print(f\"Total {len(skipped_traces)} traces skipped. They are {skipped_traces}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Generate CSV files from JSON\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing session codestral_62f3_psg_batch, simple id codestral_62f3. Look for /Users/hann/Projects/reference-benchmark-tinyml_llm/data_analysis/2025/08.09/raw_export/trimmed_codestral_62f3_psg_batch.json\n",
      "/Users/hann/Projects/reference-benchmark-tinyml_llm/data_analysis/2025/08.09/processed_data/codestral_62f3/clean_codestral_62f3_psg_batch.csv\n",
      "Successfully saved CSV to: /Users/hann/Projects/reference-benchmark-tinyml_llm/data_analysis/2025/08.09/processed_data/codestral_62f3/clean_codestral_62f3_psg_batch.csv\n"
     ]
    }
   ],
   "source": [
    "import traceback\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from dateutil import parser\n",
    "\n",
    "\n",
    "def json_to_csv(session_id):\n",
    "    \"\"\"\n",
    "    Convert JSON trace data to CSV format with aggregated metrics.\n",
    "\n",
    "    Args:\n",
    "        session_id (str): Identifier for the session to process\n",
    "    \"\"\"\n",
    "\n",
    "    def extract_observation_details(observations, trace_id):\n",
    "        \"\"\"Extract and aggregate metrics from observations\"\"\"\n",
    "        metrics = {\n",
    "            \"status\": None,\n",
    "            \"latency\": 0,\n",
    "            \"total_tokens\": 0,\n",
    "            \"prompt_tokens\": 0,\n",
    "            \"completion_tokens\": 0,\n",
    "            \"total_cost\": 0,\n",
    "            \"input_cost\": 0,\n",
    "            \"output_cost\": 0,\n",
    "            \"parameters\": set(),\n",
    "        }\n",
    "\n",
    "        # Process GENERATION observations\n",
    "        for obs in (o for o in observations if o[\"type\"] == \"GENERATION\"):\n",
    "            metrics[\"total_tokens\"] += obs[\"totalTokens\"]\n",
    "            metrics[\"prompt_tokens\"] += obs[\"promptTokens\"]\n",
    "            metrics[\"completion_tokens\"] += obs[\"completionTokens\"]\n",
    "            metrics[\"latency\"] += obs[\"latency\"]\n",
    "            for key, value in obs[\"modelParameters\"].items():\n",
    "                metrics[\"parameters\"].add(key + \":\" + value)\n",
    "\n",
    "            # Add costs if present\n",
    "            for cost_type in [\"Total\", \"Input\", \"Output\"]:\n",
    "                key = f\"calculated{cost_type}Cost\"\n",
    "                metric_key = cost_type.lower() + \"_cost\"\n",
    "                if obs.get(key) is not None:\n",
    "                    metrics[metric_key] += obs[key]\n",
    "        if len(metrics[\"parameters\"]) == 0:\n",
    "            metrics[\"parameters\"] = \"N/A\"\n",
    "        # Process SPAN observations for status\n",
    "        status_indicators = [\n",
    "            obs[\"name\"]\n",
    "            for obs in observations\n",
    "            if obs[\"type\"] == \"SPAN\" and \"start_\" not in obs[\"name\"]\n",
    "        ]\n",
    "\n",
    "        #  if later than 2025-05-19, use status_signal_from_output\n",
    "        if datetime.now() > datetime(2025, 5, 19):\n",
    "            pass\n",
    "        else:\n",
    "            # Determine status\n",
    "            success_signals = sum(\"end_\" in name for name in status_indicators)\n",
    "            failure_signals = sum(\n",
    "                \"failure_signal\" in name for name in status_indicators\n",
    "            )\n",
    "\n",
    "            if success_signals + failure_signals > 1:\n",
    "                raise ValueError(\n",
    "                    f\"Multiple status indicators found in trace {trace_id}\"\n",
    "                )\n",
    "\n",
    "            metrics[\"status\"] = (\n",
    "                \"success\"\n",
    "                if success_signals\n",
    "                else \"failure\" if failure_signals else \"unknown\"\n",
    "            )\n",
    "\n",
    "        metrics[\"prompt_cost\"] = metrics.pop(\"input_cost\")\n",
    "        metrics[\"completion_cost\"] = metrics.pop(\"output_cost\")\n",
    "        metrics[\"latency\"] = round(metrics[\"latency\"] / 1000, 2)\n",
    "        return metrics\n",
    "\n",
    "    def cal_time(trace):\n",
    "        time_diff = datetime.fromisoformat(\n",
    "            trace[\"updatedAt\"].replace(\"Z\", \"+00:00\")\n",
    "        ) - datetime.fromisoformat(trace[\"createdAt\"].replace(\"Z\", \"+00:00\"))\n",
    "        seconds_diff = time_diff.total_seconds()\n",
    "        return seconds_diff\n",
    "\n",
    "    try:\n",
    "\n",
    "        if session_id.startswith(\"da0a\"):\n",
    "            session_id = \"phi4_\" + session_id\n",
    "        simple_session_id = session_id.rsplit(\"_\", 2)[0]\n",
    "\n",
    "        \n",
    "        # Load JSON data\n",
    "        if \"tpsg\" in session_id:\n",
    "                session_id_ = session_id.replace(\"tpsg\", \"tpusg\")\n",
    "        else:\n",
    "                session_id_ = session_id\n",
    "        trimmed_path = os.path.join(raw_export_dir, f\"trimmed_{session_id_}.json\")\n",
    "        print(\n",
    "            f\"Processing session {session_id}, simple id {simple_session_id}. Look for {trimmed_path}\"\n",
    "        )\n",
    "        with open(trimmed_path, \"r\") as file:\n",
    "            traces = json.load(file)[\"data\"]\n",
    "\n",
    "        # Process traces\n",
    "        rows = [\n",
    "            {\n",
    "                \"num_run\": trace[\"metadata\"][\"num_run\"],\n",
    "                \"name\": trace[\"name\"],\n",
    "                \"trace_id\": trace[\"id\"],\n",
    "                \"batch_id\": trace[\"session_id\"],\n",
    "                # \"latency\": cal_time(trace),\n",
    "                # \"latency\": round(trace[\"latency\"], 2),\n",
    "                **extract_observation_details(\n",
    "                    trace[\"observations\"],\n",
    "                    trace[\"id\"],\n",
    "                ),\n",
    "                \"status\": (\n",
    "                    \"failure\"\n",
    "                    if trace[\"output\"][\"status\"].lower() == \"failed\"\n",
    "                    else \"success\"\n",
    "                ),\n",
    "                \"tags\": trace[\"tags\"],\n",
    "                \"timestamp\": int(parser.isoparse(trace[\"timestamp\"]).timestamp()),\n",
    "            }\n",
    "            for trace in traces\n",
    "        ]\n",
    "        # print(rows)\n",
    "        # print(rows)\n",
    "        # Create and save DataFrame\n",
    "        df = pd.DataFrame(rows).sort_values(\"num_run\")\n",
    "\n",
    "        output_dir = os.path.join(processed_data_dir, f\"{simple_session_id}\")\n",
    "        if not os.path.exists(output_dir):\n",
    "            os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "        output_path = os.path.join(output_dir, f\"clean_{session_id_}.csv\")\n",
    "\n",
    "        print(output_path)\n",
    "        df.to_csv(output_path, index=False)\n",
    "        print(f\"Successfully saved CSV to: {output_path}\")\n",
    "\n",
    "    except FileNotFoundError as e:\n",
    "        print(\n",
    "            f\"FileNotFoundError: For session {session_id} not found. Looked for {trimmed_path}\\nError info: \\n{e}\\n\\nTraceback: {traceback.format_exc()}\"\n",
    "        )\n",
    "    except json.JSONDecodeError:\n",
    "        print(f\"Error: Invalid JSON format in input file for session {session_id}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing session {session_id}: {str(e)}\")\n",
    "\n",
    "\n",
    "# Example usage\n",
    "for session_id in session_id_list:\n",
    "    json_to_csv(session_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code below is archived\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"\"\"Simply calculate success rate\"\"\"\n",
    "\n",
    "\n",
    "# def cal_success_rate(session_id):\n",
    "\n",
    "#     end_signal_count = 0\n",
    "#     failure_signal_count = 0\n",
    "#     # Function to print the name of each observation\n",
    "#     with open(f\"{raw_export_dir}/trimmed_{session_id}.json\", \"r\") as file:\n",
    "#         data = json.load(file)[\"data\"]\n",
    "#     for i in data:\n",
    "\n",
    "#         observations = i[\"observations\"]\n",
    "\n",
    "#         for observation in observations:\n",
    "#             # print(type(observation))\n",
    "#             for key, value in observation.items():\n",
    "#                 # print(f\"{key}: {value}\")\n",
    "#                 for key, value in value.items():\n",
    "#                     # print(f\"{key}: {value}\")\n",
    "#                     if key == \"name\":\n",
    "#                         if \"end_\" in value:\n",
    "\n",
    "#                             end_signal_count += 1\n",
    "#                         if \"failure_signal\" in value:\n",
    "\n",
    "#                             failure_signal_count += 1\n",
    "\n",
    "#     print(f\"Session ID: {session_id}\")\n",
    "#     total_count = end_signal_count + failure_signal_count\n",
    "#     if total_count > 0:\n",
    "#         success_rate = end_signal_count / total_count\n",
    "#         print(f\"Success rate: {success_rate:.4f}\")\n",
    "#     else:\n",
    "#         print(\"Success rate: N/A (no signals found)\")\n",
    "#     print(f\"Passed:\\t{end_signal_count}\\nFailed:\\t{failure_signal_count}\")\n",
    "#     print(\n",
    "#         \"\"\n",
    "#         if total_count == 30\n",
    "#         else \"Number of ending signals does not match the expected number!\"\n",
    "#     )\n",
    "#     print(\"-\" * 50)\n",
    "\n",
    "\n",
    "# for session_id in session_id_list:\n",
    "#     cal_success_rate(session_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def cal_time(start_time, end_time):\n",
    "#     time_diff = datetime.fromisoformat(\n",
    "#         end_time.replace(\"Z\", \"+00:00\")\n",
    "#     ) - datetime.fromisoformat(start_time.replace(\"Z\", \"+00:00\"))\n",
    "#     seconds_diff = time_diff.total_seconds()\n",
    "#     return seconds_diff\n",
    "\n",
    "\n",
    "# print(cal_time(\"2025-01-15T03:31:56.150000+00:00\", \"2025-01-15T03:32:59.384Z\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"\"\"Print the complete structure of exported json file\"\"\"\n",
    "# def print_keys(d, parent_key=''):\n",
    "#     if isinstance(d, dict):\n",
    "#         for key, value in d.items():\n",
    "#             full_key = f\"{parent_key}.{key}\" if parent_key else key\n",
    "#             print(full_key)\n",
    "#             print_keys(value, full_key)\n",
    "#     elif isinstance(d, list):\n",
    "#         for i, item in enumerate(d):\n",
    "#             full_key = f\"{parent_key}[{i}]\"\n",
    "#             print_keys(item, full_key)\n",
    "\n",
    "# # Load JSON data from a file\n",
    "# with open('fetch_traces_response.json', 'r') as file:\n",
    "#     data = json.load(file)['data'][0]\n",
    "# # Print all keys\n",
    "# print_keys(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1747226053\n",
      "1747226053.1\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "from dateutil import parser\n",
    "\n",
    "timestamp_str = \"2025-05-14T12:34:13.100000+00:00\"\n",
    "dt = parser.isoparse(\n",
    "    timestamp_str\n",
    ")  # Or datetime.fromisoformat(timestamp_str) if no timezone offset\n",
    "unix_ts = int(dt.timestamp())\n",
    "\n",
    "print(unix_ts)  # This will print the integer Unix timestamp\n",
    "print(datetime.fromisoformat(timestamp_str).timestamp())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datasci2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

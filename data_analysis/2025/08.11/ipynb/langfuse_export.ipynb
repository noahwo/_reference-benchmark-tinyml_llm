{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setting up\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ref: https://langfuse.com/docs/query-traces\n",
    "import os\n",
    "import json\n",
    "from langfuse import Langfuse\n",
    "import json\n",
    "import os\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "LOCAL_HOST = True\n",
    "\n",
    "\"\"\"Define session_id\"\"\"\n",
    "# session_id=\"qwen2.5-coder_f4d4_dp_batch\"\n",
    "session_id_list = [\n",
    "    # \"qwen2.5-coder:32b_4e11_tpsg_batch\",\n",
    "    # \"qwen2.5-coder:32b_ae24_tpsg_batch\"\n",
    "    \"qwen2.5-coder:14b_d266_psg_batch\",\n",
    " \n",
    "]\n",
    "\n",
    "\n",
    "\"\"\"Define paths\"\"\"\n",
    " \n",
    "parent_dir = os.path.dirname(os.getcwd())\n",
    "\n",
    " \n",
    "# date = os.path.basename(parent_dir)\n",
    "tex_dir = os.path.join(parent_dir, \"tex\")\n",
    "processed_data_dir = os.path.join(parent_dir, \"processed_data\")\n",
    "raw_export_dir = os.path.join(parent_dir, \"raw_export\")\n",
    "ipynb_dir = os.path.join(parent_dir, \"ipynb\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Export raw data\n",
    "\n",
    "Langfuse added a limit of 20 API invocations per minute. https://langfuse.com/faq/all/api-limits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching traces for session qwen2.5-coder:14b_d266_psg_batch...\n",
      "Fetching observation data for time-19-07-06-720300_chatcmpl-f7ed6e3f-27a5-4d5a-8170-bdd9472f7848...\n",
      "Fetching observation data for time-19-07-18-028833_chatcmpl-13976124-968a-4599-b84c-07afeeb779de...\n",
      "Fetching observation data for time-19-07-24-636501_chatcmpl-c1165c53-8e22-42fc-af6a-b3ad4b2c4e59...\n",
      "Fetching observation data for time-19-07-31-809438_chatcmpl-e8c0003d-e14d-4137-a570-e1867ea94aaf...\n",
      "Fetching observation data for time-19-07-38-856981_chatcmpl-a1f572c3-7948-4247-acdd-d2c7384127f5...\n",
      "Fetching observation data for e40b7b74-094f-4446-aeb1-efe158a209e3...\n",
      "Fetching observation data for time-19-06-22-138769_chatcmpl-cd0a5ac7-df15-4155-bcb7-48eda635b62f...\n",
      "Fetching observation data for time-19-06-33-230981_chatcmpl-e6989677-b3a0-4f67-85dc-48efed2cfe6b...\n",
      "Fetching observation data for time-19-06-39-731742_chatcmpl-fef0ba7d-d54e-4620-969a-0b0f852b3d62...\n",
      "Fetching observation data for time-19-06-46-181177_chatcmpl-09e5c406-4e6f-40a3-9c9e-5836b9f97908...\n",
      "Fetching observation data for time-19-06-53-140700_chatcmpl-680ff424-bc59-4e84-b533-b525c89f2f05...\n",
      "Fetching observation data for 0e65a88c-80df-4a17-adff-cda58d8e8c05...\n",
      "Fetching observation data for time-19-05-42-623991_chatcmpl-ebfcfd7f-dcf7-48ab-b3bb-07bd5e1af87a...\n",
      "Fetching observation data for time-19-05-53-919645_chatcmpl-319c3cf3-a2fa-40ed-88dd-707c93b3ff99...\n",
      "Fetching observation data for time-19-06-00-538852_chatcmpl-d8e10b18-f1b0-49b5-b70e-25b72b84eed5...\n",
      "Fetching observation data for time-19-06-07-539912_chatcmpl-6d102b43-d994-4b4e-b743-a7552e3978aa...\n",
      "Fetching observation data for time-19-04-50-124742_chatcmpl-4b73c0a8-d7af-4e46-88cb-f810caa76e69...\n",
      "Fetching observation data for time-19-05-01-240214_chatcmpl-c23ffc6b-2ec1-4076-9ae8-9f0a12b92929...\n",
      "Fetching observation data for time-19-05-10-169686_chatcmpl-f663b5c5-d87b-4fea-8e3f-d3bfcb09e037...\n",
      "Fetching observation data for time-19-05-19-236698_chatcmpl-e93a54ac-0c89-479f-8330-f79721a2a8a0...\n",
      "Fetching observation data for time-19-05-25-075630_chatcmpl-a2fc50d4-9816-443a-a8a7-dd654c1a137e...\n",
      "Fetching observation data for 8f79ca52-3600-4261-be65-b547d1e89ef6...\n",
      "Fetching observation data for time-19-04-03-584189_chatcmpl-0d7c002b-f33e-49fc-94c2-afb1a8b49a4c...\n",
      "Fetching observation data for time-19-04-15-416331_chatcmpl-82dd6fe3-e4f6-4ccc-bbd7-3d1df7451c4c...\n",
      "Fetching observation data for time-19-04-22-741979_chatcmpl-b71c895e-36c7-4cea-8500-353d59b076a3...\n",
      "Fetching observation data for time-19-04-29-718368_chatcmpl-adcdf086-bac6-4f11-9447-b311f8e961e5...\n",
      "Fetching observation data for time-19-04-36-758356_chatcmpl-b84836b7-1b40-4c29-b4f2-d4cdaea76c3b...\n",
      "Fetching observation data for ec52c02c-047d-4f97-bf45-e13f0fe06764...\n",
      "Fetching observation data for time-19-03-14-046852_chatcmpl-ce4b431e-5e1d-47fc-a2e3-348887881aa2...\n",
      "Fetching observation data for time-19-03-25-139691_chatcmpl-7a198c7c-cc59-4e7c-bdb1-55eb384e2ebf...\n",
      "Fetching observation data for time-19-03-32-658168_chatcmpl-7e394aa2-c91e-44e7-a75f-b036ef3c9330...\n",
      "Fetching observation data for time-19-03-41-363621_chatcmpl-36dba05f-484e-4a47-a83f-f2bdfb0f25be...\n",
      "Fetching observation data for time-19-03-48-997569_chatcmpl-a67d3dce-76fe-4f40-9073-c1aab057e0a6...\n",
      "Fetching observation data for 29cf032d-24fe-4bb6-92b7-050f1bff8b21...\n",
      "Fetching observation data for time-19-02-22-453478_chatcmpl-26287f7b-c3b8-4436-93e6-d914ad5fe6e9...\n",
      "Fetching observation data for time-19-02-33-538729_chatcmpl-0f9a3a6d-c09d-4c53-8147-f22d38034f31...\n",
      "Fetching observation data for time-19-02-41-049654_chatcmpl-60cfda8f-27b6-484f-8863-e695bdfbbafc...\n",
      "Fetching observation data for time-19-02-49-629269_chatcmpl-4b41d81d-2e65-455c-bc97-4dd2839308f5...\n",
      "Fetching observation data for time-19-03-00-029201_chatcmpl-6ac4592b-ce68-4c74-9863-f220df944be3...\n",
      "Fetching observation data for 3ad1d107-4fb7-44f8-9a0a-6274208f668c...\n",
      "Fetching observation data for time-19-01-27-903824_chatcmpl-94649e9d-fb0d-424b-b043-5a63f0814824...\n",
      "Fetching observation data for time-19-01-39-195103_chatcmpl-200b958c-6dfe-46a2-a608-49e318fafd9b...\n",
      "Fetching observation data for time-19-01-46-448697_chatcmpl-870cff2f-e430-4af4-905f-771223ce7a3b...\n",
      "Fetching observation data for time-19-01-57-334042_chatcmpl-2c192e48-1ce0-4884-b443-837adfcd6ece...\n",
      "Fetching observation data for time-19-02-07-805711_chatcmpl-1928dbdb-9489-441b-b972-b9f2aee3be7e...\n",
      "Fetching observation data for 6876213e-6eeb-4f0a-81e0-1222fb3872a8...\n",
      "Fetching observation data for time-19-00-37-098716_chatcmpl-0de1654d-de21-4427-9e9c-bb0f34d8507e...\n",
      "Fetching observation data for time-19-00-48-171596_chatcmpl-143df317-b13d-4206-8991-bfb0b5317419...\n",
      "Fetching observation data for time-19-00-55-682983_chatcmpl-6a5c8c44-35c3-4748-a8bf-c8296ebb62d3...\n",
      "Fetching observation data for time-19-01-04-216602_chatcmpl-89140c8b-4d96-4bd0-a0b7-ccc8d6314ecd...\n",
      "Fetching observation data for time-19-01-13-007497_chatcmpl-8a2df10d-ddc2-4bd1-b8b9-75a26753fb02...\n",
      "Fetching observation data for 061f8739-5ef1-4a74-8dd4-ddc1ea741fa7...\n",
      "Fetching observation data for time-18-59-43-591661_chatcmpl-0e9797a5-d411-4976-aa08-e163a48d8df0...\n",
      "Fetching observation data for time-18-59-55-006455_chatcmpl-d72ad1fd-2046-4dcb-8b9b-eff082483553...\n",
      "Fetching observation data for time-19-00-01-927982_chatcmpl-dd3cfee8-65c5-4353-a4a4-f1cab0025161...\n",
      "Fetching observation data for time-19-00-09-563942_chatcmpl-58929850-2124-4469-8d85-9a821bf945a6...\n",
      "Fetching observation data for time-19-00-20-472884_chatcmpl-f1b95b2d-9ae0-4384-b77a-79866029d9d7...\n",
      "Fetching observation data for 493ab76b-b14f-4c41-9bd9-80acde425e74...\n",
      "Fetching observation data for time-18-58-52-061506_chatcmpl-8a28ae5a-2177-4dff-90b7-e36785fd7308...\n",
      "Fetching observation data for time-18-59-03-351142_chatcmpl-7f0dab59-0c6f-47f8-9440-dc0101d1e578...\n",
      "Fetching observation data for time-18-59-09-965573_chatcmpl-33007a79-2a4b-45d3-9fad-30a24675f6c3...\n",
      "Fetching observation data for time-18-59-17-429095_chatcmpl-519e5581-ff0b-4b14-a359-aa1075f7352b...\n",
      "Fetching observation data for time-18-59-25-989232_chatcmpl-6915a644-bf5e-4bd8-9277-a36a3379d892...\n",
      "Fetching observation data for f0ae8193-4f53-44a8-873d-cd197a71445a...\n",
      "Fetching observation data for time-18-58-05-483596_chatcmpl-49b5843b-5d99-4e64-88f7-957831c83b6c...\n",
      "Fetching observation data for time-18-58-16-791562_chatcmpl-4ba1b063-b412-4397-8e6a-fcc54d0bdbdc...\n",
      "Fetching observation data for time-18-58-23-678604_chatcmpl-1edcb1f7-3168-4dda-9087-a36283590017...\n",
      "Fetching observation data for time-18-58-30-655917_chatcmpl-f81ab7d3-87f5-4ff4-bde0-8447bc1ab2e7...\n",
      "Fetching observation data for time-18-58-37-801030_chatcmpl-13e9fdf0-dc8f-4ca7-9552-cd5ce419568f...\n",
      "Fetching observation data for b3e2fd62-d6ae-486d-afb2-a646df4a44d4...\n",
      "Fetching observation data for time-18-57-10-916758_chatcmpl-019c4d48-0a7f-4b9d-a966-52af920fad0a...\n",
      "Fetching observation data for time-18-57-21-996832_chatcmpl-dd1aaae1-a8f4-4c15-8fe0-e242dc1429f8...\n",
      "Fetching observation data for time-18-57-30-929170_chatcmpl-3d844089-60dd-45c8-8992-7b11acd04fb5...\n",
      "Fetching observation data for time-18-57-40-005423_chatcmpl-e690b9df-a39e-49e7-8d2c-d4a5a3cb21a1...\n",
      "Fetching observation data for time-18-57-47-422022_chatcmpl-8f27ec75-1254-4a10-8db5-20d9689b6f7e...\n",
      "Fetching observation data for 6c53d6b0-81c2-4009-8b32-8de11b612477...\n",
      "Fetching observation data for time-18-56-20-374082_chatcmpl-a72ce210-b475-4320-9f8e-5513505f15cd...\n",
      "Fetching observation data for time-18-56-31-468734_chatcmpl-9ca40a0f-c3b6-44a3-9b8d-0a190c5d82bb...\n",
      "Fetching observation data for time-18-56-40-372527_chatcmpl-208d54b9-8405-4c5d-a9f4-371ba339b3c8...\n",
      "Fetching observation data for time-18-56-49-868632_chatcmpl-09b8ca6d-bd1a-4736-9d9a-94b624b042c9...\n",
      "Fetching observation data for time-18-56-55-640662_chatcmpl-84bdc915-aede-4140-937f-780a6067f461...\n",
      "Fetching observation data for 26e68015-4e2f-4f00-b9a2-3f05ee1532c0...\n",
      "Fetching observation data for time-18-55-28-856509_chatcmpl-e3854602-c5c5-46ca-8a14-8a0ccd7feacd...\n",
      "Fetching observation data for time-18-55-39-955090_chatcmpl-34097ee5-1717-4b07-9745-534bdbd65c75...\n",
      "Fetching observation data for time-18-55-47-471909_chatcmpl-48e4cdda-76b3-420e-80e0-49d867ac6460...\n",
      "Fetching observation data for time-18-55-56-010067_chatcmpl-35aa3ba0-de6e-4b22-a646-57012a635542...\n",
      "Fetching observation data for time-18-56-06-326064_chatcmpl-f3c7961d-eb1b-4a37-bc7f-ab15312eb23b...\n",
      "Fetching observation data for 5318609e-7b1b-471b-8109-1f54c8c460a5...\n",
      "Fetching observation data for time-18-54-36-324577_chatcmpl-45857816-47f1-4f9f-a6bd-44b0492422b4...\n",
      "Fetching observation data for time-18-54-47-635540_chatcmpl-319a1512-b4d1-40ec-8edc-d49a5d5bfc1f...\n",
      "Fetching observation data for time-18-54-54-241263_chatcmpl-3cb61932-eb47-4803-bb98-c300d79a6bd8...\n",
      "Fetching observation data for time-18-55-01-278748_chatcmpl-3adb755b-3ecb-4d62-aa82-33401578b98e...\n",
      "Fetching observation data for time-18-55-11-251081_chatcmpl-527945ee-eb11-4fe2-87a4-5776584f0f65...\n",
      "Fetching observation data for c8e2852e-5502-4dc6-aa0e-b19abc2d34b2...\n",
      "Fetching observation data for time-18-53-46-688974_chatcmpl-d83ef36d-4ab6-4b13-9960-505f43bcde72...\n",
      "Fetching observation data for time-18-53-57-837778_chatcmpl-de6e60b8-02be-4472-bfac-dadbe49c6844...\n",
      "Fetching observation data for time-18-54-06-878511_chatcmpl-b4eb0088-068f-4d2b-be19-6e9a76d13326...\n",
      "Fetching observation data for time-18-54-15-944177_chatcmpl-9db655aa-7a4b-4474-9d83-c98d5f3d8fff...\n",
      "Fetching observation data for time-18-54-21-779652_chatcmpl-5c941d89-7732-4111-866d-28e8ffbeac8c...\n",
      "Fetching observation data for 36c7cb0c-f2cc-4bd5-9f84-59fb785ac4a0...\n",
      "Fetching observation data for time-18-53-00-142639_chatcmpl-b287c544-e76b-40da-a8ce-db572de62c17...\n",
      "Fetching observation data for time-18-53-11-543137_chatcmpl-c922c962-301c-4d9f-a6e3-a4ebe2cd2bf1...\n",
      "Fetching observation data for time-18-53-18-782112_chatcmpl-668a07e1-5a12-4203-804b-6508e7926a2c...\n",
      "Fetching observation data for time-18-53-25-768077_chatcmpl-51991ccd-b372-4c26-b213-74c6efc09eb0...\n",
      "Fetching observation data for time-18-53-32-813797_chatcmpl-9e1ec443-2c74-45f2-b301-f792108531fb...\n",
      "Fetching observation data for 60a0d52b-c13f-44a2-a148-3d93eef2435d...\n",
      "Fetching observation data for time-18-52-12-603225_chatcmpl-531e735a-c2d4-468d-a37e-f9b4432496f9...\n",
      "Fetching observation data for time-18-52-23-685298_chatcmpl-b5b2221a-0924-4851-a6a8-ba6bf6829edb...\n",
      "Fetching observation data for time-18-52-32-582907_chatcmpl-9d8f497a-bfcc-47a5-be6e-a508d2efc31b...\n",
      "Fetching observation data for time-18-52-39-677659_chatcmpl-49c6daf0-0379-4e46-afd8-db1c51966532...\n",
      "Fetching observation data for time-18-52-46-666196_chatcmpl-876255fd-bf53-45c8-ae07-a140ab1d731b...\n",
      "Fetching observation data for 4de09ab0-f5c7-46d7-a0d0-9608d800f16f...\n",
      "Fetching observation data for time-18-51-26-909943_chatcmpl-9e8dbdfb-e128-4442-a3b7-1dde930df923...\n",
      "Fetching observation data for time-18-51-38-201908_chatcmpl-f763bf29-f25f-4c24-bbce-27a423bd1194...\n",
      "Fetching observation data for time-18-51-44-829103_chatcmpl-c148225c-8c94-4bb1-af20-1fa47ca0f808...\n",
      "Fetching observation data for time-18-51-51-792615_chatcmpl-7a3554c8-5feb-44f3-b59d-efb54da86b1a...\n",
      "Fetching observation data for time-18-51-58-928597_chatcmpl-6db95ced-3586-437e-ba38-75765a6f9255...\n",
      "Fetching observation data for a8309ed5-a934-4361-8d10-61131649a282...\n",
      "Fetching observation data for time-18-50-41-404509_chatcmpl-7c7ef488-ee21-4fc4-9460-61e778974aa9...\n",
      "Fetching observation data for time-18-50-52-699056_chatcmpl-f3aabc1c-7a87-4072-9c90-7a81ed3430fa...\n",
      "Fetching observation data for time-18-50-59-311055_chatcmpl-85837288-3e7b-4503-9ac0-ddaa626d06c3...\n",
      "Fetching observation data for time-18-51-06-463214_chatcmpl-aee1b276-918d-4b2e-a0b1-75aa1724f4bf...\n",
      "Fetching observation data for time-18-51-13-508093_chatcmpl-71242a18-b93c-449f-b0cc-e823d849c99e...\n",
      "Fetching observation data for a384fa0f-3130-4ce1-b39c-feed7960aca0...\n",
      "Fetching observation data for time-18-49-47-888329_chatcmpl-9ae2f7a6-366b-4846-99c9-198fddc2b803...\n",
      "Fetching observation data for time-18-49-58-972170_chatcmpl-ba2e22bf-cd3d-4ea4-93cd-14ead9a1bdd2...\n",
      "Fetching observation data for time-18-50-06-490905_chatcmpl-ace14a68-5f00-4ca5-a175-8c1efe61e593...\n",
      "Fetching observation data for time-18-50-16-959845_chatcmpl-0c26053f-96c6-4a1b-a14c-e63d7b80f5a9...\n",
      "Fetching observation data for time-18-50-24-806911_chatcmpl-d98e10de-1eb2-4b5e-892b-ba4355331d59...\n",
      "Fetching observation data for e503a968-6b5e-4105-b91c-b4d0a96dcf89...\n",
      "Fetching observation data for time-18-48-52-989715_chatcmpl-10ae90f0-0a0f-4f8c-9a7e-c47a960bec16...\n",
      "Fetching observation data for time-18-49-04-354374_chatcmpl-065e09f3-1fa1-452d-9906-b10d1712ab83...\n",
      "Fetching observation data for time-18-49-11-258525_chatcmpl-066e4bbd-c7db-4612-ba3d-155a67032210...\n",
      "Fetching observation data for time-18-49-18-896402_chatcmpl-6dab6f9f-c2b9-481e-a41f-9eb72d2243ae...\n",
      "Fetching observation data for time-18-49-30-500789_chatcmpl-bbf7c42f-5e9e-4ea7-bc37-af9d7dd03007...\n",
      "Fetching observation data for 96f4b152-e323-4394-8d24-68109506079f...\n",
      "Fetching observation data for time-18-47-59-171501_chatcmpl-77f0457e-eea5-4c8b-b937-93e704b826b3...\n",
      "Fetching observation data for time-18-48-10-494537_chatcmpl-67f10f69-8cd4-4657-80bd-59959ef5cea5...\n",
      "Fetching observation data for time-18-48-17-112315_chatcmpl-a91d8998-f596-4f25-b77e-f047f07e0e54...\n",
      "Fetching observation data for time-18-48-24-568533_chatcmpl-0704cea7-47a1-4c5d-9c76-d7406ca816e8...\n",
      "Fetching observation data for time-18-48-35-791980_chatcmpl-52855b9f-0067-43cf-9618-2f675918b246...\n",
      "Fetching observation data for c399b12a-d0b9-4306-b772-33cf3a7756be...\n",
      "Fetching observation data for time-18-47-06-640347_chatcmpl-a80e4394-2664-46b5-8673-7f5de7cfb43e...\n",
      "Fetching observation data for time-18-47-17-733074_chatcmpl-6a6c4aa5-8868-4ce9-a948-986896718bd2...\n",
      "Fetching observation data for time-18-47-25-279913_chatcmpl-eb94c004-0e9d-47aa-b51c-acf6d689c429...\n",
      "Fetching observation data for time-18-47-35-752861_chatcmpl-c4d33f51-9e66-40f1-9fc4-4b1accf79889...\n",
      "Fetching observation data for time-18-47-43-587700_chatcmpl-362bdc8b-3903-4e34-9fff-5b6d5799792b...\n",
      "Fetching observation data for 2e7efc07-52e1-4f93-a3d2-606f5c5358c2...\n",
      "Fetching observation data for time-18-46-13-634067_chatcmpl-f48189d0-e45b-44db-bbbe-975f43228ce0...\n",
      "Fetching observation data for time-18-46-24-712231_chatcmpl-18b7f0e0-55e3-488f-8c42-5cf55d0284a9...\n",
      "Fetching observation data for time-18-46-32-230567_chatcmpl-05ebab17-40b5-402a-b234-d1b95043dc63...\n",
      "Fetching observation data for time-18-46-40-771707_chatcmpl-472d5706-857d-41f8-a891-a0cbf39be78f...\n",
      "Fetching observation data for time-18-46-51-314452_chatcmpl-af592ee4-d205-4ce1-8023-e5cbbf3bc8ac...\n",
      "Fetching observation data for 4c5a1910-64da-4588-87df-82e9f3ab28a2...\n",
      "Fetching observation data for time-18-44-51-107082_chatcmpl-05740978-4893-467f-80cd-4d8fb22d1b2f...\n",
      "Fetching observation data for time-18-45-31-393850_chatcmpl-88f2e11c-6499-4462-9d16-9fcb3cc25ca9...\n",
      "Fetching observation data for time-18-45-40-313197_chatcmpl-e0692be4-1b6a-4865-978a-7f6dfa668801...\n",
      "Fetching observation data for time-18-45-49-386239_chatcmpl-bf658aab-194a-446d-b12c-e1f60937b5e2...\n",
      "Fetching observation data for time-18-45-55-206218_chatcmpl-ab8aad0c-4c81-4d7c-9513-7056eff7bb47...\n",
      "Raw JSON saved to: /Users/hann/Projects/reference-benchmark-tinyml_llm/data_analysis/2025/08.11/raw_export/raw_qwen2.5-coder:14b_d266_psg_batch.json\n"
     ]
    }
   ],
   "source": [
    "# ALTERNATIVE TO 2.\n",
    "import os\n",
    "import json\n",
    "from time import sleep\n",
    "from langfuse import Langfuse\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "\n",
    "# LANGFUSE_SERVICE_PUBLIC_KEY = \"pk-lf-559a2c0f-ee29-4c32-944c-bf73b5f0ce28\"\n",
    "# LANGFUSE_SERVICE_SECRET_KEY = \"sk-lf-75f8bf7f-a5db-4756-b0dd-d758a2a292c8\"\n",
    "# LANGFUSE_SERVICE_HOST = \"https://langfuse.hann.fi\"\n",
    "\n",
    "\n",
    "if LOCAL_HOST:\n",
    "    langfuse = Langfuse(\n",
    "        secret_key=\"sk-lf-75f8bf7f-a5db-4756-b0dd-d758a2a292c8\",\n",
    "        public_key=\"pk-lf-559a2c0f-ee29-4c32-944c-bf73b5f0ce28\",\n",
    "        host=\"https://langfuse.hann.fi\",\n",
    "    )\n",
    "else:\n",
    "    langfuse = Langfuse(\n",
    "        secret_key=LANGFUSE_SERVICE_SECRET_KEY,\n",
    "        public_key=LANGFUSE_SERVICE_PUBLIC_KEY,\n",
    "        host=LANGFUSE_SERVICE_HOST,\n",
    "    )\n",
    "\n",
    "API_invok_count = 0\n",
    "query_range_num_run = {\"start\": 0, \"end\": 1}\n",
    "\n",
    "\n",
    "class CustomJSONEncoder(json.JSONEncoder):\n",
    "    def __init__(self, *args, LOCAL_HOST=True, **kwargs):\n",
    "        self.LOCAL_HOST = LOCAL_HOST\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "    def default(self, obj):\n",
    "        if isinstance(obj, datetime):\n",
    "            return obj.isoformat()\n",
    "        if hasattr(obj, \"__dict__\"):\n",
    "            data = obj.__dict__.copy()\n",
    "            if \"observations\" in data:\n",
    "                data[\"observations\"] = [\n",
    "                    fetch_observation_data(obs, self.LOCAL_HOST)\n",
    "                    for obs in data[\"observations\"]\n",
    "                ]\n",
    "\n",
    "            return data\n",
    "        return super().default(obj)\n",
    "\n",
    "\n",
    "def fetch_observation_data(observation_id, LOCAL_HOST):\n",
    "    \"\"\"\n",
    "    Fetches observation data from Langfuse and returns its dictionary representation.\n",
    "    \"\"\"\n",
    "    print(f\"Fetching observation data for {observation_id}...\")\n",
    "    global API_invok_count\n",
    "    if API_invok_count >= 0 and not LOCAL_HOST:\n",
    "        print(\"Waiting for 3 seconds to fetch observation data...\")\n",
    "        for _ in tqdm(range(3), desc=\"Progress\", unit=\"s\"):\n",
    "            sleep(1)\n",
    "        API_invok_count = 0\n",
    "\n",
    "    observation_response = langfuse.fetch_observation(observation_id)\n",
    "    API_invok_count += 1\n",
    "\n",
    "    return observation_response.data.dict()\n",
    "\n",
    "\n",
    "def fetch_and_save_complete_data(session_id_list, raw_export_dir, LOCAL_HOST):\n",
    "    \"\"\"\n",
    "    Fetches complete trace data for each session ID and saves it to JSON files.\n",
    "\n",
    "    Parameters:\n",
    "        session_id_list (list): List of session IDs to process.\n",
    "        raw_export_dir (str): Directory path to save raw JSON files.\n",
    "    \"\"\"\n",
    "\n",
    "    def save_complete_data(session_id):\n",
    "        global API_invok_count\n",
    "        if API_invok_count >= 0 and not LOCAL_HOST:\n",
    "            print(\"Waiting for 4 seconds to fetch traces...\")\n",
    "            for _ in tqdm(range(4), desc=\"Progress\", unit=\"s\"):\n",
    "                sleep(1)\n",
    "            API_invok_count = 0\n",
    "\n",
    "        fetch_traces_response = langfuse.fetch_traces(session_id=session_id)\n",
    "        API_invok_count += 1\n",
    "\n",
    "        print(f\"Fetching traces for session {session_id}...\")\n",
    "        # Create directories if they don't exist\n",
    "        os.makedirs(raw_export_dir, exist_ok=True)\n",
    "\n",
    "        # Save complete data to JSON file\n",
    "        # if session_id.startswith(\"da0a\"):\n",
    "        #     session_id = \"phi4_\" + session_id\n",
    "        if \"tpsg\" in session_id:\n",
    "            session_id_ = session_id.replace(\"tpsg\", \"tpusg\")\n",
    "        else:\n",
    "            session_id_ = session_id\n",
    "            \n",
    "        raw_path = os.path.join(raw_export_dir, f\"raw_{session_id_}.json\")\n",
    "        with open(raw_path, \"w\") as f:\n",
    "            json.dump(fetch_traces_response, f, cls=CustomJSONEncoder, indent=2)\n",
    "\n",
    "        print(f\"Raw JSON saved to: {raw_path}\")\n",
    "\n",
    "    for session_id in session_id_list:\n",
    "        save_complete_data(session_id)\n",
    "\n",
    "\n",
    "fetch_and_save_complete_data(session_id_list, raw_export_dir, LOCAL_HOST)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Trim data\n",
    "\n",
    "Here also intercept the runs with fatal errors that need to be excluded from the analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPAN error_8c_psg_failure_signal_py_sketch_generator: Failed. Last error: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250804190745_psg_qwen2.5-coder:14b/tmp_20250804190745_psg_qwen2.5-coder:14b.py\", line 32, in <module>\n",
      "    input_data = np.frombuffer(raw_data, dtype=input_dtype).reshape(input_shape)\n",
      "ValueError: cannot reshape array of size 564314 into shape (1,300,300,3)\n",
      "\n",
      "SPAN error_c8_psg_failure_signal_py_sketch_generator: Failed. Last error: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250804190700_psg_qwen2.5-coder:14b/tmp_20250804190700_psg_qwen2.5-coder:14b.py\", line 32, in <module>\n",
      "    input_data = np.frombuffer(raw_data, dtype=input_dtype).reshape(input_shape)\n",
      "ValueError: cannot reshape array of size 564314 into shape (1,300,300,3)\n",
      "\n",
      "SPAN error_22_psg_failure_signal_py_sketch_generator: Failed. Last error: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250804190535_psg_qwen2.5-coder:14b/tmp_20250804190535_psg_qwen2.5-coder:14b.py\", line 50, in <module>\n",
      "    class_id = int(detection[1])\n",
      "TypeError: only length-1 arrays can be converted to Python scalars\n",
      "\n",
      "SPAN error_62_psg_failure_signal_py_sketch_generator: Failed. Last error: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250804190443_psg_qwen2.5-coder:14b/tmp_20250804190443_psg_qwen2.5-coder:14b.py\", line 32, in <module>\n",
      "    input_data = np.frombuffer(raw_data, dtype=input_dtype).reshape(input_shape)\n",
      "ValueError: cannot reshape array of size 564314 into shape (1,300,300,3)\n",
      "\n",
      "SPAN error_df_psg_failure_signal_py_sketch_generator: Failed. Last error: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250804190356_psg_qwen2.5-coder:14b/tmp_20250804190356_psg_qwen2.5-coder:14b.py\", line 28, in <module>\n",
      "    image = cv2.resize(image, (input_details[0]['shape'][1], input_details[0]['shape'][2]))\n",
      "cv2.error: OpenCV(4.10.0) /io/opencv/modules/imgproc/src/resize.cpp:4152: error: (-215:Assertion failed) !ssize.empty() in function 'resize'\n",
      "\n",
      "\n",
      "SPAN error_09_psg_failure_signal_py_sketch_generator: Failed. Last error: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250804190307_psg_qwen2.5-coder:14b/tmp_20250804190307_psg_qwen2.5-coder:14b.py\", line 28, in <module>\n",
      "    raw_data = np.load(input_path)  # Example: loading data from a file\n",
      "  File \"/home/wuguangh/.conda/envs/tinyml/lib/python3.10/site-packages/numpy/lib/npyio.py\", line 462, in load\n",
      "    raise ValueError(\"Cannot load file containing pickled data \"\n",
      "ValueError: Cannot load file containing pickled data when allow_pickle=False\n",
      "\n",
      "SPAN error_1d_psg_failure_signal_py_sketch_generator: Failed. Last error: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250804190215_psg_qwen2.5-coder:14b/tmp_20250804190215_psg_qwen2.5-coder:14b.py\", line 37, in <module>\n",
      "    input_data = np.expand_dims(input_data, axis=0)\n",
      "NameError: name 'np' is not defined\n",
      "\n",
      "SPAN error_7b_psg_failure_signal_py_sketch_generator: Failed. Last error: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250804190120_psg_qwen2.5-coder:14b/tmp_20250804190120_psg_qwen2.5-coder:14b.py\", line 33, in <module>\n",
      "    resized_image = cv2.resize(image, (input_shape[1], input_shape[2]))\n",
      "cv2.error: OpenCV(4.10.0) /io/opencv/modules/imgproc/src/resize.cpp:4152: error: (-215:Assertion failed) !ssize.empty() in function 'resize'\n",
      "\n",
      "\n",
      "SPAN error_f7_psg_failure_signal_py_sketch_generator: Failed. Last error: Traceback (most recent call last):\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250804190030_psg_qwen2.5-coder:14b/tmp_20250804190030_psg_qwen2.5-coder:14b.py\", line 17, in <module>\n",
      "    interpreter = Interpreter(model_path=model_path)\n",
      "NameError: name 'Interpreter' is not defined\n",
      "\n",
      "SPAN error_1d_psg_failure_signal_py_sketch_generator: Failed. Last error: Traceback (most recent call last):\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250804185936_psg_qwen2.5-coder:14b/tmp_20250804185936_psg_qwen2.5-coder:14b.py\", line 17, in <module>\n",
      "    interpreter = Interpreter(model_path=model_path)\n",
      "NameError: name 'Interpreter' is not defined\n",
      "\n",
      "SPAN error_4a_psg_failure_signal_py_sketch_generator: Failed. Last error: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250804185844_psg_qwen2.5-coder:14b/tmp_20250804185844_psg_qwen2.5-coder:14b.py\", line 32, in <module>\n",
      "    input_data = np.frombuffer(raw_data, dtype=input_dtype).reshape(input_shape)\n",
      "ValueError: cannot reshape array of size 564314 into shape (1,300,300,3)\n",
      "\n",
      "SPAN error_4f_psg_failure_signal_py_sketch_generator: Failed. Last error: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250804185758_psg_qwen2.5-coder:14b/tmp_20250804185758_psg_qwen2.5-coder:14b.py\", line 53, in <module>\n",
      "    score = float(detection[2])\n",
      "TypeError: only length-1 arrays can be converted to Python scalars\n",
      "\n",
      "SPAN error_5c_psg_failure_signal_py_sketch_generator: Failed. Last error: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250804185704_psg_qwen2.5-coder:14b/tmp_20250804185704_psg_qwen2.5-coder:14b.py\", line 52, in <module>\n",
      "    if score > 0.5:  # Threshold for confidence\n",
      "ValueError: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()\n",
      "\n",
      "SPAN error_87_psg_failure_signal_py_sketch_generator: Failed. Last error: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "qt.qpa.xcb: could not connect to display \n",
      "qt.qpa.plugin: Could not load the Qt platform plugin \"xcb\" in \"/home/wuguangh/.conda/envs/tinyml/lib/python3.10/site-packages/cv2/qt/plugins\" even though it was found.\n",
      "This application failed to start because no Qt platform plugin could be initialized. Reinstalling the application may fix this problem.\n",
      "\n",
      "Available platform plugins are: xcb.\n",
      "\n",
      "\n",
      "SPAN error_c0_psg_failure_signal_py_sketch_generator: Failed. Last error: Traceback (most recent call last):\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250804185521_psg_qwen2.5-coder:14b/tmp_20250804185521_psg_qwen2.5-coder:14b.py\", line 17, in <module>\n",
      "    interpreter = Interpreter(model_path=model_path)\n",
      "NameError: name 'Interpreter' is not defined\n",
      "\n",
      "SPAN error_4f_psg_failure_signal_py_sketch_generator: Failed. Last error: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "qt.qpa.xcb: could not connect to display \n",
      "qt.qpa.plugin: Could not load the Qt platform plugin \"xcb\" in \"/home/wuguangh/.conda/envs/tinyml/lib/python3.10/site-packages/cv2/qt/plugins\" even though it was found.\n",
      "This application failed to start because no Qt platform plugin could be initialized. Reinstalling the application may fix this problem.\n",
      "\n",
      "Available platform plugins are: xcb.\n",
      "\n",
      "\n",
      "SPAN error_b1_psg_failure_signal_py_sketch_generator: Failed. Last error: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250804185339_psg_qwen2.5-coder:14b/tmp_20250804185339_psg_qwen2.5-coder:14b.py\", line 32, in <module>\n",
      "    input_data = np.frombuffer(raw_data, dtype=input_dtype).reshape(input_shape)\n",
      "ValueError: cannot reshape array of size 564314 into shape (1,300,300,3)\n",
      "\n",
      "SPAN error_c2_psg_failure_signal_py_sketch_generator: Failed. Last error: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250804185253_psg_qwen2.5-coder:14b/tmp_20250804185253_psg_qwen2.5-coder:14b.py\", line 32, in <module>\n",
      "    input_data = np.frombuffer(raw_data, dtype=input_dtype).reshape(input_shape)\n",
      "ValueError: cannot reshape array of size 564314 into shape (1,300,300,3)\n",
      "\n",
      "SPAN error_03_psg_failure_signal_py_sketch_generator: Failed. Last error: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250804185205_psg_qwen2.5-coder:14b/tmp_20250804185205_psg_qwen2.5-coder:14b.py\", line 32, in <module>\n",
      "    input_data = np.frombuffer(raw_data, dtype=input_dtype).reshape(input_shape)\n",
      "ValueError: cannot reshape array of size 564314 into shape (1,300,300,3)\n",
      "\n",
      "SPAN error_84_psg_failure_signal_py_sketch_generator: Failed. Last error: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250804185120_psg_qwen2.5-coder:14b/tmp_20250804185120_psg_qwen2.5-coder:14b.py\", line 32, in <module>\n",
      "    input_data = np.frombuffer(raw_data, dtype=input_dtype).reshape(input_shape)\n",
      "ValueError: cannot reshape array of size 564314 into shape (1,300,300,3)\n",
      "\n",
      "SPAN error_3a_psg_failure_signal_py_sketch_generator: Failed. Last error: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250804185034_psg_qwen2.5-coder:14b/tmp_20250804185034_psg_qwen2.5-coder:14b.py\", line 50, in <module>\n",
      "    score = float(detection[2])\n",
      "TypeError: only length-1 arrays can be converted to Python scalars\n",
      "\n",
      "SPAN error_ed_psg_failure_signal_py_sketch_generator: Failed. Last error: Traceback (most recent call last):\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250804184940_psg_qwen2.5-coder:14b/tmp_20250804184940_psg_qwen2.5-coder:14b.py\", line 17, in <module>\n",
      "    interpreter = Interpreter(model_path=model_path)\n",
      "NameError: name 'Interpreter' is not defined\n",
      "\n",
      "SPAN error_9a_psg_failure_signal_py_sketch_generator: Failed. Last error: Traceback (most recent call last):\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250804184846_psg_qwen2.5-coder:14b/tmp_20250804184846_psg_qwen2.5-coder:14b.py\", line 17, in <module>\n",
      "    interpreter = Interpreter(model_path=model_path)\n",
      "NameError: name 'Interpreter' is not defined\n",
      "\n",
      "SPAN error_7e_psg_failure_signal_py_sketch_generator: Failed. Last error: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250804184752_psg_qwen2.5-coder:14b/tmp_20250804184752_psg_qwen2.5-coder:14b.py\", line 50, in <module>\n",
      "    score = float(detection[2])\n",
      "TypeError: only length-1 arrays can be converted to Python scalars\n",
      "\n",
      "SPAN error_e4_psg_failure_signal_py_sketch_generator: Failed. Last error: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250804184659_psg_qwen2.5-coder:14b/tmp_20250804184659_psg_qwen2.5-coder:14b.py\", line 38, in <module>\n",
      "    input_data = np.expand_dims(input_data, axis=0)\n",
      "NameError: name 'np' is not defined\n",
      "\n",
      "Successfully processed and saved trimmed data for session qwen2.5-coder:14b_d266_psg_batch\n",
      "Total 0 traces skipped. They are []\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "skipped_traces = []\n",
    "\n",
    "\n",
    "def process_existing_observation(observation):\n",
    "    \"\"\"\n",
    "    Processes an existing observation dictionary by trimming unwanted keys.\n",
    "    \"\"\"\n",
    "    unwanted_observation_keys = [\n",
    "        \"completionStartTime\",\n",
    "        \"metadata\",\n",
    "        \"timeToFirstToken\",\n",
    "        \"createdAt\",\n",
    "        \"usageDetails\",\n",
    "        \"usage\",\n",
    "        \"projectId\",\n",
    "        \"unit\",\n",
    "        \"updatedAt\",\n",
    "        \"version\",\n",
    "        \"parentObservationId\",\n",
    "        \"promptId\",\n",
    "        \"promptName\",\n",
    "        \"promptVersion\",\n",
    "        \"modelId\",\n",
    "        \"inputPrice\",\n",
    "        \"outputPrice\",\n",
    "        \"totalPrice\",\n",
    "        # \"modelParameters\",\n",
    "        \"input\",\n",
    "        \"output\",\n",
    "    ]\n",
    "\n",
    "    # If observation is a dictionary containing observation data\n",
    "    if isinstance(observation, dict):\n",
    "        trimmed_observation = {\n",
    "            k: v for k, v in observation.items() if k not in unwanted_observation_keys\n",
    "        }\n",
    "        return trimmed_observation\n",
    "    return observation\n",
    "\n",
    "\n",
    "def trim_data(data):\n",
    "    \"\"\"\n",
    "    Recursively trims the data structure.\n",
    "    \"\"\"\n",
    "\n",
    "    if isinstance(data, dict):\n",
    "        # Process the current dictionary\n",
    "        unwanted_trace_keys = [\n",
    "            \"release\",\n",
    "            \"version\",\n",
    "            \"user_id\",\n",
    "            \"public\",\n",
    "            \"html_path\",\n",
    "            \"scores\",\n",
    "            \"bookmarked\",\n",
    "            \"projectId\",\n",
    "            \"externalId\",\n",
    "            \"page\",\n",
    "            \"limit\",\n",
    "            \"total_pages\",\n",
    "        ]\n",
    "\n",
    "        # If this is a trace that contains observations, check for fatal errors\n",
    "        if \"observations\" in data:\n",
    "            # Check for SPAN observations with fatal errors before processing\n",
    "            skip_trace = False\n",
    "            for obs in data[\"observations\"]:\n",
    "                if isinstance(obs, dict) and obs.get(\"name\").startswith(\"error\"):\n",
    "                    status_message = obs.get(\"statusMessage\", \"\")\n",
    "                    ob_name = obs.get(\"name\")\n",
    "                    print(f\"SPAN {ob_name}: {status_message}\")\n",
    "\n",
    "                    if \"Fatal error\" in status_message:\n",
    "                        print(f\"Found Fatal error in SPAN observation, skipping trace\")\n",
    "                        skip_trace = True\n",
    "                        skipped_traces.append(data[\"name\"])\n",
    "                        break\n",
    "\n",
    "            if skip_trace:\n",
    "                return None  # Signal to skip this trace\n",
    "\n",
    "        # Create a new dictionary with wanted keys and recursively process values\n",
    "        trimmed_data = {}\n",
    "        for key, value in data.items():\n",
    "            if key not in unwanted_trace_keys:\n",
    "                if key == \"observations\":\n",
    "                    # Special handling for observations\n",
    "                    trimmed_data[key] = [\n",
    "                        process_existing_observation(obs) for obs in value\n",
    "                    ]\n",
    "                elif isinstance(value, (dict, list)):\n",
    "                    # Recursively process nested structures\n",
    "                    trimmed_data[key] = trim_data(value)\n",
    "                else:\n",
    "                    trimmed_data[key] = value\n",
    "\n",
    "        return trimmed_data\n",
    "\n",
    "    elif isinstance(data, list):\n",
    "        # Recursively process each item in the list\n",
    "        processed_items = []\n",
    "        for item in data:\n",
    "            processed_item = trim_data(item)\n",
    "            if processed_item is not None:  # Only add items that weren't filtered out\n",
    "                processed_items.append(processed_item)\n",
    "        return processed_items\n",
    "\n",
    "    else:\n",
    "        # Return non-dict, non-list values as is\n",
    "        return data\n",
    "\n",
    "\n",
    "def read_and_trim_data(session_id_list, raw_export_dir, trimmed_export_dir):\n",
    "    \"\"\"\n",
    "    Reads complete data from JSON files, trims the data, and saves the trimmed data to new JSON files.\n",
    "    \"\"\"\n",
    "    os.makedirs(trimmed_export_dir, exist_ok=True)\n",
    "\n",
    "    for session_id in session_id_list:\n",
    "        try:\n",
    "            if session_id.startswith(\"da0a\"):\n",
    "                session_id = \"phi4_\" + session_id\n",
    "            # Read raw data\n",
    "            if \"tpsg\" in session_id:\n",
    "                session_id_ = session_id.replace(\"tpsg\", \"tpusg\")\n",
    "            else:\n",
    "                session_id_ = session_id\n",
    "            raw_path = os.path.join(raw_export_dir, f\"raw_{session_id_}.json\")\n",
    "            with open(raw_path, \"r\") as f:\n",
    "                data = json.load(f)\n",
    "\n",
    "            # Process and trim the data\n",
    "            trimmed_data = trim_data(data)\n",
    "\n",
    "            # If the entire data was filtered out (unlikely but possible)\n",
    "            if trimmed_data is None:\n",
    "                print(\n",
    "                    f\"All traces in session {session_id} were filtered due to fatal errors\"\n",
    "                )\n",
    "                continue\n",
    "\n",
    "            # Save trimmed data\n",
    "            if \"tpsg\" in session_id:\n",
    "                session_id_ = session_id.replace(\"tpsg\", \"tpusg\")\n",
    "            else:\n",
    "                session_id_ = session_id\n",
    "            trimmed_path = os.path.join(\n",
    "                trimmed_export_dir, f\"trimmed_{session_id_}.json\"\n",
    "            )\n",
    "            with open(trimmed_path, \"w\") as f:\n",
    "                json.dump(trimmed_data, f, indent=2)\n",
    "\n",
    "            print(\n",
    "                f\"Successfully processed and saved trimmed data for session {session_id}\"\n",
    "            )\n",
    "\n",
    "            # Optional: Verify trimming worked\n",
    "            # print(f\"Verifying trimmed data for session {session_id}...\")\n",
    "            # verify_trimming(trimmed_path)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing session {session_id}: {str(e)}\")\n",
    "\n",
    "\n",
    "def verify_trimming(trimmed_path):\n",
    "    \"\"\"\n",
    "    Verifies that the trimmed data doesn't contain unwanted keys.\n",
    "    \"\"\"\n",
    "    with open(trimmed_path, \"r\") as f:\n",
    "        trimmed_data = json.load(f)\n",
    "\n",
    "    unwanted_keys = [\n",
    "        \"release\",\n",
    "        \"version\",\n",
    "        \"user_id\",\n",
    "        \"public\",\n",
    "        \"html_path\",\n",
    "        \"scores\",\n",
    "        \"bookmarked\",\n",
    "        \"projectId\",\n",
    "        \"externalId\",\n",
    "        \"page\",\n",
    "        \"limit\",\n",
    "        \"total_pages\",\n",
    "        \"completionStartTime\",\n",
    "        \"metadata\",\n",
    "        \"usageDetails\",\n",
    "        \"timeToFirstToken\",\n",
    "        \"createdAt\",\n",
    "        \"completionTokens\",\n",
    "        \"promptTokens\",\n",
    "        \"projectId\",\n",
    "        \"unit\",\n",
    "        \"updatedAt\",\n",
    "        \"version\",\n",
    "        # \"statusMessage\",\n",
    "        \"parentObservationId\",\n",
    "        \"promptId\",\n",
    "        \"promptName\",\n",
    "        \"promptVersion\",\n",
    "        \"modelId\",\n",
    "        \"inputPrice\",\n",
    "        \"outputPrice\",\n",
    "        \"totalPrice\",\n",
    "        \"calculatedInputCost\",\n",
    "        \"calculatedOutputCost\",\n",
    "        \"calculatedTotalCost\",\n",
    "    ]\n",
    "\n",
    "    def check_keys(obj):\n",
    "        if isinstance(obj, dict):\n",
    "            for key in obj.keys():\n",
    "                if key in unwanted_keys:\n",
    "                    print(f\"Warning: Found unwanted key '{key}' in trimmed data\")\n",
    "            for value in obj.values():\n",
    "                check_keys(value)\n",
    "        elif isinstance(obj, list):\n",
    "            for item in obj:\n",
    "                check_keys(item)\n",
    "\n",
    "    check_keys(trimmed_data)\n",
    "    print(\"Verification complete\")\n",
    "\n",
    "\n",
    "# Usage example:\n",
    "read_and_trim_data(session_id_list, raw_export_dir, raw_export_dir)\n",
    "print(f\"Total {len(skipped_traces)} traces skipped. They are {skipped_traces}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Generate CSV files from JSON\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing session qwen2.5-coder:14b_d266_psg_batch, simple id qwen2.5-coder:14b_d266. Look for /Users/hann/Projects/reference-benchmark-tinyml_llm/data_analysis/2025/08.11/raw_export/trimmed_qwen2.5-coder:14b_d266_psg_batch.json\n",
      "/Users/hann/Projects/reference-benchmark-tinyml_llm/data_analysis/2025/08.11/processed_data/qwen2.5-coder:14b_d266/clean_qwen2.5-coder:14b_d266_psg_batch.csv\n",
      "Successfully saved CSV to: /Users/hann/Projects/reference-benchmark-tinyml_llm/data_analysis/2025/08.11/processed_data/qwen2.5-coder:14b_d266/clean_qwen2.5-coder:14b_d266_psg_batch.csv\n"
     ]
    }
   ],
   "source": [
    "import traceback\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from dateutil import parser\n",
    "\n",
    "\n",
    "def json_to_csv(session_id):\n",
    "    \"\"\"\n",
    "    Convert JSON trace data to CSV format with aggregated metrics.\n",
    "\n",
    "    Args:\n",
    "        session_id (str): Identifier for the session to process\n",
    "    \"\"\"\n",
    "\n",
    "    def extract_observation_details(observations, trace_id):\n",
    "        \"\"\"Extract and aggregate metrics from observations\"\"\"\n",
    "        metrics = {\n",
    "            \"status\": None,\n",
    "            \"latency\": 0,\n",
    "            \"total_tokens\": 0,\n",
    "            \"prompt_tokens\": 0,\n",
    "            \"completion_tokens\": 0,\n",
    "            \"total_cost\": 0,\n",
    "            \"input_cost\": 0,\n",
    "            \"output_cost\": 0,\n",
    "            \"parameters\": set(),\n",
    "        }\n",
    "\n",
    "        # Process GENERATION observations\n",
    "        for obs in (o for o in observations if o[\"type\"] == \"GENERATION\"):\n",
    "            metrics[\"total_tokens\"] += obs[\"totalTokens\"]\n",
    "            metrics[\"prompt_tokens\"] += obs[\"promptTokens\"]\n",
    "            metrics[\"completion_tokens\"] += obs[\"completionTokens\"]\n",
    "            metrics[\"latency\"] += obs[\"latency\"]\n",
    "            for key, value in obs[\"modelParameters\"].items():\n",
    "                metrics[\"parameters\"].add(key + \":\" + value)\n",
    "\n",
    "            # Add costs if present\n",
    "            for cost_type in [\"Total\", \"Input\", \"Output\"]:\n",
    "                key = f\"calculated{cost_type}Cost\"\n",
    "                metric_key = cost_type.lower() + \"_cost\"\n",
    "                if obs.get(key) is not None:\n",
    "                    metrics[metric_key] += obs[key]\n",
    "        if len(metrics[\"parameters\"]) == 0:\n",
    "            metrics[\"parameters\"] = \"N/A\"\n",
    "        # Process SPAN observations for status\n",
    "        status_indicators = [\n",
    "            obs[\"name\"]\n",
    "            for obs in observations\n",
    "            if obs[\"type\"] == \"SPAN\" and \"start_\" not in obs[\"name\"]\n",
    "        ]\n",
    "\n",
    "        #  if later than 2025-05-19, use status_signal_from_output\n",
    "        if datetime.now() > datetime(2025, 5, 19):\n",
    "            pass\n",
    "        else:\n",
    "            # Determine status\n",
    "            success_signals = sum(\"end_\" in name for name in status_indicators)\n",
    "            failure_signals = sum(\n",
    "                \"failure_signal\" in name for name in status_indicators\n",
    "            )\n",
    "\n",
    "            if success_signals + failure_signals > 1:\n",
    "                raise ValueError(\n",
    "                    f\"Multiple status indicators found in trace {trace_id}\"\n",
    "                )\n",
    "\n",
    "            metrics[\"status\"] = (\n",
    "                \"success\"\n",
    "                if success_signals\n",
    "                else \"failure\" if failure_signals else \"unknown\"\n",
    "            )\n",
    "\n",
    "        metrics[\"prompt_cost\"] = metrics.pop(\"input_cost\")\n",
    "        metrics[\"completion_cost\"] = metrics.pop(\"output_cost\")\n",
    "        metrics[\"latency\"] = round(metrics[\"latency\"] / 1000, 2)\n",
    "        return metrics\n",
    "\n",
    "    def cal_time(trace):\n",
    "        time_diff = datetime.fromisoformat(\n",
    "            trace[\"updatedAt\"].replace(\"Z\", \"+00:00\")\n",
    "        ) - datetime.fromisoformat(trace[\"createdAt\"].replace(\"Z\", \"+00:00\"))\n",
    "        seconds_diff = time_diff.total_seconds()\n",
    "        return seconds_diff\n",
    "\n",
    "    try:\n",
    "\n",
    "        if session_id.startswith(\"da0a\"):\n",
    "            session_id = \"phi4_\" + session_id\n",
    "        simple_session_id = session_id.rsplit(\"_\", 2)[0]\n",
    "\n",
    "        \n",
    "        # Load JSON data\n",
    "        if \"tpsg\" in session_id:\n",
    "                session_id_ = session_id.replace(\"tpsg\", \"tpusg\")\n",
    "        else:\n",
    "                session_id_ = session_id\n",
    "        trimmed_path = os.path.join(raw_export_dir, f\"trimmed_{session_id_}.json\")\n",
    "        print(\n",
    "            f\"Processing session {session_id}, simple id {simple_session_id}. Look for {trimmed_path}\"\n",
    "        )\n",
    "        with open(trimmed_path, \"r\") as file:\n",
    "            traces = json.load(file)[\"data\"]\n",
    "\n",
    "        # Process traces\n",
    "        rows = [\n",
    "            {\n",
    "                \"num_run\": trace[\"metadata\"][\"num_run\"],\n",
    "                \"name\": trace[\"name\"],\n",
    "                \"trace_id\": trace[\"id\"],\n",
    "                \"batch_id\": trace[\"session_id\"],\n",
    "                # \"latency\": cal_time(trace),\n",
    "                # \"latency\": round(trace[\"latency\"], 2),\n",
    "                **extract_observation_details(\n",
    "                    trace[\"observations\"],\n",
    "                    trace[\"id\"],\n",
    "                ),\n",
    "                \"status\": (\n",
    "                    \"failure\"\n",
    "                    if trace[\"output\"][\"status\"].lower() == \"failed\"\n",
    "                    else \"success\"\n",
    "                ),\n",
    "                \"tags\": trace[\"tags\"],\n",
    "                \"timestamp\": int(parser.isoparse(trace[\"timestamp\"]).timestamp()),\n",
    "            }\n",
    "            for trace in traces\n",
    "        ]\n",
    "        # print(rows)\n",
    "        # print(rows)\n",
    "        # Create and save DataFrame\n",
    "        df = pd.DataFrame(rows).sort_values(\"num_run\")\n",
    "\n",
    "        output_dir = os.path.join(processed_data_dir, f\"{simple_session_id}\")\n",
    "        if not os.path.exists(output_dir):\n",
    "            os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "        output_path = os.path.join(output_dir, f\"clean_{session_id_}.csv\")\n",
    "\n",
    "        print(output_path)\n",
    "        df.to_csv(output_path, index=False)\n",
    "        print(f\"Successfully saved CSV to: {output_path}\")\n",
    "\n",
    "    except FileNotFoundError as e:\n",
    "        print(\n",
    "            f\"FileNotFoundError: For session {session_id} not found. Looked for {trimmed_path}\\nError info: \\n{e}\\n\\nTraceback: {traceback.format_exc()}\"\n",
    "        )\n",
    "    except json.JSONDecodeError:\n",
    "        print(f\"Error: Invalid JSON format in input file for session {session_id}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing session {session_id}: {str(e)}\")\n",
    "\n",
    "\n",
    "# Example usage\n",
    "for session_id in session_id_list:\n",
    "    json_to_csv(session_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code below is archived\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"\"\"Simply calculate success rate\"\"\"\n",
    "\n",
    "\n",
    "# def cal_success_rate(session_id):\n",
    "\n",
    "#     end_signal_count = 0\n",
    "#     failure_signal_count = 0\n",
    "#     # Function to print the name of each observation\n",
    "#     with open(f\"{raw_export_dir}/trimmed_{session_id}.json\", \"r\") as file:\n",
    "#         data = json.load(file)[\"data\"]\n",
    "#     for i in data:\n",
    "\n",
    "#         observations = i[\"observations\"]\n",
    "\n",
    "#         for observation in observations:\n",
    "#             # print(type(observation))\n",
    "#             for key, value in observation.items():\n",
    "#                 # print(f\"{key}: {value}\")\n",
    "#                 for key, value in value.items():\n",
    "#                     # print(f\"{key}: {value}\")\n",
    "#                     if key == \"name\":\n",
    "#                         if \"end_\" in value:\n",
    "\n",
    "#                             end_signal_count += 1\n",
    "#                         if \"failure_signal\" in value:\n",
    "\n",
    "#                             failure_signal_count += 1\n",
    "\n",
    "#     print(f\"Session ID: {session_id}\")\n",
    "#     total_count = end_signal_count + failure_signal_count\n",
    "#     if total_count > 0:\n",
    "#         success_rate = end_signal_count / total_count\n",
    "#         print(f\"Success rate: {success_rate:.4f}\")\n",
    "#     else:\n",
    "#         print(\"Success rate: N/A (no signals found)\")\n",
    "#     print(f\"Passed:\\t{end_signal_count}\\nFailed:\\t{failure_signal_count}\")\n",
    "#     print(\n",
    "#         \"\"\n",
    "#         if total_count == 30\n",
    "#         else \"Number of ending signals does not match the expected number!\"\n",
    "#     )\n",
    "#     print(\"-\" * 50)\n",
    "\n",
    "\n",
    "# for session_id in session_id_list:\n",
    "#     cal_success_rate(session_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def cal_time(start_time, end_time):\n",
    "#     time_diff = datetime.fromisoformat(\n",
    "#         end_time.replace(\"Z\", \"+00:00\")\n",
    "#     ) - datetime.fromisoformat(start_time.replace(\"Z\", \"+00:00\"))\n",
    "#     seconds_diff = time_diff.total_seconds()\n",
    "#     return seconds_diff\n",
    "\n",
    "\n",
    "# print(cal_time(\"2025-01-15T03:31:56.150000+00:00\", \"2025-01-15T03:32:59.384Z\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"\"\"Print the complete structure of exported json file\"\"\"\n",
    "# def print_keys(d, parent_key=''):\n",
    "#     if isinstance(d, dict):\n",
    "#         for key, value in d.items():\n",
    "#             full_key = f\"{parent_key}.{key}\" if parent_key else key\n",
    "#             print(full_key)\n",
    "#             print_keys(value, full_key)\n",
    "#     elif isinstance(d, list):\n",
    "#         for i, item in enumerate(d):\n",
    "#             full_key = f\"{parent_key}[{i}]\"\n",
    "#             print_keys(item, full_key)\n",
    "\n",
    "# # Load JSON data from a file\n",
    "# with open('fetch_traces_response.json', 'r') as file:\n",
    "#     data = json.load(file)['data'][0]\n",
    "# # Print all keys\n",
    "# print_keys(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1747226053\n",
      "1747226053.1\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "from dateutil import parser\n",
    "\n",
    "timestamp_str = \"2025-05-14T12:34:13.100000+00:00\"\n",
    "dt = parser.isoparse(\n",
    "    timestamp_str\n",
    ")  # Or datetime.fromisoformat(timestamp_str) if no timezone offset\n",
    "unix_ts = int(dt.timestamp())\n",
    "\n",
    "print(unix_ts)  # This will print the integer Unix timestamp\n",
    "print(datetime.fromisoformat(timestamp_str).timestamp())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datasci2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

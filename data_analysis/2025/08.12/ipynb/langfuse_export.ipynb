{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setting up\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ref: https://langfuse.com/docs/query-traces\n",
    "import os\n",
    "import json\n",
    "from langfuse import Langfuse\n",
    "import json\n",
    "import os\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "LOCAL_HOST = True\n",
    "\n",
    "\"\"\"Define session_id\"\"\"\n",
    "# session_id=\"qwen2.5-coder_f4d4_dp_batch\"\n",
    "session_id_list = [\n",
    "    # \"qwen2.5-coder:32b_4e11_tpsg_batch\",\n",
    "    # \"qwen2.5-coder:32b_ae24_tpsg_batch\"\n",
    "    \"gemma3:27b_d558_psg_batch\",\n",
    "    \"gemma3:27b_b603_tpusg_batch\"\n",
    " \n",
    "]\n",
    "\n",
    "\n",
    "\"\"\"Define paths\"\"\"\n",
    " \n",
    "parent_dir = os.path.dirname(os.getcwd())\n",
    "\n",
    " \n",
    "# date = os.path.basename(parent_dir)\n",
    "tex_dir = os.path.join(parent_dir, \"tex\")\n",
    "processed_data_dir = os.path.join(parent_dir, \"processed_data\")\n",
    "raw_export_dir = os.path.join(parent_dir, \"raw_export\")\n",
    "ipynb_dir = os.path.join(parent_dir, \"ipynb\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Export raw data\n",
    "\n",
    "Langfuse added a limit of 20 API invocations per minute. https://langfuse.com/faq/all/api-limits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching traces for session gemma3:27b_d558_psg_batch...\n",
      "Fetching observation data for time-04-06-41-707188_chatcmpl-18c585f4-57fb-447b-93d7-5cb4e924c966...\n",
      "Fetching observation data for time-04-07-07-690219_chatcmpl-3eed66eb-6c02-4ba5-b7a6-f6c6f2535237...\n",
      "Fetching observation data for time-04-07-29-883350_chatcmpl-f1076d97-0dfe-4b39-9314-9b9d278b10c5...\n",
      "Fetching observation data for time-04-07-46-934961_chatcmpl-6181823a-4980-4a19-8640-38a4f4a6f452...\n",
      "Fetching observation data for time-04-08-09-403423_chatcmpl-51fcc8bf-4c0d-4068-a99f-3f4daffd1f3e...\n",
      "Fetching observation data for time-04-04-49-139847_chatcmpl-9c3db6cb-7bf4-47cb-a96d-ae84e178d969...\n",
      "Fetching observation data for time-04-05-15-122969_chatcmpl-c4f0f1da-f7b5-4dd8-87e5-3791a1d3baca...\n",
      "Fetching observation data for time-04-05-37-331267_chatcmpl-67036c3a-ae7c-4548-9980-41d729847d2a...\n",
      "Fetching observation data for time-04-05-57-971025_chatcmpl-d7f77e5b-1945-40ef-a6fa-a6282648eee8...\n",
      "Fetching observation data for time-04-06-19-795750_chatcmpl-11b4595a-1dce-4317-9b3d-ec1f5d69a7c3...\n",
      "Fetching observation data for time-04-02-55-278063_chatcmpl-535f7576-a6a4-48c2-8982-e84a5bc94d1d...\n",
      "Fetching observation data for time-04-03-21-313665_chatcmpl-112db846-8f13-4040-a3b0-e223aaa51d67...\n",
      "Fetching observation data for time-04-03-43-540173_chatcmpl-30078155-072a-41a2-97cb-808c79f0abeb...\n",
      "Fetching observation data for time-04-04-05-121090_chatcmpl-294c988e-8978-4064-97f7-12d74ccd1292...\n",
      "Fetching observation data for time-04-04-29-747136_chatcmpl-6efc06cb-36eb-45db-ba38-186de1449a78...\n",
      "Fetching observation data for time-04-01-09-435830_chatcmpl-84ec7127-aa80-4835-9d40-597d57b2bc96...\n",
      "Fetching observation data for time-04-01-35-401109_chatcmpl-2a416553-cef5-46ab-9526-2e4a11d8841a...\n",
      "Fetching observation data for time-04-01-57-593008_chatcmpl-18f4c8f1-98f8-4ba8-80c7-5a78b938c742...\n",
      "Fetching observation data for time-04-02-14-646740_chatcmpl-94078ff3-3876-49e7-85ae-e02ba76c5d9e...\n",
      "Fetching observation data for time-04-02-37-130512_chatcmpl-d2a21086-e00c-4986-a1fe-aac694132ba7...\n",
      "Fetching observation data for time-03-59-41-831201_chatcmpl-ee87fd29-b60a-45d6-a40c-f68f4f954c76...\n",
      "Fetching observation data for time-04-00-07-805111_chatcmpl-cbca8ccb-af64-475a-b5a7-843881ddc26b...\n",
      "Fetching observation data for time-04-00-30-006667_chatcmpl-938045b6-6115-44c0-ae94-78a3e6e23004...\n",
      "Fetching observation data for time-04-00-48-327138_chatcmpl-4e902138-653a-411f-a8cf-bfd0cc667c98...\n",
      "Fetching observation data for time-03-57-53-237179_chatcmpl-ff7a6c5f-a1db-4f4f-83dd-e8ba0a185d7d...\n",
      "Fetching observation data for time-03-58-19-205052_chatcmpl-3407b553-f92e-4b72-93b9-f405163114f6...\n",
      "Fetching observation data for time-03-58-41-438658_chatcmpl-34faef82-6078-45d9-8fe5-037c95ba8343...\n",
      "Fetching observation data for time-03-58-58-461060_chatcmpl-c43fc1cc-2756-42aa-9f8f-84808ec8480a...\n",
      "Fetching observation data for time-03-59-20-672078_chatcmpl-b415abbf-d6e2-4335-a7c8-485c50d3694f...\n",
      "Fetching observation data for time-03-56-03-716690_chatcmpl-398c8cde-33f0-420e-8f9c-3325ebf4602a...\n",
      "Fetching observation data for time-03-56-29-673919_chatcmpl-c984091a-d1ac-4927-9d4b-ee916d193d8b...\n",
      "Fetching observation data for time-03-56-51-868137_chatcmpl-b8c50c36-da90-4cdd-a55f-6d67bcb5ad8a...\n",
      "Fetching observation data for time-03-57-10-864060_chatcmpl-e921320b-e90f-42c8-b0bd-3adbef064183...\n",
      "Fetching observation data for time-03-57-26-644648_chatcmpl-1f2f19cc-bcfb-4dee-9f6a-d6eaf0fad26a...\n",
      "Fetching observation data for time-03-54-30-165566_chatcmpl-2fc06561-040a-40db-b8fd-87b870d9dfd2...\n",
      "Fetching observation data for time-03-54-56-116295_chatcmpl-005f5c11-124b-42e0-abf3-0af2c6ed21eb...\n",
      "Fetching observation data for time-03-55-18-350152_chatcmpl-fffd65af-dcac-48e8-9bd5-9ba592af117b...\n",
      "Fetching observation data for time-03-55-35-388897_chatcmpl-f38b7bcd-44bd-49cc-a9d7-16b12e0b1c62...\n",
      "Fetching observation data for time-03-52-38-609358_chatcmpl-7b213b0b-2c54-4466-b815-6f8dfac6d5bd...\n",
      "Fetching observation data for time-03-53-04-581097_chatcmpl-94ae10d0-cd44-4493-b733-cb48a40eed68...\n",
      "Fetching observation data for time-03-53-26-784371_chatcmpl-9a5e559d-d249-4c5c-b0bb-eafcffa807a5...\n",
      "Fetching observation data for time-03-53-43-849399_chatcmpl-b99f282b-4174-4dfb-8fcb-e6c85485159f...\n",
      "Fetching observation data for time-03-54-03-661474_chatcmpl-bab1998a-0c57-4c72-8035-2132d75b1653...\n",
      "Fetching observation data for 662baa18-c4b3-49ff-94e6-311673ccff06...\n",
      "Fetching observation data for time-03-50-51-056797_chatcmpl-90f59154-8ea1-4dd3-9a98-c4179c0e50dd...\n",
      "Fetching observation data for time-03-51-17-007638_chatcmpl-84757487-8516-4fd3-96d7-66ed897e30ce...\n",
      "Fetching observation data for time-03-51-39-222112_chatcmpl-78ec02f1-4c5c-449b-83e9-5bc544eec2e6...\n",
      "Fetching observation data for time-03-51-56-262150_chatcmpl-09393871-738d-4d97-aa10-e7e60e4538d0...\n",
      "Fetching observation data for time-03-52-16-034133_chatcmpl-b012e3f2-d37e-44da-af25-1670534e97b1...\n",
      "Fetching observation data for time-03-49-02-384926_chatcmpl-b5e19332-c243-4782-878f-c69682ced799...\n",
      "Fetching observation data for time-03-49-28-377486_chatcmpl-126397ec-cc24-43dd-8425-1e878b17b061...\n",
      "Fetching observation data for time-03-49-50-656510_chatcmpl-2464e8bb-068d-4c5c-b43d-0fa35c6f5f98...\n",
      "Fetching observation data for time-03-50-07-700189_chatcmpl-7ff97ee6-4ca5-4a5c-a2ac-fee46996c38d...\n",
      "Fetching observation data for time-03-50-28-336354_chatcmpl-28499112-1f8c-4ad2-990c-54514bd2231c...\n",
      "Fetching observation data for time-03-47-29-330761_chatcmpl-f9093824-9c11-4667-a70b-c2e5dae9ebec...\n",
      "Fetching observation data for time-03-47-55-310079_chatcmpl-ec5ab349-66a3-4b18-93d7-619aaf10744d...\n",
      "Fetching observation data for time-03-48-17-506363_chatcmpl-905a31ed-352c-4cf2-aa3f-79e7bfaa91f9...\n",
      "Fetching observation data for time-03-48-33-850450_chatcmpl-64f99777-58e5-4e95-91a7-837d1767d8ff...\n",
      "Fetching observation data for time-03-45-57-494317_chatcmpl-5b250f5e-e913-4866-a032-b8d97a1dea35...\n",
      "Fetching observation data for time-03-46-23-484024_chatcmpl-952a1879-3812-45d6-a6ba-de8b6838b14c...\n",
      "Fetching observation data for time-03-46-45-733825_chatcmpl-38cf5e18-47b0-4562-a0b3-d0294c17a0c1...\n",
      "Fetching observation data for time-03-47-02-793358_chatcmpl-c5cd5638-01cf-4e91-a472-3c32388304f9...\n",
      "Fetching observation data for time-03-44-07-969169_chatcmpl-23e5fcaf-f212-4537-b3f2-59a66cf3dac7...\n",
      "Fetching observation data for time-03-44-33-898636_chatcmpl-4e75b9b8-e502-408f-9bb3-f3149a3f7cfd...\n",
      "Fetching observation data for time-03-44-56-143041_chatcmpl-dac238c2-56a3-4446-ab52-e64666de5a89...\n",
      "Fetching observation data for time-03-45-13-188570_chatcmpl-fca44d46-2cc6-4ea1-b356-ac52e5deafbc...\n",
      "Fetching observation data for time-03-45-35-913218_chatcmpl-68d22cec-8c4f-4bdb-8612-8ffc757d883a...\n",
      "Fetching observation data for time-03-42-38-021647_chatcmpl-c319d09b-d449-4d13-ba21-d4a54cd11510...\n",
      "Fetching observation data for time-03-43-03-951479_chatcmpl-075cbf53-32a2-418a-865d-bbc03a0271d7...\n",
      "Fetching observation data for time-03-43-26-183519_chatcmpl-6b478518-80a0-4fb1-8b28-9fcdeb922167...\n",
      "Fetching observation data for time-03-43-43-194911_chatcmpl-44cdfc4a-09b8-4f0d-ab34-e00beb8b8f84...\n",
      "Fetching observation data for time-03-40-46-361317_chatcmpl-16a91e26-e222-441e-a158-9d463d1f7bfe...\n",
      "Fetching observation data for time-03-41-12-318173_chatcmpl-666727e8-0fbd-4c1d-8c73-efe2d2b134d6...\n",
      "Fetching observation data for time-03-41-34-511546_chatcmpl-7ff0f650-2e6e-408b-93c3-62a808ddd3d6...\n",
      "Fetching observation data for time-03-41-52-229103_chatcmpl-0f646c23-0d4b-47ce-9887-e9d4d9b3545e...\n",
      "Fetching observation data for time-03-42-11-302079_chatcmpl-edd7f954-e642-4efe-a657-a7acc3458213...\n",
      "Fetching observation data for time-03-38-55-807349_chatcmpl-2a3e0bf7-312f-4f1a-86d5-8e207d1a15a4...\n",
      "Fetching observation data for time-03-39-21-778252_chatcmpl-da00390d-cb84-4fb4-adb3-e13bdc4baa2a...\n",
      "Fetching observation data for time-03-39-44-006250_chatcmpl-949b5042-83b5-45f4-924b-10716e90ba31...\n",
      "Fetching observation data for time-03-40-03-001831_chatcmpl-be692f44-aa4a-4281-b485-5efa18374726...\n",
      "Fetching observation data for time-03-40-21-503125_chatcmpl-a5df6300-f96f-4660-a52f-b2adba4c747a...\n",
      "Fetching observation data for time-03-37-07-041186_chatcmpl-2d37c08e-717c-451e-ba2c-c301d0926845...\n",
      "Fetching observation data for time-03-37-33-036932_chatcmpl-cf227ace-ee7a-4fee-a1d6-2e0fae4a5978...\n",
      "Fetching observation data for time-03-37-55-232645_chatcmpl-eaf15a92-b69d-47c6-9f79-0cf221d43347...\n",
      "Fetching observation data for time-03-38-12-266410_chatcmpl-bb451a98-3964-48ea-9c44-326e4a7c4fa0...\n",
      "Fetching observation data for time-03-38-35-052289_chatcmpl-cee87090-efbd-4d55-9836-773875226978...\n",
      "Fetching observation data for time-03-35-33-088466_chatcmpl-7070bc68-ce4c-4ac8-a570-53b301533d9c...\n",
      "Fetching observation data for time-03-35-59-080562_chatcmpl-9f54ca18-733d-40e1-837f-10c9ca357657...\n",
      "Fetching observation data for time-03-36-21-300415_chatcmpl-aa0996e6-e9c6-44b6-a03b-2b955aac91f1...\n",
      "Fetching observation data for time-03-36-38-323249_chatcmpl-111590d6-1a0d-4dc0-ac7a-24ff03d4801e...\n",
      "Fetching observation data for time-03-34-03-391717_chatcmpl-a3763fae-80eb-4547-8545-14ea5e5426ea...\n",
      "Fetching observation data for time-03-34-29-381293_chatcmpl-f38ccc0f-a756-47ff-a819-1c65140d2add...\n",
      "Fetching observation data for time-03-34-51-606476_chatcmpl-f7a7b650-858f-4c2f-808a-612a7ac62f44...\n",
      "Fetching observation data for time-03-35-08-650596_chatcmpl-decffedb-29e1-4347-bcaa-fa2de272247b...\n",
      "Fetching observation data for time-03-32-12-241697_chatcmpl-01d0b41a-8278-444e-a939-86d5bc5975f6...\n",
      "Fetching observation data for time-03-32-38-550245_chatcmpl-824a366f-9982-4151-8237-f54cc67c7824...\n",
      "Fetching observation data for time-03-33-00-766060_chatcmpl-f37ca9cf-4ec4-4427-826e-564c9e588fa4...\n",
      "Fetching observation data for time-03-33-20-075224_chatcmpl-081177c0-c280-4f5b-b88b-7fa2e9a54338...\n",
      "Fetching observation data for time-03-33-35-502700_chatcmpl-dda4a8b0-a3ba-4246-8a45-d2003b8cae24...\n",
      "Fetching observation data for e91ba5f1-de26-44e1-831a-a3b21445a9d6...\n",
      "Fetching observation data for time-03-30-15-167967_chatcmpl-005ce6d9-f25c-4e4b-979c-529731bc864a...\n",
      "Fetching observation data for time-03-31-00-450602_chatcmpl-04f5be9c-65a5-405d-bec5-c9d3f97ea808...\n",
      "Fetching observation data for time-03-31-22-285126_chatcmpl-f35a052f-e73f-4ffd-8ef5-8fccf9c418b4...\n",
      "Fetching observation data for time-03-31-39-298195_chatcmpl-a8d4530d-2095-460e-ae65-7dceac147d03...\n",
      "Raw JSON saved to: /Users/hann/Projects/reference-benchmark-tinyml_llm/data_analysis/2025/08.12/raw_export/raw_gemma3:27b_d558_psg_batch.json\n",
      "Fetching traces for session gemma3:27b_b603_tpusg_batch...\n",
      "Fetching observation data for time-14-48-59-790418_chatcmpl-be6433f5-30b3-4556-898f-a0ef31b3e94c...\n",
      "Fetching observation data for time-14-49-41-777895_chatcmpl-bb33fc68-e9e2-4a4a-a0f2-18f682875b9d...\n",
      "Fetching observation data for time-14-50-28-999126_chatcmpl-719ab6d7-4b09-4bb6-b784-ec7dafe697e3...\n",
      "Fetching observation data for time-14-51-16-520352_chatcmpl-ee708234-a024-41d8-b545-67d5a7f55324...\n",
      "Fetching observation data for time-14-52-03-796143_chatcmpl-da34465c-0cb5-49d7-aa12-cd6a56d2a722...\n",
      "Fetching observation data for 52365f5e-5a29-47a2-bd8b-14ebb268feda...\n",
      "Fetching observation data for time-14-44-56-622316_chatcmpl-7607113f-3b0f-42da-88c5-51bf19fcb9bb...\n",
      "Fetching observation data for time-14-45-38-593407_chatcmpl-1ab4851b-125d-4d3f-8c76-d1980d2b4c37...\n",
      "Fetching observation data for time-14-46-28-028606_chatcmpl-8098b159-8197-4bd1-949a-c49184a1c589...\n",
      "Fetching observation data for time-14-47-17-650998_chatcmpl-1a3ca709-ac0c-43bb-a54c-dd2333eaba44...\n",
      "Fetching observation data for time-14-48-05-102134_chatcmpl-414d45e4-c8f6-4c63-a464-41eb6b0e477b...\n",
      "Fetching observation data for 94a5ef48-8058-439c-81e4-90e9c5f10fc6...\n",
      "Fetching observation data for time-14-40-56-783425_chatcmpl-47d13043-6114-4e85-bc6b-8ea18e2c7a12...\n",
      "Fetching observation data for time-14-41-38-672886_chatcmpl-92561ad9-e6c0-47e0-9b98-96fd44fdbfce...\n",
      "Fetching observation data for time-14-42-27-699268_chatcmpl-015e5470-684e-4907-a8f7-32523cb9c1e3...\n",
      "Fetching observation data for time-14-43-14-930170_chatcmpl-be4c48ff-0e67-4141-84ca-85ca324d4bd3...\n",
      "Fetching observation data for time-14-44-02-493619_chatcmpl-99ae1b48-6fd8-452e-b5ad-66c1953326b5...\n",
      "Fetching observation data for bbce0094-8eb0-448c-a458-7f8388a42182...\n",
      "Fetching observation data for time-14-36-55-956890_chatcmpl-fcb93f7a-3da7-4e56-a555-f5580b76aca7...\n",
      "Fetching observation data for time-14-37-38-023901_chatcmpl-821754a2-6108-47fa-9f1f-16f8de6cc8bf...\n",
      "Fetching observation data for time-14-38-25-193597_chatcmpl-b2cd8bd0-e8c2-4bab-b0d5-0e3bbf3a2dbd...\n",
      "Fetching observation data for time-14-39-14-780837_chatcmpl-c53e7b06-1daf-4702-9157-624e158ebbf2...\n",
      "Fetching observation data for time-14-40-02-339694_chatcmpl-44255630-58c1-4cf9-946f-d9eb60bbe057...\n",
      "Fetching observation data for 1e89e794-780e-4895-b327-7b3cb3bf5d4b...\n",
      "Fetching observation data for time-14-32-56-291316_chatcmpl-737c206e-1005-48f2-8b4f-5bbd8b36f964...\n",
      "Fetching observation data for time-14-33-38-267648_chatcmpl-516547df-e3a1-4447-b618-13943f49e59b...\n",
      "Fetching observation data for time-14-34-27-398642_chatcmpl-2345922b-51fe-4af3-9e65-9257293f43fd...\n",
      "Fetching observation data for time-14-35-15-277980_chatcmpl-40bf5bbd-6b6e-48d3-80d3-ff311e8132a7...\n",
      "Fetching observation data for time-14-36-02-654693_chatcmpl-201f57b6-59c2-4b50-aa18-5ec62c8d4c5e...\n",
      "Fetching observation data for dde5e0b1-4563-44b3-a3da-84cef5045846...\n",
      "Fetching observation data for time-14-28-56-710169_chatcmpl-9010ff0c-5946-4bc9-bf37-e4aa7c76a189...\n",
      "Fetching observation data for time-14-29-38-706532_chatcmpl-f7ff6360-33f2-4778-9783-f31c33d87bbb...\n",
      "Fetching observation data for time-14-30-26-082766_chatcmpl-5040a0d4-8b8c-4eba-9faa-b6fbefef9a68...\n",
      "Fetching observation data for time-14-31-14-243224_chatcmpl-9edae767-7601-4e05-a738-d7fc924d3aa4...\n",
      "Fetching observation data for time-14-32-03-137800_chatcmpl-af82108b-1e02-48e6-b8d8-94b1e5fb0410...\n",
      "Fetching observation data for 8ec0760e-e04b-4595-834a-8b64e46a7802...\n",
      "Fetching observation data for time-14-24-56-801570_chatcmpl-68f71a9b-9f17-454d-9e7c-194e1b97c75b...\n",
      "Fetching observation data for time-14-25-39-003621_chatcmpl-49499462-5c31-49fb-8722-1e69747882af...\n",
      "Fetching observation data for time-14-26-26-225661_chatcmpl-492c1d0a-1250-4dc2-8b94-17afa361ea40...\n",
      "Fetching observation data for time-14-27-13-851344_chatcmpl-5f930c46-59f6-4e75-b7bf-5bec0365eb5c...\n",
      "Fetching observation data for time-14-28-01-303022_chatcmpl-a983173a-8523-4e5b-a5c5-f8bb65c71ac0...\n",
      "Fetching observation data for c514407c-48b8-4f10-bfaf-08cf84dc25b9...\n",
      "Fetching observation data for time-14-20-55-689263_chatcmpl-b3555721-efce-49ee-a4d0-5ee596859ddb...\n",
      "Fetching observation data for time-14-21-37-763582_chatcmpl-bcd04d95-0751-495a-a4ac-9820acea5604...\n",
      "Fetching observation data for time-14-22-25-098243_chatcmpl-efd89ba1-5746-47e9-94ad-455d2ad4e4ab...\n",
      "Fetching observation data for time-14-23-12-491351_chatcmpl-eb49c83f-9e43-4051-9c13-6774c0b5e316...\n",
      "Fetching observation data for time-14-24-00-409201_chatcmpl-586b925e-396a-442b-9512-1477fd79239c...\n",
      "Fetching observation data for bbc806b7-fb0c-4c79-b735-d27a261efa24...\n",
      "Fetching observation data for time-14-16-56-080627_chatcmpl-8f2623d5-fdf9-4460-9b39-c5dd4fdbed3c...\n",
      "Fetching observation data for time-14-17-38-339660_chatcmpl-2adfc2ed-e891-43e4-b0b9-894341d2199f...\n",
      "Fetching observation data for time-14-18-27-629177_chatcmpl-3fb7d27c-94f4-4b9c-ac39-7ff75a237079...\n",
      "Fetching observation data for time-14-19-15-144984_chatcmpl-256dc5e8-07eb-4e0b-bb0d-7cefb8cd62b5...\n",
      "Fetching observation data for time-14-20-02-185742_chatcmpl-e162913c-a400-44f6-bf7d-a27571af8b41...\n",
      "Fetching observation data for 81caae4f-a8d2-4529-87ad-23f3c05255da...\n",
      "Fetching observation data for time-14-12-58-527858_chatcmpl-296b507c-6d53-4741-a1c9-c4f7e35389d8...\n",
      "Fetching observation data for time-14-13-40-400142_chatcmpl-66a614a1-cb49-45e2-b9e3-42792a79272c...\n",
      "Fetching observation data for time-14-14-27-759265_chatcmpl-de48ce31-7c9c-4a1f-852d-ca59019aa483...\n",
      "Fetching observation data for time-14-15-15-646896_chatcmpl-ae2618d1-9faa-49a3-ae01-b2d4a33feda2...\n",
      "Fetching observation data for time-14-16-03-092200_chatcmpl-c658c7c7-6f3a-4e42-91cb-fed78a11acd9...\n",
      "Fetching observation data for 419a900c-752b-4761-bf1a-a464b3e62e5e...\n",
      "Fetching observation data for time-14-08-58-878151_chatcmpl-dde2084a-e483-45e0-90b3-7dbad0a0d077...\n",
      "Fetching observation data for time-14-09-40-836145_chatcmpl-51e3a2a8-7b96-4933-a603-23f49b44f8cb...\n",
      "Fetching observation data for time-14-10-29-921376_chatcmpl-8d4238de-57cd-4ffe-898a-fe47fe79d844...\n",
      "Fetching observation data for time-14-11-17-289566_chatcmpl-5b76fe97-6829-41ea-9043-a6435c9e8f59...\n",
      "Fetching observation data for time-14-12-04-990998_chatcmpl-95c0cfd8-3c8f-4679-b1c1-78ea3d71b5a6...\n",
      "Fetching observation data for cc57480a-249b-456d-a233-0440d416677f...\n",
      "Fetching observation data for time-14-04-59-120940_chatcmpl-0ad19d6a-65de-45a9-856b-76abd27357a8...\n",
      "Fetching observation data for time-14-05-41-028334_chatcmpl-f1ff47c3-231b-45ee-ade0-0882d047551a...\n",
      "Fetching observation data for time-14-06-30-056752_chatcmpl-80839354-1ef5-4d7f-8d2c-f494a1ac9193...\n",
      "Fetching observation data for time-14-07-17-270120_chatcmpl-28f30df1-1e86-4d53-8890-f044b4766715...\n",
      "Fetching observation data for time-14-08-05-625021_chatcmpl-448656cd-bd18-4588-aac0-bab364b8ac42...\n",
      "Fetching observation data for d32f1470-7357-43d5-8aa6-805a4739d96c...\n",
      "Fetching observation data for time-14-00-40-464232_chatcmpl-bf6f9323-78b4-4418-998f-c19c9f0c0f22...\n",
      "Fetching observation data for time-14-01-39-456664_chatcmpl-4fd4af74-19e3-4331-a311-fd103fd24c0d...\n",
      "Fetching observation data for time-14-02-28-531875_chatcmpl-3c6150a8-1039-4d11-9a54-c5707e58d3f9...\n",
      "Fetching observation data for time-14-03-16-381604_chatcmpl-35f86a64-c219-4c04-8c92-d4816a5f67bf...\n",
      "Fetching observation data for time-14-04-04-599924_chatcmpl-0325b7fd-8c3b-4a15-a4fd-b42cef5496f0...\n",
      "Fetching observation data for edcfe31f-633e-473c-a54d-de2d226a47a0...\n",
      "Raw JSON saved to: /Users/hann/Projects/reference-benchmark-tinyml_llm/data_analysis/2025/08.12/raw_export/raw_gemma3:27b_b603_tpusg_batch.json\n"
     ]
    }
   ],
   "source": [
    "# ALTERNATIVE TO 2.\n",
    "import os\n",
    "import json\n",
    "from time import sleep\n",
    "from langfuse import Langfuse\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "\n",
    "# LANGFUSE_SERVICE_PUBLIC_KEY = \"pk-lf-559a2c0f-ee29-4c32-944c-bf73b5f0ce28\"\n",
    "# LANGFUSE_SERVICE_SECRET_KEY = \"sk-lf-75f8bf7f-a5db-4756-b0dd-d758a2a292c8\"\n",
    "# LANGFUSE_SERVICE_HOST = \"https://langfuse.hann.fi\"\n",
    "\n",
    "\n",
    "if LOCAL_HOST:\n",
    "    langfuse = Langfuse(\n",
    "        secret_key=\"sk-lf-75f8bf7f-a5db-4756-b0dd-d758a2a292c8\",\n",
    "        public_key=\"pk-lf-559a2c0f-ee29-4c32-944c-bf73b5f0ce28\",\n",
    "        host=\"https://langfuse.hann.fi\",\n",
    "    )\n",
    "else:\n",
    "    langfuse = Langfuse(\n",
    "        secret_key=LANGFUSE_SERVICE_SECRET_KEY,\n",
    "        public_key=LANGFUSE_SERVICE_PUBLIC_KEY,\n",
    "        host=LANGFUSE_SERVICE_HOST,\n",
    "    )\n",
    "\n",
    "API_invok_count = 0\n",
    "query_range_num_run = {\"start\": 0, \"end\": 1}\n",
    "\n",
    "\n",
    "class CustomJSONEncoder(json.JSONEncoder):\n",
    "    def __init__(self, *args, LOCAL_HOST=True, **kwargs):\n",
    "        self.LOCAL_HOST = LOCAL_HOST\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "    def default(self, obj):\n",
    "        if isinstance(obj, datetime):\n",
    "            return obj.isoformat()\n",
    "        if hasattr(obj, \"__dict__\"):\n",
    "            data = obj.__dict__.copy()\n",
    "            if \"observations\" in data:\n",
    "                data[\"observations\"] = [\n",
    "                    fetch_observation_data(obs, self.LOCAL_HOST)\n",
    "                    for obs in data[\"observations\"]\n",
    "                ]\n",
    "\n",
    "            return data\n",
    "        return super().default(obj)\n",
    "\n",
    "\n",
    "def fetch_observation_data(observation_id, LOCAL_HOST):\n",
    "    \"\"\"\n",
    "    Fetches observation data from Langfuse and returns its dictionary representation.\n",
    "    \"\"\"\n",
    "    print(f\"Fetching observation data for {observation_id}...\")\n",
    "    global API_invok_count\n",
    "    if API_invok_count >= 0 and not LOCAL_HOST:\n",
    "        print(\"Waiting for 3 seconds to fetch observation data...\")\n",
    "        for _ in tqdm(range(3), desc=\"Progress\", unit=\"s\"):\n",
    "            sleep(1)\n",
    "        API_invok_count = 0\n",
    "\n",
    "    observation_response = langfuse.fetch_observation(observation_id)\n",
    "    API_invok_count += 1\n",
    "\n",
    "    return observation_response.data.dict()\n",
    "\n",
    "\n",
    "def fetch_and_save_complete_data(session_id_list, raw_export_dir, LOCAL_HOST):\n",
    "    \"\"\"\n",
    "    Fetches complete trace data for each session ID and saves it to JSON files.\n",
    "\n",
    "    Parameters:\n",
    "        session_id_list (list): List of session IDs to process.\n",
    "        raw_export_dir (str): Directory path to save raw JSON files.\n",
    "    \"\"\"\n",
    "\n",
    "    def save_complete_data(session_id):\n",
    "        global API_invok_count\n",
    "        if API_invok_count >= 0 and not LOCAL_HOST:\n",
    "            print(\"Waiting for 4 seconds to fetch traces...\")\n",
    "            for _ in tqdm(range(4), desc=\"Progress\", unit=\"s\"):\n",
    "                sleep(1)\n",
    "            API_invok_count = 0\n",
    "\n",
    "        fetch_traces_response = langfuse.fetch_traces(session_id=session_id)\n",
    "        API_invok_count += 1\n",
    "\n",
    "        print(f\"Fetching traces for session {session_id}...\")\n",
    "        # Create directories if they don't exist\n",
    "        os.makedirs(raw_export_dir, exist_ok=True)\n",
    "\n",
    "        # Save complete data to JSON file\n",
    "        # if session_id.startswith(\"da0a\"):\n",
    "        #     session_id = \"phi4_\" + session_id\n",
    "        if \"tpsg\" in session_id:\n",
    "            session_id_ = session_id.replace(\"tpsg\", \"tpusg\")\n",
    "        else:\n",
    "            session_id_ = session_id\n",
    "            \n",
    "        raw_path = os.path.join(raw_export_dir, f\"raw_{session_id_}.json\")\n",
    "        with open(raw_path, \"w\") as f:\n",
    "            json.dump(fetch_traces_response, f, cls=CustomJSONEncoder, indent=2)\n",
    "\n",
    "        print(f\"Raw JSON saved to: {raw_path}\")\n",
    "\n",
    "    for session_id in session_id_list:\n",
    "        save_complete_data(session_id)\n",
    "\n",
    "\n",
    "fetch_and_save_complete_data(session_id_list, raw_export_dir, LOCAL_HOST)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Trim data\n",
    "\n",
    "Here also intercept the runs with fatal errors that need to be excluded from the analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPAN error_b8_psg_failure_signal_py_sketch_generator: Failed. Last error: Traceback (most recent call last):\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250805035423_psg_gemma3:27b/tmp_20250805035423_psg_gemma3:27b.py\", line 29, in <module>\n",
      "    interpreter = cv2.dnn.readNetFromTflite(model_path)\n",
      "AttributeError: module 'cv2.dnn' has no attribute 'readNetFromTflite'. Did you mean: 'readNetFromTFLite'?\n",
      "\n",
      "SPAN error_16_psg_failure_signal_py_sketch_generator: Failed. Last error: Traceback (most recent call last):\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250805033356_psg_gemma3:27b/tmp_20250805033356_psg_gemma3:27b.py\", line 15, in <module>\n",
      "    interpreter = cv2.dnn.readNetFromTFLite(model_path)\n",
      "cv2.error: OpenCV(4.10.0) /io/opencv/modules/dnn/src/tflite/tflite_importer.cpp:118: error: (-213:The function/feature is not implemented) Parse tensor with type UINT8 in function 'parseTensor'\n",
      "\n",
      "\n",
      "Successfully processed and saved trimmed data for session gemma3:27b_d558_psg_batch\n",
      "SPAN error_a8_tpusg_failure_signal_tpu_sketch_generator: Failed. Last error: Traceback (most recent call last):\n",
      "  File \"script_beff577c_1754394762.py\", line 64, in <module>\n",
      "    if scores > 0.5:\n",
      "ValueError: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()\n",
      "SPAN error_f3_tpusg_failure_signal_tpu_sketch_generator: Failed. Last error: Traceback (most recent call last):\n",
      "  File \"script_25b4a576_1754394524.py\", line 64, in <module>\n",
      "    if scores > 0.5:\n",
      "ValueError: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()\n",
      "SPAN error_56_tpusg_failure_signal_tpu_sketch_generator: Failed. Last error: Traceback (most recent call last):\n",
      "  File \"script_b92c60f9_1754394281.py\", line 64, in <module>\n",
      "    if scores > 0.5:\n",
      "ValueError: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()\n",
      "SPAN error_22_tpusg_failure_signal_tpu_sketch_generator: Failed. Last error: Traceback (most recent call last):\n",
      "  File \"script_6b36134f_1754394043.py\", line 64, in <module>\n",
      "    if scores > 0.5:\n",
      "ValueError: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()\n",
      "SPAN error_36_tpusg_failure_signal_tpu_sketch_generator: Failed. Last error: Traceback (most recent call last):\n",
      "  File \"script_70a1e524_1754393802.py\", line 64, in <module>\n",
      "    if scores > 0.5:\n",
      "ValueError: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()\n",
      "SPAN error_3b_tpusg_failure_signal_tpu_sketch_generator: Failed. Last error: Traceback (most recent call last):\n",
      "  File \"script_91c793a1_1754393562.py\", line 64, in <module>\n",
      "    if scores > 0.5:\n",
      "ValueError: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()\n",
      "SPAN error_73_tpusg_failure_signal_tpu_sketch_generator: Failed. Last error: Traceback (most recent call last):\n",
      "  File \"script_fbb31adc_1754393322.py\", line 64, in <module>\n",
      "    if scores > 0.5:\n",
      "ValueError: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()\n",
      "SPAN error_87_tpusg_failure_signal_tpu_sketch_generator: Failed. Last error: Traceback (most recent call last):\n",
      "  File \"script_42b7afdf_1754393081.py\", line 64, in <module>\n",
      "    if scores > 0.5:\n",
      "ValueError: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()\n",
      "SPAN error_b1_tpusg_failure_signal_tpu_sketch_generator: Failed. Last error: Traceback (most recent call last):\n",
      "  File \"script_26307ee8_1754392841.py\", line 64, in <module>\n",
      "    if scores > 0.5:\n",
      "ValueError: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()\n",
      "SPAN error_f9_tpusg_failure_signal_tpu_sketch_generator: Failed. Last error: Traceback (most recent call last):\n",
      "  File \"script_9800eadc_1754392602.py\", line 64, in <module>\n",
      "    if scores > 0.5:\n",
      "ValueError: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()\n",
      "SPAN error_2a_tpusg_failure_signal_tpu_sketch_generator: Failed. Last error: Traceback (most recent call last):\n",
      "  File \"script_744b6451_1754392364.py\", line 64, in <module>\n",
      "    if scores > 0.5:\n",
      "ValueError: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()\n",
      "SPAN error_94_tpusg_failure_signal_tpu_sketch_generator: Failed. Last error: Traceback (most recent call last):\n",
      "  File \"script_544ce263_1754392124.py\", line 64, in <module>\n",
      "    if scores > 0.5:\n",
      "ValueError: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()\n",
      "SPAN error_ae_tpusg_failure_signal_tpu_sketch_generator: Failed. Last error: Traceback (most recent call last):\n",
      "  File \"script_57e951d8_1754391884.py\", line 64, in <module>\n",
      "    if scores > 0.5:\n",
      "ValueError: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()\n",
      "Successfully processed and saved trimmed data for session gemma3:27b_b603_tpusg_batch\n",
      "Total 0 traces skipped. They are []\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "skipped_traces = []\n",
    "\n",
    "\n",
    "def process_existing_observation(observation):\n",
    "    \"\"\"\n",
    "    Processes an existing observation dictionary by trimming unwanted keys.\n",
    "    \"\"\"\n",
    "    unwanted_observation_keys = [\n",
    "        \"completionStartTime\",\n",
    "        \"metadata\",\n",
    "        \"timeToFirstToken\",\n",
    "        \"createdAt\",\n",
    "        \"usageDetails\",\n",
    "        \"usage\",\n",
    "        \"projectId\",\n",
    "        \"unit\",\n",
    "        \"updatedAt\",\n",
    "        \"version\",\n",
    "        \"parentObservationId\",\n",
    "        \"promptId\",\n",
    "        \"promptName\",\n",
    "        \"promptVersion\",\n",
    "        \"modelId\",\n",
    "        \"inputPrice\",\n",
    "        \"outputPrice\",\n",
    "        \"totalPrice\",\n",
    "        # \"modelParameters\",\n",
    "        \"input\",\n",
    "        \"output\",\n",
    "    ]\n",
    "\n",
    "    # If observation is a dictionary containing observation data\n",
    "    if isinstance(observation, dict):\n",
    "        trimmed_observation = {\n",
    "            k: v for k, v in observation.items() if k not in unwanted_observation_keys\n",
    "        }\n",
    "        return trimmed_observation\n",
    "    return observation\n",
    "\n",
    "\n",
    "def trim_data(data):\n",
    "    \"\"\"\n",
    "    Recursively trims the data structure.\n",
    "    \"\"\"\n",
    "\n",
    "    if isinstance(data, dict):\n",
    "        # Process the current dictionary\n",
    "        unwanted_trace_keys = [\n",
    "            \"release\",\n",
    "            \"version\",\n",
    "            \"user_id\",\n",
    "            \"public\",\n",
    "            \"html_path\",\n",
    "            \"scores\",\n",
    "            \"bookmarked\",\n",
    "            \"projectId\",\n",
    "            \"externalId\",\n",
    "            \"page\",\n",
    "            \"limit\",\n",
    "            \"total_pages\",\n",
    "        ]\n",
    "\n",
    "        # If this is a trace that contains observations, check for fatal errors\n",
    "        if \"observations\" in data:\n",
    "            # Check for SPAN observations with fatal errors before processing\n",
    "            skip_trace = False\n",
    "            for obs in data[\"observations\"]:\n",
    "                if isinstance(obs, dict) and obs.get(\"name\").startswith(\"error\"):\n",
    "                    status_message = obs.get(\"statusMessage\", \"\")\n",
    "                    ob_name = obs.get(\"name\")\n",
    "                    print(f\"SPAN {ob_name}: {status_message}\")\n",
    "\n",
    "                    if \"Fatal error\" in status_message:\n",
    "                        print(f\"Found Fatal error in SPAN observation, skipping trace\")\n",
    "                        skip_trace = True\n",
    "                        skipped_traces.append(data[\"name\"])\n",
    "                        break\n",
    "\n",
    "            if skip_trace:\n",
    "                return None  # Signal to skip this trace\n",
    "\n",
    "        # Create a new dictionary with wanted keys and recursively process values\n",
    "        trimmed_data = {}\n",
    "        for key, value in data.items():\n",
    "            if key not in unwanted_trace_keys:\n",
    "                if key == \"observations\":\n",
    "                    # Special handling for observations\n",
    "                    trimmed_data[key] = [\n",
    "                        process_existing_observation(obs) for obs in value\n",
    "                    ]\n",
    "                elif isinstance(value, (dict, list)):\n",
    "                    # Recursively process nested structures\n",
    "                    trimmed_data[key] = trim_data(value)\n",
    "                else:\n",
    "                    trimmed_data[key] = value\n",
    "\n",
    "        return trimmed_data\n",
    "\n",
    "    elif isinstance(data, list):\n",
    "        # Recursively process each item in the list\n",
    "        processed_items = []\n",
    "        for item in data:\n",
    "            processed_item = trim_data(item)\n",
    "            if processed_item is not None:  # Only add items that weren't filtered out\n",
    "                processed_items.append(processed_item)\n",
    "        return processed_items\n",
    "\n",
    "    else:\n",
    "        # Return non-dict, non-list values as is\n",
    "        return data\n",
    "\n",
    "\n",
    "def read_and_trim_data(session_id_list, raw_export_dir, trimmed_export_dir):\n",
    "    \"\"\"\n",
    "    Reads complete data from JSON files, trims the data, and saves the trimmed data to new JSON files.\n",
    "    \"\"\"\n",
    "    os.makedirs(trimmed_export_dir, exist_ok=True)\n",
    "\n",
    "    for session_id in session_id_list:\n",
    "        try:\n",
    "            if session_id.startswith(\"da0a\"):\n",
    "                session_id = \"phi4_\" + session_id\n",
    "            # Read raw data\n",
    "            if \"tpsg\" in session_id:\n",
    "                session_id_ = session_id.replace(\"tpsg\", \"tpusg\")\n",
    "            else:\n",
    "                session_id_ = session_id\n",
    "            raw_path = os.path.join(raw_export_dir, f\"raw_{session_id_}.json\")\n",
    "            with open(raw_path, \"r\") as f:\n",
    "                data = json.load(f)\n",
    "\n",
    "            # Process and trim the data\n",
    "            trimmed_data = trim_data(data)\n",
    "\n",
    "            # If the entire data was filtered out (unlikely but possible)\n",
    "            if trimmed_data is None:\n",
    "                print(\n",
    "                    f\"All traces in session {session_id} were filtered due to fatal errors\"\n",
    "                )\n",
    "                continue\n",
    "\n",
    "            # Save trimmed data\n",
    "            if \"tpsg\" in session_id:\n",
    "                session_id_ = session_id.replace(\"tpsg\", \"tpusg\")\n",
    "            else:\n",
    "                session_id_ = session_id\n",
    "            trimmed_path = os.path.join(\n",
    "                trimmed_export_dir, f\"trimmed_{session_id_}.json\"\n",
    "            )\n",
    "            with open(trimmed_path, \"w\") as f:\n",
    "                json.dump(trimmed_data, f, indent=2)\n",
    "\n",
    "            print(\n",
    "                f\"Successfully processed and saved trimmed data for session {session_id}\"\n",
    "            )\n",
    "\n",
    "            # Optional: Verify trimming worked\n",
    "            # print(f\"Verifying trimmed data for session {session_id}...\")\n",
    "            # verify_trimming(trimmed_path)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing session {session_id}: {str(e)}\")\n",
    "\n",
    "\n",
    "def verify_trimming(trimmed_path):\n",
    "    \"\"\"\n",
    "    Verifies that the trimmed data doesn't contain unwanted keys.\n",
    "    \"\"\"\n",
    "    with open(trimmed_path, \"r\") as f:\n",
    "        trimmed_data = json.load(f)\n",
    "\n",
    "    unwanted_keys = [\n",
    "        \"release\",\n",
    "        \"version\",\n",
    "        \"user_id\",\n",
    "        \"public\",\n",
    "        \"html_path\",\n",
    "        \"scores\",\n",
    "        \"bookmarked\",\n",
    "        \"projectId\",\n",
    "        \"externalId\",\n",
    "        \"page\",\n",
    "        \"limit\",\n",
    "        \"total_pages\",\n",
    "        \"completionStartTime\",\n",
    "        \"metadata\",\n",
    "        \"usageDetails\",\n",
    "        \"timeToFirstToken\",\n",
    "        \"createdAt\",\n",
    "        \"completionTokens\",\n",
    "        \"promptTokens\",\n",
    "        \"projectId\",\n",
    "        \"unit\",\n",
    "        \"updatedAt\",\n",
    "        \"version\",\n",
    "        # \"statusMessage\",\n",
    "        \"parentObservationId\",\n",
    "        \"promptId\",\n",
    "        \"promptName\",\n",
    "        \"promptVersion\",\n",
    "        \"modelId\",\n",
    "        \"inputPrice\",\n",
    "        \"outputPrice\",\n",
    "        \"totalPrice\",\n",
    "        \"calculatedInputCost\",\n",
    "        \"calculatedOutputCost\",\n",
    "        \"calculatedTotalCost\",\n",
    "    ]\n",
    "\n",
    "    def check_keys(obj):\n",
    "        if isinstance(obj, dict):\n",
    "            for key in obj.keys():\n",
    "                if key in unwanted_keys:\n",
    "                    print(f\"Warning: Found unwanted key '{key}' in trimmed data\")\n",
    "            for value in obj.values():\n",
    "                check_keys(value)\n",
    "        elif isinstance(obj, list):\n",
    "            for item in obj:\n",
    "                check_keys(item)\n",
    "\n",
    "    check_keys(trimmed_data)\n",
    "    print(\"Verification complete\")\n",
    "\n",
    "\n",
    "# Usage example:\n",
    "read_and_trim_data(session_id_list, raw_export_dir, raw_export_dir)\n",
    "print(f\"Total {len(skipped_traces)} traces skipped. They are {skipped_traces}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Generate CSV files from JSON\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing session gemma3:27b_d558_psg_batch, simple id gemma3:27b_d558. Look for /Users/hann/Projects/reference-benchmark-tinyml_llm/data_analysis/2025/08.12/raw_export/trimmed_gemma3:27b_d558_psg_batch.json\n",
      "/Users/hann/Projects/reference-benchmark-tinyml_llm/data_analysis/2025/08.12/processed_data/gemma3:27b_d558/clean_gemma3:27b_d558_psg_batch.csv\n",
      "Successfully saved CSV to: /Users/hann/Projects/reference-benchmark-tinyml_llm/data_analysis/2025/08.12/processed_data/gemma3:27b_d558/clean_gemma3:27b_d558_psg_batch.csv\n",
      "Processing session gemma3:27b_b603_tpusg_batch, simple id gemma3:27b_b603. Look for /Users/hann/Projects/reference-benchmark-tinyml_llm/data_analysis/2025/08.12/raw_export/trimmed_gemma3:27b_b603_tpusg_batch.json\n",
      "/Users/hann/Projects/reference-benchmark-tinyml_llm/data_analysis/2025/08.12/processed_data/gemma3:27b_b603/clean_gemma3:27b_b603_tpusg_batch.csv\n",
      "Successfully saved CSV to: /Users/hann/Projects/reference-benchmark-tinyml_llm/data_analysis/2025/08.12/processed_data/gemma3:27b_b603/clean_gemma3:27b_b603_tpusg_batch.csv\n"
     ]
    }
   ],
   "source": [
    "import traceback\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from dateutil import parser\n",
    "\n",
    "\n",
    "def json_to_csv(session_id):\n",
    "    \"\"\"\n",
    "    Convert JSON trace data to CSV format with aggregated metrics.\n",
    "\n",
    "    Args:\n",
    "        session_id (str): Identifier for the session to process\n",
    "    \"\"\"\n",
    "\n",
    "    def extract_observation_details(observations, trace_id):\n",
    "        \"\"\"Extract and aggregate metrics from observations\"\"\"\n",
    "        metrics = {\n",
    "            \"status\": None,\n",
    "            \"latency\": 0,\n",
    "            \"total_tokens\": 0,\n",
    "            \"prompt_tokens\": 0,\n",
    "            \"completion_tokens\": 0,\n",
    "            \"total_cost\": 0,\n",
    "            \"input_cost\": 0,\n",
    "            \"output_cost\": 0,\n",
    "            \"parameters\": set(),\n",
    "        }\n",
    "\n",
    "        # Process GENERATION observations\n",
    "        for obs in (o for o in observations if o[\"type\"] == \"GENERATION\"):\n",
    "            metrics[\"total_tokens\"] += obs[\"totalTokens\"]\n",
    "            metrics[\"prompt_tokens\"] += obs[\"promptTokens\"]\n",
    "            metrics[\"completion_tokens\"] += obs[\"completionTokens\"]\n",
    "            metrics[\"latency\"] += obs[\"latency\"]\n",
    "            for key, value in obs[\"modelParameters\"].items():\n",
    "                metrics[\"parameters\"].add(key + \":\" + value)\n",
    "\n",
    "            # Add costs if present\n",
    "            for cost_type in [\"Total\", \"Input\", \"Output\"]:\n",
    "                key = f\"calculated{cost_type}Cost\"\n",
    "                metric_key = cost_type.lower() + \"_cost\"\n",
    "                if obs.get(key) is not None:\n",
    "                    metrics[metric_key] += obs[key]\n",
    "        if len(metrics[\"parameters\"]) == 0:\n",
    "            metrics[\"parameters\"] = \"N/A\"\n",
    "        # Process SPAN observations for status\n",
    "        status_indicators = [\n",
    "            obs[\"name\"]\n",
    "            for obs in observations\n",
    "            if obs[\"type\"] == \"SPAN\" and \"start_\" not in obs[\"name\"]\n",
    "        ]\n",
    "\n",
    "        #  if later than 2025-05-19, use status_signal_from_output\n",
    "        if datetime.now() > datetime(2025, 5, 19):\n",
    "            pass\n",
    "        else:\n",
    "            # Determine status\n",
    "            success_signals = sum(\"end_\" in name for name in status_indicators)\n",
    "            failure_signals = sum(\n",
    "                \"failure_signal\" in name for name in status_indicators\n",
    "            )\n",
    "\n",
    "            if success_signals + failure_signals > 1:\n",
    "                raise ValueError(\n",
    "                    f\"Multiple status indicators found in trace {trace_id}\"\n",
    "                )\n",
    "\n",
    "            metrics[\"status\"] = (\n",
    "                \"success\"\n",
    "                if success_signals\n",
    "                else \"failure\" if failure_signals else \"unknown\"\n",
    "            )\n",
    "\n",
    "        metrics[\"prompt_cost\"] = metrics.pop(\"input_cost\")\n",
    "        metrics[\"completion_cost\"] = metrics.pop(\"output_cost\")\n",
    "        metrics[\"latency\"] = round(metrics[\"latency\"] / 1000, 2)\n",
    "        return metrics\n",
    "\n",
    "    def cal_time(trace):\n",
    "        time_diff = datetime.fromisoformat(\n",
    "            trace[\"updatedAt\"].replace(\"Z\", \"+00:00\")\n",
    "        ) - datetime.fromisoformat(trace[\"createdAt\"].replace(\"Z\", \"+00:00\"))\n",
    "        seconds_diff = time_diff.total_seconds()\n",
    "        return seconds_diff\n",
    "\n",
    "    try:\n",
    "\n",
    "        if session_id.startswith(\"da0a\"):\n",
    "            session_id = \"phi4_\" + session_id\n",
    "        simple_session_id = session_id.rsplit(\"_\", 2)[0]\n",
    "\n",
    "        \n",
    "        # Load JSON data\n",
    "        if \"tpsg\" in session_id:\n",
    "                session_id_ = session_id.replace(\"tpsg\", \"tpusg\")\n",
    "        else:\n",
    "                session_id_ = session_id\n",
    "        trimmed_path = os.path.join(raw_export_dir, f\"trimmed_{session_id_}.json\")\n",
    "        print(\n",
    "            f\"Processing session {session_id}, simple id {simple_session_id}. Look for {trimmed_path}\"\n",
    "        )\n",
    "        with open(trimmed_path, \"r\") as file:\n",
    "            traces = json.load(file)[\"data\"]\n",
    "\n",
    "        # Process traces\n",
    "        rows = [\n",
    "            {\n",
    "                \"num_run\": trace[\"metadata\"][\"num_run\"],\n",
    "                \"name\": trace[\"name\"],\n",
    "                \"trace_id\": trace[\"id\"],\n",
    "                \"batch_id\": trace[\"session_id\"],\n",
    "                # \"latency\": cal_time(trace),\n",
    "                # \"latency\": round(trace[\"latency\"], 2),\n",
    "                **extract_observation_details(\n",
    "                    trace[\"observations\"],\n",
    "                    trace[\"id\"],\n",
    "                ),\n",
    "                \"status\": (\n",
    "                    \"failure\"\n",
    "                    if trace[\"output\"][\"status\"].lower() == \"failed\"\n",
    "                    else \"success\"\n",
    "                ),\n",
    "                \"tags\": trace[\"tags\"],\n",
    "                \"timestamp\": int(parser.isoparse(trace[\"timestamp\"]).timestamp()),\n",
    "            }\n",
    "            for trace in traces\n",
    "        ]\n",
    "        # print(rows)\n",
    "        # print(rows)\n",
    "        # Create and save DataFrame\n",
    "        df = pd.DataFrame(rows).sort_values(\"num_run\")\n",
    "\n",
    "        output_dir = os.path.join(processed_data_dir, f\"{simple_session_id}\")\n",
    "        if not os.path.exists(output_dir):\n",
    "            os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "        output_path = os.path.join(output_dir, f\"clean_{session_id_}.csv\")\n",
    "\n",
    "        print(output_path)\n",
    "        df.to_csv(output_path, index=False)\n",
    "        print(f\"Successfully saved CSV to: {output_path}\")\n",
    "\n",
    "    except FileNotFoundError as e:\n",
    "        print(\n",
    "            f\"FileNotFoundError: For session {session_id} not found. Looked for {trimmed_path}\\nError info: \\n{e}\\n\\nTraceback: {traceback.format_exc()}\"\n",
    "        )\n",
    "    except json.JSONDecodeError:\n",
    "        print(f\"Error: Invalid JSON format in input file for session {session_id}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing session {session_id}: {str(e)}\")\n",
    "\n",
    "\n",
    "# Example usage\n",
    "for session_id in session_id_list:\n",
    "    json_to_csv(session_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code below is archived\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"\"\"Simply calculate success rate\"\"\"\n",
    "\n",
    "\n",
    "# def cal_success_rate(session_id):\n",
    "\n",
    "#     end_signal_count = 0\n",
    "#     failure_signal_count = 0\n",
    "#     # Function to print the name of each observation\n",
    "#     with open(f\"{raw_export_dir}/trimmed_{session_id}.json\", \"r\") as file:\n",
    "#         data = json.load(file)[\"data\"]\n",
    "#     for i in data:\n",
    "\n",
    "#         observations = i[\"observations\"]\n",
    "\n",
    "#         for observation in observations:\n",
    "#             # print(type(observation))\n",
    "#             for key, value in observation.items():\n",
    "#                 # print(f\"{key}: {value}\")\n",
    "#                 for key, value in value.items():\n",
    "#                     # print(f\"{key}: {value}\")\n",
    "#                     if key == \"name\":\n",
    "#                         if \"end_\" in value:\n",
    "\n",
    "#                             end_signal_count += 1\n",
    "#                         if \"failure_signal\" in value:\n",
    "\n",
    "#                             failure_signal_count += 1\n",
    "\n",
    "#     print(f\"Session ID: {session_id}\")\n",
    "#     total_count = end_signal_count + failure_signal_count\n",
    "#     if total_count > 0:\n",
    "#         success_rate = end_signal_count / total_count\n",
    "#         print(f\"Success rate: {success_rate:.4f}\")\n",
    "#     else:\n",
    "#         print(\"Success rate: N/A (no signals found)\")\n",
    "#     print(f\"Passed:\\t{end_signal_count}\\nFailed:\\t{failure_signal_count}\")\n",
    "#     print(\n",
    "#         \"\"\n",
    "#         if total_count == 30\n",
    "#         else \"Number of ending signals does not match the expected number!\"\n",
    "#     )\n",
    "#     print(\"-\" * 50)\n",
    "\n",
    "\n",
    "# for session_id in session_id_list:\n",
    "#     cal_success_rate(session_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def cal_time(start_time, end_time):\n",
    "#     time_diff = datetime.fromisoformat(\n",
    "#         end_time.replace(\"Z\", \"+00:00\")\n",
    "#     ) - datetime.fromisoformat(start_time.replace(\"Z\", \"+00:00\"))\n",
    "#     seconds_diff = time_diff.total_seconds()\n",
    "#     return seconds_diff\n",
    "\n",
    "\n",
    "# print(cal_time(\"2025-01-15T03:31:56.150000+00:00\", \"2025-01-15T03:32:59.384Z\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"\"\"Print the complete structure of exported json file\"\"\"\n",
    "# def print_keys(d, parent_key=''):\n",
    "#     if isinstance(d, dict):\n",
    "#         for key, value in d.items():\n",
    "#             full_key = f\"{parent_key}.{key}\" if parent_key else key\n",
    "#             print(full_key)\n",
    "#             print_keys(value, full_key)\n",
    "#     elif isinstance(d, list):\n",
    "#         for i, item in enumerate(d):\n",
    "#             full_key = f\"{parent_key}[{i}]\"\n",
    "#             print_keys(item, full_key)\n",
    "\n",
    "# # Load JSON data from a file\n",
    "# with open('fetch_traces_response.json', 'r') as file:\n",
    "#     data = json.load(file)['data'][0]\n",
    "# # Print all keys\n",
    "# print_keys(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1747226053\n",
      "1747226053.1\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "from dateutil import parser\n",
    "\n",
    "timestamp_str = \"2025-05-14T12:34:13.100000+00:00\"\n",
    "dt = parser.isoparse(\n",
    "    timestamp_str\n",
    ")  # Or datetime.fromisoformat(timestamp_str) if no timezone offset\n",
    "unix_ts = int(dt.timestamp())\n",
    "\n",
    "print(unix_ts)  # This will print the integer Unix timestamp\n",
    "print(datetime.fromisoformat(timestamp_str).timestamp())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datasci2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

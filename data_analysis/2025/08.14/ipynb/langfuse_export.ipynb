{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setting up\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ref: https://langfuse.com/docs/query-traces\n",
    "import os\n",
    "import json\n",
    "from langfuse import Langfuse\n",
    "import json\n",
    "import os\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "LOCAL_HOST = True\n",
    "\n",
    "\"\"\"Define session_id\"\"\"\n",
    "# session_id=\"qwen2.5-coder_f4d4_dp_batch\"\n",
    "session_id_list = [\n",
    "    # \"qwen2.5-coder:32b_4e11_tpsg_batch\",\n",
    "    # \"qwen2.5-coder:32b_ae24_tpsg_batch\"\n",
    "    \"codestral_9eb0_psg_batch\",\n",
    "    \"codestral_9eb0_tpusg_batch\"\n",
    "]\n",
    "\n",
    "\n",
    "\"\"\"Define paths\"\"\"\n",
    " \n",
    "parent_dir = os.path.dirname(os.getcwd())\n",
    "\n",
    " \n",
    "# date = os.path.basename(parent_dir)\n",
    "tex_dir = os.path.join(parent_dir, \"tex\")\n",
    "processed_data_dir = os.path.join(parent_dir, \"processed_data\")\n",
    "raw_export_dir = os.path.join(parent_dir, \"raw_export\")\n",
    "ipynb_dir = os.path.join(parent_dir, \"ipynb\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Export raw data\n",
    "\n",
    "Langfuse added a limit of 20 API invocations per minute. https://langfuse.com/faq/all/api-limits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching traces for session codestral_9eb0_psg_batch...\n",
      "Fetching observation data for time-00-42-12-851333_chatcmpl-dcc831c9-e058-4cae-bb32-e8fada8f98c2...\n",
      "Fetching observation data for time-00-42-27-715025_chatcmpl-117904aa-28f7-4c98-a0e5-a1407b0edabd...\n",
      "Fetching observation data for time-00-42-39-879137_chatcmpl-a2770b30-5b8f-458d-b612-b41d6346b412...\n",
      "Fetching observation data for time-00-42-55-180846_chatcmpl-e1833465-3eeb-497e-a464-adf4efe63aca...\n",
      "Fetching observation data for time-00-41-55-759728_chatcmpl-fb1f6638-0131-4e09-bff5-12775659b7ba...\n",
      "Fetching observation data for 747904d0-bc57-4ea3-9881-1bd797ea3b6c...\n",
      "Fetching observation data for time-00-40-39-151792_chatcmpl-c3a6362c-2a21-437e-844e-f0e854a63fec...\n",
      "Fetching observation data for time-00-41-04-289266_chatcmpl-492b16d8-aa0b-4c76-ad64-93ae9c504c2c...\n",
      "Fetching observation data for time-00-41-15-615284_chatcmpl-d96d3687-edc8-4890-b970-2ec92d4eb30a...\n",
      "Fetching observation data for time-00-41-24-525138_chatcmpl-0cfed36c-f4b5-42cf-81ed-20ee6a5a0afb...\n",
      "Fetching observation data for time-00-41-40-045087_chatcmpl-b7d2881e-faaf-4801-966f-3b3479273b63...\n",
      "Fetching observation data for dae45f03-cb50-4eb9-9779-66cc16969844...\n",
      "Fetching observation data for time-00-39-25-330626_chatcmpl-35150a5d-eaea-4213-ac9a-1e11ff00fcac...\n",
      "Fetching observation data for time-00-39-41-018943_chatcmpl-125bcfa0-f1e2-4187-b9f7-7213da56071c...\n",
      "Fetching observation data for time-00-39-51-413884_chatcmpl-b33ddce7-0299-44f0-8b71-261376865aca...\n",
      "Fetching observation data for time-00-40-06-299078_chatcmpl-12f1880a-a6fd-47f6-b3be-66bf8541175e...\n",
      "Fetching observation data for time-00-40-16-010325_chatcmpl-b59dc530-0ba8-4972-bfba-27c76220cb53...\n",
      "Fetching observation data for f0c95e2e-d841-4626-9477-96b7ffb4f153...\n",
      "Fetching observation data for time-00-37-57-429950_chatcmpl-dcca9092-06eb-48b9-8908-d3f3053bd59e...\n",
      "Fetching observation data for time-00-38-15-018802_chatcmpl-1b75b5eb-3804-42ae-8b28-9f19c3a13e23...\n",
      "Fetching observation data for time-00-38-38-985130_chatcmpl-62439b30-cd40-47af-b6da-e25f7aec80ae...\n",
      "Fetching observation data for time-00-38-52-919863_chatcmpl-5e13de06-bdd2-46c3-8aa1-aa2ade1f05ce...\n",
      "Fetching observation data for time-00-39-02-798255_chatcmpl-bf965d78-a223-471d-bc28-0107ce378aa6...\n",
      "Fetching observation data for ca3ecd5f-b7ed-48aa-8ef5-50cb9510ac59...\n",
      "Fetching observation data for time-00-36-41-337975_chatcmpl-826d0dec-45c2-4ba2-b316-3cadf27e508e...\n",
      "Fetching observation data for time-00-36-57-296034_chatcmpl-24ae0920-0cb2-4cfc-ad64-166423406168...\n",
      "Fetching observation data for time-00-37-20-112486_chatcmpl-b5c38210-bd7f-4a76-aeb2-f4688216f65a...\n",
      "Fetching observation data for time-00-37-27-907119_chatcmpl-6f4e5aab-00bc-45c3-b583-f4c2ce116f73...\n",
      "Fetching observation data for time-00-37-41-276930_chatcmpl-9e94593d-4096-4154-9a39-31de155fffec...\n",
      "Fetching observation data for c9073ec0-c0c5-494d-9c89-330c6d8b8c53...\n",
      "Fetching observation data for time-00-35-15-570817_chatcmpl-e2c55931-f9e9-4389-b0c8-33350b5a1e66...\n",
      "Fetching observation data for time-00-35-32-501459_chatcmpl-65032979-7a96-4029-ac8b-f44d82dfe90e...\n",
      "Fetching observation data for time-00-35-43-391086_chatcmpl-29120d52-166a-4ab8-a2cc-2719d7ae35db...\n",
      "Fetching observation data for time-00-35-57-172067_chatcmpl-43577c14-01d0-4a96-99fe-15e40286ee86...\n",
      "Fetching observation data for time-00-36-14-249031_chatcmpl-7c3aded7-6937-4354-a050-f0ac5b414d78...\n",
      "Fetching observation data for d08ce5bb-793b-4286-afe8-f9c4d801d355...\n",
      "Fetching observation data for time-00-34-06-833474_chatcmpl-22ad7a67-acc3-4c6f-b595-2a5a761493e7...\n",
      "Fetching observation data for time-00-34-23-654680_chatcmpl-3dbd7648-783f-45bc-87ef-9d7aea272991...\n",
      "Fetching observation data for time-00-34-27-937009_chatcmpl-9e11f557-77c8-4395-8c9f-c956a4e1a866...\n",
      "Fetching observation data for time-00-34-43-607077_chatcmpl-5d7bc193-1263-4694-a76e-36cfe06d729d...\n",
      "Fetching observation data for time-00-34-58-043496_chatcmpl-917e2552-fd22-4e7f-9e96-f53ecd91fe41...\n",
      "Fetching observation data for 490062a9-345b-4bfb-815c-cea391067f65...\n",
      "Fetching observation data for time-00-32-51-204666_chatcmpl-e4e94800-3d12-4781-9108-da9f95373820...\n",
      "Fetching observation data for time-00-33-08-230121_chatcmpl-89bbab25-8f94-4377-9938-c711b83ecfc7...\n",
      "Fetching observation data for time-00-33-18-373741_chatcmpl-da80dce1-cc3e-4a50-85ca-8642219765d5...\n",
      "Fetching observation data for time-00-33-30-323429_chatcmpl-a429128d-7270-4bf9-aa4e-8cd859205650...\n",
      "Fetching observation data for time-00-33-45-497091_chatcmpl-c0558bc7-158e-4388-bc86-bbb4e42c5b32...\n",
      "Fetching observation data for 24611344-5766-4e37-8e9d-128ab484de0b...\n",
      "Fetching observation data for time-00-31-23-583675_chatcmpl-63981366-d0e0-484a-96a8-a2bf315588af...\n",
      "Fetching observation data for time-00-31-38-440896_chatcmpl-8170c4c7-8dd0-42ec-bcf3-fee85ad7f7db...\n",
      "Fetching observation data for time-00-32-06-330107_chatcmpl-9c5edbdd-e5fe-41a7-9370-13d8a17844a8...\n",
      "Fetching observation data for time-00-32-23-179688_chatcmpl-e93e06f3-fdf4-4606-b92a-4a7b6cff3a25...\n",
      "Fetching observation data for time-00-32-30-706609_chatcmpl-b8692684-68c7-4382-b508-ff317dd09848...\n",
      "Fetching observation data for 80efbb13-c31d-4245-8815-a58c2dfa7d90...\n",
      "Fetching observation data for time-00-29-55-347117_chatcmpl-5a659b26-a1e5-4bf9-a82d-97601701bd8e...\n",
      "Fetching observation data for time-00-30-14-676220_chatcmpl-cd74c6e9-96fd-4e79-851b-0ec29759ac25...\n",
      "Fetching observation data for time-00-30-23-003326_chatcmpl-da373b79-7b99-4909-9b8d-61937c84d391...\n",
      "Fetching observation data for time-00-30-31-820946_chatcmpl-1518641d-358e-421e-bbd2-d3ec94b30ed0...\n",
      "Fetching observation data for time-00-28-54-261248_chatcmpl-7c870f68-b51b-4b1a-b725-324332e2017b...\n",
      "Fetching observation data for time-00-29-13-036220_chatcmpl-5b19b435-41a2-41bc-8796-06a6a5a1b132...\n",
      "Fetching observation data for time-00-29-19-610774_chatcmpl-5e0b6958-835d-4352-b200-38a167b75733...\n",
      "Fetching observation data for time-00-29-29-158685_chatcmpl-8b850f4d-2416-4362-b689-93591db12905...\n",
      "Fetching observation data for time-00-29-32-221879_chatcmpl-86987455-9a8e-4ce3-ad10-1070f16c78dc...\n",
      "Fetching observation data for fd94e286-85be-4eb3-8c18-3e6e4c65fe6b...\n",
      "Fetching observation data for time-00-27-20-721362_chatcmpl-7bf0c9c9-ca8e-49e1-9f2f-c70cf14ffc06...\n",
      "Fetching observation data for time-00-27-41-628469_chatcmpl-67ce8ef1-48b9-4d24-b502-26a326c7fd41...\n",
      "Fetching observation data for time-00-27-56-045493_chatcmpl-47853c29-3e3a-4fb9-a4ba-92c98787b675...\n",
      "Fetching observation data for time-00-28-15-479157_chatcmpl-ac2664aa-30d0-4788-a6f8-d61340851f46...\n",
      "Fetching observation data for time-00-28-26-108521_chatcmpl-d35ba63c-1f3a-4436-8286-1c7a95dfec9d...\n",
      "Fetching observation data for 9f8d6c3d-886f-4124-8865-3fef3e5eddd5...\n",
      "Fetching observation data for time-00-25-56-899624_chatcmpl-4bfb7a76-41c5-40b8-9be2-8b926b4624a3...\n",
      "Fetching observation data for time-00-26-13-231304_chatcmpl-7d928f53-3e14-4b9b-ba1f-a00d1180826c...\n",
      "Fetching observation data for time-00-26-29-582319_chatcmpl-57bbeb2c-7bdf-45ad-b1c4-86d9761618ae...\n",
      "Fetching observation data for time-00-26-52-459439_chatcmpl-0d43581f-17df-4872-b357-549c986057a2...\n",
      "Fetching observation data for time-00-27-01-961101_chatcmpl-c0abd3d5-38f0-4661-8de1-29584729187d...\n",
      "Fetching observation data for 75bc4d34-861e-42f7-b137-cf8320f43815...\n",
      "Fetching observation data for time-00-24-55-332144_chatcmpl-1cf2eb4a-0da5-43fa-ae20-f3c71c34bcd5...\n",
      "Fetching observation data for time-00-25-11-348145_chatcmpl-b7270091-3807-4494-af41-791a5f4d9fd7...\n",
      "Fetching observation data for time-00-25-20-944987_chatcmpl-abc47e6d-d48d-4d7d-bfb9-7b67a94e89a6...\n",
      "Fetching observation data for time-00-25-33-507906_chatcmpl-d0fc4572-e027-483f-94a9-9fd1adbc0dd2...\n",
      "Fetching observation data for time-00-25-40-143881_chatcmpl-910b6542-4a15-4e0e-8522-4a16bdb8c4e1...\n",
      "Fetching observation data for 95ea5b2b-b406-4cd3-b384-ad5c3ba6aea8...\n",
      "Fetching observation data for time-00-23-52-769463_chatcmpl-a8c65fe8-6c0d-4260-a3d3-bcee485448c2...\n",
      "Fetching observation data for time-00-24-11-937375_chatcmpl-c3a62d23-3621-4707-8754-36fefff8bdc5...\n",
      "Fetching observation data for time-00-24-20-101350_chatcmpl-f4a0de91-3fac-49e4-98ca-80cfe9ee9e7d...\n",
      "Fetching observation data for time-00-24-26-592353_chatcmpl-82cdf5fc-8297-476a-810c-570595ba8e34...\n",
      "Fetching observation data for time-00-24-39-831633_chatcmpl-b0ee2a39-03d6-4bf5-84ef-3f0af25377a3...\n",
      "Fetching observation data for 67ca9369-7db2-4986-9f8a-2d24ece69f4a...\n",
      "Fetching observation data for time-00-22-36-077219_chatcmpl-3ce32625-d192-44dd-a5d3-95d4e0c45f06...\n",
      "Fetching observation data for time-00-22-55-401107_chatcmpl-6bf71077-807e-4eaa-8d86-7087c8f60653...\n",
      "Fetching observation data for time-00-23-07-002730_chatcmpl-e91fe3f0-5967-41d5-9df2-576c2802379b...\n",
      "Fetching observation data for time-00-23-18-414121_chatcmpl-9013a4a9-02b4-4f5e-97da-f8f59b678e68...\n",
      "Fetching observation data for time-00-23-34-239070_chatcmpl-19906fac-daab-4a3d-ace8-93970da60d59...\n",
      "Fetching observation data for dc591eb1-d3cc-4f1f-b363-2d8dd8b69d8f...\n",
      "Fetching observation data for time-00-21-25-524329_chatcmpl-e5a81bc5-9db3-4940-8002-588b9cd7487b...\n",
      "Fetching observation data for time-00-21-43-423056_chatcmpl-319a6bef-08fe-440f-884f-bff4830bade6...\n",
      "Fetching observation data for time-00-21-58-637343_chatcmpl-abce88a1-8a26-46fb-9764-cd0cee645343...\n",
      "Fetching observation data for time-00-22-06-640067_chatcmpl-87878aa4-4518-47e9-bf7a-1f5507f75c6e...\n",
      "Fetching observation data for time-00-20-08-971925_chatcmpl-adf34c84-3c22-4250-b472-c917b7d6d084...\n",
      "Fetching observation data for time-00-20-24-557099_chatcmpl-2ab67941-cd5e-44de-b1fa-28e44783e52a...\n",
      "Fetching observation data for time-00-20-35-513100_chatcmpl-8045eae7-60ee-4677-b7b4-5a653c31ea89...\n",
      "Fetching observation data for time-00-20-55-508087_chatcmpl-c3260a18-3ef7-4894-a9e5-9a7cba825ec5...\n",
      "Fetching observation data for time-00-21-06-028293_chatcmpl-2b1d0ac0-6c7b-4e75-8f96-00bf45af6590...\n",
      "Fetching observation data for 6766a937-9d27-4524-8e39-061d56132e8e...\n",
      "Fetching observation data for time-00-19-24-443596_chatcmpl-85a0e442-3e49-419b-8c4c-abd81492f361...\n",
      "Fetching observation data for time-00-19-39-387223_chatcmpl-398ced37-3961-47c1-8b6d-a760982fd716...\n",
      "Fetching observation data for time-00-19-51-726092_chatcmpl-c0101140-673e-4ada-be4f-3f96095e62c5...\n",
      "Fetching observation data for time-00-18-07-857018_chatcmpl-4d4ad821-1c02-430b-a61e-eb8b4fabeb2f...\n",
      "Fetching observation data for time-00-18-19-179165_chatcmpl-8b72f4d7-bf87-41a6-bbe5-0dd5aa96f993...\n",
      "Fetching observation data for time-00-18-30-223282_chatcmpl-08954446-f89c-40a5-b778-d4d3d78c0443...\n",
      "Fetching observation data for time-00-18-41-069049_chatcmpl-15931b5e-8708-4ffc-98bb-a241885b3a2e...\n",
      "Fetching observation data for time-00-19-01-256286_chatcmpl-944f185f-500d-4ea8-81d5-91204dcaa556...\n",
      "Fetching observation data for 88a41abd-762a-4dae-a3f2-63bf5fc46b12...\n",
      "Fetching observation data for time-00-16-37-287182_chatcmpl-44d9be01-287c-498a-b9ad-667324808638...\n",
      "Fetching observation data for time-00-16-56-420774_chatcmpl-351e0b1b-2d3d-4626-a759-6c0458ba6cdb...\n",
      "Fetching observation data for time-00-17-06-660750_chatcmpl-b2fab204-08f9-45f3-947d-4f559c8f91c3...\n",
      "Fetching observation data for time-00-17-21-183677_chatcmpl-e9355636-8cfb-40f7-af7d-29353ff13225...\n",
      "Fetching observation data for time-00-17-42-008084_chatcmpl-996c71c6-703f-4c73-acb2-2942fae9e08c...\n",
      "Fetching observation data for 3ff603dc-d222-4a2a-accc-9e5616f0fe0b...\n",
      "Fetching observation data for time-00-15-14-519974_chatcmpl-c8d19611-5e73-403b-b4b2-c73fc3a21683...\n",
      "Fetching observation data for time-00-15-34-333051_chatcmpl-3a718d57-6f6e-4ee2-90f3-41c1ee8dc843...\n",
      "Fetching observation data for time-00-15-46-001564_chatcmpl-2b862120-f774-4033-8119-db7c5e25e292...\n",
      "Fetching observation data for time-00-16-00-916965_chatcmpl-ff63e811-0943-4b44-aa1f-0b805b432d46...\n",
      "Fetching observation data for time-00-16-14-500083_chatcmpl-79b70dfc-def6-47d2-9672-add82b1f02bc...\n",
      "Fetching observation data for 08866317-f508-4b04-ad58-acd44c2046ed...\n",
      "Fetching observation data for time-00-13-45-896367_chatcmpl-7b70b249-b345-4ea3-84c4-55f2b9a1a258...\n",
      "Fetching observation data for time-00-14-03-177835_chatcmpl-7a58d054-d52d-4eac-a68d-6e44351390a3...\n",
      "Fetching observation data for time-00-14-08-455452_chatcmpl-35630a51-be4c-487e-99a5-1bcc02ce37fa...\n",
      "Fetching observation data for time-00-14-49-370302_chatcmpl-960acac1-8589-4271-becb-91d205fd237a...\n",
      "Fetching observation data for time-00-14-59-081054_chatcmpl-3ca8e7fc-ca89-4161-a90d-9150f924978e...\n",
      "Fetching observation data for 9d4bdc2c-db7b-41d6-b25d-fcc1a369ca81...\n",
      "Fetching observation data for time-00-12-25-319207_chatcmpl-9f191570-eadf-4079-9778-8f18094b2c12...\n",
      "Fetching observation data for time-00-12-41-013229_chatcmpl-555f86be-d1d7-4eba-82a6-d4d9708a724f...\n",
      "Fetching observation data for time-00-12-48-815121_chatcmpl-aded7c6d-31c4-43dd-9c6e-ce7d7d3522a3...\n",
      "Fetching observation data for time-00-13-03-868057_chatcmpl-ff067193-1db6-453c-8b18-642061e22967...\n",
      "Fetching observation data for time-00-13-22-677207_chatcmpl-288d9c7a-122c-46cd-96c2-8407cf665859...\n",
      "Fetching observation data for a8cf427b-f6f4-4f37-930d-9cd7340924ed...\n",
      "Fetching observation data for time-00-11-24-367475_chatcmpl-77a7f5d0-d2ae-4e0d-bafb-a528fcaffe4e...\n",
      "Fetching observation data for time-00-11-41-603619_chatcmpl-f9856b13-1962-4ed1-bd27-cf9ceae8a05d...\n",
      "Fetching observation data for time-00-11-45-783871_chatcmpl-475540e5-0c24-4695-8fbd-5b0e084cee68...\n",
      "Fetching observation data for time-00-11-52-181019_chatcmpl-7e2e1250-94e2-4887-9a1d-033e5b657203...\n",
      "Fetching observation data for time-00-12-04-174356_chatcmpl-b2653d1e-939b-462f-a01d-60c7e62622fd...\n",
      "Fetching observation data for 59cf92a5-53c6-439b-b90b-7f905479e188...\n",
      "Fetching observation data for time-00-10-13-784431_chatcmpl-38fa2878-fc62-4b3c-a623-77284f9548bf...\n",
      "Fetching observation data for time-00-10-27-641093_chatcmpl-5adeb55e-2bf3-4695-9f42-f92a78a360b3...\n",
      "Fetching observation data for time-00-10-36-303054_chatcmpl-c5d752ea-77ba-4fbe-9be4-131550bf50f3...\n",
      "Fetching observation data for time-00-10-49-790309_chatcmpl-b896540d-8f6c-4b50-832b-890ea02fea14...\n",
      "Fetching observation data for time-00-11-01-123048_chatcmpl-4bc135fc-ad5c-48e2-a135-37fa7bd3ad6e...\n",
      "Fetching observation data for 1804ee86-5516-431d-a326-9307c68759c1...\n",
      "Fetching observation data for time-00-09-14-168605_chatcmpl-c1d7fd0e-1aed-42b5-911c-4c8529a9f21c...\n",
      "Fetching observation data for time-00-09-31-430760_chatcmpl-9355ed45-58e8-4573-a289-98eada9411ab...\n",
      "Fetching observation data for time-00-09-44-086887_chatcmpl-64938f15-f0bf-4dff-afbb-9255ee3adb4f...\n",
      "Fetching observation data for time-00-08-21-242971_chatcmpl-85b5a25f-7ac2-48e6-9943-445e733f782c...\n",
      "Fetching observation data for time-00-08-41-461121_chatcmpl-df66c2b9-2ed2-4072-9d0c-04d7613a403d...\n",
      "Fetching observation data for time-00-08-49-689754_chatcmpl-de6b0e90-7582-422c-8adb-461ba1da9d7b...\n",
      "Fetching observation data for time-00-08-54-707279_chatcmpl-2f276a11-91a6-4bf3-9897-1e09b337cd66...\n",
      "Fetching observation data for time-00-08-57-209830_chatcmpl-ab3dc196-48a5-4093-b09f-0e10510ab3e6...\n",
      "Fetching observation data for 1e696de5-0dd3-4256-bc4d-0d2c62e240cb...\n",
      "Fetching observation data for time-00-07-49-525600_chatcmpl-0a3e64ec-2764-44cb-9b36-468b463c5dc0...\n",
      "Fetching observation data for time-00-06-17-788900_chatcmpl-fa335daa-acc5-4dd3-9fe4-da9e5a8e6ea8...\n",
      "Fetching observation data for time-00-06-34-398239_chatcmpl-4c0822bc-b5b3-4416-a041-ca667b687011...\n",
      "Fetching observation data for time-00-06-59-143350_chatcmpl-7839c589-c9ce-4609-84e0-e7030c7a5a4a...\n",
      "Fetching observation data for time-00-07-07-514939_chatcmpl-58f5780a-4df1-4edb-98c1-2aa8f68a0807...\n",
      "Fetching observation data for time-00-07-19-384580_chatcmpl-a983e7f1-b119-4cf1-a4d1-bcd48b345825...\n",
      "Fetching observation data for e509f324-d719-4501-8c9d-cd4f5b706aee...\n",
      "Raw JSON saved to: /Users/hann/Projects/reference-benchmark-tinyml_llm/data_analysis/2025/08.14/raw_export/raw_codestral_9eb0_psg_batch.json\n",
      "Fetching traces for session codestral_9eb0_tpusg_batch...\n",
      "Fetching observation data for time-00-03-57-774627_chatcmpl-ea5674fa-ae8e-4c86-9e60-2c61a9d5d937...\n",
      "Fetching observation data for time-00-04-23-480572_chatcmpl-71cb230c-53b7-4b77-9c20-bb36c6d2e2f4...\n",
      "Fetching observation data for time-00-04-50-320510_chatcmpl-6c147c73-3f77-4170-a359-d5ef6b5fb9f7...\n",
      "Fetching observation data for time-00-05-17-275134_chatcmpl-d7d4f582-e33c-4fe9-a9a7-fbe7abc3ca30...\n",
      "Fetching observation data for time-00-05-47-023468_chatcmpl-d83e8ecc-4276-4f25-b34e-fe21fc98f1a6...\n",
      "Fetching observation data for 771dacad-1b34-4a2d-b57b-644349156ba3...\n",
      "Fetching observation data for time-00-02-28-212971_chatcmpl-b19b9b05-4b85-4beb-9d51-1f54a864de73...\n",
      "Fetching observation data for time-00-02-56-484650_chatcmpl-12bba04d-47a4-4e52-b676-da35dcf82bdb...\n",
      "Fetching observation data for time-00-03-02-734273_chatcmpl-0b5a5ede-9790-4333-bc6e-b7357f509d3c...\n",
      "Fetching observation data for time-00-03-05-906288_chatcmpl-69fe75fe-d2f5-4625-9e25-71cc1a8ca072...\n",
      "Fetching observation data for time-00-03-29-056196_chatcmpl-327d27f5-86d2-43c8-9617-8e2a1abeed84...\n",
      "Fetching observation data for ddd2d773-cfbf-49a3-bb5e-043bf2cccaf0...\n",
      "Fetching observation data for time-00-00-59-907864_chatcmpl-cd9ff988-6207-4f7e-b6d4-1827bbe5d8da...\n",
      "Fetching observation data for time-00-01-18-508639_chatcmpl-25a1cca8-42fd-4e02-a0c5-dde1580c5808...\n",
      "Fetching observation data for time-00-01-38-742568_chatcmpl-77ab9616-f3c1-434c-bc35-7f85bf6a5f50...\n",
      "Fetching observation data for time-00-01-42-905546_chatcmpl-d09d5486-a9e8-4a9a-be08-bbb13fe4bfd8...\n",
      "Fetching observation data for time-00-02-08-518889_chatcmpl-4f2f2f23-9428-4261-9db3-346caa71e80b...\n",
      "Fetching observation data for 297734cd-5011-421f-9891-790e91ec041b...\n",
      "Fetching observation data for time-00-00-13-916685_chatcmpl-9d3502f5-689c-40e4-8980-4bb2ef47762a...\n",
      "Fetching observation data for time-00-00-42-791664_chatcmpl-dab5fe48-02c0-4014-83a7-dd4a6460c019...\n",
      "Fetching observation data for time-23-59-01-335908_chatcmpl-8c98fc28-d50f-4885-9cde-f66ec4e74541...\n",
      "Fetching observation data for time-23-59-16-752943_chatcmpl-a7948b67-c21a-430d-9e06-01cfefdedba8...\n",
      "Fetching observation data for time-23-59-45-275640_chatcmpl-2eb258ee-a534-418a-9e9d-e4e083ae926d...\n",
      "Fetching observation data for f13c388d-ee42-4e02-a12c-97d2fdc8d10a...\n",
      "Fetching observation data for time-23-57-17-732632_chatcmpl-cb8f3198-7f5d-4757-af7d-cc4acf8d2877...\n",
      "Fetching observation data for time-23-57-46-285759_chatcmpl-a47ea6c5-6d05-481d-8cab-02e4643097c6...\n",
      "Fetching observation data for time-23-55-57-250329_chatcmpl-4c0f7474-5a39-4908-9d27-4f5e786f8782...\n",
      "Fetching observation data for time-23-56-24-468892_chatcmpl-c7403848-1e4c-4e59-b890-2ffc0ef9d1af...\n",
      "Fetching observation data for time-23-56-56-124832_chatcmpl-5aba971d-ff93-4a99-81cd-d315bfe5a26f...\n",
      "Fetching observation data for time-23-56-59-060058_chatcmpl-2142e6a4-0855-4e1f-b08e-8c90941a75d8...\n",
      "Fetching observation data for time-23-57-01-819389_chatcmpl-fe38d2f6-5405-4b17-8fec-4f77dcc564d7...\n",
      "Fetching observation data for e472ade1-2025-481b-842b-a578d81bc86f...\n",
      "Fetching observation data for time-23-54-28-695122_chatcmpl-c242537a-8dc0-4cae-8bb1-385b9fe398bf...\n",
      "Fetching observation data for time-23-54-38-094101_chatcmpl-868e64a3-9ab1-4eb9-bd7f-3080667d4589...\n",
      "Fetching observation data for time-23-54-53-610724_chatcmpl-b1974f34-e157-4a10-bedf-8f6b241fe5ac...\n",
      "Fetching observation data for time-23-55-11-132937_chatcmpl-a44da059-e15c-4a0c-af33-3bc02f6fed37...\n",
      "Fetching observation data for time-23-55-31-524457_chatcmpl-f2a981a8-64cb-4b2a-84ce-28143ac560fe...\n",
      "Fetching observation data for 49ae8e83-debc-4527-9d1c-61c815fc9df4...\n",
      "Fetching observation data for time-23-52-04-100534_chatcmpl-2ffdce04-3c40-4768-911d-c7762fc7f7ef...\n",
      "Fetching observation data for time-23-52-26-547903_chatcmpl-e9070cc5-8360-4b77-9c8f-3e4b5b91ca9a...\n",
      "Fetching observation data for time-23-52-53-827862_chatcmpl-7709b8b6-422d-4e25-a056-5cae5924f50b...\n",
      "Fetching observation data for time-23-52-58-327354_chatcmpl-b7687bd4-7ae6-405f-845c-bad560a1f51b...\n",
      "Fetching observation data for time-23-53-19-213679_chatcmpl-60f1f904-0c23-4a99-9b69-5ea2aed99a69...\n",
      "Fetching observation data for time-23-49-51-553155_chatcmpl-bffb0d64-beac-4ae1-873b-bac5d8e5afcb...\n",
      "Fetching observation data for time-23-50-13-964239_chatcmpl-f7949726-4499-4e8a-b88c-8b87878d5dd6...\n",
      "Fetching observation data for time-23-50-43-388077_chatcmpl-a964b0ae-93ee-4c56-b6e9-3fd3ba584156...\n",
      "Fetching observation data for time-23-47-33-264978_chatcmpl-d1725822-1f45-43c8-8a32-bacefe3c3b9b...\n",
      "Fetching observation data for time-23-48-01-641667_chatcmpl-440840b8-6343-498f-8d51-66bcfdfef1a2...\n",
      "Fetching observation data for time-23-48-34-154841_chatcmpl-ce8bdb0d-5fcf-4142-ac9a-d650c25044d5...\n",
      "Fetching observation data for time-23-49-03-901503_chatcmpl-c8032e80-c827-49ab-8dda-a35bc8968fd8...\n",
      "Fetching observation data for time-23-49-36-030716_chatcmpl-d08bfc0e-71c0-4471-a803-d7c2b6b5c25b...\n",
      "Fetching observation data for bf6d0d4a-7f43-4878-b439-d16fb31f2063...\n",
      "Fetching observation data for time-23-45-32-718100_chatcmpl-39f7ec91-da72-4872-b430-52e68fe112ac...\n",
      "Fetching observation data for time-23-45-56-247051_chatcmpl-88aa270b-dba9-4f6e-bd56-ea98c6a791a3...\n",
      "Fetching observation data for time-23-46-03-068554_chatcmpl-f1f171d5-a91e-4787-a706-1f9d0004dafe...\n",
      "Fetching observation data for time-23-46-32-064482_chatcmpl-8ddb18ef-f565-4e3d-a281-8a683600342d...\n",
      "Fetching observation data for time-23-46-59-716147_chatcmpl-6134c877-fdc0-4e8f-8103-35a6ae94c32a...\n",
      "Fetching observation data for 99331851-bef8-413f-8dba-be91c1dbf9da...\n",
      "Fetching observation data for time-23-43-25-064789_chatcmpl-4c93445a-3be0-40d1-9fdc-304b755a1609...\n",
      "Fetching observation data for time-23-43-49-634646_chatcmpl-e90cd0e1-1a1a-430a-927d-c330ba16ca8a...\n",
      "Fetching observation data for time-23-43-52-983117_chatcmpl-3058cec2-717f-48c0-af13-00734c4b3efd...\n",
      "Fetching observation data for time-23-44-24-108908_chatcmpl-b56601e9-1b80-4a5d-9617-79fe51d02be2...\n",
      "Fetching observation data for time-23-44-56-233630_chatcmpl-d975dbf6-e2e6-4407-b9f3-9868e0793f0b...\n",
      "Fetching observation data for 6ec00472-86b6-42d0-983d-d7c3a651f41f...\n",
      "Fetching observation data for time-23-40-54-804778_chatcmpl-c71dad0a-dc83-43da-9ac1-eb1b009d2a0a...\n",
      "Fetching observation data for time-23-41-04-987811_chatcmpl-0be6980d-1b55-471c-aace-1b7b00b3642c...\n",
      "Fetching observation data for time-23-41-24-965493_chatcmpl-754f80f4-0c59-45e7-9148-bd16096a3e3b...\n",
      "Fetching observation data for time-23-41-43-580202_chatcmpl-cd93d487-d8fe-43f2-a07a-8aef189b3a49...\n",
      "Fetching observation data for time-23-42-05-734842_chatcmpl-ba78009c-ce59-49ee-ae83-4f0870b92be6...\n",
      "Fetching observation data for time-23-38-37-205107_chatcmpl-727bf1ce-7bd0-4680-9d6b-588f44d8cc14...\n",
      "Fetching observation data for time-23-39-06-307045_chatcmpl-926b7aa0-bc18-4141-a5b3-9d1d39b1d014...\n",
      "Fetching observation data for time-23-39-32-774746_chatcmpl-4b886ac3-4eb4-4c52-b3cd-24b8db14a22c...\n",
      "Fetching observation data for time-23-36-54-605818_chatcmpl-a2884d2b-61fe-4fde-b57b-0e07493ae621...\n",
      "Fetching observation data for time-23-37-18-857820_chatcmpl-2fc2edda-62b7-4e79-9bf0-d02a6c10140a...\n",
      "Fetching observation data for time-23-36-27-473597_chatcmpl-36af3c66-f7a9-459d-ab06-9cd2c156e732...\n",
      "Fetching observation data for time-23-34-47-913857_chatcmpl-93e61b6a-5907-4818-90f5-0cb0562246fb...\n",
      "Fetching observation data for time-23-35-11-475025_chatcmpl-2e25aded-6466-41d7-8c9d-c506d9535c6a...\n",
      "Fetching observation data for time-23-32-40-179126_chatcmpl-a0bf2160-66c3-4314-a8e6-37ba9fcdfe54...\n",
      "Fetching observation data for time-23-33-13-394661_chatcmpl-23625b11-86af-451c-bd28-faafae552dc5...\n",
      "Fetching observation data for time-23-33-39-923847_chatcmpl-d0584b1d-3b8f-4733-9e58-b955ac9777d4...\n",
      "Fetching observation data for time-23-34-09-151557_chatcmpl-3f71dc03-9880-47f3-8660-fe55c0aa272e...\n",
      "Fetching observation data for 2d55038d-0e07-4bd1-ac3d-a6164f777901...\n",
      "Fetching observation data for time-23-29-51-525964_chatcmpl-4722466c-aedc-4611-bc06-c20d4201f3ef...\n",
      "Fetching observation data for time-23-30-17-959591_chatcmpl-d40a9db9-a1bd-49c9-a78c-d33c244d033c...\n",
      "Fetching observation data for time-23-30-49-925640_chatcmpl-a7e1e89f-45c4-453f-97ee-bb6efe5cb879...\n",
      "Fetching observation data for time-23-31-25-572263_chatcmpl-5b1ad5a2-4ccb-445b-a19d-6bbd192d4c15...\n",
      "Fetching observation data for time-23-32-00-026141_chatcmpl-2cd5feb3-e571-4e73-ab62-8c59fd03a4c0...\n",
      "Fetching observation data for 88d46183-990e-435c-aabb-216862d949ae...\n",
      "Fetching observation data for time-23-27-28-480698_chatcmpl-ad5294c6-f963-4be4-8b62-31e816c108e5...\n",
      "Fetching observation data for time-23-27-57-803451_chatcmpl-693ed373-d9d1-47c1-b4fc-c665bcc7620f...\n",
      "Fetching observation data for time-23-28-27-936237_chatcmpl-5857b8df-c218-4641-81ee-5c6a551b2509...\n",
      "Fetching observation data for time-23-28-59-276254_chatcmpl-b019dc24-8531-48f4-b00a-455fcf74061a...\n",
      "Fetching observation data for time-23-29-23-676012_chatcmpl-e06e4c10-f141-43ac-9538-c2569d889f95...\n",
      "Fetching observation data for 3731114d-4265-4818-8a7c-45c9488b8c7f...\n",
      "Fetching observation data for time-23-25-54-162043_chatcmpl-7e8e9ada-3168-4b5b-b132-b457c26ed80e...\n",
      "Fetching observation data for time-23-26-14-833350_chatcmpl-56b303cb-0ff6-428f-9764-8eec6a2092a1...\n",
      "Fetching observation data for time-23-23-24-368305_chatcmpl-6edaf1ea-3b61-412b-a892-6c42aebcb6e3...\n",
      "Fetching observation data for time-23-23-49-431110_chatcmpl-dca3d273-81c5-4df7-9aed-ba83a2ac188c...\n",
      "Fetching observation data for time-23-24-18-240719_chatcmpl-7465fc46-7221-439a-ab61-311d2b084614...\n",
      "Fetching observation data for time-23-24-49-830113_chatcmpl-7591b31e-0e04-4b6d-bf28-19f484dfe178...\n",
      "Fetching observation data for time-23-25-21-258683_chatcmpl-ae79ad39-1bf6-4eef-9914-7cc1dfb9ab65...\n",
      "Fetching observation data for 67f221fb-a552-4102-a1ef-0a0ab8196751...\n",
      "Fetching observation data for time-23-21-55-116744_chatcmpl-d206a29c-0cd8-410a-85bd-53338abb1786...\n",
      "Fetching observation data for time-23-22-11-907823_chatcmpl-b59d0b09-d1fd-4a62-99ec-a2816f0b49e3...\n",
      "Fetching observation data for time-23-22-32-424768_chatcmpl-16307b4f-1829-43a4-b4c6-0a6d322efff3...\n",
      "Fetching observation data for time-23-22-50-836904_chatcmpl-557d90dd-dd08-4b70-860d-0372a600d0d6...\n",
      "Fetching observation data for time-23-23-09-075230_chatcmpl-a6f9241a-3251-4cff-98ec-05efb640dcae...\n",
      "Fetching observation data for 17a7be2b-b781-40d6-870e-86171afffcb1...\n",
      "Fetching observation data for time-23-19-52-502535_chatcmpl-af4fe91b-7ab3-4ea9-ba03-914818b22dc8...\n",
      "Fetching observation data for time-23-20-21-375748_chatcmpl-7af9ce55-ce80-48ea-b53d-849091065ccf...\n",
      "Fetching observation data for time-23-20-51-398203_chatcmpl-83dc6d6a-57a6-46a1-9e72-48969d6e9394...\n",
      "Fetching observation data for time-23-21-16-886933_chatcmpl-6a354295-3e2b-4751-b772-b0dc2d161b5a...\n",
      "Fetching observation data for time-23-21-43-373720_chatcmpl-59d23f3f-4ea3-4047-9be5-d48e55db0dbf...\n",
      "Fetching observation data for adf401b2-4b55-416b-8117-378692760a16...\n",
      "Fetching observation data for time-23-18-54-855814_chatcmpl-3c30cf65-6f3b-487e-a132-e09284ad0ea6...\n",
      "Fetching observation data for time-23-19-17-864663_chatcmpl-c5627cd6-7f08-48c4-99ee-4fb1df2af125...\n",
      "Fetching observation data for time-23-19-25-819931_chatcmpl-09c1d72e-7e7e-4d65-9b83-befefa6fc530...\n",
      "Fetching observation data for time-23-19-31-653047_chatcmpl-eb42b6b1-9dc1-47ba-91c0-eda72f3adf46...\n",
      "Fetching observation data for time-23-19-38-821934_chatcmpl-04e2bd72-c3d4-4de2-9d98-4d8a17b54cd8...\n",
      "Fetching observation data for 2665ae57-426a-4097-af05-037cfc2bbf94...\n",
      "Fetching observation data for time-23-17-30-350117_chatcmpl-93bbe31c-5572-4581-bcf1-fa77362fb7e6...\n",
      "Fetching observation data for time-23-17-53-885098_chatcmpl-3bf05054-779e-4acc-8ac3-16774c5bb61e...\n",
      "Fetching observation data for time-23-17-57-168248_chatcmpl-139cc9e2-5018-45a6-9d1c-84d2cc63cc2d...\n",
      "Fetching observation data for time-23-18-10-020073_chatcmpl-3922ef7d-5721-47b8-acf3-1bafffd99a01...\n",
      "Fetching observation data for time-23-18-29-056947_chatcmpl-ed520985-651e-47f1-996b-aa6afc217064...\n",
      "Fetching observation data for b7495bbd-1d26-4396-9acb-3f78f01b2a0c...\n",
      "Fetching observation data for time-23-15-45-498743_chatcmpl-2a893638-50b0-4ece-bf59-ce5b4fed7f97...\n",
      "Fetching observation data for time-23-16-07-619157_chatcmpl-a9318fa9-b707-4dc3-8225-71f9a175923d...\n",
      "Fetching observation data for time-23-16-12-309914_chatcmpl-a876a755-1915-489c-a363-d97c0a2adfb0...\n",
      "Fetching observation data for time-23-16-29-542757_chatcmpl-ee824206-f9cc-427a-b953-950277f0162e...\n",
      "Fetching observation data for time-23-16-55-573504_chatcmpl-4c03d210-b6bc-43a5-a823-3274dd0baea9...\n",
      "Fetching observation data for ecb56607-8aa7-4872-a1f9-05bcd31899df...\n",
      "Fetching observation data for time-23-13-06-907714_chatcmpl-1b1f198b-8250-4b13-bac2-76e99963e8d5...\n",
      "Fetching observation data for time-23-13-30-541607_chatcmpl-96e07757-a4d7-466d-b5fe-ab535f654629...\n",
      "Fetching observation data for time-23-13-57-340124_chatcmpl-1ea00d98-28a7-4844-85ae-2e3c6ab6d9b0...\n",
      "Fetching observation data for time-23-14-26-466122_chatcmpl-5e026b82-1a39-4b31-9894-75da886966c1...\n",
      "Fetching observation data for time-23-11-04-366813_chatcmpl-a9a6bb2d-de3e-4edf-ae50-36dd23330424...\n",
      "Fetching observation data for time-23-11-24-985760_chatcmpl-511ccaab-9d78-4526-a2ff-508230d7b0a6...\n",
      "Fetching observation data for time-23-11-50-998479_chatcmpl-59f05228-240f-478e-b46e-aebd052d55de...\n",
      "Fetching observation data for time-23-12-12-740255_chatcmpl-7eb7d483-d0bd-4d3e-ab41-801b9510dd52...\n",
      "Fetching observation data for time-23-12-37-199354_chatcmpl-d9c2ecaa-c0e0-4f00-8445-b72a52c56451...\n",
      "Fetching observation data for a5241230-fd46-4449-836b-c10750c8aa67...\n",
      "Fetching observation data for time-23-07-22-778709_chatcmpl-c3ad890b-d5d2-45b4-a021-94798be5a529...\n",
      "Fetching observation data for time-23-09-04-136672_chatcmpl-38452de8-73a4-444c-a84c-cb037ac63cf9...\n",
      "Fetching observation data for time-23-09-29-385999_chatcmpl-9436a6c5-ee08-4e2e-8e59-1e0e097fafbf...\n",
      "Fetching observation data for time-23-09-56-455079_chatcmpl-9ba663a4-5302-4c14-8fca-55b85c7c5bec...\n",
      "Fetching observation data for time-23-10-26-324699_chatcmpl-498b4777-c1c5-48b4-8153-b2200457231e...\n",
      "Fetching observation data for c18e590d-cf36-4918-a499-1c7edad950fb...\n",
      "Raw JSON saved to: /Users/hann/Projects/reference-benchmark-tinyml_llm/data_analysis/2025/08.14/raw_export/raw_codestral_9eb0_tpusg_batch.json\n"
     ]
    }
   ],
   "source": [
    "# ALTERNATIVE TO 2.\n",
    "import os\n",
    "import json\n",
    "from time import sleep\n",
    "from langfuse import Langfuse\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "\n",
    "# LANGFUSE_SERVICE_PUBLIC_KEY = \"pk-lf-559a2c0f-ee29-4c32-944c-bf73b5f0ce28\"\n",
    "# LANGFUSE_SERVICE_SECRET_KEY = \"sk-lf-75f8bf7f-a5db-4756-b0dd-d758a2a292c8\"\n",
    "# LANGFUSE_SERVICE_HOST = \"https://langfuse.hann.fi\"\n",
    "\n",
    "\n",
    "if LOCAL_HOST:\n",
    "    langfuse = Langfuse(\n",
    "        secret_key=\"sk-lf-75f8bf7f-a5db-4756-b0dd-d758a2a292c8\",\n",
    "        public_key=\"pk-lf-559a2c0f-ee29-4c32-944c-bf73b5f0ce28\",\n",
    "        host=\"https://langfuse.hann.fi\",\n",
    "    )\n",
    "else:\n",
    "    langfuse = Langfuse(\n",
    "        secret_key=LANGFUSE_SERVICE_SECRET_KEY,\n",
    "        public_key=LANGFUSE_SERVICE_PUBLIC_KEY,\n",
    "        host=LANGFUSE_SERVICE_HOST,\n",
    "    )\n",
    "\n",
    "API_invok_count = 0\n",
    "query_range_num_run = {\"start\": 0, \"end\": 1}\n",
    "\n",
    "\n",
    "class CustomJSONEncoder(json.JSONEncoder):\n",
    "    def __init__(self, *args, LOCAL_HOST=True, **kwargs):\n",
    "        self.LOCAL_HOST = LOCAL_HOST\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "    def default(self, obj):\n",
    "        if isinstance(obj, datetime):\n",
    "            return obj.isoformat()\n",
    "        if hasattr(obj, \"__dict__\"):\n",
    "            data = obj.__dict__.copy()\n",
    "            if \"observations\" in data:\n",
    "                data[\"observations\"] = [\n",
    "                    fetch_observation_data(obs, self.LOCAL_HOST)\n",
    "                    for obs in data[\"observations\"]\n",
    "                ]\n",
    "\n",
    "            return data\n",
    "        return super().default(obj)\n",
    "\n",
    "\n",
    "def fetch_observation_data(observation_id, LOCAL_HOST):\n",
    "    \"\"\"\n",
    "    Fetches observation data from Langfuse and returns its dictionary representation.\n",
    "    \"\"\"\n",
    "    print(f\"Fetching observation data for {observation_id}...\")\n",
    "    global API_invok_count\n",
    "    if API_invok_count >= 0 and not LOCAL_HOST:\n",
    "        print(\"Waiting for 3 seconds to fetch observation data...\")\n",
    "        for _ in tqdm(range(3), desc=\"Progress\", unit=\"s\"):\n",
    "            sleep(1)\n",
    "        API_invok_count = 0\n",
    "\n",
    "    observation_response = langfuse.fetch_observation(observation_id)\n",
    "    API_invok_count += 1\n",
    "\n",
    "    return observation_response.data.dict()\n",
    "\n",
    "\n",
    "def fetch_and_save_complete_data(session_id_list, raw_export_dir, LOCAL_HOST):\n",
    "    \"\"\"\n",
    "    Fetches complete trace data for each session ID and saves it to JSON files.\n",
    "\n",
    "    Parameters:\n",
    "        session_id_list (list): List of session IDs to process.\n",
    "        raw_export_dir (str): Directory path to save raw JSON files.\n",
    "    \"\"\"\n",
    "\n",
    "    def save_complete_data(session_id):\n",
    "        global API_invok_count\n",
    "        if API_invok_count >= 0 and not LOCAL_HOST:\n",
    "            print(\"Waiting for 4 seconds to fetch traces...\")\n",
    "            for _ in tqdm(range(4), desc=\"Progress\", unit=\"s\"):\n",
    "                sleep(1)\n",
    "            API_invok_count = 0\n",
    "\n",
    "        fetch_traces_response = langfuse.fetch_traces(session_id=session_id)\n",
    "        API_invok_count += 1\n",
    "\n",
    "        print(f\"Fetching traces for session {session_id}...\")\n",
    "        # Create directories if they don't exist\n",
    "        os.makedirs(raw_export_dir, exist_ok=True)\n",
    "\n",
    "        # Save complete data to JSON file\n",
    "        # if session_id.startswith(\"da0a\"):\n",
    "        #     session_id = \"phi4_\" + session_id\n",
    "        if \"tpsg\" in session_id:\n",
    "            session_id_ = session_id.replace(\"tpsg\", \"tpusg\")\n",
    "        else:\n",
    "            session_id_ = session_id\n",
    "            \n",
    "        raw_path = os.path.join(raw_export_dir, f\"raw_{session_id_}.json\")\n",
    "        with open(raw_path, \"w\") as f:\n",
    "            json.dump(fetch_traces_response, f, cls=CustomJSONEncoder, indent=2)\n",
    "\n",
    "        print(f\"Raw JSON saved to: {raw_path}\")\n",
    "\n",
    "    for session_id in session_id_list:\n",
    "        save_complete_data(session_id)\n",
    "\n",
    "\n",
    "fetch_and_save_complete_data(session_id_list, raw_export_dir, LOCAL_HOST)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Trim data\n",
    "\n",
    "Here also intercept the runs with fatal errors that need to be excluded from the analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPAN error_40_psg_failure_signal_py_sketch_generator: Failed. Last error: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "OpenCV: FFMPEG: tag 0x44495658/'XVID' is not supported with codec id 12 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n",
      "OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250813004307_psg_codestral:latest/tmp_20250813004307_psg_codestral:latest.py\", line 39, in <module>\n",
      "    interpreter.set_tensor(input_details[0]['index'], input_data)\n",
      "  File \"/home/wuguangh/.conda/envs/tinyml/lib/python3.10/site-packages/ai_edge_litert/interpreter.py\", line 764, in set_tensor\n",
      "    self._interpreter.SetTensor(tensor_index, value)\n",
      "ValueError: Cannot set tensor: Got value of type FLOAT32 but expected type UINT8 for input 175, name: normalized_input_image_tensor \n",
      "\n",
      "SPAN error_63_psg_failure_signal_py_sketch_generator: Failed. Last error: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250813004149_psg_codestral:latest/tmp_20250813004149_psg_codestral:latest.py\", line 22, in <module>\n",
      "    image = Image.open(input_path).resize((input_details[0]['shape'][1], input_details[0]['shape'][2]))  # resize to match model's input shape\n",
      "  File \"/home/wuguangh/.conda/envs/tinyml/lib/python3.10/site-packages/PIL/Image.py\", line 3536, in open\n",
      "    raise UnidentifiedImageError(msg)\n",
      "PIL.UnidentifiedImageError: cannot identify image file '/home/wuguangh/Projects/tinyml-autopilot/data/object_detection/sheeps.mp4'\n",
      "\n",
      "SPAN error_30_psg_failure_signal_py_sketch_generator: Failed. Last error: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250813004031_psg_codestral:latest/tmp_20250813004031_psg_codestral:latest.py\", line 26, in <module>\n",
      "    raise ValueError(\"Input data type is not float32\")\n",
      "ValueError: Input data type is not float32\n",
      "\n",
      "SPAN error_00_psg_failure_signal_py_sketch_generator: Failed. Last error: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250813003918_psg_codestral:latest/tmp_20250813003918_psg_codestral:latest.py\", line 38, in <module>\n",
      "    interpreter.set_tensor(input_details[0]['index'], input_data)\n",
      "  File \"/home/wuguangh/.conda/envs/tinyml/lib/python3.10/site-packages/ai_edge_litert/interpreter.py\", line 764, in set_tensor\n",
      "    self._interpreter.SetTensor(tensor_index, value)\n",
      "ValueError: Cannot set tensor: Got value of type FLOAT32 but expected type UINT8 for input 175, name: normalized_input_image_tensor \n",
      "\n",
      "SPAN error_6b_psg_failure_signal_py_sketch_generator: Failed. Last error: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250813003749_psg_codestral:latest/tmp_20250813003749_psg_codestral:latest.py\", line 24, in <module>\n",
      "    interpreter.set_tensor(input_details[0]['index'], input_data)\n",
      "TypeError: string indices must be integers\n",
      "\n",
      "SPAN error_e3_psg_failure_signal_py_sketch_generator: Failed. Last error: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250813003634_psg_codestral:latest/tmp_20250813003634_psg_codestral:latest.py\", line 29, in <module>\n",
      "    interpreter.set_tensor(input_details[0]['index'], input_data)\n",
      "  File \"/home/wuguangh/.conda/envs/tinyml/lib/python3.10/site-packages/ai_edge_litert/interpreter.py\", line 764, in set_tensor\n",
      "    self._interpreter.SetTensor(tensor_index, value)\n",
      "ValueError: Cannot set tensor: Got value of type FLOAT32 but expected type UINT8 for input 175, name: normalized_input_image_tensor \n",
      "\n",
      "SPAN error_df_psg_failure_signal_py_sketch_generator: Failed. Last error: Traceback (most recent call last):\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250813003508_psg_codestral:latest/tmp_20250813003508_psg_codestral:latest.py\", line 2, in <module>\n",
      "    from ai_edge_lite.interpreter import Interpreter\n",
      "ModuleNotFoundError: No module named 'ai_edge_lite'\n",
      "\n",
      "SPAN error_6f_psg_failure_signal_py_sketch_generator: Failed. Last error: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250813003400_psg_codestral:latest/tmp_20250813003400_psg_codestral:latest.py\", line 30, in <module>\n",
      "    interpreter.set_tensor(input_details[0]['index'], input_data)\n",
      "TypeError: string indices must be integers\n",
      "\n",
      "SPAN error_5b_psg_failure_signal_py_sketch_generator: Failed. Last error: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250813003244_psg_codestral:latest/tmp_20250813003244_psg_codestral:latest.py\", line 37, in <module>\n",
      "    interpreter.set_tensor(input_details[0]['index'], input_data)\n",
      "  File \"/home/wuguangh/.conda/envs/tinyml/lib/python3.10/site-packages/ai_edge_litert/interpreter.py\", line 764, in set_tensor\n",
      "    self._interpreter.SetTensor(tensor_index, value)\n",
      "ValueError: Cannot set tensor: Dimension mismatch. Got 640 but expected 300 for dimension 1 of input 175.\n",
      "\n",
      "SPAN error_6c_psg_failure_signal_py_sketch_generator: Failed. Last error: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250813002947_psg_codestral:latest/tmp_20250813002947_psg_codestral:latest.py\", line 30, in <module>\n",
      "    for filename in os.listdir(input_path):\n",
      "NotADirectoryError: [Errno 20] Not a directory: 'data/object_detection/sheeps.mp4'\n",
      "\n",
      "SPAN error_bc_psg_failure_signal_py_sketch_generator: Failed. Last error: 2025-08-13 00:28:45.802452: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-08-13 00:28:45.806574: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-08-13 00:28:45.819853: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-08-13 00:28:45.840239: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-08-13 00:28:45.846335: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-08-13 00:28:45.862153: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-08-13 00:28:46.751950: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250813002845_psg_codestral:latest/tmp_20250813002845_psg_codestral:latest.py\", line 40, in <module>\n",
      "    interpreter.set_tensor(input_details[0]['index'], input_data)\n",
      "  File \"/home/wuguangh/.conda/envs/tinyml/lib/python3.10/site-packages/tensorflow/lite/python/interpreter.py\", line 732, in set_tensor\n",
      "    self._interpreter.SetTensor(tensor_index, value)\n",
      "ValueError: Cannot set tensor: Got value of type FLOAT32 but expected type UINT8 for input 175, name: normalized_input_image_tensor \n",
      "\n",
      "SPAN error_59_psg_failure_signal_py_sketch_generator: Failed. Last error: Traceback (most recent call last):\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250813002714_psg_codestral:latest/tmp_20250813002714_psg_codestral:latest.py\", line 1, in <module>\n",
      "    from ai_edge_litert import Interpreter\n",
      "ImportError: cannot import name 'Interpreter' from 'ai_edge_litert' (/home/wuguangh/.conda/envs/tinyml/lib/python3.10/site-packages/ai_edge_litert/__init__.py)\n",
      "\n",
      "SPAN error_75_psg_failure_signal_py_sketch_generator: Failed. Last error: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250813002550_psg_codestral:latest/tmp_20250813002550_psg_codestral:latest.py\", line 21, in <module>\n",
      "    for input_data in data_source: # Replace data_source with your actual data source (file paths, video frames)\n",
      "NameError: name 'data_source' is not defined\n",
      "\n",
      "SPAN error_33_psg_failure_signal_py_sketch_generator: Failed. Last error: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250813002448_psg_codestral:latest/tmp_20250813002448_psg_codestral:latest.py\", line 26, in <module>\n",
      "    interpreter.set_tensor(input_details[0]['index'], input_data)\n",
      "  File \"/home/wuguangh/.conda/envs/tinyml/lib/python3.10/site-packages/ai_edge_litert/interpreter.py\", line 764, in set_tensor\n",
      "    self._interpreter.SetTensor(tensor_index, value)\n",
      "ValueError: Cannot set tensor: Dimension mismatch. Got 1 but expected 4 for input 175.\n",
      "\n",
      "SPAN error_ee_psg_failure_signal_py_sketch_generator: Failed. Last error: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250813002345_psg_codestral:latest/tmp_20250813002345_psg_codestral:latest.py\", line 34, in <module>\n",
      "    interpreter.set_tensor(input_details[0]['index'], input_data)\n",
      "  File \"/home/wuguangh/.conda/envs/tinyml/lib/python3.10/site-packages/ai_edge_litert/interpreter.py\", line 764, in set_tensor\n",
      "    self._interpreter.SetTensor(tensor_index, value)\n",
      "ValueError: Cannot set tensor: Dimension mismatch. Got 640 but expected 300 for dimension 1 of input 175.\n",
      "\n",
      "SPAN error_7a_psg_failure_signal_py_sketch_generator: Failed. Last error: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250813002118_psg_codestral:latest/tmp_20250813002118_psg_codestral:latest.py\", line 17, in <module>\n",
      "    input_data = np.load(input_path)  # replace with actual file reading/preprocessing code if needed\n",
      "  File \"/home/wuguangh/.conda/envs/tinyml/lib/python3.10/site-packages/numpy/lib/npyio.py\", line 462, in load\n",
      "    raise ValueError(\"Cannot load file containing pickled data \"\n",
      "ValueError: Cannot load file containing pickled data when allow_pickle=False\n",
      "\n",
      "SPAN error_9e_psg_failure_signal_py_sketch_generator: Failed. Last error: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250813001918_psg_codestral:latest/tmp_20250813001918_psg_codestral:latest.py\", line 19, in <module>\n",
      "    height = input_details[0]['shape'][1]\n",
      "TypeError: string indices must be integers\n",
      "\n",
      "SPAN error_e0_psg_failure_signal_py_sketch_generator: Failed. Last error: Traceback (most recent call last):\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250813001801_psg_codestral:latest/tmp_20250813001801_psg_codestral:latest.py\", line 11, in <module>\n",
      "    with open(LABELS_PATH, 'r') as f:\n",
      "FileNotFoundError: [Errno 2] No such file or directory: '/path/to/your/labels.txt'\n",
      "\n",
      "SPAN error_e5_psg_failure_signal_py_sketch_generator: Failed. Last error: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250813001630_psg_codestral:latest/tmp_20250813001630_psg_codestral:latest.py\", line 24, in <module>\n",
      "    raw_data = [float(line) for line in f]  # Replace with actual processing code\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250813001630_psg_codestral:latest/tmp_20250813001630_psg_codestral:latest.py\", line 24, in <listcomp>\n",
      "    raw_data = [float(line) for line in f]  # Replace with actual processing code\n",
      "  File \"/home/wuguangh/.conda/envs/tinyml/lib/python3.10/codecs.py\", line 322, in decode\n",
      "    (result, consumed) = self._buffer_decode(data, self.errors, final)\n",
      "UnicodeDecodeError: 'utf-8' codec can't decode byte 0x92 in position 42: invalid start byte\n",
      "\n",
      "SPAN error_21_psg_failure_signal_py_sketch_generator: Failed. Last error: Unexpected error during generation: The output is not a valid code block. Follow the instructions in the prompt return a complete, correct Python script enclosed in a single ```python\n",
      "<generated_code>\n",
      "``` block.\n",
      "SPAN error_1c_psg_failure_signal_py_sketch_generator: Failed. Last error: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250813001338_psg_codestral:latest/tmp_20250813001338_psg_codestral:latest.py\", line 13, in <module>\n",
      "    labels = open(labels_path).read().strip().split('\\n') if labels_path else []\n",
      "FileNotFoundError: [Errno 2] No such file or directory: 'path/to/labels.txt'\n",
      "\n",
      "SPAN error_45_psg_failure_signal_py_sketch_generator: Failed. Last error: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250813001218_psg_codestral:latest/tmp_20250813001218_psg_codestral:latest.py\", line 24, in <module>\n",
      "    for filename in os.listdir(input_dir):\n",
      "NotADirectoryError: [Errno 20] Not a directory: 'data/object_detection/sheeps.mp4'\n",
      "\n",
      "SPAN error_50_psg_failure_signal_py_sketch_generator: Failed. Last error: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250813001117_psg_codestral:latest/tmp_20250813001117_psg_codestral:latest.py\", line 27, in <module>\n",
      "    input_data = preprocess_frame(frame)  # Replace this with actual function to preprocess the frame\n",
      "NameError: name 'preprocess_frame' is not defined\n",
      "\n",
      "SPAN error_04_psg_failure_signal_py_sketch_generator: Failed. Last error: Traceback (most recent call last):\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250813000906_psg_codestral:latest/tmp_20250813000906_psg_codestral:latest.py\", line 1, in <module>\n",
      "    from ai_edge_lite.interpreter import Interpreter\n",
      "ModuleNotFoundError: No module named 'ai_edge_lite'\n",
      "\n",
      "SPAN error_c3_psg_failure_signal_py_sketch_generator: Failed. Last error: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250813000742_psg_codestral:latest/tmp_20250813000742_psg_codestral:latest.py\", line 22, in <module>\n",
      "    input_shape = input_details[0]['shape']\n",
      "TypeError: string indices must be integers\n",
      "\n",
      "Successfully processed and saved trimmed data for session codestral_9eb0_psg_batch\n",
      "SPAN error_59_tpusg_failure_signal_tpu_sketch_generator: Failed. Last error: Failed to create remote directory: kex_exchange_identification: read: Connection reset by peer\n",
      "Connection reset by 193.166.128.130 port 10022\n",
      "kex_exchange_identification: Connection closed by remote host\n",
      "Connection closed by UNKNOWN port 65535\n",
      "kex_exchange_identification: Connection closed by remote host\n",
      "Connection closed by UNKNOWN port 65535\n",
      "\n",
      "SPAN error_d8_tpusg_failure_signal_tpu_sketch_generator: Failed. Last error: Traceback (most recent call last):\n",
      "  File \"script_fded092f_1755032624.py\", line 9, in <module>\n",
      "    interpreter = tf.lite.Interpreter(model_path=\"detect.tflite\")\n",
      "NameError: name 'tf' is not defined\n",
      "SPAN error_43_tpusg_failure_signal_tpu_sketch_generator: Failed. Last error: Unexpected error during generation: Generated script is not complete. Please ensure to generate a complete Python script.\n",
      "SPAN error_f3_tpusg_failure_signal_tpu_sketch_generator: Failed. Last error: Unexpected error during generation: Generated script is not complete. Please ensure to generate a complete Python script.\n",
      "SPAN error_a7_tpusg_failure_signal_tpu_sketch_generator: Failed. Last error: Unexpected error during generation: The output is not a valid code block. Follow the instructions in the prompt return a complete, correct Python script enclosed in a single ```python\n",
      "<generated_code>\n",
      "``` block.\n",
      "SPAN error_66_tpusg_failure_signal_tpu_sketch_generator: Failed. Last error: WARNING:root:From script_70982f48_1755032142.py:25: The name DetectWithImage will be deprecated. Please use detect_with_image instead.\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"script_70982f48_1755032142.py\", line 25, in <module>\n",
      "    results = engine.DetectWithImage(frame, threshold=0.1, keep_aspect_ratio=True, relative_coord=False, top_k=10)\n",
      "  File \"/home/mendel/.local/lib/python3.7/site-packages/edgetpu/utils/warning.py\", line 44, in new_func\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/mendel/.local/lib/python3.7/site-packages/edgetpu/detection/engine.py\", line 187, in DetectWithImage\n",
      "    relative_coord, resample)\n",
      "  File \"/home/mendel/.local/lib/python3.7/site-packages/edgetpu/detection/engine.py\", line 132, in detect_with_image\n",
      "    img, (width, height), resample)\n",
      "  File \"/home/mendel/.local/lib/python3.7/site-packages/edgetpu/utils/image_processing.py\", line 47, in resampling_with_original_ratio\n",
      "    required_size[0] / old_size[0],\n",
      "TypeError: 'int' object is not subscriptable\n",
      "SPAN error_5d_tpusg_failure_signal_tpu_sketch_generator: Failed. Last error: Unexpected error during generation: Generated script is not complete. Please ensure to generate a complete Python script.\n",
      "SPAN error_4b_tpusg_failure_signal_tpu_sketch_generator: Failed. Last error: Traceback (most recent call last):\n",
      "  File \"script_068464bd_1755031638.py\", line 13, in <module>\n",
      "    with open(LABELS_PATH, 'r') as f:\n",
      "FileNotFoundError: [Errno 2] No such file or directory: '/path/to/labels'\n",
      "SPAN error_62_tpusg_failure_signal_tpu_sketch_generator: Failed. Last error: Traceback (most recent call last):\n",
      "  File \"script_89c79ba2_1755031518.py\", line 14, in <module>\n",
      "    with open(labels_file, 'r') as f:\n",
      "FileNotFoundError: [Errno 2] No such file or directory: '/home/mendel/tinyml/data/coco_labels.txt'\n",
      "SPAN error_4f_tpusg_failure_signal_tpu_sketch_generator: Failed. Last error: Traceback (most recent call last):\n",
      "  File \"script_9ad91631_1755030873.py\", line 3, in <module>\n",
      "    from tensorflow.lite.python.interpreter import Interpreter\n",
      "ModuleNotFoundError: No module named 'tensorflow'\n",
      "SPAN error_b2_tpusg_failure_signal_tpu_sketch_generator: Failed. Last error: Traceback (most recent call last):\n",
      "  File \"script_ed3dae9e_1755030746.py\", line 34, in <module>\n",
      "    labels = load_labels(labels_path)\n",
      "  File \"script_ed3dae9e_1755030746.py\", line 19, in load_labels\n",
      "    with open(path, 'r') as f:\n",
      "FileNotFoundError: [Errno 2] No such file or directory: '/home/app/coco_labels.txt'\n",
      "SPAN error_f2_tpusg_failure_signal_tpu_sketch_generator: Failed. Last error: Traceback (most recent call last):\n",
      "  File \"script_956a2d08_1755030577.py\", line 8, in <module>\n",
      "    labels = open('labels.txt').read().splitlines()\n",
      "FileNotFoundError: [Errno 2] No such file or directory: 'labels.txt'\n",
      "SPAN error_4a_tpusg_failure_signal_tpu_sketch_generator: Failed. Last error: Traceback (most recent call last):\n",
      "  File \"script_0d2d9e35_1755030340.py\", line 3, in <module>\n",
      "    from tensorflow.lite.python.interpreter import Interpreter, load_delegate\n",
      "ModuleNotFoundError: No module named 'tensorflow'\n",
      "SPAN error_af_tpusg_failure_signal_tpu_sketch_generator: Failed. Last error: Unexpected error during generation: The output is not a valid code block. Follow the instructions in the prompt return a complete, correct Python script enclosed in a single ```python\n",
      "<generated_code>\n",
      "``` block.\n",
      "SPAN error_ca_tpusg_failure_signal_tpu_sketch_generator: Failed. Last error: Unexpected error during generation: Generated script is not complete. Please ensure to generate a complete Python script.\n",
      "SPAN error_c8_tpusg_failure_signal_tpu_sketch_generator: Failed. Last error: Unexpected error during generation: The output is not a valid code block. Follow the instructions in the prompt return a complete, correct Python script enclosed in a single ```python\n",
      "<generated_code>\n",
      "``` block.\n",
      "SPAN error_af_tpusg_failure_signal_tpu_sketch_generator: Failed. Last error: Error: 'labels.txt' not found.\n",
      "SPAN error_3b_tpusg_failure_signal_tpu_sketch_generator: Failed. Last error: Traceback (most recent call last):\n",
      "  File \"script_79c910ac_1755029835.py\", line 10, in <module>\n",
      "    interpreter = Interpreter(model_path='detect.tflite', experimental_delegates=[load_delegate('libedgetpu.so.1')])\n",
      "  File \"/home/mendel/tinyml_autopilot/tinyml-env/lib/python3.7/site-packages/tflite_runtime/interpreter.py\", line 351, in __init__\n",
      "    experimental_preserve_all_tensors))\n",
      "ValueError: Could not open 'detect.tflite'.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"script_79c910ac_1755029835.py\", line 12, in <module>\n",
      "    interpreter = Interpreter(model_path='detect.tflite', experimental_delegates=[load_delegate('/usr/lib/aarch64-linux-gnu/libedgentpu.so.1.0')])\n",
      "  File \"/home/mendel/tinyml_autopilot/tinyml-env/lib/python3.7/site-packages/tflite_runtime/interpreter.py\", line 160, in load_delegate\n",
      "    delegate = Delegate(library, options)\n",
      "  File \"/home/mendel/tinyml_autopilot/tinyml-env/lib/python3.7/site-packages/tflite_runtime/interpreter.py\", line 89, in __init__\n",
      "    self._library = ctypes.pydll.LoadLibrary(library)\n",
      "  File \"/usr/lib/python3.7/ctypes/__init__.py\", line 434, in LoadLibrary\n",
      "    return self._dlltype(name)\n",
      "  File \"/usr/lib/python3.7/ctypes/__init__.py\", line 356, in __init__\n",
      "    self._handle = _dlopen(self._name, mode)\n",
      "OSError: /usr/lib/aarch64-linux-gnu/libedgentpu.so.1.0: cannot open shared object file: No such file or directory\n",
      "Exception ignored in: <function Delegate.__del__ at 0xffff77975ae8>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/mendel/tinyml_autopilot/tinyml-env/lib/python3.7/site-packages/tflite_runtime/interpreter.py\", line 124, in __del__\n",
      "    if self._library is not None:\n",
      "AttributeError: 'Delegate' object has no attribute '_library'\n",
      "SPAN error_69_tpusg_failure_signal_tpu_sketch_generator: Failed. Last error: Traceback (most recent call last):\n",
      "  File \"script_a1703512_1755029572.py\", line 26, in <module>\n",
      "    image = cv2.resize(image, input_size)\n",
      "SystemError: new style getargs format but argument is not a tuple\n",
      "SPAN error_8c_tpusg_failure_signal_tpu_sketch_generator: Failed. Last error: Traceback (most recent call last):\n",
      "  File \"script_e45d4c3f_1755029451.py\", line 16, in <module>\n",
      "    height = input_details[0]['shape'][1]\n",
      "TypeError: string indices must be integers\n",
      "Successfully processed and saved trimmed data for session codestral_9eb0_tpusg_batch\n",
      "Total 0 traces skipped. They are []\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "skipped_traces = []\n",
    "\n",
    "\n",
    "def process_existing_observation(observation):\n",
    "    \"\"\"\n",
    "    Processes an existing observation dictionary by trimming unwanted keys.\n",
    "    \"\"\"\n",
    "    unwanted_observation_keys = [\n",
    "        \"completionStartTime\",\n",
    "        \"metadata\",\n",
    "        \"timeToFirstToken\",\n",
    "        \"createdAt\",\n",
    "        \"usageDetails\",\n",
    "        \"usage\",\n",
    "        \"projectId\",\n",
    "        \"unit\",\n",
    "        \"updatedAt\",\n",
    "        \"version\",\n",
    "        \"parentObservationId\",\n",
    "        \"promptId\",\n",
    "        \"promptName\",\n",
    "        \"promptVersion\",\n",
    "        \"modelId\",\n",
    "        \"inputPrice\",\n",
    "        \"outputPrice\",\n",
    "        \"totalPrice\",\n",
    "        # \"modelParameters\",\n",
    "        \"input\",\n",
    "        \"output\",\n",
    "    ]\n",
    "\n",
    "    # If observation is a dictionary containing observation data\n",
    "    if isinstance(observation, dict):\n",
    "        trimmed_observation = {\n",
    "            k: v for k, v in observation.items() if k not in unwanted_observation_keys\n",
    "        }\n",
    "        return trimmed_observation\n",
    "    return observation\n",
    "\n",
    "\n",
    "def trim_data(data):\n",
    "    \"\"\"\n",
    "    Recursively trims the data structure.\n",
    "    \"\"\"\n",
    "\n",
    "    if isinstance(data, dict):\n",
    "        # Process the current dictionary\n",
    "        unwanted_trace_keys = [\n",
    "            \"release\",\n",
    "            \"version\",\n",
    "            \"user_id\",\n",
    "            \"public\",\n",
    "            \"html_path\",\n",
    "            \"scores\",\n",
    "            \"bookmarked\",\n",
    "            \"projectId\",\n",
    "            \"externalId\",\n",
    "            \"page\",\n",
    "            \"limit\",\n",
    "            \"total_pages\",\n",
    "        ]\n",
    "\n",
    "        # If this is a trace that contains observations, check for fatal errors\n",
    "        if \"observations\" in data:\n",
    "            # Check for SPAN observations with fatal errors before processing\n",
    "            skip_trace = False\n",
    "            for obs in data[\"observations\"]:\n",
    "                if isinstance(obs, dict) and obs.get(\"name\").startswith(\"error\"):\n",
    "                    status_message = obs.get(\"statusMessage\", \"\")\n",
    "                    ob_name = obs.get(\"name\")\n",
    "                    print(f\"SPAN {ob_name}: {status_message}\")\n",
    "\n",
    "                    if \"Fatal error\" in status_message:\n",
    "                        print(f\"Found Fatal error in SPAN observation, skipping trace\")\n",
    "                        skip_trace = True\n",
    "                        skipped_traces.append(data[\"name\"])\n",
    "                        break\n",
    "\n",
    "            if skip_trace:\n",
    "                return None  # Signal to skip this trace\n",
    "\n",
    "        # Create a new dictionary with wanted keys and recursively process values\n",
    "        trimmed_data = {}\n",
    "        for key, value in data.items():\n",
    "            if key not in unwanted_trace_keys:\n",
    "                if key == \"observations\":\n",
    "                    # Special handling for observations\n",
    "                    trimmed_data[key] = [\n",
    "                        process_existing_observation(obs) for obs in value\n",
    "                    ]\n",
    "                elif isinstance(value, (dict, list)):\n",
    "                    # Recursively process nested structures\n",
    "                    trimmed_data[key] = trim_data(value)\n",
    "                else:\n",
    "                    trimmed_data[key] = value\n",
    "\n",
    "        return trimmed_data\n",
    "\n",
    "    elif isinstance(data, list):\n",
    "        # Recursively process each item in the list\n",
    "        processed_items = []\n",
    "        for item in data:\n",
    "            processed_item = trim_data(item)\n",
    "            if processed_item is not None:  # Only add items that weren't filtered out\n",
    "                processed_items.append(processed_item)\n",
    "        return processed_items\n",
    "\n",
    "    else:\n",
    "        # Return non-dict, non-list values as is\n",
    "        return data\n",
    "\n",
    "\n",
    "def read_and_trim_data(session_id_list, raw_export_dir, trimmed_export_dir):\n",
    "    \"\"\"\n",
    "    Reads complete data from JSON files, trims the data, and saves the trimmed data to new JSON files.\n",
    "    \"\"\"\n",
    "    os.makedirs(trimmed_export_dir, exist_ok=True)\n",
    "\n",
    "    for session_id in session_id_list:\n",
    "        try:\n",
    "            if session_id.startswith(\"da0a\"):\n",
    "                session_id = \"phi4_\" + session_id\n",
    "            # Read raw data\n",
    "            if \"tpsg\" in session_id:\n",
    "                session_id_ = session_id.replace(\"tpsg\", \"tpusg\")\n",
    "            else:\n",
    "                session_id_ = session_id\n",
    "            raw_path = os.path.join(raw_export_dir, f\"raw_{session_id_}.json\")\n",
    "            with open(raw_path, \"r\") as f:\n",
    "                data = json.load(f)\n",
    "\n",
    "            # Process and trim the data\n",
    "            trimmed_data = trim_data(data)\n",
    "\n",
    "            # If the entire data was filtered out (unlikely but possible)\n",
    "            if trimmed_data is None:\n",
    "                print(\n",
    "                    f\"All traces in session {session_id} were filtered due to fatal errors\"\n",
    "                )\n",
    "                continue\n",
    "\n",
    "            # Save trimmed data\n",
    "            if \"tpsg\" in session_id:\n",
    "                session_id_ = session_id.replace(\"tpsg\", \"tpusg\")\n",
    "            else:\n",
    "                session_id_ = session_id\n",
    "            trimmed_path = os.path.join(\n",
    "                trimmed_export_dir, f\"trimmed_{session_id_}.json\"\n",
    "            )\n",
    "            with open(trimmed_path, \"w\") as f:\n",
    "                json.dump(trimmed_data, f, indent=2)\n",
    "\n",
    "            print(\n",
    "                f\"Successfully processed and saved trimmed data for session {session_id}\"\n",
    "            )\n",
    "\n",
    "            # Optional: Verify trimming worked\n",
    "            # print(f\"Verifying trimmed data for session {session_id}...\")\n",
    "            # verify_trimming(trimmed_path)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing session {session_id}: {str(e)}\")\n",
    "\n",
    "\n",
    "def verify_trimming(trimmed_path):\n",
    "    \"\"\"\n",
    "    Verifies that the trimmed data doesn't contain unwanted keys.\n",
    "    \"\"\"\n",
    "    with open(trimmed_path, \"r\") as f:\n",
    "        trimmed_data = json.load(f)\n",
    "\n",
    "    unwanted_keys = [\n",
    "        \"release\",\n",
    "        \"version\",\n",
    "        \"user_id\",\n",
    "        \"public\",\n",
    "        \"html_path\",\n",
    "        \"scores\",\n",
    "        \"bookmarked\",\n",
    "        \"projectId\",\n",
    "        \"externalId\",\n",
    "        \"page\",\n",
    "        \"limit\",\n",
    "        \"total_pages\",\n",
    "        \"completionStartTime\",\n",
    "        \"metadata\",\n",
    "        \"usageDetails\",\n",
    "        \"timeToFirstToken\",\n",
    "        \"createdAt\",\n",
    "        \"completionTokens\",\n",
    "        \"promptTokens\",\n",
    "        \"projectId\",\n",
    "        \"unit\",\n",
    "        \"updatedAt\",\n",
    "        \"version\",\n",
    "        # \"statusMessage\",\n",
    "        \"parentObservationId\",\n",
    "        \"promptId\",\n",
    "        \"promptName\",\n",
    "        \"promptVersion\",\n",
    "        \"modelId\",\n",
    "        \"inputPrice\",\n",
    "        \"outputPrice\",\n",
    "        \"totalPrice\",\n",
    "        \"calculatedInputCost\",\n",
    "        \"calculatedOutputCost\",\n",
    "        \"calculatedTotalCost\",\n",
    "    ]\n",
    "\n",
    "    def check_keys(obj):\n",
    "        if isinstance(obj, dict):\n",
    "            for key in obj.keys():\n",
    "                if key in unwanted_keys:\n",
    "                    print(f\"Warning: Found unwanted key '{key}' in trimmed data\")\n",
    "            for value in obj.values():\n",
    "                check_keys(value)\n",
    "        elif isinstance(obj, list):\n",
    "            for item in obj:\n",
    "                check_keys(item)\n",
    "\n",
    "    check_keys(trimmed_data)\n",
    "    print(\"Verification complete\")\n",
    "\n",
    "\n",
    "# Usage example:\n",
    "read_and_trim_data(session_id_list, raw_export_dir, raw_export_dir)\n",
    "print(f\"Total {len(skipped_traces)} traces skipped. They are {skipped_traces}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Generate CSV files from JSON\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing session codestral_9eb0_psg_batch, simple id codestral_9eb0. Look for /Users/hann/Projects/reference-benchmark-tinyml_llm/data_analysis/2025/08.14/raw_export/trimmed_codestral_9eb0_psg_batch.json\n",
      "/Users/hann/Projects/reference-benchmark-tinyml_llm/data_analysis/2025/08.14/processed_data/codestral_9eb0/clean_codestral_9eb0_psg_batch.csv\n",
      "Successfully saved CSV to: /Users/hann/Projects/reference-benchmark-tinyml_llm/data_analysis/2025/08.14/processed_data/codestral_9eb0/clean_codestral_9eb0_psg_batch.csv\n",
      "Processing session codestral_9eb0_tpusg_batch, simple id codestral_9eb0. Look for /Users/hann/Projects/reference-benchmark-tinyml_llm/data_analysis/2025/08.14/raw_export/trimmed_codestral_9eb0_tpusg_batch.json\n",
      "/Users/hann/Projects/reference-benchmark-tinyml_llm/data_analysis/2025/08.14/processed_data/codestral_9eb0/clean_codestral_9eb0_tpusg_batch.csv\n",
      "Successfully saved CSV to: /Users/hann/Projects/reference-benchmark-tinyml_llm/data_analysis/2025/08.14/processed_data/codestral_9eb0/clean_codestral_9eb0_tpusg_batch.csv\n"
     ]
    }
   ],
   "source": [
    "import traceback\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from dateutil import parser\n",
    "\n",
    "\n",
    "def json_to_csv(session_id):\n",
    "    \"\"\"\n",
    "    Convert JSON trace data to CSV format with aggregated metrics.\n",
    "\n",
    "    Args:\n",
    "        session_id (str): Identifier for the session to process\n",
    "    \"\"\"\n",
    "\n",
    "    def extract_observation_details(observations, trace_id):\n",
    "        \"\"\"Extract and aggregate metrics from observations\"\"\"\n",
    "        metrics = {\n",
    "            \"status\": None,\n",
    "            \"latency\": 0,\n",
    "            \"total_tokens\": 0,\n",
    "            \"prompt_tokens\": 0,\n",
    "            \"completion_tokens\": 0,\n",
    "            \"total_cost\": 0,\n",
    "            \"input_cost\": 0,\n",
    "            \"output_cost\": 0,\n",
    "            \"parameters\": set(),\n",
    "        }\n",
    "\n",
    "        # Process GENERATION observations\n",
    "        for obs in (o for o in observations if o[\"type\"] == \"GENERATION\"):\n",
    "            metrics[\"total_tokens\"] += obs[\"totalTokens\"]\n",
    "            metrics[\"prompt_tokens\"] += obs[\"promptTokens\"]\n",
    "            metrics[\"completion_tokens\"] += obs[\"completionTokens\"]\n",
    "            metrics[\"latency\"] += obs[\"latency\"]\n",
    "            for key, value in obs[\"modelParameters\"].items():\n",
    "                metrics[\"parameters\"].add(key + \":\" + value)\n",
    "\n",
    "            # Add costs if present\n",
    "            for cost_type in [\"Total\", \"Input\", \"Output\"]:\n",
    "                key = f\"calculated{cost_type}Cost\"\n",
    "                metric_key = cost_type.lower() + \"_cost\"\n",
    "                if obs.get(key) is not None:\n",
    "                    metrics[metric_key] += obs[key]\n",
    "        if len(metrics[\"parameters\"]) == 0:\n",
    "            metrics[\"parameters\"] = \"N/A\"\n",
    "        # Process SPAN observations for status\n",
    "        status_indicators = [\n",
    "            obs[\"name\"]\n",
    "            for obs in observations\n",
    "            if obs[\"type\"] == \"SPAN\" and \"start_\" not in obs[\"name\"]\n",
    "        ]\n",
    "\n",
    "        #  if later than 2025-05-19, use status_signal_from_output\n",
    "        if datetime.now() > datetime(2025, 5, 19):\n",
    "            pass\n",
    "        else:\n",
    "            # Determine status\n",
    "            success_signals = sum(\"end_\" in name for name in status_indicators)\n",
    "            failure_signals = sum(\n",
    "                \"failure_signal\" in name for name in status_indicators\n",
    "            )\n",
    "\n",
    "            if success_signals + failure_signals > 1:\n",
    "                raise ValueError(\n",
    "                    f\"Multiple status indicators found in trace {trace_id}\"\n",
    "                )\n",
    "\n",
    "            metrics[\"status\"] = (\n",
    "                \"success\"\n",
    "                if success_signals\n",
    "                else \"failure\" if failure_signals else \"unknown\"\n",
    "            )\n",
    "\n",
    "        metrics[\"prompt_cost\"] = metrics.pop(\"input_cost\")\n",
    "        metrics[\"completion_cost\"] = metrics.pop(\"output_cost\")\n",
    "        metrics[\"latency\"] = round(metrics[\"latency\"] / 1000, 2)\n",
    "        return metrics\n",
    "\n",
    "    def cal_time(trace):\n",
    "        time_diff = datetime.fromisoformat(\n",
    "            trace[\"updatedAt\"].replace(\"Z\", \"+00:00\")\n",
    "        ) - datetime.fromisoformat(trace[\"createdAt\"].replace(\"Z\", \"+00:00\"))\n",
    "        seconds_diff = time_diff.total_seconds()\n",
    "        return seconds_diff\n",
    "\n",
    "    try:\n",
    "\n",
    "        if session_id.startswith(\"da0a\"):\n",
    "            session_id = \"phi4_\" + session_id\n",
    "        simple_session_id = session_id.rsplit(\"_\", 2)[0]\n",
    "\n",
    "        \n",
    "        # Load JSON data\n",
    "        if \"tpsg\" in session_id:\n",
    "                session_id_ = session_id.replace(\"tpsg\", \"tpusg\")\n",
    "        else:\n",
    "                session_id_ = session_id\n",
    "        trimmed_path = os.path.join(raw_export_dir, f\"trimmed_{session_id_}.json\")\n",
    "        print(\n",
    "            f\"Processing session {session_id}, simple id {simple_session_id}. Look for {trimmed_path}\"\n",
    "        )\n",
    "        with open(trimmed_path, \"r\") as file:\n",
    "            traces = json.load(file)[\"data\"]\n",
    "\n",
    "        # Process traces\n",
    "        rows = [\n",
    "            {\n",
    "                \"num_run\": trace[\"metadata\"][\"num_run\"],\n",
    "                \"name\": trace[\"name\"],\n",
    "                \"trace_id\": trace[\"id\"],\n",
    "                \"batch_id\": trace[\"session_id\"],\n",
    "                # \"latency\": cal_time(trace),\n",
    "                # \"latency\": round(trace[\"latency\"], 2),\n",
    "                **extract_observation_details(\n",
    "                    trace[\"observations\"],\n",
    "                    trace[\"id\"],\n",
    "                ),\n",
    "                \"status\": (\n",
    "                    \"failure\"\n",
    "                    if trace[\"output\"][\"status\"].lower() == \"failed\"\n",
    "                    else \"success\"\n",
    "                ),\n",
    "                \"tags\": trace[\"tags\"],\n",
    "                \"timestamp\": int(parser.isoparse(trace[\"timestamp\"]).timestamp()),\n",
    "            }\n",
    "            for trace in traces\n",
    "        ]\n",
    "        # print(rows)\n",
    "        # print(rows)\n",
    "        # Create and save DataFrame\n",
    "        df = pd.DataFrame(rows).sort_values(\"num_run\")\n",
    "\n",
    "        output_dir = os.path.join(processed_data_dir, f\"{simple_session_id}\")\n",
    "        if not os.path.exists(output_dir):\n",
    "            os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "        output_path = os.path.join(output_dir, f\"clean_{session_id_}.csv\")\n",
    "\n",
    "        print(output_path)\n",
    "        df.to_csv(output_path, index=False)\n",
    "        print(f\"Successfully saved CSV to: {output_path}\")\n",
    "\n",
    "    except FileNotFoundError as e:\n",
    "        print(\n",
    "            f\"FileNotFoundError: For session {session_id} not found. Looked for {trimmed_path}\\nError info: \\n{e}\\n\\nTraceback: {traceback.format_exc()}\"\n",
    "        )\n",
    "    except json.JSONDecodeError:\n",
    "        print(f\"Error: Invalid JSON format in input file for session {session_id}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing session {session_id}: {str(e)}\")\n",
    "\n",
    "\n",
    "# Example usage\n",
    "for session_id in session_id_list:\n",
    "    json_to_csv(session_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CSV Generation with Generation Counts\n",
    "\n",
    "This section creates CSV files similar to the langfuse_export section 3, but adds a column for the number of generation attempts used for each trace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing sessions: ['codestral_9eb0_psg_batch', 'codestral_9eb0_tpusg_batch']\n",
      "Looking for raw files in: /Users/hann/Projects/reference-benchmark-tinyml_llm/data_analysis/2025/08.14/raw_export\n",
      "Will save CSV files to: /Users/hann/Projects/reference-benchmark-tinyml_llm/data_analysis/2025/08.14/processed_data\n",
      "Processing session codestral_9eb0_psg_batch, simple id codestral_9eb0. Look for /Users/hann/Projects/reference-benchmark-tinyml_llm/data_analysis/2025/08.14/raw_export/trimmed_codestral_9eb0_psg_batch.json\n",
      "/Users/hann/Projects/reference-benchmark-tinyml_llm/data_analysis/2025/08.14/processed_data/codestral_9eb0/clean_codestral_9eb0_psg_batch.csv\n",
      "Successfully saved CSV to: /Users/hann/Projects/reference-benchmark-tinyml_llm/data_analysis/2025/08.14/processed_data/codestral_9eb0/clean_codestral_9eb0_psg_batch.csv\n",
      "Processing session codestral_9eb0_tpusg_batch, simple id codestral_9eb0. Look for /Users/hann/Projects/reference-benchmark-tinyml_llm/data_analysis/2025/08.14/raw_export/trimmed_codestral_9eb0_tpusg_batch.json\n",
      "/Users/hann/Projects/reference-benchmark-tinyml_llm/data_analysis/2025/08.14/processed_data/codestral_9eb0/clean_codestral_9eb0_tpusg_batch.csv\n",
      "Successfully saved CSV to: /Users/hann/Projects/reference-benchmark-tinyml_llm/data_analysis/2025/08.14/processed_data/codestral_9eb0/clean_codestral_9eb0_tpusg_batch.csv\n"
     ]
    }
   ],
   "source": [
    "import traceback\n",
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "from datetime import datetime\n",
    "from dateutil import parser\n",
    "\n",
    "# Setup paths - same as langfuse_export\n",
    "parent_dir = os.path.dirname(os.getcwd())\n",
    "raw_export_dir = os.path.join(parent_dir, \"raw_export\")\n",
    "processed_data_dir = os.path.join(parent_dir, \"processed_data\")\n",
    "\n",
    "\n",
    "# Get session id list from data directory\n",
    "session_id_list = []\n",
    "\n",
    "for root, dirs, files in os.walk(raw_export_dir):\n",
    "    for file in files:\n",
    "        file_path = os.path.join(root, file)\n",
    "        if \"trimmed_\" in file_path:\n",
    "            session_id = file_path.split('trimmed_')[1].rstrip('.json')\n",
    "            session_id_list.append(session_id)\n",
    "\n",
    "print(f\"Processing sessions: {session_id_list}\")\n",
    "print(f\"Looking for raw files in: {raw_export_dir}\")\n",
    "print(f\"Will save CSV files to: {processed_data_dir}\")\n",
    "\n",
    "\n",
    "def json_to_csv_weighted(session_id):\n",
    "    \"\"\"\n",
    "    Convert JSON trace data to CSV format with aggregated metrics.\n",
    "    Upgraded version that includes generation_count column.\n",
    "\n",
    "    Args:\n",
    "        session_id (str): Identifier for the session to process\n",
    "    \"\"\"\n",
    "\n",
    "    def extract_observation_details(observations, trace_id):\n",
    "        \"\"\"Extract and aggregate metrics from observations\"\"\"\n",
    "        metrics = {\n",
    "            \"status\": None,\n",
    "            \"latency\": 0,\n",
    "            \"total_tokens\": 0,\n",
    "            \"prompt_tokens\": 0,\n",
    "            \"completion_tokens\": 0,\n",
    "            \"total_cost\": 0,\n",
    "            \"input_cost\": 0,\n",
    "            \"output_cost\": 0,\n",
    "            \"parameters\": set(),\n",
    "            \"generation_count\": 0,  # New field for generation count\n",
    "        }\n",
    "\n",
    "        # Count generations and process GENERATION observations\n",
    "        for obs in (o for o in observations if o[\"type\"] == \"GENERATION\"):\n",
    "            metrics[\"generation_count\"] += 1\n",
    "            metrics[\"total_tokens\"] += obs[\"totalTokens\"]\n",
    "            metrics[\"prompt_tokens\"] += obs[\"promptTokens\"]\n",
    "            metrics[\"completion_tokens\"] += obs[\"completionTokens\"]\n",
    "            metrics[\"latency\"] += obs[\"latency\"]\n",
    "            for key, value in obs[\"modelParameters\"].items():\n",
    "                metrics[\"parameters\"].add(key + \":\" + value)\n",
    "\n",
    "            # Add costs if present\n",
    "            for cost_type in [\"Total\", \"Input\", \"Output\"]:\n",
    "                key = f\"calculated{cost_type}Cost\"\n",
    "                metric_key = cost_type.lower() + \"_cost\"\n",
    "                if obs.get(key) is not None:\n",
    "                    metrics[metric_key] += obs[key]\n",
    "                    \n",
    "        if len(metrics[\"parameters\"]) == 0:\n",
    "            metrics[\"parameters\"] = \"N/A\"\n",
    "            \n",
    "        # Process SPAN observations for status\n",
    "        status_indicators = [\n",
    "            obs[\"name\"]\n",
    "            for obs in observations\n",
    "            if obs[\"type\"] == \"SPAN\" and \"start_\" not in obs[\"name\"]\n",
    "        ]\n",
    "\n",
    "        #  if later than 2025-05-19, use status_signal_from_output\n",
    "        if datetime.now() > datetime(2025, 5, 19):\n",
    "            pass\n",
    "        else:\n",
    "            # Determine status\n",
    "            success_signals = sum(\"end_\" in name for name in status_indicators)\n",
    "            failure_signals = sum(\n",
    "                \"failure_signal\" in name for name in status_indicators\n",
    "            )\n",
    "\n",
    "            if success_signals + failure_signals > 1:\n",
    "                raise ValueError(\n",
    "                    f\"Multiple status indicators found in trace {trace_id}\"\n",
    "                )\n",
    "\n",
    "            metrics[\"status\"] = (\n",
    "                \"success\"\n",
    "                if success_signals\n",
    "                else \"failure\" if failure_signals else \"unknown\"\n",
    "            )\n",
    "\n",
    "        metrics[\"prompt_cost\"] = metrics.pop(\"input_cost\")\n",
    "        metrics[\"completion_cost\"] = metrics.pop(\"output_cost\")\n",
    "        metrics[\"latency\"] = round(metrics[\"latency\"] / 1000, 2)\n",
    "        return metrics\n",
    "\n",
    "    def cal_time(trace):\n",
    "        time_diff = datetime.fromisoformat(\n",
    "            trace[\"updatedAt\"].replace(\"Z\", \"+00:00\")\n",
    "        ) - datetime.fromisoformat(trace[\"createdAt\"].replace(\"Z\", \"+00:00\"))\n",
    "        seconds_diff = time_diff.total_seconds()\n",
    "        return seconds_diff\n",
    "\n",
    "    try:\n",
    "        if session_id.startswith(\"da0a\"):\n",
    "            session_id = \"phi4_\" + session_id\n",
    "        simple_session_id = session_id.rsplit(\"_\", 2)[0]\n",
    "\n",
    "        # Load JSON data\n",
    "        if \"tpsg\" in session_id:\n",
    "            session_id_ = session_id.replace(\"tpsg\", \"tpusg\")\n",
    "        else:\n",
    "            session_id_ = session_id\n",
    "        trimmed_path = os.path.join(raw_export_dir, f\"trimmed_{session_id_}.json\")\n",
    "        print(\n",
    "            f\"Processing session {session_id}, simple id {simple_session_id}. Look for {trimmed_path}\"\n",
    "        )\n",
    "        with open(trimmed_path, \"r\") as file:\n",
    "            traces = json.load(file)[\"data\"]\n",
    "\n",
    "        # Process traces\n",
    "        rows = [\n",
    "            {\n",
    "                \"num_run\": trace[\"metadata\"][\"num_run\"],\n",
    "                \"name\": trace[\"name\"],\n",
    "                \"trace_id\": trace[\"id\"],\n",
    "                \"batch_id\": trace[\"session_id\"],\n",
    "                # \"latency\": cal_time(trace),\n",
    "                # \"latency\": round(trace[\"latency\"], 2),\n",
    "                **extract_observation_details(\n",
    "                    trace[\"observations\"],\n",
    "                    trace[\"id\"],\n",
    "                ),\n",
    "                \"status\": (\n",
    "                    \"failure\"\n",
    "                    if trace[\"output\"][\"status\"].lower() == \"failed\"\n",
    "                    else \"success\"\n",
    "                ),\n",
    "                \"tags\": trace[\"tags\"],\n",
    "                \"timestamp\": int(parser.isoparse(trace[\"timestamp\"]).timestamp()),\n",
    "            }\n",
    "            for trace in traces\n",
    "        ]\n",
    "        \n",
    "        # Create and save DataFrame\n",
    "        df = pd.DataFrame(rows).sort_values(\"num_run\")\n",
    "\n",
    "        output_dir = os.path.join(processed_data_dir, f\"{simple_session_id}\")\n",
    "        if not os.path.exists(output_dir):\n",
    "            os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "        output_path = os.path.join(output_dir, f\"clean_{session_id_}.csv\")\n",
    "\n",
    "        print(output_path)\n",
    "        df.to_csv(output_path, index=False)\n",
    "        print(f\"Successfully saved CSV to: {output_path}\")\n",
    "\n",
    "    except FileNotFoundError as e:\n",
    "        print(\n",
    "            f\"FileNotFoundError: For session {session_id} not found. Looked for {trimmed_path}\\nError info: \\n{e}\\n\\nTraceback: {traceback.format_exc()}\"\n",
    "        )\n",
    "    except json.JSONDecodeError:\n",
    "        print(f\"Error: Invalid JSON format in input file for session {session_id}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing session {session_id}: {str(e)}\")\n",
    "\n",
    "\n",
    "\n",
    "# Example usage\n",
    "for session_id in session_id_list:\n",
    "    json_to_csv_weighted(session_id)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datasci2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

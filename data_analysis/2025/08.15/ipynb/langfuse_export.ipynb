{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setting up\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ref: https://langfuse.com/docs/query-traces\n",
    "import os\n",
    "import json\n",
    "from langfuse import Langfuse\n",
    "import json\n",
    "import os\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "LOCAL_HOST = True\n",
    "\n",
    "\"\"\"Define session_id\"\"\"\n",
    "# session_id=\"qwen2.5-coder_f4d4_dp_batch\"\n",
    "session_id_list = [\n",
    "    # \"qwen2.5-coder:32b_4e11_tpsg_batch\",\n",
    "    # \"qwen2.5-coder:32b_ae24_tpsg_batch\"\n",
    "    \"codestral_e6d3_tpusg_batch\",\n",
    "    \"codestral_e6d3_psg_batch\"\n",
    "]\n",
    "\n",
    "\n",
    "\"\"\"Define paths\"\"\"\n",
    " \n",
    "parent_dir = os.path.dirname(os.getcwd())\n",
    "\n",
    " \n",
    "# date = os.path.basename(parent_dir)\n",
    "tex_dir = os.path.join(parent_dir, \"tex\")\n",
    "processed_data_dir = os.path.join(parent_dir, \"processed_data\")\n",
    "raw_export_dir = os.path.join(parent_dir, \"raw_export\")\n",
    "ipynb_dir = os.path.join(parent_dir, \"ipynb\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Export raw data\n",
    "\n",
    "Langfuse added a limit of 20 API invocations per minute. https://langfuse.com/faq/all/api-limits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching traces for session codestral_e6d3_tpusg_batch...\n",
      "Fetching observation data for time-03-08-04-477811_chatcmpl-6f46a4c0-3eb4-4cb7-a6a0-9015b8dce38f...\n",
      "Fetching observation data for time-03-08-31-401843_chatcmpl-a17572e9-9c98-4771-8062-4d6b0dcc1d6d...\n",
      "Fetching observation data for time-03-08-55-981491_chatcmpl-b91841d3-6116-4697-92dc-d6263d61a24b...\n",
      "Fetching observation data for time-03-05-49-854001_chatcmpl-349d4d2f-4ca1-4fab-a5a9-396d710afdc5...\n",
      "Fetching observation data for time-03-06-17-125456_chatcmpl-f9a0f0f1-b4a8-4d39-9217-fd1202265709...\n",
      "Fetching observation data for time-03-06-46-645764_chatcmpl-351049fe-764d-4c05-94c8-8f5c951da718...\n",
      "Fetching observation data for time-03-03-19-160140_chatcmpl-e796e460-dd8f-4205-9867-f47d04486e8c...\n",
      "Fetching observation data for time-03-03-46-134638_chatcmpl-80c15b2c-7f40-4c61-bac9-c2b548128ffb...\n",
      "Fetching observation data for time-03-04-10-981141_chatcmpl-62de8e30-7179-4105-9e39-9f27a512eda9...\n",
      "Fetching observation data for time-03-04-36-418563_chatcmpl-ef338135-5fe1-4ff3-9236-63ab375a8e92...\n",
      "Fetching observation data for time-03-02-18-716835_chatcmpl-7ad3d47f-368b-4883-b7c7-ca6589f4d753...\n",
      "Fetching observation data for time-03-02-45-862775_chatcmpl-00aca84b-9b75-4a1d-b284-c837ed0b8264...\n",
      "Fetching observation data for time-03-02-50-522665_chatcmpl-0079d9e8-e0e6-4b46-a3b8-255d714f383b...\n",
      "Fetching observation data for time-03-02-57-709961_chatcmpl-4e6d6e92-e804-4b40-86c6-e4384347b514...\n",
      "Fetching observation data for time-03-03-04-922157_chatcmpl-51ad9054-86e8-4a53-9516-26a14499a2da...\n",
      "Fetching observation data for 91911a59-f720-4a07-ae96-5775406cf5aa...\n",
      "Fetching observation data for time-03-00-22-072750_chatcmpl-aba5d9f5-448e-4b4d-9a6f-8a851c8bdf38...\n",
      "Fetching observation data for time-03-00-49-043550_chatcmpl-8c737830-e716-405e-a8da-b2c8faa1dafb...\n",
      "Fetching observation data for time-03-01-09-049694_chatcmpl-eca7881e-1ea5-48da-99b0-b53f446507eb...\n",
      "Fetching observation data for time-03-01-30-656683_chatcmpl-c342bf6b-44dc-4bb7-baa1-4afcf2bea002...\n",
      "Fetching observation data for time-03-01-50-532480_chatcmpl-02ddef21-19ea-4e64-b895-9728b4d88441...\n",
      "Fetching observation data for 6e36eaaf-ffb1-4b2b-87e8-c7a187345a10...\n",
      "Fetching observation data for time-02-58-31-349572_chatcmpl-9c644804-f2f9-45c5-a260-e706346f56fb...\n",
      "Fetching observation data for time-02-58-58-351668_chatcmpl-b7582fdf-6cbe-4798-9461-d0d88241e93a...\n",
      "Fetching observation data for time-02-59-03-021304_chatcmpl-b12fccc7-491f-44d6-83ac-21f4e56a2e98...\n",
      "Fetching observation data for time-02-59-26-883666_chatcmpl-b9e48499-d8e7-456b-b026-1ee20f65d445...\n",
      "Fetching observation data for time-02-59-50-825786_chatcmpl-e4804f42-657d-41e7-a7d4-e3e5e8a14f4d...\n",
      "Fetching observation data for be3a850f-c069-40a7-b3d8-8614d6ff61b2...\n",
      "Fetching observation data for time-02-57-32-799962_chatcmpl-4da3e269-aeb4-4d69-8268-288c6c233b3e...\n",
      "Fetching observation data for time-02-57-59-653162_chatcmpl-d4dbdb96-0e42-490c-ad3c-dc16fbb6a20d...\n",
      "Fetching observation data for time-02-58-03-262975_chatcmpl-bcb9e980-6121-4dd0-b48c-b2a7bdaa9f3f...\n",
      "Fetching observation data for time-02-58-10-484183_chatcmpl-24ef42f4-8ffa-46ad-9245-c36e304b4e8c...\n",
      "Fetching observation data for time-02-58-17-703865_chatcmpl-163e4552-becb-4a3a-8658-e68d8f02978e...\n",
      "Fetching observation data for 0fd9bebe-18c9-44f2-b4b1-87c078f13f4a...\n",
      "Fetching observation data for time-02-55-41-207519_chatcmpl-87614359-71d9-44b3-b33b-1555e8f7df17...\n",
      "Fetching observation data for time-02-56-08-291350_chatcmpl-95953792-3a83-4692-9e7d-83073aaeae71...\n",
      "Fetching observation data for time-02-56-29-660832_chatcmpl-750495f8-49b7-4dfe-807c-186aca609ce2...\n",
      "Fetching observation data for time-02-56-49-476594_chatcmpl-f4942f16-38cf-4a0a-bab3-870ce6080df7...\n",
      "Fetching observation data for time-02-57-11-328766_chatcmpl-1542ecd2-9069-4a45-beb2-723873153d51...\n",
      "Fetching observation data for 59b6ec62-a950-4b23-86a4-f0d1ca14dd92...\n",
      "Fetching observation data for time-02-53-17-266792_chatcmpl-363c66cc-4482-4f30-952b-b023c5965248...\n",
      "Fetching observation data for time-02-53-44-266342_chatcmpl-9d2825e3-eab4-499b-ae82-d0c5c1b5f091...\n",
      "Fetching observation data for time-02-54-13-339497_chatcmpl-ceb8da64-5637-4c98-9152-63210ab1deae...\n",
      "Fetching observation data for time-02-54-41-981602_chatcmpl-5c27d4ea-6e7e-45ae-8964-5ea8e1518ee2...\n",
      "Fetching observation data for time-02-55-11-700203_chatcmpl-17d94e82-64a1-4518-9ca1-3b61ee8fa887...\n",
      "Fetching observation data for c2778c32-e53b-4ef1-96f9-0c6ae2cfd84d...\n",
      "Fetching observation data for time-02-51-13-328193_chatcmpl-1e71770e-196f-4b43-aeee-b3f4d1e8e5fa...\n",
      "Fetching observation data for time-02-51-40-159215_chatcmpl-fa90d2a7-756e-4ac8-be0e-5d472a312d82...\n",
      "Fetching observation data for time-02-52-03-923636_chatcmpl-8f22fea6-8e2e-425f-86fa-e2ed36f5621d...\n",
      "Fetching observation data for time-02-49-14-505590_chatcmpl-b39998af-0eb0-4007-a866-8ac80ba2f6c1...\n",
      "Fetching observation data for time-02-49-41-562040_chatcmpl-b5983f40-e703-4639-95d7-aa52099d9217...\n",
      "Fetching observation data for time-02-49-46-819307_chatcmpl-ad04e4f2-aa33-4f5f-804d-f486bc250648...\n",
      "Fetching observation data for time-02-50-13-459814_chatcmpl-0d78038b-0be5-4d9b-a2d1-d5833d4a17bc...\n",
      "Fetching observation data for time-02-50-39-497856_chatcmpl-24bd0966-8adc-449e-b041-f50f4fe6612f...\n",
      "Fetching observation data for 654b4c0c-bd5f-4f7d-b235-2a0669309f93...\n",
      "Fetching observation data for time-02-46-49-461788_chatcmpl-56f7ca26-b54b-4aa8-821a-aeb99f70901e...\n",
      "Fetching observation data for time-02-47-16-431524_chatcmpl-b733219c-4af1-4058-a48a-262cf4b11e1e...\n",
      "Fetching observation data for time-02-47-37-325763_chatcmpl-7c54d2be-2295-4b81-a9e1-11e9b60c4372...\n",
      "Fetching observation data for time-02-48-02-665997_chatcmpl-c41d979d-5198-415e-bdf9-694056dc0681...\n",
      "Fetching observation data for time-02-44-55-864665_chatcmpl-9ae03a55-eb00-4691-838a-b9157fa4b28b...\n",
      "Fetching observation data for time-02-45-22-883823_chatcmpl-45aff62c-cddb-4707-b96d-969997b2791a...\n",
      "Fetching observation data for time-02-45-25-663312_chatcmpl-3b7f1507-d2cc-40e6-9db3-d55ea573e5c8...\n",
      "Fetching observation data for time-02-45-52-845680_chatcmpl-8aabe0d3-781d-4b5a-b8ed-076e5ad94dcb...\n",
      "Fetching observation data for time-02-46-17-144540_chatcmpl-3dc13376-4231-4965-8f8f-0f435c26cd4c...\n",
      "Fetching observation data for c3ada599-ad23-47b8-a88e-ec74d2b8649d...\n",
      "Fetching observation data for time-02-43-12-952171_chatcmpl-f0e84a2a-a1f9-43a2-94ea-a1dc4120e119...\n",
      "Fetching observation data for time-02-43-39-876448_chatcmpl-ff6ed085-0574-45b8-9106-d161db81c0db...\n",
      "Fetching observation data for time-02-43-44-527410_chatcmpl-26f77fe9-6805-4912-9344-86fdcc8f1ac7...\n",
      "Fetching observation data for time-02-44-07-570941_chatcmpl-016a58f6-7bc0-4680-8e7d-995c25e1bb83...\n",
      "Fetching observation data for time-02-44-28-878660_chatcmpl-cac7f546-2a8f-4a24-8169-d58e96303e1a...\n",
      "Fetching observation data for 5df73b06-6286-4048-b1db-ce7fceeb7ec2...\n",
      "Fetching observation data for time-02-41-27-283533_chatcmpl-f8b98155-0ce8-4b9f-8968-1ae5eb74eda1...\n",
      "Fetching observation data for time-02-41-54-635370_chatcmpl-7d6643a8-2bb6-4455-9862-bb5313aaf940...\n",
      "Fetching observation data for time-02-42-02-593493_chatcmpl-86aa6e93-150f-4bea-b0c6-0ddad890961e...\n",
      "Fetching observation data for time-02-42-32-419507_chatcmpl-b6cac18b-d7e5-46e3-95bd-1badcb5222aa...\n",
      "Fetching observation data for time-02-43-01-521266_chatcmpl-c2c592f7-a40f-45d8-a73d-24223b74e059...\n",
      "Fetching observation data for 6a52b469-e695-49b2-b667-2e68f0e4a4d8...\n",
      "Fetching observation data for time-02-39-53-715061_chatcmpl-2fe64d5f-b16d-40b3-b46b-a1b0d63565d0...\n",
      "Fetching observation data for time-02-40-20-525605_chatcmpl-ad2c8d84-907b-4060-ac51-7b0aa20201f8...\n",
      "Fetching observation data for time-02-40-24-506755_chatcmpl-a2e50768-f8b4-436d-bda4-97afd26adc6c...\n",
      "Fetching observation data for time-02-40-46-796778_chatcmpl-f44c8de5-ff02-4bd6-9d34-889ff7b470b2...\n",
      "Fetching observation data for time-02-41-13-592463_chatcmpl-b4338e8a-a5af-497e-9ecd-afa5f136c647...\n",
      "Fetching observation data for d60574d9-f4a6-48aa-82d7-82952c083514...\n",
      "Fetching observation data for time-02-37-13-131362_chatcmpl-22e434be-7865-4d1a-b923-ac7a2a71afcf...\n",
      "Fetching observation data for time-02-37-39-858567_chatcmpl-c6d8889b-0223-48fb-8482-e1618f64f506...\n",
      "Fetching observation data for time-02-38-12-546563_chatcmpl-1099f834-d5e5-4831-8cd1-22d646ce5722...\n",
      "Fetching observation data for time-02-38-36-674762_chatcmpl-6ddda447-57ed-4ca6-aad6-dc8c628a751a...\n",
      "Fetching observation data for time-02-36-20-459924_chatcmpl-5810102f-40ec-43db-ad05-cd365a6d751d...\n",
      "Fetching observation data for time-02-36-47-430538_chatcmpl-4b8ad7cd-30fc-4195-9fd9-a4ecc3e5a325...\n",
      "Fetching observation data for time-02-36-52-181308_chatcmpl-96993ca9-f222-41d7-aa8c-77f76f062f29...\n",
      "Fetching observation data for time-02-36-56-933395_chatcmpl-d0572c5c-9d6c-4070-b815-41668392e6d1...\n",
      "Fetching observation data for time-02-37-01-685194_chatcmpl-abf6d70c-2b85-469e-b458-04edbd938902...\n",
      "Fetching observation data for 0be0116d-9687-4b91-9f28-751cafa212bf...\n",
      "Fetching observation data for time-02-34-03-050050_chatcmpl-6fd002c4-ac28-4dbd-883c-b13d28e71c63...\n",
      "Fetching observation data for time-02-34-29-854734_chatcmpl-94e889ec-f9b6-4500-98b3-64206355b8fc...\n",
      "Fetching observation data for time-02-34-58-737521_chatcmpl-d2420586-6a26-4193-b67a-1509d1d9d090...\n",
      "Fetching observation data for time-02-32-22-415799_chatcmpl-0de8cb25-ee3f-41b0-9efa-7c3654aaddbd...\n",
      "Fetching observation data for time-02-32-49-382630_chatcmpl-7c9f4e5c-488d-4e0b-bce7-ead6355dc037...\n",
      "Fetching observation data for time-02-32-53-151777_chatcmpl-186672ae-c56d-4830-b2b6-a2b52c3ec7e8...\n",
      "Fetching observation data for time-02-33-13-730537_chatcmpl-a454eabb-7435-4b07-af74-1a9f9e655b70...\n",
      "Fetching observation data for time-02-33-35-939744_chatcmpl-d539c03e-e1a2-4284-b87e-b358a67fd288...\n",
      "Fetching observation data for time-02-30-22-274104_chatcmpl-5a6e6856-4d1c-4e47-b71a-0e7666a97038...\n",
      "Fetching observation data for time-02-30-49-286630_chatcmpl-9dcac2a7-9276-45b4-b92d-472c2671e2b0...\n",
      "Fetching observation data for time-02-30-54-545452_chatcmpl-1f2ce5fc-c5cb-434b-8f39-c49d17051eed...\n",
      "Fetching observation data for time-02-31-25-653974_chatcmpl-df352115-814d-4321-9b50-19ff685d6d68...\n",
      "Fetching observation data for time-02-31-55-212869_chatcmpl-bc3320bf-63f3-4622-bba7-8a6d20b05bcc...\n",
      "Fetching observation data for 0ba5d894-5a87-4ca0-832a-f03974f4e5ae...\n",
      "Fetching observation data for time-02-28-40-717300_chatcmpl-1c407faa-0eba-4d8b-812e-a32b544bd748...\n",
      "Fetching observation data for time-02-29-07-994733_chatcmpl-6a8f3b73-8112-41d3-bc8c-84ed122a9b3b...\n",
      "Fetching observation data for time-02-29-37-192187_chatcmpl-45103aff-134f-4b92-a4dd-f5f0ec5d28ac...\n",
      "Fetching observation data for time-02-30-06-866925_chatcmpl-1c5ae1b9-9bfe-40ba-8270-807e2e31b442...\n",
      "Fetching observation data for time-02-30-10-437324_chatcmpl-05458a28-7b9d-4d55-8cf7-2995ffabc485...\n",
      "Fetching observation data for fd610cb8-5e4a-4ac3-af37-30192cab97b2...\n",
      "Fetching observation data for time-02-26-37-140369_chatcmpl-d890cbf0-afda-4ee1-b9de-72cfef6bc0b8...\n",
      "Fetching observation data for time-02-27-04-016125_chatcmpl-3ef2575c-62ab-4ae1-8bb6-7694144393c0...\n",
      "Fetching observation data for time-02-27-23-614082_chatcmpl-ba36d764-26af-4fc5-93cc-66215470e40a...\n",
      "Fetching observation data for time-02-27-47-700537_chatcmpl-916f3502-854a-4825-bb6a-dd3f41d74ebb...\n",
      "Fetching observation data for time-02-28-09-933061_chatcmpl-0791d7f1-b452-4368-8d9c-3ef56df9da48...\n",
      "Fetching observation data for 039ff544-b346-445f-a984-c06e22e32d43...\n",
      "Fetching observation data for time-02-24-32-891942_chatcmpl-5fe927aa-c363-4092-a1d9-19615f8c3510...\n",
      "Fetching observation data for time-02-24-59-615257_chatcmpl-343be046-40b0-4d4b-8636-9bcd8fbecdb3...\n",
      "Fetching observation data for time-02-25-07-586519_chatcmpl-5ac68f42-ba7f-4d93-8bc6-b8a1982aceb8...\n",
      "Fetching observation data for time-02-25-36-390933_chatcmpl-ab2929a8-992e-4505-b2ab-b0b5f2505e65...\n",
      "Fetching observation data for time-02-26-05-287263_chatcmpl-ca06db7e-2e6c-4f7a-904a-cc3dfc868a75...\n",
      "Fetching observation data for f4152c95-d106-49e6-8444-b6af1ec73c7c...\n",
      "Fetching observation data for time-02-22-22-981912_chatcmpl-32dc4507-e92d-497a-a39e-a32a7f737d67...\n",
      "Fetching observation data for time-02-22-49-916834_chatcmpl-df174ccc-da24-4c1a-b7c5-02549ef40c40...\n",
      "Fetching observation data for time-02-23-11-069900_chatcmpl-350a4578-09a7-4cb9-8bae-7485651549b1...\n",
      "Fetching observation data for time-02-23-36-868040_chatcmpl-b5425004-8eeb-4a7c-8a87-fec3db1f14ef...\n",
      "Fetching observation data for time-02-24-01-807367_chatcmpl-648f1b46-48cb-4c6d-84ff-4ce5bd94c2c6...\n",
      "Fetching observation data for 6272c95c-75e2-42ed-ae39-7410ae930c91...\n",
      "Fetching observation data for time-02-20-32-981752_chatcmpl-3a53a6bb-c047-40d9-9e52-eb96c6288406...\n",
      "Fetching observation data for time-02-21-00-021464_chatcmpl-97d79836-ee43-4b29-a6d2-9709296dac66...\n",
      "Fetching observation data for time-02-21-25-174628_chatcmpl-e77fea72-27a6-45a0-9ddb-c49d4b9601c5...\n",
      "Fetching observation data for time-02-21-49-084257_chatcmpl-6d823590-0d88-4626-bd5e-3fa28b823dc5...\n",
      "Fetching observation data for time-02-22-12-121976_chatcmpl-e883ca6f-e73b-4060-87e9-b76190351b13...\n",
      "Fetching observation data for e5801c98-af82-4dc2-ac59-077665e4da96...\n",
      "Fetching observation data for time-02-19-32-437557_chatcmpl-f120c539-d5a1-4d67-8cdc-8ea292111ef6...\n",
      "Fetching observation data for time-02-19-59-851759_chatcmpl-6e805879-6030-48f7-bbe0-65d640821111...\n",
      "Fetching observation data for time-02-20-04-279486_chatcmpl-20735b26-266f-4749-bf78-1fdddf039e5f...\n",
      "Fetching observation data for time-02-20-11-491295_chatcmpl-607b262b-6981-4592-96be-73c6abe56767...\n",
      "Fetching observation data for time-02-20-18-664116_chatcmpl-47235510-dc1b-490f-897a-62927c09f5be...\n",
      "Fetching observation data for 20709411-7153-4667-ab76-f70ab8fd136f...\n",
      "Fetching observation data for time-02-17-37-850164_chatcmpl-5f3d6ee5-9b38-4c70-b120-9e96cc703dfb...\n",
      "Fetching observation data for time-02-18-05-042611_chatcmpl-8f3af995-3cb9-431a-87b9-c2b8d11fbe95...\n",
      "Fetching observation data for time-02-18-25-985478_chatcmpl-159fa412-5fd4-4839-a818-19697bb66cfa...\n",
      "Fetching observation data for time-02-18-31-653600_chatcmpl-439f5830-93eb-4ee2-a4ce-70ecf42093ac...\n",
      "Fetching observation data for time-02-18-59-410166_chatcmpl-c45b7b9e-afbe-4157-87be-2bff39d0b3d5...\n",
      "Fetching observation data for 71cffba1-bb6d-42c6-b1a6-725aaf1ad689...\n",
      "Fetching observation data for time-02-16-38-326124_chatcmpl-b0cfe2fe-dfa3-4160-a02f-8e0c80fa6936...\n",
      "Fetching observation data for time-02-17-05-442642_chatcmpl-56ce7796-c95b-4229-aaea-e34c17d6ce6f...\n",
      "Fetching observation data for time-02-17-09-911147_chatcmpl-cca24d75-9acb-4b04-86b3-b42d6554936b...\n",
      "Fetching observation data for time-02-17-17-094519_chatcmpl-f717eace-72c0-4724-85a3-032718bf8b54...\n",
      "Fetching observation data for time-02-17-24-283831_chatcmpl-54daa9f7-aa25-42aa-a0f7-57f8117f0f69...\n",
      "Fetching observation data for ba3c136b-f3d6-4794-a58a-0bed37c40987...\n",
      "Fetching observation data for time-02-14-34-720361_chatcmpl-b92561eb-585b-46b2-bdd3-e946575fb3be...\n",
      "Fetching observation data for time-02-15-21-183621_chatcmpl-a57345cc-0984-423a-81e8-2864867624c1...\n",
      "Fetching observation data for time-02-15-42-234754_chatcmpl-7e23efd9-6014-492a-89fb-3f1a16233bde...\n",
      "Fetching observation data for time-02-16-03-981778_chatcmpl-8efa0a1c-ef86-40f4-a4e4-493dd903cc4f...\n",
      "Fetching observation data for time-02-16-26-410894_chatcmpl-0922c37c-e791-45d3-a368-6fcfe350cc3e...\n",
      "Fetching observation data for 66a0ac8d-4ee1-4275-abed-417eac594e7c...\n",
      "Raw JSON saved to: /Users/hann/Projects/reference-benchmark-tinyml_llm/data_analysis/2025/08.15/raw_export/raw_codestral_e6d3_tpusg_batch.json\n",
      "Fetching traces for session codestral_e6d3_psg_batch...\n",
      "Fetching observation data for time-03-45-45-867327_chatcmpl-d7b7ffbb-4d4d-4756-b0b5-547507cbc5cd...\n",
      "Fetching observation data for time-03-46-04-586685_chatcmpl-07b0dd8a-e87e-44f7-9b95-c56e62f7cc05...\n",
      "Fetching observation data for time-03-46-15-675367_chatcmpl-9708d5b3-5a35-4496-8051-683f39264fb2...\n",
      "Fetching observation data for time-03-46-27-226275_chatcmpl-f4f0792a-d116-4887-8d5d-087a44f30a18...\n",
      "Fetching observation data for time-03-46-43-661108_chatcmpl-94dc4d21-20c2-4533-957e-81e510637fcb...\n",
      "Fetching observation data for 30933fcf-27b0-4879-9b21-6e0caa7a9aa9...\n",
      "Fetching observation data for time-03-44-38-520185_chatcmpl-b44e627e-0b33-4097-b346-a6c287781797...\n",
      "Fetching observation data for time-03-44-56-662732_chatcmpl-879bb929-a4ef-4ffb-a5e9-8750dd3fc99c...\n",
      "Fetching observation data for time-03-45-07-799745_chatcmpl-7b695ff7-8a8e-488f-be18-8e7410bc8cd7...\n",
      "Fetching observation data for time-03-45-21-567558_chatcmpl-c33a180a-d1e9-42bc-a99c-affa5326288b...\n",
      "Fetching observation data for time-03-43-13-842035_chatcmpl-17f04b49-248a-4145-bf1c-5e9ea57d909e...\n",
      "Fetching observation data for time-03-43-32-540269_chatcmpl-a1245a37-3b56-4c52-acdf-21271253d5dc...\n",
      "Fetching observation data for time-03-43-44-109320_chatcmpl-0ef989ba-084d-46c1-9da1-c9af53e8b347...\n",
      "Fetching observation data for time-03-43-57-316372_chatcmpl-2cc05803-8371-46a5-ad6e-65d0377f73e4...\n",
      "Fetching observation data for time-03-44-22-919397_chatcmpl-8aed3177-a6e5-44ee-bbf2-384ad9d37687...\n",
      "Fetching observation data for cd31a037-9363-4415-8a96-21e138eae4d1...\n",
      "Fetching observation data for time-03-41-56-702070_chatcmpl-7264e6db-165a-4de8-8298-5eec206b70a9...\n",
      "Fetching observation data for time-03-42-14-845688_chatcmpl-d771e876-4ec0-428a-a81c-a349217885c6...\n",
      "Fetching observation data for time-03-42-25-980561_chatcmpl-d4711fdc-acf0-4808-b639-f6b01d065fe6...\n",
      "Fetching observation data for time-03-42-43-867014_chatcmpl-34dc4841-bd0c-4872-9b12-b4f89a8de3cd...\n",
      "Fetching observation data for time-03-42-56-288725_chatcmpl-c1f3072a-59a7-4109-9cfb-4e6ff84cb093...\n",
      "Fetching observation data for 25741736-42d4-47b4-97f1-d9af2b998583...\n",
      "Fetching observation data for time-03-40-41-446811_chatcmpl-ebc2facb-c9ab-4a80-a904-36d248fe9cbb...\n",
      "Fetching observation data for time-03-41-00-185082_chatcmpl-e158eb57-7c37-4339-828d-3ad80eed71e2...\n",
      "Fetching observation data for time-03-41-11-166352_chatcmpl-ff0ccae8-67cd-44fa-976e-ef5fd64f707a...\n",
      "Fetching observation data for time-03-41-32-593063_chatcmpl-07b5ea8b-ce67-4aea-b6c3-639baa26d6f0...\n",
      "Fetching observation data for time-03-41-38-102706_chatcmpl-1c4d100d-1cb7-405f-9e07-54018685557b...\n",
      "Fetching observation data for 38c981ed-e720-4e06-afc4-e2008d5c0861...\n",
      "Fetching observation data for time-03-39-48-923633_chatcmpl-cff6b1d8-3148-4cf8-b07c-de9cf6093bdc...\n",
      "Fetching observation data for time-03-40-07-010597_chatcmpl-b8642caf-e2b5-4b57-ac08-85a48d7f1820...\n",
      "Fetching observation data for time-03-40-15-575014_chatcmpl-33ac196b-324f-4d3b-b5a4-967ebd9c3b55...\n",
      "Fetching observation data for time-03-38-39-379810_chatcmpl-3f3fa3a7-2377-49fd-9a10-9ff560bf76ba...\n",
      "Fetching observation data for time-03-38-58-087931_chatcmpl-fcd7c8e8-6ba0-4893-b562-c4149012e9c2...\n",
      "Fetching observation data for time-03-39-06-094088_chatcmpl-2f59e48d-8b53-4a19-8bde-512ef3f06515...\n",
      "Fetching observation data for time-03-39-15-542560_chatcmpl-6afda353-c866-46bd-b33c-be23553ed969...\n",
      "Fetching observation data for time-03-39-29-240729_chatcmpl-0a8d6623-a259-400c-9ef9-40ea0e0c6d77...\n",
      "Fetching observation data for 5bda8e6a-f543-42ed-869d-476514099607...\n",
      "Fetching observation data for time-03-37-08-829507_chatcmpl-b51dfb9b-b6aa-4a7f-9976-b1131d4fe23f...\n",
      "Fetching observation data for time-03-37-27-505231_chatcmpl-7414d772-065a-4de2-8f60-8095ebf71285...\n",
      "Fetching observation data for time-03-37-39-046062_chatcmpl-0178bf69-642c-419c-bec2-53a9e3fa0a90...\n",
      "Fetching observation data for time-03-37-53-528980_chatcmpl-5ae89172-931f-4e8e-a551-4b6093d130a6...\n",
      "Fetching observation data for time-03-38-15-141109_chatcmpl-27dd11c8-c804-435d-b2b0-040cad5a802c...\n",
      "Fetching observation data for cb74384d-ebb1-48f5-ae5f-ae2e06ac1ba8...\n",
      "Fetching observation data for time-03-35-54-293126_chatcmpl-32b2141c-f2d7-4987-8e12-5378f16b0805...\n",
      "Fetching observation data for time-03-36-13-014708_chatcmpl-2549848f-9b78-4925-87e4-2ed5544cdaf6...\n",
      "Fetching observation data for time-03-36-23-987814_chatcmpl-3d35148b-3977-475a-8378-b9d67aa24c42...\n",
      "Fetching observation data for time-03-36-38-314055_chatcmpl-7bc49a80-e78c-4e04-b20f-68328e8ad23d...\n",
      "Fetching observation data for time-03-36-52-920294_chatcmpl-3589e197-0dfc-4295-8c7d-3fe341374db4...\n",
      "Fetching observation data for a9f5541c-9405-4bfd-844a-386fc6307a87...\n",
      "Fetching observation data for time-03-34-38-493059_chatcmpl-fd59359e-931e-4799-974d-c970c3614e87...\n",
      "Fetching observation data for time-03-34-57-164092_chatcmpl-235ecac3-e915-4fb9-b85c-94849eae0d72...\n",
      "Fetching observation data for time-03-35-08-711412_chatcmpl-c66caf05-7508-444e-9152-459d079fc6e1...\n",
      "Fetching observation data for time-03-35-24-607088_chatcmpl-bc7a4abb-1343-488a-82b6-a31c8a86ad36...\n",
      "Fetching observation data for time-03-33-13-646188_chatcmpl-0559ba86-704f-4eca-a601-08a62f2e5a4a...\n",
      "Fetching observation data for time-03-33-32-306306_chatcmpl-8130aa67-d33c-4d50-ad36-f34f87fbda5c...\n",
      "Fetching observation data for time-03-33-43-307189_chatcmpl-1c0754c7-94a9-450e-972b-077b80ff564f...\n",
      "Fetching observation data for time-03-34-01-685097_chatcmpl-460a6c34-5455-436d-819d-ba15e428f2dd...\n",
      "Fetching observation data for time-03-34-24-735952_chatcmpl-8f061750-2fe3-4645-8991-2ea0f1b620eb...\n",
      "Fetching observation data for 4a535047-879e-45cb-8501-be17c8e4b8a8...\n",
      "Fetching observation data for time-03-32-16-098504_chatcmpl-ef9cd4b7-8bd8-4471-b7d5-d98cb3d82a78...\n",
      "Fetching observation data for time-03-32-34-799346_chatcmpl-93bd2263-d9bd-444c-ac67-3e7cae5b1d32...\n",
      "Fetching observation data for time-03-32-42-807153_chatcmpl-d37ec58b-b912-4eb7-9cd3-d54fbf07955c...\n",
      "Fetching observation data for time-03-32-50-656736_chatcmpl-300b17fe-bcd2-458e-9b6b-efc22def65ee...\n",
      "Fetching observation data for time-03-32-59-701603_chatcmpl-79d1be6b-499d-4e58-ba51-e31b6329d4ad...\n",
      "Fetching observation data for 9c4a2357-6636-4c25-b385-e139199c92ad...\n",
      "Fetching observation data for time-03-31-06-533347_chatcmpl-2c239da3-b6b9-4da5-ac97-db5f611d107f...\n",
      "Fetching observation data for time-03-31-25-235261_chatcmpl-1c8eba42-2c03-4ffc-9c7e-d2ca36188f49...\n",
      "Fetching observation data for time-03-31-36-209080_chatcmpl-be61343d-d49f-46fe-a5fc-655d98806a50...\n",
      "Fetching observation data for time-03-31-46-960103_chatcmpl-25d8fa4d-23c5-4db7-8bc8-d190a20f1417...\n",
      "Fetching observation data for time-03-31-56-552843_chatcmpl-3e9be6c0-173b-42e8-bca2-d571edefd17e...\n",
      "Fetching observation data for 3ad83d91-7a56-45b7-b999-1a29bccd6a95...\n",
      "Fetching observation data for time-03-29-43-945185_chatcmpl-1d48ec7f-4053-4786-9f29-cf055c66ea90...\n",
      "Fetching observation data for time-03-30-02-644233_chatcmpl-3d1c7245-38f0-453c-9573-7c8f217d0d33...\n",
      "Fetching observation data for time-03-30-13-626791_chatcmpl-12548889-8b45-4ffc-9074-846561c7dded...\n",
      "Fetching observation data for time-03-30-25-556109_chatcmpl-6feecff0-2534-4f66-bc5a-53c5f9b3caa2...\n",
      "Fetching observation data for time-03-30-39-660319_chatcmpl-ed99d62c-161e-485c-9cfc-a30ab224a4bb...\n",
      "Fetching observation data for f824b65a-f5f5-49d9-a3a4-e88b73a6d7cf...\n",
      "Fetching observation data for time-03-28-36-429076_chatcmpl-e4e72181-7aaa-42d8-bb28-58be2528c288...\n",
      "Fetching observation data for time-03-28-55-100104_chatcmpl-aa352729-124c-43a9-8399-75d3f1288985...\n",
      "Fetching observation data for time-03-29-03-131748_chatcmpl-6db7d1b8-d118-4fa0-a204-445e52a44151...\n",
      "Fetching observation data for time-03-29-13-963132_chatcmpl-7060e141-b7d7-4110-9d05-921469b81b85...\n",
      "Fetching observation data for time-03-29-25-828294_chatcmpl-39dd26b2-af2f-498d-a5ed-eeda56935555...\n",
      "Fetching observation data for 5d1ffb29-dc3c-4710-9f47-677b5a741bd0...\n",
      "Fetching observation data for time-03-27-19-839090_chatcmpl-43135b91-2585-4c69-88e0-164ca10ead26...\n",
      "Fetching observation data for time-03-27-38-536190_chatcmpl-1ebfcf18-beaa-4117-8fd5-cd9090c25b63...\n",
      "Fetching observation data for time-03-27-46-551932_chatcmpl-26a0706a-fe26-45f2-b995-03aee7220482...\n",
      "Fetching observation data for time-03-27-57-388425_chatcmpl-37c16dae-0e53-4fa5-852e-769596834f7b...\n",
      "Fetching observation data for time-03-28-06-815115_chatcmpl-477e1818-ec86-461f-a9ae-20ef0c5f87ec...\n",
      "Fetching observation data for f74b862f-df86-4975-9d78-260d0a7756df...\n",
      "Fetching observation data for time-03-25-57-273856_chatcmpl-8cc83b2a-f9cb-4937-b1b5-403581ac0ffd...\n",
      "Fetching observation data for time-03-26-16-012147_chatcmpl-86243b15-5bee-4d3b-9f75-f658013b85bf...\n",
      "Fetching observation data for time-03-26-24-023054_chatcmpl-23dec563-372c-448c-93c8-dec7ebb1ee2f...\n",
      "Fetching observation data for time-03-26-48-301688_chatcmpl-067f2fdb-caea-44d8-8751-1023c9b8111a...\n",
      "Fetching observation data for time-03-26-59-083352_chatcmpl-0ded9f6e-8708-4be3-b63b-979e94113927...\n",
      "Fetching observation data for 3907c8bb-1b9e-4fb2-81b5-2ee1213bb2bd...\n",
      "Fetching observation data for time-03-24-53-780976_chatcmpl-df941d50-fcdc-432b-aaa7-dfe4b194327d...\n",
      "Fetching observation data for time-03-25-12-465260_chatcmpl-6425d745-1c43-4b5a-bae0-6dac8d2f9f35...\n",
      "Fetching observation data for time-03-25-20-470529_chatcmpl-8391c918-28e9-4fb3-acd1-19534604e3e4...\n",
      "Fetching observation data for time-03-25-39-200682_chatcmpl-97c34cf9-afd8-4cef-81ad-8a7265c11a03...\n",
      "Fetching observation data for time-03-23-32-863206_chatcmpl-4fe5e7bc-cee6-42d6-94f0-51a8822d2d0b...\n",
      "Fetching observation data for time-03-23-51-550529_chatcmpl-1531fabe-f0b8-4279-a468-9d11c2209c2e...\n",
      "Fetching observation data for time-03-24-03-127831_chatcmpl-f2d5da80-3f10-444a-a576-c938cffed6ca...\n",
      "Fetching observation data for time-03-24-17-405077_chatcmpl-aa9f0af9-3e5e-495f-a88e-4f8831ddede7...\n",
      "Fetching observation data for time-03-24-35-232099_chatcmpl-701b97b8-17c0-41b3-9666-cd5c75b269d9...\n",
      "Fetching observation data for b557c6ad-fae0-4357-9468-2ccb8e1c1ad0...\n",
      "Fetching observation data for time-03-22-17-309025_chatcmpl-bebecacf-5dbb-4620-96cf-576e8e61e7e9...\n",
      "Fetching observation data for time-03-22-35-974082_chatcmpl-99a411fb-428e-4f61-a1ca-4046b5918c2f...\n",
      "Fetching observation data for time-03-22-47-508880_chatcmpl-028ecc72-7412-4271-b048-69baf91af59e...\n",
      "Fetching observation data for time-03-23-09-640143_chatcmpl-dbd6acb3-6740-45f5-847c-c1e04e867009...\n",
      "Fetching observation data for time-03-23-17-810453_chatcmpl-6c0744f7-c968-4ad2-af73-a6d9b6530fd9...\n",
      "Fetching observation data for f9e26951-6345-4497-bb36-979e37f2edd5...\n",
      "Fetching observation data for time-03-20-58-718117_chatcmpl-2544e089-27f7-4975-9aae-d633409dda79...\n",
      "Fetching observation data for time-03-21-17-387083_chatcmpl-779468a8-1889-4639-b0ee-3cb48164abb0...\n",
      "Fetching observation data for time-03-21-28-362154_chatcmpl-1ff0c3cb-bdcc-4fa2-87cc-f9cce6b09b3a...\n",
      "Fetching observation data for time-03-21-51-071137_chatcmpl-cbb7288c-040a-4521-b170-2c65871aefdd...\n",
      "Fetching observation data for time-03-22-00-769099_chatcmpl-d1a537e9-7b4b-4e28-b44c-f7ed56da6063...\n",
      "Fetching observation data for 8c29b8cd-87cc-4994-93ca-70771b4d2d80...\n",
      "Fetching observation data for time-03-19-56-185857_chatcmpl-25aa3612-3d8e-4853-b2aa-2a2e537c8c60...\n",
      "Fetching observation data for time-03-20-15-051846_chatcmpl-bfa2aca5-1f85-49ea-ad63-5e5320ef42f5...\n",
      "Fetching observation data for time-03-20-26-544576_chatcmpl-59c4e1b7-daa7-4200-9cec-0e7268bb7e9d...\n",
      "Fetching observation data for time-03-20-32-022972_chatcmpl-1027af37-e57b-4e76-9afb-32bda69b87a1...\n",
      "Fetching observation data for time-03-20-42-784048_chatcmpl-bfafeb3f-a3ba-49b3-8684-97c74163b3ff...\n",
      "Fetching observation data for af89472f-e022-4102-a177-be728132e53f...\n",
      "Fetching observation data for time-03-18-59-611956_chatcmpl-61c6ff79-eb15-46af-8287-c930dfda4b37...\n",
      "Fetching observation data for time-03-19-18-310813_chatcmpl-e06afa0c-a096-44ad-bbb0-611df6ecce93...\n",
      "Fetching observation data for time-03-19-29-809898_chatcmpl-a49185c1-9daf-487d-b5b1-b44d3290398b...\n",
      "Fetching observation data for time-03-19-33-278553_chatcmpl-801d7635-c359-4554-a524-86fef7021799...\n",
      "Fetching observation data for time-03-17-57-666054_chatcmpl-ca7fb21c-cd74-4852-998c-b21f7a8d1efc...\n",
      "Fetching observation data for time-03-18-15-794271_chatcmpl-0d04ff8b-af53-400e-8d62-04b6783a778b...\n",
      "Fetching observation data for time-03-18-26-914663_chatcmpl-89466458-c7b1-40d1-b95f-c08b0d71a0a2...\n",
      "Fetching observation data for time-03-16-38-946553_chatcmpl-50137a19-a88e-48a9-a770-98cb0d3e0bea...\n",
      "Fetching observation data for time-03-16-57-613253_chatcmpl-17dcc92d-3788-42a7-b491-e47bf6150d4c...\n",
      "Fetching observation data for time-03-17-08-591176_chatcmpl-6ba749f4-2505-4101-a01f-2979496434ff...\n",
      "Fetching observation data for time-03-17-22-705624_chatcmpl-c0fd6eed-ba6a-489a-83d9-eda5169ee127...\n",
      "Fetching observation data for time-03-17-33-863422_chatcmpl-6286f3d5-3b7b-4493-94b0-1bc7c430544a...\n",
      "Fetching observation data for 453fb0c6-03d3-46c3-b92d-3af75d2bfef9...\n",
      "Fetching observation data for time-03-15-18-374826_chatcmpl-bd89d9ee-779f-4f86-a332-bd980008ee79...\n",
      "Fetching observation data for time-03-15-37-052321_chatcmpl-93106722-fdc3-47f8-b10d-2f70540afab6...\n",
      "Fetching observation data for time-03-15-48-028463_chatcmpl-c96fb5d2-bbd3-4a6e-9d29-b536fdce3bf0...\n",
      "Fetching observation data for time-03-16-00-157119_chatcmpl-ad4ad053-9c97-4a8c-a5e4-9e2650271f30...\n",
      "Fetching observation data for time-03-16-14-560222_chatcmpl-1a11bb86-670f-470e-bfc8-c3971633060b...\n",
      "Fetching observation data for 68601b66-4871-4b39-a7de-037cd7386b33...\n",
      "Fetching observation data for time-03-13-56-840336_chatcmpl-cb2963e2-bb66-4c86-ae7b-cd7b58dea928...\n",
      "Fetching observation data for time-03-14-15-511105_chatcmpl-e3e34063-0064-4208-9cbf-f3c2ac1e26da...\n",
      "Fetching observation data for time-03-14-26-515368_chatcmpl-1dec024a-e18f-49eb-9a91-8cb54b732cca...\n",
      "Fetching observation data for time-03-14-39-412486_chatcmpl-b83aed85-4bcd-4136-b5f0-06ab201ccf5c...\n",
      "Fetching observation data for time-03-14-50-564518_chatcmpl-d5a901e7-0638-442a-be4f-d58626a53d57...\n",
      "Fetching observation data for 893cb5a9-9bfb-417a-bb19-2ef7e9ecc3e2...\n",
      "Fetching observation data for time-03-12-37-243893_chatcmpl-1f04563c-f672-4385-a399-f7c5c5186f3a...\n",
      "Fetching observation data for time-03-12-55-935117_chatcmpl-444b58cf-f777-4f27-b0ef-cbcd2cbc2ca3...\n",
      "Fetching observation data for time-03-13-07-484735_chatcmpl-8c4cf160-f931-4d1f-b734-1c2abad5a080...\n",
      "Fetching observation data for time-03-13-19-518869_chatcmpl-957bcd70-fe3f-4f76-bba4-cfa6f57c02cb...\n",
      "Fetching observation data for time-03-13-34-277105_chatcmpl-85fda415-f139-4ebc-8a69-4457311c1e3d...\n",
      "Fetching observation data for e9c54986-bcef-4ff6-9615-845ad93da5ea...\n",
      "Fetching observation data for time-03-11-21-595954_chatcmpl-85f4ae0b-e73c-4b0d-8192-fea11cfded29...\n",
      "Fetching observation data for time-03-11-40-301078_chatcmpl-0d4807fd-ac01-4077-8d19-c8939104da34...\n",
      "Fetching observation data for time-03-11-48-319644_chatcmpl-003ecb75-a308-455d-b576-62c19d9e7ed4...\n",
      "Fetching observation data for time-03-11-59-174697_chatcmpl-7318f7d2-f447-46de-b09f-4fe163f8c723...\n",
      "Fetching observation data for time-03-12-08-604686_chatcmpl-3f224510-c328-4701-81f6-f0c45d2fc792...\n",
      "Fetching observation data for 4c94fb00-74c0-4128-a6c6-3c27c9c84c03...\n",
      "Fetching observation data for time-03-10-09-037472_chatcmpl-d5b53b8e-7300-48e1-9a8a-4718da4ec252...\n",
      "Fetching observation data for time-03-10-27-728163_chatcmpl-4382fe03-1848-4990-8cc0-cdd7cacc5a68...\n",
      "Fetching observation data for time-03-10-39-291286_chatcmpl-65139d65-7234-46a1-9af2-1424a75e1bc7...\n",
      "Fetching observation data for time-03-10-52-205035_chatcmpl-cd9b56f8-2bda-4737-8033-88e884d6543e...\n",
      "Fetching observation data for time-03-11-00-700058_chatcmpl-1ed3ed13-ec3c-472d-92a4-db4ca6045211...\n",
      "Fetching observation data for eacd40a5-944b-4ea9-acf2-3e9fe2ab63f3...\n",
      "Raw JSON saved to: /Users/hann/Projects/reference-benchmark-tinyml_llm/data_analysis/2025/08.15/raw_export/raw_codestral_e6d3_psg_batch.json\n"
     ]
    }
   ],
   "source": [
    "# ALTERNATIVE TO 2.\n",
    "import os\n",
    "import json\n",
    "from time import sleep\n",
    "from langfuse import Langfuse\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "\n",
    "# LANGFUSE_SERVICE_PUBLIC_KEY = \"pk-lf-559a2c0f-ee29-4c32-944c-bf73b5f0ce28\"\n",
    "# LANGFUSE_SERVICE_SECRET_KEY = \"sk-lf-75f8bf7f-a5db-4756-b0dd-d758a2a292c8\"\n",
    "# LANGFUSE_SERVICE_HOST = \"https://langfuse.hann.fi\"\n",
    "\n",
    "\n",
    "if LOCAL_HOST:\n",
    "    langfuse = Langfuse(\n",
    "        secret_key=\"sk-lf-75f8bf7f-a5db-4756-b0dd-d758a2a292c8\",\n",
    "        public_key=\"pk-lf-559a2c0f-ee29-4c32-944c-bf73b5f0ce28\",\n",
    "        host=\"https://langfuse.hann.fi\",\n",
    "    )\n",
    "else:\n",
    "    langfuse = Langfuse(\n",
    "        secret_key=LANGFUSE_SERVICE_SECRET_KEY,\n",
    "        public_key=LANGFUSE_SERVICE_PUBLIC_KEY,\n",
    "        host=LANGFUSE_SERVICE_HOST,\n",
    "    )\n",
    "\n",
    "API_invok_count = 0\n",
    "query_range_num_run = {\"start\": 0, \"end\": 1}\n",
    "\n",
    "\n",
    "class CustomJSONEncoder(json.JSONEncoder):\n",
    "    def __init__(self, *args, LOCAL_HOST=True, **kwargs):\n",
    "        self.LOCAL_HOST = LOCAL_HOST\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "    def default(self, obj):\n",
    "        if isinstance(obj, datetime):\n",
    "            return obj.isoformat()\n",
    "        if hasattr(obj, \"__dict__\"):\n",
    "            data = obj.__dict__.copy()\n",
    "            if \"observations\" in data:\n",
    "                data[\"observations\"] = [\n",
    "                    fetch_observation_data(obs, self.LOCAL_HOST)\n",
    "                    for obs in data[\"observations\"]\n",
    "                ]\n",
    "\n",
    "            return data\n",
    "        return super().default(obj)\n",
    "\n",
    "\n",
    "def fetch_observation_data(observation_id, LOCAL_HOST):\n",
    "    \"\"\"\n",
    "    Fetches observation data from Langfuse and returns its dictionary representation.\n",
    "    \"\"\"\n",
    "    print(f\"Fetching observation data for {observation_id}...\")\n",
    "    global API_invok_count\n",
    "    if API_invok_count >= 0 and not LOCAL_HOST:\n",
    "        print(\"Waiting for 3 seconds to fetch observation data...\")\n",
    "        for _ in tqdm(range(3), desc=\"Progress\", unit=\"s\"):\n",
    "            sleep(1)\n",
    "        API_invok_count = 0\n",
    "\n",
    "    observation_response = langfuse.fetch_observation(observation_id)\n",
    "    API_invok_count += 1\n",
    "\n",
    "    return observation_response.data.dict()\n",
    "\n",
    "\n",
    "def fetch_and_save_complete_data(session_id_list, raw_export_dir, LOCAL_HOST):\n",
    "    \"\"\"\n",
    "    Fetches complete trace data for each session ID and saves it to JSON files.\n",
    "\n",
    "    Parameters:\n",
    "        session_id_list (list): List of session IDs to process.\n",
    "        raw_export_dir (str): Directory path to save raw JSON files.\n",
    "    \"\"\"\n",
    "\n",
    "    def save_complete_data(session_id):\n",
    "        global API_invok_count\n",
    "        if API_invok_count >= 0 and not LOCAL_HOST:\n",
    "            print(\"Waiting for 4 seconds to fetch traces...\")\n",
    "            for _ in tqdm(range(4), desc=\"Progress\", unit=\"s\"):\n",
    "                sleep(1)\n",
    "            API_invok_count = 0\n",
    "\n",
    "        fetch_traces_response = langfuse.fetch_traces(session_id=session_id)\n",
    "        API_invok_count += 1\n",
    "\n",
    "        print(f\"Fetching traces for session {session_id}...\")\n",
    "        # Create directories if they don't exist\n",
    "        os.makedirs(raw_export_dir, exist_ok=True)\n",
    "\n",
    "        # Save complete data to JSON file\n",
    "        # if session_id.startswith(\"da0a\"):\n",
    "        #     session_id = \"phi4_\" + session_id\n",
    "        if \"tpsg\" in session_id:\n",
    "            session_id_ = session_id.replace(\"tpsg\", \"tpusg\")\n",
    "        else:\n",
    "            session_id_ = session_id\n",
    "            \n",
    "        raw_path = os.path.join(raw_export_dir, f\"raw_{session_id_}.json\")\n",
    "        with open(raw_path, \"w\") as f:\n",
    "            json.dump(fetch_traces_response, f, cls=CustomJSONEncoder, indent=2)\n",
    "\n",
    "        print(f\"Raw JSON saved to: {raw_path}\")\n",
    "\n",
    "    for session_id in session_id_list:\n",
    "        save_complete_data(session_id)\n",
    "\n",
    "\n",
    "fetch_and_save_complete_data(session_id_list, raw_export_dir, LOCAL_HOST)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Trim data\n",
    "\n",
    "Here also intercept the runs with fatal errors that need to be excluded from the analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPAN error_19_tpusg_failure_signal_tpu_sketch_generator: Failed. Last error: Unexpected error during generation: The output is not a valid code block. Follow the instructions in the prompt return a complete, correct Python script enclosed in a single ```python\n",
      "<generated_code>\n",
      "``` block.\n",
      "SPAN error_b4_tpusg_failure_signal_tpu_sketch_generator: Failed. Last error: Traceback (most recent call last):\n",
      "  File \"script_d8568010_1755043323.py\", line 3, in <module>\n",
      "    import tflite\n",
      "ModuleNotFoundError: No module named 'tflite'\n",
      "SPAN error_77_tpusg_failure_signal_tpu_sketch_generator: Failed. Last error: Traceback (most recent call last):\n",
      "  File \"script_1eb423a4_1755043206.py\", line 8, in <module>\n",
      "    labels = read_label_file('path/to/your/labels.txt')\n",
      "  File \"/home/mendel/tinyml_autopilot/tinyml-env/lib/python3.7/site-packages/pycoral/utils/dataset.py\", line 36, in read_label_file\n",
      "    with open(file_path, 'r', encoding='utf-8') as f:\n",
      "FileNotFoundError: [Errno 2] No such file or directory: 'path/to/your/labels.txt'\n",
      "SPAN error_6d_tpusg_failure_signal_tpu_sketch_generator: Failed. Last error: Unexpected error during generation: The output is not a valid code block. Follow the instructions in the prompt return a complete, correct Python script enclosed in a single ```python\n",
      "<generated_code>\n",
      "``` block.\n",
      "SPAN error_7a_tpusg_failure_signal_tpu_sketch_generator: Failed. Last error: Unexpected error during generation: Generated script is not complete. Please ensure to generate a complete Python script.\n",
      "SPAN error_6c_tpusg_failure_signal_tpu_sketch_generator: Failed. Last error: Unexpected error during generation: Generated script is not complete. Please ensure to generate a complete Python script.\n",
      "SPAN error_a7_tpusg_failure_signal_tpu_sketch_generator: Failed. Last error: Traceback (most recent call last):\n",
      "  File \"script_044b793b_1755042657.py\", line 8, in <module>\n",
      "    experimental_delegates=[load_delegate('libedgetpu.so.1')])\n",
      "  File \"/home/mendel/tinyml_autopilot/tinyml-env/lib/python3.7/site-packages/tflite_runtime/interpreter.py\", line 351, in __init__\n",
      "    experimental_preserve_all_tensors))\n",
      "ValueError: Could not open 'model.tflite'.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"script_044b793b_1755042657.py\", line 11, in <module>\n",
      "    experimental_delegates=[load_delegate('/usr/lib/aarch64-linux-gnu/libedgetpu.so.1')])\n",
      "  File \"/home/mendel/tinyml_autopilot/tinyml-env/lib/python3.7/site-packages/tflite_runtime/interpreter.py\", line 351, in __init__\n",
      "    experimental_preserve_all_tensors))\n",
      "ValueError: Could not open 'model.tflite'.\n",
      "SPAN error_1f_tpusg_failure_signal_tpu_sketch_generator: Failed. Last error: Traceback (most recent call last):\n",
      "  File \"script_ca92468f_1755042395.py\", line 7, in <module>\n",
      "    interpreter = Interpreter(model_path='model.tflite', experimental_delegates=[load_delegate('libedgetpu.so.1.0')])\n",
      "  File \"/home/mendel/tinyml_autopilot/tinyml-env/lib/python3.7/site-packages/tflite_runtime/interpreter.py\", line 351, in __init__\n",
      "    experimental_preserve_all_tensors))\n",
      "ValueError: Could not open 'model.tflite'.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"script_ca92468f_1755042395.py\", line 9, in <module>\n",
      "    interpreter = Interpreter(model_path='model.tflite', experimental_delegates=[load_delegate('/usr/lib/aarch64-linux-gnu/libedgetpu.so.1.0')])\n",
      "  File \"/home/mendel/tinyml_autopilot/tinyml-env/lib/python3.7/site-packages/tflite_runtime/interpreter.py\", line 351, in __init__\n",
      "    experimental_preserve_all_tensors))\n",
      "ValueError: Could not open 'model.tflite'.\n",
      "SPAN error_ac_tpusg_failure_signal_tpu_sketch_generator: Failed. Last error: Traceback (most recent call last):\n",
      "  File \"script_8ebb3109_1755042281.py\", line 10, in <module>\n",
      "    with open(labels_path, 'r') as f:\n",
      "FileNotFoundError: [Errno 2] No such file or directory: '<actual_path_to_your_labels_file>'\n",
      "SPAN error_dc_tpusg_failure_signal_tpu_sketch_generator: Failed. Last error: Unexpected error during generation: Generated script is not complete. Please ensure to generate a complete Python script.\n",
      "SPAN error_7b_tpusg_failure_signal_tpu_sketch_generator: Failed. Last error: Unexpected error during generation: Generated script is not complete. Please ensure to generate a complete Python script.\n",
      "SPAN error_48_tpusg_failure_signal_tpu_sketch_generator: Failed. Last error: Unexpected error during generation: The output is not a valid code block. Follow the instructions in the prompt return a complete, correct Python script enclosed in a single ```python\n",
      "<generated_code>\n",
      "``` block.\n",
      "SPAN error_a6_tpusg_failure_signal_tpu_sketch_generator: Failed. Last error: Traceback (most recent call last):\n",
      "  File \"script_b1c3be98_1755041527.py\", line 3, in <module>\n",
      "    interpreter = Interpreter(model_path='your_model.tflite',\n",
      "NameError: name 'Interpreter' is not defined\n",
      "SPAN error_1d_tpusg_failure_signal_tpu_sketch_generator: Failed. Last error: Unexpected error during generation: The output is not a valid code block. Follow the instructions in the prompt return a complete, correct Python script enclosed in a single ```python\n",
      "<generated_code>\n",
      "``` block.\n",
      "SPAN error_4e_tpusg_failure_signal_tpu_sketch_generator: Failed. Last error: Traceback (most recent call last):\n",
      "  File \"script_2b6b681f_1755041306.py\", line 13, in <module>\n",
      "    height = input_details[0]['shape'][1]\n",
      "TypeError: string indices must be integers\n",
      "SPAN error_99_tpusg_failure_signal_tpu_sketch_generator: Failed. Last error: Traceback (most recent call last):\n",
      "  File \"script_f8d9fcaa_1755041185.py\", line 2, in <module>\n",
      "    with open(label_path, 'r') as f:\n",
      "NameError: name 'label_path' is not defined\n",
      "SPAN error_44_tpusg_failure_signal_tpu_sketch_generator: Failed. Last error: Traceback (most recent call last):\n",
      "  File \"script_b46d84b0_1755041058.py\", line 52, in <module>\n",
      "    boxes = interpreter.get_tensor(output_details[0]['index'])[0]\n",
      "TypeError: string indices must be integers\n",
      "SPAN error_2c_tpusg_failure_signal_tpu_sketch_generator: Failed. Last error: Unexpected error during generation: Generated script is not complete. Please ensure to generate a complete Python script.\n",
      "SPAN error_2f_tpusg_failure_signal_tpu_sketch_generator: Failed. Last error: Unexpected error during generation: The output is not a valid code block. Follow the instructions in the prompt return a complete, correct Python script enclosed in a single ```python\n",
      "<generated_code>\n",
      "``` block.\n",
      "SPAN error_f0_tpusg_failure_signal_tpu_sketch_generator: Failed. Last error: OpenCV Error: Assertion failed (ssize.width > 0 && ssize.height > 0) in resize, file /build/opencv-tragD2/opencv-3.2.0+dfsg/modules/imgproc/src/imgwarp.cpp, line 3492\n",
      "Traceback (most recent call last):\n",
      "  File \"script_cf5a9ea3_1755040758.py\", line 28, in <module>\n",
      "    resized_image = cv2.resize(image, (width, height))\n",
      "cv2.error: /build/opencv-tragD2/opencv-3.2.0+dfsg/modules/imgproc/src/imgwarp.cpp:3492: error: (-215) ssize.width > 0 && ssize.height > 0 in function resize\n",
      "\n",
      "SPAN error_ea_tpusg_failure_signal_tpu_sketch_generator: Failed. Last error: Unexpected error during generation: The output is not a valid code block. Follow the instructions in the prompt return a complete, correct Python script enclosed in a single ```python\n",
      "<generated_code>\n",
      "``` block.\n",
      "SPAN error_f4_tpusg_failure_signal_tpu_sketch_generator: Failed. Last error: Unexpected error during generation: The output is not a valid code block. Follow the instructions in the prompt return a complete, correct Python script enclosed in a single ```python\n",
      "<generated_code>\n",
      "``` block.\n",
      "Successfully processed and saved trimmed data for session codestral_e6d3_tpusg_batch\n",
      "SPAN error_3e_psg_failure_signal_py_sketch_generator: Failed. Last error: Unexpected error during generation: The output is not a valid code block. Follow the instructions in the prompt return a complete, correct Python script enclosed in a single ```python\n",
      "<generated_code>\n",
      "``` block.\n",
      "SPAN error_ca_psg_failure_signal_py_sketch_generator: Failed. Last error: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250813034431_psg_codestral:latest/tmp_20250813034431_psg_codestral:latest.py\", line 22, in <module>\n",
      "    for line in f:\n",
      "  File \"/home/wuguangh/.conda/envs/tinyml/lib/python3.10/codecs.py\", line 322, in decode\n",
      "    (result, consumed) = self._buffer_decode(data, self.errors, final)\n",
      "UnicodeDecodeError: 'utf-8' codec can't decode byte 0x92 in position 42: invalid start byte\n",
      "\n",
      "SPAN error_53_psg_failure_signal_py_sketch_generator: Failed. Last error: Unexpected error during generation: The output is not a valid code block. Follow the instructions in the prompt return a complete, correct Python script enclosed in a single ```python\n",
      "<generated_code>\n",
      "``` block.\n",
      "SPAN error_fe_psg_failure_signal_py_sketch_generator: Failed. Last error: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250813034148_psg_codestral:latest/tmp_20250813034148_psg_codestral:latest.py\", line 25, in <module>\n",
      "    for line in f:\n",
      "  File \"/home/wuguangh/.conda/envs/tinyml/lib/python3.10/codecs.py\", line 322, in decode\n",
      "    (result, consumed) = self._buffer_decode(data, self.errors, final)\n",
      "UnicodeDecodeError: 'utf-8' codec can't decode byte 0x92 in position 42: invalid start byte\n",
      "\n",
      "SPAN error_54_psg_failure_signal_py_sketch_generator: Failed. Last error: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250813033941_psg_codestral:latest/tmp_20250813033941_psg_codestral:latest.py\", line 32, in <module>\n",
      "    interpreter.set_tensor(input_details[0]['index'], input_data)\n",
      "  File \"/home/wuguangh/.conda/envs/tinyml/lib/python3.10/site-packages/ai_edge_litert/interpreter.py\", line 764, in set_tensor\n",
      "    self._interpreter.SetTensor(tensor_index, value)\n",
      "ValueError: Cannot set tensor: Got value of type FLOAT32 but expected type UINT8 for input 175, name: normalized_input_image_tensor \n",
      "\n",
      "SPAN error_1d_psg_failure_signal_py_sketch_generator: Failed. Last error: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250813033832_psg_codestral:latest/tmp_20250813033832_psg_codestral:latest.py\", line 24, in <module>\n",
      "    image = Image.open(image_path).convert('RGB')\n",
      "  File \"/home/wuguangh/.conda/envs/tinyml/lib/python3.10/site-packages/PIL/Image.py\", line 3469, in open\n",
      "    fp = builtins.open(filename, \"rb\")\n",
      "FileNotFoundError: [Errno 2] No such file or directory: '/home/wuguangh/Projects/tinyml-autopilot/path/to/image.jpg'\n",
      "\n",
      "SPAN error_71_psg_failure_signal_py_sketch_generator: Failed. Last error: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250813033702_psg_codestral:latest/tmp_20250813033702_psg_codestral:latest.py\", line 29, in <module>\n",
      "    input_data = np.frombuffer(raw_data, dtype=input_dtype).reshape(input_shape)\n",
      "ValueError: cannot reshape array of size 564314 into shape (1,300,300,3)\n",
      "\n",
      "SPAN error_11_psg_failure_signal_py_sketch_generator: Failed. Last error: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250813033431_psg_codestral:latest/tmp_20250813033431_psg_codestral:latest.py\", line 19, in <module>\n",
      "    input_data = np.array([float(val) for val in file.read().split()], dtype=np.float32).reshape(input_details[0]['shape'])\n",
      "  File \"/home/wuguangh/.conda/envs/tinyml/lib/python3.10/codecs.py\", line 322, in decode\n",
      "    (result, consumed) = self._buffer_decode(data, self.errors, final)\n",
      "UnicodeDecodeError: 'utf-8' codec can't decode byte 0x92 in position 42: invalid start byte\n",
      "\n",
      "SPAN error_7e_psg_failure_signal_py_sketch_generator: Failed. Last error: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250813033306_psg_codestral:latest/tmp_20250813033306_psg_codestral:latest.py\", line 17, in <module>\n",
      "    input_data = np.random.rand(*input_shape).astype(np.float32)\n",
      "  File \"numpy/random/mtrand.pyx\", line 1219, in numpy.random.mtrand.RandomState.rand\n",
      "  File \"numpy/random/mtrand.pyx\", line 437, in numpy.random.mtrand.RandomState.random_sample\n",
      "  File \"_common.pyx\", line 307, in numpy.random._common.double_fill\n",
      "TypeError: 'str' object cannot be interpreted as an integer\n",
      "\n",
      "SPAN error_46_psg_failure_signal_py_sketch_generator: Failed. Last error: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "OpenCV: FFMPEG: tag 0x44495658/'XVID' is not supported with codec id 12 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n",
      "OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250813033209_psg_codestral:latest/tmp_20250813033209_psg_codestral:latest.py\", line 37, in <module>\n",
      "    interpreter.set_tensor(input_details[0]['index'], input_data)\n",
      "  File \"/home/wuguangh/.conda/envs/tinyml/lib/python3.10/site-packages/ai_edge_litert/interpreter.py\", line 764, in set_tensor\n",
      "    self._interpreter.SetTensor(tensor_index, value)\n",
      "ValueError: Cannot set tensor: Got value of type FLOAT32 but expected type UINT8 for input 175, name: normalized_input_image_tensor \n",
      "\n",
      "SPAN error_df_psg_failure_signal_py_sketch_generator: Failed. Last error: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250813033059_psg_codestral:latest/tmp_20250813033059_psg_codestral:latest.py\", line 37, in <module>\n",
      "    interpreter.set_tensor(input_details[0]['index'], input_data)\n",
      "  File \"/home/wuguangh/.conda/envs/tinyml/lib/python3.10/site-packages/ai_edge_litert/interpreter.py\", line 764, in set_tensor\n",
      "    self._interpreter.SetTensor(tensor_index, value)\n",
      "ValueError: Cannot set tensor: Got value of type FLOAT32 but expected type UINT8 for input 175, name: normalized_input_image_tensor \n",
      "\n",
      "SPAN error_69_psg_failure_signal_py_sketch_generator: Failed. Last error: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250813032937_psg_codestral:latest/tmp_20250813032937_psg_codestral:latest.py\", line 23, in <module>\n",
      "    for line in f:\n",
      "  File \"/home/wuguangh/.conda/envs/tinyml/lib/python3.10/codecs.py\", line 322, in decode\n",
      "    (result, consumed) = self._buffer_decode(data, self.errors, final)\n",
      "UnicodeDecodeError: 'utf-8' codec can't decode byte 0x92 in position 42: invalid start byte\n",
      "\n",
      "SPAN error_49_psg_failure_signal_py_sketch_generator: Failed. Last error: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250813032829_psg_codestral:latest/tmp_20250813032829_psg_codestral:latest.py\", line 42, in <module>\n",
      "    interpreter.set_tensor(input_details[0]['index'], input_data)\n",
      "  File \"/home/wuguangh/.conda/envs/tinyml/lib/python3.10/site-packages/ai_edge_litert/interpreter.py\", line 764, in set_tensor\n",
      "    self._interpreter.SetTensor(tensor_index, value)\n",
      "ValueError: Cannot set tensor: Got value of type FLOAT32 but expected type UINT8 for input 175, name: normalized_input_image_tensor \n",
      "\n",
      "SPAN error_65_psg_failure_signal_py_sketch_generator: Failed. Last error: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "OpenCV: FFMPEG: tag 0x44495658/'XVID' is not supported with codec id 12 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n",
      "OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250813032712_psg_codestral:latest/tmp_20250813032712_psg_codestral:latest.py\", line 38, in <module>\n",
      "    interpreter.set_tensor(input_details[0]['index'], input_data)\n",
      "  File \"/home/wuguangh/.conda/envs/tinyml/lib/python3.10/site-packages/ai_edge_litert/interpreter.py\", line 764, in set_tensor\n",
      "    self._interpreter.SetTensor(tensor_index, value)\n",
      "ValueError: Cannot set tensor: Got value of type FLOAT32 but expected type UINT8 for input 175, name: normalized_input_image_tensor \n",
      "\n",
      "SPAN error_3d_psg_failure_signal_py_sketch_generator: Failed. Last error: Unexpected error during generation: The output is not a valid code block. Follow the instructions in the prompt return a complete, correct Python script enclosed in a single ```python\n",
      "<generated_code>\n",
      "``` block.\n",
      "SPAN error_eb_psg_failure_signal_py_sketch_generator: Failed. Last error: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250813032325_psg_codestral:latest/tmp_20250813032325_psg_codestral:latest.py\", line 20, in <module>\n",
      "    interpreter.set_tensor(input_details[0]['index'], input_data)\n",
      "  File \"/home/wuguangh/.conda/envs/tinyml/lib/python3.10/site-packages/ai_edge_litert/interpreter.py\", line 764, in set_tensor\n",
      "    self._interpreter.SetTensor(tensor_index, value)\n",
      "ValueError: Cannot set tensor: Got value of type STRING but expected type UINT8 for input 175, name: normalized_input_image_tensor \n",
      "\n",
      "SPAN error_37_psg_failure_signal_py_sketch_generator: Failed. Last error: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250813032210_psg_codestral:latest/tmp_20250813032210_psg_codestral:latest.py\", line 21, in <module>\n",
      "    image = np.load(input_path)  # Assuming the image is saved as a numpy array\n",
      "  File \"/home/wuguangh/.conda/envs/tinyml/lib/python3.10/site-packages/numpy/lib/npyio.py\", line 462, in load\n",
      "    raise ValueError(\"Cannot load file containing pickled data \"\n",
      "ValueError: Cannot load file containing pickled data when allow_pickle=False\n",
      "\n",
      "SPAN error_24_psg_failure_signal_py_sketch_generator: Failed. Last error: Traceback (most recent call last):\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250813032051_psg_codestral:latest/tmp_20250813032051_psg_codestral:latest.py\", line 5, in <module>\n",
      "    interpreter = Interpreter(model_path='ssd_mobilenet_v1_coco_quant_2018_06_29/detect.tflite')\n",
      "  File \"/home/wuguangh/.conda/envs/tinyml/lib/python3.10/site-packages/ai_edge_litert/interpreter.py\", line 490, in __init__\n",
      "    self._interpreter = _interpreter_wrapper.CreateWrapperFromFile(\n",
      "ValueError: Could not open 'ssd_mobilenet_v1_coco_quant_2018_06_29/detect.tflite'.\n",
      "\n",
      "SPAN error_92_psg_failure_signal_py_sketch_generator: Failed. Last error: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250813031751_psg_codestral:latest/tmp_20250813031751_psg_codestral:latest.py\", line 26, in <module>\n",
      "    for filename in os.listdir(image_folder_path):\n",
      "NameError: name 'os' is not defined\n",
      "\n",
      "SPAN error_20_psg_failure_signal_py_sketch_generator: Failed. Last error: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250813031632_psg_codestral:latest/tmp_20250813031632_psg_codestral:latest.py\", line 29, in <module>\n",
      "    interpreter.set_tensor(input_details[0]['index'], input_data)\n",
      "  File \"/home/wuguangh/.conda/envs/tinyml/lib/python3.10/site-packages/ai_edge_litert/interpreter.py\", line 764, in set_tensor\n",
      "    self._interpreter.SetTensor(tensor_index, value)\n",
      "ValueError: Cannot set tensor: Got value of type FLOAT32 but expected type UINT8 for input 175, name: normalized_input_image_tensor \n",
      "\n",
      "SPAN error_11_psg_failure_signal_py_sketch_generator: Failed. Last error: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250813031511_psg_codestral:latest/tmp_20250813031511_psg_codestral:latest.py\", line 43, in <module>\n",
      "    interpreter.set_tensor(input_details[0]['index'], input_data)\n",
      "  File \"/home/wuguangh/.conda/envs/tinyml/lib/python3.10/site-packages/ai_edge_litert/interpreter.py\", line 764, in set_tensor\n",
      "    self._interpreter.SetTensor(tensor_index, value)\n",
      "ValueError: Cannot set tensor: Got value of type FLOAT32 but expected type UINT8 for input 175, name: normalized_input_image_tensor \n",
      "\n",
      "SPAN error_c4_psg_failure_signal_py_sketch_generator: Failed. Last error: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250813031350_psg_codestral:latest/tmp_20250813031350_psg_codestral:latest.py\", line 25, in <module>\n",
      "    frame = read_frame(video_file)  # Implement this function to read a frame from the video file\n",
      "NameError: name 'read_frame' is not defined\n",
      "\n",
      "SPAN error_51_psg_failure_signal_py_sketch_generator: Failed. Last error: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250813031230_psg_codestral:latest/tmp_20250813031230_psg_codestral:latest.py\", line 25, in <module>\n",
      "    for filename in os.listdir(input_dir):\n",
      "NameError: name 'os' is not defined\n",
      "\n",
      "SPAN error_eb_psg_failure_signal_py_sketch_generator: Failed. Last error: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250813031114_psg_codestral:latest/tmp_20250813031114_psg_codestral:latest.py\", line 30, in <module>\n",
      "    input_data = np.array(raw_data, dtype=input_details[0]['dtype'])\n",
      "TypeError: int() argument must be a string, a bytes-like object or a real number, not 'ellipsis'\n",
      "\n",
      "Successfully processed and saved trimmed data for session codestral_e6d3_psg_batch\n",
      "Total 0 traces skipped. They are []\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "skipped_traces = []\n",
    "\n",
    "\n",
    "def process_existing_observation(observation):\n",
    "    \"\"\"\n",
    "    Processes an existing observation dictionary by trimming unwanted keys.\n",
    "    \"\"\"\n",
    "    unwanted_observation_keys = [\n",
    "        \"completionStartTime\",\n",
    "        \"metadata\",\n",
    "        \"timeToFirstToken\",\n",
    "        \"createdAt\",\n",
    "        \"usageDetails\",\n",
    "        \"usage\",\n",
    "        \"projectId\",\n",
    "        \"unit\",\n",
    "        \"updatedAt\",\n",
    "        \"version\",\n",
    "        \"parentObservationId\",\n",
    "        \"promptId\",\n",
    "        \"promptName\",\n",
    "        \"promptVersion\",\n",
    "        \"modelId\",\n",
    "        \"inputPrice\",\n",
    "        \"outputPrice\",\n",
    "        \"totalPrice\",\n",
    "        # \"modelParameters\",\n",
    "        \"input\",\n",
    "        \"output\",\n",
    "    ]\n",
    "\n",
    "    # If observation is a dictionary containing observation data\n",
    "    if isinstance(observation, dict):\n",
    "        trimmed_observation = {\n",
    "            k: v for k, v in observation.items() if k not in unwanted_observation_keys\n",
    "        }\n",
    "        return trimmed_observation\n",
    "    return observation\n",
    "\n",
    "\n",
    "def trim_data(data):\n",
    "    \"\"\"\n",
    "    Recursively trims the data structure.\n",
    "    \"\"\"\n",
    "\n",
    "    if isinstance(data, dict):\n",
    "        # Process the current dictionary\n",
    "        unwanted_trace_keys = [\n",
    "            \"release\",\n",
    "            \"version\",\n",
    "            \"user_id\",\n",
    "            \"public\",\n",
    "            \"html_path\",\n",
    "            \"scores\",\n",
    "            \"bookmarked\",\n",
    "            \"projectId\",\n",
    "            \"externalId\",\n",
    "            \"page\",\n",
    "            \"limit\",\n",
    "            \"total_pages\",\n",
    "        ]\n",
    "\n",
    "        # If this is a trace that contains observations, check for fatal errors\n",
    "        if \"observations\" in data:\n",
    "            # Check for SPAN observations with fatal errors before processing\n",
    "            skip_trace = False\n",
    "            for obs in data[\"observations\"]:\n",
    "                if isinstance(obs, dict) and obs.get(\"name\").startswith(\"error\"):\n",
    "                    status_message = obs.get(\"statusMessage\", \"\")\n",
    "                    ob_name = obs.get(\"name\")\n",
    "                    print(f\"SPAN {ob_name}: {status_message}\")\n",
    "\n",
    "                    if \"Fatal error\" in status_message:\n",
    "                        print(f\"Found Fatal error in SPAN observation, skipping trace\")\n",
    "                        skip_trace = True\n",
    "                        skipped_traces.append(data[\"name\"])\n",
    "                        break\n",
    "\n",
    "            if skip_trace:\n",
    "                return None  # Signal to skip this trace\n",
    "\n",
    "        # Create a new dictionary with wanted keys and recursively process values\n",
    "        trimmed_data = {}\n",
    "        for key, value in data.items():\n",
    "            if key not in unwanted_trace_keys:\n",
    "                if key == \"observations\":\n",
    "                    # Special handling for observations\n",
    "                    trimmed_data[key] = [\n",
    "                        process_existing_observation(obs) for obs in value\n",
    "                    ]\n",
    "                elif isinstance(value, (dict, list)):\n",
    "                    # Recursively process nested structures\n",
    "                    trimmed_data[key] = trim_data(value)\n",
    "                else:\n",
    "                    trimmed_data[key] = value\n",
    "\n",
    "        return trimmed_data\n",
    "\n",
    "    elif isinstance(data, list):\n",
    "        # Recursively process each item in the list\n",
    "        processed_items = []\n",
    "        for item in data:\n",
    "            processed_item = trim_data(item)\n",
    "            if processed_item is not None:  # Only add items that weren't filtered out\n",
    "                processed_items.append(processed_item)\n",
    "        return processed_items\n",
    "\n",
    "    else:\n",
    "        # Return non-dict, non-list values as is\n",
    "        return data\n",
    "\n",
    "\n",
    "def read_and_trim_data(session_id_list, raw_export_dir, trimmed_export_dir):\n",
    "    \"\"\"\n",
    "    Reads complete data from JSON files, trims the data, and saves the trimmed data to new JSON files.\n",
    "    \"\"\"\n",
    "    os.makedirs(trimmed_export_dir, exist_ok=True)\n",
    "\n",
    "    for session_id in session_id_list:\n",
    "        try:\n",
    "            if session_id.startswith(\"da0a\"):\n",
    "                session_id = \"phi4_\" + session_id\n",
    "            # Read raw data\n",
    "            if \"tpsg\" in session_id:\n",
    "                session_id_ = session_id.replace(\"tpsg\", \"tpusg\")\n",
    "            else:\n",
    "                session_id_ = session_id\n",
    "            raw_path = os.path.join(raw_export_dir, f\"raw_{session_id_}.json\")\n",
    "            with open(raw_path, \"r\") as f:\n",
    "                data = json.load(f)\n",
    "\n",
    "            # Process and trim the data\n",
    "            trimmed_data = trim_data(data)\n",
    "\n",
    "            # If the entire data was filtered out (unlikely but possible)\n",
    "            if trimmed_data is None:\n",
    "                print(\n",
    "                    f\"All traces in session {session_id} were filtered due to fatal errors\"\n",
    "                )\n",
    "                continue\n",
    "\n",
    "            # Save trimmed data\n",
    "            if \"tpsg\" in session_id:\n",
    "                session_id_ = session_id.replace(\"tpsg\", \"tpusg\")\n",
    "            else:\n",
    "                session_id_ = session_id\n",
    "            trimmed_path = os.path.join(\n",
    "                trimmed_export_dir, f\"trimmed_{session_id_}.json\"\n",
    "            )\n",
    "            with open(trimmed_path, \"w\") as f:\n",
    "                json.dump(trimmed_data, f, indent=2)\n",
    "\n",
    "            print(\n",
    "                f\"Successfully processed and saved trimmed data for session {session_id}\"\n",
    "            )\n",
    "\n",
    "            # Optional: Verify trimming worked\n",
    "            # print(f\"Verifying trimmed data for session {session_id}...\")\n",
    "            # verify_trimming(trimmed_path)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing session {session_id}: {str(e)}\")\n",
    "\n",
    "\n",
    "def verify_trimming(trimmed_path):\n",
    "    \"\"\"\n",
    "    Verifies that the trimmed data doesn't contain unwanted keys.\n",
    "    \"\"\"\n",
    "    with open(trimmed_path, \"r\") as f:\n",
    "        trimmed_data = json.load(f)\n",
    "\n",
    "    unwanted_keys = [\n",
    "        \"release\",\n",
    "        \"version\",\n",
    "        \"user_id\",\n",
    "        \"public\",\n",
    "        \"html_path\",\n",
    "        \"scores\",\n",
    "        \"bookmarked\",\n",
    "        \"projectId\",\n",
    "        \"externalId\",\n",
    "        \"page\",\n",
    "        \"limit\",\n",
    "        \"total_pages\",\n",
    "        \"completionStartTime\",\n",
    "        \"metadata\",\n",
    "        \"usageDetails\",\n",
    "        \"timeToFirstToken\",\n",
    "        \"createdAt\",\n",
    "        \"completionTokens\",\n",
    "        \"promptTokens\",\n",
    "        \"projectId\",\n",
    "        \"unit\",\n",
    "        \"updatedAt\",\n",
    "        \"version\",\n",
    "        # \"statusMessage\",\n",
    "        \"parentObservationId\",\n",
    "        \"promptId\",\n",
    "        \"promptName\",\n",
    "        \"promptVersion\",\n",
    "        \"modelId\",\n",
    "        \"inputPrice\",\n",
    "        \"outputPrice\",\n",
    "        \"totalPrice\",\n",
    "        \"calculatedInputCost\",\n",
    "        \"calculatedOutputCost\",\n",
    "        \"calculatedTotalCost\",\n",
    "    ]\n",
    "\n",
    "    def check_keys(obj):\n",
    "        if isinstance(obj, dict):\n",
    "            for key in obj.keys():\n",
    "                if key in unwanted_keys:\n",
    "                    print(f\"Warning: Found unwanted key '{key}' in trimmed data\")\n",
    "            for value in obj.values():\n",
    "                check_keys(value)\n",
    "        elif isinstance(obj, list):\n",
    "            for item in obj:\n",
    "                check_keys(item)\n",
    "\n",
    "    check_keys(trimmed_data)\n",
    "    print(\"Verification complete\")\n",
    "\n",
    "\n",
    "# Usage example:\n",
    "read_and_trim_data(session_id_list, raw_export_dir, raw_export_dir)\n",
    "print(f\"Total {len(skipped_traces)} traces skipped. They are {skipped_traces}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Generate CSV files from JSON\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing session codestral_e6d3_tpusg_batch, simple id codestral_e6d3. Look for /Users/hann/Projects/reference-benchmark-tinyml_llm/data_analysis/2025/08.15/raw_export/trimmed_codestral_e6d3_tpusg_batch.json\n",
      "/Users/hann/Projects/reference-benchmark-tinyml_llm/data_analysis/2025/08.15/processed_data/codestral_e6d3/clean_codestral_e6d3_tpusg_batch.csv\n",
      "Successfully saved CSV to: /Users/hann/Projects/reference-benchmark-tinyml_llm/data_analysis/2025/08.15/processed_data/codestral_e6d3/clean_codestral_e6d3_tpusg_batch.csv\n",
      "Processing session codestral_e6d3_psg_batch, simple id codestral_e6d3. Look for /Users/hann/Projects/reference-benchmark-tinyml_llm/data_analysis/2025/08.15/raw_export/trimmed_codestral_e6d3_psg_batch.json\n",
      "/Users/hann/Projects/reference-benchmark-tinyml_llm/data_analysis/2025/08.15/processed_data/codestral_e6d3/clean_codestral_e6d3_psg_batch.csv\n",
      "Successfully saved CSV to: /Users/hann/Projects/reference-benchmark-tinyml_llm/data_analysis/2025/08.15/processed_data/codestral_e6d3/clean_codestral_e6d3_psg_batch.csv\n"
     ]
    }
   ],
   "source": [
    "import traceback\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from dateutil import parser\n",
    "\n",
    "\n",
    "def json_to_csv(session_id):\n",
    "    \"\"\"\n",
    "    Convert JSON trace data to CSV format with aggregated metrics.\n",
    "\n",
    "    Args:\n",
    "        session_id (str): Identifier for the session to process\n",
    "    \"\"\"\n",
    "\n",
    "    def extract_observation_details(observations, trace_id):\n",
    "        \"\"\"Extract and aggregate metrics from observations\"\"\"\n",
    "        metrics = {\n",
    "            \"status\": None,\n",
    "            \"latency\": 0,\n",
    "            \"total_tokens\": 0,\n",
    "            \"prompt_tokens\": 0,\n",
    "            \"completion_tokens\": 0,\n",
    "            \"total_cost\": 0,\n",
    "            \"input_cost\": 0,\n",
    "            \"output_cost\": 0,\n",
    "            \"parameters\": set(),\n",
    "        }\n",
    "\n",
    "        # Process GENERATION observations\n",
    "        for obs in (o for o in observations if o[\"type\"] == \"GENERATION\"):\n",
    "            metrics[\"total_tokens\"] += obs[\"totalTokens\"]\n",
    "            metrics[\"prompt_tokens\"] += obs[\"promptTokens\"]\n",
    "            metrics[\"completion_tokens\"] += obs[\"completionTokens\"]\n",
    "            metrics[\"latency\"] += obs[\"latency\"]\n",
    "            for key, value in obs[\"modelParameters\"].items():\n",
    "                metrics[\"parameters\"].add(key + \":\" + value)\n",
    "\n",
    "            # Add costs if present\n",
    "            for cost_type in [\"Total\", \"Input\", \"Output\"]:\n",
    "                key = f\"calculated{cost_type}Cost\"\n",
    "                metric_key = cost_type.lower() + \"_cost\"\n",
    "                if obs.get(key) is not None:\n",
    "                    metrics[metric_key] += obs[key]\n",
    "        if len(metrics[\"parameters\"]) == 0:\n",
    "            metrics[\"parameters\"] = \"N/A\"\n",
    "        # Process SPAN observations for status\n",
    "        status_indicators = [\n",
    "            obs[\"name\"]\n",
    "            for obs in observations\n",
    "            if obs[\"type\"] == \"SPAN\" and \"start_\" not in obs[\"name\"]\n",
    "        ]\n",
    "\n",
    "        #  if later than 2025-05-19, use status_signal_from_output\n",
    "        if datetime.now() > datetime(2025, 5, 19):\n",
    "            pass\n",
    "        else:\n",
    "            # Determine status\n",
    "            success_signals = sum(\"end_\" in name for name in status_indicators)\n",
    "            failure_signals = sum(\n",
    "                \"failure_signal\" in name for name in status_indicators\n",
    "            )\n",
    "\n",
    "            if success_signals + failure_signals > 1:\n",
    "                raise ValueError(\n",
    "                    f\"Multiple status indicators found in trace {trace_id}\"\n",
    "                )\n",
    "\n",
    "            metrics[\"status\"] = (\n",
    "                \"success\"\n",
    "                if success_signals\n",
    "                else \"failure\" if failure_signals else \"unknown\"\n",
    "            )\n",
    "\n",
    "        metrics[\"prompt_cost\"] = metrics.pop(\"input_cost\")\n",
    "        metrics[\"completion_cost\"] = metrics.pop(\"output_cost\")\n",
    "        metrics[\"latency\"] = round(metrics[\"latency\"] / 1000, 2)\n",
    "        return metrics\n",
    "\n",
    "    def cal_time(trace):\n",
    "        time_diff = datetime.fromisoformat(\n",
    "            trace[\"updatedAt\"].replace(\"Z\", \"+00:00\")\n",
    "        ) - datetime.fromisoformat(trace[\"createdAt\"].replace(\"Z\", \"+00:00\"))\n",
    "        seconds_diff = time_diff.total_seconds()\n",
    "        return seconds_diff\n",
    "\n",
    "    try:\n",
    "\n",
    "        if session_id.startswith(\"da0a\"):\n",
    "            session_id = \"phi4_\" + session_id\n",
    "        simple_session_id = session_id.rsplit(\"_\", 2)[0]\n",
    "\n",
    "        \n",
    "        # Load JSON data\n",
    "        if \"tpsg\" in session_id:\n",
    "                session_id_ = session_id.replace(\"tpsg\", \"tpusg\")\n",
    "        else:\n",
    "                session_id_ = session_id\n",
    "        trimmed_path = os.path.join(raw_export_dir, f\"trimmed_{session_id_}.json\")\n",
    "        print(\n",
    "            f\"Processing session {session_id}, simple id {simple_session_id}. Look for {trimmed_path}\"\n",
    "        )\n",
    "        with open(trimmed_path, \"r\") as file:\n",
    "            traces = json.load(file)[\"data\"]\n",
    "\n",
    "        # Process traces\n",
    "        rows = [\n",
    "            {\n",
    "                \"num_run\": trace[\"metadata\"][\"num_run\"],\n",
    "                \"name\": trace[\"name\"],\n",
    "                \"trace_id\": trace[\"id\"],\n",
    "                \"batch_id\": trace[\"session_id\"],\n",
    "                # \"latency\": cal_time(trace),\n",
    "                # \"latency\": round(trace[\"latency\"], 2),\n",
    "                **extract_observation_details(\n",
    "                    trace[\"observations\"],\n",
    "                    trace[\"id\"],\n",
    "                ),\n",
    "                \"status\": (\n",
    "                    \"failure\"\n",
    "                    if trace[\"output\"][\"status\"].lower() == \"failed\"\n",
    "                    else \"success\"\n",
    "                ),\n",
    "                \"tags\": trace[\"tags\"],\n",
    "                \"timestamp\": int(parser.isoparse(trace[\"timestamp\"]).timestamp()),\n",
    "            }\n",
    "            for trace in traces\n",
    "        ]\n",
    "        # print(rows)\n",
    "        # print(rows)\n",
    "        # Create and save DataFrame\n",
    "        df = pd.DataFrame(rows).sort_values(\"num_run\")\n",
    "\n",
    "        output_dir = os.path.join(processed_data_dir, f\"{simple_session_id}\")\n",
    "        if not os.path.exists(output_dir):\n",
    "            os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "        output_path = os.path.join(output_dir, f\"clean_{session_id_}.csv\")\n",
    "\n",
    "        print(output_path)\n",
    "        df.to_csv(output_path, index=False)\n",
    "        print(f\"Successfully saved CSV to: {output_path}\")\n",
    "\n",
    "    except FileNotFoundError as e:\n",
    "        print(\n",
    "            f\"FileNotFoundError: For session {session_id} not found. Looked for {trimmed_path}\\nError info: \\n{e}\\n\\nTraceback: {traceback.format_exc()}\"\n",
    "        )\n",
    "    except json.JSONDecodeError:\n",
    "        print(f\"Error: Invalid JSON format in input file for session {session_id}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing session {session_id}: {str(e)}\")\n",
    "\n",
    "\n",
    "# Example usage\n",
    "for session_id in session_id_list:\n",
    "    json_to_csv(session_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CSV Generation with Generation Counts\n",
    "\n",
    "This section creates CSV files similar to the langfuse_export section 3, but adds a column for the number of generation attempts used for each trace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing sessions: ['codestral_e6d3_psg_batch', 'codestral_e6d3_tpusg_batch']\n",
      "Looking for raw files in: /Users/hann/Projects/reference-benchmark-tinyml_llm/data_analysis/2025/08.15/raw_export\n",
      "Will save CSV files to: /Users/hann/Projects/reference-benchmark-tinyml_llm/data_analysis/2025/08.15/processed_data\n",
      "Processing session codestral_e6d3_psg_batch, simple id codestral_e6d3. Look for /Users/hann/Projects/reference-benchmark-tinyml_llm/data_analysis/2025/08.15/raw_export/trimmed_codestral_e6d3_psg_batch.json\n",
      "/Users/hann/Projects/reference-benchmark-tinyml_llm/data_analysis/2025/08.15/processed_data/codestral_e6d3/clean_codestral_e6d3_psg_batch.csv\n",
      "Successfully saved CSV to: /Users/hann/Projects/reference-benchmark-tinyml_llm/data_analysis/2025/08.15/processed_data/codestral_e6d3/clean_codestral_e6d3_psg_batch.csv\n",
      "Processing session codestral_e6d3_tpusg_batch, simple id codestral_e6d3. Look for /Users/hann/Projects/reference-benchmark-tinyml_llm/data_analysis/2025/08.15/raw_export/trimmed_codestral_e6d3_tpusg_batch.json\n",
      "/Users/hann/Projects/reference-benchmark-tinyml_llm/data_analysis/2025/08.15/processed_data/codestral_e6d3/clean_codestral_e6d3_tpusg_batch.csv\n",
      "Successfully saved CSV to: /Users/hann/Projects/reference-benchmark-tinyml_llm/data_analysis/2025/08.15/processed_data/codestral_e6d3/clean_codestral_e6d3_tpusg_batch.csv\n"
     ]
    }
   ],
   "source": [
    "import traceback\n",
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "from datetime import datetime\n",
    "from dateutil import parser\n",
    "\n",
    "# Setup paths - same as langfuse_export\n",
    "parent_dir = os.path.dirname(os.getcwd())\n",
    "raw_export_dir = os.path.join(parent_dir, \"raw_export\")\n",
    "processed_data_dir = os.path.join(parent_dir, \"processed_data\")\n",
    "\n",
    "\n",
    "# Get session id list from data directory\n",
    "session_id_list = []\n",
    "\n",
    "for root, dirs, files in os.walk(raw_export_dir):\n",
    "    for file in files:\n",
    "        file_path = os.path.join(root, file)\n",
    "        if \"trimmed_\" in file_path:\n",
    "            session_id = file_path.split('trimmed_')[1].rstrip('.json')\n",
    "            session_id_list.append(session_id)\n",
    "\n",
    "print(f\"Processing sessions: {session_id_list}\")\n",
    "print(f\"Looking for raw files in: {raw_export_dir}\")\n",
    "print(f\"Will save CSV files to: {processed_data_dir}\")\n",
    "\n",
    "\n",
    "def json_to_csv_weighted(session_id):\n",
    "    \"\"\"\n",
    "    Convert JSON trace data to CSV format with aggregated metrics.\n",
    "    Upgraded version that includes generation_count column.\n",
    "\n",
    "    Args:\n",
    "        session_id (str): Identifier for the session to process\n",
    "    \"\"\"\n",
    "\n",
    "    def extract_observation_details(observations, trace_id):\n",
    "        \"\"\"Extract and aggregate metrics from observations\"\"\"\n",
    "        metrics = {\n",
    "            \"status\": None,\n",
    "            \"latency\": 0,\n",
    "            \"total_tokens\": 0,\n",
    "            \"prompt_tokens\": 0,\n",
    "            \"completion_tokens\": 0,\n",
    "            \"total_cost\": 0,\n",
    "            \"input_cost\": 0,\n",
    "            \"output_cost\": 0,\n",
    "            \"parameters\": set(),\n",
    "            \"generation_count\": 0,  # New field for generation count\n",
    "        }\n",
    "\n",
    "        # Count generations and process GENERATION observations\n",
    "        for obs in (o for o in observations if o[\"type\"] == \"GENERATION\"):\n",
    "            metrics[\"generation_count\"] += 1\n",
    "            metrics[\"total_tokens\"] += obs[\"totalTokens\"]\n",
    "            metrics[\"prompt_tokens\"] += obs[\"promptTokens\"]\n",
    "            metrics[\"completion_tokens\"] += obs[\"completionTokens\"]\n",
    "            metrics[\"latency\"] += obs[\"latency\"]\n",
    "            for key, value in obs[\"modelParameters\"].items():\n",
    "                metrics[\"parameters\"].add(key + \":\" + value)\n",
    "\n",
    "            # Add costs if present\n",
    "            for cost_type in [\"Total\", \"Input\", \"Output\"]:\n",
    "                key = f\"calculated{cost_type}Cost\"\n",
    "                metric_key = cost_type.lower() + \"_cost\"\n",
    "                if obs.get(key) is not None:\n",
    "                    metrics[metric_key] += obs[key]\n",
    "                    \n",
    "        if len(metrics[\"parameters\"]) == 0:\n",
    "            metrics[\"parameters\"] = \"N/A\"\n",
    "            \n",
    "        # Process SPAN observations for status\n",
    "        status_indicators = [\n",
    "            obs[\"name\"]\n",
    "            for obs in observations\n",
    "            if obs[\"type\"] == \"SPAN\" and \"start_\" not in obs[\"name\"]\n",
    "        ]\n",
    "\n",
    "        #  if later than 2025-05-19, use status_signal_from_output\n",
    "        if datetime.now() > datetime(2025, 5, 19):\n",
    "            pass\n",
    "        else:\n",
    "            # Determine status\n",
    "            success_signals = sum(\"end_\" in name for name in status_indicators)\n",
    "            failure_signals = sum(\n",
    "                \"failure_signal\" in name for name in status_indicators\n",
    "            )\n",
    "\n",
    "            if success_signals + failure_signals > 1:\n",
    "                raise ValueError(\n",
    "                    f\"Multiple status indicators found in trace {trace_id}\"\n",
    "                )\n",
    "\n",
    "            metrics[\"status\"] = (\n",
    "                \"success\"\n",
    "                if success_signals\n",
    "                else \"failure\" if failure_signals else \"unknown\"\n",
    "            )\n",
    "\n",
    "        metrics[\"prompt_cost\"] = metrics.pop(\"input_cost\")\n",
    "        metrics[\"completion_cost\"] = metrics.pop(\"output_cost\")\n",
    "        metrics[\"latency\"] = round(metrics[\"latency\"] / 1000, 2)\n",
    "        return metrics\n",
    "\n",
    "    def cal_time(trace):\n",
    "        time_diff = datetime.fromisoformat(\n",
    "            trace[\"updatedAt\"].replace(\"Z\", \"+00:00\")\n",
    "        ) - datetime.fromisoformat(trace[\"createdAt\"].replace(\"Z\", \"+00:00\"))\n",
    "        seconds_diff = time_diff.total_seconds()\n",
    "        return seconds_diff\n",
    "\n",
    "    try:\n",
    "        if session_id.startswith(\"da0a\"):\n",
    "            session_id = \"phi4_\" + session_id\n",
    "        simple_session_id = session_id.rsplit(\"_\", 2)[0]\n",
    "\n",
    "        # Load JSON data\n",
    "        if \"tpsg\" in session_id:\n",
    "            session_id_ = session_id.replace(\"tpsg\", \"tpusg\")\n",
    "        else:\n",
    "            session_id_ = session_id\n",
    "        trimmed_path = os.path.join(raw_export_dir, f\"trimmed_{session_id_}.json\")\n",
    "        print(\n",
    "            f\"Processing session {session_id}, simple id {simple_session_id}. Look for {trimmed_path}\"\n",
    "        )\n",
    "        with open(trimmed_path, \"r\") as file:\n",
    "            traces = json.load(file)[\"data\"]\n",
    "\n",
    "        # Process traces\n",
    "        rows = [\n",
    "            {\n",
    "                \"num_run\": trace[\"metadata\"][\"num_run\"],\n",
    "                \"name\": trace[\"name\"],\n",
    "                \"trace_id\": trace[\"id\"],\n",
    "                \"batch_id\": trace[\"session_id\"],\n",
    "                # \"latency\": cal_time(trace),\n",
    "                # \"latency\": round(trace[\"latency\"], 2),\n",
    "                **extract_observation_details(\n",
    "                    trace[\"observations\"],\n",
    "                    trace[\"id\"],\n",
    "                ),\n",
    "                \"status\": (\n",
    "                    \"failure\"\n",
    "                    if trace[\"output\"][\"status\"].lower() == \"failed\"\n",
    "                    else \"success\"\n",
    "                ),\n",
    "                \"tags\": trace[\"tags\"],\n",
    "                \"timestamp\": int(parser.isoparse(trace[\"timestamp\"]).timestamp()),\n",
    "            }\n",
    "            for trace in traces\n",
    "        ]\n",
    "        \n",
    "        # Create and save DataFrame\n",
    "        df = pd.DataFrame(rows).sort_values(\"num_run\")\n",
    "\n",
    "        output_dir = os.path.join(processed_data_dir, f\"{simple_session_id}\")\n",
    "        if not os.path.exists(output_dir):\n",
    "            os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "        output_path = os.path.join(output_dir, f\"clean_{session_id_}.csv\")\n",
    "\n",
    "        print(output_path)\n",
    "        df.to_csv(output_path, index=False)\n",
    "        print(f\"Successfully saved CSV to: {output_path}\")\n",
    "\n",
    "    except FileNotFoundError as e:\n",
    "        print(\n",
    "            f\"FileNotFoundError: For session {session_id} not found. Looked for {trimmed_path}\\nError info: \\n{e}\\n\\nTraceback: {traceback.format_exc()}\"\n",
    "        )\n",
    "    except json.JSONDecodeError:\n",
    "        print(f\"Error: Invalid JSON format in input file for session {session_id}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing session {session_id}: {str(e)}\")\n",
    "\n",
    "\n",
    "\n",
    "# Example usage\n",
    "for session_id in session_id_list:\n",
    "    json_to_csv_weighted(session_id)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datasci2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

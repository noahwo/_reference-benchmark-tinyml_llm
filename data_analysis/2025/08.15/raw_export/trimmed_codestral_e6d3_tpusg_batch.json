{
  "data": [
    {
      "id": "604fa2cb",
      "timestamp": "2025-08-13T00:08:04.475000+00:00",
      "name": "604f_tpu_sketch_generator",
      "input": null,
      "output": {
        "status": "success",
        "sketch": "import cv2\nimport numpy as np\nfrom tflite_runtime.interpreter import load_delegate, Interpreter\n\n# Define paths\nlabel_path  = \"/home/mendel/tinyml_autopilot/models/labelmap.txt\"\nmodel_path  = \"/home/mendel/tinyml_autopilot/models/edgetpu_detect.tflite\"\ninput_path  = \"/home/mendel/tinyml_autopilot/data//sheeps.mp4\"\noutput_path  = \"/home/mendel/tinyml_autopilot/results/sheeps_detections.mp4\"\nconfidence_threshold  = 0.5\n\n# Load labels\nwith open(label_path, 'r') as f:\n    labels = [line.strip() for line in f.readlines()]\n\n# Load interpreter with EdgeTPU\ninterpreter = Interpreter(model_path=model_path, experimental_delegates=[load_delegate('/usr/lib/aarch64-linux-gnu/libedgetpu.so.1.0')])\ninterpreter.allocate_tensors()\n\n# Get model details\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\nheight = input_details[0]['shape'][1]\nwidth = input_details[0]['shape'][2]\nfloating_model = (input_details[0]['dtype'] == np.float32)\n\n# Input acquisition and preprocessing loop\ncap = cv2.VideoCapture(input_path)\nout_file = open(output_path, 'w')\n\nwhile cap.isOpened():\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    # Preprocess data\n    resized_frame = cv2.resize(frame, (width, height))\n    input_data = np.expand_dims(resized_frame, axis=0)\n\n    # Quantization handling\n    if floating_model:\n        input_data = (np.float32(input_data) - 127.5) / 127.5\n\n    # Inference\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n    interpreter.invoke()\n\n    # Output interpretation and handling\n    boxes = interpreter.get_tensor(output_details[0]['index'])[0]\n    classes = interpreter.get_tensor(output_details[1]['index'])[0]\n    scores = interpreter.get_tensor(output_details[2]['index'])[0]\n\n    for i in range(len(scores)):\n        if ((scores[i] > confidence_threshold) and (scores[i] <= 1.0)):\n            ymin = int(max(1, (boxes[i][0] * height)))\n            xmin = int(max(1, (boxes[i][1] * width)))\n            ymax = int(min(height, (boxes[i][2] * height)))\n            xmax = int(min(width, (boxes[i][3] * width)))\n\n            object_name = labels[int(classes[i])]\n            label = '%s: %d%%' % (object_name, int(scores[i]*100))\n            out_file.write('%s,%d,%d,%d,%d\\n' % (label, xmin, ymin, xmax, ymax))\n\n# Cleanup\ncap.release()\nout_file.close()"
      },
      "session_id": "codestral_e6d3_tpusg_batch",
      "metadata": {
        "num_run": 30
      },
      "tags": [
        "benchmark",
        "codestral:latest",
        "tpu_sketch_generator"
      ],
      "latency": 69.907,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-03-08-04-477811_chatcmpl-6f46a4c0-3eb4-4cb7-a6a0-9015b8dce38f",
          "traceId": "604fa2cb",
          "type": "GENERATION",
          "name": "604f_tpusg_gen_attempt#1",
          "startTime": "2025-08-13T00:08:04.477000+00:00",
          "endTime": "2025-08-13T00:08:23.640000+00:00",
          "model": "codestral:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 19163.0,
          "completionTokens": 1001,
          "environment": "default",
          "totalTokens": 3049,
          "promptTokens": 2048,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-03-08-31-401843_chatcmpl-a17572e9-9c98-4771-8062-4d6b0dcc1d6d",
          "traceId": "604fa2cb",
          "type": "GENERATION",
          "name": "604f_tpusg_gen_attempt#2",
          "startTime": "2025-08-13T00:08:31.401000+00:00",
          "endTime": "2025-08-13T00:08:48.170000+00:00",
          "model": "codestral:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 16769.0,
          "completionTokens": 870,
          "environment": "default",
          "totalTokens": 2918,
          "promptTokens": 2048,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-03-08-55-981491_chatcmpl-b91841d3-6116-4697-92dc-d6263d61a24b",
          "traceId": "604fa2cb",
          "type": "GENERATION",
          "name": "604f_tpusg_gen_attempt#3",
          "startTime": "2025-08-13T00:08:55.981000+00:00",
          "endTime": "2025-08-13T00:09:14.384000+00:00",
          "model": "codestral:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 18403.0,
          "completionTokens": 962,
          "environment": "default",
          "totalTokens": 3010,
          "promptTokens": 2048,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        }
      ],
      "createdAt": "2025-08-13T00:08:04.998Z",
      "updatedAt": "2025-08-13T00:10:18.213Z",
      "environment": "default"
    },
    {
      "id": "e6c68b2b",
      "timestamp": "2025-08-13T00:05:49.852000+00:00",
      "name": "e6c6_tpu_sketch_generator",
      "input": null,
      "output": {
        "status": "success",
        "sketch": "import cv2\nimport numpy as np\nfrom pycoral.adapters import common\nfrom pycoral.utils.edgetpu import make_interpreter\n\n# Define paths and thresholds\nlabel_path  = \"/home/mendel/tinyml_autopilot/models/labelmap.txt\"\ninput_path  = \"/home/mendel/tinyml_autopilot/data//sheeps.mp4\"\noutput_path  = \"/home/mendel/tinyml_autopilot/results/sheeps_detections.mp4\"\nconfidence_threshold  = 0.5\nmodel_path  = \"/home/mendel/tinyml_autopilot/models/edgetpu_detect.tflite\"\n\n# Load labels\nwith open(label_path, 'r') as f:\n    labels = [line.strip() for line in f.readlines()]\n\n# Load interpreter with EdgeTPU\ninterpreter = make_interpreter(model_path)\ninterpreter.allocate_tensors()\n\n# Get model details\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\nheight = input_details[0]['shape'][1]\nwidth = input_details[0]['shape'][2]\nfloating_model = (input_details[0]['dtype'] == np.float32)\n\n# Input acquisition and preprocessing loop\ncap = cv2.VideoCapture(input_path)\nout = cv2.VideoWriter(output_path, cv2.VideoWriter_fourcc(*'XVID'), 30.0, (width, height))\n\nwhile cap.isOpened():\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    # Preprocess data\n    resized_frame = cv2.resize(frame, (width, height))\n    input_data = np.expand_dims(resized_frame, axis=0)\n\n    # Quantization handling\n    if floating_model:\n        input_data = (np.float32(input_data) - 127.5) / 127.5\n\n    # Inference\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n    interpreter.invoke()\n\n    # Output interpretation and handling\n    boxes = interpreter.get_tensor(output_details[0]['index'])[0]\n    classes = interpreter.get_tensor(output_details[1]['index'])[0]\n    scores = interpreter.get_tensor(output_details[2]['index'])[0]\n\n    for i in range(len(scores)):\n        if ((scores[i] > confidence_threshold) and (scores[i] <= 1.0)):\n            ymin = int(max(1, (boxes[i][0] * height)))\n            xmin = int(max(1, (boxes[i][1] * width)))\n            ymax = int(min(height, (boxes[i][2] * height)))\n            xmax = int(min(width, (boxes[i][3] * width)))\n\n            cv2.rectangle(frame, (xmin, ymin), (xmax, ymax), (10, 255, 0), 4)\n            object_name = labels[int(classes[i])]\n            label = '%s: %d%%' % (object_name, int(scores[i]*100))\n            labelSize, baseLine = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.7, 2)\n            label_ymin = max(ymin, labelSize[1] + 10)\n            cv2.rectangle(frame, (xmin, label_ymin - labelSize[1]), (xmin + labelSize[0], label_ymin + baseLine), (255, 255, 255), cv2.FILLED)\n            cv2.putText(frame, label, (xmin, label_ymin - 7), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 0), 2)\n\n    out.write(frame)\n\ncap.release()\nout.release()\ncv2.destroyAllWindows()"
      },
      "session_id": "codestral_e6d3_tpusg_batch",
      "metadata": {
        "num_run": 29
      },
      "tags": [
        "benchmark",
        "codestral:latest",
        "tpu_sketch_generator"
      ],
      "latency": 78.666,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-03-05-49-854001_chatcmpl-349d4d2f-4ca1-4fab-a5a9-396d710afdc5",
          "traceId": "e6c68b2b",
          "type": "GENERATION",
          "name": "e6c6_tpusg_gen_attempt#1",
          "startTime": "2025-08-13T00:05:49.854000+00:00",
          "endTime": "2025-08-13T00:06:09.022000+00:00",
          "model": "codestral:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 19168.0,
          "completionTokens": 1001,
          "environment": "default",
          "totalTokens": 3049,
          "promptTokens": 2048,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-03-06-17-125456_chatcmpl-f9a0f0f1-b4a8-4d39-9217-fd1202265709",
          "traceId": "e6c68b2b",
          "type": "GENERATION",
          "name": "e6c6_tpusg_gen_attempt#2",
          "startTime": "2025-08-13T00:06:17.125000+00:00",
          "endTime": "2025-08-13T00:06:38.493000+00:00",
          "model": "codestral:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 21368.0,
          "completionTokens": 1128,
          "environment": "default",
          "totalTokens": 3176,
          "promptTokens": 2048,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-03-06-46-645764_chatcmpl-351049fe-764d-4c05-94c8-8f5c951da718",
          "traceId": "e6c68b2b",
          "type": "GENERATION",
          "name": "e6c6_tpusg_gen_attempt#3",
          "startTime": "2025-08-13T00:06:46.645000+00:00",
          "endTime": "2025-08-13T00:07:08.520000+00:00",
          "model": "codestral:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 21875.0,
          "completionTokens": 1157,
          "environment": "default",
          "totalTokens": 3205,
          "promptTokens": 2048,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        }
      ],
      "createdAt": "2025-08-13T00:05:50.372Z",
      "updatedAt": "2025-08-13T00:08:12.612Z",
      "environment": "default"
    },
    {
      "id": "3a97fc61",
      "timestamp": "2025-08-13T00:03:19.158000+00:00",
      "name": "3a97_tpu_sketch_generator",
      "input": null,
      "output": {
        "status": "success",
        "sketch": "import cv2\nimport numpy as np\nfrom tflite_runtime.interpreter import Interpreter\nfrom tflite_runtime.interpreter import load_delegate\n\n# Define label path\nlabel_path  = \"/home/mendel/tinyml_autopilot/models/labelmap.txt\"\n\n# Load labels\nwith open(label_path, 'r') as f:\n    labels = [line.strip() for line in f.readlines()]\n\n# Define other paths and parameters\nmodel_path  = \"/home/mendel/tinyml_autopilot/models/edgetpu_detect.tflite\"\ninput_path  = \"/home/mendel/tinyml_autopilot/data//sheeps.mp4\"\noutput_path  = \"/home/mendel/tinyml_autopilot/results/sheeps_detections.mp4\"\nconfidence_threshold  = 0.5\n\n# Load interpreter with EdgeTPU\ninterpreter = Interpreter(model_path=model_path, experimental_delegates=[load_delegate('/usr/lib/aarch64-linux-gnu/libedgetpu.so.1.0')])\ninterpreter.allocate_tensors()\n\n# Get model details\ninput_details = interpreter.get_input_details()[0]\noutput_details = interpreter.get_output_details()\nheight = input_details['shape'][1]\nwidth = input_details['shape'][2]\nfloating_model = (input_details['dtype'] == np.float32)\n\n# Input acquisition and preprocessing loop\ncap = cv2.VideoCapture(input_path)\nout_file = open(output_path, 'w')\n\nwhile cap.isOpened():\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    # Preprocess data\n    resized_frame = cv2.resize(frame, (width, height))\n    input_data = np.expand_dims(resized_frame, axis=0)\n\n    # Quantization handling\n    if floating_model:\n        input_data = (np.float32(input_data) - 127.5) / 127.5\n\n    # Inference\n    interpreter.set_tensor(input_details['index'], input_data)\n    interpreter.invoke()\n\n    # Output interpretation and handling\n    boxes = interpreter.get_tensor(output_details[0]['index'])[0]\n    classes = interpreter.get_tensor(output_details[1]['index'])[0]\n    scores = interpreter.get_tensor(output_details[2]['index'])[0]\n\n    for i in range(len(scores)):\n        if ((scores[i] > confidence_threshold) and (scores[i] <= 1.0)):\n            ymin = int(max(1, (boxes[i][0] * height)))\n            xmin = int(max(1, (boxes[i][1] * width)))\n            ymax = int(min(height, (boxes[i][2] * height)))\n            xmax = int(min(width, (boxes[i][3] * width)))\n\n            object_name = labels[int(classes[i])]\n            label = '%s: %d%%' % (object_name, int(scores[i]*100))\n            out_file.write('%s,%d,%d,%d,%d\\n' % (label, xmin, ymin, xmax, ymax))\n\n# Cleanup\ncap.release()\nout_file.close()"
      },
      "session_id": "codestral_e6d3_tpusg_batch",
      "metadata": {
        "num_run": 28
      },
      "tags": [
        "benchmark",
        "codestral:latest",
        "tpu_sketch_generator"
      ],
      "latency": 96.681,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-03-03-19-160140_chatcmpl-e796e460-dd8f-4205-9867-f47d04486e8c",
          "traceId": "3a97fc61",
          "type": "GENERATION",
          "name": "3a97_tpusg_gen_attempt#1",
          "startTime": "2025-08-13T00:03:19.160000+00:00",
          "endTime": "2025-08-13T00:03:38.351000+00:00",
          "model": "codestral:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 19191.0,
          "completionTokens": 1001,
          "environment": "default",
          "totalTokens": 3049,
          "promptTokens": 2048,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-03-03-46-134638_chatcmpl-80c15b2c-7f40-4c61-bac9-c2b548128ffb",
          "traceId": "3a97fc61",
          "type": "GENERATION",
          "name": "3a97_tpusg_gen_attempt#2",
          "startTime": "2025-08-13T00:03:46.134000+00:00",
          "endTime": "2025-08-13T00:04:03.110000+00:00",
          "model": "codestral:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 16976.0,
          "completionTokens": 881,
          "environment": "default",
          "totalTokens": 2929,
          "promptTokens": 2048,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-03-04-10-981141_chatcmpl-62de8e30-7179-4105-9e39-9f27a512eda9",
          "traceId": "3a97fc61",
          "type": "GENERATION",
          "name": "3a97_tpusg_gen_attempt#3",
          "startTime": "2025-08-13T00:04:10.981000+00:00",
          "endTime": "2025-08-13T00:04:28.604000+00:00",
          "model": "codestral:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 17623.0,
          "completionTokens": 917,
          "environment": "default",
          "totalTokens": 2965,
          "promptTokens": 2048,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-03-04-36-418563_chatcmpl-ef338135-5fe1-4ff3-9236-63ab375a8e92",
          "traceId": "3a97fc61",
          "type": "GENERATION",
          "name": "3a97_tpusg_gen_attempt#4",
          "startTime": "2025-08-13T00:04:36.418000+00:00",
          "endTime": "2025-08-13T00:04:55.841000+00:00",
          "model": "codestral:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 19423.0,
          "completionTokens": 1019,
          "environment": "default",
          "totalTokens": 3067,
          "promptTokens": 2048,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        }
      ],
      "createdAt": "2025-08-13T00:03:19.691Z",
      "updatedAt": "2025-08-13T00:05:59.456Z",
      "environment": "default"
    },
    {
      "id": "19790f0a",
      "timestamp": "2025-08-13T00:02:18.713000+00:00",
      "name": "1979_tpu_sketch_generator",
      "input": null,
      "output": {
        "status": "failed",
        "last_code": "import cv2\nimport numpy as np\nfrom tensorflow.lite import Interpreter\nfrom tensorflow.lite.experimental import load_delegate\n\n# Define paths and parameters\nmodel_path  = \"/home/mendel/tinyml_autopilot/models/edgetpu_detect.tflite\"\ninput_path  = \"/home/mendel/tinyml_autopilot/data//sheeps.mp4\"\nlabel_path  = \"/home/mendel/tinyml_autopilot/models/labelmap.txt\"\noutput_path  = \"/home/mendel/tinyml_autopilot/results/sheeps_detections.mp4\"\nconfidence_threshold  = 0.5\n\n# Load labels\nwith open(label_path, 'r') as f:\n    labels = [line.strip() for line in f.readlines()]\n\n# Load interpreter with EdgeTPU\ninterpreter = Interpreter(model_path=model_path, experimental_delegates=[load_delegate('/usr/lib/aarch64-linux-gnu/libedgetpu.so.1.0')])\ninterpreter.allocate_tensors()\n\n# Get model details\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\nheight = input_details[0]['shape'][1]\nwidth = input_details[0]['shape'][2]\nfloating_model = (input_details[0]['dtype'] == np.float32)\n\n# Input acquisition and preprocessing loop\ncap = cv2.VideoCapture(input_path)\nout = cv2.VideoWriter(output_path, cv2.VideoWriter_fourcc(*'XVID'), 30.0, (width, height))\n\nwhile cap.isOpened():\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    # Preprocess data\n    resized_frame = cv2.resize(frame, (width, height))\n    input_data = np.expand_dims(resized_frame, axis=0)\n\n    # Quantization handling\n    if floating_model:\n        input_data = (np.float32(input_data) - 127.5) / 127.5\n\n    # Inference\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n    interpreter.invoke()\n\n    # Output interpretation and handling\n    boxes = interpreter.get_tensor(output_details[0]['index'])[0]\n    classes = interpreter.get_tensor(output_details[1]['index'])[0]\n    scores = interpreter.get_tensor(output_details[2]['index'])[0]\n\n    for i in range(len(scores)):\n        if ((scores[i] > confidence_threshold) and (scores[i] <= 1.0)):\n            ymin = int(max(1, (boxes[i][0] * height)))\n            xmin = int(max(1, (boxes[i][1] * width)))\n            ymax = int(min(height, (boxes[i][2] * height)))\n            xmax = int(min(width, (boxes[i][3] * width)))\n\n            cv2.rectangle(frame, (xmin, ymin), (xmax, ymax), (10, 255, 0), 4)\n            object_name = labels[int(classes[i])]\n            label = '%s: %d%%' % (object_name, int(scores[i]*100))\n            labelSize, baseLine = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.7, 2)\n            label_ymin = max(ymin, labelSize[1] + 10)\n            cv2.rectangle(frame, (xmin, label_ymin-labelSize[1]-10), (xmin+labelSize[0], label_ymin+baseLine-10), (255, 255, 255), cv2.FILLED)\n            cv2.putText(frame, label, (xmin, label_ymin-7), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 0), 2)\n\n    out.write(frame)\n\n# Cleanup\ncap.release()\nout.release()\ncv2.destroyAllWindows()",
        "last_error": "Unexpected error during generation: The output is not a valid code block. Follow the instructions in the prompt return a complete, correct Python script enclosed in a single ```python\n<generated_code>\n``` block."
      },
      "session_id": "codestral_e6d3_tpusg_batch",
      "metadata": {
        "num_run": 27
      },
      "tags": [
        "benchmark",
        "codestral:latest",
        "tpu_sketch_generator"
      ],
      "latency": 53.419,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-03-02-18-716835_chatcmpl-7ad3d47f-368b-4883-b7c7-ca6589f4d753",
          "traceId": "19790f0a",
          "type": "GENERATION",
          "name": "1979_tpusg_gen_attempt#1",
          "startTime": "2025-08-13T00:02:18.716000+00:00",
          "endTime": "2025-08-13T00:02:37.907000+00:00",
          "model": "codestral:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 19191.0,
          "completionTokens": 1001,
          "environment": "default",
          "totalTokens": 3049,
          "promptTokens": 2048,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-03-02-45-862775_chatcmpl-00aca84b-9b75-4a1d-b284-c837ed0b8264",
          "traceId": "19790f0a",
          "type": "GENERATION",
          "name": "1979_tpusg_gen_attempt#2",
          "startTime": "2025-08-13T00:02:45.862000+00:00",
          "endTime": "2025-08-13T00:02:50.514000+00:00",
          "model": "codestral:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 4652.0,
          "completionTokens": 186,
          "environment": "default",
          "totalTokens": 2234,
          "promptTokens": 2048,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-03-02-50-522665_chatcmpl-0079d9e8-e0e6-4b46-a3b8-255d714f383b",
          "traceId": "19790f0a",
          "type": "GENERATION",
          "name": "1979_tpusg_gen_attempt#3",
          "startTime": "2025-08-13T00:02:50.522000+00:00",
          "endTime": "2025-08-13T00:02:57.703000+00:00",
          "model": "codestral:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 7181.0,
          "completionTokens": 330,
          "environment": "default",
          "totalTokens": 2378,
          "promptTokens": 2048,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-03-02-57-709961_chatcmpl-4e6d6e92-e804-4b40-86c6-e4384347b514",
          "traceId": "19790f0a",
          "type": "GENERATION",
          "name": "1979_tpusg_gen_attempt#4",
          "startTime": "2025-08-13T00:02:57.709000+00:00",
          "endTime": "2025-08-13T00:03:04.919000+00:00",
          "model": "codestral:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 7210.0,
          "completionTokens": 332,
          "environment": "default",
          "totalTokens": 2380,
          "promptTokens": 2048,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-03-03-04-922157_chatcmpl-51ad9054-86e8-4a53-9516-26a14499a2da",
          "traceId": "19790f0a",
          "type": "GENERATION",
          "name": "1979_tpusg_gen_attempt#5",
          "startTime": "2025-08-13T00:03:04.922000+00:00",
          "endTime": "2025-08-13T00:03:12.130000+00:00",
          "model": "codestral:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 7208.0,
          "completionTokens": 332,
          "environment": "default",
          "totalTokens": 2380,
          "promptTokens": 2048,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "91911a59-f720-4a07-ae96-5775406cf5aa",
          "traceId": "19790f0a",
          "type": "SPAN",
          "name": "error_19_tpusg_failure_signal_tpu_sketch_generator",
          "startTime": "2025-08-13T00:03:12.135000+00:00",
          "level": "ERROR",
          "statusMessage": "Failed. Last error: Unexpected error during generation: The output is not a valid code block. Follow the instructions in the prompt return a complete, correct Python script enclosed in a single ```python\n<generated_code>\n``` block.",
          "calculatedTotalCost": 0.0,
          "completionTokens": 0,
          "environment": "default",
          "totalTokens": 0,
          "promptTokens": 0,
          "costDetails": {},
          "endTime": null,
          "model": null,
          "modelParameters": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null,
          "latency": null
        }
      ],
      "createdAt": "2025-08-13T00:02:19.233Z",
      "updatedAt": "2025-08-13T00:03:28.039Z",
      "environment": "default"
    },
    {
      "id": "b42f9c07",
      "timestamp": "2025-08-13T00:00:22.070000+00:00",
      "name": "b42f_tpu_sketch_generator",
      "input": null,
      "output": {
        "status": "failed",
        "last_code": "import numpy as np\nimport cv2\nimport tflite\nfrom tflite_runtime.interpreter import Interpreter\n\n# Load labels\nwith open(label_path, 'r') as f:\n    labels = [line.strip() for line in f.readlines()]\n\n# Load TFLite model and allocate tensors.\ninterpreter = Interpreter(model_path=model_path)\ninterpreter.allocate_tensors()\n\n# Get input and output details\ninput_details  = \"/home/mendel/tinyml_autopilot/data//sheeps.mp4\"\noutput_details  = \"/home/mendel/tinyml_autopilot/results/sheeps_detections.mp4\"\nheight = input_details[0]['shape'][1]\nwidth = input_details[0]['shape'][2]\nfloating_model = (input_details[0]['dtype'] == np.float32)\n\n# Input acquisition and preprocessing loop\ncap = cv2.VideoCapture(input_path)\nwhile cap.isOpened():\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    # Preprocess data\n    resized_frame = cv2.resize(frame, (width, height))\n    input_data = np.expand_dims(resized_frame, axis=0)\n\n    # Quantization handling\n    if floating_model:\n        input_data = (np.float32(input_data) - 127.5) / 127.5\n\n    # Inference\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n    interpreter.invoke()\n\n    # Output interpretation and handling\n    boxes = interpreter.get_tensor(output_details[0]['index'])[0]\n    classes = interpreter.get_tensor(output_details[1]['index'])[0]\n    scores = interpreter.get_tensor(output_details[2]['index'])[0]\n\n    for i in range(len(scores)):\n        if ((scores[i] > confidence_threshold) and (scores[i] <= 1.0)):\n            object_name = labels[int(classes[i])]\n            print('Detected:', object_name, 'with a score of:', scores[i])",
        "last_error": "Traceback (most recent call last):\n  File \"script_d8568010_1755043323.py\", line 3, in <module>\n    import tflite\nModuleNotFoundError: No module named 'tflite'"
      },
      "session_id": "codestral_e6d3_tpusg_batch",
      "metadata": {
        "num_run": 26
      },
      "tags": [
        "benchmark",
        "codestral:latest",
        "tpu_sketch_generator"
      ],
      "latency": 108.766,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-03-00-22-072750_chatcmpl-aba5d9f5-448e-4b4d-9a6f-8a851c8bdf38",
          "traceId": "b42f9c07",
          "type": "GENERATION",
          "name": "b42f_tpusg_gen_attempt#1",
          "startTime": "2025-08-13T00:00:22.072000+00:00",
          "endTime": "2025-08-13T00:00:41.241000+00:00",
          "model": "codestral:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 19169.0,
          "completionTokens": 1001,
          "environment": "default",
          "totalTokens": 3049,
          "promptTokens": 2048,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-03-00-49-043550_chatcmpl-8c737830-e716-405e-a8da-b2c8faa1dafb",
          "traceId": "b42f9c07",
          "type": "GENERATION",
          "name": "b42f_tpusg_gen_attempt#2",
          "startTime": "2025-08-13T00:00:49.043000+00:00",
          "endTime": "2025-08-13T00:01:04.531000+00:00",
          "model": "codestral:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 15488.0,
          "completionTokens": 796,
          "environment": "default",
          "totalTokens": 2844,
          "promptTokens": 2048,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-03-01-09-049694_chatcmpl-eca7881e-1ea5-48da-99b0-b53f446507eb",
          "traceId": "b42f9c07",
          "type": "GENERATION",
          "name": "b42f_tpusg_gen_attempt#3",
          "startTime": "2025-08-13T00:01:09.049000+00:00",
          "endTime": "2025-08-13T00:01:23.163000+00:00",
          "model": "codestral:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 14114.0,
          "completionTokens": 718,
          "environment": "default",
          "totalTokens": 2766,
          "promptTokens": 2048,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-03-01-30-656683_chatcmpl-c342bf6b-44dc-4bb7-baa1-4afcf2bea002",
          "traceId": "b42f9c07",
          "type": "GENERATION",
          "name": "b42f_tpusg_gen_attempt#4",
          "startTime": "2025-08-13T00:01:30.656000+00:00",
          "endTime": "2025-08-13T00:01:42.951000+00:00",
          "model": "codestral:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 12295.0,
          "completionTokens": 617,
          "environment": "default",
          "totalTokens": 2665,
          "promptTokens": 2048,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-03-01-50-532480_chatcmpl-02ddef21-19ea-4e64-b895-9728b4d88441",
          "traceId": "b42f9c07",
          "type": "GENERATION",
          "name": "b42f_tpusg_gen_attempt#5",
          "startTime": "2025-08-13T00:01:50.532000+00:00",
          "endTime": "2025-08-13T00:02:03.025000+00:00",
          "model": "codestral:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 12493.0,
          "completionTokens": 628,
          "environment": "default",
          "totalTokens": 2676,
          "promptTokens": 2048,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "6e36eaaf-ffb1-4b2b-87e8-c7a187345a10",
          "traceId": "b42f9c07",
          "type": "SPAN",
          "name": "error_b4_tpusg_failure_signal_tpu_sketch_generator",
          "startTime": "2025-08-13T00:02:10.838000+00:00",
          "level": "ERROR",
          "statusMessage": "Failed. Last error: Traceback (most recent call last):\n  File \"script_d8568010_1755043323.py\", line 3, in <module>\n    import tflite\nModuleNotFoundError: No module named 'tflite'",
          "calculatedTotalCost": 0.0,
          "completionTokens": 0,
          "environment": "default",
          "totalTokens": 0,
          "promptTokens": 0,
          "costDetails": {},
          "endTime": null,
          "model": null,
          "modelParameters": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null,
          "latency": null
        }
      ],
      "createdAt": "2025-08-13T00:00:22.591Z",
      "updatedAt": "2025-08-13T00:02:26.829Z",
      "environment": "default"
    },
    {
      "id": "77f078d2",
      "timestamp": "2025-08-12T23:58:31.347000+00:00",
      "name": "77f0_tpu_sketch_generator",
      "input": null,
      "output": {
        "status": "failed",
        "last_code": "import cv2\nfrom pycoral.adapters import common\nfrom pycoral.adapters import detect\nfrom pycoral.utils.edgetpu import make_interpreter\nfrom pycoral.utils.dataset import read_label_file\n\n# Replace 'path/to/labels.txt' with the correct path to your labels file\nlabels = read_label_file('path/to/your/labels.txt')\n\n# Replace 'path/to/model.tflite' with the correct path to your model file\ninterpreter = make_interpreter('path/to/your/model.tflite')\ninterpreter.allocate_tensors()\n\n# Open the video capture device (0 is usually the default camera)\ncap = cv2.VideoCapture(0)\n\nwhile True:\n    # Read a frame from the camera\n    ret, frame = cap.read()\n\n    # Convert the frame to RGB and resize it to 300x300 (the input size expected by the model)\n    cv2_im = frame.copy()\n    cv2_im = cv2.cvtColor(cv2_im, cv2.COLOR_BGR2RGB)\n    cv2_im = cv2.resize(cv2_im, (300, 300))\n\n    # Preprocess the image for the model\n    common.set_input(interpreter, cv2_im)\n\n    # Run inference on the input data\n    interpreter.invoke()\n\n    # Get the output from the model\n    result = detect.get_objects(interpreter, 0.5, scale=1.0)\n\n    # Draw bounding boxes and labels on the frame\n    for obj in result:\n        bbox = obj.bbox\n        xmin, ymin, width, height = int(bbox.xmin * frame.shape[1]), int(bbox.ymin * frame.shape[0]), int(bbox.width * frame.shape[1]), int(bbox.height * frame.shape[0])\n        cv2.rectangle(frame, (xmin, ymin), (xmin + width, ymin + height), (0, 255, 0), 2)\n        label = labels.get(obj.id, obj.id)\n        cv2.putText(frame, f'{label}: {obj.score:.2f}', (xmin, ymin - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n\n    # Display the frame with bounding boxes and labels\n    cv2.imshow('Object Detection', frame)\n\n    # Break the loop if 'q' is pressed\n    if cv2.waitKey(1) & 0xFF == ord('q'):\n        break\n\n# Release the video capture device and close all windows\ncap.release()\ncv2.destroyAllWindows()",
        "last_error": "Traceback (most recent call last):\n  File \"script_1eb423a4_1755043206.py\", line 8, in <module>\n    labels = read_label_file('path/to/your/labels.txt')\n  File \"/home/mendel/tinyml_autopilot/tinyml-env/lib/python3.7/site-packages/pycoral/utils/dataset.py\", line 36, in read_label_file\n    with open(file_path, 'r', encoding='utf-8') as f:\nFileNotFoundError: [Errno 2] No such file or directory: 'path/to/your/labels.txt'"
      },
      "session_id": "codestral_e6d3_tpusg_batch",
      "metadata": {
        "num_run": 25
      },
      "tags": [
        "benchmark",
        "codestral:latest",
        "tpu_sketch_generator"
      ],
      "latency": 102.976,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-02-58-31-349572_chatcmpl-9c644804-f2f9-45c5-a260-e706346f56fb",
          "traceId": "77f078d2",
          "type": "GENERATION",
          "name": "77f0_tpusg_gen_attempt#1",
          "startTime": "2025-08-12T23:58:31.349000+00:00",
          "endTime": "2025-08-12T23:58:50.569000+00:00",
          "model": "codestral:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 19220.0,
          "completionTokens": 1001,
          "environment": "default",
          "totalTokens": 3049,
          "promptTokens": 2048,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-02-58-58-351668_chatcmpl-b7582fdf-6cbe-4798-9461-d0d88241e93a",
          "traceId": "77f078d2",
          "type": "GENERATION",
          "name": "77f0_tpusg_gen_attempt#2",
          "startTime": "2025-08-12T23:58:58.351000+00:00",
          "endTime": "2025-08-12T23:59:03.014000+00:00",
          "model": "codestral:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 4663.0,
          "completionTokens": 183,
          "environment": "default",
          "totalTokens": 2231,
          "promptTokens": 2048,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-02-59-03-021304_chatcmpl-b12fccc7-491f-44d6-83ac-21f4e56a2e98",
          "traceId": "77f078d2",
          "type": "GENERATION",
          "name": "77f0_tpusg_gen_attempt#3",
          "startTime": "2025-08-12T23:59:03.021000+00:00",
          "endTime": "2025-08-12T23:59:18.612000+00:00",
          "model": "codestral:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 15591.0,
          "completionTokens": 803,
          "environment": "default",
          "totalTokens": 2851,
          "promptTokens": 2048,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-02-59-26-883666_chatcmpl-b9e48499-d8e7-456b-b026-1ee20f65d445",
          "traceId": "77f078d2",
          "type": "GENERATION",
          "name": "77f0_tpusg_gen_attempt#4",
          "startTime": "2025-08-12T23:59:26.883000+00:00",
          "endTime": "2025-08-12T23:59:42.632000+00:00",
          "model": "codestral:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 15749.0,
          "completionTokens": 812,
          "environment": "default",
          "totalTokens": 2860,
          "promptTokens": 2048,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-02-59-50-825786_chatcmpl-e4804f42-657d-41e7-a7d4-e3e5e8a14f4d",
          "traceId": "77f078d2",
          "type": "GENERATION",
          "name": "77f0_tpusg_gen_attempt#5",
          "startTime": "2025-08-12T23:59:50.825000+00:00",
          "endTime": "2025-08-13T00:00:06.101000+00:00",
          "model": "codestral:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 15276.0,
          "completionTokens": 785,
          "environment": "default",
          "totalTokens": 2833,
          "promptTokens": 2048,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "be3a850f-c069-40a7-b3d8-8614d6ff61b2",
          "traceId": "77f078d2",
          "type": "SPAN",
          "name": "error_77_tpusg_failure_signal_tpu_sketch_generator",
          "startTime": "2025-08-13T00:00:14.325000+00:00",
          "level": "ERROR",
          "statusMessage": "Failed. Last error: Traceback (most recent call last):\n  File \"script_1eb423a4_1755043206.py\", line 8, in <module>\n    labels = read_label_file('path/to/your/labels.txt')\n  File \"/home/mendel/tinyml_autopilot/tinyml-env/lib/python3.7/site-packages/pycoral/utils/dataset.py\", line 36, in read_label_file\n    with open(file_path, 'r', encoding='utf-8') as f:\nFileNotFoundError: [Errno 2] No such file or directory: 'path/to/your/labels.txt'",
          "calculatedTotalCost": 0.0,
          "completionTokens": 0,
          "environment": "default",
          "totalTokens": 0,
          "promptTokens": 0,
          "costDetails": {},
          "endTime": null,
          "model": null,
          "modelParameters": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null,
          "latency": null
        }
      ],
      "createdAt": "2025-08-12T23:58:31.869Z",
      "updatedAt": "2025-08-13T00:00:29.623Z",
      "environment": "default"
    },
    {
      "id": "6dc18df5",
      "timestamp": "2025-08-12T23:57:32.798000+00:00",
      "name": "6dc1_tpu_sketch_generator",
      "input": null,
      "output": {
        "status": "failed",
        "last_code": "import cv2\nimport numpy as np\nfrom tensorflow.lite import Interpreter\nfrom tensorflow.lite.experimental import load_delegate\n\n# Define paths and parameters\nmodel_path  = \"/home/mendel/tinyml_autopilot/models/edgetpu_detect.tflite\"\ninput_path  = \"/home/mendel/tinyml_autopilot/data//sheeps.mp4\"\nlabel_path  = \"/home/mendel/tinyml_autopilot/models/labelmap.txt\"\noutput_path  = \"/home/mendel/tinyml_autopilot/results/sheeps_detections.mp4\"\nconfidence_threshold  = 0.5\n\n# Load labels\nwith open(label_path, 'r') as f:\n    labels = [line.strip() for line in f.readlines()]\n\n# Load interpreter with EdgeTPU\ninterpreter = Interpreter(model_path=model_path, experimental_delegates=[load_delegate('/usr/lib/aarch64-linux-gnu/libedgetpu.so.1.0')])\ninterpreter.allocate_tensors()\n\n# Get model details\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\nheight = input_details[0]['shape'][1]\nwidth = input_details[0]['shape'][2]\nfloating_model = (input_details[0]['dtype'] == np.float32)\n\n# Input acquisition and preprocessing loop\ncap = cv2.VideoCapture(input_path)\nout = cv2.VideoWriter(output_path, cv2.VideoWriter_fourcc(*'XVID'), 30.0, (width, height))\n\nwhile cap.isOpened():\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    # Preprocess data\n    resized_frame = cv2.resize(frame, (width, height))\n    input_data = np.expand_dims(resized_frame, axis=0)\n\n    # Quantization handling\n    if floating_model:\n        input_data = (np.float32(input_data) - 127.5) / 127.5\n\n    # Inference\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n    interpreter.invoke()\n\n    # Output interpretation and handling\n    boxes = interpreter.get_tensor(output_details[0]['index'])[0]\n    classes = interpreter.get_tensor(output_details[1]['index'])[0]\n    scores = interpreter.get_tensor(output_details[2]['index'])[0]\n\n    for i in range(len(scores)):\n        if ((scores[i] > confidence_threshold) and (scores[i] <= 1.0)):\n            ymin = int(max(1, (boxes[i][0] * height)))\n            xmin = int(max(1, (boxes[i][1] * width)))\n            ymax = int(min(height, (boxes[i][2] * height)))\n            xmax = int(min(width, (boxes[i][3] * width)))\n\n            cv2.rectangle(frame, (xmin, ymin), (xmax, ymax), (10, 255, 0), 4)\n            object_name = labels[int(classes[i])]\n            label = '%s: %d%%' % (object_name, int(scores[i]*100))\n            labelSize, baseLine = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.7, 2)\n            label_ymin = max(ymin, labelSize[1] + 10)\n            cv2.rectangle(frame, (xmin, label_ymin-labelSize[1]-10), (xmin+labelSize[0], label_ymin+baseLine-10), (255, 255, 255), cv2.FILLED)\n            cv2.putText(frame, label, (xmin, label_ymin-7), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 0), 2)\n\n    out.write(frame)\n\n# Cleanup\ncap.release()\nout.release()\ncv2.destroyAllWindows()",
        "last_error": "Unexpected error during generation: The output is not a valid code block. Follow the instructions in the prompt return a complete, correct Python script enclosed in a single ```python\n<generated_code>\n``` block."
      },
      "session_id": "codestral_e6d3_tpusg_batch",
      "metadata": {
        "num_run": 24
      },
      "tags": [
        "benchmark",
        "codestral:latest",
        "tpu_sketch_generator"
      ],
      "latency": 52.12,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-02-57-32-799962_chatcmpl-4da3e269-aeb4-4d69-8268-288c6c233b3e",
          "traceId": "6dc18df5",
          "type": "GENERATION",
          "name": "6dc1_tpusg_gen_attempt#1",
          "startTime": "2025-08-12T23:57:32.799000+00:00",
          "endTime": "2025-08-12T23:57:51.939000+00:00",
          "model": "codestral:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 19140.0,
          "completionTokens": 1001,
          "environment": "default",
          "totalTokens": 3049,
          "promptTokens": 2048,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-02-57-59-653162_chatcmpl-d4dbdb96-0e42-490c-ad3c-dc16fbb6a20d",
          "traceId": "6dc18df5",
          "type": "GENERATION",
          "name": "6dc1_tpusg_gen_attempt#2",
          "startTime": "2025-08-12T23:57:59.653000+00:00",
          "endTime": "2025-08-12T23:58:03.241000+00:00",
          "model": "codestral:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 3588.0,
          "completionTokens": 127,
          "environment": "default",
          "totalTokens": 2175,
          "promptTokens": 2048,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-02-58-03-262975_chatcmpl-bcb9e980-6121-4dd0-b48c-b2a7bdaa9f3f",
          "traceId": "6dc18df5",
          "type": "GENERATION",
          "name": "6dc1_tpusg_gen_attempt#3",
          "startTime": "2025-08-12T23:58:03.262000+00:00",
          "endTime": "2025-08-12T23:58:10.477000+00:00",
          "model": "codestral:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 7215.0,
          "completionTokens": 332,
          "environment": "default",
          "totalTokens": 2380,
          "promptTokens": 2048,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-02-58-10-484183_chatcmpl-24ef42f4-8ffa-46ad-9245-c36e304b4e8c",
          "traceId": "6dc18df5",
          "type": "GENERATION",
          "name": "6dc1_tpusg_gen_attempt#4",
          "startTime": "2025-08-12T23:58:10.484000+00:00",
          "endTime": "2025-08-12T23:58:17.693000+00:00",
          "model": "codestral:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 7209.0,
          "completionTokens": 332,
          "environment": "default",
          "totalTokens": 2380,
          "promptTokens": 2048,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-02-58-17-703865_chatcmpl-163e4552-becb-4a3a-8658-e68d8f02978e",
          "traceId": "6dc18df5",
          "type": "GENERATION",
          "name": "6dc1_tpusg_gen_attempt#5",
          "startTime": "2025-08-12T23:58:17.703000+00:00",
          "endTime": "2025-08-12T23:58:24.913000+00:00",
          "model": "codestral:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 7210.0,
          "completionTokens": 332,
          "environment": "default",
          "totalTokens": 2380,
          "promptTokens": 2048,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "0fd9bebe-18c9-44f2-b4b1-87c078f13f4a",
          "traceId": "6dc18df5",
          "type": "SPAN",
          "name": "error_6d_tpusg_failure_signal_tpu_sketch_generator",
          "startTime": "2025-08-12T23:58:24.919000+00:00",
          "level": "ERROR",
          "statusMessage": "Failed. Last error: Unexpected error during generation: The output is not a valid code block. Follow the instructions in the prompt return a complete, correct Python script enclosed in a single ```python\n<generated_code>\n``` block.",
          "calculatedTotalCost": 0.0,
          "completionTokens": 0,
          "environment": "default",
          "totalTokens": 0,
          "promptTokens": 0,
          "costDetails": {},
          "endTime": null,
          "model": null,
          "modelParameters": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null,
          "latency": null
        }
      ],
      "createdAt": "2025-08-12T23:57:33.317Z",
      "updatedAt": "2025-08-12T23:58:40.439Z",
      "environment": "default"
    },
    {
      "id": "7aa02ae1",
      "timestamp": "2025-08-12T23:55:41.205000+00:00",
      "name": "7aa0_tpu_sketch_generator",
      "input": null,
      "output": {
        "status": "failed",
        "last_code": "result = detect.get_objects(interpreter, confidence_threshold)",
        "last_error": "Unexpected error during generation: Generated script is not complete. Please ensure to generate a complete Python script."
      },
      "session_id": "codestral_e6d3_tpusg_batch",
      "metadata": {
        "num_run": 23
      },
      "tags": [
        "benchmark",
        "codestral:latest",
        "tpu_sketch_generator"
      ],
      "latency": 104.425,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-02-55-41-207519_chatcmpl-87614359-71d9-44b3-b33b-1555e8f7df17",
          "traceId": "7aa02ae1",
          "type": "GENERATION",
          "name": "7aa0_tpusg_gen_attempt#1",
          "startTime": "2025-08-12T23:55:41.207000+00:00",
          "endTime": "2025-08-12T23:56:00.406000+00:00",
          "model": "codestral:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 19199.0,
          "completionTokens": 1001,
          "environment": "default",
          "totalTokens": 3049,
          "promptTokens": 2048,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-02-56-08-291350_chatcmpl-95953792-3a83-4692-9e7d-83073aaeae71",
          "traceId": "7aa02ae1",
          "type": "GENERATION",
          "name": "7aa0_tpusg_gen_attempt#2",
          "startTime": "2025-08-12T23:56:08.291000+00:00",
          "endTime": "2025-08-12T23:56:21.458000+00:00",
          "model": "codestral:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 13167.0,
          "completionTokens": 666,
          "environment": "default",
          "totalTokens": 2714,
          "promptTokens": 2048,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-02-56-29-660832_chatcmpl-750495f8-49b7-4dfe-807c-186aca609ce2",
          "traceId": "7aa02ae1",
          "type": "GENERATION",
          "name": "7aa0_tpusg_gen_attempt#3",
          "startTime": "2025-08-12T23:56:29.660000+00:00",
          "endTime": "2025-08-12T23:56:41.163000+00:00",
          "model": "codestral:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 11503.0,
          "completionTokens": 573,
          "environment": "default",
          "totalTokens": 2621,
          "promptTokens": 2048,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-02-56-49-476594_chatcmpl-f4942f16-38cf-4a0a-bab3-870ce6080df7",
          "traceId": "7aa02ae1",
          "type": "GENERATION",
          "name": "7aa0_tpusg_gen_attempt#4",
          "startTime": "2025-08-12T23:56:49.476000+00:00",
          "endTime": "2025-08-12T23:57:02.317000+00:00",
          "model": "codestral:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 12841.0,
          "completionTokens": 647,
          "environment": "default",
          "totalTokens": 2695,
          "promptTokens": 2048,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-02-57-11-328766_chatcmpl-1542ecd2-9069-4a45-beb2-723873153d51",
          "traceId": "7aa02ae1",
          "type": "GENERATION",
          "name": "7aa0_tpusg_gen_attempt#5",
          "startTime": "2025-08-12T23:57:11.328000+00:00",
          "endTime": "2025-08-12T23:57:25.629000+00:00",
          "model": "codestral:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 14301.0,
          "completionTokens": 731,
          "environment": "default",
          "totalTokens": 2779,
          "promptTokens": 2048,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "59b6ec62-a950-4b23-86a4-f0d1ca14dd92",
          "traceId": "7aa02ae1",
          "type": "SPAN",
          "name": "error_7a_tpusg_failure_signal_tpu_sketch_generator",
          "startTime": "2025-08-12T23:57:25.632000+00:00",
          "level": "ERROR",
          "statusMessage": "Failed. Last error: Unexpected error during generation: Generated script is not complete. Please ensure to generate a complete Python script.",
          "calculatedTotalCost": 0.0,
          "completionTokens": 0,
          "environment": "default",
          "totalTokens": 0,
          "promptTokens": 0,
          "costDetails": {},
          "endTime": null,
          "model": null,
          "modelParameters": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null,
          "latency": null
        }
      ],
      "createdAt": "2025-08-12T23:55:41.725Z",
      "updatedAt": "2025-08-12T23:57:41.640Z",
      "environment": "default"
    },
    {
      "id": "6cc9d4aa",
      "timestamp": "2025-08-12T23:53:17.264000+00:00",
      "name": "6cc9_tpu_sketch_generator",
      "input": null,
      "output": {
        "status": "failed",
        "last_code": "out = cv2.VideoWriter(output_path, cv2.VideoWriter_fourcc(*'mp4v'), 30.0, (width, height))",
        "last_error": "Unexpected error during generation: Generated script is not complete. Please ensure to generate a complete Python script."
      },
      "session_id": "codestral_e6d3_tpusg_batch",
      "metadata": {
        "num_run": 22
      },
      "tags": [
        "benchmark",
        "codestral:latest",
        "tpu_sketch_generator"
      ],
      "latency": 136.501,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-02-53-17-266792_chatcmpl-363c66cc-4482-4f30-952b-b023c5965248",
          "traceId": "6cc9d4aa",
          "type": "GENERATION",
          "name": "6cc9_tpusg_gen_attempt#1",
          "startTime": "2025-08-12T23:53:17.266000+00:00",
          "endTime": "2025-08-12T23:53:36.435000+00:00",
          "model": "codestral:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 19169.0,
          "completionTokens": 1001,
          "environment": "default",
          "totalTokens": 3049,
          "promptTokens": 2048,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-02-53-44-266342_chatcmpl-9d2825e3-eab4-499b-ae82-d0c5c1b5f091",
          "traceId": "6cc9d4aa",
          "type": "GENERATION",
          "name": "6cc9_tpusg_gen_attempt#2",
          "startTime": "2025-08-12T23:53:44.266000+00:00",
          "endTime": "2025-08-12T23:54:05.632000+00:00",
          "model": "codestral:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 21366.0,
          "completionTokens": 1129,
          "environment": "default",
          "totalTokens": 3177,
          "promptTokens": 2048,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-02-54-13-339497_chatcmpl-ceb8da64-5637-4c98-9152-63210ab1deae",
          "traceId": "6cc9d4aa",
          "type": "GENERATION",
          "name": "6cc9_tpusg_gen_attempt#3",
          "startTime": "2025-08-12T23:54:13.339000+00:00",
          "endTime": "2025-08-12T23:54:34.285000+00:00",
          "model": "codestral:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 20946.0,
          "completionTokens": 1105,
          "environment": "default",
          "totalTokens": 3153,
          "promptTokens": 2048,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-02-54-41-981602_chatcmpl-5c27d4ea-6e7e-45ae-8964-5ea8e1518ee2",
          "traceId": "6cc9d4aa",
          "type": "GENERATION",
          "name": "6cc9_tpusg_gen_attempt#4",
          "startTime": "2025-08-12T23:54:41.981000+00:00",
          "endTime": "2025-08-12T23:55:04.094000+00:00",
          "model": "codestral:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 22113.0,
          "completionTokens": 1171,
          "environment": "default",
          "totalTokens": 3219,
          "promptTokens": 2048,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-02-55-11-700203_chatcmpl-17d94e82-64a1-4518-9ca1-3b61ee8fa887",
          "traceId": "6cc9d4aa",
          "type": "GENERATION",
          "name": "6cc9_tpusg_gen_attempt#5",
          "startTime": "2025-08-12T23:55:11.700000+00:00",
          "endTime": "2025-08-12T23:55:33.764000+00:00",
          "model": "codestral:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 22064.0,
          "completionTokens": 1168,
          "environment": "default",
          "totalTokens": 3216,
          "promptTokens": 2048,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "c2778c32-e53b-4ef1-96f9-0c6ae2cfd84d",
          "traceId": "6cc9d4aa",
          "type": "SPAN",
          "name": "error_6c_tpusg_failure_signal_tpu_sketch_generator",
          "startTime": "2025-08-12T23:55:33.767000+00:00",
          "level": "ERROR",
          "statusMessage": "Failed. Last error: Unexpected error during generation: Generated script is not complete. Please ensure to generate a complete Python script.",
          "calculatedTotalCost": 0.0,
          "completionTokens": 0,
          "environment": "default",
          "totalTokens": 0,
          "promptTokens": 0,
          "costDetails": {},
          "endTime": null,
          "model": null,
          "modelParameters": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null,
          "latency": null
        }
      ],
      "createdAt": "2025-08-12T23:53:17.795Z",
      "updatedAt": "2025-08-12T23:55:49.754Z",
      "environment": "default"
    },
    {
      "id": "d1b7c1a1",
      "timestamp": "2025-08-12T23:51:13.325000+00:00",
      "name": "d1b7_tpu_sketch_generator",
      "input": null,
      "output": {
        "status": "success",
        "sketch": "import cv2\nimport numpy as np\nfrom tflite_runtime.interpreter import Interpreter, load_delegate\n\n# Define label path\nlabel_path  = \"/home/mendel/tinyml_autopilot/models/labelmap.txt\"\n\n# Load labels\nwith open(label_path, 'r') as f:\n    labels = [line.strip() for line in f.readlines()]\n\n# Define model and input paths\nmodel_path  = \"/home/mendel/tinyml_autopilot/models/edgetpu_detect.tflite\"\ninput_path  = \"/home/mendel/tinyml_autopilot/data//sheeps.mp4\"\noutput_path  = \"/home/mendel/tinyml_autopilot/results/sheeps_detections.mp4\"\nconfidence_threshold  = 0.5\n\n# Load interpreter with EdgeTPU\ninterpreter = Interpreter(model_path=model_path, experimental_delegates=[load_delegate('/usr/lib/aarch64-linux-gnu/libedgetpu.so.1')])\ninterpreter.allocate_tensors()\n\n# Get model details\ninput_details  = interpreter.get_input_details()\noutput_details  = interpreter.get_output_details()\nheight = input_details[0]['shape'][1]\nwidth = input_details[0]['shape'][2]\nfloating_model = (input_details[0]['dtype'] == np.float32)\n\n# Input acquisition and preprocessing loop\ncap = cv2.VideoCapture(input_path)\nwhile cap.isOpened():\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    # Preprocess data\n    resized_frame = cv2.resize(frame, (width, height))\n    input_data = np.expand_dims(resized_frame, axis=0)\n    if floating_model:\n        input_data = (np.float32(input_data) - 127.5) / 127.5\n\n    # Inference\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n    interpreter.invoke()\n\n    # Output interpretation and handling loop\n    boxes = interpreter.get_tensor(output_details[0]['index'])[0]\n    classes = interpreter.get_tensor(output_details[1]['index'])[0]\n    scores = interpreter.get_tensor(output_details[2]['index'])[0]\n\n    for i in range(len(scores)):\n        if ((scores[i] > confidence_threshold) and (scores[i] <= 1.0)):\n            ymin = int((boxes[i][0] * frame.shape[0]))\n            xmin = int((boxes[i][1] * frame.shape[1]))\n            ymax = int((boxes[i][2] * frame.shape[0]))\n            xmax = int((boxes[i][3] * frame.shape[1]))\n\n            # Handle output\n            object_name = labels[int(classes[i])]\n            label = '%s: %d%%' % (object_name, int(scores[i]*100))\n            print('Detected:', label, 'at coordinates:', xmin, ymin, xmax, ymax)\n\n# Cleanup\ncap.release()"
      },
      "session_id": "codestral_e6d3_tpusg_batch",
      "metadata": {
        "num_run": 21
      },
      "tags": [
        "benchmark",
        "codestral:latest",
        "tpu_sketch_generator"
      ],
      "latency": 68.19,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-02-51-13-328193_chatcmpl-1e71770e-196f-4b43-aeee-b3f4d1e8e5fa",
          "traceId": "d1b7c1a1",
          "type": "GENERATION",
          "name": "d1b7_tpusg_gen_attempt#1",
          "startTime": "2025-08-12T23:51:13.328000+00:00",
          "endTime": "2025-08-12T23:51:32.236000+00:00",
          "model": "codestral:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 18908.0,
          "completionTokens": 987,
          "environment": "default",
          "totalTokens": 3035,
          "promptTokens": 2048,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-02-51-40-159215_chatcmpl-fa90d2a7-756e-4ac8-be0e-5d472a312d82",
          "traceId": "d1b7c1a1",
          "type": "GENERATION",
          "name": "d1b7_tpusg_gen_attempt#2",
          "startTime": "2025-08-12T23:51:40.159000+00:00",
          "endTime": "2025-08-12T23:51:56.163000+00:00",
          "model": "codestral:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 16004.0,
          "completionTokens": 827,
          "environment": "default",
          "totalTokens": 2875,
          "promptTokens": 2048,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-02-52-03-923636_chatcmpl-8f22fea6-8e2e-425f-86fa-e2ed36f5621d",
          "traceId": "d1b7c1a1",
          "type": "GENERATION",
          "name": "d1b7_tpusg_gen_attempt#3",
          "startTime": "2025-08-12T23:52:03.923000+00:00",
          "endTime": "2025-08-12T23:52:21.518000+00:00",
          "model": "codestral:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 17595.0,
          "completionTokens": 917,
          "environment": "default",
          "totalTokens": 2965,
          "promptTokens": 2048,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        }
      ],
      "createdAt": "2025-08-12T23:51:13.846Z",
      "updatedAt": "2025-08-12T23:53:25.065Z",
      "environment": "default"
    },
    {
      "id": "a7d8c023",
      "timestamp": "2025-08-12T23:49:14.502000+00:00",
      "name": "a7d8_tpu_sketch_generator",
      "input": null,
      "output": {
        "status": "failed",
        "last_code": "import cv2\nimport numpy as np\nfrom tflite_runtime.interpreter import Interpreter, load_delegate\n\n# Load model with EdgeTPU acceleration\ntry:\n    interpreter = Interpreter(model_path='model.tflite',\n                              experimental_delegates=[load_delegate('libedgetpu.so.1')])\nexcept ValueError:\n    interpreter = Interpreter(model_path='model.tflite',\n                              experimental_delegates=[load_delegate('/usr/lib/aarch64-linux-gnu/libedgetpu.so.1')])\ninterpreter.allocate_tensors()\n\n# Get model details\ninput_details  = \"/home/mendel/tinyml_autopilot/data//sheeps.mp4\"\noutput_details  = \"/home/mendel/tinyml_autopilot/results/sheeps_detections.mp4\"\nheight = input_details[0]['shape'][1]\nwidth = input_details[0]['shape'][2]\nfloating_model = (input_details[0]['dtype'] == np.float32)\n\n# Open video file\ncap = cv2.VideoCapture('video.mp4')\nwhile cap.isOpened():\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    # Preprocess data\n    resized_frame = cv2.resize(frame, (width, height))\n    input_data = np.expand_dims(resized_frame, axis=0)\n    if floating_model:\n        input_data = (np.float32(input_data) - 127.5) / 127.5\n\n    # Run inference\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n    interpreter.invoke()\n\n    # Get output data\n    boxes = interpreter.get_tensor(output_details[0]['index'])[0]\n    classes = interpreter.get_tensor(output_details[1]['index'])[0]\n    scores = interpreter.get_tensor(output_details[2]['index'])[0]\n\n    # Post-processing\n    for i in range(len(scores)):\n        if ((scores[i] > 0.5) and (scores[i] <= 1.0)):\n            ymin = int(max(1, (boxes[i][0] * height)))\n            xmin = int(max(1, (boxes[i][1] * width)))\n            ymax = int(min(height, (boxes[i][2] * height)))\n            xmax = int(min(width, (boxes[i][3] * width)))\n\n            # Draw bounding box on frame\n            cv2.rectangle(frame, (xmin, ymin), (xmax, ymax), (10, 255, 0), 2)\n            label = '%d: %d%%' % (classes[i], int(scores[i]*100))\n            cv2.putText(frame, label, (xmin, min(ymax, height-20)), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)\n\n    # Show frame with bounding boxes\n    cv2.imshow('Object detection', frame)\n    if cv2.waitKey(1) & 0xFF == ord('q'):\n        break\n\n# Release resources\ncap.release()\ncv2.destroyAllWindows()",
        "last_error": "Traceback (most recent call last):\n  File \"script_044b793b_1755042657.py\", line 8, in <module>\n    experimental_delegates=[load_delegate('libedgetpu.so.1')])\n  File \"/home/mendel/tinyml_autopilot/tinyml-env/lib/python3.7/site-packages/tflite_runtime/interpreter.py\", line 351, in __init__\n    experimental_preserve_all_tensors))\nValueError: Could not open 'model.tflite'.\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"script_044b793b_1755042657.py\", line 11, in <module>\n    experimental_delegates=[load_delegate('/usr/lib/aarch64-linux-gnu/libedgetpu.so.1')])\n  File \"/home/mendel/tinyml_autopilot/tinyml-env/lib/python3.7/site-packages/tflite_runtime/interpreter.py\", line 351, in __init__\n    experimental_preserve_all_tensors))\nValueError: Could not open 'model.tflite'."
      },
      "session_id": "codestral_e6d3_tpusg_batch",
      "metadata": {
        "num_run": 20
      },
      "tags": [
        "benchmark",
        "codestral:latest",
        "tpu_sketch_generator"
      ],
      "latency": 111.13,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-02-49-14-505590_chatcmpl-b39998af-0eb0-4007-a866-8ac80ba2f6c1",
          "traceId": "a7d8c023",
          "type": "GENERATION",
          "name": "a7d8_tpusg_gen_attempt#1",
          "startTime": "2025-08-12T23:49:14.505000+00:00",
          "endTime": "2025-08-12T23:49:33.726000+00:00",
          "model": "codestral:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 19221.0,
          "completionTokens": 1001,
          "environment": "default",
          "totalTokens": 3049,
          "promptTokens": 2048,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-02-49-41-562040_chatcmpl-b5983f40-e703-4639-95d7-aa52099d9217",
          "traceId": "a7d8c023",
          "type": "GENERATION",
          "name": "a7d8_tpusg_gen_attempt#2",
          "startTime": "2025-08-12T23:49:41.562000+00:00",
          "endTime": "2025-08-12T23:49:46.811000+00:00",
          "model": "codestral:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 5249.0,
          "completionTokens": 220,
          "environment": "default",
          "totalTokens": 2268,
          "promptTokens": 2048,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-02-49-46-819307_chatcmpl-ad04e4f2-aa33-4f5f-804d-f486bc250648",
          "traceId": "a7d8c023",
          "type": "GENERATION",
          "name": "a7d8_tpusg_gen_attempt#3",
          "startTime": "2025-08-12T23:49:46.819000+00:00",
          "endTime": "2025-08-12T23:50:05.502000+00:00",
          "model": "codestral:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 18683.0,
          "completionTokens": 979,
          "environment": "default",
          "totalTokens": 3027,
          "promptTokens": 2048,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-02-50-13-459814_chatcmpl-0d78038b-0be5-4d9b-a2d1-d5833d4a17bc",
          "traceId": "a7d8c023",
          "type": "GENERATION",
          "name": "a7d8_tpusg_gen_attempt#4",
          "startTime": "2025-08-12T23:50:13.459000+00:00",
          "endTime": "2025-08-12T23:50:31.643000+00:00",
          "model": "codestral:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 18184.0,
          "completionTokens": 949,
          "environment": "default",
          "totalTokens": 2997,
          "promptTokens": 2048,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-02-50-39-497856_chatcmpl-24bd0966-8adc-449e-b041-f50f4fe6612f",
          "traceId": "a7d8c023",
          "type": "GENERATION",
          "name": "a7d8_tpusg_gen_attempt#5",
          "startTime": "2025-08-12T23:50:39.497000+00:00",
          "endTime": "2025-08-12T23:50:57.517000+00:00",
          "model": "codestral:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 18020.0,
          "completionTokens": 940,
          "environment": "default",
          "totalTokens": 2988,
          "promptTokens": 2048,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "654b4c0c-bd5f-4f7d-b235-2a0669309f93",
          "traceId": "a7d8c023",
          "type": "SPAN",
          "name": "error_a7_tpusg_failure_signal_tpu_sketch_generator",
          "startTime": "2025-08-12T23:51:05.635000+00:00",
          "level": "ERROR",
          "statusMessage": "Failed. Last error: Traceback (most recent call last):\n  File \"script_044b793b_1755042657.py\", line 8, in <module>\n    experimental_delegates=[load_delegate('libedgetpu.so.1')])\n  File \"/home/mendel/tinyml_autopilot/tinyml-env/lib/python3.7/site-packages/tflite_runtime/interpreter.py\", line 351, in __init__\n    experimental_preserve_all_tensors))\nValueError: Could not open 'model.tflite'.\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"script_044b793b_1755042657.py\", line 11, in <module>\n    experimental_delegates=[load_delegate('/usr/lib/aarch64-linux-gnu/libedgetpu.so.1')])\n  File \"/home/mendel/tinyml_autopilot/tinyml-env/lib/python3.7/site-packages/tflite_runtime/interpreter.py\", line 351, in __init__\n    experimental_preserve_all_tensors))\nValueError: Could not open 'model.tflite'.",
          "calculatedTotalCost": 0.0,
          "completionTokens": 0,
          "environment": "default",
          "totalTokens": 0,
          "promptTokens": 0,
          "costDetails": {},
          "endTime": null,
          "model": null,
          "modelParameters": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null,
          "latency": null
        }
      ],
      "createdAt": "2025-08-12T23:49:15.027Z",
      "updatedAt": "2025-08-12T23:51:20.754Z",
      "environment": "default"
    },
    {
      "id": "1c1ff4ce",
      "timestamp": "2025-08-12T23:46:49.460000+00:00",
      "name": "1c1f_tpu_sketch_generator",
      "input": null,
      "output": {
        "status": "success",
        "sketch": "import numpy as np\nimport cv2\nfrom tflite_runtime.interpreter import load_delegate, Interpreter\n\n# Define variables\nlabel_path   = \"/home/mendel/tinyml_autopilot/models/labelmap.txt\"\nmodel_path   = \"/home/mendel/tinyml_autopilot/models/edgetpu_detect.tflite\"\ninput_path   = \"/home/mendel/tinyml_autopilot/data//sheeps.mp4\"\noutput_path  = \"/home/mendel/tinyml_autopilot/results/sheeps_detections.mp4\"\nconfidence_threshold   = 0.5\n\n# Load labels\nwith open(label_path, 'r') as f:\n    labels = [line.strip() for line in f.readlines()]\n\n# Load interpreter with EdgeTPU\ninterpreter = Interpreter(model_path=model_path, experimental_delegates=[load_delegate('/usr/lib/aarch64-linux-gnu/libedgetpu.so.1')])\ninterpreter.allocate_tensors()\n\n# Get model details\ninput_details  = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\nheight = input_details[0]['shape'][1]\nwidth = input_details[0]['shape'][2]\nfloating_model = (input_details[0]['dtype'] == np.float32)\n\n# Input acquisition and preprocessing loop\ncap = cv2.VideoCapture(input_path)\nwhile cap.isOpened():\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    # Preprocess data\n    resized_frame = cv2.resize(frame, (width, height))\n    input_data = np.expand_dims(resized_frame, axis=0)\n    if floating_model:\n        input_data = (np.float32(input_data) - 127.5) / 127.5\n\n    # Inference\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n    interpreter.invoke()\n\n    # Output interpretation and handling loop\n    boxes = interpreter.get_tensor(output_details[0]['index'])[0]\n    classes = interpreter.get_tensor(output_details[1]['index'])[0]\n    scores = interpreter.get_tensor(output_details[2]['index'])[0]\n\n    for i in range(len(scores)):\n        if ((scores[i] > confidence_threshold) and (scores[i] <= 1.0)):\n            ymin = int((boxes[i][0] * frame.shape[0]))\n            xmin = int((boxes[i][1] * frame.shape[1]))\n            ymax = int((boxes[i][2] * frame.shape[0]))\n            xmax = int((boxes[i][3] * frame.shape[1]))\n\n            # Handle output\n            object_name = labels[int(classes[i])]\n            label = '%s: %d%%' % (object_name, int(scores[i]*100))\n            print(label)"
      },
      "session_id": "codestral_e6d3_tpusg_batch",
      "metadata": {
        "num_run": 19
      },
      "tags": [
        "benchmark",
        "codestral:latest",
        "tpu_sketch_generator"
      ],
      "latency": 90.631,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-02-46-49-461788_chatcmpl-56f7ca26-b54b-4aa8-821a-aeb99f70901e",
          "traceId": "1c1ff4ce",
          "type": "GENERATION",
          "name": "1c1f_tpusg_gen_attempt#1",
          "startTime": "2025-08-12T23:46:49.461000+00:00",
          "endTime": "2025-08-12T23:47:08.379000+00:00",
          "model": "codestral:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 18918.0,
          "completionTokens": 987,
          "environment": "default",
          "totalTokens": 3035,
          "promptTokens": 2048,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-02-47-16-431524_chatcmpl-b733219c-4af1-4058-a48a-262cf4b11e1e",
          "traceId": "1c1ff4ce",
          "type": "GENERATION",
          "name": "1c1f_tpusg_gen_attempt#2",
          "startTime": "2025-08-12T23:47:16.431000+00:00",
          "endTime": "2025-08-12T23:47:32.717000+00:00",
          "model": "codestral:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 16286.0,
          "completionTokens": 842,
          "environment": "default",
          "totalTokens": 2890,
          "promptTokens": 2048,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-02-47-37-325763_chatcmpl-7c54d2be-2295-4b81-a9e1-11e9b60c4372",
          "traceId": "1c1ff4ce",
          "type": "GENERATION",
          "name": "1c1f_tpusg_gen_attempt#3",
          "startTime": "2025-08-12T23:47:37.325000+00:00",
          "endTime": "2025-08-12T23:47:54.215000+00:00",
          "model": "codestral:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 16890.0,
          "completionTokens": 877,
          "environment": "default",
          "totalTokens": 2925,
          "promptTokens": 2048,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-02-48-02-665997_chatcmpl-c41d979d-5198-415e-bdf9-694056dc0681",
          "traceId": "1c1ff4ce",
          "type": "GENERATION",
          "name": "1c1f_tpusg_gen_attempt#4",
          "startTime": "2025-08-12T23:48:02.665000+00:00",
          "endTime": "2025-08-12T23:48:20.092000+00:00",
          "model": "codestral:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 17427.0,
          "completionTokens": 907,
          "environment": "default",
          "totalTokens": 2955,
          "promptTokens": 2048,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        }
      ],
      "createdAt": "2025-08-12T23:46:49.978Z",
      "updatedAt": "2025-08-12T23:49:23.243Z",
      "environment": "default"
    },
    {
      "id": "1fdec86e",
      "timestamp": "2025-08-12T23:44:55.862000+00:00",
      "name": "1fde_tpu_sketch_generator",
      "input": null,
      "output": {
        "status": "failed",
        "last_code": "import cv2\nimport numpy as np\nfrom tflite_runtime.interpreter import Interpreter, load_delegate\n\n# Load TFLite model with EdgeTPU acceleration\ntry:\n    interpreter = Interpreter(model_path='model.tflite', experimental_delegates=[load_delegate('libedgetpu.so.1.0')])\nexcept:\n    interpreter = Interpreter(model_path='model.tflite', experimental_delegates=[load_delegate('/usr/lib/aarch64-linux-gnu/libedgetpu.so.1.0')])\ninterpreter.allocate_tensors()\n\n# Get model details\ninput_details  = \"/home/mendel/tinyml_autopilot/data//sheeps.mp4\"\noutput_details  = \"/home/mendel/tinyml_autopilot/results/sheeps_detections.mp4\"\nheight = input_details[0]['shape'][1]\nwidth = input_details[0]['shape'][2]\nfloating_model = (input_details[0]['dtype'] == np.float32)\n\n# Load image from file and preprocess it\nimage = cv2.imread('input_image.jpg')\nimage_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\nresized_img = cv2.resize(image_rgb, (width, height))\ninput_data = np.expand_dims(resized_img, axis=0)\nif floating_model:\n    input_data = (np.float32(input_data) - 127.5) / 127.5\n\n# Run inference\ninterpreter.set_tensor(input_details[0]['index'], input_data)\ninterpreter.invoke()\n\n# Get output data and interpret results\nboxes = interpreter.get_tensor(output_details[0]['index'])[0] # Bounding box coordinates of detected objects\nclasses = interpreter.get_tensor(output_details[1]['index'])[0] # Class index number of detected objects\nscores = interpreter.get_tensor(output_details[2]['index'])[0] # Confidence of detected objects\nnum = interpreter.get_tensor(output_details[3]['index'])[0]  # Total number of detected objects (inaccurate and not needed)\n\n# Apply post-processing steps\nfor i in range(len(scores)):\n    if ((scores[i] > 0.5) and (scores[i] <= 1.0)):\n        ymin = int(max(1,(boxes[i][0] * image.shape[0])))\n        xmin = int(max(1,(boxes[i][1] * image.shape[1])))\n        ymax = int(min(image.shape[0],(boxes[i][2] * image.shape[0])))\n        xmax = int(min(image.shape[1],(boxes[i][3] * image.shape[1])))\n        cv2.rectangle(image, (xmin,ymin), (xmax,ymax), (10, 255, 0), 4)\n\n# Save the result with bounding boxes\ncv2.imwrite('output_image.jpg', image)",
        "last_error": "Traceback (most recent call last):\n  File \"script_ca92468f_1755042395.py\", line 7, in <module>\n    interpreter = Interpreter(model_path='model.tflite', experimental_delegates=[load_delegate('libedgetpu.so.1.0')])\n  File \"/home/mendel/tinyml_autopilot/tinyml-env/lib/python3.7/site-packages/tflite_runtime/interpreter.py\", line 351, in __init__\n    experimental_preserve_all_tensors))\nValueError: Could not open 'model.tflite'.\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"script_ca92468f_1755042395.py\", line 9, in <module>\n    interpreter = Interpreter(model_path='model.tflite', experimental_delegates=[load_delegate('/usr/lib/aarch64-linux-gnu/libedgetpu.so.1.0')])\n  File \"/home/mendel/tinyml_autopilot/tinyml-env/lib/python3.7/site-packages/tflite_runtime/interpreter.py\", line 351, in __init__\n    experimental_preserve_all_tensors))\nValueError: Could not open 'model.tflite'."
      },
      "session_id": "codestral_e6d3_tpusg_batch",
      "metadata": {
        "num_run": 18
      },
      "tags": [
        "benchmark",
        "codestral:latest",
        "tpu_sketch_generator"
      ],
      "latency": 107.483,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-02-44-55-864665_chatcmpl-9ae03a55-eb00-4691-838a-b9157fa4b28b",
          "traceId": "1fdec86e",
          "type": "GENERATION",
          "name": "1fde_tpusg_gen_attempt#1",
          "startTime": "2025-08-12T23:44:55.864000+00:00",
          "endTime": "2025-08-12T23:45:15.092000+00:00",
          "model": "codestral:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 19228.0,
          "completionTokens": 1001,
          "environment": "default",
          "totalTokens": 3049,
          "promptTokens": 2048,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-02-45-22-883823_chatcmpl-45aff62c-cddb-4707-b96d-969997b2791a",
          "traceId": "1fdec86e",
          "type": "GENERATION",
          "name": "1fde_tpusg_gen_attempt#2",
          "startTime": "2025-08-12T23:45:22.883000+00:00",
          "endTime": "2025-08-12T23:45:25.656000+00:00",
          "model": "codestral:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 2773.0,
          "completionTokens": 81,
          "environment": "default",
          "totalTokens": 2129,
          "promptTokens": 2048,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-02-45-25-663312_chatcmpl-3b7f1507-d2cc-40e6-9db3-d55ea573e5c8",
          "traceId": "1fdec86e",
          "type": "GENERATION",
          "name": "1fde_tpusg_gen_attempt#3",
          "startTime": "2025-08-12T23:45:25.663000+00:00",
          "endTime": "2025-08-12T23:45:44.940000+00:00",
          "model": "codestral:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 19277.0,
          "completionTokens": 1012,
          "environment": "default",
          "totalTokens": 3060,
          "promptTokens": 2048,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-02-45-52-845680_chatcmpl-8aabe0d3-781d-4b5a-b8ed-076e5ad94dcb",
          "traceId": "1fdec86e",
          "type": "GENERATION",
          "name": "1fde_tpusg_gen_attempt#4",
          "startTime": "2025-08-12T23:45:52.845000+00:00",
          "endTime": "2025-08-12T23:46:09.204000+00:00",
          "model": "codestral:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 16359.0,
          "completionTokens": 846,
          "environment": "default",
          "totalTokens": 2894,
          "promptTokens": 2048,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-02-46-17-144540_chatcmpl-3dc13376-4231-4965-8f8f-0f435c26cd4c",
          "traceId": "1fdec86e",
          "type": "GENERATION",
          "name": "1fde_tpusg_gen_attempt#5",
          "startTime": "2025-08-12T23:46:17.144000+00:00",
          "endTime": "2025-08-12T23:46:35.443000+00:00",
          "model": "codestral:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 18299.0,
          "completionTokens": 954,
          "environment": "default",
          "totalTokens": 3002,
          "promptTokens": 2048,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "c3ada599-ad23-47b8-a88e-ec74d2b8649d",
          "traceId": "1fdec86e",
          "type": "SPAN",
          "name": "error_1f_tpusg_failure_signal_tpu_sketch_generator",
          "startTime": "2025-08-12T23:46:43.347000+00:00",
          "level": "ERROR",
          "statusMessage": "Failed. Last error: Traceback (most recent call last):\n  File \"script_ca92468f_1755042395.py\", line 7, in <module>\n    interpreter = Interpreter(model_path='model.tflite', experimental_delegates=[load_delegate('libedgetpu.so.1.0')])\n  File \"/home/mendel/tinyml_autopilot/tinyml-env/lib/python3.7/site-packages/tflite_runtime/interpreter.py\", line 351, in __init__\n    experimental_preserve_all_tensors))\nValueError: Could not open 'model.tflite'.\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"script_ca92468f_1755042395.py\", line 9, in <module>\n    interpreter = Interpreter(model_path='model.tflite', experimental_delegates=[load_delegate('/usr/lib/aarch64-linux-gnu/libedgetpu.so.1.0')])\n  File \"/home/mendel/tinyml_autopilot/tinyml-env/lib/python3.7/site-packages/tflite_runtime/interpreter.py\", line 351, in __init__\n    experimental_preserve_all_tensors))\nValueError: Could not open 'model.tflite'.",
          "calculatedTotalCost": 0.0,
          "completionTokens": 0,
          "environment": "default",
          "totalTokens": 0,
          "promptTokens": 0,
          "costDetails": {},
          "endTime": null,
          "model": null,
          "modelParameters": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null,
          "latency": null
        }
      ],
      "createdAt": "2025-08-12T23:44:56.379Z",
      "updatedAt": "2025-08-12T23:46:58.596Z",
      "environment": "default"
    },
    {
      "id": "ac201e38",
      "timestamp": "2025-08-12T23:43:12.950000+00:00",
      "name": "ac20_tpu_sketch_generator",
      "input": null,
      "output": {
        "status": "failed",
        "last_code": "import cv2\nimport numpy as np\nfrom edgetpu.detection.engine import DetectionEngine\nfrom PIL import Image\n\n# Phase 1: Load Interpreter with EdgeTPU & Get Model Details\nmodel_path    = \"/home/mendel/tinyml_autopilot/models/edgetpu_detect.tflite\"\nlabels_path = \"<actual_path_to_your_labels_file>\" # replace this with the actual path to your labels file\n\nwith open(labels_path, 'r') as f:\n    labels = [line.strip() for line in f.readlines()]\n\nengine = DetectionEngine(model_path)\n\n# Phase 2: Input Acquisition & Preprocessing Loop\ncap = cv2.VideoCapture(\"<your_video_path>\") # replace this with the actual path to your video file\n\nwhile cap.isOpened():\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    # Phase 3: Inference (Run per preprocessed input)\n    img = Image.fromarray(frame)\n    results = engine.DetectWithImage(img, threshold=0.1, keep_aspect_ratio=True, relative_coord=False, top_k=10)\n\n    # Phase 4: Output Interpretation & Handling Loop\n    for obj in results:\n        box = obj.bounding_box.flatten().astype(\"int\")\n        (startX, startY, endX, endY) = box\n        label = labels[obj.label_id]\n        cv2.rectangle(frame, (startX, startY), (endX, endY), (0, 255, 0), 2)\n        y = startY - 15 if startY - 15 > 15 else startY + 15\n        cv2.putText(frame, label, (startX, y), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n\n    # Phase 4: Handle Output\n    cv2.imshow(\"Frame\", frame)\n    key = cv2.waitKey(1) & 0xFF\n    if key == ord(\"q\"):\n        break\n\n# Phase 5: Cleanup\ncap.release()\ncv2.destroyAllWindows()",
        "last_error": "Traceback (most recent call last):\n  File \"script_8ebb3109_1755042281.py\", line 10, in <module>\n    with open(labels_path, 'r') as f:\nFileNotFoundError: [Errno 2] No such file or directory: '<actual_path_to_your_labels_file>'"
      },
      "session_id": "codestral_e6d3_tpusg_batch",
      "metadata": {
        "num_run": 17
      },
      "tags": [
        "benchmark",
        "codestral:latest",
        "tpu_sketch_generator"
      ],
      "latency": 97.017,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-02-43-12-952171_chatcmpl-f0e84a2a-a1f9-43a2-94ea-a1dc4120e119",
          "traceId": "ac201e38",
          "type": "GENERATION",
          "name": "ac20_tpusg_gen_attempt#1",
          "startTime": "2025-08-12T23:43:12.952000+00:00",
          "endTime": "2025-08-12T23:43:32.105000+00:00",
          "model": "codestral:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 19153.0,
          "completionTokens": 1001,
          "environment": "default",
          "totalTokens": 3049,
          "promptTokens": 2048,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-02-43-39-876448_chatcmpl-ff6ed085-0574-45b8-9106-d161db81c0db",
          "traceId": "ac201e38",
          "type": "GENERATION",
          "name": "ac20_tpusg_gen_attempt#2",
          "startTime": "2025-08-12T23:43:39.876000+00:00",
          "endTime": "2025-08-12T23:43:44.520000+00:00",
          "model": "codestral:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 4644.0,
          "completionTokens": 183,
          "environment": "default",
          "totalTokens": 2231,
          "promptTokens": 2048,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-02-43-44-527410_chatcmpl-26f77fe9-6805-4912-9344-86fdcc8f1ac7",
          "traceId": "ac201e38",
          "type": "GENERATION",
          "name": "ac20_tpusg_gen_attempt#3",
          "startTime": "2025-08-12T23:43:44.527000+00:00",
          "endTime": "2025-08-12T23:43:59.190000+00:00",
          "model": "codestral:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 14663.0,
          "completionTokens": 750,
          "environment": "default",
          "totalTokens": 2798,
          "promptTokens": 2048,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-02-44-07-570941_chatcmpl-016a58f6-7bc0-4680-8e7d-995c25e1bb83",
          "traceId": "ac201e38",
          "type": "GENERATION",
          "name": "ac20_tpusg_gen_attempt#4",
          "startTime": "2025-08-12T23:44:07.570000+00:00",
          "endTime": "2025-08-12T23:44:20.748000+00:00",
          "model": "codestral:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 13178.0,
          "completionTokens": 667,
          "environment": "default",
          "totalTokens": 2715,
          "promptTokens": 2048,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-02-44-28-878660_chatcmpl-cac7f546-2a8f-4a24-8169-d58e96303e1a",
          "traceId": "ac201e38",
          "type": "GENERATION",
          "name": "ac20_tpusg_gen_attempt#5",
          "startTime": "2025-08-12T23:44:28.878000+00:00",
          "endTime": "2025-08-12T23:44:41.858000+00:00",
          "model": "codestral:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 12980.0,
          "completionTokens": 656,
          "environment": "default",
          "totalTokens": 2704,
          "promptTokens": 2048,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "5df73b06-6286-4048-b1db-ce7fceeb7ec2",
          "traceId": "ac201e38",
          "type": "SPAN",
          "name": "error_ac_tpusg_failure_signal_tpu_sketch_generator",
          "startTime": "2025-08-12T23:44:49.969000+00:00",
          "level": "ERROR",
          "statusMessage": "Failed. Last error: Traceback (most recent call last):\n  File \"script_8ebb3109_1755042281.py\", line 10, in <module>\n    with open(labels_path, 'r') as f:\nFileNotFoundError: [Errno 2] No such file or directory: '<actual_path_to_your_labels_file>'",
          "calculatedTotalCost": 0.0,
          "completionTokens": 0,
          "environment": "default",
          "totalTokens": 0,
          "promptTokens": 0,
          "costDetails": {},
          "endTime": null,
          "model": null,
          "modelParameters": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null,
          "latency": null
        }
      ],
      "createdAt": "2025-08-12T23:43:13.473Z",
      "updatedAt": "2025-08-12T23:44:55.228Z",
      "environment": "default"
    },
    {
      "id": "dc7bfa4b",
      "timestamp": "2025-08-12T23:41:27.281000+00:00",
      "name": "dc7b_tpu_sketch_generator",
      "input": null,
      "output": {
        "status": "failed",
        "last_code": "# Get model details\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\nheight = input_details[0]['shape'][1]\nwidth = input_details[0]['shape'][2]\nfloating_model = (input_details[0]['dtype'] == np.float32)",
        "last_error": "Unexpected error during generation: Generated script is not complete. Please ensure to generate a complete Python script."
      },
      "session_id": "codestral_e6d3_tpusg_batch",
      "metadata": {
        "num_run": 16
      },
      "tags": [
        "benchmark",
        "codestral:latest",
        "tpu_sketch_generator"
      ],
      "latency": 98.981,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-02-41-27-283533_chatcmpl-f8b98155-0ce8-4b9f-8968-1ae5eb74eda1",
          "traceId": "dc7bfa4b",
          "type": "GENERATION",
          "name": "dc7b_tpusg_gen_attempt#1",
          "startTime": "2025-08-12T23:41:27.283000+00:00",
          "endTime": "2025-08-12T23:41:46.197000+00:00",
          "model": "codestral:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 18914.0,
          "completionTokens": 987,
          "environment": "default",
          "totalTokens": 3035,
          "promptTokens": 2048,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-02-41-54-635370_chatcmpl-7d6643a8-2bb6-4455-9862-bb5313aaf940",
          "traceId": "dc7bfa4b",
          "type": "GENERATION",
          "name": "dc7b_tpusg_gen_attempt#2",
          "startTime": "2025-08-12T23:41:54.635000+00:00",
          "endTime": "2025-08-12T23:42:02.578000+00:00",
          "model": "codestral:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 7943.0,
          "completionTokens": 372,
          "environment": "default",
          "totalTokens": 2420,
          "promptTokens": 2048,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-02-42-02-593493_chatcmpl-86aa6e93-150f-4bea-b0c6-0ddad890961e",
          "traceId": "dc7bfa4b",
          "type": "GENERATION",
          "name": "dc7b_tpusg_gen_attempt#3",
          "startTime": "2025-08-12T23:42:02.593000+00:00",
          "endTime": "2025-08-12T23:42:24.606000+00:00",
          "model": "codestral:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 22013.0,
          "completionTokens": 1166,
          "environment": "default",
          "totalTokens": 3214,
          "promptTokens": 2048,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-02-42-32-419507_chatcmpl-b6cac18b-d7e5-46e3-95bd-1badcb5222aa",
          "traceId": "dc7bfa4b",
          "type": "GENERATION",
          "name": "dc7b_tpusg_gen_attempt#4",
          "startTime": "2025-08-12T23:42:32.419000+00:00",
          "endTime": "2025-08-12T23:42:53.732000+00:00",
          "model": "codestral:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 21313.0,
          "completionTokens": 1126,
          "environment": "default",
          "totalTokens": 3174,
          "promptTokens": 2048,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-02-43-01-521266_chatcmpl-c2c592f7-a40f-45d8-a73d-24223b74e059",
          "traceId": "dc7bfa4b",
          "type": "GENERATION",
          "name": "dc7b_tpusg_gen_attempt#5",
          "startTime": "2025-08-12T23:43:01.521000+00:00",
          "endTime": "2025-08-12T23:43:06.257000+00:00",
          "model": "codestral:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 4736.0,
          "completionTokens": 191,
          "environment": "default",
          "totalTokens": 2239,
          "promptTokens": 2048,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "6a52b469-e695-49b2-b667-2e68f0e4a4d8",
          "traceId": "dc7bfa4b",
          "type": "SPAN",
          "name": "error_dc_tpusg_failure_signal_tpu_sketch_generator",
          "startTime": "2025-08-12T23:43:06.264000+00:00",
          "level": "ERROR",
          "statusMessage": "Failed. Last error: Unexpected error during generation: Generated script is not complete. Please ensure to generate a complete Python script.",
          "calculatedTotalCost": 0.0,
          "completionTokens": 0,
          "environment": "default",
          "totalTokens": 0,
          "promptTokens": 0,
          "costDetails": {},
          "endTime": null,
          "model": null,
          "modelParameters": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null,
          "latency": null
        }
      ],
      "createdAt": "2025-08-12T23:41:27.799Z",
      "updatedAt": "2025-08-12T23:43:11.666Z",
      "environment": "default"
    },
    {
      "id": "7b24ee84",
      "timestamp": "2025-08-12T23:39:53.713000+00:00",
      "name": "7b24_tpu_sketch_generator",
      "input": null,
      "output": {
        "status": "failed",
        "last_code": "input_details = interpreter.get_input_details()\n      output_details = interpreter.get_output_details()",
        "last_error": "Unexpected error during generation: Generated script is not complete. Please ensure to generate a complete Python script."
      },
      "session_id": "codestral_e6d3_tpusg_batch",
      "metadata": {
        "num_run": 15
      },
      "tags": [
        "benchmark",
        "codestral:latest",
        "tpu_sketch_generator"
      ],
      "latency": 86.799,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-02-39-53-715061_chatcmpl-2fe64d5f-b16d-40b3-b46b-a1b0d63565d0",
          "traceId": "7b24ee84",
          "type": "GENERATION",
          "name": "7b24_tpusg_gen_attempt#1",
          "startTime": "2025-08-12T23:39:53.715000+00:00",
          "endTime": "2025-08-12T23:40:12.624000+00:00",
          "model": "codestral:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 18909.0,
          "completionTokens": 987,
          "environment": "default",
          "totalTokens": 3035,
          "promptTokens": 2048,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-02-40-20-525605_chatcmpl-ad2c8d84-907b-4060-ac51-7b0aa20201f8",
          "traceId": "7b24ee84",
          "type": "GENERATION",
          "name": "7b24_tpusg_gen_attempt#2",
          "startTime": "2025-08-12T23:40:20.525000+00:00",
          "endTime": "2025-08-12T23:40:24.499000+00:00",
          "model": "codestral:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 3974.0,
          "completionTokens": 148,
          "environment": "default",
          "totalTokens": 2196,
          "promptTokens": 2048,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-02-40-24-506755_chatcmpl-a2e50768-f8b4-436d-bda4-97afd26adc6c",
          "traceId": "7b24ee84",
          "type": "GENERATION",
          "name": "7b24_tpusg_gen_attempt#3",
          "startTime": "2025-08-12T23:40:24.506000+00:00",
          "endTime": "2025-08-12T23:40:39.005000+00:00",
          "model": "codestral:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 14499.0,
          "completionTokens": 743,
          "environment": "default",
          "totalTokens": 2791,
          "promptTokens": 2048,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-02-40-46-796778_chatcmpl-f44c8de5-ff02-4bd6-9d34-889ff7b470b2",
          "traceId": "7b24ee84",
          "type": "GENERATION",
          "name": "7b24_tpusg_gen_attempt#4",
          "startTime": "2025-08-12T23:40:46.796000+00:00",
          "endTime": "2025-08-12T23:41:05.790000+00:00",
          "model": "codestral:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 18994.0,
          "completionTokens": 995,
          "environment": "default",
          "totalTokens": 3043,
          "promptTokens": 2048,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-02-41-13-592463_chatcmpl-b4338e8a-a5af-497e-9ecd-afa5f136c647",
          "traceId": "7b24ee84",
          "type": "GENERATION",
          "name": "7b24_tpusg_gen_attempt#5",
          "startTime": "2025-08-12T23:41:13.592000+00:00",
          "endTime": "2025-08-12T23:41:20.501000+00:00",
          "model": "codestral:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 6909.0,
          "completionTokens": 312,
          "environment": "default",
          "totalTokens": 2360,
          "promptTokens": 2048,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "d60574d9-f4a6-48aa-82d7-82952c083514",
          "traceId": "7b24ee84",
          "type": "SPAN",
          "name": "error_7b_tpusg_failure_signal_tpu_sketch_generator",
          "startTime": "2025-08-12T23:41:20.514000+00:00",
          "level": "ERROR",
          "statusMessage": "Failed. Last error: Unexpected error during generation: Generated script is not complete. Please ensure to generate a complete Python script.",
          "calculatedTotalCost": 0.0,
          "completionTokens": 0,
          "environment": "default",
          "totalTokens": 0,
          "promptTokens": 0,
          "costDetails": {},
          "endTime": null,
          "model": null,
          "modelParameters": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null,
          "latency": null
        }
      ],
      "createdAt": "2025-08-12T23:39:54.230Z",
      "updatedAt": "2025-08-12T23:41:26.304Z",
      "environment": "default"
    },
    {
      "id": "ea5fee76",
      "timestamp": "2025-08-12T23:37:13.130000+00:00",
      "name": "ea5f_tpu_sketch_generator",
      "input": null,
      "output": {
        "status": "success",
        "sketch": "import cv2\nimport numpy as np\nfrom tflite_runtime.interpreter import load_delegate, Interpreter\n\n# Load interpreter with EdgeTPU\nmodel_path  = \"/home/mendel/tinyml_autopilot/models/edgetpu_detect.tflite\"\ninput_path  = \"/home/mendel/tinyml_autopilot/data//sheeps.mp4\"\noutput_details  = \"/home/mendel/tinyml_autopilot/results/sheeps_detections.mp4\"\nconfidence_threshold  = 0.5\n\ninterpreter = Interpreter(model_path=model_path, experimental_delegates=[load_delegate('/usr/lib/aarch64-linux-gnu/libedgetpu.so.1')])\ninterpreter.allocate_tensors()\n\n# Get model details\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\nheight = input_details[0]['shape'][1]\nwidth = input_details[0]['shape'][2]\nfloating_model = (input_details[0]['dtype'] == np.float32)\n\n# Input acquisition and preprocessing loop\ncap = cv2.VideoCapture(input_path)\nif not cap.isOpened():\n    print(\"Error: Could not open video file.\")\n    exit()\n\nwhile cap.isOpened():\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    # Preprocess data\n    resized_frame = cv2.resize(frame, (width, height))\n    input_data = np.expand_dims(resized_frame, axis=0)\n    if floating_model:\n        input_data = (np.float32(input_data) - 127.5) / 127.5\n\n    # Inference\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n    interpreter.invoke()\n\n    # Output interpretation and handling loop\n    boxes = interpreter.get_tensor(output_details[0]['index'])[0]\n    classes = interpreter.get_tensor(output_details[1]['index'])[0]\n    scores = interpreter.get_tensor(output_details[2]['index'])[0]\n\n    for i in range(len(scores)):\n        if ((scores[i] > confidence_threshold) and (scores[i] <= 1.0)):\n            ymin = int((boxes[i][0] * frame.shape[0]))\n            xmin = int((boxes[i][1] * frame.shape[1]))\n            ymax = int((boxes[i][2] * frame.shape[0]))\n            xmax = int((boxes[i][3] * frame.shape[1]))\n\n            # Handle output\n            cv2.rectangle(frame, (xmin, ymin), (xmax, ymax), (10, 255, 0), 4)\n            object_name = \"Object\"  # replace this with the actual label if available\n            label = '%s: %d%%' % (object_name, int(scores[i]*100))\n            labelSize, baseLine = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.7, 2)\n            ymin = max(ymin, labelSize[1] + 10)\n            cv2.rectangle(frame, (xmin, ymin - labelSize[1] - 10), (xmin + labelSize[0], ymin + baseLine - 10), (255, 255, 255), cv2.FILLED)\n            cv2.putText(frame, label, (xmin, ymin-7), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (10, 255, 0), 2)\n\n    # Display the resulting frame\n    cv2.imshow('Object Detection', frame)\n\n    if cv2.waitKey(1) & 0xFF == ord('q'):\n        break\n\ncap.release()\ncv2.destroyAllWindows()"
      },
      "session_id": "codestral_e6d3_tpusg_batch",
      "metadata": {
        "num_run": 14
      },
      "tags": [
        "benchmark",
        "codestral:latest",
        "tpu_sketch_generator"
      ],
      "latency": 105.014,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-02-37-13-131362_chatcmpl-22e434be-7865-4d1a-b923-ac7a2a71afcf",
          "traceId": "ea5fee76",
          "type": "GENERATION",
          "name": "ea5f_tpusg_gen_attempt#1",
          "startTime": "2025-08-12T23:37:13.131000+00:00",
          "endTime": "2025-08-12T23:37:32.056000+00:00",
          "model": "codestral:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 18925.0,
          "completionTokens": 987,
          "environment": "default",
          "totalTokens": 3035,
          "promptTokens": 2048,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-02-37-39-858567_chatcmpl-c6d8889b-0223-48fb-8482-e1618f64f506",
          "traceId": "ea5fee76",
          "type": "GENERATION",
          "name": "ea5f_tpusg_gen_attempt#2",
          "startTime": "2025-08-12T23:37:39.858000+00:00",
          "endTime": "2025-08-12T23:38:04.761000+00:00",
          "model": "codestral:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 24903.0,
          "completionTokens": 1328,
          "environment": "default",
          "totalTokens": 3376,
          "promptTokens": 2048,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-02-38-12-546563_chatcmpl-1099f834-d5e5-4831-8cd1-22d646ce5722",
          "traceId": "ea5fee76",
          "type": "GENERATION",
          "name": "ea5f_tpusg_gen_attempt#3",
          "startTime": "2025-08-12T23:38:12.546000+00:00",
          "endTime": "2025-08-12T23:38:32.608000+00:00",
          "model": "codestral:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 20062.0,
          "completionTokens": 1055,
          "environment": "default",
          "totalTokens": 3103,
          "promptTokens": 2048,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-02-38-36-674762_chatcmpl-6ddda447-57ed-4ca6-aad6-dc8c628a751a",
          "traceId": "ea5fee76",
          "type": "GENERATION",
          "name": "ea5f_tpusg_gen_attempt#4",
          "startTime": "2025-08-12T23:38:36.674000+00:00",
          "endTime": "2025-08-12T23:38:58.145000+00:00",
          "model": "codestral:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 21471.0,
          "completionTokens": 1135,
          "environment": "default",
          "totalTokens": 3183,
          "promptTokens": 2048,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        }
      ],
      "createdAt": "2025-08-12T23:37:13.648Z",
      "updatedAt": "2025-08-12T23:39:52.876Z",
      "environment": "default"
    },
    {
      "id": "48658181",
      "timestamp": "2025-08-12T23:36:20.458000+00:00",
      "name": "4865_tpu_sketch_generator",
      "input": null,
      "output": {
        "status": "failed",
        "last_code": "import cv2\nimport numpy as np\nfrom tensorflow.lite import Interpreter\nfrom tensorflow.lite.experimental import load_delegate\n\n# Define paths and parameters\nmodel_path  = \"/home/mendel/tinyml_autopilot/models/edgetpu_detect.tflite\"\ninput_path  = \"/home/mendel/tinyml_autopilot/data//sheeps.mp4\"\nlabel_path  = \"/home/mendel/tinyml_autopilot/models/labelmap.txt\"\noutput_path  = \"/home/mendel/tinyml_autopilot/results/sheeps_detections.mp4\"\nconfidence_threshold  = 0.5\n\n# Load labels\nwith open(label_path, 'r') as f:\n    labels = [line.strip() for line in f.readlines()]\n\n# Load interpreter with EdgeTPU\ninterpreter = Interpreter(model_path=model_path, experimental_delegates=[load_delegate('/usr/lib/aarch64-linux-gnu/libedgetpu.so.1.0')])\ninterpreter.allocate_tensors()\n\n# Get model details\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\nheight = input_details[0]['shape'][1]\nwidth = input_details[0]['shape'][2]\nfloating_model = (input_details[0]['dtype'] == np.float32)\n\n# Input acquisition and preprocessing loop\ncap = cv2.VideoCapture(input_path)\nwhile cap.isOpened():\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    # Preprocess data\n    resized_frame = cv2.resize(frame, (width, height))\n    input_data = np.expand_dims(resized_frame, axis=0)\n    if floating_model:\n        input_data = (np.float32(input_data) - 127.5) / 127.5\n\n    # Inference\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n    interpreter.invoke()\n\n    # Output interpretation and handling loop\n    boxes = interpreter.get_tensor(output_details[0]['index'])[0]\n    classes = interpreter.get_tensor(output_details[1]['index'])[0]\n    scores = interpreter.get_tensor(output_details[2]['index'])[0]\n\n    for i in range(len(scores)):\n        if ((scores[i] > confidence_threshold) and (scores[i] <= 1.0)):\n            ymin = int((boxes[i][0] * frame.shape[0]))\n            xmin = int((boxes[i][1] * frame.shape[1]))\n            ymax = int((boxes[i][2] * frame.shape[0]))\n            xmax = int((boxes[i][3] * frame.shape[1]))\n\n            # Handle output\n            cv2.rectangle(frame, (xmin, ymin), (xmax, ymax), (10, 255, 0), 4)\n            object_name = labels[int(classes[i])]\n            label = '%s: %d%%' % (object_name, int(scores[i]*100))\n            labelSize, baseLine = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.7, 2)\n            ymin = max(ymin, labelSize[1] + 10)\n            cv2.rectangle(frame, (xmin, ymin - labelSize[1] - 10), (xmin + labelSize[0], ymin + baseLine - 10), (255, 255, 255), cv2.FILLED)\n            cv2.putText(frame, label, (xmin, ymin - 7), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 0), 2)\n\n    # Display output\n    cv2.imshow('Object Detection', frame)\n    if cv2.waitKey(1) & 0xFF == ord('q'):\n        break\n\n# Cleanup\ncap.release()\ncv2.destroyAllWindows()",
        "last_error": "Unexpected error during generation: The output is not a valid code block. Follow the instructions in the prompt return a complete, correct Python script enclosed in a single ```python\n<generated_code>\n``` block."
      },
      "session_id": "codestral_e6d3_tpusg_batch",
      "metadata": {
        "num_run": 13
      },
      "tags": [
        "benchmark",
        "codestral:latest",
        "tpu_sketch_generator"
      ],
      "latency": 46.244,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-02-36-20-459924_chatcmpl-5810102f-40ec-43db-ad05-cd365a6d751d",
          "traceId": "48658181",
          "type": "GENERATION",
          "name": "4865_tpusg_gen_attempt#1",
          "startTime": "2025-08-12T23:36:20.459000+00:00",
          "endTime": "2025-08-12T23:36:39.379000+00:00",
          "model": "codestral:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 18920.0,
          "completionTokens": 987,
          "environment": "default",
          "totalTokens": 3035,
          "promptTokens": 2048,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-02-36-47-430538_chatcmpl-4b8ad7cd-30fc-4195-9fd9-a4ecc3e5a325",
          "traceId": "48658181",
          "type": "GENERATION",
          "name": "4865_tpusg_gen_attempt#2",
          "startTime": "2025-08-12T23:36:47.430000+00:00",
          "endTime": "2025-08-12T23:36:52.173000+00:00",
          "model": "codestral:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 4743.0,
          "completionTokens": 191,
          "environment": "default",
          "totalTokens": 2239,
          "promptTokens": 2048,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-02-36-52-181308_chatcmpl-96993ca9-f222-41d7-aa8c-77f76f062f29",
          "traceId": "48658181",
          "type": "GENERATION",
          "name": "4865_tpusg_gen_attempt#3",
          "startTime": "2025-08-12T23:36:52.181000+00:00",
          "endTime": "2025-08-12T23:36:56.927000+00:00",
          "model": "codestral:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 4746.0,
          "completionTokens": 193,
          "environment": "default",
          "totalTokens": 2241,
          "promptTokens": 2048,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-02-36-56-933395_chatcmpl-d0572c5c-9d6c-4070-b815-41668392e6d1",
          "traceId": "48658181",
          "type": "GENERATION",
          "name": "4865_tpusg_gen_attempt#4",
          "startTime": "2025-08-12T23:36:56.933000+00:00",
          "endTime": "2025-08-12T23:37:01.678000+00:00",
          "model": "codestral:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 4745.0,
          "completionTokens": 193,
          "environment": "default",
          "totalTokens": 2241,
          "promptTokens": 2048,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-02-37-01-685194_chatcmpl-abf6d70c-2b85-469e-b458-04edbd938902",
          "traceId": "48658181",
          "type": "GENERATION",
          "name": "4865_tpusg_gen_attempt#5",
          "startTime": "2025-08-12T23:37:01.685000+00:00",
          "endTime": "2025-08-12T23:37:06.698000+00:00",
          "model": "codestral:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 5013.0,
          "completionTokens": 208,
          "environment": "default",
          "totalTokens": 2256,
          "promptTokens": 2048,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "0be0116d-9687-4b91-9f28-751cafa212bf",
          "traceId": "48658181",
          "type": "SPAN",
          "name": "error_48_tpusg_failure_signal_tpu_sketch_generator",
          "startTime": "2025-08-12T23:37:06.703000+00:00",
          "level": "ERROR",
          "statusMessage": "Failed. Last error: Unexpected error during generation: The output is not a valid code block. Follow the instructions in the prompt return a complete, correct Python script enclosed in a single ```python\n<generated_code>\n``` block.",
          "calculatedTotalCost": 0.0,
          "completionTokens": 0,
          "environment": "default",
          "totalTokens": 0,
          "promptTokens": 0,
          "costDetails": {},
          "endTime": null,
          "model": null,
          "modelParameters": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null,
          "latency": null
        }
      ],
      "createdAt": "2025-08-12T23:36:20.978Z",
      "updatedAt": "2025-08-12T23:37:12.122Z",
      "environment": "default"
    },
    {
      "id": "eff1795e",
      "timestamp": "2025-08-12T23:34:03.047000+00:00",
      "name": "eff1_tpu_sketch_generator",
      "input": null,
      "output": {
        "status": "success",
        "sketch": "import cv2\nimport numpy as np\nfrom tflite_runtime.interpreter import load_delegate, Interpreter\n\n# Define the paths\nlabel_path  = \"/home/mendel/tinyml_autopilot/models/labelmap.txt\"\nmodel_path  = \"/home/mendel/tinyml_autopilot/models/edgetpu_detect.tflite\"\ninput_path  = \"/home/mendel/tinyml_autopilot/data//sheeps.mp4\"\noutput_path  = \"/home/mendel/tinyml_autopilot/results/sheeps_detections.mp4\"\nconfidence_threshold  = 0.5\n\n# Load labels\nwith open(label_path, 'r') as f:\n    labels = [line.strip() for line in f.readlines()]\n\n# Load interpreter with EdgeTPU\ninterpreter = Interpreter(model_path=model_path, experimental_delegates=[load_delegate('/usr/lib/aarch64-linux-gnu/libedgetpu.so.1')])\ninterpreter.allocate_tensors()\n\n# Get model details\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\nheight = input_details[0]['shape'][1]\nwidth = input_details[0]['shape'][2]\nfloating_model = (input_details[0]['dtype'] == np.float32)\n\n# Input acquisition and preprocessing loop\ncap = cv2.VideoCapture(input_path)\nfourcc = cv2.VideoWriter_fourcc(*'mp4v')\nout = cv2.VideoWriter(output_path, fourcc, 20.0, (int(cap.get(3)), int(cap.get(4))))\nwhile cap.isOpened():\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    # Preprocess data\n    resized_frame = cv2.resize(frame, (width, height))\n    input_data = np.expand_dims(resized_frame, axis=0)\n    if floating_model:\n        input_data = (np.float32(input_data) - 127.5) / 127.5\n\n    # Inference\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n    interpreter.invoke()\n\n    # Output interpretation and handling loop\n    boxes = interpreter.get_tensor(output_details[0]['index'])[0]\n    classes = interpreter.get_tensor(output_details[1]['index'])[0]\n    scores = interpreter.get_tensor(output_details[2]['index'])[0]\n\n    for i in range(len(scores)):\n        if ((scores[i] > confidence_threshold) and (scores[i] <= 1.0)):\n            ymin = int((boxes[i][0] * frame.shape[0]))\n            xmin = int((boxes[i][1] * frame.shape[1]))\n            ymax = int((boxes[i][2] * frame.shape[0]))\n            xmax = int((boxes[i][3] * frame.shape[1]))\n\n            # Handle output\n            cv2.rectangle(frame, (xmin, ymin), (xmax, ymax), (10, 255, 0), 4)\n            object_name = labels[int(classes[i])]\n            label = '%s: %d%%' % (object_name, int(scores[i]*100))\n            labelSize, baseLine = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.7, 2)\n            ymin = max(ymin, labelSize[1] + 10)\n            cv2.rectangle(frame, (xmin, ymin - labelSize[1] - 10), (xmin + labelSize[0], ymin + baseLine - 10), (255, 255, 255), cv2.FILLED)\n            cv2.putText(frame, label, (xmin, ymin-7), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 0), 2)\n    out.write(frame)\ncap.release()\nout.release()"
      },
      "session_id": "codestral_e6d3_tpusg_batch",
      "metadata": {
        "num_run": 12
      },
      "tags": [
        "benchmark",
        "codestral:latest",
        "tpu_sketch_generator"
      ],
      "latency": 77.211,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-02-34-03-050050_chatcmpl-6fd002c4-ac28-4dbd-883c-b13d28e71c63",
          "traceId": "eff1795e",
          "type": "GENERATION",
          "name": "eff1_tpusg_gen_attempt#1",
          "startTime": "2025-08-12T23:34:03.050000+00:00",
          "endTime": "2025-08-12T23:34:21.955000+00:00",
          "model": "codestral:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 18905.0,
          "completionTokens": 987,
          "environment": "default",
          "totalTokens": 3035,
          "promptTokens": 2048,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-02-34-29-854734_chatcmpl-94e889ec-f9b6-4500-98b3-64206355b8fc",
          "traceId": "eff1795e",
          "type": "GENERATION",
          "name": "eff1_tpusg_gen_attempt#2",
          "startTime": "2025-08-12T23:34:29.854000+00:00",
          "endTime": "2025-08-12T23:34:49.946000+00:00",
          "model": "codestral:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 20092.0,
          "completionTokens": 1057,
          "environment": "default",
          "totalTokens": 3105,
          "promptTokens": 2048,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-02-34-58-737521_chatcmpl-d2420586-6a26-4193-b67a-1509d1d9d090",
          "traceId": "eff1795e",
          "type": "GENERATION",
          "name": "eff1_tpusg_gen_attempt#3",
          "startTime": "2025-08-12T23:34:58.737000+00:00",
          "endTime": "2025-08-12T23:35:20.261000+00:00",
          "model": "codestral:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 21524.0,
          "completionTokens": 1138,
          "environment": "default",
          "totalTokens": 3186,
          "promptTokens": 2048,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        }
      ],
      "createdAt": "2025-08-12T23:34:03.563Z",
      "updatedAt": "2025-08-12T23:36:18.838Z",
      "environment": "default"
    },
    {
      "id": "958622f5",
      "timestamp": "2025-08-12T23:32:22.411000+00:00",
      "name": "9586_tpu_sketch_generator",
      "input": null,
      "output": {
        "status": "success",
        "sketch": "import cv2\nimport numpy as np\nfrom tflite_runtime.interpreter import Interpreter, load_delegate\n\n# Load the TFLite model and allocate tensors\ntry:\n    interpreter = Interpreter(model_path='/home/mendel/tinyml_autopilot/data/model.tflite',\n                              experimental_delegates=[load_delegate('libedgetpu.so.1')])\nexcept ValueError as e:\n    print(\"Error loading model:\", str(e))\n    exit()\ninterpreter.allocate_tensors()\n\n# Get input and output details\ninput_details  = \"/home/mendel/tinyml_autopilot/data//sheeps.mp4\"\noutput_details  = \"/home/mendel/tinyml_autopilot/results/sheeps_detections.mp4\"\nheight = input_details[0]['shape'][1]\nwidth = input_details[0]['shape'][2]\n\n# Open the video file\ncap = cv2.VideoCapture('/home/mendel/tinyml_autopilot/data/sheeps.mp4')\n\nwhile cap.isOpened():\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    # Preprocess the image\n    image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n    image = cv2.resize(image, (width, height))\n    input_data = np.expand_dims(image, axis=0)\n    if input_details[0]['dtype'] == np.float32:\n        input_data = (np.float32(input_data) - 127.5) / 127.5\n\n    # Set the tensor to point to the input data to be used for inference\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n\n    # Run inference\n    interpreter.invoke()\n\n    # Get output data\n    output_data = interpreter.get_tensor(output_details[0]['index'])\n    results = np.squeeze(output_data)\n\n    # Interpret results and handle output\n    print(results)\n\n# Release the video capture object and close any open windows\ncap.release()\ncv2.destroyAllWindows()"
      },
      "session_id": "codestral_e6d3_tpusg_batch",
      "metadata": {
        "num_run": 11
      },
      "tags": [
        "benchmark",
        "codestral:latest",
        "tpu_sketch_generator"
      ],
      "latency": 86.614,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-02-32-22-415799_chatcmpl-0de8cb25-ee3f-41b0-9efa-7c3654aaddbd",
          "traceId": "958622f5",
          "type": "GENERATION",
          "name": "9586_tpusg_gen_attempt#1",
          "startTime": "2025-08-12T23:32:22.415000+00:00",
          "endTime": "2025-08-12T23:32:41.363000+00:00",
          "model": "codestral:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 18948.0,
          "completionTokens": 987,
          "environment": "default",
          "totalTokens": 3035,
          "promptTokens": 2048,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-02-32-49-382630_chatcmpl-7c9f4e5c-488d-4e0b-bce7-ead6355dc037",
          "traceId": "958622f5",
          "type": "GENERATION",
          "name": "9586_tpusg_gen_attempt#2",
          "startTime": "2025-08-12T23:32:49.382000+00:00",
          "endTime": "2025-08-12T23:32:53.134000+00:00",
          "model": "codestral:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 3752.0,
          "completionTokens": 135,
          "environment": "default",
          "totalTokens": 2183,
          "promptTokens": 2048,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-02-32-53-151777_chatcmpl-186672ae-c56d-4830-b2b6-a2b52c3ec7e8",
          "traceId": "958622f5",
          "type": "GENERATION",
          "name": "9586_tpusg_gen_attempt#3",
          "startTime": "2025-08-12T23:32:53.151000+00:00",
          "endTime": "2025-08-12T23:33:05.819000+00:00",
          "model": "codestral:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 12668.0,
          "completionTokens": 639,
          "environment": "default",
          "totalTokens": 2687,
          "promptTokens": 2048,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-02-33-13-730537_chatcmpl-a454eabb-7435-4b07-af74-1a9f9e655b70",
          "traceId": "958622f5",
          "type": "GENERATION",
          "name": "9586_tpusg_gen_attempt#4",
          "startTime": "2025-08-12T23:33:13.730000+00:00",
          "endTime": "2025-08-12T23:33:28.028000+00:00",
          "model": "codestral:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 14298.0,
          "completionTokens": 728,
          "environment": "default",
          "totalTokens": 2776,
          "promptTokens": 2048,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-02-33-35-939744_chatcmpl-d539c03e-e1a2-4284-b87e-b358a67fd288",
          "traceId": "958622f5",
          "type": "GENERATION",
          "name": "9586_tpusg_gen_attempt#5",
          "startTime": "2025-08-12T23:33:35.939000+00:00",
          "endTime": "2025-08-12T23:33:49.029000+00:00",
          "model": "codestral:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 13090.0,
          "completionTokens": 662,
          "environment": "default",
          "totalTokens": 2710,
          "promptTokens": 2048,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        }
      ],
      "createdAt": "2025-08-12T23:32:22.942Z",
      "updatedAt": "2025-08-12T23:34:02.164Z",
      "environment": "default"
    },
    {
      "id": "a6f0f20c",
      "timestamp": "2025-08-12T23:30:22.272000+00:00",
      "name": "a6f0_tpu_sketch_generator",
      "input": null,
      "output": {
        "status": "failed",
        "last_code": "# Load model with EdgeTPU\ntry:\n    interpreter = Interpreter(model_path='your_model.tflite',\n                              experimental_delegates=[load_delegate('libedgetpu.so.1')])\nexcept ValueError:\n    interpreter = Interpreter(model_path='your_model.tflite',\n                              experimental_delegates=[load_delegate('/usr/lib/aarch64-linux-gnu/libedgetpu.so.1')])\ninterpreter.allocate_tensors()\n\n# Get model details\ninput_details  = \"/home/mendel/tinyml_autopilot/data//sheeps.mp4\"\noutput_details  = \"/home/mendel/tinyml_autopilot/results/sheeps_detections.mp4\"\nheight = input_details[0]['shape'][1]\nwidth = input_details[0]['shape'][2]\nfloating_model = (input_details[0]['dtype'] == np.float32)\n\n# Open video file\ncap = cv2.VideoCapture('sheeps.mp4')\n\nwhile cap.isOpened():\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    # Preprocess data\n    img = Image.fromarray(frame)\n    img = img.resize((width, height))\n    input_data = np.expand_dims(img, axis=0)\n    if floating_model:\n        input_data = (np.float32(input_data) - 127.5) / 127.5\n\n    # Run inference\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n    interpreter.invoke()\n\n    # Interpret results\n    boxes = interpreter.get_tensor(output_details[0]['index'])[0]\n    classes = interpreter.get_tensor(output_details[1]['index'])[0]\n    scores = interpreter.get_tensor(output_details[2]['index'])[0]\n\n    # Post-processing and displaying the results is omitted for brevity",
        "last_error": "Traceback (most recent call last):\n  File \"script_b1c3be98_1755041527.py\", line 3, in <module>\n    interpreter = Interpreter(model_path='your_model.tflite',\nNameError: name 'Interpreter' is not defined"
      },
      "session_id": "codestral_e6d3_tpusg_batch",
      "metadata": {
        "num_run": 10
      },
      "tags": [
        "benchmark",
        "codestral:latest",
        "tpu_sketch_generator"
      ],
      "latency": 109.627,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-02-30-22-274104_chatcmpl-5a6e6856-4d1c-4e47-b71a-0e7666a97038",
          "traceId": "a6f0f20c",
          "type": "GENERATION",
          "name": "a6f0_tpusg_gen_attempt#1",
          "startTime": "2025-08-12T23:30:22.274000+00:00",
          "endTime": "2025-08-12T23:30:41.443000+00:00",
          "model": "codestral:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 19169.0,
          "completionTokens": 1001,
          "environment": "default",
          "totalTokens": 3049,
          "promptTokens": 2048,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-02-30-49-286630_chatcmpl-9dcac2a7-9276-45b4-b92d-472c2671e2b0",
          "traceId": "a6f0f20c",
          "type": "GENERATION",
          "name": "a6f0_tpusg_gen_attempt#2",
          "startTime": "2025-08-12T23:30:49.286000+00:00",
          "endTime": "2025-08-12T23:30:54.537000+00:00",
          "model": "codestral:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 5251.0,
          "completionTokens": 220,
          "environment": "default",
          "totalTokens": 2268,
          "promptTokens": 2048,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-02-30-54-545452_chatcmpl-1f2ce5fc-c5cb-434b-8f39-c49d17051eed",
          "traceId": "a6f0f20c",
          "type": "GENERATION",
          "name": "a6f0_tpusg_gen_attempt#3",
          "startTime": "2025-08-12T23:30:54.545000+00:00",
          "endTime": "2025-08-12T23:31:17.605000+00:00",
          "model": "codestral:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 23060.0,
          "completionTokens": 1223,
          "environment": "default",
          "totalTokens": 3271,
          "promptTokens": 2048,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-02-31-25-653974_chatcmpl-df352115-814d-4321-9b50-19ff685d6d68",
          "traceId": "a6f0f20c",
          "type": "GENERATION",
          "name": "a6f0_tpusg_gen_attempt#4",
          "startTime": "2025-08-12T23:31:25.653000+00:00",
          "endTime": "2025-08-12T23:31:47.364000+00:00",
          "model": "codestral:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 21711.0,
          "completionTokens": 1147,
          "environment": "default",
          "totalTokens": 3195,
          "promptTokens": 2048,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-02-31-55-212869_chatcmpl-bc3320bf-63f3-4622-bba7-8a6d20b05bcc",
          "traceId": "a6f0f20c",
          "type": "GENERATION",
          "name": "a6f0_tpusg_gen_attempt#5",
          "startTime": "2025-08-12T23:31:55.212000+00:00",
          "endTime": "2025-08-12T23:32:07.766000+00:00",
          "model": "codestral:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 12554.0,
          "completionTokens": 632,
          "environment": "default",
          "totalTokens": 2680,
          "promptTokens": 2048,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "0ba5d894-5a87-4ca0-832a-f03974f4e5ae",
          "traceId": "a6f0f20c",
          "type": "SPAN",
          "name": "error_a6_tpusg_failure_signal_tpu_sketch_generator",
          "startTime": "2025-08-12T23:32:11.901000+00:00",
          "level": "ERROR",
          "statusMessage": "Failed. Last error: Traceback (most recent call last):\n  File \"script_b1c3be98_1755041527.py\", line 3, in <module>\n    interpreter = Interpreter(model_path='your_model.tflite',\nNameError: name 'Interpreter' is not defined",
          "calculatedTotalCost": 0.0,
          "completionTokens": 0,
          "environment": "default",
          "totalTokens": 0,
          "promptTokens": 0,
          "costDetails": {},
          "endTime": null,
          "model": null,
          "modelParameters": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null,
          "latency": null
        }
      ],
      "createdAt": "2025-08-12T23:30:22.790Z",
      "updatedAt": "2025-08-12T23:32:17.523Z",
      "environment": "default"
    },
    {
      "id": "1dca5d6e",
      "timestamp": "2025-08-12T23:28:40.715000+00:00",
      "name": "1dca_tpu_sketch_generator",
      "input": null,
      "output": {
        "status": "failed",
        "last_code": "import numpy as np\nimport cv2\nfrom tensorflow.lite.python.interpreter import Interpreter\nfrom tensorflow.lite.python.interpreter import load_delegate\n\n# Define paths and parameters\nlabel_path  = \"/home/mendel/tinyml_autopilot/models/labelmap.txt\"\nmodel_path  = \"/home/mendel/tinyml_autopilot/models/edgetpu_detect.tflite\"\ninput_path  = \"/home/mendel/tinyml_autopilot/data//sheeps.mp4\"\noutput_path  = \"/home/mendel/tinyml_autopilot/results/sheeps_detections.mp4\"\nconfidence_threshold  = 0.5\n\n# Load labels\nwith open(label_path, 'r') as f:\n    labels = [line.strip() for line in f.readlines()]\n\n# Load interpreter with EdgeTPU\ninterpreter = Interpreter(model_path=model_path, experimental_delegates=[load_delegate('/usr/lib/aarch64-linux-gnu/libedgetpu.so')])\ninterpreter.allocate_tensors()\n\n# Get model details\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\nheight = input_details[0]['shape'][1]\nwidth = input_details[0]['shape'][2]\nfloating_model = (input_details[0]['dtype'] == np.float32)\n\n# Input acquisition and preprocessing loop\ncap = cv2.VideoCapture(input_path)\nout = cv2.VideoWriter(output_path, cv2.VideoWriter_fourcc(*'XVID'), 30.0, (width, height))\n\nwhile cap.isOpened():\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    # Preprocess data\n    resized_frame = cv2.resize(frame, (width, height))\n    input_data = np.expand_dims(resized_frame, axis=0)\n\n    # Quantization handling\n    if floating_model:\n        input_data = (np.float32(input_data) - 127.5) / 127.5\n\n    # Inference\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n    interpreter.invoke()\n\n    # Output interpretation and handling\n    boxes = interpreter.get_tensor(output_details[0]['index'])[0]\n    classes = interpreter.get_tensor(output_details[1]['index'])[0]\n    scores = interpreter.get_tensor(output_details[2]['index'])[0]\n\n    for i in range(len(scores)):\n        if ((scores[i] > confidence_threshold) and (scores[i] <= 1.0)):\n            ymin = int(max(1, (boxes[i][0] * height)))\n            xmin = int(max(1, (boxes[i][1] * width)))\n            ymax = int(min(height, (boxes[i][2] * height)))\n            xmax = int(min(width, (boxes[i][3] * width)))\n\n            cv2.rectangle(frame, (xmin, ymin), (xmax, ymax), (10, 255, 0), 4)\n            object_name = labels[int(classes[i])]\n            label = '%s: %d%%' % (object_name, int(scores[i]*100))\n            labelSize, baseLine = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.7, 2)\n            label_ymin = max(ymin, labelSize[1] + 10)\n            cv2.rectangle(frame, (xmin, label_ymin-labelSize[1]-10), (xmin + labelSize[0], label_ymin+baseLine-10), (255, 255, 255), cv2.FILLED)\n            cv2.putText(frame, label, (xmin, label_ymin-7), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 0), 2)\n    out.write(frame)\ncap.release()\nout.release()",
        "last_error": "Unexpected error during generation: The output is not a valid code block. Follow the instructions in the prompt return a complete, correct Python script enclosed in a single ```python\n<generated_code>\n``` block."
      },
      "session_id": "codestral_e6d3_tpusg_batch",
      "metadata": {
        "num_run": 9
      },
      "tags": [
        "benchmark",
        "codestral:latest",
        "tpu_sketch_generator"
      ],
      "latency": 95.3,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-02-28-40-717300_chatcmpl-1c407faa-0eba-4d8b-812e-a32b544bd748",
          "traceId": "1dca5d6e",
          "type": "GENERATION",
          "name": "1dca_tpusg_gen_attempt#1",
          "startTime": "2025-08-12T23:28:40.717000+00:00",
          "endTime": "2025-08-12T23:29:00.092000+00:00",
          "model": "codestral:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 19375.0,
          "completionTokens": 1001,
          "environment": "default",
          "totalTokens": 3049,
          "promptTokens": 2048,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-02-29-07-994733_chatcmpl-6a8f3b73-8112-41d3-bc8c-84ed122a9b3b",
          "traceId": "1dca5d6e",
          "type": "GENERATION",
          "name": "1dca_tpusg_gen_attempt#2",
          "startTime": "2025-08-12T23:29:07.994000+00:00",
          "endTime": "2025-08-12T23:29:29.473000+00:00",
          "model": "codestral:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 21479.0,
          "completionTokens": 1134,
          "environment": "default",
          "totalTokens": 3182,
          "promptTokens": 2048,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-02-29-37-192187_chatcmpl-45103aff-134f-4b92-a4dd-f5f0ec5d28ac",
          "traceId": "1dca5d6e",
          "type": "GENERATION",
          "name": "1dca_tpusg_gen_attempt#3",
          "startTime": "2025-08-12T23:29:37.192000+00:00",
          "endTime": "2025-08-12T23:29:59.079000+00:00",
          "model": "codestral:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 21887.0,
          "completionTokens": 1158,
          "environment": "default",
          "totalTokens": 3206,
          "promptTokens": 2048,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-02-30-06-866925_chatcmpl-1c5ae1b9-9bfe-40ba-8270-807e2e31b442",
          "traceId": "1dca5d6e",
          "type": "GENERATION",
          "name": "1dca_tpusg_gen_attempt#4",
          "startTime": "2025-08-12T23:30:06.866000+00:00",
          "endTime": "2025-08-12T23:30:10.430000+00:00",
          "model": "codestral:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 3564.0,
          "completionTokens": 124,
          "environment": "default",
          "totalTokens": 2172,
          "promptTokens": 2048,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-02-30-10-437324_chatcmpl-05458a28-7b9d-4d55-8cf7-2995ffabc485",
          "traceId": "1dca5d6e",
          "type": "GENERATION",
          "name": "1dca_tpusg_gen_attempt#5",
          "startTime": "2025-08-12T23:30:10.437000+00:00",
          "endTime": "2025-08-12T23:30:16.012000+00:00",
          "model": "codestral:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 5575.0,
          "completionTokens": 229,
          "environment": "default",
          "totalTokens": 2277,
          "promptTokens": 2048,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "fd610cb8-5e4a-4ac3-af37-30192cab97b2",
          "traceId": "1dca5d6e",
          "type": "SPAN",
          "name": "error_1d_tpusg_failure_signal_tpu_sketch_generator",
          "startTime": "2025-08-12T23:30:16.017000+00:00",
          "level": "ERROR",
          "statusMessage": "Failed. Last error: Unexpected error during generation: The output is not a valid code block. Follow the instructions in the prompt return a complete, correct Python script enclosed in a single ```python\n<generated_code>\n``` block.",
          "calculatedTotalCost": 0.0,
          "completionTokens": 0,
          "environment": "default",
          "totalTokens": 0,
          "promptTokens": 0,
          "costDetails": {},
          "endTime": null,
          "model": null,
          "modelParameters": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null,
          "latency": null
        }
      ],
      "createdAt": "2025-08-12T23:28:41.231Z",
      "updatedAt": "2025-08-12T23:30:21.444Z",
      "environment": "default"
    },
    {
      "id": "4ef98a63",
      "timestamp": "2025-08-12T23:26:37.138000+00:00",
      "name": "4ef9_tpu_sketch_generator",
      "input": null,
      "output": {
        "status": "failed",
        "last_code": "import numpy as np\nfrom tflite_runtime.interpreter import Interpreter\nfrom tflite_runtime.interpreter import load_delegate\nimport cv2\n\n# Load interpreter with EdgeTPU\ninterpreter = Interpreter(model_path='/home/mendel/tinyml_autopilot/models/detect.tflite', experimental_delegates=[load_delegate('/usr/lib/aarch64-linux-gnu/libedgetpu.so.1')])\ninterpreter.allocate_tensors()\n\n# Get model details\ninput_details  = \"/home/mendel/tinyml_autopilot/data//sheeps.mp4\"\noutput_details  = \"/home/mendel/tinyml_autopilot/results/sheeps_detections.mp4\"\nheight = input_details[0]['shape'][1]\nwidth = input_details[0]['shape'][2]\nfloating_model = (input_details[0]['dtype'] == np.float32)\nconfidence_threshold  = 0.5\n\n# Open output video writer\nfourcc = cv2.VideoWriter_fourcc(*'mp4v')\nout = cv2.VideoWriter('/home/mendel/tinyml_autopilot/results/sheeps_detections.mp4', fourcc, 30.0, (640,  480))\n\n# Input acquisition and preprocessing loop\ncap = cv2.VideoCapture('/home/mendel/tinyml_autopilot/data/sheeps.mp4')\nwhile cap.isOpened():\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    # Preprocess data\n    resized_frame = cv2.resize(frame, (width, height))\n    input_data = np.expand_dims(resized_frame, axis=0)\n    if floating_model:\n        input_data = (np.float32(input_data) - 127.5) / 127.5\n\n    # Inference\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n    interpreter.invoke()\n\n    # Output interpretation and handling loop\n    boxes = interpreter.get_tensor(output_details[0]['index'])[0]\n    classes = interpreter.get_tensor(output_details[1]['index'])[0]\n    scores = interpreter.get_tensor(output_details[2]['index'])[0]\n\n    for i in range(len(scores)):\n        if ((scores[i] > confidence_threshold) and (scores[i] <= 1.0)):\n            ymin = int((boxes[i][0] * frame.shape[0]))\n            xmin = int((boxes[i][1] * frame.shape[1]))\n            ymax = int((boxes[i][2] * frame.shape[0]))\n            xmax = int((boxes[i][3] * frame.shape[1]))\n\n            # Handle output\n            print('Detected object with confidence:', scores[i]*100)\n            cv2.rectangle(frame, (xmin, ymin), (xmax, ymax), (0, 255, 0), 2)\n    out.write(frame)\n\n# Release resources\ncap.release()\nout.release()",
        "last_error": "Traceback (most recent call last):\n  File \"script_2b6b681f_1755041306.py\", line 13, in <module>\n    height = input_details[0]['shape'][1]\nTypeError: string indices must be integers"
      },
      "session_id": "codestral_e6d3_tpusg_batch",
      "metadata": {
        "num_run": 8
      },
      "tags": [
        "benchmark",
        "codestral:latest",
        "tpu_sketch_generator"
      ],
      "latency": 117.232,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-02-26-37-140369_chatcmpl-d890cbf0-afda-4ee1-b9de-72cfef6bc0b8",
          "traceId": "4ef98a63",
          "type": "GENERATION",
          "name": "4ef9_tpusg_gen_attempt#1",
          "startTime": "2025-08-12T23:26:37.140000+00:00",
          "endTime": "2025-08-12T23:26:56.071000+00:00",
          "model": "codestral:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 18931.0,
          "completionTokens": 987,
          "environment": "default",
          "totalTokens": 3035,
          "promptTokens": 2048,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-02-27-04-016125_chatcmpl-3ef2575c-62ab-4ae1-8bb6-7694144393c0",
          "traceId": "4ef98a63",
          "type": "GENERATION",
          "name": "4ef9_tpusg_gen_attempt#2",
          "startTime": "2025-08-12T23:27:04.016000+00:00",
          "endTime": "2025-08-12T23:27:18.961000+00:00",
          "model": "codestral:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 14945.0,
          "completionTokens": 767,
          "environment": "default",
          "totalTokens": 2815,
          "promptTokens": 2048,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-02-27-23-614082_chatcmpl-ba36d764-26af-4fc5-93cc-66215470e40a",
          "traceId": "4ef98a63",
          "type": "GENERATION",
          "name": "4ef9_tpusg_gen_attempt#3",
          "startTime": "2025-08-12T23:27:23.614000+00:00",
          "endTime": "2025-08-12T23:27:40.024000+00:00",
          "model": "codestral:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 16410.0,
          "completionTokens": 850,
          "environment": "default",
          "totalTokens": 2898,
          "promptTokens": 2048,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-02-27-47-700537_chatcmpl-916f3502-854a-4825-bb6a-dd3f41d74ebb",
          "traceId": "4ef98a63",
          "type": "GENERATION",
          "name": "4ef9_tpusg_gen_attempt#4",
          "startTime": "2025-08-12T23:27:47.700000+00:00",
          "endTime": "2025-08-12T23:28:02.202000+00:00",
          "model": "codestral:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 14502.0,
          "completionTokens": 742,
          "environment": "default",
          "totalTokens": 2790,
          "promptTokens": 2048,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-02-28-09-933061_chatcmpl-0791d7f1-b452-4368-8d9c-3ef56df9da48",
          "traceId": "4ef98a63",
          "type": "GENERATION",
          "name": "4ef9_tpusg_gen_attempt#5",
          "startTime": "2025-08-12T23:28:09.933000+00:00",
          "endTime": "2025-08-12T23:28:26.645000+00:00",
          "model": "codestral:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 16712.0,
          "completionTokens": 866,
          "environment": "default",
          "totalTokens": 2914,
          "promptTokens": 2048,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "039ff544-b346-445f-a984-c06e22e32d43",
          "traceId": "4ef98a63",
          "type": "SPAN",
          "name": "error_4e_tpusg_failure_signal_tpu_sketch_generator",
          "startTime": "2025-08-12T23:28:34.372000+00:00",
          "level": "ERROR",
          "statusMessage": "Failed. Last error: Traceback (most recent call last):\n  File \"script_2b6b681f_1755041306.py\", line 13, in <module>\n    height = input_details[0]['shape'][1]\nTypeError: string indices must be integers",
          "calculatedTotalCost": 0.0,
          "completionTokens": 0,
          "environment": "default",
          "totalTokens": 0,
          "promptTokens": 0,
          "costDetails": {},
          "endTime": null,
          "model": null,
          "modelParameters": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null,
          "latency": null
        }
      ],
      "createdAt": "2025-08-12T23:26:37.653Z",
      "updatedAt": "2025-08-12T23:28:39.883Z",
      "environment": "default"
    },
    {
      "id": "9939e16f",
      "timestamp": "2025-08-12T23:24:32.889000+00:00",
      "name": "9939_tpu_sketch_generator",
      "input": null,
      "output": {
        "status": "failed",
        "last_code": "# Load labels\nwith open(label_path, 'r') as f:\n    labels = [line.strip() for line in f.readlines()]\n\n# Load interpreter with EdgeTPU\ninterpreter = Interpreter(model_path=model_path)\ninterpreter.allocate_tensors()\ndelegate = load_delegate('/usr/lib/aarch64-linux-gnu/libedgetpu.so.1')\ninterpreter.set_delegates([delegate])\n\n# Get model details\ninput_details  = \"/home/mendel/tinyml_autopilot/data//sheeps.mp4\"\noutput_details  = \"/home/mendel/tinyml_autopilot/results/sheeps_detections.mp4\"\nheight = input_details[0]['shape'][1]\nwidth = input_details[0]['shape'][2]\n\n# Input acquisition and preprocessing loop\ncap = cv2.VideoCapture(input_path)  # Assuming input is a video file\nwhile cap.isOpened():\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    # Preprocess data\n    resized_frame = cv2.resize(frame, (width, height))\n    input_data = np.expand_dims(resized_frame, axis=0)\n\n    # Quantization handling\n    floating_model = (input_details[0]['dtype'] == np.float32)\n    if floating_model:\n        input_data = (np.float32(input_data) - 127.5) / 127.5\n\n    # Inference\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n    interpreter.invoke()\n\n    # Output interpretation and handling loop\n    output_data = interpreter.get_tensor(output_details[0]['index'])\n\n    # Interpret results (assuming object detection model)\n    boxes = output_data[0][:, :4]\n    classes = output_data[0][:, 5].astype(int)\n    scores = output_data[0][:, 4]\n\n    for i in range(len(scores)):\n        if ((scores[i] > confidence_threshold) and (scores[i] <= 1.0)):\n            ymin = int(max(1,(boxes[i][0] * frame.shape[0])))\n            xmin = int(max(1,(boxes[i][1] * frame.shape[1])))\n            ymax = int(min(frame.shape[0],(boxes[i][2] * frame.shape[0])))\n            xmax = int(min(frame.shape[1],(boxes[i][3] * frame.shape[1])))\n\n            cv2.rectangle(frame, (xmin, ymin), (xmax, ymax), (10, 255, 0), 4)\n            object_name = labels[int(classes[i])]\n            label = '%s: %d%%' % (object_name, int(scores[i]*100))\n            labelSize, baseLine = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.7, 2)\n            label_ymin = max(ymin, labelSize[1] + 10)\n            cv2.rectangle(frame, (xmin, label_ymin-labelSize[1]-10), (xmin+labelSize[0], label_ymin+baseLine-10), (255, 255, 255), cv2.FILLED)\n            cv2.putText(frame, label, (xmin, label_ymin-7), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 0), 2)\n\n    # Handle output (display frame with bounding boxes)\n    cv2.imshow('Object Detection', frame)\n    if cv2.waitKey(1) & 0xFF == ord('q'):\n        break\n\ncap.release()\ncv2.destroyAllWindows()",
        "last_error": "Traceback (most recent call last):\n  File \"script_f8d9fcaa_1755041185.py\", line 2, in <module>\n    with open(label_path, 'r') as f:\nNameError: name 'label_path' is not defined"
      },
      "session_id": "codestral_e6d3_tpusg_batch",
      "metadata": {
        "num_run": 7
      },
      "tags": [
        "benchmark",
        "codestral:latest",
        "tpu_sketch_generator"
      ],
      "latency": 117.183,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-02-24-32-891942_chatcmpl-5fe927aa-c363-4092-a1d9-19615f8c3510",
          "traceId": "9939e16f",
          "type": "GENERATION",
          "name": "9939_tpusg_gen_attempt#1",
          "startTime": "2025-08-12T23:24:32.891000+00:00",
          "endTime": "2025-08-12T23:24:51.793000+00:00",
          "model": "codestral:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 18902.0,
          "completionTokens": 987,
          "environment": "default",
          "totalTokens": 3035,
          "promptTokens": 2048,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-02-24-59-615257_chatcmpl-343be046-40b0-4d4b-8636-9bcd8fbecdb3",
          "traceId": "9939e16f",
          "type": "GENERATION",
          "name": "9939_tpusg_gen_attempt#2",
          "startTime": "2025-08-12T23:24:59.615000+00:00",
          "endTime": "2025-08-12T23:25:07.578000+00:00",
          "model": "codestral:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 7963.0,
          "completionTokens": 373,
          "environment": "default",
          "totalTokens": 2421,
          "promptTokens": 2048,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-02-25-07-586519_chatcmpl-5ac68f42-ba7f-4d93-8bc6-b8a1982aceb8",
          "traceId": "9939e16f",
          "type": "GENERATION",
          "name": "9939_tpusg_gen_attempt#3",
          "startTime": "2025-08-12T23:25:07.586000+00:00",
          "endTime": "2025-08-12T23:25:28.687000+00:00",
          "model": "codestral:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 21101.0,
          "completionTokens": 1116,
          "environment": "default",
          "totalTokens": 3164,
          "promptTokens": 2048,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-02-25-36-390933_chatcmpl-ab2929a8-992e-4505-b2ab-b0b5f2505e65",
          "traceId": "9939e16f",
          "type": "GENERATION",
          "name": "9939_tpusg_gen_attempt#4",
          "startTime": "2025-08-12T23:25:36.390000+00:00",
          "endTime": "2025-08-12T23:25:57.425000+00:00",
          "model": "codestral:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 21035.0,
          "completionTokens": 1109,
          "environment": "default",
          "totalTokens": 3157,
          "promptTokens": 2048,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-02-26-05-287263_chatcmpl-ca06db7e-2e6c-4f7a-904a-cc3dfc868a75",
          "traceId": "9939e16f",
          "type": "GENERATION",
          "name": "9939_tpusg_gen_attempt#5",
          "startTime": "2025-08-12T23:26:05.287000+00:00",
          "endTime": "2025-08-12T23:26:25.987000+00:00",
          "model": "codestral:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 20700.0,
          "completionTokens": 1091,
          "environment": "default",
          "totalTokens": 3139,
          "promptTokens": 2048,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "f4152c95-d106-49e6-8444-b6af1ec73c7c",
          "traceId": "9939e16f",
          "type": "SPAN",
          "name": "error_99_tpusg_failure_signal_tpu_sketch_generator",
          "startTime": "2025-08-12T23:26:30.074000+00:00",
          "level": "ERROR",
          "statusMessage": "Failed. Last error: Traceback (most recent call last):\n  File \"script_f8d9fcaa_1755041185.py\", line 2, in <module>\n    with open(label_path, 'r') as f:\nNameError: name 'label_path' is not defined",
          "calculatedTotalCost": 0.0,
          "completionTokens": 0,
          "environment": "default",
          "totalTokens": 0,
          "promptTokens": 0,
          "costDetails": {},
          "endTime": null,
          "model": null,
          "modelParameters": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null,
          "latency": null
        }
      ],
      "createdAt": "2025-08-12T23:24:33.406Z",
      "updatedAt": "2025-08-12T23:26:35.654Z",
      "environment": "default"
    },
    {
      "id": "44cec04d",
      "timestamp": "2025-08-12T23:22:22.980000+00:00",
      "name": "44ce_tpu_sketch_generator",
      "input": null,
      "output": {
        "status": "failed",
        "last_code": "import cv2\nimport numpy as np\nfrom tflite_runtime.interpreter import Interpreter\nfrom tflite_runtime.interpreter import load_delegate\n\n# Define label path here\nlabel_path    = \"/home/mendel/tinyml_autopilot/models/labelmap.txt\"\n\n# Load labels\nwith open(label_path, 'r') as f:\n    labels = [line.strip() for line in f.readlines()]\n\n# Define model and input paths here\nmodel_path    = \"/home/mendel/tinyml_autopilot/models/edgetpu_detect.tflite\"\ninput_path    = \"/home/mendel/tinyml_autopilot/data//sheeps.mp4\"\n\n# Define confidence threshold here\nconfidence_threshold    = 0.5\n\n# Load interpreter with EdgeTPU\ninterpreter = Interpreter(model_path=model_path, experimental_delegates=[load_delegate('/usr/lib/aarch64-linux-gnu/libedgetpu.so.1.0')])\ninterpreter.allocate_tensors()\n\n# Get model details\ninput_details = interpreter.get_input_details()\noutput_details  = \"/home/mendel/tinyml_autopilot/results/sheeps_detections.mp4\"\nheight = input_details[0]['shape'][1]\nwidth = input_details[0]['shape'][2]\nfloating_model = (input_details[0]['dtype'] == np.float32)\n\n# Input acquisition and preprocessing loop\ncap = cv2.VideoCapture(input_path)\n\nwhile cap.isOpened():\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    # Preprocess data\n    resized_frame = cv2.resize(frame, (width, height))\n    input_data = np.expand_dims(resized_frame, axis=0)\n\n    # Quantization handling\n    if floating_model:\n        input_data = (np.float32(input_data) - 127.5) / 127.5\n\n    # Inference\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n    interpreter.invoke()\n\n    # Output interpretation and handling\n    boxes = interpreter.get_tensor(output_details[0]['index'])[0]\n    classes = interpreter.get_tensor(output_details[1]['index'])[0]\n    scores = interpreter.get_tensor(output_details[2]['index'])[0]\n\n    for i in range(len(scores)):\n        if ((scores[i] > confidence_threshold) and (scores[i] <= 1.0)):\n            object_name = labels[int(classes[i])]\n            print(f'Detected {object_name} with a score of {scores[i]}')\n\n# Cleanup\ncap.release()",
        "last_error": "Traceback (most recent call last):\n  File \"script_b46d84b0_1755041058.py\", line 52, in <module>\n    boxes = interpreter.get_tensor(output_details[0]['index'])[0]\nTypeError: string indices must be integers"
      },
      "session_id": "codestral_e6d3_tpusg_batch",
      "metadata": {
        "num_run": 6
      },
      "tags": [
        "benchmark",
        "codestral:latest",
        "tpu_sketch_generator"
      ],
      "latency": 123.942,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-02-22-22-981912_chatcmpl-32dc4507-e92d-497a-a39e-a32a7f737d67",
          "traceId": "44cec04d",
          "type": "GENERATION",
          "name": "44ce_tpusg_gen_attempt#1",
          "startTime": "2025-08-12T23:22:22.981000+00:00",
          "endTime": "2025-08-12T23:22:42.136000+00:00",
          "model": "codestral:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 19155.0,
          "completionTokens": 1001,
          "environment": "default",
          "totalTokens": 3049,
          "promptTokens": 2048,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-02-22-49-916834_chatcmpl-df174ccc-da24-4c1a-b7c5-02549ef40c40",
          "traceId": "44cec04d",
          "type": "GENERATION",
          "name": "44ce_tpusg_gen_attempt#2",
          "startTime": "2025-08-12T23:22:49.916000+00:00",
          "endTime": "2025-08-12T23:23:03.169000+00:00",
          "model": "codestral:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 13253.0,
          "completionTokens": 672,
          "environment": "default",
          "totalTokens": 2720,
          "promptTokens": 2048,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-02-23-11-069900_chatcmpl-350a4578-09a7-4cb9-8bae-7485651549b1",
          "traceId": "44cec04d",
          "type": "GENERATION",
          "name": "44ce_tpusg_gen_attempt#3",
          "startTime": "2025-08-12T23:23:11.069000+00:00",
          "endTime": "2025-08-12T23:23:28.493000+00:00",
          "model": "codestral:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 17424.0,
          "completionTokens": 907,
          "environment": "default",
          "totalTokens": 2955,
          "promptTokens": 2048,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-02-23-36-868040_chatcmpl-b5425004-8eeb-4a7c-8a87-fec3db1f14ef",
          "traceId": "44cec04d",
          "type": "GENERATION",
          "name": "44ce_tpusg_gen_attempt#4",
          "startTime": "2025-08-12T23:23:36.868000+00:00",
          "endTime": "2025-08-12T23:23:53.172000+00:00",
          "model": "codestral:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 16304.0,
          "completionTokens": 843,
          "environment": "default",
          "totalTokens": 2891,
          "promptTokens": 2048,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-02-24-01-807367_chatcmpl-648f1b46-48cb-4c6d-84ff-4ce5bd94c2c6",
          "traceId": "44cec04d",
          "type": "GENERATION",
          "name": "44ce_tpusg_gen_attempt#5",
          "startTime": "2025-08-12T23:24:01.807000+00:00",
          "endTime": "2025-08-12T23:24:18.101000+00:00",
          "model": "codestral:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 16294.0,
          "completionTokens": 843,
          "environment": "default",
          "totalTokens": 2891,
          "promptTokens": 2048,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "6272c95c-75e2-42ed-ae39-7410ae930c91",
          "traceId": "44cec04d",
          "type": "SPAN",
          "name": "error_44_tpusg_failure_signal_tpu_sketch_generator",
          "startTime": "2025-08-12T23:24:26.923000+00:00",
          "level": "ERROR",
          "statusMessage": "Failed. Last error: Traceback (most recent call last):\n  File \"script_b46d84b0_1755041058.py\", line 52, in <module>\n    boxes = interpreter.get_tensor(output_details[0]['index'])[0]\nTypeError: string indices must be integers",
          "calculatedTotalCost": 0.0,
          "completionTokens": 0,
          "environment": "default",
          "totalTokens": 0,
          "promptTokens": 0,
          "costDetails": {},
          "endTime": null,
          "model": null,
          "modelParameters": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null,
          "latency": null
        }
      ],
      "createdAt": "2025-08-12T23:22:23.497Z",
      "updatedAt": "2025-08-12T23:24:32.238Z",
      "environment": "default"
    },
    {
      "id": "2c16c0ce",
      "timestamp": "2025-08-12T23:20:32.980000+00:00",
      "name": "2c16_tpu_sketch_generator",
      "input": null,
      "output": {
        "status": "failed",
        "last_code": "# Define label path\nlabel_path = '/path/to/labels.txt'\n\n# Rest of the code...",
        "last_error": "Unexpected error during generation: Generated script is not complete. Please ensure to generate a complete Python script."
      },
      "session_id": "codestral_e6d3_tpusg_batch",
      "metadata": {
        "num_run": 5
      },
      "tags": [
        "benchmark",
        "codestral:latest",
        "tpu_sketch_generator"
      ],
      "latency": 103.303,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-02-20-32-981752_chatcmpl-3a53a6bb-c047-40d9-9e52-eb96c6288406",
          "traceId": "2c16c0ce",
          "type": "GENERATION",
          "name": "2c16_tpusg_gen_attempt#1",
          "startTime": "2025-08-12T23:20:32.981000+00:00",
          "endTime": "2025-08-12T23:20:52.143000+00:00",
          "model": "codestral:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 19162.0,
          "completionTokens": 1001,
          "environment": "default",
          "totalTokens": 3049,
          "promptTokens": 2048,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-02-21-00-021464_chatcmpl-97d79836-ee43-4b29-a6d2-9709296dac66",
          "traceId": "2c16c0ce",
          "type": "GENERATION",
          "name": "2c16_tpusg_gen_attempt#2",
          "startTime": "2025-08-12T23:21:00.021000+00:00",
          "endTime": "2025-08-12T23:21:17.251000+00:00",
          "model": "codestral:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 17230.0,
          "completionTokens": 896,
          "environment": "default",
          "totalTokens": 2944,
          "promptTokens": 2048,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-02-21-25-174628_chatcmpl-e77fea72-27a6-45a0-9ddb-c49d4b9601c5",
          "traceId": "2c16c0ce",
          "type": "GENERATION",
          "name": "2c16_tpusg_gen_attempt#3",
          "startTime": "2025-08-12T23:21:25.174000+00:00",
          "endTime": "2025-08-12T23:21:41.231000+00:00",
          "model": "codestral:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 16057.0,
          "completionTokens": 830,
          "environment": "default",
          "totalTokens": 2878,
          "promptTokens": 2048,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-02-21-49-084257_chatcmpl-6d823590-0d88-4626-bd5e-3fa28b823dc5",
          "traceId": "2c16c0ce",
          "type": "GENERATION",
          "name": "2c16_tpusg_gen_attempt#4",
          "startTime": "2025-08-12T23:21:49.084000+00:00",
          "endTime": "2025-08-12T23:22:03.960000+00:00",
          "model": "codestral:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 14876.0,
          "completionTokens": 763,
          "environment": "default",
          "totalTokens": 2811,
          "promptTokens": 2048,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-02-22-12-121976_chatcmpl-e883ca6f-e73b-4060-87e9-b76190351b13",
          "traceId": "2c16c0ce",
          "type": "GENERATION",
          "name": "2c16_tpusg_gen_attempt#5",
          "startTime": "2025-08-12T23:22:12.121000+00:00",
          "endTime": "2025-08-12T23:22:16.267000+00:00",
          "model": "codestral:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 4146.0,
          "completionTokens": 158,
          "environment": "default",
          "totalTokens": 2206,
          "promptTokens": 2048,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "e5801c98-af82-4dc2-ac59-077665e4da96",
          "traceId": "2c16c0ce",
          "type": "SPAN",
          "name": "error_2c_tpusg_failure_signal_tpu_sketch_generator",
          "startTime": "2025-08-12T23:22:16.284000+00:00",
          "level": "ERROR",
          "statusMessage": "Failed. Last error: Unexpected error during generation: Generated script is not complete. Please ensure to generate a complete Python script.",
          "calculatedTotalCost": 0.0,
          "completionTokens": 0,
          "environment": "default",
          "totalTokens": 0,
          "promptTokens": 0,
          "costDetails": {},
          "endTime": null,
          "model": null,
          "modelParameters": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null,
          "latency": null
        }
      ],
      "createdAt": "2025-08-12T23:20:33.495Z",
      "updatedAt": "2025-08-12T23:22:21.687Z",
      "environment": "default"
    },
    {
      "id": "2fb220ad",
      "timestamp": "2025-08-12T23:19:32.435000+00:00",
      "name": "2fb2_tpu_sketch_generator",
      "input": null,
      "output": {
        "status": "failed",
        "last_code": "import cv2\nimport numpy as np\nfrom tensorflow.lite import Interpreter\nfrom tensorflow.lite.experimental import load_delegate\n\n# Define paths and parameters\nmodel_path  = \"/home/mendel/tinyml_autopilot/models/edgetpu_detect.tflite\"\ninput_path  = \"/home/mendel/tinyml_autopilot/data//sheeps.mp4\"\nlabel_path  = \"/home/mendel/tinyml_autopilot/models/labelmap.txt\"\noutput_path  = \"/home/mendel/tinyml_autopilot/results/sheeps_detections.mp4\"\nconfidence_threshold  = 0.5\n\n# Load labels\nwith open(label_path, 'r') as f:\n    labels = [line.strip() for line in f.readlines()]\n\n# Load interpreter with EdgeTPU\ninterpreter = Interpreter(model_path=model_path, experimental_delegates=[load_delegate('/usr/lib/aarch64-linux-gnu/libedgetpu.so.1.0')])\ninterpreter.allocate_tensors()\n\n# Get model details\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\nheight = input_details[0]['shape'][1]\nwidth = input_details[0]['shape'][2]\nfloating_model = (input_details[0]['dtype'] == np.float32)\n\n# Input acquisition and preprocessing loop\ncap = cv2.VideoCapture(input_path)\nout = cv2.VideoWriter(output_path, cv2.VideoWriter_fourcc(*'XVID'), 30.0, (width, height))\n\nwhile cap.isOpened():\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    # Preprocess data\n    resized_frame = cv2.resize(frame, (width, height))\n    input_data = np.expand_dims(resized_frame, axis=0)\n\n    # Quantization handling\n    if floating_model:\n        input_data = (np.float32(input_data) - 127.5) / 127.5\n\n    # Inference\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n    interpreter.invoke()\n\n    # Output interpretation and handling\n    boxes = interpreter.get_tensor(output_details[0]['index'])[0]\n    classes = interpreter.get_tensor(output_details[1]['index'])[0]\n    scores = interpreter.get_tensor(output_details[2]['index'])[0]\n\n    for i in range(len(scores)):\n        if ((scores[i] > confidence_threshold) and (scores[i] <= 1.0)):\n            ymin = int(max(1, (boxes[i][0] * height)))\n            xmin = int(max(1, (boxes[i][1] * width)))\n            ymax = int(min(height, (boxes[i][2] * height)))\n            xmax = int(min(width, (boxes[i][3] * width)))\n\n            cv2.rectangle(frame, (xmin, ymin), (xmax, ymax), (10, 255, 0), 4)\n            object_name = labels[int(classes[i])]\n            label = '%s: %d%%' % (object_name, int(scores[i]*100))\n            labelSize, baseLine = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.7, 2)\n            label_ymin = max(ymin, labelSize[1] + 10)\n            cv2.rectangle(frame, (xmin, label_ymin-labelSize[1]-10), (xmin+labelSize[0], label_ymin+baseLine-10), (255, 255, 255), cv2.FILLED)\n            cv2.putText(frame, label, (xmin, label_ymin-7), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 0), 2)\n\n    out.write(frame)\n\n# Cleanup\ncap.release()\nout.release()\ncv2.destroyAllWindows()",
        "last_error": "Unexpected error during generation: The output is not a valid code block. Follow the instructions in the prompt return a complete, correct Python script enclosed in a single ```python\n<generated_code>\n``` block."
      },
      "session_id": "codestral_e6d3_tpusg_batch",
      "metadata": {
        "num_run": 4
      },
      "tags": [
        "benchmark",
        "codestral:latest",
        "tpu_sketch_generator"
      ],
      "latency": 53.444,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-02-19-32-437557_chatcmpl-f120c539-d5a1-4d67-8cdc-8ea292111ef6",
          "traceId": "2fb220ad",
          "type": "GENERATION",
          "name": "2fb2_tpusg_gen_attempt#1",
          "startTime": "2025-08-12T23:19:32.437000+00:00",
          "endTime": "2025-08-12T23:19:51.592000+00:00",
          "model": "codestral:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 19155.0,
          "completionTokens": 1001,
          "environment": "default",
          "totalTokens": 3049,
          "promptTokens": 2048,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-02-19-59-851759_chatcmpl-6e805879-6030-48f7-bbe0-65d640821111",
          "traceId": "2fb220ad",
          "type": "GENERATION",
          "name": "2fb2_tpusg_gen_attempt#2",
          "startTime": "2025-08-12T23:19:59.851000+00:00",
          "endTime": "2025-08-12T23:20:04.270000+00:00",
          "model": "codestral:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 4419.0,
          "completionTokens": 173,
          "environment": "default",
          "totalTokens": 2221,
          "promptTokens": 2048,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-02-20-04-279486_chatcmpl-20735b26-266f-4749-bf78-1fdddf039e5f",
          "traceId": "2fb220ad",
          "type": "GENERATION",
          "name": "2fb2_tpusg_gen_attempt#3",
          "startTime": "2025-08-12T23:20:04.279000+00:00",
          "endTime": "2025-08-12T23:20:11.484000+00:00",
          "model": "codestral:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 7205.0,
          "completionTokens": 332,
          "environment": "default",
          "totalTokens": 2380,
          "promptTokens": 2048,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-02-20-11-491295_chatcmpl-607b262b-6981-4592-96be-73c6abe56767",
          "traceId": "2fb220ad",
          "type": "GENERATION",
          "name": "2fb2_tpusg_gen_attempt#4",
          "startTime": "2025-08-12T23:20:11.491000+00:00",
          "endTime": "2025-08-12T23:20:18.660000+00:00",
          "model": "codestral:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 7169.0,
          "completionTokens": 330,
          "environment": "default",
          "totalTokens": 2378,
          "promptTokens": 2048,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-02-20-18-664116_chatcmpl-47235510-dc1b-490f-897a-62927c09f5be",
          "traceId": "2fb220ad",
          "type": "GENERATION",
          "name": "2fb2_tpusg_gen_attempt#5",
          "startTime": "2025-08-12T23:20:18.664000+00:00",
          "endTime": "2025-08-12T23:20:25.875000+00:00",
          "model": "codestral:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 7211.0,
          "completionTokens": 332,
          "environment": "default",
          "totalTokens": 2380,
          "promptTokens": 2048,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "20709411-7153-4667-ab76-f70ab8fd136f",
          "traceId": "2fb220ad",
          "type": "SPAN",
          "name": "error_2f_tpusg_failure_signal_tpu_sketch_generator",
          "startTime": "2025-08-12T23:20:25.881000+00:00",
          "level": "ERROR",
          "statusMessage": "Failed. Last error: Unexpected error during generation: The output is not a valid code block. Follow the instructions in the prompt return a complete, correct Python script enclosed in a single ```python\n<generated_code>\n``` block.",
          "calculatedTotalCost": 0.0,
          "completionTokens": 0,
          "environment": "default",
          "totalTokens": 0,
          "promptTokens": 0,
          "costDetails": {},
          "endTime": null,
          "model": null,
          "modelParameters": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null,
          "latency": null
        }
      ],
      "createdAt": "2025-08-12T23:19:32.952Z",
      "updatedAt": "2025-08-12T23:20:31.908Z",
      "environment": "default"
    },
    {
      "id": "f0d2e6e2",
      "timestamp": "2025-08-12T23:17:37.848000+00:00",
      "name": "f0d2_tpu_sketch_generator",
      "input": null,
      "output": {
        "status": "failed",
        "last_code": "import cv2\nimport numpy as np\nfrom tflite_runtime.interpreter import Interpreter\nfrom tflite_runtime.interpreter import load_delegate\n\n# Define paths and parameters\nmodel_path   = \"/home/mendel/tinyml_autopilot/models/edgetpu_detect.tflite\"\ninput_path   = \"/home/mendel/tinyml_autopilot/data//sheeps.mp4\"\noutput_path   = \"/home/mendel/tinyml_autopilot/results/sheeps_detections.mp4\"\nconfidence_threshold   = 0.5\n\n# Load interpreter with EdgeTPU acceleration\ntry:\n    interpreter = Interpreter(model_path=model_path, experimental_delegates=[load_delegate('libedgetpu.so.1.0')])\nexcept:\n    interpreter = Interpreter(model_path=model_path, experimental_delegates=[load_delegate('/usr/lib/aarch64-linux-gnu/libedgetpu.so.1.0')])\ninterpreter.allocate_tensors()\n\n# Get model details\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\nheight = input_details[0]['shape'][1]\nwidth = input_details[0]['shape'][2]\nfloating_model = (input_details[0]['dtype'] == np.float32)\n\n# Input acquisition and preprocessing loop\nimage = cv2.imread(input_path)\nresized_image = cv2.resize(image, (width, height))\ninput_data = np.expand_dims(resized_image, axis=0)\nif floating_model:\n    input_data = (np.float32(input_data) - 127.5) / 127.5\n\n# Inference\ninterpreter.set_tensor(input_details[0]['index'], input_data)\ninterpreter.invoke()\n\n# Output interpretation and handling loop\nboxes = interpreter.get_tensor(output_details[0]['index'])[0]\nclasses = interpreter.get_tensor(output_details[1]['index'])[0]\nscores = interpreter.get_tensor(output_details[2]['index'])[0]\nnum = interpreter.get_tensor(output_details[3]['index'])[0]\n\n# Post-processing (for detection models)\nfor i in range(int(num)):\n    if scores[i] > confidence_threshold:\n        ymin, xmin, ymax, xmax = boxes[i]\n        xmin = int(xmin * image.shape[1])\n        xmax = int(xmax * image.shape[1])\n        ymin = int(ymin * image.shape[0])\n        ymax = int(ymax * image.shape[0])\n        label = int(classes[i])  # Since labels are not provided, we will use the class index as the label\n        cv2.rectangle(image, (xmin, ymin), (xmax, ymax), (10, 255, 0), 2)\n        cv2.putText(image, f'{label}: {scores[i]:.2f}', (xmin, ymin - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (36, 255, 12), 2)\n\n# Handle output\ncv2.imwrite(output_path, image)",
        "last_error": "OpenCV Error: Assertion failed (ssize.width > 0 && ssize.height > 0) in resize, file /build/opencv-tragD2/opencv-3.2.0+dfsg/modules/imgproc/src/imgwarp.cpp, line 3492\nTraceback (most recent call last):\n  File \"script_cf5a9ea3_1755040758.py\", line 28, in <module>\n    resized_image = cv2.resize(image, (width, height))\ncv2.error: /build/opencv-tragD2/opencv-3.2.0+dfsg/modules/imgproc/src/imgwarp.cpp:3492: error: (-215) ssize.width > 0 && ssize.height > 0 in function resize\n"
      },
      "session_id": "codestral_e6d3_tpusg_batch",
      "metadata": {
        "num_run": 3
      },
      "tags": [
        "benchmark",
        "codestral:latest",
        "tpu_sketch_generator"
      ],
      "latency": 108.419,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-02-17-37-850164_chatcmpl-5f3d6ee5-9b38-4c70-b120-9e96cc703dfb",
          "traceId": "f0d2e6e2",
          "type": "GENERATION",
          "name": "f0d2_tpusg_gen_attempt#1",
          "startTime": "2025-08-12T23:17:37.850000+00:00",
          "endTime": "2025-08-12T23:17:56.765000+00:00",
          "model": "codestral:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 18915.0,
          "completionTokens": 987,
          "environment": "default",
          "totalTokens": 3035,
          "promptTokens": 2048,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-02-18-05-042611_chatcmpl-8f3af995-3cb9-431a-87b9-c2b8d11fbe95",
          "traceId": "f0d2e6e2",
          "type": "GENERATION",
          "name": "f0d2_tpusg_gen_attempt#2",
          "startTime": "2025-08-12T23:18:05.042000+00:00",
          "endTime": "2025-08-12T23:18:21.063000+00:00",
          "model": "codestral:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 16021.0,
          "completionTokens": 828,
          "environment": "default",
          "totalTokens": 2876,
          "promptTokens": 2048,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-02-18-25-985478_chatcmpl-159fa412-5fd4-4839-a818-19697bb66cfa",
          "traceId": "f0d2e6e2",
          "type": "GENERATION",
          "name": "f0d2_tpusg_gen_attempt#3",
          "startTime": "2025-08-12T23:18:25.985000+00:00",
          "endTime": "2025-08-12T23:18:31.646000+00:00",
          "model": "codestral:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 5661.0,
          "completionTokens": 244,
          "environment": "default",
          "totalTokens": 2292,
          "promptTokens": 2048,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-02-18-31-653600_chatcmpl-439f5830-93eb-4ee2-a4ce-70ecf42093ac",
          "traceId": "f0d2e6e2",
          "type": "GENERATION",
          "name": "f0d2_tpusg_gen_attempt#4",
          "startTime": "2025-08-12T23:18:31.653000+00:00",
          "endTime": "2025-08-12T23:18:50.940000+00:00",
          "model": "codestral:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 19287.0,
          "completionTokens": 1013,
          "environment": "default",
          "totalTokens": 3061,
          "promptTokens": 2048,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-02-18-59-410166_chatcmpl-c45b7b9e-afbe-4157-87be-2bff39d0b3d5",
          "traceId": "f0d2e6e2",
          "type": "GENERATION",
          "name": "f0d2_tpusg_gen_attempt#5",
          "startTime": "2025-08-12T23:18:59.410000+00:00",
          "endTime": "2025-08-12T23:19:18.031000+00:00",
          "model": "codestral:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 18621.0,
          "completionTokens": 974,
          "environment": "default",
          "totalTokens": 3022,
          "promptTokens": 2048,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "71cffba1-bb6d-42c6-b1a6-725aaf1ad689",
          "traceId": "f0d2e6e2",
          "type": "SPAN",
          "name": "error_f0_tpusg_failure_signal_tpu_sketch_generator",
          "startTime": "2025-08-12T23:19:26.269000+00:00",
          "level": "ERROR",
          "statusMessage": "Failed. Last error: OpenCV Error: Assertion failed (ssize.width > 0 && ssize.height > 0) in resize, file /build/opencv-tragD2/opencv-3.2.0+dfsg/modules/imgproc/src/imgwarp.cpp, line 3492\nTraceback (most recent call last):\n  File \"script_cf5a9ea3_1755040758.py\", line 28, in <module>\n    resized_image = cv2.resize(image, (width, height))\ncv2.error: /build/opencv-tragD2/opencv-3.2.0+dfsg/modules/imgproc/src/imgwarp.cpp:3492: error: (-215) ssize.width > 0 && ssize.height > 0 in function resize\n",
          "calculatedTotalCost": 0.0,
          "completionTokens": 0,
          "environment": "default",
          "totalTokens": 0,
          "promptTokens": 0,
          "costDetails": {},
          "endTime": null,
          "model": null,
          "modelParameters": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null,
          "latency": null
        }
      ],
      "createdAt": "2025-08-12T23:17:38.366Z",
      "updatedAt": "2025-08-12T23:19:31.599Z",
      "environment": "default"
    },
    {
      "id": "eaa9e0cf",
      "timestamp": "2025-08-12T23:16:38.324000+00:00",
      "name": "eaa9_tpu_sketch_generator",
      "input": null,
      "output": {
        "status": "failed",
        "last_code": "import cv2\nimport numpy as np\nfrom tensorflow.lite import Interpreter\nfrom tensorflow.lite.experimental import load_delegate\n\n# Define paths and parameters\nmodel_path  = \"/home/mendel/tinyml_autopilot/models/edgetpu_detect.tflite\"\ninput_path  = \"/home/mendel/tinyml_autopilot/data//sheeps.mp4\"\nlabel_path  = \"/home/mendel/tinyml_autopilot/models/labelmap.txt\"\noutput_path  = \"/home/mendel/tinyml_autopilot/results/sheeps_detections.mp4\"\nconfidence_threshold  = 0.5\n\n# Load labels\nwith open(label_path, 'r') as f:\n    labels = [line.strip() for line in f.readlines()]\n\n# Load interpreter with EdgeTPU\ninterpreter = Interpreter(model_path=model_path, experimental_delegates=[load_delegate('/usr/lib/aarch64-linux-gnu/libedgetpu.so.1.0')])\ninterpreter.allocate_tensors()\n\n# Get model details\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\nheight = input_details[0]['shape'][1]\nwidth = input_details[0]['shape'][2]\nfloating_model = (input_details[0]['dtype'] == np.float32)\n\n# Input acquisition and preprocessing loop\ncap = cv2.VideoCapture(input_path)\nout = cv2.VideoWriter(output_path, cv2.VideoWriter_fourcc(*'XVID'), 30.0, (width, height))\n\nwhile cap.isOpened():\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    # Preprocess data\n    resized_frame = cv2.resize(frame, (width, height))\n    input_data = np.expand_dims(resized_frame, axis=0)\n\n    # Quantization handling\n    if floating_model:\n        input_data = (np.float32(input_data) - 127.5) / 127.5\n\n    # Inference\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n    interpreter.invoke()\n\n    # Output interpretation and handling\n    boxes = interpreter.get_tensor(output_details[0]['index'])[0]\n    classes = interpreter.get_tensor(output_details[1]['index'])[0]\n    scores = interpreter.get_tensor(output_details[2]['index'])[0]\n\n    for i in range(len(scores)):\n        if ((scores[i] > confidence_threshold) and (scores[i] <= 1.0)):\n            ymin = int(max(1, (boxes[i][0] * height)))\n            xmin = int(max(1, (boxes[i][1] * width)))\n            ymax = int(min(height, (boxes[i][2] * height)))\n            xmax = int(min(width, (boxes[i][3] * width)))\n\n            cv2.rectangle(frame, (xmin, ymin), (xmax, ymax), (10, 255, 0), 4)\n            object_name = labels[int(classes[i])]\n            label = '%s: %d%%' % (object_name, int(scores[i]*100))\n            labelSize, baseLine = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.7, 2)\n            label_ymin = max(ymin, labelSize[1] + 10)\n            cv2.rectangle(frame, (xmin, label_ymin-labelSize[1]-10), (xmin+labelSize[0], label_ymin+baseLine-10), (255, 255, 255), cv2.FILLED)\n            cv2.putText(frame, label, (xmin, label_ymin-7), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 0), 2)\n\n    out.write(frame)\n\n# Cleanup\ncap.release()\nout.release()\ncv2.destroyAllWindows()",
        "last_error": "Unexpected error during generation: The output is not a valid code block. Follow the instructions in the prompt return a complete, correct Python script enclosed in a single ```python\n<generated_code>\n``` block."
      },
      "session_id": "codestral_e6d3_tpusg_batch",
      "metadata": {
        "num_run": 2
      },
      "tags": [
        "benchmark",
        "codestral:latest",
        "tpu_sketch_generator"
      ],
      "latency": 53.14,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-02-16-38-326124_chatcmpl-b0cfe2fe-dfa3-4160-a02f-8e0c80fa6936",
          "traceId": "eaa9e0cf",
          "type": "GENERATION",
          "name": "eaa9_tpusg_gen_attempt#1",
          "startTime": "2025-08-12T23:16:38.326000+00:00",
          "endTime": "2025-08-12T23:16:57.526000+00:00",
          "model": "codestral:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 19200.0,
          "completionTokens": 1001,
          "environment": "default",
          "totalTokens": 3049,
          "promptTokens": 2048,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-02-17-05-442642_chatcmpl-56ce7796-c95b-4229-aaea-e34c17d6ce6f",
          "traceId": "eaa9e0cf",
          "type": "GENERATION",
          "name": "eaa9_tpusg_gen_attempt#2",
          "startTime": "2025-08-12T23:17:05.442000+00:00",
          "endTime": "2025-08-12T23:17:09.903000+00:00",
          "model": "codestral:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 4461.0,
          "completionTokens": 176,
          "environment": "default",
          "totalTokens": 2224,
          "promptTokens": 2048,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-02-17-09-911147_chatcmpl-cca24d75-9acb-4b04-86b3-b42d6554936b",
          "traceId": "eaa9e0cf",
          "type": "GENERATION",
          "name": "eaa9_tpusg_gen_attempt#3",
          "startTime": "2025-08-12T23:17:09.911000+00:00",
          "endTime": "2025-08-12T23:17:17.089000+00:00",
          "model": "codestral:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 7178.0,
          "completionTokens": 330,
          "environment": "default",
          "totalTokens": 2378,
          "promptTokens": 2048,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-02-17-17-094519_chatcmpl-f717eace-72c0-4724-85a3-032718bf8b54",
          "traceId": "eaa9e0cf",
          "type": "GENERATION",
          "name": "eaa9_tpusg_gen_attempt#4",
          "startTime": "2025-08-12T23:17:17.094000+00:00",
          "endTime": "2025-08-12T23:17:24.277000+00:00",
          "model": "codestral:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 7183.0,
          "completionTokens": 330,
          "environment": "default",
          "totalTokens": 2378,
          "promptTokens": 2048,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-02-17-24-283831_chatcmpl-54daa9f7-aa25-42aa-a0f7-57f8117f0f69",
          "traceId": "eaa9e0cf",
          "type": "GENERATION",
          "name": "eaa9_tpusg_gen_attempt#5",
          "startTime": "2025-08-12T23:17:24.283000+00:00",
          "endTime": "2025-08-12T23:17:31.460000+00:00",
          "model": "codestral:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 7177.0,
          "completionTokens": 330,
          "environment": "default",
          "totalTokens": 2378,
          "promptTokens": 2048,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "ba3c136b-f3d6-4794-a58a-0bed37c40987",
          "traceId": "eaa9e0cf",
          "type": "SPAN",
          "name": "error_ea_tpusg_failure_signal_tpu_sketch_generator",
          "startTime": "2025-08-12T23:17:31.466000+00:00",
          "level": "ERROR",
          "statusMessage": "Failed. Last error: Unexpected error during generation: The output is not a valid code block. Follow the instructions in the prompt return a complete, correct Python script enclosed in a single ```python\n<generated_code>\n``` block.",
          "calculatedTotalCost": 0.0,
          "completionTokens": 0,
          "environment": "default",
          "totalTokens": 0,
          "promptTokens": 0,
          "costDetails": {},
          "endTime": null,
          "model": null,
          "modelParameters": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null,
          "latency": null
        }
      ],
      "createdAt": "2025-08-12T23:16:38.841Z",
      "updatedAt": "2025-08-12T23:17:37.003Z",
      "environment": "default"
    },
    {
      "id": "f4700758",
      "timestamp": "2025-08-12T23:14:34.718000+00:00",
      "name": "f470_tpu_sketch_generator",
      "input": null,
      "output": {
        "status": "failed",
        "last_code": "import numpy as np\nimport cv2\nfrom pycoral.adapters import common\nfrom pycoral.adapters import detect\nfrom pycoral.utils.edgetpu import make_interpreter\n\n# Load labels\nwith open(label_path, 'r') as f:\n    labels = [line.strip() for line in f.readlines()]\n\n# Load interpreter with EdgeTPU\ninterpreter = make_interpreter(model_path)\ninterpreter.allocate_tensors()\n\n# Get model details\ninput_details    = \"/home/mendel/tinyml_autopilot/data//sheeps.mp4\"\noutput_details   = \"/home/mendel/tinyml_autopilot/results/sheeps_detections.mp4\"\nheight = input_details['shape'][1]\nwidth = input_details['shape'][2]\nfloating_model = (input_details['dtype'] == np.float32)\n\n# Input acquisition and preprocessing loop\ncap = cv2.VideoCapture(input_path)\nwhile cap.isOpened():\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    # Preprocess data\n    resized_frame = cv2.resize(frame, (width, height))\n    input_data = np.expand_dims(resized_frame, axis=0)\n    if floating_model:\n        input_data = (np.float32(input_data) - 127.5) / 127.5\n\n    # Inference\n    interpreter.set_tensor(input_details['index'], input_data)\n    interpreter.invoke()\n\n    # Output interpretation and handling loop\n    boxes = interpreter.get_tensor(output_details[0]['index'])[0]\n    classes = interpreter.get_tensor(output_details[1]['index'])[0]\n    scores = interpreter.get_tensor(output_details[2]['index'])[0]\n\n    for i in range(len(scores)):\n        if ((scores[i] > confidence_threshold) and (scores[i] <= 1.0)):\n            ymin = int((boxes[i][0] * frame.shape[0]))\n            xmin = int((boxes[i][1] * frame.shape[1]))\n            ymax = int((boxes[i][2] * frame.shape[0]))\n            xmax = int((boxes[i][3] * frame.shape[1]))\n\n            # Handle output (removed OpenCV code)",
        "last_error": "Unexpected error during generation: The output is not a valid code block. Follow the instructions in the prompt return a complete, correct Python script enclosed in a single ```python\n<generated_code>\n``` block."
      },
      "session_id": "codestral_e6d3_tpusg_batch",
      "metadata": {
        "num_run": 1
      },
      "tags": [
        "benchmark",
        "codestral:latest",
        "tpu_sketch_generator"
      ],
      "latency": 116.721,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-02-14-34-720361_chatcmpl-b92561eb-585b-46b2-bdd3-e946575fb3be",
          "traceId": "f4700758",
          "type": "GENERATION",
          "name": "f470_tpusg_gen_attempt#1",
          "startTime": "2025-08-12T23:14:34.720000+00:00",
          "endTime": "2025-08-12T23:15:13.299000+00:00",
          "model": "codestral:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 38579.0,
          "completionTokens": 987,
          "environment": "default",
          "totalTokens": 3035,
          "promptTokens": 2048,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-02-15-21-183621_chatcmpl-a57345cc-0984-423a-81e8-2864867624c1",
          "traceId": "f4700758",
          "type": "GENERATION",
          "name": "f470_tpusg_gen_attempt#2",
          "startTime": "2025-08-12T23:15:21.183000+00:00",
          "endTime": "2025-08-12T23:15:37.525000+00:00",
          "model": "codestral:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 16342.0,
          "completionTokens": 846,
          "environment": "default",
          "totalTokens": 2894,
          "promptTokens": 2048,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-02-15-42-234754_chatcmpl-7e23efd9-6014-492a-89fb-3f1a16233bde",
          "traceId": "f4700758",
          "type": "GENERATION",
          "name": "f470_tpusg_gen_attempt#3",
          "startTime": "2025-08-12T23:15:42.234000+00:00",
          "endTime": "2025-08-12T23:15:56.368000+00:00",
          "model": "codestral:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 14134.0,
          "completionTokens": 721,
          "environment": "default",
          "totalTokens": 2769,
          "promptTokens": 2048,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-02-16-03-981778_chatcmpl-8efa0a1c-ef86-40f4-a4e4-493dd903cc4f",
          "traceId": "f4700758",
          "type": "GENERATION",
          "name": "f470_tpusg_gen_attempt#4",
          "startTime": "2025-08-12T23:16:03.981000+00:00",
          "endTime": "2025-08-12T23:16:18.173000+00:00",
          "model": "codestral:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 14192.0,
          "completionTokens": 724,
          "environment": "default",
          "totalTokens": 2772,
          "promptTokens": 2048,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-02-16-26-410894_chatcmpl-0922c37c-e791-45d3-a368-6fcfe350cc3e",
          "traceId": "f4700758",
          "type": "GENERATION",
          "name": "f470_tpusg_gen_attempt#5",
          "startTime": "2025-08-12T23:16:26.410000+00:00",
          "endTime": "2025-08-12T23:16:31.434000+00:00",
          "model": "codestral:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 5024.0,
          "completionTokens": 208,
          "environment": "default",
          "totalTokens": 2256,
          "promptTokens": 2048,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "66a0ac8d-4ee1-4275-abed-417eac594e7c",
          "traceId": "f4700758",
          "type": "SPAN",
          "name": "error_f4_tpusg_failure_signal_tpu_sketch_generator",
          "startTime": "2025-08-12T23:16:31.441000+00:00",
          "level": "ERROR",
          "statusMessage": "Failed. Last error: Unexpected error during generation: The output is not a valid code block. Follow the instructions in the prompt return a complete, correct Python script enclosed in a single ```python\n<generated_code>\n``` block.",
          "calculatedTotalCost": 0.0,
          "completionTokens": 0,
          "environment": "default",
          "totalTokens": 0,
          "promptTokens": 0,
          "costDetails": {},
          "endTime": null,
          "model": null,
          "modelParameters": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null,
          "latency": null
        }
      ],
      "createdAt": "2025-08-12T23:14:35.233Z",
      "updatedAt": "2025-08-12T23:16:37.195Z",
      "environment": "default"
    }
  ],
  "meta": {
    "total_items": 30
  }
}
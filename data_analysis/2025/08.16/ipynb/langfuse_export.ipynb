{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setting up\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ref: https://langfuse.com/docs/query-traces\n",
    "import os\n",
    "import json\n",
    "from langfuse import Langfuse\n",
    "import json\n",
    "import os\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "LOCAL_HOST = True\n",
    "\n",
    "\"\"\"Define session_id\"\"\"\n",
    "# session_id=\"qwen2.5-coder_f4d4_dp_batch\"\n",
    "session_id_list = [\n",
    "    # \"qwen2.5-coder:32b_4e11_tpsg_batch\",\n",
    "    # \"qwen2.5-coder:32b_ae24_tpsg_batch\"\n",
    "    \"gemma3:27b_04fd_psg_batch\",\n",
    "    \"gemma3:27b_04fd_tpusg_batch\"\n",
    "]\n",
    "\n",
    "\n",
    "\"\"\"Define paths\"\"\"\n",
    " \n",
    "parent_dir = os.path.dirname(os.getcwd())\n",
    "\n",
    " \n",
    "# date = os.path.basename(parent_dir)\n",
    "tex_dir = os.path.join(parent_dir, \"tex\")\n",
    "processed_data_dir = os.path.join(parent_dir, \"processed_data\")\n",
    "raw_export_dir = os.path.join(parent_dir, \"raw_export\")\n",
    "ipynb_dir = os.path.join(parent_dir, \"ipynb\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Export raw data\n",
    "\n",
    "Langfuse added a limit of 20 API invocations per minute. https://langfuse.com/faq/all/api-limits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching traces for session gemma3:27b_04fd_psg_batch...\n",
      "Fetching observation data for time-08-09-26-619028_chatcmpl-96b3d163-69c2-4e63-8899-519562af34cd...\n",
      "Fetching observation data for time-08-09-48-189302_chatcmpl-eef6881f-98f9-498a-9bd3-575fab9cbe87...\n",
      "Fetching observation data for time-08-10-14-574114_chatcmpl-2d629868-78ab-4a2f-8294-b5f564eaaa2c...\n",
      "Fetching observation data for time-08-10-40-755118_chatcmpl-c2558df2-0421-4f89-8a2a-74158cc44530...\n",
      "Fetching observation data for time-08-11-06-181860_chatcmpl-188e458b-d883-4ffa-abf9-e0104b4f8ccf...\n",
      "Fetching observation data for c4b7f909-ecb4-4b1f-b7f3-c9280ba53d25...\n",
      "Fetching observation data for time-08-07-01-880995_chatcmpl-295df2e7-d6fe-4bbe-855e-6b527a08765a...\n",
      "Fetching observation data for time-08-07-24-850472_chatcmpl-5b310c63-edb2-4f7b-897e-e40f83d6c007...\n",
      "Fetching observation data for time-08-07-52-733997_chatcmpl-9a609b65-bf68-4e39-b390-5b701633950d...\n",
      "Fetching observation data for time-08-08-22-321418_chatcmpl-4597e672-d644-4439-858d-5ad5352c37f4...\n",
      "Fetching observation data for time-08-08-50-376412_chatcmpl-2e711363-faad-4b7d-99ba-9dd206cad81a...\n",
      "Fetching observation data for d73efe2d-adce-4dfe-917e-7a8c1b55aa4a...\n",
      "Fetching observation data for time-08-05-31-262359_chatcmpl-0232549d-1328-453f-87f5-282f1f728c20...\n",
      "Fetching observation data for time-08-05-54-813066_chatcmpl-4af81578-c73d-4926-89d8-6167251e2db3...\n",
      "Fetching observation data for time-08-06-24-656467_chatcmpl-83d7f907-a501-4574-9306-cf77e40e3761...\n",
      "Fetching observation data for time-08-02-51-632233_chatcmpl-88f19d93-6acc-4f5d-83bc-d3e9b6668ec3...\n",
      "Fetching observation data for time-08-03-19-581723_chatcmpl-d3a9bca1-fa6e-4bc2-9653-f11db74bda8d...\n",
      "Fetching observation data for time-08-03-52-190545_chatcmpl-7346a2b9-e08f-48f7-b9a6-4f7bfb6b31f7...\n",
      "Fetching observation data for time-08-04-23-208450_chatcmpl-e5b9ad40-0742-47ad-98fc-6ba5fca39bc6...\n",
      "Fetching observation data for time-08-04-51-800852_chatcmpl-849b68fd-44a4-4ef3-8133-8cf2e55b147a...\n",
      "Fetching observation data for e7fc1b14-0419-4160-b53d-72746fcfecde...\n",
      "Fetching observation data for time-08-00-17-779929_chatcmpl-d2a393a0-cd23-40ac-9ab4-499034b3c118...\n",
      "Fetching observation data for time-08-00-42-588896_chatcmpl-2c341612-b975-4d29-bdaa-36d445a773b8...\n",
      "Fetching observation data for time-08-01-13-922469_chatcmpl-09c05e43-03b5-466c-8bf1-8a7aadceee54...\n",
      "Fetching observation data for time-08-01-44-776625_chatcmpl-a206c99c-c0d4-4b96-902a-c8409d8d9f88...\n",
      "Fetching observation data for time-08-02-16-153485_chatcmpl-d6f816d1-e2fd-4a7b-ba05-f0eda65bfed4...\n",
      "Fetching observation data for f7f5e7b9-e936-4b4f-9722-ecd74ffa75ba...\n",
      "Fetching observation data for time-07-57-23-129507_chatcmpl-13779600-ba48-4287-922d-79ec4f5f4806...\n",
      "Fetching observation data for time-07-57-44-764913_chatcmpl-0ac85c7b-5b1c-4e18-8795-9c6ab3ba6939...\n",
      "Fetching observation data for time-07-58-25-438889_chatcmpl-87d2106b-96af-4a2a-bd5d-2bc5bd50de42...\n",
      "Fetching observation data for time-07-59-00-904631_chatcmpl-683a4c2f-53e1-4ec8-a7e4-c7418675631c...\n",
      "Fetching observation data for time-07-59-34-866869_chatcmpl-4eb2aca1-2a87-4f60-8640-71013f43bda9...\n",
      "Fetching observation data for 8ec2d491-dcc2-4ed9-b371-b184544947fe...\n",
      "Fetching observation data for time-07-55-08-365227_chatcmpl-8eb1fc7a-d917-48a4-b1da-ed7498b3adbf...\n",
      "Fetching observation data for time-07-55-29-735362_chatcmpl-231f43d4-993f-4853-a5bc-c8e9080d251f...\n",
      "Fetching observation data for time-07-55-57-910256_chatcmpl-da810580-2e59-40d2-839d-9ccd3ffd29bd...\n",
      "Fetching observation data for time-07-56-23-846923_chatcmpl-95464d13-fca9-4550-a9b8-3ba123835fc2...\n",
      "Fetching observation data for time-07-56-50-285319_chatcmpl-671b4772-037a-462c-a9a5-7856cb854032...\n",
      "Fetching observation data for bc24ccb2-53fc-418c-bd40-258d066b54a3...\n",
      "Fetching observation data for time-07-54-06-343998_chatcmpl-468e3c11-20c5-41f3-b89c-664773689073...\n",
      "Fetching observation data for time-07-54-28-834009_chatcmpl-fe074b07-fe33-48e5-97c2-127053189af3...\n",
      "Fetching observation data for time-07-51-29-576238_chatcmpl-b3efb670-dec4-48ad-82b1-727f7d64f4b9...\n",
      "Fetching observation data for time-07-51-55-707101_chatcmpl-3aec1567-7bf3-48c7-ae3e-215c0717a886...\n",
      "Fetching observation data for time-07-52-27-317008_chatcmpl-360b88a3-ca84-49d7-b330-27ce6b285a7a...\n",
      "Fetching observation data for time-07-52-57-805922_chatcmpl-4a4479a1-6532-41af-b803-ecb64ac7db9e...\n",
      "Fetching observation data for time-07-53-28-485336_chatcmpl-5de409fa-15dd-4209-9a74-3f20b1adfc5e...\n",
      "Fetching observation data for d781b918-924b-48bf-aa6a-77ebf8cfa319...\n",
      "Fetching observation data for time-07-48-50-898961_chatcmpl-ded9a201-765f-452a-aff6-46d47fe4b387...\n",
      "Fetching observation data for time-07-49-14-593168_chatcmpl-30ab7076-b572-470e-8bbb-566510e4bc3f...\n",
      "Fetching observation data for time-07-49-44-159462_chatcmpl-630d5e76-0e7a-415d-a218-aa1978fce3df...\n",
      "Fetching observation data for time-07-50-17-210777_chatcmpl-db439435-9934-4be9-a9a1-2967ce040c88...\n",
      "Fetching observation data for time-07-50-50-272821_chatcmpl-e9baf950-6bb3-478c-a060-040753903f60...\n",
      "Fetching observation data for b8228b99-4948-4547-84da-51f176f8abeb...\n",
      "Fetching observation data for time-07-48-22-008824_chatcmpl-341bf5a5-3c0a-4385-b588-8683856603a3...\n",
      "Fetching observation data for time-07-45-47-088230_chatcmpl-8e538351-472e-4c32-ba55-3b41566b1d15...\n",
      "Fetching observation data for time-07-46-12-952683_chatcmpl-9abb5c42-1edf-42e7-bbce-724c623dd07d...\n",
      "Fetching observation data for time-07-46-41-889520_chatcmpl-dfd8d04d-1b00-4d25-8a0e-db0ec6040e22...\n",
      "Fetching observation data for time-07-47-13-231198_chatcmpl-f0df8782-052b-4215-b943-a2aa281c36c1...\n",
      "Fetching observation data for time-07-47-45-050754_chatcmpl-0e1036bc-c93c-44e2-ab43-b9ec4762c59d...\n",
      "Fetching observation data for 55bdb395-271b-4a33-bc01-98a7d5132c27...\n",
      "Fetching observation data for time-07-43-26-214779_chatcmpl-013852e6-b422-46b0-9ac4-ee71210bd96e...\n",
      "Fetching observation data for time-07-43-47-815116_chatcmpl-426e6b7f-824b-4baf-a44a-3f29421f7a9e...\n",
      "Fetching observation data for time-07-44-16-578998_chatcmpl-96223f21-f494-4dd9-9aaf-57fd584a9e4f...\n",
      "Fetching observation data for time-07-44-44-211867_chatcmpl-b7f0ed83-bb02-4cd2-a4d4-066eb29fe5fa...\n",
      "Fetching observation data for time-07-45-13-535110_chatcmpl-7bfd28f6-52e0-4d5b-abe0-7a9a9196ee7e...\n",
      "Fetching observation data for 53ac88ed-032b-4308-80d8-da53d0652d6b...\n",
      "Fetching observation data for time-07-41-14-580248_chatcmpl-8cea5d99-98f6-4695-8115-c12f6e46c101...\n",
      "Fetching observation data for time-07-41-34-760458_chatcmpl-c9d4c362-8584-4376-adcc-1f66152b0fc2...\n",
      "Fetching observation data for time-07-41-57-308024_chatcmpl-51be62a9-42f3-471b-ba37-3ce217ded6fd...\n",
      "Fetching observation data for time-07-42-26-809558_chatcmpl-0b448ff6-9a1d-4ae0-a430-868d611aad73...\n",
      "Fetching observation data for time-07-42-53-603691_chatcmpl-91b6dba5-45a4-429a-ac15-5c3c459e9f49...\n",
      "Fetching observation data for ffdf86bf-e527-4545-b5df-974ec789bb52...\n",
      "Fetching observation data for time-07-38-59-015488_chatcmpl-98ab257c-61b7-45ed-ab4a-4e178d7be7cf...\n",
      "Fetching observation data for time-07-39-20-533806_chatcmpl-0cb7e596-3eab-4e6b-966c-9c31fa37a683...\n",
      "Fetching observation data for time-07-39-45-860001_chatcmpl-b0765bbd-ff78-424f-a8e8-6010a335baf9...\n",
      "Fetching observation data for time-07-40-13-954270_chatcmpl-b631a22d-e9c3-4724-ad12-513f8557db71...\n",
      "Fetching observation data for time-07-40-40-559468_chatcmpl-92cc9f39-f53f-4aff-b7a0-5576b53a92fa...\n",
      "Fetching observation data for efe5dbc3-0f09-40b4-bbb9-cd6c72c43920...\n",
      "Fetching observation data for time-07-36-37-378321_chatcmpl-724500c4-9116-46d6-8949-015150e8188c...\n",
      "Fetching observation data for time-07-36-59-428069_chatcmpl-01c74e94-5d13-4121-8dbc-102b0fe0e8e7...\n",
      "Fetching observation data for time-07-37-27-475167_chatcmpl-de4b373a-f6f0-441b-884e-17b57881c19b...\n",
      "Fetching observation data for time-07-37-56-594876_chatcmpl-ca1781c8-4c3b-4787-8835-d0975bb121e1...\n",
      "Fetching observation data for time-07-38-24-154305_chatcmpl-04de6bf2-bb50-4cd2-8449-4b6a5d9a9051...\n",
      "Fetching observation data for a3391fb7-6c9c-4925-975f-0868aaaedc4e...\n",
      "Fetching observation data for time-07-34-23-451083_chatcmpl-90576595-be78-479b-bb38-e0505a702405...\n",
      "Fetching observation data for time-07-34-44-760317_chatcmpl-e940298a-74ac-421e-acac-7cdb2192f8c6...\n",
      "Fetching observation data for time-07-35-12-260324_chatcmpl-64940ed1-bbeb-4c34-921c-bb99de6ff902...\n",
      "Fetching observation data for time-07-35-40-123666_chatcmpl-f3c4960f-9cc7-4020-bf09-4e2230e8812b...\n",
      "Fetching observation data for time-07-36-04-845375_chatcmpl-a58ccd40-f0bd-4987-8f85-9da39117b71e...\n",
      "Fetching observation data for fa6cd8d3-c3d8-4bc2-964b-520ab5ea8953...\n",
      "Fetching observation data for time-07-31-59-876918_chatcmpl-b6bd6b56-b362-4418-916a-643aa33cc8a8...\n",
      "Fetching observation data for time-07-32-19-823439_chatcmpl-b51d3901-daf6-44dd-ae79-454b75c8f488...\n",
      "Fetching observation data for time-07-32-46-061758_chatcmpl-ac7d4c6c-f7a3-4762-af27-ab907db08941...\n",
      "Fetching observation data for time-07-33-19-619537_chatcmpl-ef9b4864-c740-433a-80ce-3c76f6a865db...\n",
      "Fetching observation data for time-07-33-48-378311_chatcmpl-07003c63-a3c8-4d38-8e66-263674f48d50...\n",
      "Fetching observation data for 1f6248eb-67df-482e-9ee6-df1d20a9fbf4...\n",
      "Fetching observation data for time-07-31-27-128406_chatcmpl-3e178b7b-692d-4d29-b8a2-65efeabdd250...\n",
      "Fetching observation data for time-07-29-03-328114_chatcmpl-89c7d890-bab4-465f-87b7-4eb82492fffe...\n",
      "Fetching observation data for time-07-29-26-285336_chatcmpl-eaff7f33-4978-4b76-b416-e93ee926090a...\n",
      "Fetching observation data for time-07-29-53-869090_chatcmpl-155aee26-b8db-4bc9-a25a-50e189370b82...\n",
      "Fetching observation data for time-07-30-23-331687_chatcmpl-2220f465-3228-4b1a-9323-ddeea61a84bc...\n",
      "Fetching observation data for time-07-30-51-612521_chatcmpl-762e666b-c0ec-40a6-a628-4a466a698c4c...\n",
      "Fetching observation data for aa59b1b3-c488-4aee-b9b8-eddf3046effe...\n",
      "Fetching observation data for time-07-26-59-374926_chatcmpl-4421906c-3981-42fe-ad9e-9947d5b0f3b4...\n",
      "Fetching observation data for time-07-27-23-184222_chatcmpl-0fb96927-61ae-439d-862d-4bd4d2a1f085...\n",
      "Fetching observation data for time-07-27-53-015537_chatcmpl-bfeae5ca-68ec-49d8-9d48-d3f1d248a009...\n",
      "Fetching observation data for time-07-28-24-483757_chatcmpl-ecbcdb9f-9797-4380-8bb2-cf425064ecbb...\n",
      "Fetching observation data for time-07-24-44-387208_chatcmpl-23aa1136-b57d-4d7e-9748-1524d6f2222d...\n",
      "Fetching observation data for time-07-25-05-711785_chatcmpl-f3a33792-d381-488e-a98d-188c9379c3ad...\n",
      "Fetching observation data for time-07-25-35-197852_chatcmpl-cc2fc44a-fdf9-4bef-9117-76ec419c8e83...\n",
      "Fetching observation data for time-07-26-02-763503_chatcmpl-3dc6dfc0-db41-413e-af91-ea6d0ad6b9cb...\n",
      "Fetching observation data for time-07-26-28-708615_chatcmpl-46a5fe2f-4f9f-4df5-b434-86934d40e3db...\n",
      "Fetching observation data for 59e3ae13-de3b-439a-8e8e-4c7907c2265d...\n",
      "Fetching observation data for time-07-22-27-637769_chatcmpl-88a400db-2a51-46bd-8a7d-74b4e63d9654...\n",
      "Fetching observation data for time-07-22-49-108691_chatcmpl-56ee5b1a-68c1-4469-a015-a2248762de9e...\n",
      "Fetching observation data for time-07-23-15-158064_chatcmpl-633e0d22-5df0-411e-93b7-5e03ffffb3f7...\n",
      "Fetching observation data for time-07-23-45-473587_chatcmpl-8dba6d0b-6518-424b-874b-062e159db3c8...\n",
      "Fetching observation data for time-07-24-12-860426_chatcmpl-e2888199-7e39-4ed5-b7d1-8986f784e41d...\n",
      "Fetching observation data for 21b28181-39d5-49dc-ad97-a3f710d58ce1...\n",
      "Fetching observation data for time-07-19-35-812725_chatcmpl-68f7413f-30fd-4015-bc0f-17db299c5fc6...\n",
      "Fetching observation data for time-07-19-58-350784_chatcmpl-78626cca-e3a3-404d-b186-ecf26e86df9b...\n",
      "Fetching observation data for time-07-20-24-421989_chatcmpl-8d6c73bf-446d-4145-9a20-1dfb2370ae43...\n",
      "Fetching observation data for time-07-21-20-367059_chatcmpl-a89bbae0-5246-4b57-a81c-fde63c8f3086...\n",
      "Fetching observation data for 467e3f82-ec47-4152-8e8e-f8aba69d1588...\n",
      "Fetching observation data for time-07-19-06-131571_chatcmpl-ac29bc82-29fc-45e1-af5c-1896332f6a99...\n",
      "Fetching observation data for time-07-16-54-352397_chatcmpl-e2790bf0-a2e2-46c1-8d43-16560dc42a22...\n",
      "Fetching observation data for time-07-17-15-875926_chatcmpl-4ed416d9-be54-43d8-80ae-92837dc54207...\n",
      "Fetching observation data for time-07-17-40-930304_chatcmpl-2afa3528-9406-4cc1-a535-ef7cbdcef104...\n",
      "Fetching observation data for time-07-18-07-722451_chatcmpl-54755969-f04a-4bdb-93cd-0c369493fcae...\n",
      "Fetching observation data for time-07-18-34-836132_chatcmpl-b4933542-c9c6-42a7-a7d3-1f935f1f2712...\n",
      "Fetching observation data for 25fdf3de-f00a-4d76-9b15-ed1a638d8a2a...\n",
      "Fetching observation data for time-07-16-27-715539_chatcmpl-ae2e7734-d287-43d9-95c4-3eebb575b47c...\n",
      "Fetching observation data for time-07-14-10-053033_chatcmpl-2bbaacdd-bd35-4083-acdd-c31705b8fbec...\n",
      "Fetching observation data for time-07-14-31-757099_chatcmpl-1e212e14-b27a-4da1-8746-4f32c0f15cc6...\n",
      "Fetching observation data for time-07-14-59-141610_chatcmpl-321ae121-f676-4b1d-942b-f5d8da302de3...\n",
      "Fetching observation data for time-07-15-24-393095_chatcmpl-38a92933-1148-41aa-a03b-b17c6f695a3f...\n",
      "Fetching observation data for time-07-15-51-396834_chatcmpl-e6ca2c9b-1dc6-4177-b310-5de44f0f1552...\n",
      "Fetching observation data for 8f4371f9-bb03-4738-a3bd-c0e59faf6a07...\n",
      "Fetching observation data for time-07-11-40-154927_chatcmpl-f7edd4df-12f6-4737-a1e2-49f6f5d96309...\n",
      "Fetching observation data for time-07-12-03-149626_chatcmpl-c68ba84d-b3f7-4319-9221-68d6456167db...\n",
      "Fetching observation data for time-07-12-34-226138_chatcmpl-b9778a17-d8ed-49e3-9bec-f77d30910e63...\n",
      "Fetching observation data for time-07-13-03-664283_chatcmpl-765d8870-86cf-498d-84a0-1f6f5d5354f4...\n",
      "Fetching observation data for time-07-13-33-267137_chatcmpl-66114f37-1bf7-4d5a-ae63-dbf0079552d3...\n",
      "Fetching observation data for cf418475-52cf-4f4b-aed8-bae7cad61ec5...\n",
      "Fetching observation data for time-07-10-23-540825_chatcmpl-8869222d-1654-45cb-8f75-28846dc29f3b...\n",
      "Fetching observation data for time-07-10-44-305651_chatcmpl-7bac45bb-66ec-4b30-be03-aef50b4104d4...\n",
      "Fetching observation data for time-07-11-08-604446_chatcmpl-aa163a22-f67f-4351-b86c-0b702ec2e6cf...\n",
      "Raw JSON saved to: /Users/hann/Projects/reference-benchmark-tinyml_llm/data_analysis/2025/08.16/raw_export/raw_gemma3:27b_04fd_psg_batch.json\n",
      "Fetching traces for session gemma3:27b_04fd_tpusg_batch...\n",
      "Fetching observation data for time-07-07-21-835882_chatcmpl-c372ad06-958a-4d4b-90e4-2902fcac22ce...\n",
      "Fetching observation data for time-07-07-53-834846_chatcmpl-1fc83033-3460-4b13-88b8-87c74278507a...\n",
      "Fetching observation data for time-07-08-28-735724_chatcmpl-fb5ee4d4-964b-4e0a-913e-a02b5d51cb59...\n",
      "Fetching observation data for time-07-09-06-174301_chatcmpl-86d47b5f-5c57-4ac8-ad6b-4f9ec83f722f...\n",
      "Fetching observation data for time-07-09-40-923566_chatcmpl-48c21568-c2b6-456d-94ee-134eb859086c...\n",
      "Fetching observation data for 38106f96-8cd9-4722-a398-f5793015b71e...\n",
      "Fetching observation data for time-07-03-58-932165_chatcmpl-c5c35141-2151-46f1-93b5-2513145796a7...\n",
      "Fetching observation data for time-07-04-33-663056_chatcmpl-cbcc44b9-9caa-4c4c-af8f-b020cf107284...\n",
      "Fetching observation data for time-07-05-14-184290_chatcmpl-9a3e5336-f192-4284-a398-6a9291657ee3...\n",
      "Fetching observation data for time-07-05-53-130200_chatcmpl-89ac585d-cad1-4159-a5a3-d082eeb3ab2e...\n",
      "Fetching observation data for time-07-06-32-449083_chatcmpl-4929ef98-6242-41f4-af7d-29ba7f248c7b...\n",
      "Fetching observation data for a8ee5da3-6c44-4b91-929f-cdacb24e7b1c...\n",
      "Fetching observation data for time-07-00-40-983568_chatcmpl-3882ec16-75a2-42cf-9709-a2340f58bf63...\n",
      "Fetching observation data for time-07-01-12-540431_chatcmpl-eece820d-6b7a-44c1-a983-6883a8b54121...\n",
      "Fetching observation data for time-07-01-51-520932_chatcmpl-97e32bb0-7a4d-4733-9dda-1ed77cf096e7...\n",
      "Fetching observation data for time-07-02-32-215192_chatcmpl-9d06c42b-b0bf-4a8d-9d8b-831046fb91fe...\n",
      "Fetching observation data for time-07-03-12-698949_chatcmpl-f74655d1-b11d-4a4b-9aeb-02c473fca414...\n",
      "Fetching observation data for 36e47fea-c692-490e-9cab-f6dbd94c8158...\n",
      "Fetching observation data for time-06-57-22-170911_chatcmpl-ad97d30a-9a64-4f80-bd90-22ec1a7f9e46...\n",
      "Fetching observation data for time-06-57-56-651441_chatcmpl-47324445-5a8f-41c5-85aa-03fd83e2f994...\n",
      "Fetching observation data for time-06-58-35-672549_chatcmpl-18f69648-799c-4dbc-98d0-1cd969363239...\n",
      "Fetching observation data for time-06-59-16-020700_chatcmpl-a45742c4-1bf8-46ff-9d74-713bd6af76d4...\n",
      "Fetching observation data for time-06-59-54-657643_chatcmpl-ad13af99-ce52-4da7-bc84-3ce68e91fc99...\n",
      "Fetching observation data for 7e43a77c-38ad-43ca-b7ac-f0980ac158ce...\n",
      "Fetching observation data for time-06-54-20-350753_chatcmpl-6e100d10-c108-419c-8c8f-01de1065bccb...\n",
      "Fetching observation data for time-06-54-56-780506_chatcmpl-d8d0560f-8852-4290-b4f9-6c6ced966edb...\n",
      "Fetching observation data for time-06-55-36-725564_chatcmpl-98bf7f66-f946-4e98-a7a8-9eb00afcbb97...\n",
      "Fetching observation data for time-06-56-13-141629_chatcmpl-83577de3-49bf-4838-b80f-45f0236d6068...\n",
      "Fetching observation data for time-06-56-44-493125_chatcmpl-48fa874d-7e95-44cf-9b9e-3a3bd0dd242d...\n",
      "Fetching observation data for cb20bc8d-2b73-4d1b-93ac-85fe84137a05...\n",
      "Fetching observation data for time-06-50-52-769950_chatcmpl-41e36e7b-0e25-4a80-bc98-afc72bc441f3...\n",
      "Fetching observation data for time-06-51-30-641736_chatcmpl-c3c96433-8694-449a-a658-099f8e6f379e...\n",
      "Fetching observation data for time-06-52-04-555500_chatcmpl-b8a2e938-c4f3-4fda-bcc4-224029852d07...\n",
      "Fetching observation data for time-06-52-47-647794_chatcmpl-417579e7-5050-44d4-b6e9-24eb013f935d...\n",
      "Fetching observation data for time-06-53-33-638285_chatcmpl-dc840b0f-aecf-4d51-8b43-0daf3875554e...\n",
      "Fetching observation data for e05ba226-4009-4f2d-a3f7-0492145b78c6...\n",
      "Fetching observation data for time-06-47-26-112347_chatcmpl-a52f5c6e-10de-4fc1-a733-57ca00cadf3f...\n",
      "Fetching observation data for time-06-48-01-073065_chatcmpl-fd5f70f2-2380-49ad-b82c-9003cc4a9c9a...\n",
      "Fetching observation data for time-06-48-41-969364_chatcmpl-b7c1e8a1-7971-4d5c-bfbe-78f3dff16aba...\n",
      "Fetching observation data for time-06-49-21-953680_chatcmpl-dc268b83-3cb8-46dc-97ba-54a8ce0f118f...\n",
      "Fetching observation data for time-06-50-04-741015_chatcmpl-bb387915-4faa-49a5-a557-608b74d754e3...\n",
      "Fetching observation data for b54397af-2c8f-4cf1-b07e-3d753e72f860...\n",
      "Fetching observation data for time-06-44-19-529765_chatcmpl-07d1b236-8cb9-409c-8a73-41785316ddba...\n",
      "Fetching observation data for time-06-44-52-597811_chatcmpl-4eff9e63-79d0-40de-81dc-c4d2d0775f82...\n",
      "Fetching observation data for time-06-45-29-585218_chatcmpl-c7e32277-f1a1-4a3a-bf92-f83600039749...\n",
      "Fetching observation data for time-06-46-05-779614_chatcmpl-cfc3f01c-2776-4c57-a75c-9924c451bec4...\n",
      "Fetching observation data for time-06-46-44-041311_chatcmpl-c6a680a7-95c2-4b13-b7a7-778bddf5bbf3...\n",
      "Fetching observation data for 389670bb-4625-4338-8a87-707990ae64c7...\n",
      "Fetching observation data for time-06-40-55-681077_chatcmpl-ca57e2a1-3aef-4657-8972-0ff766b53681...\n",
      "Fetching observation data for time-06-41-30-183554_chatcmpl-71e2d82b-75a9-4f46-91f0-230c8eafe41e...\n",
      "Fetching observation data for time-06-42-12-613941_chatcmpl-ca3c5832-e0b2-42c9-830d-29943592266a...\n",
      "Fetching observation data for time-06-42-52-430342_chatcmpl-fab0c5a3-58ea-4f33-9af3-38c8afd08318...\n",
      "Fetching observation data for time-06-43-31-006582_chatcmpl-d14ac450-b472-4662-aeb5-16d07cf57220...\n",
      "Fetching observation data for bea1e062-28b1-4cdf-8041-6b42ca3671ec...\n",
      "Fetching observation data for time-06-37-26-071534_chatcmpl-c7f49af0-f0c1-444b-b98f-d6deb7ac7120...\n",
      "Fetching observation data for time-06-38-00-307850_chatcmpl-875a97ba-26e0-4eef-a35e-48a55060e6f0...\n",
      "Fetching observation data for time-06-38-41-360128_chatcmpl-bb76f2d0-f856-419a-8f76-0a8f1289db4a...\n",
      "Fetching observation data for time-06-39-28-887432_chatcmpl-b9c1343c-4f1d-4f62-8b79-533e8d79a0d8...\n",
      "Fetching observation data for time-06-40-06-593943_chatcmpl-8d799d9e-5732-4e53-b777-ddae8ae2ce76...\n",
      "Fetching observation data for c0d48d8d-34cb-473a-a58a-b01c9a35c031...\n",
      "Fetching observation data for time-06-34-22-407485_chatcmpl-6156452a-a72c-4d5f-b3d0-feacffb9feb4...\n",
      "Fetching observation data for time-06-34-57-328218_chatcmpl-9701f069-10b0-42e9-83fe-bb75773b9ce5...\n",
      "Fetching observation data for time-06-35-36-838708_chatcmpl-ddf0c6ac-49c9-45b4-9c62-968409128278...\n",
      "Fetching observation data for time-06-36-12-914508_chatcmpl-af05f1f9-1623-4153-a49e-29825a4c2714...\n",
      "Fetching observation data for time-06-36-46-730401_chatcmpl-ee198a77-2e95-489b-8b78-055bb3682e74...\n",
      "Fetching observation data for 42834b15-d5c4-40ac-b30d-6407e506f2ba...\n",
      "Fetching observation data for time-06-31-00-157013_chatcmpl-cbe92318-ee44-4c98-ae35-19f89c2187a5...\n",
      "Fetching observation data for time-06-31-35-173495_chatcmpl-c864ecc5-8768-47c9-923e-2110ba4f5989...\n",
      "Fetching observation data for time-06-32-14-881136_chatcmpl-fde261fb-1ee9-4c1a-8ada-896bf6e737e7...\n",
      "Fetching observation data for time-06-32-55-034016_chatcmpl-e6217e4f-44c6-4364-8573-e47ba0110e26...\n",
      "Fetching observation data for time-06-33-35-389054_chatcmpl-274dbdd6-25d2-400f-a1dc-6bb02d4867af...\n",
      "Fetching observation data for 4df7d56d-6fde-4240-9d02-bc1eeaa23ccc...\n",
      "Fetching observation data for time-06-27-52-024632_chatcmpl-4a30ce68-a7b7-4103-8a51-7295e0261b05...\n",
      "Fetching observation data for time-06-28-24-921935_chatcmpl-ac8c1df2-2feb-4fa9-8acd-132db4c8c0cd...\n",
      "Fetching observation data for time-06-29-03-106017_chatcmpl-2a7da485-1014-4455-bca0-7f3f243a8c6d...\n",
      "Fetching observation data for time-06-29-38-353869_chatcmpl-ac77f89d-492b-4aa8-abde-1119dd077a0a...\n",
      "Fetching observation data for time-06-30-16-381527_chatcmpl-27b87a3a-13a9-4f58-9cff-787005c8bbfe...\n",
      "Fetching observation data for 88e9f5b6-4868-4aef-a065-426b232d9050...\n",
      "Fetching observation data for time-06-24-40-866968_chatcmpl-ce21af30-8313-44ff-bc39-f0dd009bc79d...\n",
      "Fetching observation data for time-06-25-14-023336_chatcmpl-3ea3e7e4-c01f-4817-9de5-ce9d4109a71b...\n",
      "Fetching observation data for time-06-25-52-867931_chatcmpl-cc481cb7-1647-42a0-8a0a-0ecc2cc3309e...\n",
      "Fetching observation data for time-06-26-31-216314_chatcmpl-9caeaf1a-85c5-4568-a022-3d0ead6f1293...\n",
      "Fetching observation data for time-06-27-07-849359_chatcmpl-91f759f3-5cf0-4675-8d73-c25249ca90e4...\n",
      "Fetching observation data for 62ddae28-c2b4-4d92-882e-0cfc44ce6bd9...\n",
      "Fetching observation data for time-06-21-19-988541_chatcmpl-233198cf-52dc-44af-a7d7-6618d18b56aa...\n",
      "Fetching observation data for time-06-21-54-691719_chatcmpl-7d9e1950-5599-43e0-a46e-f2ab8a75f038...\n",
      "Fetching observation data for time-06-22-34-757396_chatcmpl-8e70ef6d-6987-45bf-8b16-59480999e591...\n",
      "Fetching observation data for time-06-23-14-445366_chatcmpl-2abe1ba9-e191-44cc-aaec-e0d8df1bb9ed...\n",
      "Fetching observation data for time-06-23-53-152839_chatcmpl-ffa63a20-e2a6-403a-8b86-f824323687e9...\n",
      "Fetching observation data for 718b8f54-63d5-4e6c-8333-5bed88b64c0d...\n",
      "Fetching observation data for time-06-18-00-971709_chatcmpl-617b681b-f452-4ca3-8e65-1d972264cccb...\n",
      "Fetching observation data for time-06-18-37-375678_chatcmpl-24f028fa-a56d-4755-97fc-1bd39d048e6e...\n",
      "Fetching observation data for time-06-19-17-528417_chatcmpl-8d02bda7-dd5e-4ebe-8f7f-b3d1951260f0...\n",
      "Fetching observation data for time-06-19-55-244310_chatcmpl-92558313-3595-4dac-b9c4-c4aed7cedc04...\n",
      "Fetching observation data for time-06-20-34-951333_chatcmpl-8a8311ce-7b2a-4635-badb-9cf5fc3baea4...\n",
      "Fetching observation data for time-06-16-08-402290_chatcmpl-01463b6c-b445-47d2-92ec-96eef4a308c1...\n",
      "Fetching observation data for time-06-16-45-108193_chatcmpl-86f3fc1a-2121-4c6e-88f6-755abe4cd8bb...\n",
      "Fetching observation data for time-06-17-15-382170_chatcmpl-9e05f0af-b971-4c1e-a23a-774533a77489...\n",
      "Fetching observation data for time-06-12-49-772439_chatcmpl-eaf5c316-4211-4e07-9925-05b3b3f9875c...\n",
      "Fetching observation data for time-06-13-24-486160_chatcmpl-6a9064d9-9a5b-42e3-8e86-defc35bd5692...\n",
      "Fetching observation data for time-06-14-04-646853_chatcmpl-dbd11cce-7aad-4883-b984-8f2e33d38ff1...\n",
      "Fetching observation data for time-06-14-43-058775_chatcmpl-f985db63-8af4-451a-8445-dd7441f4cdc3...\n",
      "Fetching observation data for time-06-15-24-013188_chatcmpl-12ce2d01-f24e-45f1-801c-9c49bc900030...\n",
      "Fetching observation data for 824ee57a-e8f9-4cd1-a62e-b4f8b6486ece...\n",
      "Fetching observation data for time-06-09-46-036078_chatcmpl-d7e9f08f-65b7-4151-a1d7-b0e4b2ef4a35...\n",
      "Fetching observation data for time-06-10-18-574449_chatcmpl-cef91cc2-dbb0-444e-a14d-6ba822e40bbc...\n",
      "Fetching observation data for time-06-10-54-886443_chatcmpl-9c3856f6-ded8-4a9b-a0d4-d8970dd3d628...\n",
      "Fetching observation data for time-06-11-33-006994_chatcmpl-0d26f139-72d5-4bb9-afcf-9cce258f1d0f...\n",
      "Fetching observation data for time-06-12-08-272133_chatcmpl-6bc5389e-1573-432b-a1a2-62ddcefad4e7...\n",
      "Fetching observation data for 3bbf92a2-fb58-45a0-a1e4-d6db72af942b...\n",
      "Fetching observation data for time-06-06-35-920904_chatcmpl-f7aa2816-5501-418b-adac-1ae2d98bba3d...\n",
      "Fetching observation data for time-06-07-12-341788_chatcmpl-7775233e-4c64-42f3-9294-174831b2eeb3...\n",
      "Fetching observation data for time-06-07-46-134741_chatcmpl-bddc1eff-6051-4bb2-9ad2-a4f1ca4e3cc3...\n",
      "Fetching observation data for time-06-08-24-430892_chatcmpl-e6034fc4-91b4-4ec9-8407-af288a18219f...\n",
      "Fetching observation data for time-06-09-00-364498_chatcmpl-e1dc0c6f-b0c2-47fa-a2c8-82afc7a1a511...\n",
      "Fetching observation data for 75a8e505-8aaf-41a0-8d1c-bfc9cb4e73f1...\n",
      "Fetching observation data for time-04-24-06-133370_chatcmpl-3c71119d-fe13-458d-8a37-dc50bf63f37b...\n",
      "Fetching observation data for time-04-24-39-754044_chatcmpl-93715eea-83a6-41d2-b1d7-059b555547c8...\n",
      "Fetching observation data for time-06-05-27-356034_chatcmpl-9e9ead64-dd63-448a-bec2-81265de6b3a3...\n",
      "Fetching observation data for time-06-05-56-414406_chatcmpl-36363468-aebc-4f51-8e24-87277fbce3a9...\n",
      "Fetching observation data for 75b26adb-6d4f-4bfa-b4c4-7ebc4421ddee...\n",
      "Fetching observation data for time-04-20-43-549424_chatcmpl-b256c2e8-063a-4ab9-a2da-6c9259b902f5...\n",
      "Fetching observation data for time-04-21-18-030272_chatcmpl-c20428dd-178b-497b-94f8-a121a94c15fc...\n",
      "Fetching observation data for time-04-21-59-273455_chatcmpl-285ad4e3-b384-4495-91c4-40ffcd32b510...\n",
      "Fetching observation data for time-04-22-39-019200_chatcmpl-12c0e15a-1a85-4dc7-b1f2-f5aeacc319f7...\n",
      "Fetching observation data for time-04-23-18-105286_chatcmpl-87a5e219-519f-4549-b5c4-1833108af88c...\n",
      "Fetching observation data for 8d9dd7ef-77fd-40df-abcb-28ab2e3811d7...\n",
      "Fetching observation data for time-04-17-32-717743_chatcmpl-8e508aec-df35-467c-9811-6aa21d5f5f54...\n",
      "Fetching observation data for time-04-18-08-951283_chatcmpl-4a77a8e7-9df0-492d-beb4-cdbecf19d514...\n",
      "Fetching observation data for time-04-18-45-461776_chatcmpl-ca76750d-f129-424a-a697-a4bd711fc7ef...\n",
      "Fetching observation data for time-04-19-22-940599_chatcmpl-19578b99-5b95-489d-a83d-7a138af730d5...\n",
      "Fetching observation data for time-04-19-59-714470_chatcmpl-5d469935-a6de-4833-9b7a-72da43a54a6d...\n",
      "Fetching observation data for 97c8c308-ef7e-41bf-ad75-80dabd4603f4...\n",
      "Fetching observation data for time-04-14-24-665301_chatcmpl-c5d335b4-4324-42ab-85b7-7d92488cc46c...\n",
      "Fetching observation data for time-04-15-01-575082_chatcmpl-39ae473e-22d1-48cf-a2e9-b678a580b540...\n",
      "Fetching observation data for time-04-15-36-009029_chatcmpl-456ca030-bce7-451f-b6ea-6bb6aabb1b7d...\n",
      "Fetching observation data for time-04-16-11-717498_chatcmpl-7142830d-3b5c-4774-8006-4cd6c4aab27f...\n",
      "Fetching observation data for time-04-16-49-609144_chatcmpl-e3872a69-9e22-404f-ae8b-4a7e071dabbd...\n",
      "Fetching observation data for dc01d858-d9e2-4e5c-91ae-e26487cca646...\n",
      "Fetching observation data for time-04-11-10-550656_chatcmpl-80587960-6d72-4679-81a3-f16a3a9df8a9...\n",
      "Fetching observation data for time-04-11-44-023895_chatcmpl-1db7b7c6-97c7-453a-84ea-bce758701d4c...\n",
      "Fetching observation data for time-04-12-24-329614_chatcmpl-d832fd08-19eb-4f4c-a72f-018354e14e7c...\n",
      "Fetching observation data for time-04-13-01-637902_chatcmpl-112846c5-4522-494e-931a-a8504dc91efb...\n",
      "Fetching observation data for time-04-13-41-058527_chatcmpl-613863e8-6b68-4deb-a295-a1bde0dade2f...\n",
      "Fetching observation data for a7de2516-f4ac-4723-8403-4d66f67afa40...\n",
      "Fetching observation data for time-04-07-53-952244_chatcmpl-5a1e31d0-1b37-4459-81d2-2e62fa1ccd91...\n",
      "Fetching observation data for time-04-08-25-766232_chatcmpl-99d6cf16-c3cd-4e8a-b484-ebac22b8a439...\n",
      "Fetching observation data for time-04-09-05-783229_chatcmpl-47b6af24-b5ca-40a4-a80e-e2c0139355c8...\n",
      "Fetching observation data for time-04-09-43-994738_chatcmpl-1b1cc756-add3-46fb-b5e5-a4ff66bcfaef...\n",
      "Fetching observation data for time-04-10-24-590601_chatcmpl-d5910afa-c889-44e4-850d-2552f93810e9...\n",
      "Fetching observation data for d44a7b4c-0975-4cb6-a8e7-7ee3914e8c82...\n",
      "Fetching observation data for time-04-04-54-506928_chatcmpl-258d48c6-340a-4444-9e8d-1616f5f6bbf2...\n",
      "Fetching observation data for time-04-05-30-704338_chatcmpl-52dee1f1-4c89-4254-8995-2ecd7422beb7...\n",
      "Fetching observation data for time-04-05-59-213871_chatcmpl-d6430cb2-e54c-4b85-b0b2-02a43ac9d6b7...\n",
      "Fetching observation data for time-04-06-34-164571_chatcmpl-cdc7b0b5-a0f0-4240-8b9f-7ed14a35ef53...\n",
      "Fetching observation data for time-04-07-10-499470_chatcmpl-779877a0-626f-4559-919a-387cedb4ac21...\n",
      "Fetching observation data for 7c20ab0c-b8ca-4dd3-8c5a-a0b6e37a5868...\n",
      "Fetching observation data for time-04-01-45-024837_chatcmpl-6de8f45f-fdc5-4f84-a32d-5ec60f1dadbf...\n",
      "Fetching observation data for time-04-02-21-169324_chatcmpl-ff67174f-0b87-44e2-9345-a2aae5a72ea0...\n",
      "Fetching observation data for time-04-02-58-801975_chatcmpl-2522516c-0509-4f18-95e0-d63e1ab3a647...\n",
      "Fetching observation data for time-04-03-32-175946_chatcmpl-f86b8d91-a2f4-44cd-8c4e-38f5c9a953e0...\n",
      "Fetching observation data for time-04-04-13-816935_chatcmpl-77adafd8-41a1-492e-acb1-7f6a5814e674...\n",
      "Fetching observation data for 965061af-7200-4f26-97ed-3464248bf915...\n",
      "Fetching observation data for time-03-58-25-444532_chatcmpl-7b7c8a24-59a1-407e-be27-699b07bd88bf...\n",
      "Fetching observation data for time-03-59-00-506103_chatcmpl-b3258160-a3de-485f-8862-6734c849b667...\n",
      "Fetching observation data for time-03-59-40-362851_chatcmpl-879eac0f-8d3b-418d-aacf-f9f646bd4251...\n",
      "Fetching observation data for time-04-00-21-917324_chatcmpl-1d89d345-a6df-4719-9857-65ce7555765d...\n",
      "Fetching observation data for time-04-01-00-141462_chatcmpl-a77815d0-2003-4a1d-9572-0f766602a59e...\n",
      "Fetching observation data for 01b31c5b-7c26-4bef-ae76-a40c3683c808...\n",
      "Fetching observation data for time-03-54-32-636625_chatcmpl-957f447b-3895-4a3b-9a90-3c6d5ec5257f...\n",
      "Fetching observation data for time-03-55-36-648508_chatcmpl-81b11ffb-4d06-419f-a3e1-9cd32a7e61d5...\n",
      "Fetching observation data for time-03-56-17-588533_chatcmpl-ae1b9853-cd18-47f8-bf86-ac171583948d...\n",
      "Fetching observation data for time-03-56-58-524927_chatcmpl-08a82626-aa7e-4b65-90a3-5aacc3a71cbf...\n",
      "Fetching observation data for time-03-57-39-800261_chatcmpl-50528aaa-7572-4d99-8aac-bc5d466644f4...\n",
      "Fetching observation data for b32d58e2-ca7a-4e16-8a87-f2056d17420a...\n",
      "Raw JSON saved to: /Users/hann/Projects/reference-benchmark-tinyml_llm/data_analysis/2025/08.16/raw_export/raw_gemma3:27b_04fd_tpusg_batch.json\n"
     ]
    }
   ],
   "source": [
    "# ALTERNATIVE TO 2.\n",
    "import os\n",
    "import json\n",
    "from time import sleep\n",
    "from langfuse import Langfuse\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "\n",
    "# LANGFUSE_SERVICE_PUBLIC_KEY = \"pk-lf-559a2c0f-ee29-4c32-944c-bf73b5f0ce28\"\n",
    "# LANGFUSE_SERVICE_SECRET_KEY = \"sk-lf-75f8bf7f-a5db-4756-b0dd-d758a2a292c8\"\n",
    "# LANGFUSE_SERVICE_HOST = \"https://langfuse.hann.fi\"\n",
    "\n",
    "\n",
    "if LOCAL_HOST:\n",
    "    langfuse = Langfuse(\n",
    "        secret_key=\"sk-lf-75f8bf7f-a5db-4756-b0dd-d758a2a292c8\",\n",
    "        public_key=\"pk-lf-559a2c0f-ee29-4c32-944c-bf73b5f0ce28\",\n",
    "        host=\"https://langfuse.hann.fi\",\n",
    "    )\n",
    "else:\n",
    "    langfuse = Langfuse(\n",
    "        secret_key=LANGFUSE_SERVICE_SECRET_KEY,\n",
    "        public_key=LANGFUSE_SERVICE_PUBLIC_KEY,\n",
    "        host=LANGFUSE_SERVICE_HOST,\n",
    "    )\n",
    "\n",
    "API_invok_count = 0\n",
    "query_range_num_run = {\"start\": 0, \"end\": 1}\n",
    "\n",
    "\n",
    "class CustomJSONEncoder(json.JSONEncoder):\n",
    "    def __init__(self, *args, LOCAL_HOST=True, **kwargs):\n",
    "        self.LOCAL_HOST = LOCAL_HOST\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "    def default(self, obj):\n",
    "        if isinstance(obj, datetime):\n",
    "            return obj.isoformat()\n",
    "        if hasattr(obj, \"__dict__\"):\n",
    "            data = obj.__dict__.copy()\n",
    "            if \"observations\" in data:\n",
    "                data[\"observations\"] = [\n",
    "                    fetch_observation_data(obs, self.LOCAL_HOST)\n",
    "                    for obs in data[\"observations\"]\n",
    "                ]\n",
    "\n",
    "            return data\n",
    "        return super().default(obj)\n",
    "\n",
    "\n",
    "def fetch_observation_data(observation_id, LOCAL_HOST):\n",
    "    \"\"\"\n",
    "    Fetches observation data from Langfuse and returns its dictionary representation.\n",
    "    \"\"\"\n",
    "    print(f\"Fetching observation data for {observation_id}...\")\n",
    "    global API_invok_count\n",
    "    if API_invok_count >= 0 and not LOCAL_HOST:\n",
    "        print(\"Waiting for 3 seconds to fetch observation data...\")\n",
    "        for _ in tqdm(range(3), desc=\"Progress\", unit=\"s\"):\n",
    "            sleep(1)\n",
    "        API_invok_count = 0\n",
    "\n",
    "    observation_response = langfuse.fetch_observation(observation_id)\n",
    "    API_invok_count += 1\n",
    "\n",
    "    return observation_response.data.dict()\n",
    "\n",
    "\n",
    "def fetch_and_save_complete_data(session_id_list, raw_export_dir, LOCAL_HOST):\n",
    "    \"\"\"\n",
    "    Fetches complete trace data for each session ID and saves it to JSON files.\n",
    "\n",
    "    Parameters:\n",
    "        session_id_list (list): List of session IDs to process.\n",
    "        raw_export_dir (str): Directory path to save raw JSON files.\n",
    "    \"\"\"\n",
    "\n",
    "    def save_complete_data(session_id):\n",
    "        global API_invok_count\n",
    "        if API_invok_count >= 0 and not LOCAL_HOST:\n",
    "            print(\"Waiting for 4 seconds to fetch traces...\")\n",
    "            for _ in tqdm(range(4), desc=\"Progress\", unit=\"s\"):\n",
    "                sleep(1)\n",
    "            API_invok_count = 0\n",
    "\n",
    "        fetch_traces_response = langfuse.fetch_traces(session_id=session_id)\n",
    "        API_invok_count += 1\n",
    "\n",
    "        print(f\"Fetching traces for session {session_id}...\")\n",
    "        # Create directories if they don't exist\n",
    "        os.makedirs(raw_export_dir, exist_ok=True)\n",
    "\n",
    "        # Save complete data to JSON file\n",
    "        # if session_id.startswith(\"da0a\"):\n",
    "        #     session_id = \"phi4_\" + session_id\n",
    "        if \"tpsg\" in session_id:\n",
    "            session_id_ = session_id.replace(\"tpsg\", \"tpusg\")\n",
    "        else:\n",
    "            session_id_ = session_id\n",
    "            \n",
    "        raw_path = os.path.join(raw_export_dir, f\"raw_{session_id_}.json\")\n",
    "        with open(raw_path, \"w\") as f:\n",
    "            json.dump(fetch_traces_response, f, cls=CustomJSONEncoder, indent=2)\n",
    "\n",
    "        print(f\"Raw JSON saved to: {raw_path}\")\n",
    "\n",
    "    for session_id in session_id_list:\n",
    "        save_complete_data(session_id)\n",
    "\n",
    "\n",
    "fetch_and_save_complete_data(session_id_list, raw_export_dir, LOCAL_HOST)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Trim data\n",
    "\n",
    "Here also intercept the runs with fatal errors that need to be excluded from the analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPAN error_88_psg_failure_signal_py_sketch_generator: Failed. Last error: Error loading model: OpenCV(4.10.0) /io/opencv/modules/dnn/src/tflite/tflite_importer.cpp:118: error: (-213:The function/feature is not implemented) Parse tensor with type UINT8 in function 'parseTensor'\n",
      "\n",
      "\n",
      "SPAN error_c2_psg_failure_signal_py_sketch_generator: Failed. Last error: Error loading model: OpenCV(4.10.0) /io/opencv/modules/dnn/src/tflite/tflite_importer.cpp:118: error: (-213:The function/feature is not implemented) Parse tensor with type UINT8 in function 'parseTensor'\n",
      "\n",
      "\n",
      "SPAN error_e2_psg_failure_signal_py_sketch_generator: Failed. Last error: Error loading model: OpenCV(4.10.0) /io/opencv/modules/dnn/src/tflite/tflite_importer.cpp:118: error: (-213:The function/feature is not implemented) Parse tensor with type UINT8 in function 'parseTensor'\n",
      "\n",
      "\n",
      "SPAN error_24_psg_failure_signal_py_sketch_generator: Failed. Last error: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250813080244_psg_gemma3:27b/tmp_20250813080244_psg_gemma3:27b.py\", line 54, in <module>\n",
      "    interpreter.set_tensor(input_details[0]['index'], input_image)\n",
      "  File \"/home/wuguangh/.conda/envs/tinyml/lib/python3.10/site-packages/tflite_runtime/interpreter.py\", line 720, in set_tensor\n",
      "    self._interpreter.SetTensor(tensor_index, value)\n",
      "ValueError: Cannot set tensor: Got value of type FLOAT32 but expected type UINT8 for input 175, name: normalized_input_image_tensor \n",
      "\n",
      "SPAN error_0f_psg_failure_signal_py_sketch_generator: Failed. Last error: 2025-08-13 08:00:08.394053: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-08-13 08:00:08.398623: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-08-13 08:00:08.412589: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-08-13 08:00:08.433870: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-08-13 08:00:08.440544: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-08-13 08:00:08.457024: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-08-13 08:00:09.314776: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250813080008_psg_gemma3:27b/tmp_20250813080008_psg_gemma3:27b.py\", line 72, in <module>\n",
      "    if confidence > confidence_threshold:\n",
      "ValueError: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()\n",
      "\n",
      "SPAN error_47_psg_failure_signal_py_sketch_generator: Failed. Last error: Error loading the model: OpenCV(4.10.0) /io/opencv/modules/dnn/src/tflite/tflite_importer.cpp:118: error: (-213:The function/feature is not implemented) Parse tensor with type UINT8 in function 'parseTensor'\n",
      "\n",
      "\n",
      "SPAN error_17_psg_failure_signal_py_sketch_generator: Failed. Last error: Traceback (most recent call last):\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250813075359_psg_gemma3:27b/tmp_20250813075359_psg_gemma3:27b.py\", line 17, in <module>\n",
      "    interpreter = cv2.dnn.readNet(model_path)\n",
      "cv2.error: OpenCV(4.10.0) /io/opencv/modules/dnn/src/tflite/tflite_importer.cpp:118: error: (-213:The function/feature is not implemented) Parse tensor with type UINT8 in function 'parseTensor'\n",
      "\n",
      "\n",
      "SPAN error_68_psg_failure_signal_py_sketch_generator: Failed. Last error: 2025-08-13 07:51:20.381961: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-08-13 07:51:20.386640: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-08-13 07:51:20.400593: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-08-13 07:51:20.422811: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-08-13 07:51:20.429277: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-08-13 07:51:20.445919: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-08-13 07:51:21.297735: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250813075120_psg_gemma3:27b/tmp_20250813075120_psg_gemma3:27b.py\", line 65, in <module>\n",
      "    if classes[i] > confidence_threshold:\n",
      "ValueError: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()\n",
      "\n",
      "SPAN error_15_psg_failure_signal_py_sketch_generator: Failed. Last error: Error loading model: OpenCV(4.10.0) /io/opencv/modules/dnn/src/tflite/tflite_importer.cpp:118: error: (-213:The function/feature is not implemented) Parse tensor with type UINT8 in function 'parseTensor'\n",
      "\n",
      "\n",
      "SPAN error_36_psg_failure_signal_py_sketch_generator: Failed. Last error: Traceback (most recent call last):\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250813074540_psg_gemma3:27b/tmp_20250813074540_psg_gemma3:27b.py\", line 17, in <module>\n",
      "    interpreter = cv2.dnn.readNet(model_path)\n",
      "cv2.error: OpenCV(4.10.0) /io/opencv/modules/dnn/src/tflite/tflite_importer.cpp:118: error: (-213:The function/feature is not implemented) Parse tensor with type UINT8 in function 'parseTensor'\n",
      "\n",
      "\n",
      "SPAN error_07_psg_failure_signal_py_sketch_generator: Failed. Last error: Traceback (most recent call last):\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250813074319_psg_gemma3:27b/tmp_20250813074319_psg_gemma3:27b.py\", line 18, in <module>\n",
      "    interpreter = cv2.dnn.readNet(model_path)\n",
      "cv2.error: OpenCV(4.10.0) /io/opencv/modules/dnn/src/tflite/tflite_importer.cpp:118: error: (-213:The function/feature is not implemented) Parse tensor with type UINT8 in function 'parseTensor'\n",
      "\n",
      "\n",
      "SPAN error_71_psg_failure_signal_py_sketch_generator: Failed. Last error: Traceback (most recent call last):\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250813074108_psg_gemma3:27b/tmp_20250813074108_psg_gemma3:27b.py\", line 18, in <module>\n",
      "    interpreter = cv2.dnn.readNet(model_path)\n",
      "cv2.error: OpenCV(4.10.0) /io/opencv/modules/dnn/src/tflite/tflite_importer.cpp:118: error: (-213:The function/feature is not implemented) Parse tensor with type UINT8 in function 'parseTensor'\n",
      "\n",
      "\n",
      "SPAN error_46_psg_failure_signal_py_sketch_generator: Failed. Last error: Error loading model: OpenCV(4.10.0) /io/opencv/modules/dnn/src/tflite/tflite_importer.cpp:118: error: (-213:The function/feature is not implemented) Parse tensor with type UINT8 in function 'parseTensor'\n",
      "\n",
      "\n",
      "SPAN error_db_psg_failure_signal_py_sketch_generator: Failed. Last error: Traceback (most recent call last):\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250813073630_psg_gemma3:27b/tmp_20250813073630_psg_gemma3:27b.py\", line 17, in <module>\n",
      "    interpreter = cv2.dnn.readNet(model_path)\n",
      "cv2.error: OpenCV(4.10.0) /io/opencv/modules/dnn/src/tflite/tflite_importer.cpp:118: error: (-213:The function/feature is not implemented) Parse tensor with type UINT8 in function 'parseTensor'\n",
      "\n",
      "\n",
      "SPAN error_33_psg_failure_signal_py_sketch_generator: Failed. Last error: Error loading the model: OpenCV(4.10.0) /io/opencv/modules/dnn/src/tflite/tflite_importer.cpp:118: error: (-213:The function/feature is not implemented) Parse tensor with type UINT8 in function 'parseTensor'\n",
      "\n",
      "\n",
      "SPAN error_dd_psg_failure_signal_py_sketch_generator: Failed. Last error: Traceback (most recent call last):\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250813073119_psg_gemma3:27b/tmp_20250813073119_psg_gemma3:27b.py\", line 17, in <module>\n",
      "    interpreter = cv2.dnn.readNet(model_path)\n",
      "cv2.error: OpenCV(4.10.0) /io/opencv/modules/dnn/src/tflite/tflite_importer.cpp:118: error: (-213:The function/feature is not implemented) Parse tensor with type UINT8 in function 'parseTensor'\n",
      "\n",
      "\n",
      "SPAN error_8c_psg_failure_signal_py_sketch_generator: Failed. Last error: Traceback (most recent call last):\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250813072652_psg_gemma3:27b/tmp_20250813072652_psg_gemma3:27b.py\", line 17, in <module>\n",
      "    interpreter = cv2.dnn.readNet(model_path)\n",
      "cv2.error: OpenCV(4.10.0) /io/opencv/modules/dnn/src/tflite/tflite_importer.cpp:118: error: (-213:The function/feature is not implemented) Parse tensor with type UINT8 in function 'parseTensor'\n",
      "\n",
      "\n",
      "SPAN error_44_psg_failure_signal_py_sketch_generator: Failed. Last error: Error loading model: OpenCV(4.10.0) /io/opencv/modules/dnn/src/tflite/tflite_importer.cpp:118: error: (-213:The function/feature is not implemented) Parse tensor with type UINT8 in function 'parseTensor'\n",
      "\n",
      "\n",
      "SPAN error_fc_psg_failure_signal_py_sketch_generator: Failed. Last error: Traceback (most recent call last):\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250813072220_psg_gemma3:27b/tmp_20250813072220_psg_gemma3:27b.py\", line 18, in <module>\n",
      "    interpreter = cv2.dnn.readNet(model_path)\n",
      "cv2.error: OpenCV(4.10.0) /io/opencv/modules/dnn/src/tflite/tflite_importer.cpp:118: error: (-213:The function/feature is not implemented) Parse tensor with type UINT8 in function 'parseTensor'\n",
      "\n",
      "\n",
      "SPAN error_7d_psg_failure_signal_py_sketch_generator: Failed. Last error: Traceback (most recent call last):\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250813071859_psg_gemma3:27b/tmp_20250813071859_psg_gemma3:27b.py\", line 17, in <module>\n",
      "    interpreter = cv2.dnn.readNet(model_path)\n",
      "cv2.error: OpenCV(4.10.0) /io/opencv/modules/dnn/src/tflite/tflite_importer.cpp:118: error: (-213:The function/feature is not implemented) Parse tensor with type UINT8 in function 'parseTensor'\n",
      "\n",
      "\n",
      "SPAN error_11_psg_failure_signal_py_sketch_generator: Failed. Last error: Traceback (most recent call last):\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250813071620_psg_gemma3:27b/tmp_20250813071620_psg_gemma3:27b.py\", line 17, in <module>\n",
      "    interpreter = cv2.dnn.readNet(model_path)\n",
      "cv2.error: OpenCV(4.10.0) /io/opencv/modules/dnn/src/tflite/tflite_importer.cpp:118: error: (-213:The function/feature is not implemented) Parse tensor with type UINT8 in function 'parseTensor'\n",
      "\n",
      "\n",
      "SPAN error_97_psg_failure_signal_py_sketch_generator: Failed. Last error: Error loading model: OpenCV(4.10.0) /io/opencv/modules/dnn/src/tflite/tflite_importer.cpp:118: error: (-213:The function/feature is not implemented) Parse tensor with type UINT8 in function 'parseTensor'\n",
      "\n",
      "\n",
      "Successfully processed and saved trimmed data for session gemma3:27b_04fd_psg_batch\n",
      "SPAN error_bf_tpusg_failure_signal_tpu_sketch_generator: Failed. Last error: Traceback (most recent call last):\n",
      "  File \"script_61ba65d0_1755058208.py\", line 57, in <module>\n",
      "    if confidence > 0.5:\n",
      "ValueError: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()\n",
      "SPAN error_c6_tpusg_failure_signal_tpu_sketch_generator: Failed. Last error: Traceback (most recent call last):\n",
      "  File \"script_320095b9_1755058026.py\", line 66, in <module>\n",
      "    classes = output_data[1]\n",
      "IndexError: index 1 is out of bounds for axis 0 with size 1\n",
      "SPAN error_28_tpusg_failure_signal_tpu_sketch_generator: Failed. Last error: Traceback (most recent call last):\n",
      "  File \"script_a3d2fa68_1755057824.py\", line 75, in <module>\n",
      "    if scores > 0.5:\n",
      "ValueError: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()\n",
      "SPAN error_72_tpusg_failure_signal_tpu_sketch_generator: Failed. Last error: Traceback (most recent call last):\n",
      "  File \"script_2df18abf_1755057626.py\", line 67, in <module>\n",
      "    classes = output_data[1]\n",
      "IndexError: index 1 is out of bounds for axis 0 with size 1\n",
      "SPAN error_5a_tpusg_failure_signal_tpu_sketch_generator: Failed. Last error: Traceback (most recent call last):\n",
      "  File \"script_3b3b9286_1755057431.py\", line 1, in <module>\n",
      "    import tensorflow as tf\n",
      "ModuleNotFoundError: No module named 'tensorflow'\n",
      "SPAN error_ec_tpusg_failure_signal_tpu_sketch_generator: Failed. Last error: Error loading with CUDA: module 'cv2' has no attribute 'dnn'\n",
      "Falling back to CPU...\n",
      "Traceback (most recent call last):\n",
      "  File \"script_2fd9771b_1755057245.py\", line 6, in <module>\n",
      "    interpreter = cv2.dnn.readNet('detect.tflite')\n",
      "AttributeError: module 'cv2' has no attribute 'dnn'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"script_2fd9771b_1755057245.py\", line 12, in <module>\n",
      "    interpreter = cv2.dnn.readNet('detect.tflite')\n",
      "AttributeError: module 'cv2' has no attribute 'dnn'\n",
      "SPAN error_4a_tpusg_failure_signal_tpu_sketch_generator: Failed. Last error: Traceback (most recent call last):\n",
      "  File \"script_3280d061_1755057039.py\", line 63, in <module>\n",
      "    classes = output_data[..., 4]\n",
      "IndexError: index 4 is out of bounds for axis 2 with size 4\n",
      "SPAN error_87_tpusg_failure_signal_tpu_sketch_generator: Failed. Last error: Traceback (most recent call last):\n",
      "  File \"script_55299f2d_1755056831.py\", line 66, in <module>\n",
      "    if scores > confidence_threshold:\n",
      "ValueError: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()\n",
      "SPAN error_86_tpusg_failure_signal_tpu_sketch_generator: Failed. Last error: Traceback (most recent call last):\n",
      "  File \"script_82ecdac0_1755056643.py\", line 64, in <module>\n",
      "    classes = output_data[0, ..., 5]\n",
      "IndexError: index 5 is out of bounds for axis 2 with size 4\n",
      "SPAN error_f8_tpusg_failure_signal_tpu_sketch_generator: Failed. Last error: Traceback (most recent call last):\n",
      "  File \"script_ac809288_1755056441.py\", line 66, in <module>\n",
      "    classes = output_data[0, ..., 4]\n",
      "IndexError: index 4 is out of bounds for axis 2 with size 4\n",
      "SPAN error_80_tpusg_failure_signal_tpu_sketch_generator: Failed. Last error:   File \"script_e6ef48b9_1755056235.py\", line 1\n",
      "    <complete_code>\n",
      "    ^\n",
      "SyntaxError: invalid syntax\n",
      "SPAN error_46_tpusg_failure_signal_tpu_sketch_generator: Failed. Last error: Traceback (most recent call last):\n",
      "  File \"script_e4fed3d0_1755056046.py\", line 64, in <module>\n",
      "    classes = output_data[1]  # Corrected line\n",
      "IndexError: index 1 is out of bounds for axis 0 with size 1\n",
      "SPAN error_9d_tpusg_failure_signal_tpu_sketch_generator: Failed. Last error: Traceback (most recent call last):\n",
      "  File \"script_fafb92d5_1755055845.py\", line 65, in <module>\n",
      "    if scores > confidence_threshold: #This line caused the error. scores is a numpy array\n",
      "ValueError: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()\n",
      "SPAN error_cd_tpusg_failure_signal_tpu_sketch_generator: Failed. Last error: Traceback (most recent call last):\n",
      "  File \"script_43e2f5ee_1755055656.py\", line 65, in <module>\n",
      "    if scores > confidence_threshold:\n",
      "ValueError: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()\n",
      "SPAN error_61_tpusg_failure_signal_tpu_sketch_generator: Failed. Last error: Traceback (most recent call last):\n",
      "  File \"script_fe4378c8_1755055466.py\", line 74, in <module>\n",
      "    if scores > detection_threshold:\n",
      "ValueError: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()\n",
      "SPAN error_7b_tpusg_failure_signal_tpu_sketch_generator: Failed. Last error: Traceback (most recent call last):\n",
      "  File \"script_78854782_1755054954.py\", line 69, in <module>\n",
      "    if scores > confidence_threshold:\n",
      "ValueError: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()\n",
      "SPAN error_5f_tpusg_failure_signal_tpu_sketch_generator: Failed. Last error: Traceback (most recent call last):\n",
      "  File \"script_69347d72_1755054755.py\", line 63, in <module>\n",
      "    if scores > 0.5:\n",
      "ValueError: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()\n",
      "SPAN error_62_tpusg_failure_signal_tpu_sketch_generator: Failed. Last error: Traceback (most recent call last):\n",
      "  File \"script_c5f7a06d_1755054571.py\", line 55, in <module>\n",
      "    classes = output_data[0, ..., 5]\n",
      "IndexError: index 5 is out of bounds for axis 2 with size 4\n",
      "SPAN error_38_tpusg_failure_signal_tpu_sketch_generator: Failed. Last error: Traceback (most recent call last):\n",
      "  File \"script_e24603ca_1755054383.py\", line 13, in <module>\n",
      "    interpreter.allocate_tensor()\n",
      "AttributeError: 'Interpreter' object has no attribute 'allocate_tensor'\n",
      "SPAN error_90_tpusg_failure_signal_tpu_sketch_generator: Failed. Last error: Traceback (most recent call last):\n",
      "  File \"script_432f6938_1755048233.py\", line 64, in <module>\n",
      "    classes = output_data[0, ..., 5]\n",
      "IndexError: index 5 is out of bounds for axis 2 with size 4\n",
      "SPAN error_fd_tpusg_failure_signal_tpu_sketch_generator: Failed. Last error: Traceback (most recent call last):\n",
      "  File \"script_bdb1c432_1755048029.py\", line 3, in <module>\n",
      "    import tensorflow as tf\n",
      "ModuleNotFoundError: No module named 'tensorflow'\n",
      "SPAN error_e8_tpusg_failure_signal_tpu_sketch_generator: Failed. Last error: Traceback (most recent call last):\n",
      "  File \"script_639bbbf8_1755047841.py\", line 1, in <module>\n",
      "    import tensorflow as tf\n",
      "ModuleNotFoundError: No module named 'tensorflow'\n",
      "SPAN error_c9_tpusg_failure_signal_tpu_sketch_generator: Failed. Last error: Traceback (most recent call last):\n",
      "  File \"script_59198240_1755047648.py\", line 68, in <module>\n",
      "    if confidence > confidence_threshold:\n",
      "ValueError: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()\n",
      "SPAN error_d0_tpusg_failure_signal_tpu_sketch_generator: Failed. Last error: Traceback (most recent call last):\n",
      "  File \"script_30477ec9_1755047456.py\", line 66, in <module>\n",
      "    if confidence > 0.5:\n",
      "ValueError: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()\n",
      "SPAN error_2b_tpusg_failure_signal_tpu_sketch_generator: Failed. Last error: Traceback (most recent call last):\n",
      "  File \"script_4753cb97_1755047262.py\", line 2, in <module>\n",
      "    import tensorflow as tf\n",
      "ModuleNotFoundError: No module named 'tensorflow'\n",
      "SPAN error_94_tpusg_failure_signal_tpu_sketch_generator: Failed. Last error:   File \"script_18892ecd_1755047083.py\", line 1\n",
      "    from tf lite_runtime.interpreter import Interpreter, load_delegate\n",
      "                       ^\n",
      "SyntaxError: invalid syntax\n",
      "SPAN error_49_tpusg_failure_signal_tpu_sketch_generator: Failed. Last error: Traceback (most recent call last):\n",
      "  File \"script_7bade229_1755046891.py\", line 64, in <module>\n",
      "    classes = output_data[0, ..., 5]\n",
      "IndexError: index 5 is out of bounds for axis 2 with size 4\n",
      "SPAN error_0c_tpusg_failure_signal_tpu_sketch_generator: Failed. Last error: Traceback (most recent call last):\n",
      "  File \"script_ea9a372d_1755046689.py\", line 63, in <module>\n",
      "    if confidence > 0.5:\n",
      "ValueError: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()\n",
      "Successfully processed and saved trimmed data for session gemma3:27b_04fd_tpusg_batch\n",
      "Total 0 traces skipped. They are []\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "skipped_traces = []\n",
    "\n",
    "\n",
    "def process_existing_observation(observation):\n",
    "    \"\"\"\n",
    "    Processes an existing observation dictionary by trimming unwanted keys.\n",
    "    \"\"\"\n",
    "    unwanted_observation_keys = [\n",
    "        \"completionStartTime\",\n",
    "        \"metadata\",\n",
    "        \"timeToFirstToken\",\n",
    "        \"createdAt\",\n",
    "        \"usageDetails\",\n",
    "        \"usage\",\n",
    "        \"projectId\",\n",
    "        \"unit\",\n",
    "        \"updatedAt\",\n",
    "        \"version\",\n",
    "        \"parentObservationId\",\n",
    "        \"promptId\",\n",
    "        \"promptName\",\n",
    "        \"promptVersion\",\n",
    "        \"modelId\",\n",
    "        \"inputPrice\",\n",
    "        \"outputPrice\",\n",
    "        \"totalPrice\",\n",
    "        # \"modelParameters\",\n",
    "        \"input\",\n",
    "        \"output\",\n",
    "    ]\n",
    "\n",
    "    # If observation is a dictionary containing observation data\n",
    "    if isinstance(observation, dict):\n",
    "        trimmed_observation = {\n",
    "            k: v for k, v in observation.items() if k not in unwanted_observation_keys\n",
    "        }\n",
    "        return trimmed_observation\n",
    "    return observation\n",
    "\n",
    "\n",
    "def trim_data(data):\n",
    "    \"\"\"\n",
    "    Recursively trims the data structure.\n",
    "    \"\"\"\n",
    "\n",
    "    if isinstance(data, dict):\n",
    "        # Process the current dictionary\n",
    "        unwanted_trace_keys = [\n",
    "            \"release\",\n",
    "            \"version\",\n",
    "            \"user_id\",\n",
    "            \"public\",\n",
    "            \"html_path\",\n",
    "            \"scores\",\n",
    "            \"bookmarked\",\n",
    "            \"projectId\",\n",
    "            \"externalId\",\n",
    "            \"page\",\n",
    "            \"limit\",\n",
    "            \"total_pages\",\n",
    "        ]\n",
    "\n",
    "        # If this is a trace that contains observations, check for fatal errors\n",
    "        if \"observations\" in data:\n",
    "            # Check for SPAN observations with fatal errors before processing\n",
    "            skip_trace = False\n",
    "            for obs in data[\"observations\"]:\n",
    "                if isinstance(obs, dict) and obs.get(\"name\").startswith(\"error\"):\n",
    "                    status_message = obs.get(\"statusMessage\", \"\")\n",
    "                    ob_name = obs.get(\"name\")\n",
    "                    print(f\"SPAN {ob_name}: {status_message}\")\n",
    "\n",
    "                    if \"Fatal error\" in status_message:\n",
    "                        print(f\"Found Fatal error in SPAN observation, skipping trace\")\n",
    "                        skip_trace = True\n",
    "                        skipped_traces.append(data[\"name\"])\n",
    "                        break\n",
    "\n",
    "            if skip_trace:\n",
    "                return None  # Signal to skip this trace\n",
    "\n",
    "        # Create a new dictionary with wanted keys and recursively process values\n",
    "        trimmed_data = {}\n",
    "        for key, value in data.items():\n",
    "            if key not in unwanted_trace_keys:\n",
    "                if key == \"observations\":\n",
    "                    # Special handling for observations\n",
    "                    trimmed_data[key] = [\n",
    "                        process_existing_observation(obs) for obs in value\n",
    "                    ]\n",
    "                elif isinstance(value, (dict, list)):\n",
    "                    # Recursively process nested structures\n",
    "                    trimmed_data[key] = trim_data(value)\n",
    "                else:\n",
    "                    trimmed_data[key] = value\n",
    "\n",
    "        return trimmed_data\n",
    "\n",
    "    elif isinstance(data, list):\n",
    "        # Recursively process each item in the list\n",
    "        processed_items = []\n",
    "        for item in data:\n",
    "            processed_item = trim_data(item)\n",
    "            if processed_item is not None:  # Only add items that weren't filtered out\n",
    "                processed_items.append(processed_item)\n",
    "        return processed_items\n",
    "\n",
    "    else:\n",
    "        # Return non-dict, non-list values as is\n",
    "        return data\n",
    "\n",
    "\n",
    "def read_and_trim_data(session_id_list, raw_export_dir, trimmed_export_dir):\n",
    "    \"\"\"\n",
    "    Reads complete data from JSON files, trims the data, and saves the trimmed data to new JSON files.\n",
    "    \"\"\"\n",
    "    os.makedirs(trimmed_export_dir, exist_ok=True)\n",
    "\n",
    "    for session_id in session_id_list:\n",
    "        try:\n",
    "            if session_id.startswith(\"da0a\"):\n",
    "                session_id = \"phi4_\" + session_id\n",
    "            # Read raw data\n",
    "            if \"tpsg\" in session_id:\n",
    "                session_id_ = session_id.replace(\"tpsg\", \"tpusg\")\n",
    "            else:\n",
    "                session_id_ = session_id\n",
    "            raw_path = os.path.join(raw_export_dir, f\"raw_{session_id_}.json\")\n",
    "            with open(raw_path, \"r\") as f:\n",
    "                data = json.load(f)\n",
    "\n",
    "            # Process and trim the data\n",
    "            trimmed_data = trim_data(data)\n",
    "\n",
    "            # If the entire data was filtered out (unlikely but possible)\n",
    "            if trimmed_data is None:\n",
    "                print(\n",
    "                    f\"All traces in session {session_id} were filtered due to fatal errors\"\n",
    "                )\n",
    "                continue\n",
    "\n",
    "            # Save trimmed data\n",
    "            if \"tpsg\" in session_id:\n",
    "                session_id_ = session_id.replace(\"tpsg\", \"tpusg\")\n",
    "            else:\n",
    "                session_id_ = session_id\n",
    "            trimmed_path = os.path.join(\n",
    "                trimmed_export_dir, f\"trimmed_{session_id_}.json\"\n",
    "            )\n",
    "            with open(trimmed_path, \"w\") as f:\n",
    "                json.dump(trimmed_data, f, indent=2)\n",
    "\n",
    "            print(\n",
    "                f\"Successfully processed and saved trimmed data for session {session_id}\"\n",
    "            )\n",
    "\n",
    "            # Optional: Verify trimming worked\n",
    "            # print(f\"Verifying trimmed data for session {session_id}...\")\n",
    "            # verify_trimming(trimmed_path)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing session {session_id}: {str(e)}\")\n",
    "\n",
    "\n",
    "def verify_trimming(trimmed_path):\n",
    "    \"\"\"\n",
    "    Verifies that the trimmed data doesn't contain unwanted keys.\n",
    "    \"\"\"\n",
    "    with open(trimmed_path, \"r\") as f:\n",
    "        trimmed_data = json.load(f)\n",
    "\n",
    "    unwanted_keys = [\n",
    "        \"release\",\n",
    "        \"version\",\n",
    "        \"user_id\",\n",
    "        \"public\",\n",
    "        \"html_path\",\n",
    "        \"scores\",\n",
    "        \"bookmarked\",\n",
    "        \"projectId\",\n",
    "        \"externalId\",\n",
    "        \"page\",\n",
    "        \"limit\",\n",
    "        \"total_pages\",\n",
    "        \"completionStartTime\",\n",
    "        \"metadata\",\n",
    "        \"usageDetails\",\n",
    "        \"timeToFirstToken\",\n",
    "        \"createdAt\",\n",
    "        \"completionTokens\",\n",
    "        \"promptTokens\",\n",
    "        \"projectId\",\n",
    "        \"unit\",\n",
    "        \"updatedAt\",\n",
    "        \"version\",\n",
    "        # \"statusMessage\",\n",
    "        \"parentObservationId\",\n",
    "        \"promptId\",\n",
    "        \"promptName\",\n",
    "        \"promptVersion\",\n",
    "        \"modelId\",\n",
    "        \"inputPrice\",\n",
    "        \"outputPrice\",\n",
    "        \"totalPrice\",\n",
    "        \"calculatedInputCost\",\n",
    "        \"calculatedOutputCost\",\n",
    "        \"calculatedTotalCost\",\n",
    "    ]\n",
    "\n",
    "    def check_keys(obj):\n",
    "        if isinstance(obj, dict):\n",
    "            for key in obj.keys():\n",
    "                if key in unwanted_keys:\n",
    "                    print(f\"Warning: Found unwanted key '{key}' in trimmed data\")\n",
    "            for value in obj.values():\n",
    "                check_keys(value)\n",
    "        elif isinstance(obj, list):\n",
    "            for item in obj:\n",
    "                check_keys(item)\n",
    "\n",
    "    check_keys(trimmed_data)\n",
    "    print(\"Verification complete\")\n",
    "\n",
    "\n",
    "# Usage example:\n",
    "read_and_trim_data(session_id_list, raw_export_dir, raw_export_dir)\n",
    "print(f\"Total {len(skipped_traces)} traces skipped. They are {skipped_traces}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Generate CSV files from JSON\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing session gemma3:27b_04fd_psg_batch, simple id gemma3:27b_04fd. Look for /Users/hann/Projects/reference-benchmark-tinyml_llm/data_analysis/2025/08.16/raw_export/trimmed_gemma3:27b_04fd_psg_batch.json\n",
      "/Users/hann/Projects/reference-benchmark-tinyml_llm/data_analysis/2025/08.16/processed_data/gemma3:27b_04fd/clean_gemma3:27b_04fd_psg_batch.csv\n",
      "Successfully saved CSV to: /Users/hann/Projects/reference-benchmark-tinyml_llm/data_analysis/2025/08.16/processed_data/gemma3:27b_04fd/clean_gemma3:27b_04fd_psg_batch.csv\n",
      "Processing session gemma3:27b_04fd_tpusg_batch, simple id gemma3:27b_04fd. Look for /Users/hann/Projects/reference-benchmark-tinyml_llm/data_analysis/2025/08.16/raw_export/trimmed_gemma3:27b_04fd_tpusg_batch.json\n",
      "/Users/hann/Projects/reference-benchmark-tinyml_llm/data_analysis/2025/08.16/processed_data/gemma3:27b_04fd/clean_gemma3:27b_04fd_tpusg_batch.csv\n",
      "Successfully saved CSV to: /Users/hann/Projects/reference-benchmark-tinyml_llm/data_analysis/2025/08.16/processed_data/gemma3:27b_04fd/clean_gemma3:27b_04fd_tpusg_batch.csv\n"
     ]
    }
   ],
   "source": [
    "import traceback\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from dateutil import parser\n",
    "\n",
    "\n",
    "def json_to_csv(session_id):\n",
    "    \"\"\"\n",
    "    Convert JSON trace data to CSV format with aggregated metrics.\n",
    "\n",
    "    Args:\n",
    "        session_id (str): Identifier for the session to process\n",
    "    \"\"\"\n",
    "\n",
    "    def extract_observation_details(observations, trace_id):\n",
    "        \"\"\"Extract and aggregate metrics from observations\"\"\"\n",
    "        metrics = {\n",
    "            \"status\": None,\n",
    "            \"latency\": 0,\n",
    "            \"total_tokens\": 0,\n",
    "            \"prompt_tokens\": 0,\n",
    "            \"completion_tokens\": 0,\n",
    "            \"total_cost\": 0,\n",
    "            \"input_cost\": 0,\n",
    "            \"output_cost\": 0,\n",
    "            \"parameters\": set(),\n",
    "        }\n",
    "\n",
    "        # Process GENERATION observations\n",
    "        for obs in (o for o in observations if o[\"type\"] == \"GENERATION\"):\n",
    "            metrics[\"total_tokens\"] += obs[\"totalTokens\"]\n",
    "            metrics[\"prompt_tokens\"] += obs[\"promptTokens\"]\n",
    "            metrics[\"completion_tokens\"] += obs[\"completionTokens\"]\n",
    "            metrics[\"latency\"] += obs[\"latency\"]\n",
    "            for key, value in obs[\"modelParameters\"].items():\n",
    "                metrics[\"parameters\"].add(key + \":\" + value)\n",
    "\n",
    "            # Add costs if present\n",
    "            for cost_type in [\"Total\", \"Input\", \"Output\"]:\n",
    "                key = f\"calculated{cost_type}Cost\"\n",
    "                metric_key = cost_type.lower() + \"_cost\"\n",
    "                if obs.get(key) is not None:\n",
    "                    metrics[metric_key] += obs[key]\n",
    "        if len(metrics[\"parameters\"]) == 0:\n",
    "            metrics[\"parameters\"] = \"N/A\"\n",
    "        # Process SPAN observations for status\n",
    "        status_indicators = [\n",
    "            obs[\"name\"]\n",
    "            for obs in observations\n",
    "            if obs[\"type\"] == \"SPAN\" and \"start_\" not in obs[\"name\"]\n",
    "        ]\n",
    "\n",
    "        #  if later than 2025-05-19, use status_signal_from_output\n",
    "        if datetime.now() > datetime(2025, 5, 19):\n",
    "            pass\n",
    "        else:\n",
    "            # Determine status\n",
    "            success_signals = sum(\"end_\" in name for name in status_indicators)\n",
    "            failure_signals = sum(\n",
    "                \"failure_signal\" in name for name in status_indicators\n",
    "            )\n",
    "\n",
    "            if success_signals + failure_signals > 1:\n",
    "                raise ValueError(\n",
    "                    f\"Multiple status indicators found in trace {trace_id}\"\n",
    "                )\n",
    "\n",
    "            metrics[\"status\"] = (\n",
    "                \"success\"\n",
    "                if success_signals\n",
    "                else \"failure\" if failure_signals else \"unknown\"\n",
    "            )\n",
    "\n",
    "        metrics[\"prompt_cost\"] = metrics.pop(\"input_cost\")\n",
    "        metrics[\"completion_cost\"] = metrics.pop(\"output_cost\")\n",
    "        metrics[\"latency\"] = round(metrics[\"latency\"] / 1000, 2)\n",
    "        return metrics\n",
    "\n",
    "    def cal_time(trace):\n",
    "        time_diff = datetime.fromisoformat(\n",
    "            trace[\"updatedAt\"].replace(\"Z\", \"+00:00\")\n",
    "        ) - datetime.fromisoformat(trace[\"createdAt\"].replace(\"Z\", \"+00:00\"))\n",
    "        seconds_diff = time_diff.total_seconds()\n",
    "        return seconds_diff\n",
    "\n",
    "    try:\n",
    "\n",
    "        if session_id.startswith(\"da0a\"):\n",
    "            session_id = \"phi4_\" + session_id\n",
    "        simple_session_id = session_id.rsplit(\"_\", 2)[0]\n",
    "\n",
    "        \n",
    "        # Load JSON data\n",
    "        if \"tpsg\" in session_id:\n",
    "                session_id_ = session_id.replace(\"tpsg\", \"tpusg\")\n",
    "        else:\n",
    "                session_id_ = session_id\n",
    "        trimmed_path = os.path.join(raw_export_dir, f\"trimmed_{session_id_}.json\")\n",
    "        print(\n",
    "            f\"Processing session {session_id}, simple id {simple_session_id}. Look for {trimmed_path}\"\n",
    "        )\n",
    "        with open(trimmed_path, \"r\") as file:\n",
    "            traces = json.load(file)[\"data\"]\n",
    "\n",
    "        # Process traces\n",
    "        rows = [\n",
    "            {\n",
    "                \"num_run\": trace[\"metadata\"][\"num_run\"],\n",
    "                \"name\": trace[\"name\"],\n",
    "                \"trace_id\": trace[\"id\"],\n",
    "                \"batch_id\": trace[\"session_id\"],\n",
    "                # \"latency\": cal_time(trace),\n",
    "                # \"latency\": round(trace[\"latency\"], 2),\n",
    "                **extract_observation_details(\n",
    "                    trace[\"observations\"],\n",
    "                    trace[\"id\"],\n",
    "                ),\n",
    "                \"status\": (\n",
    "                    \"failure\"\n",
    "                    if trace[\"output\"][\"status\"].lower() == \"failed\"\n",
    "                    else \"success\"\n",
    "                ),\n",
    "                \"tags\": trace[\"tags\"],\n",
    "                \"timestamp\": int(parser.isoparse(trace[\"timestamp\"]).timestamp()),\n",
    "            }\n",
    "            for trace in traces\n",
    "        ]\n",
    "        # print(rows)\n",
    "        # print(rows)\n",
    "        # Create and save DataFrame\n",
    "        df = pd.DataFrame(rows).sort_values(\"num_run\")\n",
    "\n",
    "        output_dir = os.path.join(processed_data_dir, f\"{simple_session_id}\")\n",
    "        if not os.path.exists(output_dir):\n",
    "            os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "        output_path = os.path.join(output_dir, f\"clean_{session_id_}.csv\")\n",
    "\n",
    "        print(output_path)\n",
    "        df.to_csv(output_path, index=False)\n",
    "        print(f\"Successfully saved CSV to: {output_path}\")\n",
    "\n",
    "    except FileNotFoundError as e:\n",
    "        print(\n",
    "            f\"FileNotFoundError: For session {session_id} not found. Looked for {trimmed_path}\\nError info: \\n{e}\\n\\nTraceback: {traceback.format_exc()}\"\n",
    "        )\n",
    "    except json.JSONDecodeError:\n",
    "        print(f\"Error: Invalid JSON format in input file for session {session_id}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing session {session_id}: {str(e)}\")\n",
    "\n",
    "\n",
    "# Example usage\n",
    "for session_id in session_id_list:\n",
    "    json_to_csv(session_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CSV Generation with Generation Counts\n",
    "\n",
    "This section creates CSV files similar to the langfuse_export section 3, but adds a column for the number of generation attempts used for each trace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing sessions: ['gemma3:27b_04fd_psg_batch', 'gemma3:27b_04fd_tpusg_batch']\n",
      "Looking for raw files in: /Users/hann/Projects/reference-benchmark-tinyml_llm/data_analysis/2025/08.16/raw_export\n",
      "Will save CSV files to: /Users/hann/Projects/reference-benchmark-tinyml_llm/data_analysis/2025/08.16/processed_data\n",
      "Processing session gemma3:27b_04fd_psg_batch, simple id gemma3:27b_04fd. Look for /Users/hann/Projects/reference-benchmark-tinyml_llm/data_analysis/2025/08.16/raw_export/trimmed_gemma3:27b_04fd_psg_batch.json\n",
      "/Users/hann/Projects/reference-benchmark-tinyml_llm/data_analysis/2025/08.16/processed_data/gemma3:27b_04fd/clean_gemma3:27b_04fd_psg_batch.csv\n",
      "Successfully saved CSV to: /Users/hann/Projects/reference-benchmark-tinyml_llm/data_analysis/2025/08.16/processed_data/gemma3:27b_04fd/clean_gemma3:27b_04fd_psg_batch.csv\n",
      "Processing session gemma3:27b_04fd_tpusg_batch, simple id gemma3:27b_04fd. Look for /Users/hann/Projects/reference-benchmark-tinyml_llm/data_analysis/2025/08.16/raw_export/trimmed_gemma3:27b_04fd_tpusg_batch.json\n",
      "/Users/hann/Projects/reference-benchmark-tinyml_llm/data_analysis/2025/08.16/processed_data/gemma3:27b_04fd/clean_gemma3:27b_04fd_tpusg_batch.csv\n",
      "Successfully saved CSV to: /Users/hann/Projects/reference-benchmark-tinyml_llm/data_analysis/2025/08.16/processed_data/gemma3:27b_04fd/clean_gemma3:27b_04fd_tpusg_batch.csv\n"
     ]
    }
   ],
   "source": [
    "import traceback\n",
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "from datetime import datetime\n",
    "from dateutil import parser\n",
    "\n",
    "# Setup paths - same as langfuse_export\n",
    "parent_dir = os.path.dirname(os.getcwd())\n",
    "raw_export_dir = os.path.join(parent_dir, \"raw_export\")\n",
    "processed_data_dir = os.path.join(parent_dir, \"processed_data\")\n",
    "\n",
    "\n",
    "# Get session id list from data directory\n",
    "session_id_list = []\n",
    "\n",
    "for root, dirs, files in os.walk(raw_export_dir):\n",
    "    for file in files:\n",
    "        file_path = os.path.join(root, file)\n",
    "        if \"trimmed_\" in file_path:\n",
    "            session_id = file_path.split('trimmed_')[1].rstrip('.json')\n",
    "            session_id_list.append(session_id)\n",
    "\n",
    "print(f\"Processing sessions: {session_id_list}\")\n",
    "print(f\"Looking for raw files in: {raw_export_dir}\")\n",
    "print(f\"Will save CSV files to: {processed_data_dir}\")\n",
    "\n",
    "\n",
    "def json_to_csv_weighted(session_id):\n",
    "    \"\"\"\n",
    "    Convert JSON trace data to CSV format with aggregated metrics.\n",
    "    Upgraded version that includes generation_count column.\n",
    "\n",
    "    Args:\n",
    "        session_id (str): Identifier for the session to process\n",
    "    \"\"\"\n",
    "\n",
    "    def extract_observation_details(observations, trace_id):\n",
    "        \"\"\"Extract and aggregate metrics from observations\"\"\"\n",
    "        metrics = {\n",
    "            \"status\": None,\n",
    "            \"latency\": 0,\n",
    "            \"total_tokens\": 0,\n",
    "            \"prompt_tokens\": 0,\n",
    "            \"completion_tokens\": 0,\n",
    "            \"total_cost\": 0,\n",
    "            \"input_cost\": 0,\n",
    "            \"output_cost\": 0,\n",
    "            \"parameters\": set(),\n",
    "            \"generation_count\": 0,  # New field for generation count\n",
    "        }\n",
    "\n",
    "        # Count generations and process GENERATION observations\n",
    "        for obs in (o for o in observations if o[\"type\"] == \"GENERATION\"):\n",
    "            metrics[\"generation_count\"] += 1\n",
    "            metrics[\"total_tokens\"] += obs[\"totalTokens\"]\n",
    "            metrics[\"prompt_tokens\"] += obs[\"promptTokens\"]\n",
    "            metrics[\"completion_tokens\"] += obs[\"completionTokens\"]\n",
    "            metrics[\"latency\"] += obs[\"latency\"]\n",
    "            for key, value in obs[\"modelParameters\"].items():\n",
    "                metrics[\"parameters\"].add(key + \":\" + value)\n",
    "\n",
    "            # Add costs if present\n",
    "            for cost_type in [\"Total\", \"Input\", \"Output\"]:\n",
    "                key = f\"calculated{cost_type}Cost\"\n",
    "                metric_key = cost_type.lower() + \"_cost\"\n",
    "                if obs.get(key) is not None:\n",
    "                    metrics[metric_key] += obs[key]\n",
    "                    \n",
    "        if len(metrics[\"parameters\"]) == 0:\n",
    "            metrics[\"parameters\"] = \"N/A\"\n",
    "            \n",
    "        # Process SPAN observations for status\n",
    "        status_indicators = [\n",
    "            obs[\"name\"]\n",
    "            for obs in observations\n",
    "            if obs[\"type\"] == \"SPAN\" and \"start_\" not in obs[\"name\"]\n",
    "        ]\n",
    "\n",
    "        #  if later than 2025-05-19, use status_signal_from_output\n",
    "        if datetime.now() > datetime(2025, 5, 19):\n",
    "            pass\n",
    "        else:\n",
    "            # Determine status\n",
    "            success_signals = sum(\"end_\" in name for name in status_indicators)\n",
    "            failure_signals = sum(\n",
    "                \"failure_signal\" in name for name in status_indicators\n",
    "            )\n",
    "\n",
    "            if success_signals + failure_signals > 1:\n",
    "                raise ValueError(\n",
    "                    f\"Multiple status indicators found in trace {trace_id}\"\n",
    "                )\n",
    "\n",
    "            metrics[\"status\"] = (\n",
    "                \"success\"\n",
    "                if success_signals\n",
    "                else \"failure\" if failure_signals else \"unknown\"\n",
    "            )\n",
    "\n",
    "        metrics[\"prompt_cost\"] = metrics.pop(\"input_cost\")\n",
    "        metrics[\"completion_cost\"] = metrics.pop(\"output_cost\")\n",
    "        metrics[\"latency\"] = round(metrics[\"latency\"] / 1000, 2)\n",
    "        return metrics\n",
    "\n",
    "    def cal_time(trace):\n",
    "        time_diff = datetime.fromisoformat(\n",
    "            trace[\"updatedAt\"].replace(\"Z\", \"+00:00\")\n",
    "        ) - datetime.fromisoformat(trace[\"createdAt\"].replace(\"Z\", \"+00:00\"))\n",
    "        seconds_diff = time_diff.total_seconds()\n",
    "        return seconds_diff\n",
    "\n",
    "    try:\n",
    "        if session_id.startswith(\"da0a\"):\n",
    "            session_id = \"phi4_\" + session_id\n",
    "        simple_session_id = session_id.rsplit(\"_\", 2)[0]\n",
    "\n",
    "        # Load JSON data\n",
    "        if \"tpsg\" in session_id:\n",
    "            session_id_ = session_id.replace(\"tpsg\", \"tpusg\")\n",
    "        else:\n",
    "            session_id_ = session_id\n",
    "        trimmed_path = os.path.join(raw_export_dir, f\"trimmed_{session_id_}.json\")\n",
    "        print(\n",
    "            f\"Processing session {session_id}, simple id {simple_session_id}. Look for {trimmed_path}\"\n",
    "        )\n",
    "        with open(trimmed_path, \"r\") as file:\n",
    "            traces = json.load(file)[\"data\"]\n",
    "\n",
    "        # Process traces\n",
    "        rows = [\n",
    "            {\n",
    "                \"num_run\": trace[\"metadata\"][\"num_run\"],\n",
    "                \"name\": trace[\"name\"],\n",
    "                \"trace_id\": trace[\"id\"],\n",
    "                \"batch_id\": trace[\"session_id\"],\n",
    "                # \"latency\": cal_time(trace),\n",
    "                # \"latency\": round(trace[\"latency\"], 2),\n",
    "                **extract_observation_details(\n",
    "                    trace[\"observations\"],\n",
    "                    trace[\"id\"],\n",
    "                ),\n",
    "                \"status\": (\n",
    "                    \"failure\"\n",
    "                    if trace[\"output\"][\"status\"].lower() == \"failed\"\n",
    "                    else \"success\"\n",
    "                ),\n",
    "                \"tags\": trace[\"tags\"],\n",
    "                \"timestamp\": int(parser.isoparse(trace[\"timestamp\"]).timestamp()),\n",
    "            }\n",
    "            for trace in traces\n",
    "        ]\n",
    "        \n",
    "        # Create and save DataFrame\n",
    "        df = pd.DataFrame(rows).sort_values(\"num_run\")\n",
    "\n",
    "        output_dir = os.path.join(processed_data_dir, f\"{simple_session_id}\")\n",
    "        if not os.path.exists(output_dir):\n",
    "            os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "        output_path = os.path.join(output_dir, f\"clean_{session_id_}.csv\")\n",
    "\n",
    "        print(output_path)\n",
    "        df.to_csv(output_path, index=False)\n",
    "        print(f\"Successfully saved CSV to: {output_path}\")\n",
    "\n",
    "    except FileNotFoundError as e:\n",
    "        print(\n",
    "            f\"FileNotFoundError: For session {session_id} not found. Looked for {trimmed_path}\\nError info: \\n{e}\\n\\nTraceback: {traceback.format_exc()}\"\n",
    "        )\n",
    "    except json.JSONDecodeError:\n",
    "        print(f\"Error: Invalid JSON format in input file for session {session_id}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing session {session_id}: {str(e)}\")\n",
    "\n",
    "\n",
    "\n",
    "# Example usage\n",
    "for session_id in session_id_list:\n",
    "    json_to_csv_weighted(session_id)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datasci2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

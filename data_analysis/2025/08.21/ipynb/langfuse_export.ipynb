{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setting up\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ref: https://langfuse.com/docs/query-traces\n",
    "import os\n",
    "import json\n",
    "from langfuse import Langfuse\n",
    "import json\n",
    "import os\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "LOCAL_HOST = True\n",
    "\n",
    "\"\"\"Define session_id\"\"\"\n",
    "# session_id=\"qwen2.5-coder_f4d4_dp_batch\"\n",
    "session_id_list = [\n",
    "    # \"qwen2.5-coder:32b_4e11_tpsg_batch\",\n",
    "    # \"qwen2.5-coder:32b_ae24_tpsg_batch\"\n",
    "    \"qwen2.5-coder:14b_5d09_tpusg_batch\",\n",
    "    \"qwen2.5-coder:14b_5d09_psg_batch\"\n",
    "]\n",
    "\n",
    "\n",
    "\"\"\"Define paths\"\"\"\n",
    " \n",
    "parent_dir = os.path.dirname(os.getcwd())\n",
    "\n",
    " \n",
    "# date = os.path.basename(parent_dir)\n",
    "tex_dir = os.path.join(parent_dir, \"tex\")\n",
    "processed_data_dir = os.path.join(parent_dir, \"processed_data\")\n",
    "raw_export_dir = os.path.join(parent_dir, \"raw_export\")\n",
    "ipynb_dir = os.path.join(parent_dir, \"ipynb\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Export raw data\n",
    "\n",
    "Langfuse added a limit of 20 API invocations per minute. https://langfuse.com/faq/all/api-limits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching traces for session qwen2.5-coder:14b_5d09_tpusg_batch...\n",
      "Fetching observation data for time-22-45-46-365947_chatcmpl-80f8846a-a64c-4e29-b2e3-e3f9ff3ed7ff...\n",
      "Fetching observation data for time-22-44-08-763336_chatcmpl-f5f40d7b-2725-4317-8e7e-66f699b245ba...\n",
      "Fetching observation data for time-22-44-31-171755_chatcmpl-71f309c1-d917-41c8-a648-b2aac3681be3...\n",
      "Fetching observation data for time-22-43-02-216539_chatcmpl-6cfe0ef8-13be-43d2-9d40-27b2a372bcd2...\n",
      "Fetching observation data for time-22-41-07-221834_chatcmpl-21826881-09fe-4573-9668-80811c68fc64...\n",
      "Fetching observation data for time-22-41-28-307068_chatcmpl-0dd12f66-0875-4304-b275-237a59bc1bf2...\n",
      "Fetching observation data for time-22-41-52-327985_chatcmpl-c88d6b1c-16f5-4d03-8aef-a0e90d606342...\n",
      "Fetching observation data for time-22-39-30-957977_chatcmpl-5f4ca8c1-a3cf-4746-9187-5e7059bd2b3e...\n",
      "Fetching observation data for time-22-39-51-934875_chatcmpl-0c003d9e-cf1c-4921-9548-82e972b982ae...\n",
      "Fetching observation data for time-22-38-17-731921_chatcmpl-10d1bb1c-4101-4b51-a585-34ffa3d66170...\n",
      "Fetching observation data for time-22-36-39-156147_chatcmpl-2b809069-321d-4314-8803-67582406a404...\n",
      "Fetching observation data for time-22-37-02-234351_chatcmpl-fd857d37-3c89-4da4-81ff-59b1e4edc86a...\n",
      "Fetching observation data for time-22-34-39-535178_chatcmpl-9d18d9ff-babe-4c09-af2d-b7a4b57b9818...\n",
      "Fetching observation data for time-22-34-58-608895_chatcmpl-4b9c1d2d-474d-4f2c-8ba7-b35b559687ad...\n",
      "Fetching observation data for time-22-35-26-042489_chatcmpl-1997e629-4f6d-4022-9513-827f7d781476...\n",
      "Fetching observation data for time-22-33-32-852271_chatcmpl-681196fa-0308-4d2a-b6ae-ee2424fc50f8...\n",
      "Fetching observation data for time-22-31-56-203458_chatcmpl-98b66e27-a89b-40d4-8c36-ca3cb0b6005a...\n",
      "Fetching observation data for time-22-32-17-753721_chatcmpl-09d2d1ad-6816-4f3d-a601-a27cb883b53c...\n",
      "Fetching observation data for time-22-30-45-467174_chatcmpl-becc8aa4-90c8-4dd5-af26-6608c844ce09...\n",
      "Fetching observation data for time-22-29-36-591177_chatcmpl-f5489b0c-c7bd-4c3a-8f9c-bb6bd27114a6...\n",
      "Fetching observation data for time-22-28-24-655439_chatcmpl-7c58904c-9370-4517-aac8-7a151601bc11...\n",
      "Fetching observation data for time-22-26-49-031309_chatcmpl-20fad46e-5fb1-4a1c-a13a-7133c73fbb1c...\n",
      "Fetching observation data for time-22-27-10-494002_chatcmpl-4f284deb-a72d-471a-9948-a6db56a84b21...\n",
      "Fetching observation data for time-22-25-14-152396_chatcmpl-8b8d6236-1766-413d-8694-b27b885533e5...\n",
      "Fetching observation data for time-22-25-34-902902_chatcmpl-b1732307-e874-4eee-a5d3-a87d79d1223a...\n",
      "Fetching observation data for time-22-24-01-587634_chatcmpl-3619b0c0-346f-42b9-99ec-17452bf32c87...\n",
      "Fetching observation data for time-22-22-53-845227_chatcmpl-a411586e-478e-404b-8dfc-4ab7482c7b0a...\n",
      "Fetching observation data for time-22-21-25-010167_chatcmpl-6659b786-a296-4866-a29b-6bceeec19b21...\n",
      "Fetching observation data for time-22-21-42-688910_chatcmpl-9f1d6a6d-d204-4cbd-ac4b-e6c5967267b2...\n",
      "Fetching observation data for time-22-19-53-021678_chatcmpl-c811f292-0c6b-4809-ad32-ae835b9089f9...\n",
      "Fetching observation data for time-22-20-14-254853_chatcmpl-c91a208b-fdb5-4eb0-a70a-f871055ee8cc...\n",
      "Fetching observation data for time-22-18-16-184992_chatcmpl-80926246-607a-490d-a3f1-75afc671b13b...\n",
      "Fetching observation data for time-22-18-37-620656_chatcmpl-13e790fc-4b55-4cc6-a5af-7227df43a556...\n",
      "Fetching observation data for time-22-17-02-240868_chatcmpl-4eabc228-2521-4922-9b3f-0b642e50f5ef...\n",
      "Fetching observation data for time-22-15-31-283724_chatcmpl-fd9a07f1-a59c-47bf-81ba-a951a832d88a...\n",
      "Fetching observation data for time-22-15-51-771960_chatcmpl-3934aef9-5d27-41d2-a212-545108a61b56...\n",
      "Fetching observation data for time-22-13-30-669718_chatcmpl-6b16f1bf-8569-4298-ae62-1b9be5b47cc0...\n",
      "Fetching observation data for time-22-13-52-119668_chatcmpl-28f6fabb-a7e3-4348-9369-9bc54b597885...\n",
      "Fetching observation data for time-22-14-17-762258_chatcmpl-e7d57934-ae93-44f1-9ae9-22a484b47f4d...\n",
      "Fetching observation data for time-22-10-36-973825_chatcmpl-ac1275ee-031e-4934-941c-f9e8b0c62dbb...\n",
      "Fetching observation data for time-22-10-59-155414_chatcmpl-acfc29c7-b102-4258-801b-56ab6c15d3fc...\n",
      "Fetching observation data for time-22-11-23-596485_chatcmpl-ef519506-15f1-444a-8a8f-287160379cd2...\n",
      "Fetching observation data for time-22-11-49-319930_chatcmpl-be2dd6ef-90be-4cb0-b306-c930e48ef653...\n",
      "Fetching observation data for time-22-12-13-973987_chatcmpl-795adb69-8054-4e3e-8d1b-61b0fcb45352...\n",
      "Fetching observation data for time-22-09-25-289762_chatcmpl-0758760f-ed07-4dc2-841c-e1b1c3a7f850...\n",
      "Fetching observation data for time-22-08-10-169362_chatcmpl-ccd485db-262f-410c-9bf4-358c412a0728...\n",
      "Fetching observation data for time-22-06-59-361344_chatcmpl-51ab9ea4-117f-4f60-85f7-eda4992d4b64...\n",
      "Fetching observation data for time-22-05-25-221863_chatcmpl-a37de7a3-483c-4108-812b-39925dd56fec...\n",
      "Fetching observation data for time-22-05-46-144558_chatcmpl-9fa4bc78-7e1b-43ab-8cb5-0f05701674ec...\n",
      "Fetching observation data for time-22-04-11-978341_chatcmpl-751ceae7-2986-4a6e-b392-ef33389aad3f...\n",
      "Fetching observation data for time-22-02-59-337143_chatcmpl-7fb9ef63-8afa-496d-bf47-e9349167d30d...\n",
      "Raw JSON saved to: /home/han/Projects/reference-benchmark-tinyml_llm/data_analysis/2025/08.21/raw_export/raw_qwen2.5-coder:14b_5d09_tpusg_batch.json\n",
      "Fetching traces for session qwen2.5-coder:14b_5d09_psg_batch...\n",
      "Fetching observation data for time-23-19-03-004032_chatcmpl-71fffb7c-17a3-49ea-8032-df091172ba44...\n",
      "Fetching observation data for time-23-19-12-266062_chatcmpl-fd91301e-422e-4c8a-a7f7-b97676215fbc...\n",
      "Fetching observation data for time-23-19-24-652617_chatcmpl-eb375f19-87e5-45ea-b7b6-ac5d75494e73...\n",
      "Fetching observation data for time-23-18-17-376712_chatcmpl-7ffc8729-6754-45e3-9dc9-7d4671453b70...\n",
      "Fetching observation data for time-23-18-31-968040_chatcmpl-5869325a-0009-4266-b2e2-98dfbd0bde5d...\n",
      "Fetching observation data for time-23-17-07-496170_chatcmpl-8044fbac-4c46-4a68-b731-c6cd8908edf0...\n",
      "Fetching observation data for time-23-17-17-983640_chatcmpl-77b21d6c-aa41-4f8b-946c-f643f6fe5425...\n",
      "Fetching observation data for time-23-17-30-171445_chatcmpl-2ad397e3-c4d6-49a4-acda-9d446dad5488...\n",
      "Fetching observation data for time-23-17-43-703416_chatcmpl-38e4aac7-210e-4d40-987e-a74efe0420d2...\n",
      "Fetching observation data for time-23-17-57-348915_chatcmpl-55141f3c-d3e8-4c2d-9e1a-690b67f80125...\n",
      "Fetching observation data for af70fc98-3736-4c5c-b2dc-a57813ffeb5f...\n",
      "Fetching observation data for time-23-15-54-821703_chatcmpl-a94d7ee8-5231-426c-bd62-0c71d3f49118...\n",
      "Fetching observation data for time-23-16-05-783570_chatcmpl-5331dac8-be78-435b-9ba0-dc58e4192075...\n",
      "Fetching observation data for time-23-16-18-860798_chatcmpl-0fb14a98-66e6-495f-826d-b035602a7a7e...\n",
      "Fetching observation data for time-23-16-34-324579_chatcmpl-606cd584-ced6-47b6-8927-f0cf8cc0dbaf...\n",
      "Fetching observation data for time-23-16-46-983919_chatcmpl-e09184e2-a513-4e47-b496-14224f905544...\n",
      "Fetching observation data for 22cd5fc1-3bc3-4282-81fa-1ea86d6171d8...\n",
      "Fetching observation data for time-23-15-17-154090_chatcmpl-169448f7-f3e8-4ea8-9e22-6ee207b65454...\n",
      "Fetching observation data for time-23-15-29-672750_chatcmpl-5db07252-fb79-4445-b869-544be137cb1a...\n",
      "Fetching observation data for time-23-13-58-518955_chatcmpl-6841cbd2-a067-465b-96ba-ade558f43234...\n",
      "Fetching observation data for time-23-14-09-990436_chatcmpl-6208a92f-09b4-4971-af74-031ba536553d...\n",
      "Fetching observation data for time-23-14-25-951491_chatcmpl-9dc9f557-30df-41bb-9339-b28ec675be4f...\n",
      "Fetching observation data for time-23-14-38-928606_chatcmpl-90a2b75d-361e-4b4c-87ef-de7dca703bd0...\n",
      "Fetching observation data for time-23-14-54-708132_chatcmpl-942e1f47-3703-4e39-90bd-44942c8626e5...\n",
      "Fetching observation data for 8248623c-126f-4c6a-9529-53863fc51186...\n",
      "Fetching observation data for time-23-12-47-777479_chatcmpl-62a9fdb8-23e1-4cc5-b074-a0fc3b0c0cb2...\n",
      "Fetching observation data for time-23-12-58-104643_chatcmpl-e7785448-14ea-45f5-a6ab-0a5e7817239b...\n",
      "Fetching observation data for time-23-13-12-210639_chatcmpl-241e6249-e6c2-4150-bd81-08b934f1aacc...\n",
      "Fetching observation data for time-23-13-24-928288_chatcmpl-307255c0-d692-4caf-81ed-f9e88441a3e1...\n",
      "Fetching observation data for time-23-13-36-758409_chatcmpl-73ea861a-5e39-4ca6-ac70-2bb27f7273d5...\n",
      "Fetching observation data for edce5cc9-8720-4e1c-9496-9be2e99e5044...\n",
      "Fetching observation data for time-23-11-30-005065_chatcmpl-ae52c079-770c-4d67-8c30-f8e10c905e2d...\n",
      "Fetching observation data for time-23-11-40-710112_chatcmpl-05f76e9d-b4b7-45f4-a6df-0162eb6882fb...\n",
      "Fetching observation data for time-23-11-55-058496_chatcmpl-ace79a17-2013-4f3b-a752-0106a953228c...\n",
      "Fetching observation data for time-23-12-08-357784_chatcmpl-c03e88e2-1c99-49f0-9c35-1f70372508c1...\n",
      "Fetching observation data for time-23-12-24-127924_chatcmpl-449dfe68-730f-43a2-bd50-b3958239503f...\n",
      "Fetching observation data for e6e0d437-ad0b-4241-9527-1d3e7118e639...\n",
      "Fetching observation data for time-23-10-28-268698_chatcmpl-b1f75f04-1090-4309-bed7-3eaa4e609a1d...\n",
      "Fetching observation data for time-23-10-39-874917_chatcmpl-f0895e6c-5011-4912-a47a-0932d545b757...\n",
      "Fetching observation data for time-23-09-37-059321_chatcmpl-d1212ff5-3df5-469d-8bb4-1babdc4226ff...\n",
      "Fetching observation data for time-23-08-24-491268_chatcmpl-491d0bf0-ecf8-4964-9785-103ebc3345fe...\n",
      "Fetching observation data for time-23-08-35-410062_chatcmpl-05639e13-fc50-4a80-9511-0031451c7219...\n",
      "Fetching observation data for time-23-08-49-133766_chatcmpl-75ab2838-6960-4397-9a70-50e3bfdbe187...\n",
      "Fetching observation data for time-23-09-02-146454_chatcmpl-43a0b75c-7ee2-4ede-8be4-062d4a9195e7...\n",
      "Fetching observation data for time-23-09-17-356498_chatcmpl-cd889e20-6ee0-44bd-a621-a88711693c61...\n",
      "Fetching observation data for 589b7176-7f81-4cf0-825a-f1a7691421cd...\n",
      "Fetching observation data for time-23-07-04-921024_chatcmpl-ccdfc39b-5aa0-4583-ba6e-e2c155704465...\n",
      "Fetching observation data for time-23-07-15-496954_chatcmpl-f72fb929-488f-41ae-aa58-b0506cca676e...\n",
      "Fetching observation data for time-23-07-28-029158_chatcmpl-308b3fca-c3cb-4f96-a423-59321811f929...\n",
      "Fetching observation data for time-23-07-42-991811_chatcmpl-d4e00897-5b64-43b6-9625-b1298ffae100...\n",
      "Fetching observation data for time-23-08-00-580834_chatcmpl-1b17ae8d-eefb-4bff-a841-50dbe1c6eff9...\n",
      "Fetching observation data for dc868c53-7469-4f25-b90e-450f081e4f02...\n",
      "Fetching observation data for time-23-05-33-279313_chatcmpl-18807c25-f5d4-47c1-a661-5eaa550bc524...\n",
      "Fetching observation data for time-23-05-42-949051_chatcmpl-b56447b7-5bdf-4877-b7f3-b961b6ff3549...\n",
      "Fetching observation data for time-23-05-58-428987_chatcmpl-86939f98-d69c-4c2c-b09b-e31377deaa07...\n",
      "Fetching observation data for time-23-06-15-852707_chatcmpl-1a8577a9-80a4-45db-bf1a-cf5cfd7fc7e7...\n",
      "Fetching observation data for time-23-06-44-258700_chatcmpl-a15d7d71-8fb0-4ee3-991e-96416addb8ea...\n",
      "Fetching observation data for b079fdf1-ba48-4507-b21a-03172af82595...\n",
      "Fetching observation data for time-23-04-20-374923_chatcmpl-962047c4-a5b0-4312-95ff-0d11fb6392e7...\n",
      "Fetching observation data for time-23-04-31-535587_chatcmpl-d609da17-fd26-4169-a1d6-4578b7820367...\n",
      "Fetching observation data for time-23-04-47-254455_chatcmpl-df21a019-1af0-464d-95a9-930caeb74704...\n",
      "Fetching observation data for time-23-05-04-003354_chatcmpl-38d36ce4-7dd8-4e1b-852c-52388070e18b...\n",
      "Fetching observation data for time-23-03-53-781900_chatcmpl-63668da2-73ae-4d43-85a4-517feed2b315...\n",
      "Fetching observation data for time-23-02-32-132725_chatcmpl-4f5701b6-de86-4313-b5e0-68f63af246a3...\n",
      "Fetching observation data for time-23-02-43-215440_chatcmpl-7111b450-3d35-4a9a-bfb2-1f299cbbedf8...\n",
      "Fetching observation data for time-23-02-57-089115_chatcmpl-e75b31a1-6fa6-429a-8563-072f698bcc1f...\n",
      "Fetching observation data for time-23-03-20-487334_chatcmpl-b6ba0968-fcfa-4e97-8f37-3535a0d2a235...\n",
      "Fetching observation data for time-23-03-33-829238_chatcmpl-aec8c851-2aa5-4526-aedb-0ac0a843b4d3...\n",
      "Fetching observation data for b1287a69-981c-4310-ac20-b26228387181...\n",
      "Fetching observation data for time-23-01-43-471236_chatcmpl-e7f0801d-2e1f-4874-aad1-a4e4402c12bb...\n",
      "Fetching observation data for time-23-00-22-722770_chatcmpl-5e04703b-f2ce-43cd-a738-e4040579dfb0...\n",
      "Fetching observation data for time-23-00-33-930557_chatcmpl-52c81ae6-f1a4-4b74-9e08-28fcd679b406...\n",
      "Fetching observation data for time-23-00-49-706641_chatcmpl-56323530-1240-4c64-aa99-c7ea0fe65a1b...\n",
      "Fetching observation data for time-23-01-08-778997_chatcmpl-f3df86d3-5e80-45a8-883d-26dd00dc3a6b...\n",
      "Fetching observation data for time-23-01-24-813859_chatcmpl-bc99bbdb-3933-4124-8433-0078550920d5...\n",
      "Fetching observation data for 142b893e-212d-4159-9513-8e28dfd69137...\n",
      "Fetching observation data for time-22-59-18-084917_chatcmpl-87d424a7-f5d2-418f-9201-cd09fb2386a3...\n",
      "Fetching observation data for time-22-59-29-872482_chatcmpl-7584cef1-7659-4555-be9c-19ae1494e10d...\n",
      "Fetching observation data for time-22-58-10-270927_chatcmpl-d865f318-3704-4532-9a14-8d142b769a5d...\n",
      "Fetching observation data for time-22-58-21-174916_chatcmpl-2d1c2e87-d610-4ca5-993e-1032f951372e...\n",
      "Fetching observation data for time-22-58-34-072067_chatcmpl-6e4e65e4-c0a4-405d-8d43-686bf63cd004...\n",
      "Fetching observation data for time-22-58-46-580288_chatcmpl-0dbb66d6-a477-49ca-a70e-2f8528e72357...\n",
      "Fetching observation data for time-22-58-58-948743_chatcmpl-08ec7d41-c1b0-42a2-90d9-a7e4d24e86e5...\n",
      "Fetching observation data for 4eb22d52-c2bc-4547-bc0f-33305081c0fb...\n",
      "Fetching observation data for time-22-56-51-731311_chatcmpl-cc3b841c-9972-485c-b2ca-de0cb16b7ade...\n",
      "Fetching observation data for time-22-57-01-443885_chatcmpl-7b4c703e-3f00-45e6-9953-aa35f4461248...\n",
      "Fetching observation data for time-22-57-13-015918_chatcmpl-3f583d56-39a2-44a4-96b0-539451c5a71e...\n",
      "Fetching observation data for time-22-57-29-532225_chatcmpl-c0714d1a-805b-4933-a3c5-a9ac183eb3d4...\n",
      "Fetching observation data for time-22-57-45-455565_chatcmpl-fc648b00-ac17-4039-9137-ca0e3611747a...\n",
      "Fetching observation data for cefb1f05-c821-4200-a8fd-f0ba15a57902...\n",
      "Fetching observation data for time-22-55-35-230980_chatcmpl-aca65193-0937-426b-b5af-9ec6c618ba7f...\n",
      "Fetching observation data for time-22-55-46-424680_chatcmpl-58aa77c4-eceb-4e84-b678-c948c433096a...\n",
      "Fetching observation data for time-22-56-00-724594_chatcmpl-1824b38d-f31a-4f45-bbae-190f74ac0802...\n",
      "Fetching observation data for time-22-54-12-716945_chatcmpl-07c1b23b-bae9-4dcc-adf4-8e7481c2266a...\n",
      "Fetching observation data for time-22-54-24-820887_chatcmpl-6508d448-19f5-4f07-895d-22566c268633...\n",
      "Fetching observation data for time-22-54-39-964672_chatcmpl-40f0e5d2-a2b0-42a9-a240-6efdb252b3a2...\n",
      "Fetching observation data for time-22-54-55-592595_chatcmpl-8832f4a2-ef75-4a66-9b6d-ddf15a2011ef...\n",
      "Fetching observation data for time-22-55-12-868544_chatcmpl-9888e7f9-d74f-4cdf-8f46-15cec6b2466a...\n",
      "Fetching observation data for f6f850c0-164e-4914-9b77-3d8b87651b66...\n",
      "Fetching observation data for time-22-53-01-158873_chatcmpl-63f97484-10b0-4ff6-bf3a-cbaa99f8be9e...\n",
      "Fetching observation data for time-22-53-11-478871_chatcmpl-c97e5dd9-3dfb-45c3-ad36-112598030046...\n",
      "Fetching observation data for time-22-53-23-431735_chatcmpl-434df1cc-e1f7-4a25-a0fa-b0d789fcea23...\n",
      "Fetching observation data for time-22-51-59-625286_chatcmpl-5f4c3cac-f636-471f-a09d-09a723450e5c...\n",
      "Fetching observation data for time-22-52-10-126100_chatcmpl-e103cdf5-45fb-4873-bf2e-98a828dd0e51...\n",
      "Fetching observation data for time-22-51-05-072629_chatcmpl-aeea2b6e-a406-4f87-ae9d-106056dbacc7...\n",
      "Fetching observation data for time-22-51-15-884535_chatcmpl-0616b7ec-32f2-4942-9e23-43b9e0483498...\n",
      "Fetching observation data for time-22-51-32-559498_chatcmpl-4316a3bb-3061-4f90-bd11-583091e69424...\n",
      "Fetching observation data for time-22-50-03-561394_chatcmpl-586291ea-928b-40be-8ee3-029af27fabab...\n",
      "Fetching observation data for time-22-50-35-405695_chatcmpl-4e19f073-a919-441c-ac3d-9832b1fc8c8e...\n",
      "Fetching observation data for time-22-48-53-023985_chatcmpl-70f802fa-8b5d-41c6-99d2-0187ed3e1253...\n",
      "Fetching observation data for time-22-49-03-098498_chatcmpl-20875bfa-da05-44e2-ae94-48ab027d3498...\n",
      "Fetching observation data for time-22-49-14-309133_chatcmpl-a680dae3-ae39-480e-a910-8f1e90d211e8...\n",
      "Fetching observation data for time-22-47-43-445949_chatcmpl-a8cf1bfe-b97f-4faa-8575-ee91d2a91583...\n",
      "Fetching observation data for time-22-47-53-567062_chatcmpl-42eaa3af-eccf-44a2-ae6f-8688fab4c54c...\n",
      "Fetching observation data for time-22-48-06-008492_chatcmpl-c94162bb-96d8-4f9e-a7de-1ddf7215c594...\n",
      "Fetching observation data for time-22-48-19-872615_chatcmpl-9c43344e-b58c-4f73-b8fe-6f411fa2d263...\n",
      "Fetching observation data for time-22-48-31-567299_chatcmpl-3cc70f4c-39b1-47dc-b28d-31fc124a0813...\n",
      "Fetching observation data for 8feb6f66-26d2-4e9f-b438-5300cb9bbe03...\n",
      "Fetching observation data for time-22-46-52-909544_chatcmpl-a712f61f-0a20-4203-90d1-2d6ecb1e62b5...\n",
      "Raw JSON saved to: /home/han/Projects/reference-benchmark-tinyml_llm/data_analysis/2025/08.21/raw_export/raw_qwen2.5-coder:14b_5d09_psg_batch.json\n"
     ]
    }
   ],
   "source": [
    "# ALTERNATIVE TO 2.\n",
    "import os\n",
    "import json\n",
    "from time import sleep\n",
    "from langfuse import Langfuse\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "\n",
    "# LANGFUSE_SERVICE_PUBLIC_KEY = \"pk-lf-559a2c0f-ee29-4c32-944c-bf73b5f0ce28\"\n",
    "# LANGFUSE_SERVICE_SECRET_KEY = \"sk-lf-75f8bf7f-a5db-4756-b0dd-d758a2a292c8\"\n",
    "# LANGFUSE_SERVICE_HOST = \"https://langfuse.hann.fi\"\n",
    "\n",
    "\n",
    "if LOCAL_HOST:\n",
    "    langfuse = Langfuse(\n",
    "        secret_key=\"sk-lf-75f8bf7f-a5db-4756-b0dd-d758a2a292c8\",\n",
    "        public_key=\"pk-lf-559a2c0f-ee29-4c32-944c-bf73b5f0ce28\",\n",
    "        host=\"https://langfuse.hann.fi\",\n",
    "    )\n",
    "else:\n",
    "    langfuse = Langfuse(\n",
    "        secret_key=LANGFUSE_SERVICE_SECRET_KEY,\n",
    "        public_key=LANGFUSE_SERVICE_PUBLIC_KEY,\n",
    "        host=LANGFUSE_SERVICE_HOST,\n",
    "    )\n",
    "\n",
    "API_invok_count = 0\n",
    "query_range_num_run = {\"start\": 0, \"end\": 1}\n",
    "\n",
    "\n",
    "class CustomJSONEncoder(json.JSONEncoder):\n",
    "    def __init__(self, *args, LOCAL_HOST=True, **kwargs):\n",
    "        self.LOCAL_HOST = LOCAL_HOST\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "    def default(self, obj):\n",
    "        if isinstance(obj, datetime):\n",
    "            return obj.isoformat()\n",
    "        if hasattr(obj, \"__dict__\"):\n",
    "            data = obj.__dict__.copy()\n",
    "            if \"observations\" in data:\n",
    "                data[\"observations\"] = [\n",
    "                    fetch_observation_data(obs, self.LOCAL_HOST)\n",
    "                    for obs in data[\"observations\"]\n",
    "                ]\n",
    "\n",
    "            return data\n",
    "        return super().default(obj)\n",
    "\n",
    "\n",
    "def fetch_observation_data(observation_id, LOCAL_HOST):\n",
    "    \"\"\"\n",
    "    Fetches observation data from Langfuse and returns its dictionary representation.\n",
    "    \"\"\"\n",
    "    print(f\"Fetching observation data for {observation_id}...\")\n",
    "    global API_invok_count\n",
    "    if API_invok_count >= 0 and not LOCAL_HOST:\n",
    "        print(\"Waiting for 3 seconds to fetch observation data...\")\n",
    "        for _ in tqdm(range(3), desc=\"Progress\", unit=\"s\"):\n",
    "            sleep(1)\n",
    "        API_invok_count = 0\n",
    "\n",
    "    observation_response = langfuse.fetch_observation(observation_id)\n",
    "    API_invok_count += 1\n",
    "\n",
    "    return observation_response.data.dict()\n",
    "\n",
    "\n",
    "def fetch_and_save_complete_data(session_id_list, raw_export_dir, LOCAL_HOST):\n",
    "    \"\"\"\n",
    "    Fetches complete trace data for each session ID and saves it to JSON files.\n",
    "\n",
    "    Parameters:\n",
    "        session_id_list (list): List of session IDs to process.\n",
    "        raw_export_dir (str): Directory path to save raw JSON files.\n",
    "    \"\"\"\n",
    "\n",
    "    def save_complete_data(session_id):\n",
    "        global API_invok_count\n",
    "        if API_invok_count >= 0 and not LOCAL_HOST:\n",
    "            print(\"Waiting for 4 seconds to fetch traces...\")\n",
    "            for _ in tqdm(range(4), desc=\"Progress\", unit=\"s\"):\n",
    "                sleep(1)\n",
    "            API_invok_count = 0\n",
    "\n",
    "        fetch_traces_response = langfuse.fetch_traces(session_id=session_id)\n",
    "        API_invok_count += 1\n",
    "\n",
    "        print(f\"Fetching traces for session {session_id}...\")\n",
    "        # Create directories if they don't exist\n",
    "        os.makedirs(raw_export_dir, exist_ok=True)\n",
    "\n",
    "        # Save complete data to JSON file\n",
    "        # if session_id.startswith(\"da0a\"):\n",
    "        #     session_id = \"phi4_\" + session_id\n",
    "        if \"tpsg\" in session_id:\n",
    "            session_id_ = session_id.replace(\"tpsg\", \"tpusg\")\n",
    "        else:\n",
    "            session_id_ = session_id\n",
    "            \n",
    "        raw_path = os.path.join(raw_export_dir, f\"raw_{session_id_}.json\")\n",
    "        with open(raw_path, \"w\") as f:\n",
    "            json.dump(fetch_traces_response, f, cls=CustomJSONEncoder, indent=2)\n",
    "\n",
    "        print(f\"Raw JSON saved to: {raw_path}\")\n",
    "\n",
    "    for session_id in session_id_list:\n",
    "        save_complete_data(session_id)\n",
    "\n",
    "\n",
    "fetch_and_save_complete_data(session_id_list, raw_export_dir, LOCAL_HOST)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Trim data\n",
    "\n",
    "Here also intercept the runs with fatal errors that need to be excluded from the analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully processed and saved trimmed data for session qwen2.5-coder:14b_5d09_tpusg_batch\n",
      "SPAN error_7c_psg_failure_signal_py_sketch_generator: Failed. Last error: Max retries reached with failure. Last error from execution: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250819231810_psg_qwen2.5-coder:14b/tmp_20250819231810_psg_qwen2.5-coder:14b.py\", line 56, in <module>\n",
      "    if scores[0][i] > confidence_threshold:\n",
      "ValueError: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()\n",
      "\n",
      "SPAN error_e2_psg_failure_signal_py_sketch_generator: Failed. Last error: Max retries reached with failure. Last error from execution: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250819231700_psg_qwen2.5-coder:14b/tmp_20250819231700_psg_qwen2.5-coder:14b.py\", line 57, in <module>\n",
      "    label = labels[int(classes[i])]\n",
      "IndexError: invalid index to scalar variable.\n",
      "\n",
      "SPAN error_dc_psg_failure_signal_py_sketch_generator: Failed. Last error: Max retries reached with failure. Last error from execution: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "OpenCV: FFMPEG: tag 0x44495658/'XVID' is not supported with codec id 12 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n",
      "OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250819231510_psg_qwen2.5-coder:14b/tmp_20250819231510_psg_qwen2.5-coder:14b.py\", line 63, in <module>\n",
      "    class_id = int(classes[i])\n",
      "IndexError: invalid index to scalar variable.\n",
      "\n",
      "SPAN error_21_psg_failure_signal_py_sketch_generator: Failed. Last error: Max retries reached with failure. Last error from execution: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250819231351_psg_qwen2.5-coder:14b/tmp_20250819231351_psg_qwen2.5-coder:14b.py\", line 26, in <module>\n",
      "    model_height, model_width  = \"qwen2.5-coder:14b\"\n",
      "ValueError: too many values to unpack (expected 2)\n",
      "\n",
      "SPAN error_27_psg_failure_signal_py_sketch_generator: Failed. Last error: Max retries reached with failure. Last error from execution: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250819231241_psg_qwen2.5-coder:14b/tmp_20250819231241_psg_qwen2.5-coder:14b.py\", line 38, in <module>\n",
      "    interpreter.set_tensor(input_details[0]['index'], np.squeeze(input_blob).astype(np.uint8))\n",
      "  File \"/home/wuguangh/.conda/envs/tinyml/lib/python3.10/site-packages/tflite_runtime/interpreter.py\", line 720, in set_tensor\n",
      "    self._interpreter.SetTensor(tensor_index, value)\n",
      "ValueError: Cannot set tensor: Dimension mismatch. Got 3 but expected 4 for input 175.\n",
      "\n",
      "SPAN error_18_psg_failure_signal_py_sketch_generator: Failed. Last error: Max retries reached with failure. Last error from execution: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250819230930_psg_qwen2.5-coder:14b/tmp_20250819230930_psg_qwen2.5-coder:14b.py\", line 46, in <module>\n",
      "    boxes = interpreter.get_tensor(output_details['detection_boxes'][0])\n",
      "TypeError: list indices must be integers or slices, not str\n",
      "\n",
      "SPAN error_2e_psg_failure_signal_py_sketch_generator: Failed. Last error: Max retries reached with failure. Last error from execution: 2025-08-19 23:08:15.294623: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-08-19 23:08:15.299202: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-08-19 23:08:15.313120: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-08-19 23:08:15.334410: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-08-19 23:08:15.340854: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-08-19 23:08:15.356680: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-08-19 23:08:16.197191: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250819230814_psg_qwen2.5-coder:14b/tmp_20250819230814_psg_qwen2.5-coder:14b.py\", line 48, in <module>\n",
      "    boxes = interpreter.get_tensor(output_details['detection_boxes'][0])[0]\n",
      "TypeError: list indices must be integers or slices, not str\n",
      "\n",
      "SPAN error_bd_psg_failure_signal_py_sketch_generator: Failed. Last error: Max retries reached with failure. Last error from execution: 2025-08-19 23:06:56.259874: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-08-19 23:06:56.264629: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-08-19 23:06:56.278754: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-08-19 23:06:56.299751: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-08-19 23:06:56.310668: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-08-19 23:06:56.331255: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-08-19 23:06:57.177848: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "qt.qpa.xcb: could not connect to display \n",
      "qt.qpa.plugin: Could not load the Qt platform plugin \"xcb\" in \"/home/wuguangh/.conda/envs/tinyml/lib/python3.10/site-packages/cv2/qt/plugins\" even though it was found.\n",
      "This application failed to start because no Qt platform plugin could be initialized. Reinstalling the application may fix this problem.\n",
      "\n",
      "Available platform plugins are: xcb.\n",
      "\n",
      "\n",
      "SPAN error_a5_psg_failure_signal_py_sketch_generator: Failed. Last error: Max retries reached with failure. Last error from execution: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250819230346_psg_qwen2.5-coder:14b/tmp_20250819230346_psg_qwen2.5-coder:14b.py\", line 23, in <module>\n",
      "    cap = cv2.VideoCapture(input_path)\n",
      "NameError: name 'cv2' is not defined\n",
      "\n",
      "SPAN error_8b_psg_failure_signal_py_sketch_generator: Failed. Last error: Max retries reached with failure. Last error from execution:   File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250819230136_psg_qwen2.5-coder:14b/tmp_20250819230136_psg_qwen2.5-coder:14b.py\", line 73\n",
      "    <REPORT THE FIX OF THE LAST ERROR>\n",
      "    ^\n",
      "SyntaxError: invalid syntax\n",
      "\n",
      "SPAN error_96_psg_failure_signal_py_sketch_generator: Failed. Last error: Max retries reached with failure. Last error from execution: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250819225911_psg_qwen2.5-coder:14b/tmp_20250819225911_psg_qwen2.5-coder:14b.py\", line 45, in <module>\n",
      "    interpreter.set_tensor(input_details[0]['index'], input_data)\n",
      "  File \"/home/wuguangh/.conda/envs/tinyml/lib/python3.10/site-packages/tflite_runtime/interpreter.py\", line 720, in set_tensor\n",
      "    self._interpreter.SetTensor(tensor_index, value)\n",
      "ValueError: Cannot set tensor: Got value of type FLOAT32 but expected type UINT8 for input 175, name: normalized_input_image_tensor \n",
      "\n",
      "SPAN error_2d_psg_failure_signal_py_sketch_generator: Failed. Last error: Max retries reached with failure. Last error from execution: 2025-08-19 22:58:01.461055: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-08-19 22:58:01.466058: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-08-19 22:58:01.480163: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-08-19 22:58:01.501655: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-08-19 22:58:01.507858: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-08-19 22:58:01.523665: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-08-19 22:58:02.358552: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250819225801_psg_qwen2.5-coder:14b/tmp_20250819225801_psg_qwen2.5-coder:14b.py\", line 45, in <module>\n",
      "    interpreter.set_tensor(input_details[0]['index'], [input_tensor])\n",
      "  File \"/home/wuguangh/.conda/envs/tinyml/lib/python3.10/site-packages/tensorflow/lite/python/interpreter.py\", line 732, in set_tensor\n",
      "    self._interpreter.SetTensor(tensor_index, value)\n",
      "ValueError: Cannot set tensor: Dimension mismatch. Got 3 but expected 300 for dimension 1 of input 175.\n",
      "\n",
      "SPAN error_db_psg_failure_signal_py_sketch_generator: Failed. Last error: Max retries reached with failure. Last error from execution: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250819225529_psg_qwen2.5-coder:14b/tmp_20250819225529_psg_qwen2.5-coder:14b.py\", line 70, in <module>\n",
      "    if scores[i] > confidence_threshold:\n",
      "ValueError: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()\n",
      "\n",
      "SPAN error_bf_psg_failure_signal_py_sketch_generator: Failed. Last error: Max retries reached with failure. Last error from execution: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250819224846_psg_qwen2.5-coder:14b/tmp_20250819224846_psg_qwen2.5-coder:14b.py\", line 38, in <module>\n",
      "    interpreter.set_tensor(input_details[0]['index'], input_data)\n",
      "  File \"/home/wuguangh/.conda/envs/tinyml/lib/python3.10/site-packages/tflite_runtime/interpreter.py\", line 720, in set_tensor\n",
      "    self._interpreter.SetTensor(tensor_index, value)\n",
      "ValueError: Cannot set tensor: Got value of type FLOAT32 but expected type UINT8 for input 175, name: normalized_input_image_tensor \n",
      "\n",
      "Successfully processed and saved trimmed data for session qwen2.5-coder:14b_5d09_psg_batch\n",
      "Total 0 traces skipped. They are []\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "skipped_traces = []\n",
    "\n",
    "\n",
    "def process_existing_observation(observation):\n",
    "    \"\"\"\n",
    "    Processes an existing observation dictionary by trimming unwanted keys.\n",
    "    \"\"\"\n",
    "    unwanted_observation_keys = [\n",
    "        \"completionStartTime\",\n",
    "        \"metadata\",\n",
    "        \"timeToFirstToken\",\n",
    "        \"createdAt\",\n",
    "        \"usageDetails\",\n",
    "        \"usage\",\n",
    "        \"projectId\",\n",
    "        \"unit\",\n",
    "        \"updatedAt\",\n",
    "        \"version\",\n",
    "        \"parentObservationId\",\n",
    "        \"promptId\",\n",
    "        \"promptName\",\n",
    "        \"promptVersion\",\n",
    "        \"modelId\",\n",
    "        \"inputPrice\",\n",
    "        \"outputPrice\",\n",
    "        \"totalPrice\",\n",
    "        # \"modelParameters\",\n",
    "        \"input\",\n",
    "        \"output\",\n",
    "    ]\n",
    "\n",
    "    # If observation is a dictionary containing observation data\n",
    "    if isinstance(observation, dict):\n",
    "        trimmed_observation = {\n",
    "            k: v for k, v in observation.items() if k not in unwanted_observation_keys\n",
    "        }\n",
    "        return trimmed_observation\n",
    "    return observation\n",
    "\n",
    "\n",
    "def trim_data(data):\n",
    "    \"\"\"\n",
    "    Recursively trims the data structure.\n",
    "    \"\"\"\n",
    "\n",
    "    if isinstance(data, dict):\n",
    "        # Process the current dictionary\n",
    "        unwanted_trace_keys = [\n",
    "            \"release\",\n",
    "            \"version\",\n",
    "            \"user_id\",\n",
    "            \"public\",\n",
    "            \"html_path\",\n",
    "            \"scores\",\n",
    "            \"bookmarked\",\n",
    "            \"projectId\",\n",
    "            \"externalId\",\n",
    "            \"page\",\n",
    "            \"limit\",\n",
    "            \"total_pages\",\n",
    "        ]\n",
    "\n",
    "        # If this is a trace that contains observations, check for fatal errors\n",
    "        if \"observations\" in data:\n",
    "            # Check for SPAN observations with fatal errors before processing\n",
    "            skip_trace = False\n",
    "            for obs in data[\"observations\"]:\n",
    "                if isinstance(obs, dict) and obs.get(\"name\").startswith(\"error\"):\n",
    "                    status_message = obs.get(\"statusMessage\", \"\")\n",
    "                    ob_name = obs.get(\"name\")\n",
    "                    print(f\"SPAN {ob_name}: {status_message}\")\n",
    "\n",
    "                    if \"Fatal error\" in status_message:\n",
    "                        print(f\"Found Fatal error in SPAN observation, skipping trace\")\n",
    "                        skip_trace = True\n",
    "                        skipped_traces.append(data[\"name\"])\n",
    "                        break\n",
    "\n",
    "            if skip_trace:\n",
    "                return None  # Signal to skip this trace\n",
    "\n",
    "        # Create a new dictionary with wanted keys and recursively process values\n",
    "        trimmed_data = {}\n",
    "        for key, value in data.items():\n",
    "            if key not in unwanted_trace_keys:\n",
    "                if key == \"observations\":\n",
    "                    # Special handling for observations\n",
    "                    trimmed_data[key] = [\n",
    "                        process_existing_observation(obs) for obs in value\n",
    "                    ]\n",
    "                elif isinstance(value, (dict, list)):\n",
    "                    # Recursively process nested structures\n",
    "                    trimmed_data[key] = trim_data(value)\n",
    "                else:\n",
    "                    trimmed_data[key] = value\n",
    "\n",
    "        return trimmed_data\n",
    "\n",
    "    elif isinstance(data, list):\n",
    "        # Recursively process each item in the list\n",
    "        processed_items = []\n",
    "        for item in data:\n",
    "            processed_item = trim_data(item)\n",
    "            if processed_item is not None:  # Only add items that weren't filtered out\n",
    "                processed_items.append(processed_item)\n",
    "        return processed_items\n",
    "\n",
    "    else:\n",
    "        # Return non-dict, non-list values as is\n",
    "        return data\n",
    "\n",
    "\n",
    "def read_and_trim_data(session_id_list, raw_export_dir, trimmed_export_dir):\n",
    "    \"\"\"\n",
    "    Reads complete data from JSON files, trims the data, and saves the trimmed data to new JSON files.\n",
    "    \"\"\"\n",
    "    os.makedirs(trimmed_export_dir, exist_ok=True)\n",
    "\n",
    "    for session_id in session_id_list:\n",
    "        try:\n",
    "            if session_id.startswith(\"da0a\"):\n",
    "                session_id = \"phi4_\" + session_id\n",
    "            # Read raw data\n",
    "            if \"tpsg\" in session_id:\n",
    "                session_id_ = session_id.replace(\"tpsg\", \"tpusg\")\n",
    "            else:\n",
    "                session_id_ = session_id\n",
    "            raw_path = os.path.join(raw_export_dir, f\"raw_{session_id_}.json\")\n",
    "            with open(raw_path, \"r\") as f:\n",
    "                data = json.load(f)\n",
    "\n",
    "            # Process and trim the data\n",
    "            trimmed_data = trim_data(data)\n",
    "\n",
    "            # If the entire data was filtered out (unlikely but possible)\n",
    "            if trimmed_data is None:\n",
    "                print(\n",
    "                    f\"All traces in session {session_id} were filtered due to fatal errors\"\n",
    "                )\n",
    "                continue\n",
    "\n",
    "            # Save trimmed data\n",
    "            if \"tpsg\" in session_id:\n",
    "                session_id_ = session_id.replace(\"tpsg\", \"tpusg\")\n",
    "            else:\n",
    "                session_id_ = session_id\n",
    "            trimmed_path = os.path.join(\n",
    "                trimmed_export_dir, f\"trimmed_{session_id_}.json\"\n",
    "            )\n",
    "            with open(trimmed_path, \"w\") as f:\n",
    "                json.dump(trimmed_data, f, indent=2)\n",
    "\n",
    "            print(\n",
    "                f\"Successfully processed and saved trimmed data for session {session_id}\"\n",
    "            )\n",
    "\n",
    "            # Optional: Verify trimming worked\n",
    "            # print(f\"Verifying trimmed data for session {session_id}...\")\n",
    "            # verify_trimming(trimmed_path)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing session {session_id}: {str(e)}\")\n",
    "\n",
    "\n",
    "def verify_trimming(trimmed_path):\n",
    "    \"\"\"\n",
    "    Verifies that the trimmed data doesn't contain unwanted keys.\n",
    "    \"\"\"\n",
    "    with open(trimmed_path, \"r\") as f:\n",
    "        trimmed_data = json.load(f)\n",
    "\n",
    "    unwanted_keys = [\n",
    "        \"release\",\n",
    "        \"version\",\n",
    "        \"user_id\",\n",
    "        \"public\",\n",
    "        \"html_path\",\n",
    "        \"scores\",\n",
    "        \"bookmarked\",\n",
    "        \"projectId\",\n",
    "        \"externalId\",\n",
    "        \"page\",\n",
    "        \"limit\",\n",
    "        \"total_pages\",\n",
    "        \"completionStartTime\",\n",
    "        \"metadata\",\n",
    "        \"usageDetails\",\n",
    "        \"timeToFirstToken\",\n",
    "        \"createdAt\",\n",
    "        \"completionTokens\",\n",
    "        \"promptTokens\",\n",
    "        \"projectId\",\n",
    "        \"unit\",\n",
    "        \"updatedAt\",\n",
    "        \"version\",\n",
    "        # \"statusMessage\",\n",
    "        \"parentObservationId\",\n",
    "        \"promptId\",\n",
    "        \"promptName\",\n",
    "        \"promptVersion\",\n",
    "        \"modelId\",\n",
    "        \"inputPrice\",\n",
    "        \"outputPrice\",\n",
    "        \"totalPrice\",\n",
    "        \"calculatedInputCost\",\n",
    "        \"calculatedOutputCost\",\n",
    "        \"calculatedTotalCost\",\n",
    "    ]\n",
    "\n",
    "    def check_keys(obj):\n",
    "        if isinstance(obj, dict):\n",
    "            for key in obj.keys():\n",
    "                if key in unwanted_keys:\n",
    "                    print(f\"Warning: Found unwanted key '{key}' in trimmed data\")\n",
    "            for value in obj.values():\n",
    "                check_keys(value)\n",
    "        elif isinstance(obj, list):\n",
    "            for item in obj:\n",
    "                check_keys(item)\n",
    "\n",
    "    check_keys(trimmed_data)\n",
    "    print(\"Verification complete\")\n",
    "\n",
    "\n",
    "# Usage example:\n",
    "read_and_trim_data(session_id_list, raw_export_dir, raw_export_dir)\n",
    "print(f\"Total {len(skipped_traces)} traces skipped. They are {skipped_traces}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Generate CSV files from JSON\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing session qwen2.5-coder:14b_5d09_tpusg_batch, simple id qwen2.5-coder:14b_5d09. Look for /home/han/Projects/reference-benchmark-tinyml_llm/data_analysis/2025/08.21/raw_export/trimmed_qwen2.5-coder:14b_5d09_tpusg_batch.json\n",
      "/home/han/Projects/reference-benchmark-tinyml_llm/data_analysis/2025/08.21/processed_data/qwen2.5-coder:14b_5d09/clean_qwen2.5-coder:14b_5d09_tpusg_batch.csv\n",
      "Successfully saved CSV to: /home/han/Projects/reference-benchmark-tinyml_llm/data_analysis/2025/08.21/processed_data/qwen2.5-coder:14b_5d09/clean_qwen2.5-coder:14b_5d09_tpusg_batch.csv\n",
      "Processing session qwen2.5-coder:14b_5d09_psg_batch, simple id qwen2.5-coder:14b_5d09. Look for /home/han/Projects/reference-benchmark-tinyml_llm/data_analysis/2025/08.21/raw_export/trimmed_qwen2.5-coder:14b_5d09_psg_batch.json\n",
      "/home/han/Projects/reference-benchmark-tinyml_llm/data_analysis/2025/08.21/processed_data/qwen2.5-coder:14b_5d09/clean_qwen2.5-coder:14b_5d09_psg_batch.csv\n",
      "Successfully saved CSV to: /home/han/Projects/reference-benchmark-tinyml_llm/data_analysis/2025/08.21/processed_data/qwen2.5-coder:14b_5d09/clean_qwen2.5-coder:14b_5d09_psg_batch.csv\n"
     ]
    }
   ],
   "source": [
    "import traceback\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from dateutil import parser\n",
    "\n",
    "\n",
    "def json_to_csv(session_id):\n",
    "    \"\"\"\n",
    "    Convert JSON trace data to CSV format with aggregated metrics.\n",
    "\n",
    "    Args:\n",
    "        session_id (str): Identifier for the session to process\n",
    "    \"\"\"\n",
    "\n",
    "    def extract_observation_details(observations, trace_id):\n",
    "        \"\"\"Extract and aggregate metrics from observations\"\"\"\n",
    "        metrics = {\n",
    "            \"status\": None,\n",
    "            \"latency\": 0,\n",
    "            \"total_tokens\": 0,\n",
    "            \"prompt_tokens\": 0,\n",
    "            \"completion_tokens\": 0,\n",
    "            \"total_cost\": 0,\n",
    "            \"input_cost\": 0,\n",
    "            \"output_cost\": 0,\n",
    "            \"parameters\": set(),\n",
    "        }\n",
    "\n",
    "        # Process GENERATION observations\n",
    "        for obs in (o for o in observations if o[\"type\"] == \"GENERATION\"):\n",
    "            metrics[\"total_tokens\"] += obs[\"totalTokens\"]\n",
    "            metrics[\"prompt_tokens\"] += obs[\"promptTokens\"]\n",
    "            metrics[\"completion_tokens\"] += obs[\"completionTokens\"]\n",
    "            metrics[\"latency\"] += obs[\"latency\"]\n",
    "            for key, value in obs[\"modelParameters\"].items():\n",
    "                metrics[\"parameters\"].add(key + \":\" + value)\n",
    "\n",
    "            # Add costs if present\n",
    "            for cost_type in [\"Total\", \"Input\", \"Output\"]:\n",
    "                key = f\"calculated{cost_type}Cost\"\n",
    "                metric_key = cost_type.lower() + \"_cost\"\n",
    "                if obs.get(key) is not None:\n",
    "                    metrics[metric_key] += obs[key]\n",
    "        if len(metrics[\"parameters\"]) == 0:\n",
    "            metrics[\"parameters\"] = \"N/A\"\n",
    "        # Process SPAN observations for status\n",
    "        status_indicators = [\n",
    "            obs[\"name\"]\n",
    "            for obs in observations\n",
    "            if obs[\"type\"] == \"SPAN\" and \"start_\" not in obs[\"name\"]\n",
    "        ]\n",
    "\n",
    "        #  if later than 2025-05-19, use status_signal_from_output\n",
    "        if datetime.now() > datetime(2025, 5, 19):\n",
    "            pass\n",
    "        else:\n",
    "            # Determine status\n",
    "            success_signals = sum(\"end_\" in name for name in status_indicators)\n",
    "            failure_signals = sum(\n",
    "                \"failure_signal\" in name for name in status_indicators\n",
    "            )\n",
    "\n",
    "            if success_signals + failure_signals > 1:\n",
    "                raise ValueError(\n",
    "                    f\"Multiple status indicators found in trace {trace_id}\"\n",
    "                )\n",
    "\n",
    "            metrics[\"status\"] = (\n",
    "                \"success\"\n",
    "                if success_signals\n",
    "                else \"failure\" if failure_signals else \"unknown\"\n",
    "            )\n",
    "\n",
    "        metrics[\"prompt_cost\"] = metrics.pop(\"input_cost\")\n",
    "        metrics[\"completion_cost\"] = metrics.pop(\"output_cost\")\n",
    "        metrics[\"latency\"] = round(metrics[\"latency\"] / 1000, 2)\n",
    "        return metrics\n",
    "\n",
    "    def cal_time(trace):\n",
    "        time_diff = datetime.fromisoformat(\n",
    "            trace[\"updatedAt\"].replace(\"Z\", \"+00:00\")\n",
    "        ) - datetime.fromisoformat(trace[\"createdAt\"].replace(\"Z\", \"+00:00\"))\n",
    "        seconds_diff = time_diff.total_seconds()\n",
    "        return seconds_diff\n",
    "\n",
    "    try:\n",
    "\n",
    "        if session_id.startswith(\"da0a\"):\n",
    "            session_id = \"phi4_\" + session_id\n",
    "        simple_session_id = session_id.rsplit(\"_\", 2)[0]\n",
    "\n",
    "        \n",
    "        # Load JSON data\n",
    "        if \"tpsg\" in session_id:\n",
    "                session_id_ = session_id.replace(\"tpsg\", \"tpusg\")\n",
    "        else:\n",
    "                session_id_ = session_id\n",
    "        trimmed_path = os.path.join(raw_export_dir, f\"trimmed_{session_id_}.json\")\n",
    "        print(\n",
    "            f\"Processing session {session_id}, simple id {simple_session_id}. Look for {trimmed_path}\"\n",
    "        )\n",
    "        with open(trimmed_path, \"r\") as file:\n",
    "            traces = json.load(file)[\"data\"]\n",
    "\n",
    "        # Process traces\n",
    "        rows = [\n",
    "            {\n",
    "                \"num_run\": trace[\"metadata\"][\"num_run\"],\n",
    "                \"name\": trace[\"name\"],\n",
    "                \"trace_id\": trace[\"id\"],\n",
    "                \"batch_id\": trace[\"session_id\"],\n",
    "                # \"latency\": cal_time(trace),\n",
    "                # \"latency\": round(trace[\"latency\"], 2),\n",
    "                **extract_observation_details(\n",
    "                    trace[\"observations\"],\n",
    "                    trace[\"id\"],\n",
    "                ),\n",
    "                \"status\": (\n",
    "                    \"failure\"\n",
    "                    if trace[\"output\"][\"status\"].lower() == \"failed\"\n",
    "                    else \"success\"\n",
    "                ),\n",
    "                \"tags\": trace[\"tags\"],\n",
    "                \"timestamp\": int(parser.isoparse(trace[\"timestamp\"]).timestamp()),\n",
    "            }\n",
    "            for trace in traces\n",
    "        ]\n",
    "        # print(rows)\n",
    "        # print(rows)\n",
    "        # Create and save DataFrame\n",
    "        df = pd.DataFrame(rows).sort_values(\"num_run\")\n",
    "\n",
    "        output_dir = os.path.join(processed_data_dir, f\"{simple_session_id}\")\n",
    "        if not os.path.exists(output_dir):\n",
    "            os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "        output_path = os.path.join(output_dir, f\"clean_{session_id_}.csv\")\n",
    "\n",
    "        print(output_path)\n",
    "        df.to_csv(output_path, index=False)\n",
    "        print(f\"Successfully saved CSV to: {output_path}\")\n",
    "\n",
    "    except FileNotFoundError as e:\n",
    "        print(\n",
    "            f\"FileNotFoundError: For session {session_id} not found. Looked for {trimmed_path}\\nError info: \\n{e}\\n\\nTraceback: {traceback.format_exc()}\"\n",
    "        )\n",
    "    except json.JSONDecodeError:\n",
    "        print(f\"Error: Invalid JSON format in input file for session {session_id}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing session {session_id}: {str(e)}\")\n",
    "\n",
    "\n",
    "# Example usage\n",
    "for session_id in session_id_list:\n",
    "    json_to_csv(session_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CSV Generation with Generation Counts\n",
    "\n",
    "This section creates CSV files similar to the langfuse_export section 3, but adds a column for the number of generation attempts used for each trace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing sessions: ['qwen2.5-coder:14b_5d09_tpusg_batch', 'qwen2.5-coder:14b_5d09_psg_batch']\n",
      "Looking for raw files in: /home/han/Projects/reference-benchmark-tinyml_llm/data_analysis/2025/08.21/raw_export\n",
      "Will save CSV files to: /home/han/Projects/reference-benchmark-tinyml_llm/data_analysis/2025/08.21/processed_data\n",
      "Processing session qwen2.5-coder:14b_5d09_tpusg_batch, simple id qwen2.5-coder:14b_5d09. Look for /home/han/Projects/reference-benchmark-tinyml_llm/data_analysis/2025/08.21/raw_export/trimmed_qwen2.5-coder:14b_5d09_tpusg_batch.json\n",
      "/home/han/Projects/reference-benchmark-tinyml_llm/data_analysis/2025/08.21/processed_data/qwen2.5-coder:14b_5d09/clean_qwen2.5-coder:14b_5d09_tpusg_batch.csv\n",
      "Successfully saved CSV to: /home/han/Projects/reference-benchmark-tinyml_llm/data_analysis/2025/08.21/processed_data/qwen2.5-coder:14b_5d09/clean_qwen2.5-coder:14b_5d09_tpusg_batch.csv\n",
      "Processing session qwen2.5-coder:14b_5d09_psg_batch, simple id qwen2.5-coder:14b_5d09. Look for /home/han/Projects/reference-benchmark-tinyml_llm/data_analysis/2025/08.21/raw_export/trimmed_qwen2.5-coder:14b_5d09_psg_batch.json\n",
      "/home/han/Projects/reference-benchmark-tinyml_llm/data_analysis/2025/08.21/processed_data/qwen2.5-coder:14b_5d09/clean_qwen2.5-coder:14b_5d09_psg_batch.csv\n",
      "Successfully saved CSV to: /home/han/Projects/reference-benchmark-tinyml_llm/data_analysis/2025/08.21/processed_data/qwen2.5-coder:14b_5d09/clean_qwen2.5-coder:14b_5d09_psg_batch.csv\n"
     ]
    }
   ],
   "source": [
    "import traceback\n",
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "from datetime import datetime\n",
    "from dateutil import parser\n",
    "\n",
    "# Setup paths - same as langfuse_export\n",
    "parent_dir = os.path.dirname(os.getcwd())\n",
    "raw_export_dir = os.path.join(parent_dir, \"raw_export\")\n",
    "processed_data_dir = os.path.join(parent_dir, \"processed_data\")\n",
    "\n",
    "\n",
    "# Get session id list from data directory\n",
    "session_id_list = []\n",
    "\n",
    "for root, dirs, files in os.walk(raw_export_dir):\n",
    "    for file in files:\n",
    "        file_path = os.path.join(root, file)\n",
    "        if \"trimmed_\" in file_path:\n",
    "            session_id = file_path.split('trimmed_')[1].rstrip('.json')\n",
    "            session_id_list.append(session_id)\n",
    "\n",
    "print(f\"Processing sessions: {session_id_list}\")\n",
    "print(f\"Looking for raw files in: {raw_export_dir}\")\n",
    "print(f\"Will save CSV files to: {processed_data_dir}\")\n",
    "\n",
    "\n",
    "def json_to_csv_weighted(session_id):\n",
    "    \"\"\"\n",
    "    Convert JSON trace data to CSV format with aggregated metrics.\n",
    "    Upgraded version that includes generation_count column.\n",
    "\n",
    "    Args:\n",
    "        session_id (str): Identifier for the session to process\n",
    "    \"\"\"\n",
    "\n",
    "    def extract_observation_details(observations, trace_id):\n",
    "        \"\"\"Extract and aggregate metrics from observations\"\"\"\n",
    "        metrics = {\n",
    "            \"status\": None,\n",
    "            \"latency\": 0,\n",
    "            \"total_tokens\": 0,\n",
    "            \"prompt_tokens\": 0,\n",
    "            \"completion_tokens\": 0,\n",
    "            \"total_cost\": 0,\n",
    "            \"input_cost\": 0,\n",
    "            \"output_cost\": 0,\n",
    "            \"parameters\": set(),\n",
    "            \"generation_count\": 0,  # New field for generation count\n",
    "        }\n",
    "\n",
    "        # Count generations and process GENERATION observations\n",
    "        for obs in (o for o in observations if o[\"type\"] == \"GENERATION\"):\n",
    "            metrics[\"generation_count\"] += 1\n",
    "            metrics[\"total_tokens\"] += obs[\"totalTokens\"]\n",
    "            metrics[\"prompt_tokens\"] += obs[\"promptTokens\"]\n",
    "            metrics[\"completion_tokens\"] += obs[\"completionTokens\"]\n",
    "            metrics[\"latency\"] += obs[\"latency\"]\n",
    "            for key, value in obs[\"modelParameters\"].items():\n",
    "                metrics[\"parameters\"].add(key + \":\" + value)\n",
    "\n",
    "            # Add costs if present\n",
    "            for cost_type in [\"Total\", \"Input\", \"Output\"]:\n",
    "                key = f\"calculated{cost_type}Cost\"\n",
    "                metric_key = cost_type.lower() + \"_cost\"\n",
    "                if obs.get(key) is not None:\n",
    "                    metrics[metric_key] += obs[key]\n",
    "                    \n",
    "        if len(metrics[\"parameters\"]) == 0:\n",
    "            metrics[\"parameters\"] = \"N/A\"\n",
    "            \n",
    "        # Process SPAN observations for status\n",
    "        status_indicators = [\n",
    "            obs[\"name\"]\n",
    "            for obs in observations\n",
    "            if obs[\"type\"] == \"SPAN\" and \"start_\" not in obs[\"name\"]\n",
    "        ]\n",
    "\n",
    "        #  if later than 2025-05-19, use status_signal_from_output\n",
    "        if datetime.now() > datetime(2025, 5, 19):\n",
    "            pass\n",
    "        else:\n",
    "            # Determine status\n",
    "            success_signals = sum(\"end_\" in name for name in status_indicators)\n",
    "            failure_signals = sum(\n",
    "                \"failure_signal\" in name for name in status_indicators\n",
    "            )\n",
    "\n",
    "            if success_signals + failure_signals > 1:\n",
    "                raise ValueError(\n",
    "                    f\"Multiple status indicators found in trace {trace_id}\"\n",
    "                )\n",
    "\n",
    "            metrics[\"status\"] = (\n",
    "                \"success\"\n",
    "                if success_signals\n",
    "                else \"failure\" if failure_signals else \"unknown\"\n",
    "            )\n",
    "\n",
    "        metrics[\"prompt_cost\"] = metrics.pop(\"input_cost\")\n",
    "        metrics[\"completion_cost\"] = metrics.pop(\"output_cost\")\n",
    "        metrics[\"latency\"] = round(metrics[\"latency\"] / 1000, 2)\n",
    "        return metrics\n",
    "\n",
    "    def cal_time(trace):\n",
    "        time_diff = datetime.fromisoformat(\n",
    "            trace[\"updatedAt\"].replace(\"Z\", \"+00:00\")\n",
    "        ) - datetime.fromisoformat(trace[\"createdAt\"].replace(\"Z\", \"+00:00\"))\n",
    "        seconds_diff = time_diff.total_seconds()\n",
    "        return seconds_diff\n",
    "\n",
    "    try:\n",
    "        if session_id.startswith(\"da0a\"):\n",
    "            session_id = \"phi4_\" + session_id\n",
    "        simple_session_id = session_id.rsplit(\"_\", 2)[0]\n",
    "\n",
    "        # Load JSON data\n",
    "        if \"tpsg\" in session_id:\n",
    "            session_id_ = session_id.replace(\"tpsg\", \"tpusg\")\n",
    "        else:\n",
    "            session_id_ = session_id\n",
    "        trimmed_path = os.path.join(raw_export_dir, f\"trimmed_{session_id_}.json\")\n",
    "        print(\n",
    "            f\"Processing session {session_id}, simple id {simple_session_id}. Look for {trimmed_path}\"\n",
    "        )\n",
    "        with open(trimmed_path, \"r\") as file:\n",
    "            traces = json.load(file)[\"data\"]\n",
    "\n",
    "        # Process traces\n",
    "        rows = [\n",
    "            {\n",
    "                \"num_run\": trace[\"metadata\"][\"num_run\"],\n",
    "                \"name\": trace[\"name\"],\n",
    "                \"trace_id\": trace[\"id\"],\n",
    "                \"batch_id\": trace[\"session_id\"],\n",
    "                # \"latency\": cal_time(trace),\n",
    "                # \"latency\": round(trace[\"latency\"], 2),\n",
    "                **extract_observation_details(\n",
    "                    trace[\"observations\"],\n",
    "                    trace[\"id\"],\n",
    "                ),\n",
    "                \"status\": (\n",
    "                    \"failure\"\n",
    "                    if trace[\"output\"][\"status\"].lower() == \"failed\"\n",
    "                    else \"success\"\n",
    "                ),\n",
    "                \"tags\": trace[\"tags\"],\n",
    "                \"timestamp\": int(parser.isoparse(trace[\"timestamp\"]).timestamp()),\n",
    "            }\n",
    "            for trace in traces\n",
    "        ]\n",
    "        \n",
    "        # Create and save DataFrame\n",
    "        df = pd.DataFrame(rows).sort_values(\"num_run\")\n",
    "\n",
    "        output_dir = os.path.join(processed_data_dir, f\"{simple_session_id}\")\n",
    "        if not os.path.exists(output_dir):\n",
    "            os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "        output_path = os.path.join(output_dir, f\"clean_{session_id_}.csv\")\n",
    "\n",
    "        print(output_path)\n",
    "        df.to_csv(output_path, index=False)\n",
    "        print(f\"Successfully saved CSV to: {output_path}\")\n",
    "\n",
    "    except FileNotFoundError as e:\n",
    "        print(\n",
    "            f\"FileNotFoundError: For session {session_id} not found. Looked for {trimmed_path}\\nError info: \\n{e}\\n\\nTraceback: {traceback.format_exc()}\"\n",
    "        )\n",
    "    except json.JSONDecodeError:\n",
    "        print(f\"Error: Invalid JSON format in input file for session {session_id}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing session {session_id}: {str(e)}\")\n",
    "\n",
    "\n",
    "\n",
    "# Example usage\n",
    "for session_id in session_id_list:\n",
    "    json_to_csv_weighted(session_id)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llmdev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

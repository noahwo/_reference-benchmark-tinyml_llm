{
  "data": [
    {
      "id": "e0ec470b",
      "timestamp": "2025-08-20T00:59:06.494000+00:00",
      "name": "e0ec_py_sketch_generator",
      "input": null,
      "output": {
        "status": "success",
        "sketch": "import numpy as np\nimport cv2\nfrom tflite_runtime.interpreter import Interpreter\n\n# Phase 1: Setup\nmodel_path   = \"models/ssd-mobilenet_v1/detect.tflite\"\nlabel_path   = \"models/ssd-mobilenet_v1/labelmap.txt\"\ninput_path   = \"data/object_detection/sheeps.mp4\"\noutput_path   = \"results/object_detection/test_results/sheeps_detections.mp4\"\nconfidence_threshold   = 0.5\n\n# Load Labels\nwith open(label_path, 'r') as f:\n    labels = [line.strip() for line in f.readlines()]\n\n# Load Interpreter\ninterpreter = Interpreter(model_path=model_path)\ninterpreter.allocate_tensors()\n\n# Get Model Details\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\n\n# Phase 2: Input Acquisition & Preprocessing Loop\ncap = cv2.VideoCapture(input_path)\n\nif not cap.isOpened():\n    print(\"Error opening video file\")\n    exit()\n\nwidth = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\nheight = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\nfourcc = cv2.VideoWriter_fourcc(*'mp4v')\nout = cv2.VideoWriter(output_path, fourcc, 30.0, (width, height))\n\nwhile cap.isOpened():\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    # Preprocess Data\n    input_data = cv2.resize(frame, (input_details[0]['shape'][1], input_details[0]['shape'][2]))\n    input_data = input_data.reshape((1, input_details[0]['shape'][1], input_details[0]['shape'][2], 3)).astype(np.uint8)\n\n    # Normalize if required by the model\n    if 'mean' in input_details[0] and 'std' in input_details[0]:\n        mean = np.array(input_details[0]['mean']).reshape((1, 1, 3))\n        std = np.array(input_details[0]['std']).reshape((1, 1, 3))\n        input_data = (input_data - mean) / std\n\n    # Phase 3: Inference\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n    interpreter.invoke()\n\n    # Phase 4: Output Interpretation & Handling Loop\n    # Get Output Tensor(s)\n    boxes = interpreter.get_tensor(output_details[0]['index'])[0]  # Bounding box coordinates\n    classes = interpreter.get_tensor(output_details[1]['index'])[0]  # Class indices\n    scores = interpreter.get_tensor(output_details[2]['index'])[0]  # Confidence scores\n    num_detections = interpreter.get_tensor(output_details[3]['index'])[0]  # Number of detections\n\n    # Interpret Results\n    for i in range(int(num_detections)):\n        if scores[i] > confidence_threshold:\n            class_name = labels[int(classes[i])]\n            y_min, x_min, y_max, x_max = boxes[i]\n            cv2.rectangle(frame, (int(x_min * width), int(y_min * height)), (int(x_max * width), int(y_max * height)), (0, 255, 0), 2)\n            cv2.putText(frame, f'{class_name}: {scores[i]:.2f}', (int(x_min * width), int(y_min * height) - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n\n    # Handle Output\n    out.write(frame)\n\n# Phase 5: Cleanup\ncap.release()\nout.release()\ncv2.destroyAllWindows()"
      },
      "session_id": "qwen2.5-coder:14b_c83f_psg_batch",
      "metadata": {
        "num_run": 30
      },
      "tags": [
        "benchmark",
        "py_sketch_generator",
        "qwen2.5-coder:14b"
      ],
      "latency": 27.564,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-03-59-06-496300_chatcmpl-7cc62aea-7e28-46de-a8f9-a4c02eed1647",
          "traceId": "e0ec470b",
          "type": "GENERATION",
          "name": "e0ec_psg_gen_attempt#1",
          "startTime": "2025-08-20T00:59:06.496000+00:00",
          "endTime": "2025-08-20T00:59:18.389000+00:00",
          "model": "qwen2.5-coder:14b",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 11893.0,
          "environment": "default",
          "promptTokens": 1618,
          "totalTokens": 2320,
          "costDetails": {},
          "completionTokens": 702,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-03-59-18-568055_chatcmpl-3775336e-d245-4674-9177-c6db52bf1a5d",
          "traceId": "e0ec470b",
          "type": "GENERATION",
          "name": "e0ec_psg_gen_attempt#2",
          "startTime": "2025-08-20T00:59:18.568000+00:00",
          "endTime": "2025-08-20T00:59:34.060000+00:00",
          "model": "qwen2.5-coder:14b",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 15492.0,
          "environment": "default",
          "promptTokens": 2048,
          "totalTokens": 2976,
          "costDetails": {},
          "completionTokens": 928,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        }
      ],
      "createdAt": "2025-08-20T00:59:07.012Z",
      "environment": "default",
      "updatedAt": "2025-08-20T01:00:11.235Z"
    },
    {
      "id": "91fa8245",
      "timestamp": "2025-08-20T00:57:58.903000+00:00",
      "name": "91fa_py_sketch_generator",
      "input": null,
      "output": {
        "status": "success",
        "sketch": "import numpy as np\nimport cv2\nimport tensorflow as tf\n\n# Phase 1: Setup\n\n# Paths/Parameters\nmodel_path     = \"models/ssd-mobilenet_v1/detect.tflite\"\nlabel_path     = \"models/ssd-mobilenet_v1/labelmap.txt\"\ninput_path     = \"data/object_detection/sheeps.mp4\"\noutput_path     = \"results/object_detection/test_results/sheeps_detections.mp4\"\nconfidence_threshold     = 0.5\n\n# Load Labels\nwith open(label_path, 'r') as f:\n    labels = [line.strip() for line in f.readlines()]\n\n# Load Interpreter\ninterpreter = tf.lite.Interpreter(model_path=model_path)\ninterpreter.allocate_tensors()\n\n# Get Model Details\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\n\n# Phase 2: Input Acquisition & Preprocessing Loop\n\n# Open video file\ncap = cv2.VideoCapture(input_path)\n\n# Define the codec and create VideoWriter object\nfourcc = cv2.VideoWriter_fourcc(*'XVID')\nout = cv2.VideoWriter(output_path, fourcc, 20.0, (int(cap.get(3)), int(cap.get(4))))\n\nwhile cap.isOpened():\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    # Preprocess Data\n    input_data = cv2.resize(frame, (input_details[0]['shape'][1], input_details[0]['shape'][2]))\n    input_data = cv2.cvtColor(input_data, cv2.COLOR_BGR2RGB)\n    input_data = np.expand_dims(input_data, axis=0)\n    input_data = (input_data - 127.5) / 127.5\n    input_data = input_data.astype(np.uint8)\n\n    # Phase 3: Inference\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n    interpreter.invoke()\n\n    # Phase 4: Output Interpretation & Handling Loop\n\n    # Get Output Tensor(s)\n    boxes = interpreter.get_tensor(output_details[0]['index'])[0]\n    classes = interpreter.get_tensor(output_details[1]['index'])[0]\n    scores = interpreter.get_tensor(output_details[2]['index'])[0]\n\n    # Interpret Results\n    for i in range(len(scores)):\n        if scores[i] > confidence_threshold:\n            y_min, x_min, y_max, x_max = boxes[i]\n            label = labels[int(classes[i])]\n            score = scores[i]\n\n            # Draw bounding box and label on the frame\n            cv2.rectangle(frame, (int(x_min * frame.shape[1]), int(y_min * frame.shape[0])),\n                          (int(x_max * frame.shape[1]), int(y_max * frame.shape[0])), (0, 255, 0), 2)\n            label_text = f'{label}: {score:.2f}'\n            cv2.putText(frame, label_text, (int(x_min * frame.shape[1]), int(y_min * frame.shape[0]) - 10),\n                        cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n\n    # Handle Output\n    out.write(frame)\n\n# Phase 5: Cleanup\n\ncap.release()\nout.release()\ncv2.destroyAllWindows()"
      },
      "session_id": "qwen2.5-coder:14b_c83f_psg_batch",
      "metadata": {
        "num_run": 29
      },
      "tags": [
        "benchmark",
        "py_sketch_generator",
        "qwen2.5-coder:14b"
      ],
      "latency": 53.108,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-03-57-58-904479_chatcmpl-cdbec683-3cd2-4631-8b9e-c1550e95d65e",
          "traceId": "91fa8245",
          "type": "GENERATION",
          "name": "91fa_psg_gen_attempt#1",
          "startTime": "2025-08-20T00:57:58.904000+00:00",
          "endTime": "2025-08-20T00:58:09.864000+00:00",
          "model": "qwen2.5-coder:14b",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 10960.0,
          "environment": "default",
          "promptTokens": 1618,
          "totalTokens": 2246,
          "costDetails": {},
          "completionTokens": 628,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-03-58-10-015278_chatcmpl-deb455e2-3b86-4a30-baf1-9cd9df5feafd",
          "traceId": "91fa8245",
          "type": "GENERATION",
          "name": "91fa_psg_gen_attempt#2",
          "startTime": "2025-08-20T00:58:10.015000+00:00",
          "endTime": "2025-08-20T00:58:22.604000+00:00",
          "model": "qwen2.5-coder:14b",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 12589.0,
          "environment": "default",
          "promptTokens": 2048,
          "totalTokens": 2790,
          "costDetails": {},
          "completionTokens": 742,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-03-58-22-748129_chatcmpl-e0988d3c-a959-49b2-b6d6-682a777fec8f",
          "traceId": "91fa8245",
          "type": "GENERATION",
          "name": "91fa_psg_gen_attempt#3",
          "startTime": "2025-08-20T00:58:22.748000+00:00",
          "endTime": "2025-08-20T00:58:34.898000+00:00",
          "model": "qwen2.5-coder:14b",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 12150.0,
          "environment": "default",
          "promptTokens": 2048,
          "totalTokens": 2764,
          "costDetails": {},
          "completionTokens": 716,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-03-58-38-257254_chatcmpl-c50c0110-18e3-4a41-905a-098bbad26bf8",
          "traceId": "91fa8245",
          "type": "GENERATION",
          "name": "91fa_psg_gen_attempt#4",
          "startTime": "2025-08-20T00:58:38.257000+00:00",
          "endTime": "2025-08-20T00:58:52.012000+00:00",
          "model": "qwen2.5-coder:14b",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 13755.0,
          "environment": "default",
          "promptTokens": 2048,
          "totalTokens": 2863,
          "costDetails": {},
          "completionTokens": 815,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        }
      ],
      "createdAt": "2025-08-20T00:57:59.420Z",
      "environment": "default",
      "updatedAt": "2025-08-20T00:59:06.111Z"
    },
    {
      "id": "34177d8e",
      "timestamp": "2025-08-20T00:57:11.285000+00:00",
      "name": "3417_py_sketch_generator",
      "input": null,
      "output": {
        "status": "success",
        "sketch": "import os\nimport numpy as np\nfrom tflite_runtime.interpreter import Interpreter\nimport cv2\n\n# Phase 1: Setup\nmodel_path  = \"models/ssd-mobilenet_v1/detect.tflite\"\nlabel_path  = \"models/ssd-mobilenet_v1/labelmap.txt\"\ninput_path  = \"data/object_detection/sheeps.mp4\"\noutput_path  = \"results/object_detection/test_results/sheeps_detections.mp4\"\nconfidence_threshold  = 0.5\n\n# Load Labels\nwith open(label_path, 'r') as f:\n    labels = [line.strip() for line in f.readlines()]\n\n# Load Interpreter\ninterpreter = Interpreter(model_path=model_path)\ninterpreter.allocate_tensors()\n\n# Get Model Details\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\n\ninput_shape = input_details[0]['shape']\ninput_dtype = input_details[0]['dtype']\n\n# Phase 2: Input Acquisition & Preprocessing Loop\ncap = cv2.VideoCapture(input_path)\nfourcc = cv2.VideoWriter_fourcc(*'mp4v')\nout = cv2.VideoWriter(output_path, fourcc, cap.get(cv2.CAP_PROP_FPS), (int(cap.get(cv2.CAP_PROP_FRAME_WIDTH)), int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))))\n\nwhile cap.isOpened():\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    # Preprocess Data\n    input_data = cv2.resize(frame, (input_shape[1], input_shape[2]))\n    input_data = input_data / 127.5 - 1.0  # Normalize to [-1, 1]\n    input_data = np.expand_dims(input_data, axis=0).astype(input_dtype)\n\n    # Phase 3: Inference\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n    interpreter.invoke()\n\n    # Phase 4: Output Interpretation & Handling Loop\n    boxes = interpreter.get_tensor(output_details[0]['index'])[0]\n    classes = interpreter.get_tensor(output_details[1]['index'])[0]\n    scores = interpreter.get_tensor(output_details[2]['index'])[0]\n\n    for box, cls, score in zip(boxes, classes, scores):\n        if score > confidence_threshold:\n            label = labels[int(cls)]\n            ymin, xmin, ymax, xmax = map(int, box)\n            cv2.rectangle(frame, (xmin, ymin), (xmax, ymax), (0, 255, 0), 2)\n            cv2.putText(frame, f'{label}: {score:.2f}', (xmin, ymin - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n\n    # Handle Output\n    out.write(frame)\n\n# Phase 5: Cleanup\ncap.release()\nout.release()\ncv2.destroyAllWindows()"
      },
      "session_id": "qwen2.5-coder:14b_c83f_psg_batch",
      "metadata": {
        "num_run": 28
      },
      "tags": [
        "benchmark",
        "py_sketch_generator",
        "qwen2.5-coder:14b"
      ],
      "latency": 10.224,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-03-57-11-287441_chatcmpl-acf90efa-7c2f-49bf-b105-e429aac7e1bd",
          "traceId": "34177d8e",
          "type": "GENERATION",
          "name": "3417_psg_gen_attempt#1",
          "startTime": "2025-08-20T00:57:11.287000+00:00",
          "endTime": "2025-08-20T00:57:21.511000+00:00",
          "model": "qwen2.5-coder:14b",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 10224.0,
          "environment": "default",
          "promptTokens": 1618,
          "totalTokens": 2220,
          "costDetails": {},
          "completionTokens": 602,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        }
      ],
      "createdAt": "2025-08-20T00:57:11.804Z",
      "environment": "default",
      "updatedAt": "2025-08-20T00:57:58.473Z"
    },
    {
      "id": "915e15ce",
      "timestamp": "2025-08-20T00:56:08.593000+00:00",
      "name": "915e_py_sketch_generator",
      "input": null,
      "output": {
        "status": "success",
        "sketch": "import numpy as np\nimport cv2\nfrom tflite_runtime.interpreter import Interpreter\n\n# Phase 1: Setup\nmodel_path  = \"models/ssd-mobilenet_v1/detect.tflite\"\nlabel_path  = \"models/ssd-mobilenet_v1/labelmap.txt\"\ninput_path  = \"data/object_detection/sheeps.mp4\"\noutput_path  = \"results/object_detection/test_results/sheeps_detections.mp4\"\nconfidence_threshold  = 0.5\n\n# Load labels\nwith open(label_path, 'r') as f:\n    labels = [line.strip() for line in f.readlines()]\n\n# Load interpreter\ninterpreter = Interpreter(model_path=model_path)\ninterpreter.allocate_tensors()\n\n# Get model details\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\n\n# Phase 2: Input Acquisition & Preprocessing Loop\ncap = cv2.VideoCapture(input_path)\n\nif not cap.isOpened():\n    print(\"Error opening video file\")\n    exit()\n\nfourcc = cv2.VideoWriter_fourcc(*'mp4v')\nout = cv2.VideoWriter(output_path, fourcc, 20.0, (int(cap.get(3)), int(cap.get(4))))\n\nwhile True:\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    # Preprocess data\n    input_data = cv2.resize(frame, (input_details[0]['shape'][1], input_details[0]['shape'][2]))\n    input_data = input_data[np.newaxis].astype(input_details[0]['dtype'])\n\n    # Phase 3: Inference\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n    interpreter.invoke()\n\n    # Phase 4: Output Interpretation & Handling Loop\n    boxes = interpreter.get_tensor(output_details[0]['index'])[0]  # Fixed index access\n    classes = interpreter.get_tensor(output_details[1]['index'])[0].astype(int)\n    scores = interpreter.get_tensor(output_details[2]['index'])[0]\n\n    for box, cls, score in zip(boxes, classes, scores):\n        if score > confidence_threshold:\n            y1, x1, y2, x2 = int(box[0] * frame.shape[0]), int(box[1] * frame.shape[1]), int(box[2] * frame.shape[0]), int(box[3] * frame.shape[1])\n            label = labels[cls]\n            cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n            cv2.putText(frame, f'{label} {score:.2f}', (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n\n    out.write(frame)\n\n# Phase 5: Cleanup\ncap.release()\nout.release()\ncv2.destroyAllWindows()"
      },
      "session_id": "qwen2.5-coder:14b_c83f_psg_batch",
      "metadata": {
        "num_run": 27
      },
      "tags": [
        "benchmark",
        "py_sketch_generator",
        "qwen2.5-coder:14b"
      ],
      "latency": 24.833,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-03-56-08-594609_chatcmpl-6c94a098-0eec-48b8-b3e5-f1b71bc2423f",
          "traceId": "915e15ce",
          "type": "GENERATION",
          "name": "915e_psg_gen_attempt#1",
          "startTime": "2025-08-20T00:56:08.594000+00:00",
          "endTime": "2025-08-20T00:56:18.985000+00:00",
          "model": "qwen2.5-coder:14b",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 10391.0,
          "environment": "default",
          "promptTokens": 1618,
          "totalTokens": 2230,
          "costDetails": {},
          "completionTokens": 612,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-03-56-19-361071_chatcmpl-19d1668e-cdb2-40ce-a4da-2d89f02d4a14",
          "traceId": "915e15ce",
          "type": "GENERATION",
          "name": "915e_psg_gen_attempt#2",
          "startTime": "2025-08-20T00:56:19.361000+00:00",
          "endTime": "2025-08-20T00:56:33.427000+00:00",
          "model": "qwen2.5-coder:14b",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 14066.0,
          "environment": "default",
          "promptTokens": 2048,
          "totalTokens": 2886,
          "costDetails": {},
          "completionTokens": 838,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        }
      ],
      "createdAt": "2025-08-20T00:56:09.108Z",
      "environment": "default",
      "updatedAt": "2025-08-20T00:57:10.804Z"
    },
    {
      "id": "d0d13e5e",
      "timestamp": "2025-08-20T00:55:30.926000+00:00",
      "name": "d0d1_py_sketch_generator",
      "input": null,
      "output": {
        "status": "success",
        "sketch": "import numpy as np\nimport cv2\nimport tensorflow as tf\n\n# Phase 1: Setup\nmodel_path  = \"models/ssd-mobilenet_v1/detect.tflite\"\nlabel_path  = \"models/ssd-mobilenet_v1/labelmap.txt\"\ninput_path  = \"data/object_detection/sheeps.mp4\"\noutput_path  = \"results/object_detection/test_results/sheeps_detections.mp4\"\nconfidence_threshold  = 0.5\n\n# Load labels\nwith open(label_path, 'r') as f:\n    labels = [line.strip() for line in f.readlines()]\n\n# Load interpreter\ninterpreter = tf.lite.Interpreter(model_path=model_path)\ninterpreter.allocate_tensors()\n\n# Get model details\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\n\n# Phase 2: Input Acquisition & Preprocessing Loop\ncap = cv2.VideoCapture(input_path)\n\nif not cap.isOpened():\n    print(\"Error opening video file\")\n    exit()\n\nfourcc = cv2.VideoWriter_fourcc(*'mp4v')\nout = cv2.VideoWriter(output_path, fourcc, 30.0, (int(cap.get(3)), int(cap.get(4))))\n\nwhile True:\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    # Preprocess data\n    input_data = cv2.resize(frame, (input_details[0]['shape'][1], input_details[0]['shape'][2]))\n    input_data = np.expand_dims(input_data, axis=0)\n    input_data = input_data.astype(input_details[0]['dtype'])\n\n    # Phase 3: Inference\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n    interpreter.invoke()\n\n    # Phase 4: Output Interpretation & Handling Loop\n    output_boxes = interpreter.get_tensor(output_details[0]['index'])[0]  # Bounding boxes\n    output_classes = interpreter.get_tensor(output_details[1]['index'])[0]  # Class IDs\n    output_scores = interpreter.get_tensor(output_details[2]['index'])[0]  # Confidence scores\n\n    for i in range(len(output_boxes)):\n        if output_scores[i] > confidence_threshold:\n            class_id = int(output_classes[i])\n            box = output_boxes[i]\n            label = labels[class_id]\n\n            y1, x1, y2, x2 = map(int, box * [frame.shape[0], frame.shape[1], frame.shape[0], frame.shape[1]])\n            cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n            cv2.putText(frame, f\"{label}: {output_scores[i]:.2f}\", (x1, y1 - 10),\n                        cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n\n    out.write(frame)\n\n# Phase 5: Cleanup\ncap.release()\nout.release()\ncv2.destroyAllWindows()"
      },
      "session_id": "qwen2.5-coder:14b_c83f_psg_batch",
      "metadata": {
        "num_run": 26
      },
      "tags": [
        "benchmark",
        "py_sketch_generator",
        "qwen2.5-coder:14b"
      ],
      "latency": 22.933,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-03-55-30-928398_chatcmpl-3bfded65-0989-4c45-8b1d-8442f005df4c",
          "traceId": "d0d13e5e",
          "type": "GENERATION",
          "name": "d0d1_psg_gen_attempt#1",
          "startTime": "2025-08-20T00:55:30.928000+00:00",
          "endTime": "2025-08-20T00:55:41.788000+00:00",
          "model": "qwen2.5-coder:14b",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 10860.0,
          "environment": "default",
          "promptTokens": 1618,
          "totalTokens": 2260,
          "costDetails": {},
          "completionTokens": 642,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-03-55-41-937472_chatcmpl-99cbc777-4ca9-4283-a744-82288069f152",
          "traceId": "d0d13e5e",
          "type": "GENERATION",
          "name": "d0d1_psg_gen_attempt#2",
          "startTime": "2025-08-20T00:55:41.937000+00:00",
          "endTime": "2025-08-20T00:55:53.861000+00:00",
          "model": "qwen2.5-coder:14b",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 11924.0,
          "environment": "default",
          "promptTokens": 2048,
          "totalTokens": 2750,
          "costDetails": {},
          "completionTokens": 702,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        }
      ],
      "createdAt": "2025-08-20T00:55:31.443Z",
      "environment": "default",
      "updatedAt": "2025-08-20T00:56:08.081Z"
    },
    {
      "id": "60a3dcf9",
      "timestamp": "2025-08-20T00:54:41.063000+00:00",
      "name": "60a3_py_sketch_generator",
      "input": null,
      "output": {
        "status": "success",
        "sketch": "import numpy as np\nimport cv2\n\n# Phase 1: Setup\nmodel_path   = \"models/ssd-mobilenet_v1/detect.tflite\"\nlabel_path   = \"models/ssd-mobilenet_v1/labelmap.txt\"\ninput_path   = \"data/object_detection/sheeps.mp4\"\noutput_path   = \"results/object_detection/test_results/sheeps_detections.mp4\"\nconfidence_threshold   = 0.5\n\n# Load labels\nwith open(label_path, 'r') as f:\n    labels = [line.strip() for line in f.readlines()]\n\n# Load interpreter\nimport tensorflow.lite as tflite\ninterpreter = tflite.Interpreter(model_path=model_path)\ninterpreter.allocate_tensors()\n\n# Get model details\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\n\ninput_shape = input_details[0]['shape']\ninput_dtype = input_details[0]['dtype']\n\n# Phase 2: Input Acquisition & Preprocessing Loop\ncap = cv2.VideoCapture(input_path)\nif not cap.isOpened():\n    raise IOError(\"Cannot open video file\")\n\nfourcc = cv2.VideoWriter_fourcc(*'mp4v')\nout = cv2.VideoWriter(output_path, fourcc, 30.0, (int(cap.get(3)), int(cap.get(4))))\n\nwhile True:\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    # Preprocess data\n    input_data = cv2.resize(frame, (input_shape[1], input_shape[2]))\n    input_data = input_data / 255.0\n    input_data = np.expand_dims(input_data, axis=0).astype(input_dtype)\n\n    # Phase 3: Inference\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n    interpreter.invoke()\n\n    # Phase 4: Output Interpretation & Handling Loop\n    boxes = interpreter.get_tensor(output_details[0]['index'])[0]\n    classes = interpreter.get_tensor(output_details[1]['index'])[0]\n    scores = interpreter.get_tensor(output_details[2]['index'])[0]\n\n    for i in range(len(scores)):\n        if scores[i] > confidence_threshold:\n            ymin, xmin, ymax, xmax = boxes[i]\n            label = labels[int(classes[i])]\n            cv2.rectangle(frame, (int(xmin * frame.shape[1]), int(ymin * frame.shape[0])),\n                          (int(xmax * frame.shape[1]), int(ymax * frame.shape[0])), (0, 255, 0), 2)\n            cv2.putText(frame, f'{label}: {scores[i]:.2f}', (int(xmin * frame.shape[1]), int(ymin * frame.shape[0]) - 10),\n                        cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n\n    out.write(frame)\n\n# Phase 5: Cleanup\ncap.release()\nout.release()\ncv2.destroyAllWindows()"
      },
      "session_id": "qwen2.5-coder:14b_c83f_psg_batch",
      "metadata": {
        "num_run": 25
      },
      "tags": [
        "benchmark",
        "py_sketch_generator",
        "qwen2.5-coder:14b"
      ],
      "latency": 34.43,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-03-54-41-064916_chatcmpl-80e4946c-792c-4061-beea-e041b5034ba8",
          "traceId": "60a3dcf9",
          "type": "GENERATION",
          "name": "60a3_psg_gen_attempt#1",
          "startTime": "2025-08-20T00:54:41.064000+00:00",
          "endTime": "2025-08-20T00:54:51.483000+00:00",
          "model": "qwen2.5-coder:14b",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 10419.0,
          "environment": "default",
          "promptTokens": 1618,
          "totalTokens": 2231,
          "costDetails": {},
          "completionTokens": 613,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-03-54-51-635292_chatcmpl-abbd3026-5999-4f1f-9184-246f09d43394",
          "traceId": "60a3dcf9",
          "type": "GENERATION",
          "name": "60a3_psg_gen_attempt#2",
          "startTime": "2025-08-20T00:54:51.635000+00:00",
          "endTime": "2025-08-20T00:55:03.576000+00:00",
          "model": "qwen2.5-coder:14b",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 11941.0,
          "environment": "default",
          "promptTokens": 2048,
          "totalTokens": 2750,
          "costDetails": {},
          "completionTokens": 702,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-03-55-03-717996_chatcmpl-f6a1f046-d7bc-423e-b12c-e19a3a66f439",
          "traceId": "60a3dcf9",
          "type": "GENERATION",
          "name": "60a3_psg_gen_attempt#3",
          "startTime": "2025-08-20T00:55:03.717000+00:00",
          "endTime": "2025-08-20T00:55:15.494000+00:00",
          "model": "qwen2.5-coder:14b",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 11777.0,
          "environment": "default",
          "promptTokens": 2048,
          "totalTokens": 2740,
          "costDetails": {},
          "completionTokens": 692,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        }
      ],
      "createdAt": "2025-08-20T00:54:41.581Z",
      "environment": "default",
      "updatedAt": "2025-08-20T00:55:30.251Z"
    },
    {
      "id": "c14a2ef1",
      "timestamp": "2025-08-20T00:53:52.407000+00:00",
      "name": "c14a_py_sketch_generator",
      "input": null,
      "output": {
        "status": "success",
        "sketch": "import numpy as np\nimport cv2\nfrom tflite_runtime.interpreter import Interpreter\n\n# Phase 1: Setup\nmodel_path  = \"models/ssd-mobilenet_v1/detect.tflite\"\nlabel_path  = \"models/ssd-mobilenet_v1/labelmap.txt\"\ninput_path  = \"data/object_detection/sheeps.mp4\"\noutput_path  = \"results/object_detection/test_results/sheeps_detections.mp4\"\nconfidence_threshold  = 0.5\n\n# Load labels\nwith open(label_path, 'r') as f:\n    labels = [line.strip() for line in f.readlines()]\n\n# Load interpreter\ninterpreter = Interpreter(model_path=model_path)\ninterpreter.allocate_tensors()\n\n# Get model details\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\n\ninput_shape = input_details[0]['shape']\ninput_dtype = input_details[0]['dtype']\n\n# Phase 2: Input Acquisition & Preprocessing Loop\ncap = cv2.VideoCapture(input_path)\nif not cap.isOpened():\n    raise ValueError(\"Error opening video file\")\n\nfourcc = cv2.VideoWriter_fourcc(*'mp4v')\nout = cv2.VideoWriter(output_path, fourcc, 30.0, (int(cap.get(3)), int(cap.get(4))))\n\nwhile cap.isOpened():\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    # Preprocess data\n    input_data = cv2.resize(frame, (input_shape[1], input_shape[2]))\n    input_data = input_data.astype(input_dtype)\n    input_data = np.expand_dims(input_data, axis=0)\n\n    # Phase 3: Inference\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n    interpreter.invoke()\n\n    # Phase 4: Output Interpretation & Handling Loop\n    boxes = interpreter.get_tensor(output_details[0]['index'])[0]\n    classes = interpreter.get_tensor(output_details[1]['index'])[0]\n    scores = interpreter.get_tensor(output_details[2]['index'])[0]\n\n    for i in range(len(scores)):\n        if scores[i] > confidence_threshold:\n            class_name = labels[int(classes[i])]\n            box = boxes[i]\n            y_min, x_min, y_max, x_max = map(int, box * [frame.shape[0], frame.shape[1], frame.shape[0], frame.shape[1]])\n            cv2.rectangle(frame, (x_min, y_min), (x_max, y_max), (0, 255, 0), 2)\n            cv2.putText(frame, f'{class_name}: {scores[i]:.2f}', (x_min, y_min - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n\n    out.write(frame)\n\n# Phase 5: Cleanup\ncap.release()\nout.release()\ncv2.destroyAllWindows()"
      },
      "session_id": "qwen2.5-coder:14b_c83f_psg_batch",
      "metadata": {
        "num_run": 24
      },
      "tags": [
        "benchmark",
        "py_sketch_generator",
        "qwen2.5-coder:14b"
      ],
      "latency": 10.347,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-03-53-52-409395_chatcmpl-1b104fc7-aa4b-43df-9c7d-2e3208e82232",
          "traceId": "c14a2ef1",
          "type": "GENERATION",
          "name": "c14a_psg_gen_attempt#1",
          "startTime": "2025-08-20T00:53:52.409000+00:00",
          "endTime": "2025-08-20T00:54:02.756000+00:00",
          "model": "qwen2.5-coder:14b",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 10347.0,
          "environment": "default",
          "promptTokens": 1618,
          "totalTokens": 2227,
          "costDetails": {},
          "completionTokens": 609,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        }
      ],
      "createdAt": "2025-08-20T00:53:52.924Z",
      "environment": "default",
      "updatedAt": "2025-08-20T00:54:40.575Z"
    },
    {
      "id": "ebe2e5eb",
      "timestamp": "2025-08-20T00:52:49.693000+00:00",
      "name": "ebe2_py_sketch_generator",
      "input": null,
      "output": {
        "status": "success",
        "sketch": "import numpy as np\nimport cv2\nfrom tflite_runtime.interpreter import Interpreter\n\n# Phase 1: Setup\nmodel_path  = \"models/ssd-mobilenet_v1/detect.tflite\"\nlabel_path  = \"models/ssd-mobilenet_v1/labelmap.txt\"\ninput_path  = \"data/object_detection/sheeps.mp4\"\noutput_path  = \"results/object_detection/test_results/sheeps_detections.mp4\"\nconfidence_threshold  = 0.5\n\n# Load labels\nwith open(label_path, 'r') as f:\n    labels = [line.strip() for line in f.readlines()]\n\n# Load interpreter\ninterpreter = Interpreter(model_path=model_path)\ninterpreter.allocate_tensors()\n\n# Get model details\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\n\ninput_shape = input_details[0]['shape']\ninput_dtype = input_details[0]['dtype']\n\n# Phase 2: Input Acquisition & Preprocessing Loop\ncap = cv2.VideoCapture(input_path)\nfourcc = cv2.VideoWriter_fourcc(*'mp4v')\nout = cv2.VideoWriter(output_path, fourcc, cap.get(cv2.CAP_PROP_FPS), (int(cap.get(3)), int(cap.get(4))))\n\nwhile True:\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    # Preprocess data\n    input_data = cv2.resize(frame, (input_shape[1], input_shape[2]))\n    input_data = np.expand_dims(input_data, axis=0)\n    input_data = input_data.astype(input_dtype)\n\n    # Phase 3: Inference\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n    interpreter.invoke()\n\n    # Phase 4: Output Interpretation & Handling Loop\n    boxes = interpreter.get_tensor(output_details[0]['index'])\n    scores = interpreter.get_tensor(output_details[1]['index'])\n    classes = interpreter.get_tensor(output_details[2]['index'])\n\n    for box, score, class_id in zip(boxes[0], scores[0], classes[0]):\n        if score > confidence_threshold:\n            ymin, xmin, ymax, xmax = box\n            label = labels[int(class_id)]\n            cv2.rectangle(frame, (int(xmin * frame.shape[1]), int(ymin * frame.shape[0])),\n                           (int(xmax * frame.shape[1]), int(ymax * frame.shape[0])), (0, 255, 0), 2)\n            cv2.putText(frame, f'{label}: {score:.2f}', (int(xmin * frame.shape[1]), int(ymin * frame.shape[0]) - 10),\n                        cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n\n    # Handle Output\n    out.write(frame)\n\n# Phase 5: Cleanup\ncap.release()\nout.release()\ncv2.destroyAllWindows()"
      },
      "session_id": "qwen2.5-coder:14b_c83f_psg_batch",
      "metadata": {
        "num_run": 23
      },
      "tags": [
        "benchmark",
        "py_sketch_generator",
        "qwen2.5-coder:14b"
      ],
      "latency": 24.387,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-03-52-49-695674_chatcmpl-84dc664b-2707-4742-ac54-b99384d629e7",
          "traceId": "ebe2e5eb",
          "type": "GENERATION",
          "name": "ebe2_psg_gen_attempt#1",
          "startTime": "2025-08-20T00:52:49.695000+00:00",
          "endTime": "2025-08-20T00:53:00.045000+00:00",
          "model": "qwen2.5-coder:14b",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 10350.0,
          "environment": "default",
          "promptTokens": 1618,
          "totalTokens": 2227,
          "costDetails": {},
          "completionTokens": 609,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-03-53-00-426408_chatcmpl-13a977f6-c11f-46df-aae6-15e5355b4e4d",
          "traceId": "ebe2e5eb",
          "type": "GENERATION",
          "name": "ebe2_psg_gen_attempt#2",
          "startTime": "2025-08-20T00:53:00.426000+00:00",
          "endTime": "2025-08-20T00:53:14.082000+00:00",
          "model": "qwen2.5-coder:14b",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 13656.0,
          "environment": "default",
          "promptTokens": 2048,
          "totalTokens": 2859,
          "costDetails": {},
          "completionTokens": 811,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        }
      ],
      "createdAt": "2025-08-20T00:52:50.211Z",
      "environment": "default",
      "updatedAt": "2025-08-20T00:53:51.398Z"
    },
    {
      "id": "25fcdf2b",
      "timestamp": "2025-08-20T00:52:00.884000+00:00",
      "name": "25fc_py_sketch_generator",
      "input": null,
      "output": {
        "status": "success",
        "sketch": "import os\nimport time\nimport numpy as np\nfrom tflite_runtime.interpreter import Interpreter\n\n# Phase 1: Setup\nmodel_path  = \"models/ssd-mobilenet_v1/detect.tflite\"\nlabel_path  = \"models/ssd-mobilenet_v1/labelmap.txt\"\ninput_path  = \"data/object_detection/sheeps.mp4\"\noutput_path  = \"results/object_detection/test_results/sheeps_detections.mp4\"\nconfidence_threshold  = 0.5\n\n# Load labels\nwith open(label_path, 'r') as f:\n    labels = [line.strip() for line in f.readlines()]\n\n# Load interpreter\ninterpreter = Interpreter(model_path=model_path)\ninterpreter.allocate_tensors()\n\n# Get model details\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\n\ninput_shape = input_details[0]['shape']\ninput_dtype = input_details[0]['dtype']\n\n# Phase 2: Input Acquisition & Preprocessing Loop\nimport cv2\n\ncap = cv2.VideoCapture(input_path)\nfourcc = cv2.VideoWriter_fourcc(*'mp4v')\nout = cv2.VideoWriter(output_path, fourcc, cap.get(cv2.CAP_PROP_FPS), (int(cap.get(3)), int(cap.get(4))))\n\nwhile cap.isOpened():\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    # Preprocess data\n    resized_frame = cv2.resize(frame, (input_shape[1], input_shape[2]))\n    normalized_frame = resized_frame / 255.0\n    input_data = np.expand_dims(normalized_frame, axis=0).astype(input_dtype)\n\n    # Phase 3: Inference\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n    interpreter.invoke()\n\n    # Phase 4: Output Interpretation & Handling Loop\n    boxes = interpreter.get_tensor(output_details[0]['index'])\n    classes = interpreter.get_tensor(output_details[1]['index'])\n    scores = interpreter.get_tensor(output_details[2]['index'])\n\n    for i in range(len(scores[0])):\n        if scores[0][i] > confidence_threshold:\n            ymin, xmin, ymax, xmax = boxes[0][i]\n            label = labels[int(classes[0][i])]\n            cv2.rectangle(frame, (int(xmin * frame.shape[1]), int(ymin * frame.shape[0])),\n                          (int(xmax * frame.shape[1]), int(ymax * frame.shape[0])), (0, 255, 0), 2)\n            cv2.putText(frame, f'{label}: {scores[0][i]:.2f}', \n                        (int(xmin * frame.shape[1]), int(ymin * frame.shape[0]) - 10),\n                        cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n\n    out.write(frame)\n\n# Phase 5: Cleanup\ncap.release()\nout.release()\ncv2.destroyAllWindows()"
      },
      "session_id": "qwen2.5-coder:14b_c83f_psg_batch",
      "metadata": {
        "num_run": 22
      },
      "tags": [
        "benchmark",
        "py_sketch_generator",
        "qwen2.5-coder:14b"
      ],
      "latency": 10.639,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-03-52-00-886521_chatcmpl-a2e50948-96de-488f-8dee-850e4c71eb32",
          "traceId": "25fcdf2b",
          "type": "GENERATION",
          "name": "25fc_psg_gen_attempt#1",
          "startTime": "2025-08-20T00:52:00.886000+00:00",
          "endTime": "2025-08-20T00:52:11.525000+00:00",
          "model": "qwen2.5-coder:14b",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 10639.0,
          "environment": "default",
          "promptTokens": 1618,
          "totalTokens": 2245,
          "costDetails": {},
          "completionTokens": 627,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        }
      ],
      "createdAt": "2025-08-20T00:52:01.402Z",
      "environment": "default",
      "updatedAt": "2025-08-20T00:52:49.081Z"
    },
    {
      "id": "0c7d16f7",
      "timestamp": "2025-08-20T00:50:45.923000+00:00",
      "name": "0c7d_py_sketch_generator",
      "input": null,
      "output": {
        "status": "failed",
        "last_code": "import numpy as np\nimport cv2\nfrom tflite_runtime.interpreter import Interpreter\n\n# Phase 1: Setup\nmodel_path     = \"models/ssd-mobilenet_v1/detect.tflite\"\nlabel_path     = \"models/ssd-mobilenet_v1/labelmap.txt\"\ninput_path     = \"data/object_detection/sheeps.mp4\"\noutput_path     = \"results/object_detection/test_results/sheeps_detections.mp4\"\nconfidence_threshold     = 0.5\n\n# Load labels\nwith open(label_path, 'r') as f:\n    labels = [line.strip() for line in f.readlines()]\n\n# Load interpreter and allocate tensors\ninterpreter = Interpreter(model_path=model_path)\ninterpreter.allocate_tensors()\n\n# Get model details\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\n\n# Ensure input tensor is of type UINT8 as expected by the model\nif input_details[0]['dtype'] == np.uint8:\n    def preprocess(frame):\n        # Convert to grayscale if necessary, resize, and normalize\n        frame = cv2.resize(frame, (input_details[0]['shape'][1], input_details[0]['shape'][2]))\n        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)  # Ensure the correct color format\n        input_data = np.expand_dims(frame, axis=0)\n        return input_data.astype(np.uint8)\nelse:\n    raise ValueError(\"Input tensor type mismatch. Expected UINT8.\")\n\n# Phase 2: Input Acquisition & Preprocessing Loop\ncap = cv2.VideoCapture(input_path)\n\nframe_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\nframe_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\nfourcc = cv2.VideoWriter_fourcc(*'mp4v')\nout = cv2.VideoWriter(output_path, fourcc, 30.0, (frame_width, frame_height))\n\nwhile cap.isOpened():\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    # Preprocess data\n    input_data = preprocess(frame)\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n\n    # Phase 3: Inference\n    interpreter.invoke()\n\n    # Phase 4: Output Interpretation & Handling Loop\n    boxes = interpreter.get_tensor(output_details[0]['index'])  # Corrected line\n    classes = interpreter.get_tensor(output_details[1]['index'])\n    scores = interpreter.get_tensor(output_details[2]['index'])\n\n    for i in range(len(scores)):\n        if scores[i] > confidence_threshold:\n            class_id = int(classes[i])\n            label = labels[class_id]\n            ymin, xmin, ymax, xmax = boxes[i]\n            ymin = int(ymin * frame_height)\n            xmin = int(xmin * frame_width)\n            ymax = int(ymax * frame_height)\n            xmax = int(xmax * frame_width)\n\n            cv2.rectangle(frame, (xmin, ymin), (xmax, ymax), (0, 255, 0), 2)\n            cv2.putText(frame, f'{label}: {scores[i]:.2f}', (xmin, ymin - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n\n    out.write(frame)\n\n# Phase 5: Cleanup\ncap.release()\nout.release()\ncv2.destroyAllWindows()",
        "last_error": "Max retries reached with failure. Last error from execution: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\nTraceback (most recent call last):\n  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250820035139_psg_qwen2.5-coder:14b/tmp_20250820035139_psg_qwen2.5-coder:14b.py\", line 61, in <module>\n    if scores[i] > confidence_threshold:\nValueError: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()\n"
      },
      "session_id": "qwen2.5-coder:14b_c83f_psg_batch",
      "metadata": {
        "num_run": 21
      },
      "tags": [
        "benchmark",
        "py_sketch_generator",
        "qwen2.5-coder:14b"
      ],
      "latency": 67.577,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-03-50-45-925314_chatcmpl-b3bc1181-292a-4300-8b88-63e95a026e1b",
          "traceId": "0c7d16f7",
          "type": "GENERATION",
          "name": "0c7d_psg_gen_attempt#1",
          "startTime": "2025-08-20T00:50:45.925000+00:00",
          "endTime": "2025-08-20T00:50:56.475000+00:00",
          "model": "qwen2.5-coder:14b",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 10550.0,
          "environment": "default",
          "promptTokens": 1618,
          "totalTokens": 2241,
          "costDetails": {},
          "completionTokens": 623,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-03-50-56-673227_chatcmpl-57d8a28f-74ce-4abe-9b48-20d3a4ef82af",
          "traceId": "0c7d16f7",
          "type": "GENERATION",
          "name": "0c7d_psg_gen_attempt#2",
          "startTime": "2025-08-20T00:50:56.673000+00:00",
          "endTime": "2025-08-20T00:51:10.669000+00:00",
          "model": "qwen2.5-coder:14b",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 13996.0,
          "environment": "default",
          "promptTokens": 2048,
          "totalTokens": 2881,
          "costDetails": {},
          "completionTokens": 833,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-03-51-11-035948_chatcmpl-62115b93-bc7a-4f7c-aede-dc94f2a21137",
          "traceId": "0c7d16f7",
          "type": "GENERATION",
          "name": "0c7d_psg_gen_attempt#3",
          "startTime": "2025-08-20T00:51:11.035000+00:00",
          "endTime": "2025-08-20T00:51:24.619000+00:00",
          "model": "qwen2.5-coder:14b",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 13584.0,
          "environment": "default",
          "promptTokens": 2048,
          "totalTokens": 2855,
          "costDetails": {},
          "completionTokens": 807,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-03-51-25-007418_chatcmpl-a8cfa8f5-18bc-4d2a-a451-155938bd0dbc",
          "traceId": "0c7d16f7",
          "type": "GENERATION",
          "name": "0c7d_psg_gen_attempt#4",
          "startTime": "2025-08-20T00:51:25.007000+00:00",
          "endTime": "2025-08-20T00:51:39.622000+00:00",
          "model": "qwen2.5-coder:14b",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 14615.0,
          "environment": "default",
          "promptTokens": 2048,
          "totalTokens": 2920,
          "costDetails": {},
          "completionTokens": 872,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-03-51-39-989463_chatcmpl-306cf026-60db-44ec-9aa9-23249d5f8f63",
          "traceId": "0c7d16f7",
          "type": "GENERATION",
          "name": "0c7d_psg_gen_attempt#5",
          "startTime": "2025-08-20T00:51:39.989000+00:00",
          "endTime": "2025-08-20T00:51:53.500000+00:00",
          "model": "qwen2.5-coder:14b",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 13511.0,
          "environment": "default",
          "promptTokens": 2048,
          "totalTokens": 2850,
          "costDetails": {},
          "completionTokens": 802,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "29082b66-8752-4a0f-9606-f5865162c33c",
          "traceId": "0c7d16f7",
          "type": "SPAN",
          "name": "error_0c_psg_failure_signal_py_sketch_generator",
          "startTime": "2025-08-20T00:51:53.502000+00:00",
          "level": "ERROR",
          "statusMessage": "Failed. Last error: Max retries reached with failure. Last error from execution: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\nTraceback (most recent call last):\n  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250820035139_psg_qwen2.5-coder:14b/tmp_20250820035139_psg_qwen2.5-coder:14b.py\", line 61, in <module>\n    if scores[i] > confidence_threshold:\nValueError: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()\n",
          "calculatedTotalCost": 0.0,
          "environment": "default",
          "promptTokens": 0,
          "totalTokens": 0,
          "costDetails": {},
          "completionTokens": 0,
          "endTime": null,
          "model": null,
          "modelParameters": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null,
          "latency": null
        }
      ],
      "createdAt": "2025-08-20T00:50:46.440Z",
      "environment": "default",
      "updatedAt": "2025-08-20T00:51:59.309Z"
    },
    {
      "id": "3ecf274a",
      "timestamp": "2025-08-20T00:49:41.997000+00:00",
      "name": "3ecf_py_sketch_generator",
      "input": null,
      "output": {
        "status": "success",
        "sketch": "import numpy as np\nimport cv2\nfrom tflite_runtime.interpreter import Interpreter\n\n# Phase 1: Setup\n# Paths/Parameters\nmodel_path   = \"models/ssd-mobilenet_v1/detect.tflite\"\nlabel_path   = \"models/ssd-mobilenet_v1/labelmap.txt\"\ninput_path   = \"data/object_detection/sheeps.mp4\"\noutput_path   = \"results/object_detection/test_results/sheeps_detections.mp4\"\nconfidence_threshold   = 0.5\n\n# Load Labels\nwith open(label_path, 'r') as f:\n    labels = [line.strip() for line in f.readlines()]\n\n# Load Interpreter\ninterpreter = Interpreter(model_path=model_path)\ninterpreter.allocate_tensors()\n\n# Get Model Details\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\n\n# Phase 2: Input Acquisition & Preprocessing Loop\ncap = cv2.VideoCapture(input_path)\n\nif not cap.isOpened():\n    raise ValueError(\"Could not open video file.\")\n\nfourcc = cv2.VideoWriter_fourcc(*'mp4v')\nout = cv2.VideoWriter(output_path, fourcc, 30.0, (int(cap.get(3)), int(cap.get(4))))\n\nwhile cap.isOpened():\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    # Preprocess Data\n    input_data = cv2.resize(frame, (input_details[0]['shape'][1], input_details[0]['shape'][2]))\n    input_data = input_data[:, :, ::-1].astype(np.float32)  # Convert to RGB and float32\n    input_data /= 127.5  # Normalize\n    input_data -= 1.0\n    input_data = np.expand_dims(input_data, axis=0)\n\n    if input_details[0]['dtype'] == np.uint8:\n        input_data = (input_data * 127.5).astype(np.uint8)  # Convert back to uint8\n\n    # Phase 3: Inference\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n    interpreter.invoke()\n\n    # Phase 4: Output Interpretation & Handling Loop\n    boxes = interpreter.get_tensor(output_details[0]['index'])[0]\n    classes = interpreter.get_tensor(output_details[1]['index'])[0]\n    scores = interpreter.get_tensor(output_details[2]['index'])[0]\n\n    for i in range(len(scores)):\n        if scores[i] > confidence_threshold:\n            y1, x1, y2, x2 = boxes[i]\n            y1, x1, y2, x2 = int(y1 * frame.shape[0]), int(x1 * frame.shape[1]), int(y2 * frame.shape[0]), int(x2 * frame.shape[1])\n            class_label = labels[int(classes[i])]\n            cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n            cv2.putText(frame, f'{class_label}: {scores[i]:.2f}', (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n\n    out.write(frame)\n\n# Phase 5: Cleanup\ncap.release()\nout.release()\ncv2.destroyAllWindows()"
      },
      "session_id": "qwen2.5-coder:14b_c83f_psg_batch",
      "metadata": {
        "num_run": 20
      },
      "tags": [
        "benchmark",
        "py_sketch_generator",
        "qwen2.5-coder:14b"
      ],
      "latency": 25.394,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-03-49-41-999282_chatcmpl-a1beea7c-b52f-4d38-9e66-5957b89b25af",
          "traceId": "3ecf274a",
          "type": "GENERATION",
          "name": "3ecf_psg_gen_attempt#1",
          "startTime": "2025-08-20T00:49:41.999000+00:00",
          "endTime": "2025-08-20T00:49:53.444000+00:00",
          "model": "qwen2.5-coder:14b",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 11445.0,
          "environment": "default",
          "promptTokens": 1618,
          "totalTokens": 2297,
          "costDetails": {},
          "completionTokens": 679,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-03-49-53-627788_chatcmpl-7a65f99f-3c47-414e-b1fc-ac13a95d9646",
          "traceId": "3ecf274a",
          "type": "GENERATION",
          "name": "3ecf_psg_gen_attempt#2",
          "startTime": "2025-08-20T00:49:53.627000+00:00",
          "endTime": "2025-08-20T00:50:07.393000+00:00",
          "model": "qwen2.5-coder:14b",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 13766.0,
          "environment": "default",
          "promptTokens": 2048,
          "totalTokens": 2867,
          "costDetails": {},
          "completionTokens": 819,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        }
      ],
      "createdAt": "2025-08-20T00:49:42.513Z",
      "environment": "default",
      "updatedAt": "2025-08-20T00:50:45.249Z"
    },
    {
      "id": "ca9fc646",
      "timestamp": "2025-08-20T00:48:28.242000+00:00",
      "name": "ca9f_py_sketch_generator",
      "input": null,
      "output": {
        "status": "success",
        "sketch": "import numpy as np\nimport cv2\nfrom tflite_runtime.interpreter import Interpreter\n\n# Phase 1: Setup\nmodel_path    = \"models/ssd-mobilenet_v1/detect.tflite\"\nlabel_path    = \"models/ssd-mobilenet_v1/labelmap.txt\"\ninput_path    = \"data/object_detection/sheeps.mp4\"\noutput_path    = \"results/object_detection/test_results/sheeps_detections.mp4\"\nconfidence_threshold    = 0.5\n\n# Load Labels\nwith open(label_path, 'r') as f:\n    labels = [line.strip() for line in f.readlines()]\n\n# Load Interpreter\ninterpreter = Interpreter(model_path=model_path)\ninterpreter.allocate_tensors()\n\n# Get Model Details\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\n\n# Phase 2: Input Acquisition & Preprocessing Loop\ncap = cv2.VideoCapture(input_path)\nfourcc = cv2.VideoWriter_fourcc(*'mp4v')\nout = cv2.VideoWriter(output_path, fourcc, 30.0, (int(cap.get(3)), int(cap.get(4))))\n\nwhile cap.isOpened():\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    # Preprocess Data\n    input_data = cv2.resize(frame, (input_details[0]['shape'][1], input_details[0]['shape'][2]))\n    input_data = np.expand_dims(input_data, axis=0)\n    input_data = input_data.astype(input_details[0]['dtype'])\n\n    # Phase 3: Inference\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n    interpreter.invoke()\n\n    # Phase 4: Output Interpretation & Handling Loop\n    boxes = interpreter.get_tensor(output_details[0]['index'])[0]\n    classes = interpreter.get_tensor(output_details[1]['index'])[0].astype(np.int32)\n    scores = interpreter.get_tensor(output_details[2]['index'])[0]\n\n    for i in range(len(scores)):\n        if scores[i] > confidence_threshold:\n            (ymin, xmin, ymax, xmax) = boxes[i]\n            label = labels[classes[i]]\n            cv2.rectangle(frame, (int(xmin * frame.shape[1]), int(ymin * frame.shape[0])),\n                           (int(xmax * frame.shape[1]), int(ymax * frame.shape[0])), (0, 255, 0), 2)\n            cv2.putText(frame, f'{label}: {scores[i]:.2f}', (int(xmin * frame.shape[1]), int(ymin * frame.shape[0]) - 10),\n                        cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n\n    out.write(frame)\n\n# Phase 5: Cleanup\ncap.release()\nout.release()\ncv2.destroyAllWindows()"
      },
      "session_id": "qwen2.5-coder:14b_c83f_psg_batch",
      "metadata": {
        "num_run": 19
      },
      "tags": [
        "benchmark",
        "py_sketch_generator",
        "qwen2.5-coder:14b"
      ],
      "latency": 35.643,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-03-48-28-243518_chatcmpl-748eabf9-3dc8-4784-be6d-6f843f5f4e02",
          "traceId": "ca9fc646",
          "type": "GENERATION",
          "name": "ca9f_psg_gen_attempt#1",
          "startTime": "2025-08-20T00:48:28.243000+00:00",
          "endTime": "2025-08-20T00:48:38.434000+00:00",
          "model": "qwen2.5-coder:14b",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 10191.0,
          "environment": "default",
          "promptTokens": 1618,
          "totalTokens": 2217,
          "costDetails": {},
          "completionTokens": 599,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-03-48-38-812977_chatcmpl-c6627de2-2243-44ae-8661-03d947805d4d",
          "traceId": "ca9fc646",
          "type": "GENERATION",
          "name": "ca9f_psg_gen_attempt#2",
          "startTime": "2025-08-20T00:48:38.812000+00:00",
          "endTime": "2025-08-20T00:48:51.806000+00:00",
          "model": "qwen2.5-coder:14b",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 12994.0,
          "environment": "default",
          "promptTokens": 2048,
          "totalTokens": 2817,
          "costDetails": {},
          "completionTokens": 769,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-03-48-52-181081_chatcmpl-0419a2b3-e2dc-4c14-a8ae-f6ebbe07c562",
          "traceId": "ca9fc646",
          "type": "GENERATION",
          "name": "ca9f_psg_gen_attempt#3",
          "startTime": "2025-08-20T00:48:52.181000+00:00",
          "endTime": "2025-08-20T00:49:03.886000+00:00",
          "model": "qwen2.5-coder:14b",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 11705.0,
          "environment": "default",
          "promptTokens": 2048,
          "totalTokens": 2735,
          "costDetails": {},
          "completionTokens": 687,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        }
      ],
      "createdAt": "2025-08-20T00:48:28.758Z",
      "environment": "default",
      "updatedAt": "2025-08-20T00:49:41.422Z"
    },
    {
      "id": "c7f29867",
      "timestamp": "2025-08-20T00:47:16.403000+00:00",
      "name": "c7f2_py_sketch_generator",
      "input": null,
      "output": {
        "status": "failed",
        "last_code": "import numpy as np\nimport cv2\nfrom tflite_runtime.interpreter import Interpreter\n\n# Phase 1: Setup\nmodel_path  = \"models/ssd-mobilenet_v1/detect.tflite\"\nlabel_path  = \"models/ssd-mobilenet_v1/labelmap.txt\"\ninput_path  = \"data/object_detection/sheeps.mp4\"\noutput_path  = \"results/object_detection/test_results/sheeps_detections.mp4\"\nconfidence_threshold  = 0.5\n\n# Load Labels\nwith open(label_path, 'r') as f:\n    labels = [line.strip() for line in f.readlines()]\n\n# Load Interpreter\ninterpreter = Interpreter(model_path=model_path)\ninterpreter.allocate_tensors()\n\n# Get Model Details\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\n\ninput_shape = input_details[0]['shape']\ninput_dtype = input_details[0]['dtype']\n\n# Phase 2: Input Acquisition & Preprocessing Loop\ncap = cv2.VideoCapture(input_path)\nfourcc = cv2.VideoWriter_fourcc(*'mp4v')\nout = cv2.VideoWriter(output_path, fourcc, cap.get(cv2.CAP_PROP_FPS), \n                      (int(cap.get(cv2.CAP_PROP_FRAME_WIDTH)), int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))))\n\nwhile cap.isOpened():\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    # Preprocess Data\n    input_data = cv2.resize(frame, (input_shape[1], input_shape[2]))\n    input_data = cv2.cvtColor(input_data, cv2.COLOR_BGR2RGB)\n    input_data = np.expand_dims(input_data, axis=0).astype(input_dtype)\n\n    # Phase 3: Inference\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n    interpreter.invoke()\n\n    # Phase 4: Output Interpretation & Handling Loop\n    # Get Output Tensor(s)\n    boxes = interpreter.get_tensor(output_details[1]['index'])[0]  # Bounding boxes\n    classes = interpreter.get_tensor(output_details[3]['index'])[0]  # Class indices\n    scores = interpreter.get_tensor(output_details[0]['index'])[0]   # Confidence scores\n\n    for i in range(len(scores)):\n        if scores[i] > confidence_threshold:\n            class_name = labels[int(classes[i])]\n            box = boxes[i]\n            ymin, xmin, ymax, xmax = box\n            h, w, _ = frame.shape\n            xmin = int(xmin * w)\n            ymin = int(ymin * h)\n            xmax = int(xmax * w)\n            ymax = int(ymax * h)\n\n            cv2.rectangle(frame, (xmin, ymin), (xmax, ymax), (0, 255, 0), 2)\n            cv2.putText(frame, f'{class_name}: {scores[i]:.2f}', (xmin, ymin - 10), \n                        cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n\n    out.write(frame)\n\n# Phase 5: Cleanup\ncap.release()\nout.release()\ncv2.destroyAllWindows()",
        "last_error": "Max retries reached with failure. Last error from execution: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\nTraceback (most recent call last):\n  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250820034821_psg_qwen2.5-coder:14b/tmp_20250820034821_psg_qwen2.5-coder:14b.py\", line 54, in <module>\n    if scores[i] > confidence_threshold:\nValueError: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()\n"
      },
      "session_id": "qwen2.5-coder:14b_c83f_psg_batch",
      "metadata": {
        "num_run": 18
      },
      "tags": [
        "benchmark",
        "py_sketch_generator",
        "qwen2.5-coder:14b"
      ],
      "latency": 65.521,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-03-47-16-405501_chatcmpl-41cbd217-37d9-43bb-b420-bc06470ecc78",
          "traceId": "c7f29867",
          "type": "GENERATION",
          "name": "c7f2_psg_gen_attempt#1",
          "startTime": "2025-08-20T00:47:16.405000+00:00",
          "endTime": "2025-08-20T00:47:27.460000+00:00",
          "model": "qwen2.5-coder:14b",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 11055.0,
          "environment": "default",
          "promptTokens": 1618,
          "totalTokens": 2272,
          "costDetails": {},
          "completionTokens": 654,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-03-47-27-837979_chatcmpl-b638680d-4122-45ea-86cb-107c5ffb995f",
          "traceId": "c7f29867",
          "type": "GENERATION",
          "name": "c7f2_psg_gen_attempt#2",
          "startTime": "2025-08-20T00:47:27.837000+00:00",
          "endTime": "2025-08-20T00:47:41.814000+00:00",
          "model": "qwen2.5-coder:14b",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 13977.0,
          "environment": "default",
          "promptTokens": 2048,
          "totalTokens": 2879,
          "costDetails": {},
          "completionTokens": 831,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-03-47-42-193154_chatcmpl-d8d44aae-47ad-4b85-b925-27ab3b0efe57",
          "traceId": "c7f29867",
          "type": "GENERATION",
          "name": "c7f2_psg_gen_attempt#3",
          "startTime": "2025-08-20T00:47:42.193000+00:00",
          "endTime": "2025-08-20T00:47:55.044000+00:00",
          "model": "qwen2.5-coder:14b",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 12851.0,
          "environment": "default",
          "promptTokens": 2048,
          "totalTokens": 2806,
          "costDetails": {},
          "completionTokens": 758,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-03-47-55-421168_chatcmpl-6ba905dc-2d3c-4584-a688-afd2ec67612b",
          "traceId": "c7f29867",
          "type": "GENERATION",
          "name": "c7f2_psg_gen_attempt#4",
          "startTime": "2025-08-20T00:47:55.421000+00:00",
          "endTime": "2025-08-20T00:48:08.768000+00:00",
          "model": "qwen2.5-coder:14b",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 13347.0,
          "environment": "default",
          "promptTokens": 2048,
          "totalTokens": 2839,
          "costDetails": {},
          "completionTokens": 791,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-03-48-09-136949_chatcmpl-1bc405d6-6241-4669-a811-4c413ce026ac",
          "traceId": "c7f29867",
          "type": "GENERATION",
          "name": "c7f2_psg_gen_attempt#5",
          "startTime": "2025-08-20T00:48:09.136000+00:00",
          "endTime": "2025-08-20T00:48:21.559000+00:00",
          "model": "qwen2.5-coder:14b",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 12423.0,
          "environment": "default",
          "promptTokens": 2048,
          "totalTokens": 2781,
          "costDetails": {},
          "completionTokens": 733,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "591a6e0b-1f2f-4e48-a528-85d7e203e352",
          "traceId": "c7f29867",
          "type": "SPAN",
          "name": "error_c7_psg_failure_signal_py_sketch_generator",
          "startTime": "2025-08-20T00:48:21.926000+00:00",
          "level": "ERROR",
          "statusMessage": "Failed. Last error: Max retries reached with failure. Last error from execution: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\nTraceback (most recent call last):\n  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250820034821_psg_qwen2.5-coder:14b/tmp_20250820034821_psg_qwen2.5-coder:14b.py\", line 54, in <module>\n    if scores[i] > confidence_threshold:\nValueError: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()\n",
          "calculatedTotalCost": 0.0,
          "environment": "default",
          "promptTokens": 0,
          "totalTokens": 0,
          "costDetails": {},
          "completionTokens": 0,
          "endTime": null,
          "model": null,
          "modelParameters": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null,
          "latency": null
        }
      ],
      "createdAt": "2025-08-20T00:47:16.923Z",
      "environment": "default",
      "updatedAt": "2025-08-20T00:48:27.059Z"
    },
    {
      "id": "120d4427",
      "timestamp": "2025-08-20T00:46:00.685000+00:00",
      "name": "120d_py_sketch_generator",
      "input": null,
      "output": {
        "status": "success",
        "sketch": "import numpy as np\nimport cv2\n\n# Configuration Parameters\nmodel_path     = \"models/ssd-mobilenet_v1/detect.tflite\"\nlabel_path     = \"models/ssd-mobilenet_v1/labelmap.txt\"\ninput_path     = \"data/object_detection/sheeps.mp4\"\noutput_path     = \"results/object_detection/test_results/sheeps_detections.mp4\"\nconfidence_threshold     = 0.5\n\n# Load labels\nwith open(label_path, 'r') as f:\n    labels = [line.strip() for line in f.readlines()]\n\n# Load TFLite model and allocate tensors\nimport tensorflow as tf\ninterpreter = tf.lite.Interpreter(model_path=model_path)\ninterpreter.allocate_tensors()\n\n# Get input and output tensors details\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\n\n# Open video file\ncap = cv2.VideoCapture(input_path)\n\n# Define the codec and create VideoWriter object\nfourcc = cv2.VideoWriter_fourcc(*'mp4v')\nout = cv2.VideoWriter(output_path, fourcc, 30.0, (int(cap.get(3)), int(cap.get(4))))\n\nwhile cap.isOpened():\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    # Resize the frame to the expected input size of the model\n    frame_resized = cv2.resize(frame, (input_details[0]['shape'][1], input_details[0]['shape'][2]))\n\n    # Preprocess the frame\n    input_data = np.expand_dims(frame_resized, axis=0)\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n    interpreter.invoke()\n\n    # Get output tensors\n    boxes = interpreter.get_tensor(output_details[0]['index'])[0]\n    classes = interpreter.get_tensor(output_details[1]['index'])[0].astype(np.int32)\n    scores = interpreter.get_tensor(output_details[2]['index'])[0]\n\n    # Post-process the output\n    for i in range(len(scores)):\n        if scores[i] > confidence_threshold:\n            label = labels[classes[i]]\n            ymin, xmin, ymax, xmax = boxes[i]\n            (left, right, top, bottom) = (xmin * frame.shape[1], xmax * frame.shape[1],\n                                         ymin * frame.shape[0], ymax * frame.shape[0])\n            cv2.rectangle(frame, (int(left), int(top)), (int(right), int(bottom)), (0, 255, 0), 2)\n            cv2.putText(frame, f'{label}: {scores[i]:.2f}', (int(left), int(top) - 10),\n                        cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n\n    # Write the frame to the output file\n    out.write(frame)\n\n# Release everything when done\ncap.release()\nout.release()\ncv2.destroyAllWindows()"
      },
      "session_id": "qwen2.5-coder:14b_c83f_psg_batch",
      "metadata": {
        "num_run": 17
      },
      "tags": [
        "benchmark",
        "py_sketch_generator",
        "qwen2.5-coder:14b"
      ],
      "latency": 60.763,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-03-46-00-686921_chatcmpl-f15c09b5-b494-4c4b-a844-365aef57a29e",
          "traceId": "120d4427",
          "type": "GENERATION",
          "name": "120d_psg_gen_attempt#1",
          "startTime": "2025-08-20T00:46:00.686000+00:00",
          "endTime": "2025-08-20T00:46:10.381000+00:00",
          "model": "qwen2.5-coder:14b",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 9695.0,
          "environment": "default",
          "promptTokens": 1618,
          "totalTokens": 2185,
          "costDetails": {},
          "completionTokens": 567,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-03-46-10-541245_chatcmpl-d7b9ed39-4f85-4a3f-9972-84a54ff1f8fb",
          "traceId": "120d4427",
          "type": "GENERATION",
          "name": "120d_psg_gen_attempt#2",
          "startTime": "2025-08-20T00:46:10.541000+00:00",
          "endTime": "2025-08-20T00:46:21.836000+00:00",
          "model": "qwen2.5-coder:14b",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 11295.0,
          "environment": "default",
          "promptTokens": 2048,
          "totalTokens": 2709,
          "costDetails": {},
          "completionTokens": 661,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-03-46-21-985186_chatcmpl-6e7c0ebf-435f-4195-a6fd-35cb6b429340",
          "traceId": "120d4427",
          "type": "GENERATION",
          "name": "120d_psg_gen_attempt#3",
          "startTime": "2025-08-20T00:46:21.985000+00:00",
          "endTime": "2025-08-20T00:46:33.292000+00:00",
          "model": "qwen2.5-coder:14b",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 11307.0,
          "environment": "default",
          "promptTokens": 2048,
          "totalTokens": 2710,
          "costDetails": {},
          "completionTokens": 662,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-03-46-33-440185_chatcmpl-b69f65c6-e97c-422a-845a-67ab8f271c5c",
          "traceId": "120d4427",
          "type": "GENERATION",
          "name": "120d_psg_gen_attempt#4",
          "startTime": "2025-08-20T00:46:33.440000+00:00",
          "endTime": "2025-08-20T00:46:44.419000+00:00",
          "model": "qwen2.5-coder:14b",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 10979.0,
          "environment": "default",
          "promptTokens": 2048,
          "totalTokens": 2689,
          "costDetails": {},
          "completionTokens": 641,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-03-46-47-939346_chatcmpl-5df3ccc6-50b5-431c-be61-5d4eba56bad2",
          "traceId": "120d4427",
          "type": "GENERATION",
          "name": "120d_psg_gen_attempt#5",
          "startTime": "2025-08-20T00:46:47.939000+00:00",
          "endTime": "2025-08-20T00:47:01.449000+00:00",
          "model": "qwen2.5-coder:14b",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 13510.0,
          "environment": "default",
          "promptTokens": 2048,
          "totalTokens": 2849,
          "costDetails": {},
          "completionTokens": 801,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        }
      ],
      "createdAt": "2025-08-20T00:46:01.205Z",
      "environment": "default",
      "updatedAt": "2025-08-20T00:47:15.906Z"
    },
    {
      "id": "f0aaeb14",
      "timestamp": "2025-08-20T00:44:58.957000+00:00",
      "name": "f0aa_py_sketch_generator",
      "input": null,
      "output": {
        "status": "success",
        "sketch": "import numpy as np\nimport cv2\nfrom tflite_runtime.interpreter import Interpreter\n\n# Phase 1: Setup\n# Define necessary variables\nmodel_path  = \"models/ssd-mobilenet_v1/detect.tflite\"\nlabel_path  = \"models/ssd-mobilenet_v1/labelmap.txt\"\ninput_path  = \"data/object_detection/sheeps.mp4\"\noutput_path  = \"results/object_detection/test_results/sheeps_detections.mp4\"\nconfidence_threshold  = 0.5\n\n# Load labels\nwith open(label_path, 'r') as f:\n    labels = [line.strip() for line in f.readlines()]\n\n# Load Interpreter\ninterpreter = Interpreter(model_path=model_path)\ninterpreter.allocate_tensors()\n\n# Get Model Details\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\n\n# Phase 2: Input Acquisition & Preprocessing Loop\ncap = cv2.VideoCapture(input_path)\n\nif not cap.isOpened():\n    raise ValueError(\"Could not open video file\")\n\nfourcc = cv2.VideoWriter_fourcc(*'mp4v')\nout = cv2.VideoWriter(output_path, fourcc, cap.get(cv2.CAP_PROP_FPS), (int(cap.get(cv2.CAP_PROP_FRAME_WIDTH)), int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))))\n\nwhile True:\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    # Preprocess Data\n    input_data = cv2.resize(frame, (300, 300))\n    input_data = np.expand_dims(input_data, axis=0)\n    input_data = input_data.astype(np.uint8)  # Change to UINT8\n\n    # Phase 3: Inference\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n    interpreter.invoke()\n\n    # Phase 4: Output Interpretation & Handling Loop\n    boxes = interpreter.get_tensor(output_details[0]['index'])[0]  # Bounding boxes\n    classes = interpreter.get_tensor(output_details[1]['index'])[0]  # Class indices\n    scores = interpreter.get_tensor(output_details[2]['index'])[0]   # Confidence scores\n\n    for i in range(len(scores)):\n        if scores[i] > confidence_threshold:\n            class_id = int(classes[i])\n            box = boxes[i]\n            x_min, y_min, x_max, y_max = [int(x) for x in box * np.array([frame.shape[1], frame.shape[0], frame.shape[1], frame.shape[0]])]\n\n            label = f'{labels[class_id]}: {scores[i]:.2f}'\n            cv2.rectangle(frame, (x_min, y_min), (x_max, y_max), (0, 255, 0), 2)\n            cv2.putText(frame, label, (x_min, y_min - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n\n    out.write(frame)\n\ncap.release()\nout.release()"
      },
      "session_id": "qwen2.5-coder:14b_c83f_psg_batch",
      "metadata": {
        "num_run": 16
      },
      "tags": [
        "benchmark",
        "py_sketch_generator",
        "qwen2.5-coder:14b"
      ],
      "latency": 24.101,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-03-44-58-959213_chatcmpl-1f85f719-3c38-438c-aa12-fa9963ba5292",
          "traceId": "f0aaeb14",
          "type": "GENERATION",
          "name": "f0aa_psg_gen_attempt#1",
          "startTime": "2025-08-20T00:44:58.959000+00:00",
          "endTime": "2025-08-20T00:45:09.781000+00:00",
          "model": "qwen2.5-coder:14b",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 10822.0,
          "environment": "default",
          "promptTokens": 1618,
          "totalTokens": 2257,
          "costDetails": {},
          "completionTokens": 639,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-03-45-09-967041_chatcmpl-66617d12-164d-4378-a5e1-2544957e079f",
          "traceId": "f0aaeb14",
          "type": "GENERATION",
          "name": "f0aa_psg_gen_attempt#2",
          "startTime": "2025-08-20T00:45:09.967000+00:00",
          "endTime": "2025-08-20T00:45:23.060000+00:00",
          "model": "qwen2.5-coder:14b",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 13093.0,
          "environment": "default",
          "promptTokens": 2048,
          "totalTokens": 2824,
          "costDetails": {},
          "completionTokens": 776,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        }
      ],
      "createdAt": "2025-08-20T00:44:59.477Z",
      "environment": "default",
      "updatedAt": "2025-08-20T00:46:00.131Z"
    },
    {
      "id": "80240ce9",
      "timestamp": "2025-08-20T00:44:01.061000+00:00",
      "name": "8024_py_sketch_generator",
      "input": null,
      "output": {
        "status": "success",
        "sketch": "import numpy as np\nimport cv2\n\n# Phase 1: Setup\nmodel_path    = \"models/ssd-mobilenet_v1/detect.tflite\"\nlabel_path    = \"models/ssd-mobilenet_v1/labelmap.txt\"\ninput_path    = \"data/object_detection/sheeps.mp4\"\noutput_path    = \"results/object_detection/test_results/sheeps_detections.mp4\"\nconfidence_threshold    = 0.5\n\n# Load Labels\nwith open(label_path, 'r') as f:\n    labels = [line.strip() for line in f.readlines()]\n\n# Load Interpreter\nimport tensorflow as tf\ninterpreter = tf.lite.Interpreter(model_path=model_path)\ninterpreter.allocate_tensors()\n\n# Get Model Details\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\n\ninput_shape = input_details[0]['shape']\ninput_dtype = input_details[0]['dtype']\n\n# Phase 2: Input Acquisition & Preprocessing Loop\ncap = cv2.VideoCapture(input_path)\nfourcc = cv2.VideoWriter_fourcc(*'mp4v')\nout = cv2.VideoWriter(output_path, fourcc, cap.get(cv2.CAP_PROP_FPS), (int(cap.get(cv2.CAP_PROP_FRAME_WIDTH)), int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))))\n\nwhile cap.isOpened():\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    # Preprocess Data\n    input_data = cv2.resize(frame, (input_shape[1], input_shape[2]))\n    input_data = input_data.reshape((1,) + input_data.shape)\n    input_data = input_data.astype(input_dtype)  # Ensure the dtype matches the model's expected input type\n\n    # Phase 3: Inference\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n    interpreter.invoke()\n\n    # Phase 4: Output Interpretation & Handling Loop\n    boxes = interpreter.get_tensor(output_details[0]['index'])[0]  # shape: (num_boxes, 4)\n    classes = interpreter.get_tensor(output_details[1]['index'])[0]  # shape: (num_boxes,)\n    scores = interpreter.get_tensor(output_details[2]['index'])[0]  # shape: (num_boxes,)\n\n    for i in range(len(scores)):\n        if scores[i] > confidence_threshold:\n            ymin, xmin, ymax, xmax = boxes[i]\n            label = labels[int(classes[i])]\n            cv2.rectangle(frame, (int(xmin * frame.shape[1]), int(ymin * frame.shape[0])), \n                          (int(xmax * frame.shape[1]), int(ymax * frame.shape[0])), (0, 255, 0), 2)\n            cv2.putText(frame, f'{label}: {scores[i]:.2f}', \n                        (int(xmin * frame.shape[1]), int(ymin * frame.shape[0]) - 10), \n                        cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n\n    # Handle Output\n    out.write(frame)\n\n# Phase 5: Cleanup\ncap.release()\nout.release()\ncv2.destroyAllWindows()"
      },
      "session_id": "qwen2.5-coder:14b_c83f_psg_batch",
      "metadata": {
        "num_run": 15
      },
      "tags": [
        "benchmark",
        "py_sketch_generator",
        "qwen2.5-coder:14b"
      ],
      "latency": 42.274,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-03-44-01-063511_chatcmpl-a2fc76f6-f563-45ab-b034-0fb12758b936",
          "traceId": "80240ce9",
          "type": "GENERATION",
          "name": "8024_psg_gen_attempt#1",
          "startTime": "2025-08-20T00:44:01.063000+00:00",
          "endTime": "2025-08-20T00:44:12.253000+00:00",
          "model": "qwen2.5-coder:14b",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 11190.0,
          "environment": "default",
          "promptTokens": 1618,
          "totalTokens": 2275,
          "costDetails": {},
          "completionTokens": 657,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-03-44-12-410981_chatcmpl-95351b57-4b20-4a8d-9c74-2ba5131f8ead",
          "traceId": "80240ce9",
          "type": "GENERATION",
          "name": "8024_psg_gen_attempt#2",
          "startTime": "2025-08-20T00:44:12.410000+00:00",
          "endTime": "2025-08-20T00:44:25.012000+00:00",
          "model": "qwen2.5-coder:14b",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 12602.0,
          "environment": "default",
          "promptTokens": 2048,
          "totalTokens": 2792,
          "costDetails": {},
          "completionTokens": 744,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-03-44-28-953725_chatcmpl-8e6ed267-1b73-4854-8a65-2640c5f6dde4",
          "traceId": "80240ce9",
          "type": "GENERATION",
          "name": "8024_psg_gen_attempt#3",
          "startTime": "2025-08-20T00:44:28.953000+00:00",
          "endTime": "2025-08-20T00:44:43.337000+00:00",
          "model": "qwen2.5-coder:14b",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 14384.0,
          "environment": "default",
          "promptTokens": 2048,
          "totalTokens": 2905,
          "costDetails": {},
          "completionTokens": 857,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        }
      ],
      "createdAt": "2025-08-20T00:44:01.579Z",
      "environment": "default",
      "updatedAt": "2025-08-20T00:44:58.216Z"
    },
    {
      "id": "1fd89e23",
      "timestamp": "2025-08-20T00:42:52.997000+00:00",
      "name": "1fd8_py_sketch_generator",
      "input": null,
      "output": {
        "status": "failed",
        "last_code": "import numpy as np\nimport cv2\n\n# Import TensorFlow Lite interpreter\nfrom tflite_runtime.interpreter import Interpreter\n\n# Phase 1: Setup\nmodel_path    = \"models/ssd-mobilenet_v1/detect.tflite\"\nlabel_path    = \"models/ssd-mobilenet_v1/labelmap.txt\"\ninput_path    = \"data/object_detection/sheeps.mp4\"\noutput_path    = \"results/object_detection/test_results/sheeps_detections.mp4\"\nconfidence_threshold    = 0.5\n\n# Load labels\nwith open(label_path, 'r') as f:\n    labels = [line.strip() for line in f.readlines()]\n\n# Load interpreter and allocate tensors\ninterpreter = Interpreter(model_path=model_path)\ninterpreter.allocate_tensors()\n\n# Get model details\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\n\n# Phase 2: Input Acquisition & Preprocessing Loop\ncap = cv2.VideoCapture(input_path)\nfourcc = cv2.VideoWriter_fourcc(*'mp4v')\nout = cv2.VideoWriter(output_path, fourcc, 30.0, (int(cap.get(3)), int(cap.get(4))))\n\nwhile cap.isOpened():\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    # Preprocess data\n    input_data = cv2.resize(frame, (input_details[0]['shape'][1], input_details[0]['shape'][2]))\n    input_data = input_data.reshape((1,) + input_data.shape)\n    input_data = (input_data - 127.5) / 127.5\n    input_data = np.array(input_data, dtype=input_details[0]['dtype'])\n\n    # Phase 3: Inference\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n    interpreter.invoke()\n\n    # Phase 4: Output Interpretation & Handling Loop\n    # Get output tensors\n    boxes = interpreter.get_tensor(output_details[1]['index'])[0]  # Assuming index 1 is for boxes\n    classes = interpreter.get_tensor(output_details[3]['index'])[0]  # Assuming index 3 is for classes\n    scores = interpreter.get_tensor(output_details[0]['index'])[0]   # Assuming index 0 is for scores\n\n    for i in range(len(scores)):\n        if scores[i] > confidence_threshold:\n            class_name = labels[int(classes[i])]\n            box = boxes[i]\n            y1, x1, y2, x2 = int(box[0] * frame.shape[0]), int(box[1] * frame.shape[1]), int(box[2] * frame.shape[0]), int(box[3] * frame.shape[1])\n            cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n            cv2.putText(frame, f'{class_name}: {scores[i]:.2f}', (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n\n    # Handle Output\n    out.write(frame)\n\n# Phase 5: Cleanup\ncap.release()\nout.release()\ncv2.destroyAllWindows()",
        "last_error": "Max retries reached with failure. Last error from execution: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\nTraceback (most recent call last):\n  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250820034354_psg_qwen2.5-coder:14b/tmp_20250820034354_psg_qwen2.5-coder:14b.py\", line 53, in <module>\n    if scores[i] > confidence_threshold:\nValueError: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()\n"
      },
      "session_id": "qwen2.5-coder:14b_c83f_psg_batch",
      "metadata": {
        "num_run": 14
      },
      "tags": [
        "benchmark",
        "py_sketch_generator",
        "qwen2.5-coder:14b"
      ],
      "latency": 61.542,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-03-42-52-999848_chatcmpl-9123e2c0-7704-4fb8-b952-e8f203736dcd",
          "traceId": "1fd89e23",
          "type": "GENERATION",
          "name": "1fd8_psg_gen_attempt#1",
          "startTime": "2025-08-20T00:42:52.999000+00:00",
          "endTime": "2025-08-20T00:43:03.962000+00:00",
          "model": "qwen2.5-coder:14b",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 10963.0,
          "environment": "default",
          "promptTokens": 1618,
          "totalTokens": 2257,
          "costDetails": {},
          "completionTokens": 639,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-03-43-04-168360_chatcmpl-cb6f5fb3-15ea-4c6a-a724-558d9a45b79a",
          "traceId": "1fd89e23",
          "type": "GENERATION",
          "name": "1fd8_psg_gen_attempt#2",
          "startTime": "2025-08-20T00:43:04.168000+00:00",
          "endTime": "2025-08-20T00:43:16.184000+00:00",
          "model": "qwen2.5-coder:14b",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 12016.0,
          "environment": "default",
          "promptTokens": 2048,
          "totalTokens": 2754,
          "costDetails": {},
          "completionTokens": 706,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-03-43-16-194699_chatcmpl-a588c8b8-1d6f-499f-a00b-5d25666e9a04",
          "traceId": "1fd89e23",
          "type": "GENERATION",
          "name": "1fd8_psg_gen_attempt#3",
          "startTime": "2025-08-20T00:43:16.194000+00:00",
          "endTime": "2025-08-20T00:43:28.759000+00:00",
          "model": "qwen2.5-coder:14b",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 12565.0,
          "environment": "default",
          "promptTokens": 2048,
          "totalTokens": 2790,
          "costDetails": {},
          "completionTokens": 742,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-03-43-28-912544_chatcmpl-c074a347-907d-4d0a-808b-4713c937f93c",
          "traceId": "1fd89e23",
          "type": "GENERATION",
          "name": "1fd8_psg_gen_attempt#4",
          "startTime": "2025-08-20T00:43:28.912000+00:00",
          "endTime": "2025-08-20T00:43:41.694000+00:00",
          "model": "qwen2.5-coder:14b",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 12782.0,
          "environment": "default",
          "promptTokens": 2048,
          "totalTokens": 2804,
          "costDetails": {},
          "completionTokens": 756,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-03-43-41-845271_chatcmpl-a62c48db-7c7d-49ae-be6a-72287ffae431",
          "traceId": "1fd89e23",
          "type": "GENERATION",
          "name": "1fd8_psg_gen_attempt#5",
          "startTime": "2025-08-20T00:43:41.845000+00:00",
          "endTime": "2025-08-20T00:43:54.168000+00:00",
          "model": "qwen2.5-coder:14b",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 12323.0,
          "environment": "default",
          "promptTokens": 2048,
          "totalTokens": 2775,
          "costDetails": {},
          "completionTokens": 727,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "17d14e93-7309-4611-b670-f3458e1af6cf",
          "traceId": "1fd89e23",
          "type": "SPAN",
          "name": "error_1f_psg_failure_signal_py_sketch_generator",
          "startTime": "2025-08-20T00:43:54.541000+00:00",
          "level": "ERROR",
          "statusMessage": "Failed. Last error: Max retries reached with failure. Last error from execution: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\nTraceback (most recent call last):\n  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250820034354_psg_qwen2.5-coder:14b/tmp_20250820034354_psg_qwen2.5-coder:14b.py\", line 53, in <module>\n    if scores[i] > confidence_threshold:\nValueError: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()\n",
          "calculatedTotalCost": 0.0,
          "environment": "default",
          "promptTokens": 0,
          "totalTokens": 0,
          "costDetails": {},
          "completionTokens": 0,
          "endTime": null,
          "model": null,
          "modelParameters": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null,
          "latency": null
        }
      ],
      "createdAt": "2025-08-20T00:42:53.517Z",
      "environment": "default",
      "updatedAt": "2025-08-20T00:43:59.616Z"
    },
    {
      "id": "894c25d7",
      "timestamp": "2025-08-20T00:41:40.714000+00:00",
      "name": "894c_py_sketch_generator",
      "input": null,
      "output": {
        "status": "failed",
        "last_code": "import numpy as np\nimport cv2\nfrom tflite_runtime.interpreter import Interpreter\n\n# Configuration Parameters\nmodel_path   = \"models/ssd-mobilenet_v1/detect.tflite\"\nlabel_path   = \"models/ssd-mobilenet_v1/labelmap.txt\"\ninput_path   = \"data/object_detection/sheeps.mp4\"\noutput_path   = \"results/object_detection/test_results/sheeps_detections.mp4\"\nconfidence_threshold   = 0.5\n\n# Load Labels\nwith open(label_path, 'r') as f:\n    labels = [line.strip() for line in f.readlines()]\n\n# Load Interpreter\ninterpreter = Interpreter(model_path=model_path)\ninterpreter.allocate_tensors()\n\n# Get Model Details\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\n\n# Open Video File\ncap = cv2.VideoCapture(input_path)\nfourcc = cv2.VideoWriter_fourcc(*'mp4v')\nout = cv2.VideoWriter(output_path, fourcc, cap.get(cv2.CAP_PROP_FPS), (int(cap.get(cv2.CAP_PROP_FRAME_WIDTH)), int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))))\n\nwhile True:\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    # Preprocess Data\n    input_data = cv2.resize(frame, (input_details[0]['shape'][1], input_details[0]['shape'][2]))\n    input_data = np.expand_dims(input_data, axis=0)\n    input_data = input_data.astype(input_details[0]['dtype'])  # Ensure correct data type\n\n    # Set Input Tensor\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n\n    # Run Inference\n    interpreter.invoke()\n\n    # Get Output Tensor(s)\n    boxes = interpreter.get_tensor(output_details[0]['index'])[0]  # Correctly index the output tensor\n    classes = interpreter.get_tensor(output_details[1]['index']).astype(int)\n    scores = interpreter.get_tensor(output_details[2]['index'])\n\n    # Interpret Results\n    for i in range(len(scores)):\n        if scores[i] > confidence_threshold:\n            (ymin, xmin, ymax, xmax) = boxes[i]\n            ymin = int(ymin * frame.shape[0])\n            xmin = int(xmin * frame.shape[1])\n            ymax = int(ymax * frame.shape[0])\n            xmax = int(xmax * frame.shape[1])\n\n            label = labels[classes[i] - 1]  # Adjust for zero-based indexing\n            cv2.rectangle(frame, (xmin, ymin), (xmax, ymax), (0, 255, 0), 2)\n            cv2.putText(frame, f'{label}: {scores[i]:.2f}', (xmin, ymin - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n\n    # Handle Output\n    out.write(frame)\n\n# Cleanup\ncap.release()\nout.release()\ncv2.destroyAllWindows()",
        "last_error": "Max retries reached with failure. Last error from execution: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\nTraceback (most recent call last):\n  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250820034245_psg_qwen2.5-coder:14b/tmp_20250820034245_psg_qwen2.5-coder:14b.py\", line 52, in <module>\n    if scores[i] > confidence_threshold:\nValueError: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()\n"
      },
      "session_id": "qwen2.5-coder:14b_c83f_psg_batch",
      "metadata": {
        "num_run": 13
      },
      "tags": [
        "benchmark",
        "py_sketch_generator",
        "qwen2.5-coder:14b"
      ],
      "latency": 65.17,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-03-41-40-716664_chatcmpl-dbd11a45-e9b6-42ed-85bf-256668b07302",
          "traceId": "894c25d7",
          "type": "GENERATION",
          "name": "894c_psg_gen_attempt#1",
          "startTime": "2025-08-20T00:41:40.716000+00:00",
          "endTime": "2025-08-20T00:41:51.222000+00:00",
          "model": "qwen2.5-coder:14b",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 10506.0,
          "environment": "default",
          "promptTokens": 1618,
          "totalTokens": 2237,
          "costDetails": {},
          "completionTokens": 619,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-03-41-51-416317_chatcmpl-4bdfa126-5036-48c9-84b0-3a786462ffae",
          "traceId": "894c25d7",
          "type": "GENERATION",
          "name": "894c_psg_gen_attempt#2",
          "startTime": "2025-08-20T00:41:51.416000+00:00",
          "endTime": "2025-08-20T00:42:04.335000+00:00",
          "model": "qwen2.5-coder:14b",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 12919.0,
          "environment": "default",
          "promptTokens": 2048,
          "totalTokens": 2813,
          "costDetails": {},
          "completionTokens": 765,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-03-42-04-701984_chatcmpl-029a6023-cdf0-4a0d-a6c2-563e6fcaa179",
          "traceId": "894c25d7",
          "type": "GENERATION",
          "name": "894c_psg_gen_attempt#3",
          "startTime": "2025-08-20T00:42:04.701000+00:00",
          "endTime": "2025-08-20T00:42:17.991000+00:00",
          "model": "qwen2.5-coder:14b",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 13290.0,
          "environment": "default",
          "promptTokens": 2048,
          "totalTokens": 2836,
          "costDetails": {},
          "completionTokens": 788,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-03-42-18-374514_chatcmpl-66f7a424-ebf6-494d-9a43-2c2f9038cfc2",
          "traceId": "894c25d7",
          "type": "GENERATION",
          "name": "894c_psg_gen_attempt#4",
          "startTime": "2025-08-20T00:42:18.374000+00:00",
          "endTime": "2025-08-20T00:42:31.764000+00:00",
          "model": "qwen2.5-coder:14b",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 13390.0,
          "environment": "default",
          "promptTokens": 2048,
          "totalTokens": 2843,
          "costDetails": {},
          "completionTokens": 795,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-03-42-32-135051_chatcmpl-3b2a3eaa-84c1-4489-9f45-93eb3275806f",
          "traceId": "894c25d7",
          "type": "GENERATION",
          "name": "894c_psg_gen_attempt#5",
          "startTime": "2025-08-20T00:42:32.135000+00:00",
          "endTime": "2025-08-20T00:42:45.507000+00:00",
          "model": "qwen2.5-coder:14b",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 13372.0,
          "environment": "default",
          "promptTokens": 2048,
          "totalTokens": 2841,
          "costDetails": {},
          "completionTokens": 793,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "d4570b9b-5421-48cd-8e5b-31c6dc4e449d",
          "traceId": "894c25d7",
          "type": "SPAN",
          "name": "error_89_psg_failure_signal_py_sketch_generator",
          "startTime": "2025-08-20T00:42:45.886000+00:00",
          "level": "ERROR",
          "statusMessage": "Failed. Last error: Max retries reached with failure. Last error from execution: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\nTraceback (most recent call last):\n  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250820034245_psg_qwen2.5-coder:14b/tmp_20250820034245_psg_qwen2.5-coder:14b.py\", line 52, in <module>\n    if scores[i] > confidence_threshold:\nValueError: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()\n",
          "calculatedTotalCost": 0.0,
          "environment": "default",
          "promptTokens": 0,
          "totalTokens": 0,
          "costDetails": {},
          "completionTokens": 0,
          "endTime": null,
          "model": null,
          "modelParameters": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null,
          "latency": null
        }
      ],
      "createdAt": "2025-08-20T00:41:41.234Z",
      "environment": "default",
      "updatedAt": "2025-08-20T00:42:51.380Z"
    },
    {
      "id": "29e53ebd",
      "timestamp": "2025-08-20T00:40:36.027000+00:00",
      "name": "29e5_py_sketch_generator",
      "input": null,
      "output": {
        "status": "success",
        "sketch": "import os\nimport cv2\nimport numpy as np\n\n# Phase 1: Setup\nmodel_path   = \"models/ssd-mobilenet_v1/detect.tflite\"\nlabel_path   = \"models/ssd-mobilenet_v1/labelmap.txt\"\ninput_path   = \"data/object_detection/sheeps.mp4\"\noutput_path   = \"results/object_detection/test_results/sheeps_detections.mp4\"\nconfidence_threshold   = 0.5\n\n# Load labels\nwith open(label_path, 'r') as f:\n    labels = [line.strip() for line in f.readlines()]\n\n# Load interpreter\nfrom tflite_runtime.interpreter import Interpreter\ninterpreter = Interpreter(model_path=model_path)\ninterpreter.allocate_tensors()\n\n# Get model details\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\n\n# Phase 2: Input Acquisition & Preprocessing Loop\ncap = cv2.VideoCapture(input_path)\nfourcc = cv2.VideoWriter_fourcc(*'mp4v')\nout = cv2.VideoWriter(output_path, fourcc, 30.0, (int(cap.get(3)), int(cap.get(4))))\n\nwhile cap.isOpened():\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    # Preprocess data\n    input_data = cv2.resize(frame, (input_details[0]['shape'][1], input_details[0]['shape'][2]))\n    input_data = input_data.astype(np.uint8)  # Ensure the type is UINT8\n    input_data = np.expand_dims(input_data, axis=0)\n\n    # Normalize if required\n    if input_details[0]['dtype'] == np.float32:\n        input_data = (input_data / 127.5) - 1.0\n\n    # Phase 3: Inference\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n    interpreter.invoke()\n\n    # Phase 4: Output Interpretation & Handling Loop\n    # Get output tensors\n    boxes = interpreter.get_tensor(output_details[0]['index'])\n    classes = interpreter.get_tensor(output_details[1]['index'])\n    scores = interpreter.get_tensor(output_details[2]['index'])\n\n    # Process results\n    num_detections = int(scores.shape[1])\n    for i in range(num_detections):\n        if scores[0, i] > confidence_threshold:\n            ymin, xmin, ymax, xmax = boxes[0, i]\n            (h, w) = frame.shape[:2]\n            (startX, startY) = (int(xmin * w), int(ymin * h))\n            (endX, endY) = (int(xmax * w), int(ymax * h))\n\n            label = labels[int(classes[0, i])]\n            cv2.rectangle(frame, (startX, startY), (endX, endY), (0, 255, 0), 2)\n            y = startY - 10 if startY - 10 > 10 else startY + 10\n            cv2.putText(frame, f'{label}: {scores[0, i]:.2f}', (startX, y),\n                        cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n\n    # Write the frame with detections to the output video file\n    out.write(frame)\n\n# Phase 5: Cleanup\ncap.release()\nout.release()\ncv2.destroyAllWindows()"
      },
      "session_id": "qwen2.5-coder:14b_c83f_psg_batch",
      "metadata": {
        "num_run": 12
      },
      "tags": [
        "benchmark",
        "py_sketch_generator",
        "qwen2.5-coder:14b"
      ],
      "latency": 26.61,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-03-40-36-028235_chatcmpl-8ec73979-c8f8-410f-a9c8-146d87f21c65",
          "traceId": "29e53ebd",
          "type": "GENERATION",
          "name": "29e5_psg_gen_attempt#1",
          "startTime": "2025-08-20T00:40:36.028000+00:00",
          "endTime": "2025-08-20T00:40:47.310000+00:00",
          "model": "qwen2.5-coder:14b",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 11282.0,
          "environment": "default",
          "promptTokens": 1618,
          "totalTokens": 2287,
          "costDetails": {},
          "completionTokens": 669,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-03-40-47-491942_chatcmpl-8652104e-3f7b-4f24-9ab3-10363ef71cd8",
          "traceId": "29e53ebd",
          "type": "GENERATION",
          "name": "29e5_psg_gen_attempt#2",
          "startTime": "2025-08-20T00:40:47.491000+00:00",
          "endTime": "2025-08-20T00:41:02.638000+00:00",
          "model": "qwen2.5-coder:14b",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 15147.0,
          "environment": "default",
          "promptTokens": 2048,
          "totalTokens": 2954,
          "costDetails": {},
          "completionTokens": 906,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        }
      ],
      "createdAt": "2025-08-20T00:40:36.547Z",
      "environment": "default",
      "updatedAt": "2025-08-20T00:41:40.231Z"
    },
    {
      "id": "8f180d78",
      "timestamp": "2025-08-20T00:39:16.194000+00:00",
      "name": "8f18_py_sketch_generator",
      "input": null,
      "output": {
        "status": "failed",
        "last_code": "import numpy as np\nimport cv2\n\n# Phase 1: Setup\nmodel_path  = \"models/ssd-mobilenet_v1/detect.tflite\"\nlabel_path  = \"models/ssd-mobilenet_v1/labelmap.txt\"\ninput_path  = \"data/object_detection/sheeps.mp4\"\noutput_path  = \"results/object_detection/test_results/sheeps_detections.mp4\"\nconfidence_threshold  = 0.5\n\n# Load labels\nwith open(label_path, 'r') as f:\n    labels = [line.strip() for line in f.readlines()]\n\n# Load interpreter\ninterpreter = tf.lite.Interpreter(model_path=model_path)\ninterpreter.allocate_tensors()\n\n# Get model details\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\n\ninput_shape = input_details[0]['shape']\ninput_dtype = input_details[0]['dtype']\n\n# Phase 2: Input Acquisition & Preprocessing Loop\ncap = cv2.VideoCapture(input_path)\nfourcc = cv2.VideoWriter_fourcc(*'mp4v')\nout = cv2.VideoWriter(output_path, fourcc, 30.0, (int(cap.get(3)), int(cap.get(4))))\n\nwhile cap.isOpened():\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    # Preprocess data\n    input_data = cv2.resize(frame, (input_shape[1], input_shape[2]))\n    input_data = input_data.astype(input_dtype)\n    input_data = np.expand_dims(input_data, axis=0)\n\n    # Phase 3: Inference\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n    interpreter.invoke()\n\n    # Phase 4: Output Interpretation & Handling Loop\n    boxes = interpreter.get_tensor(output_details[0]['index'])[0]\n    classes = interpreter.get_tensor(output_details[1]['index'])[0]\n    scores = interpreter.get_tensor(output_details[2]['index'])[0]\n\n    for i in range(len(scores)):\n        if scores[i] > confidence_threshold:\n            class_id = int(classes[i])\n            label = labels[class_id]\n            box = boxes[i]\n            ymin, xmin, ymax, xmax = box\n            cv2.rectangle(frame, (int(xmin * frame.shape[1]), int(ymin * frame.shape[0])), \n                          (int(xmax * frame.shape[1]), int(ymax * frame.shape[0])), (0, 255, 0), 2)\n            cv2.putText(frame, f'{label}: {scores[i]:.2f}', \n                        (int(xmin * frame.shape[1]), int(ymin * frame.shape[0]) - 10),\n                        cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n\n    out.write(frame)\n\n# Phase 5: Cleanup\ncap.release()\nout.release()\ncv2.destroyAllWindows()\n\n<REPORT THE FIX OF THE LAST ERROR>\nThe error was due to an indentation issue in the `if` statement. The corrected code ensures proper indentation for the block following the `if` condition.",
        "last_error": "Max retries reached with failure. Last error from execution:   File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250820034028_psg_qwen2.5-coder:14b/tmp_20250820034028_psg_qwen2.5-coder:14b.py\", line 69\n    <REPORT THE FIX OF THE LAST ERROR>\n    ^\nSyntaxError: invalid syntax\n"
      },
      "session_id": "qwen2.5-coder:14b_c83f_psg_batch",
      "metadata": {
        "num_run": 11
      },
      "tags": [
        "benchmark",
        "py_sketch_generator",
        "qwen2.5-coder:14b"
      ],
      "latency": 72.649,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-03-39-16-195335_chatcmpl-a3b1ddc6-3337-46e9-938a-96a785ad3883",
          "traceId": "8f180d78",
          "type": "GENERATION",
          "name": "8f18_psg_gen_attempt#1",
          "startTime": "2025-08-20T00:39:16.195000+00:00",
          "endTime": "2025-08-20T00:39:26.749000+00:00",
          "model": "qwen2.5-coder:14b",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 10554.0,
          "environment": "default",
          "promptTokens": 1618,
          "totalTokens": 2239,
          "costDetails": {},
          "completionTokens": 621,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-03-39-26-895538_chatcmpl-10ac105e-406d-433e-a548-378f18d4de71",
          "traceId": "8f180d78",
          "type": "GENERATION",
          "name": "8f18_psg_gen_attempt#2",
          "startTime": "2025-08-20T00:39:26.895000+00:00",
          "endTime": "2025-08-20T00:39:39.262000+00:00",
          "model": "qwen2.5-coder:14b",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 12367.0,
          "environment": "default",
          "promptTokens": 2048,
          "totalTokens": 2777,
          "costDetails": {},
          "completionTokens": 729,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-03-39-43-052490_chatcmpl-3fdb1934-7f6f-4e0e-ab42-9c851b64f416",
          "traceId": "8f180d78",
          "type": "GENERATION",
          "name": "8f18_psg_gen_attempt#3",
          "startTime": "2025-08-20T00:39:43.052000+00:00",
          "endTime": "2025-08-20T00:39:56.078000+00:00",
          "model": "qwen2.5-coder:14b",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 13026.0,
          "environment": "default",
          "promptTokens": 2048,
          "totalTokens": 2818,
          "costDetails": {},
          "completionTokens": 770,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-03-39-59-883486_chatcmpl-bc1b61c6-5555-43e9-b6e5-198467c33b50",
          "traceId": "8f180d78",
          "type": "GENERATION",
          "name": "8f18_psg_gen_attempt#4",
          "startTime": "2025-08-20T00:39:59.883000+00:00",
          "endTime": "2025-08-20T00:40:17.813000+00:00",
          "model": "qwen2.5-coder:14b",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 17930.0,
          "environment": "default",
          "promptTokens": 2048,
          "totalTokens": 3131,
          "costDetails": {},
          "completionTokens": 1083,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-03-40-17-842106_chatcmpl-ddd07671-074c-4d88-8e83-17523e8a2fe2",
          "traceId": "8f180d78",
          "type": "GENERATION",
          "name": "8f18_psg_gen_attempt#5",
          "startTime": "2025-08-20T00:40:17.842000+00:00",
          "endTime": "2025-08-20T00:40:28.818000+00:00",
          "model": "qwen2.5-coder:14b",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 10976.0,
          "environment": "default",
          "promptTokens": 1812,
          "totalTokens": 2459,
          "costDetails": {},
          "completionTokens": 647,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "51ba08ab-6d38-43d7-b325-9f36daec50b5",
          "traceId": "8f180d78",
          "type": "SPAN",
          "name": "error_8f_psg_failure_signal_py_sketch_generator",
          "startTime": "2025-08-20T00:40:28.844000+00:00",
          "level": "ERROR",
          "statusMessage": "Failed. Last error: Max retries reached with failure. Last error from execution:   File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250820034028_psg_qwen2.5-coder:14b/tmp_20250820034028_psg_qwen2.5-coder:14b.py\", line 69\n    <REPORT THE FIX OF THE LAST ERROR>\n    ^\nSyntaxError: invalid syntax\n",
          "calculatedTotalCost": 0.0,
          "environment": "default",
          "promptTokens": 0,
          "totalTokens": 0,
          "costDetails": {},
          "completionTokens": 0,
          "endTime": null,
          "model": null,
          "modelParameters": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null,
          "latency": null
        }
      ],
      "createdAt": "2025-08-20T00:39:16.712Z",
      "environment": "default",
      "updatedAt": "2025-08-20T00:40:34.609Z"
    },
    {
      "id": "08552506",
      "timestamp": "2025-08-20T00:38:04.669000+00:00",
      "name": "0855_py_sketch_generator",
      "input": null,
      "output": {
        "status": "failed",
        "last_code": "import numpy as np\nfrom tflite_runtime.interpreter import Interpreter\nimport cv2\n\n# Phase 1: Setup\nmodel_path  = \"models/ssd-mobilenet_v1/detect.tflite\"\nlabel_path  = \"models/ssd-mobilenet_v1/labelmap.txt\"\ninput_path  = \"data/object_detection/sheeps.mp4\"\noutput_path  = \"results/object_detection/test_results/sheeps_detections.mp4\"\nconfidence_threshold  = 0.5\n\n# Load labels\nwith open(label_path, 'r') as f:\n    labels = [line.strip() for line in f.readlines()]\n\n# Load interpreter\ninterpreter = Interpreter(model_path=model_path)\ninterpreter.allocate_tensors()\n\n# Get model details\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\n\n# Phase 2: Input Acquisition & Preprocessing Loop\ncap = cv2.VideoCapture(input_path)\nfourcc = cv2.VideoWriter_fourcc(*'mp4v')\nout = cv2.VideoWriter(output_path, fourcc, cap.get(cv2.CAP_PROP_FPS), (int(cap.get(cv2.CAP_PROP_FRAME_WIDTH)), int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))))\n\nwhile True:\n    ret, frame = cap.read()\n    if not ret:\n        break\n    \n    # Preprocess data\n    input_data = cv2.resize(frame, (300, 300))\n    input_data = np.expand_dims(input_data, axis=0)\n    \n    # Convert to FLOAT32 as expected by the model\n    input_data = input_data.astype('float32')\n    \n    interpreter.set_tensor(input_details[0]['index'], input_data)\n    \n    # Phase 3: Inference\n    interpreter.invoke()\n    \n    # Phase 4: Output Interpretation & Handling Loop\n    boxes = interpreter.get_tensor(output_details[1]['index'])[0]  # Assuming the output details index for boxes is 1\n    classes = interpreter.get_tensor(output_details[3]['index'])[0]  # Assuming the output details index for classes is 3\n    scores = interpreter.get_tensor(output_details[0]['index'])[0]   # Assuming the output details index for scores is 0\n    \n    for i in range(boxes.shape[0]):\n        confidence = scores[i]\n        if confidence > confidence_threshold:\n            label_id = int(classes[i])\n            label_name = labels[label_id] if label_id < len(labels) else \"unknown\"\n            x_min = int(boxes[i, 1] * frame.shape[1])\n            y_min = int(boxes[i, 0] * frame.shape[0])\n            x_max = int(boxes[i, 3] * frame.shape[1])\n            y_max = int(boxes[i, 2] * frame.shape[0])\n            \n            cv2.rectangle(frame, (x_min, y_min), (x_max, y_max), (0, 255, 0), 2)\n            cv2.putText(frame, f'{label_name}: {confidence:.2f}', (x_min, y_min - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n    \n    out.write(frame)\n\n# Phase 5: Cleanup\ncap.release()\nout.release()",
        "last_error": "Max retries reached with failure. Last error from execution: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\nTraceback (most recent call last):\n  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250820033909_psg_qwen2.5-coder:14b/tmp_20250820033909_psg_qwen2.5-coder:14b.py\", line 41, in <module>\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n  File \"/home/wuguangh/.conda/envs/tinyml/lib/python3.10/site-packages/tflite_runtime/interpreter.py\", line 720, in set_tensor\n    self._interpreter.SetTensor(tensor_index, value)\nValueError: Cannot set tensor: Got value of type FLOAT32 but expected type UINT8 for input 175, name: normalized_input_image_tensor \n"
      },
      "session_id": "qwen2.5-coder:14b_c83f_psg_batch",
      "metadata": {
        "num_run": 10
      },
      "tags": [
        "benchmark",
        "py_sketch_generator",
        "qwen2.5-coder:14b"
      ],
      "latency": 65.388,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-03-38-04-671325_chatcmpl-0cb67384-2d8c-46c2-bee4-96fdb167d5c8",
          "traceId": "08552506",
          "type": "GENERATION",
          "name": "0855_psg_gen_attempt#1",
          "startTime": "2025-08-20T00:38:04.671000+00:00",
          "endTime": "2025-08-20T00:38:15.412000+00:00",
          "model": "qwen2.5-coder:14b",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 10741.0,
          "environment": "default",
          "promptTokens": 1618,
          "totalTokens": 2253,
          "costDetails": {},
          "completionTokens": 635,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-03-38-15-554716_chatcmpl-d943fab1-bf1c-4542-807f-1a3e46631b56",
          "traceId": "08552506",
          "type": "GENERATION",
          "name": "0855_psg_gen_attempt#2",
          "startTime": "2025-08-20T00:38:15.554000+00:00",
          "endTime": "2025-08-20T00:38:27.947000+00:00",
          "model": "qwen2.5-coder:14b",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 12393.0,
          "environment": "default",
          "promptTokens": 2048,
          "totalTokens": 2779,
          "costDetails": {},
          "completionTokens": 731,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-03-38-28-065056_chatcmpl-89df0d1d-dafc-484b-bf9b-4811783a00bf",
          "traceId": "08552506",
          "type": "GENERATION",
          "name": "0855_psg_gen_attempt#3",
          "startTime": "2025-08-20T00:38:28.065000+00:00",
          "endTime": "2025-08-20T00:38:40.118000+00:00",
          "model": "qwen2.5-coder:14b",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 12053.0,
          "environment": "default",
          "promptTokens": 2048,
          "totalTokens": 2758,
          "costDetails": {},
          "completionTokens": 710,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-03-38-40-288252_chatcmpl-763ec514-94a1-48db-81bf-7d7bcba308e2",
          "traceId": "08552506",
          "type": "GENERATION",
          "name": "0855_psg_gen_attempt#4",
          "startTime": "2025-08-20T00:38:40.288000+00:00",
          "endTime": "2025-08-20T00:38:56.025000+00:00",
          "model": "qwen2.5-coder:14b",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 15737.0,
          "environment": "default",
          "promptTokens": 2048,
          "totalTokens": 2992,
          "costDetails": {},
          "completionTokens": 944,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-03-38-56-408879_chatcmpl-c9152459-70f4-49ad-ac31-41706120f1c6",
          "traceId": "08552506",
          "type": "GENERATION",
          "name": "0855_psg_gen_attempt#5",
          "startTime": "2025-08-20T00:38:56.408000+00:00",
          "endTime": "2025-08-20T00:39:09.867000+00:00",
          "model": "qwen2.5-coder:14b",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 13459.0,
          "environment": "default",
          "promptTokens": 2048,
          "totalTokens": 2847,
          "costDetails": {},
          "completionTokens": 799,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "33314a86-29a2-41ba-8fb4-b4a0806a8847",
          "traceId": "08552506",
          "type": "SPAN",
          "name": "error_08_psg_failure_signal_py_sketch_generator",
          "startTime": "2025-08-20T00:39:10.059000+00:00",
          "level": "ERROR",
          "statusMessage": "Failed. Last error: Max retries reached with failure. Last error from execution: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\nTraceback (most recent call last):\n  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250820033909_psg_qwen2.5-coder:14b/tmp_20250820033909_psg_qwen2.5-coder:14b.py\", line 41, in <module>\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n  File \"/home/wuguangh/.conda/envs/tinyml/lib/python3.10/site-packages/tflite_runtime/interpreter.py\", line 720, in set_tensor\n    self._interpreter.SetTensor(tensor_index, value)\nValueError: Cannot set tensor: Got value of type FLOAT32 but expected type UINT8 for input 175, name: normalized_input_image_tensor \n",
          "calculatedTotalCost": 0.0,
          "environment": "default",
          "promptTokens": 0,
          "totalTokens": 0,
          "costDetails": {},
          "completionTokens": 0,
          "endTime": null,
          "model": null,
          "modelParameters": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null,
          "latency": null
        }
      ],
      "createdAt": "2025-08-20T00:38:05.188Z",
      "environment": "default",
      "updatedAt": "2025-08-20T00:39:15.262Z"
    },
    {
      "id": "693b0a84",
      "timestamp": "2025-08-20T00:36:35.135000+00:00",
      "name": "693b_py_sketch_generator",
      "input": null,
      "output": {
        "status": "success",
        "sketch": "import numpy as np\nimport cv2\nfrom tflite_runtime.interpreter import Interpreter\n\n# Phase 1: Setup\nmodel_path  = \"models/ssd-mobilenet_v1/detect.tflite\"\nlabel_path  = \"models/ssd-mobilenet_v1/labelmap.txt\"\ninput_path  = \"data/object_detection/sheeps.mp4\"\noutput_path  = \"results/object_detection/test_results/sheeps_detections.mp4\"\nconfidence_threshold  = 0.5\n\n# Load labels\nwith open(label_path, 'r') as f:\n    labels = [line.strip() for line in f.readlines()]\n\n# Load Interpreter\ninterpreter = Interpreter(model_path=model_path)\ninterpreter.allocate_tensors()\n\n# Get Model Details\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\n\n# Phase 2: Input Acquisition & Preprocessing Loop\ncap = cv2.VideoCapture(input_path)\nfourcc = cv2.VideoWriter_fourcc(*'mp4v')\nout = cv2.VideoWriter(output_path, fourcc, 30.0, (int(cap.get(3)), int(cap.get(4))))\n\nwhile cap.isOpened():\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    # Preprocess Data\n    height, width = frame.shape[:2]\n    input_data = cv2.resize(frame, (300, 300))\n    input_data = input_data.astype('float32')\n    input_data /= 127.5\n    input_data -= 1.0\n    input_data = np.expand_dims(input_data, axis=0)\n\n    # Ensure the input data type matches the expected type by the model\n    if input_details[0]['dtype'] == np.uint8:\n        input_data = (input_data * 127.5 + 127.5).astype(np.uint8)\n    \n    interpreter.set_tensor(input_details[0]['index'], input_data)\n\n    # Phase 3: Inference\n    interpreter.invoke()\n\n    # Get outputs from the model\n    boxes = interpreter.get_tensor(output_details[0]['index'])[0]\n    classes = interpreter.get_tensor(output_details[1]['index'])[0]  # Removed label_offset as it was not defined\n    scores = interpreter.get_tensor(output_details[2]['index'])[0]\n\n    # Phase 4: Output Interpretation & Handling Loop\n    for i in range(len(scores)):\n        if scores[i] > confidence_threshold:\n            (left, top, right, bottom) = boxes[i]\n            left *= width\n            top *= height\n            right *= width\n            bottom *= height\n\n            label_id = int(classes[i])\n            label_name = labels[label_id]\n\n            cv2.rectangle(frame, (int(left), int(top)), (int(right), int(bottom)), (0, 255, 0), 2)\n            cv2.putText(frame, f'{label_name}: {scores[i]:.2f}', (int(left), int(top) - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n\n    # Handle Output\n    out.write(frame)\n\n# Phase 5: Cleanup\ncap.release()\nout.release()\ncv2.destroyAllWindows()"
      },
      "session_id": "qwen2.5-coder:14b_c83f_psg_batch",
      "metadata": {
        "num_run": 9
      },
      "tags": [
        "benchmark",
        "py_sketch_generator",
        "qwen2.5-coder:14b"
      ],
      "latency": 51.543,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-03-36-35-137244_chatcmpl-1ba0862e-d3e6-460b-95fc-44cb227bed92",
          "traceId": "693b0a84",
          "type": "GENERATION",
          "name": "693b_psg_gen_attempt#1",
          "startTime": "2025-08-20T00:36:35.137000+00:00",
          "endTime": "2025-08-20T00:36:45.466000+00:00",
          "model": "qwen2.5-coder:14b",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 10329.0,
          "environment": "default",
          "promptTokens": 1618,
          "totalTokens": 2226,
          "costDetails": {},
          "completionTokens": 608,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-03-36-45-611084_chatcmpl-6e46fd44-43d8-4510-880d-72437d513ae7",
          "traceId": "693b0a84",
          "type": "GENERATION",
          "name": "693b_psg_gen_attempt#2",
          "startTime": "2025-08-20T00:36:45.611000+00:00",
          "endTime": "2025-08-20T00:36:59.937000+00:00",
          "model": "qwen2.5-coder:14b",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 14326.0,
          "environment": "default",
          "promptTokens": 2048,
          "totalTokens": 2901,
          "costDetails": {},
          "completionTokens": 853,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-03-37-00-113492_chatcmpl-bd94cc5f-eceb-4b0d-a523-68605ad468be",
          "traceId": "693b0a84",
          "type": "GENERATION",
          "name": "693b_psg_gen_attempt#3",
          "startTime": "2025-08-20T00:37:00.113000+00:00",
          "endTime": "2025-08-20T00:37:12.947000+00:00",
          "model": "qwen2.5-coder:14b",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 12834.0,
          "environment": "default",
          "promptTokens": 2048,
          "totalTokens": 2807,
          "costDetails": {},
          "completionTokens": 759,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-03-37-13-307311_chatcmpl-8d5b6e55-9edd-4d9f-80d2-7547ae2b0a76",
          "traceId": "693b0a84",
          "type": "GENERATION",
          "name": "693b_psg_gen_attempt#4",
          "startTime": "2025-08-20T00:37:13.307000+00:00",
          "endTime": "2025-08-20T00:37:26.680000+00:00",
          "model": "qwen2.5-coder:14b",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 13373.0,
          "environment": "default",
          "promptTokens": 2048,
          "totalTokens": 2841,
          "costDetails": {},
          "completionTokens": 793,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        }
      ],
      "createdAt": "2025-08-20T00:36:35.653Z",
      "environment": "default",
      "updatedAt": "2025-08-20T00:38:03.774Z"
    },
    {
      "id": "020645f7",
      "timestamp": "2025-08-20T00:35:15.610000+00:00",
      "name": "0206_py_sketch_generator",
      "input": null,
      "output": {
        "status": "success",
        "sketch": "import numpy as np\nimport cv2\nfrom tflite_runtime.interpreter import Interpreter\n\n# Phase 1: Setup\n# Define necessary variables\nmodel_path    = \"models/ssd-mobilenet_v1/detect.tflite\"\nlabel_path    = \"models/ssd-mobilenet_v1/labelmap.txt\"\ninput_path    = \"data/object_detection/sheeps.mp4\"\noutput_path    = \"results/object_detection/test_results/sheeps_detections.mp4\"\nconfidence_threshold    = 0.5\n\n# Load labels\nwith open(label_path, 'r') as f:\n    labels = [line.strip() for line in f.readlines()]\n\n# Load interpreter\ninterpreter = Interpreter(model_path=model_path)\ninterpreter.allocate_tensors()\n\n# Get model details\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\n\n# Phase 2: Input Acquisition & Preprocessing Loop\ncap = cv2.VideoCapture(input_path)\nfourcc = cv2.VideoWriter_fourcc(*'mp4v')\nout = cv2.VideoWriter(output_path, fourcc, cap.get(cv2.CAP_PROP_FPS), (int(cap.get(cv2.CAP_PROP_FRAME_WIDTH)), int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))))\n\nwhile cap.isOpened():\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    # Preprocess data\n    input_shape = input_details[0]['shape'][1:3]\n    resized_frame = cv2.resize(frame, (input_shape[1], input_shape[0]))\n    normalized_frame = resized_frame / 255.0\n    input_data = np.expand_dims(normalized_frame, axis=0).astype(input_details[0]['dtype'])\n\n    # Phase 3: Inference\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n    interpreter.invoke()\n\n    # Phase 4: Output Interpretation & Handling Loop\n    boxes = interpreter.get_tensor(output_details[0]['index'])\n    scores = interpreter.get_tensor(output_details[1]['index'])\n    classes = interpreter.get_tensor(output_details[2]['index'])\n\n    for i in range(len(scores[0])):\n        if scores[0][i] > confidence_threshold:\n            ymin, xmin, ymax, xmax = boxes[0][i]\n            label = labels[int(classes[0][i])]\n            cv2.rectangle(frame, (int(xmin * frame.shape[1]), int(ymin * frame.shape[0])),\n                          (int(xmax * frame.shape[1]), int(ymax * frame.shape[0])), (0, 255, 0), 2)\n            cv2.putText(frame, f'{label}: {scores[0][i]:.2f}', \n                        (int(xmin * frame.shape[1]), int(ymin * frame.shape[0]) - 10),\n                        cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n\n    # Phase 4.3: Handle Output\n    out.write(frame)\n\n# Phase 5: Cleanup\ncap.release()\nout.release()"
      },
      "session_id": "qwen2.5-coder:14b_c83f_psg_batch",
      "metadata": {
        "num_run": 8
      },
      "tags": [
        "benchmark",
        "py_sketch_generator",
        "qwen2.5-coder:14b"
      ],
      "latency": 41.76,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-03-35-15-612009_chatcmpl-5d18c950-3fab-467d-9374-1f3615c87a19",
          "traceId": "020645f7",
          "type": "GENERATION",
          "name": "0206_psg_gen_attempt#1",
          "startTime": "2025-08-20T00:35:15.612000+00:00",
          "endTime": "2025-08-20T00:35:25.943000+00:00",
          "model": "qwen2.5-coder:14b",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 10331.0,
          "environment": "default",
          "promptTokens": 1618,
          "totalTokens": 2226,
          "costDetails": {},
          "completionTokens": 608,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-03-35-26-304284_chatcmpl-d021af17-506a-443a-9a6e-f2d03a9b6243",
          "traceId": "020645f7",
          "type": "GENERATION",
          "name": "0206_psg_gen_attempt#2",
          "startTime": "2025-08-20T00:35:26.304000+00:00",
          "endTime": "2025-08-20T00:35:39.984000+00:00",
          "model": "qwen2.5-coder:14b",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 13680.0,
          "environment": "default",
          "promptTokens": 2048,
          "totalTokens": 2861,
          "costDetails": {},
          "completionTokens": 813,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-03-35-41-522229_chatcmpl-6f761b8b-0d72-4977-82d4-990350c17075",
          "traceId": "020645f7",
          "type": "GENERATION",
          "name": "0206_psg_gen_attempt#3",
          "startTime": "2025-08-20T00:35:41.522000+00:00",
          "endTime": "2025-08-20T00:35:57.372000+00:00",
          "model": "qwen2.5-coder:14b",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 15850.0,
          "environment": "default",
          "promptTokens": 2048,
          "totalTokens": 2997,
          "costDetails": {},
          "completionTokens": 949,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        }
      ],
      "createdAt": "2025-08-20T00:35:16.128Z",
      "environment": "default",
      "updatedAt": "2025-08-20T00:36:34.258Z"
    },
    {
      "id": "3cc4ad5a",
      "timestamp": "2025-08-20T00:33:45.085000+00:00",
      "name": "3cc4_py_sketch_generator",
      "input": null,
      "output": {
        "status": "success",
        "sketch": "import numpy as np\nimport cv2\nimport tflite_runtime.interpreter as tflite\n\n# Phase 1: Setup\nmodel_path   = \"models/ssd-mobilenet_v1/detect.tflite\"\nlabel_path   = \"models/ssd-mobilenet_v1/labelmap.txt\"\ninput_path   = \"data/object_detection/sheeps.mp4\"\noutput_path   = \"results/object_detection/test_results/sheeps_detections.mp4\"\nconfidence_threshold   = 0.5\n\n# Load Labels\nwith open(label_path, 'r') as f:\n    labels = [line.strip() for line in f.readlines()]\n\n# Load Interpreter\ninterpreter = tflite.Interpreter(model_path=model_path)\ninterpreter.allocate_tensors()\n\n# Get Model Details\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\n\n# Phase 2: Input Acquisition & Preprocessing Loop\ncap = cv2.VideoCapture(input_path)\nwidth = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\nheight = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\nfourcc = cv2.VideoWriter_fourcc(*'mp4v')\nout = cv2.VideoWriter(output_path, fourcc, 30.0, (width, height))\n\nwhile cap.isOpened():\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    # Preprocess Data\n    input_frame = cv2.resize(frame, (input_details[0]['shape'][1], input_details[0]['shape'][2]))\n    input_frame = input_frame.astype(np.float32)\n    input_frame = np.expand_dims(input_frame, axis=0)\n\n    if input_details[0]['dtype'] == np.uint8:\n        input_frame = (input_frame * 255).astype(np.uint8)\n\n    interpreter.set_tensor(input_details[0]['index'], input_frame)\n\n    # Phase 3: Inference\n    interpreter.invoke()\n\n    # Phase 4: Output Interpretation & Handling Loop\n    boxes = interpreter.get_tensor(output_details[0]['index'])[0]\n    classes = interpreter.get_tensor(output_details[1]['index'])[0]\n    scores = interpreter.get_tensor(output_details[2]['index'])[0]\n\n    for i in range(len(scores)):\n        if scores[i] > confidence_threshold:\n            idx = int(classes[i])\n            label = labels[idx-1] if 0 <= idx < len(labels) else 'unknown'\n            x_min, y_min, x_max, y_max = boxes[i][1] * width, boxes[i][0] * height, boxes[i][3] * width, boxes[i][2] * height\n            cv2.rectangle(frame, (int(x_min), int(y_min)), (int(x_max), int(y_max)), (0, 255, 0), 2)\n            cv2.putText(frame, f'{label}: {scores[i]:.2f}', (int(x_min), int(y_min) - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n\n    # Handle Output\n    out.write(frame)\n\n# Phase 5: Cleanup\ncap.release()\nout.release()\ncv2.destroyAllWindows()"
      },
      "session_id": "qwen2.5-coder:14b_c83f_psg_batch",
      "metadata": {
        "num_run": 7
      },
      "tags": [
        "benchmark",
        "py_sketch_generator",
        "qwen2.5-coder:14b"
      ],
      "latency": 52.912,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-03-33-45-087115_chatcmpl-5cc37c76-3c0d-4a62-9f4b-211c8b587e43",
          "traceId": "3cc4ad5a",
          "type": "GENERATION",
          "name": "3cc4_psg_gen_attempt#1",
          "startTime": "2025-08-20T00:33:45.087000+00:00",
          "endTime": "2025-08-20T00:33:55.204000+00:00",
          "model": "qwen2.5-coder:14b",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 10117.0,
          "environment": "default",
          "promptTokens": 1618,
          "totalTokens": 2212,
          "costDetails": {},
          "completionTokens": 594,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-03-33-55-348056_chatcmpl-d223c4db-58d4-4ad4-ab05-0eba6f03ae92",
          "traceId": "3cc4ad5a",
          "type": "GENERATION",
          "name": "3cc4_psg_gen_attempt#2",
          "startTime": "2025-08-20T00:33:55.348000+00:00",
          "endTime": "2025-08-20T00:34:09.298000+00:00",
          "model": "qwen2.5-coder:14b",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 13950.0,
          "environment": "default",
          "promptTokens": 2048,
          "totalTokens": 2876,
          "costDetails": {},
          "completionTokens": 828,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-03-34-09-440320_chatcmpl-f7af7310-4900-4cc6-9c3f-fbaf4c458f88",
          "traceId": "3cc4ad5a",
          "type": "GENERATION",
          "name": "3cc4_psg_gen_attempt#3",
          "startTime": "2025-08-20T00:34:09.440000+00:00",
          "endTime": "2025-08-20T00:34:24.702000+00:00",
          "model": "qwen2.5-coder:14b",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 15262.0,
          "environment": "default",
          "promptTokens": 2048,
          "totalTokens": 2961,
          "costDetails": {},
          "completionTokens": 913,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-03-34-24-900072_chatcmpl-83db0686-fcd2-4dcb-a828-54c89bacad31",
          "traceId": "3cc4ad5a",
          "type": "GENERATION",
          "name": "3cc4_psg_gen_attempt#4",
          "startTime": "2025-08-20T00:34:24.900000+00:00",
          "endTime": "2025-08-20T00:34:37.999000+00:00",
          "model": "qwen2.5-coder:14b",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 13099.0,
          "environment": "default",
          "promptTokens": 2048,
          "totalTokens": 2824,
          "costDetails": {},
          "completionTokens": 776,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        }
      ],
      "createdAt": "2025-08-20T00:33:45.604Z",
      "environment": "default",
      "updatedAt": "2025-08-20T00:35:15.276Z"
    },
    {
      "id": "c5ec849c",
      "timestamp": "2025-08-20T00:32:19.934000+00:00",
      "name": "c5ec_py_sketch_generator",
      "input": null,
      "output": {
        "status": "failed",
        "last_code": "import numpy as np\nimport cv2\nimport tensorflow as tf\n\n# Phase 1: Setup\nmodel_path  = \"models/ssd-mobilenet_v1/detect.tflite\"\nlabel_path  = \"models/ssd-mobilenet_v1/labelmap.txt\"\ninput_path  = \"data/object_detection/sheeps.mp4\"\noutput_path  = \"results/object_detection/test_results/sheeps_detections.mp4\"\nconfidence_threshold  = 0.5\n\n# Load Labels\nwith open(label_path, 'r') as f:\n    labels = [line.strip() for line in f.readlines()]\n\n# Load Interpreter\ninterpreter = tf.lite.Interpreter(model_path=model_path)\ninterpreter.allocate_tensors()\n\n# Get Model Details\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\n\n# Phase 2: Input Acquisition & Preprocessing Loop\ncap = cv2.VideoCapture(input_path)\n\nwhile cap.isOpened():\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    # Preprocess Data\n    input_height, input_width = input_details[0]['shape'][1], input_details[0]['shape'][2]\n    resized_frame = cv2.resize(frame, (input_width, input_height))\n    normalized_frame = resized_frame / 255.0\n    input_data = np.expand_dims(normalized_frame, axis=0).astype(input_details[0]['dtype'])\n\n    # Phase 3: Inference\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n    interpreter.invoke()\n\n    # Phase 4: Output Interpretation & Handling Loop\n    boxes = interpreter.get_tensor(output_details[1]['index'])\n    scores = interpreter.get_tensor(output_details[2]['index'])\n    classes = interpreter.get_tensor(output_details[3]['index']).astype(int)\n\n    # Assuming the number of detections is in the first output tensor (output_details[0])\n    num_detections = int(interpreter.get_tensor(output_details[0]['index'])[0])  # Access the first element\n\n    # Filter out detections below the confidence threshold\n    for i in range(num_detections):\n        if scores[0, i] > confidence_threshold:\n            label = labels[classes[0, i]]\n            ymin, xmin, ymax, xmax = boxes[0, i]\n\n            # Draw bounding box and label on the frame\n            cv2.rectangle(frame, (int(xmin * frame.shape[1]), int(ymin * frame.shape[0])), \n                           (int(xmax * frame.shape[1]), int(ymax * frame.shape[0])), (0, 255, 0), 2)\n            cv2.putText(frame, f'{label}: {scores[0, i]:.2f}', \n                        (int(xmin * frame.shape[1]), int(ymin * frame.shape[0]) - 10), \n                        cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n\n    # Display the resulting frame\n    cv2.imshow('Object Detection', frame)\n    if cv2.waitKey(1) & 0xFF == ord('q'):\n        break\n\n# Phase 5: Cleanup\ncap.release()\ncv2.destroyAllWindows()",
        "last_error": "Max retries reached with failure. Last error from execution: 2025-08-20 03:33:36.045715: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n2025-08-20 03:33:36.050204: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n2025-08-20 03:33:36.064201: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2025-08-20 03:33:36.085681: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2025-08-20 03:33:36.091991: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n2025-08-20 03:33:36.107768: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\nTo enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n2025-08-20 03:33:36.966208: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\nINFO: Created TensorFlow Lite XNNPACK delegate for CPU.\nTraceback (most recent call last):\n  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250820033335_psg_qwen2.5-coder:14b/tmp_20250820033335_psg_qwen2.5-coder:14b.py\", line 48, in <module>\n    num_detections = int(interpreter.get_tensor(output_details[0]['index'])[0])  # Access the first element\nTypeError: only length-1 arrays can be converted to Python scalars\n"
      },
      "session_id": "qwen2.5-coder:14b_c83f_psg_batch",
      "metadata": {
        "num_run": 6
      },
      "tags": [
        "benchmark",
        "py_sketch_generator",
        "qwen2.5-coder:14b"
      ],
      "latency": 78.972,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-03-32-19-936209_chatcmpl-ef4041bf-bb3d-48a5-aa01-0f1ab6309232",
          "traceId": "c5ec849c",
          "type": "GENERATION",
          "name": "c5ec_psg_gen_attempt#1",
          "startTime": "2025-08-20T00:32:19.936000+00:00",
          "endTime": "2025-08-20T00:32:30.500000+00:00",
          "model": "qwen2.5-coder:14b",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 10564.0,
          "environment": "default",
          "promptTokens": 1618,
          "totalTokens": 2240,
          "costDetails": {},
          "completionTokens": 622,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-03-32-30-641060_chatcmpl-f24c7afd-4f22-4b7b-8b83-ee0d0d7d0afb",
          "traceId": "c5ec849c",
          "type": "GENERATION",
          "name": "c5ec_psg_gen_attempt#2",
          "startTime": "2025-08-20T00:32:30.641000+00:00",
          "endTime": "2025-08-20T00:32:42.208000+00:00",
          "model": "qwen2.5-coder:14b",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 11567.0,
          "environment": "default",
          "promptTokens": 2048,
          "totalTokens": 2727,
          "costDetails": {},
          "completionTokens": 679,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-03-32-45-352246_chatcmpl-90190ada-379a-4bd2-9ecc-3164920acc3e",
          "traceId": "c5ec849c",
          "type": "GENERATION",
          "name": "c5ec_psg_gen_attempt#3",
          "startTime": "2025-08-20T00:32:45.352000+00:00",
          "endTime": "2025-08-20T00:33:00.551000+00:00",
          "model": "qwen2.5-coder:14b",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 15199.0,
          "environment": "default",
          "promptTokens": 2048,
          "totalTokens": 2954,
          "costDetails": {},
          "completionTokens": 906,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-03-33-03-757622_chatcmpl-a0769538-ba17-45ef-996c-c44c3fd3c18d",
          "traceId": "c5ec849c",
          "type": "GENERATION",
          "name": "c5ec_psg_gen_attempt#4",
          "startTime": "2025-08-20T00:33:03.757000+00:00",
          "endTime": "2025-08-20T00:33:17.315000+00:00",
          "model": "qwen2.5-coder:14b",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 13558.0,
          "environment": "default",
          "promptTokens": 2048,
          "totalTokens": 2852,
          "costDetails": {},
          "completionTokens": 804,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-03-33-20-620439_chatcmpl-797107fa-1447-4a9a-be8e-f1cf4ed49ac4",
          "traceId": "c5ec849c",
          "type": "GENERATION",
          "name": "c5ec_psg_gen_attempt#5",
          "startTime": "2025-08-20T00:33:20.620000+00:00",
          "endTime": "2025-08-20T00:33:35.694000+00:00",
          "model": "qwen2.5-coder:14b",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 15074.0,
          "environment": "default",
          "promptTokens": 2048,
          "totalTokens": 2948,
          "costDetails": {},
          "completionTokens": 900,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "b3e74950-8e9b-4a1a-b70c-bc2189356ee6",
          "traceId": "c5ec849c",
          "type": "SPAN",
          "name": "error_c5_psg_failure_signal_py_sketch_generator",
          "startTime": "2025-08-20T00:33:38.908000+00:00",
          "level": "ERROR",
          "statusMessage": "Failed. Last error: Max retries reached with failure. Last error from execution: 2025-08-20 03:33:36.045715: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n2025-08-20 03:33:36.050204: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n2025-08-20 03:33:36.064201: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2025-08-20 03:33:36.085681: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2025-08-20 03:33:36.091991: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n2025-08-20 03:33:36.107768: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\nTo enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n2025-08-20 03:33:36.966208: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\nINFO: Created TensorFlow Lite XNNPACK delegate for CPU.\nTraceback (most recent call last):\n  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250820033335_psg_qwen2.5-coder:14b/tmp_20250820033335_psg_qwen2.5-coder:14b.py\", line 48, in <module>\n    num_detections = int(interpreter.get_tensor(output_details[0]['index'])[0])  # Access the first element\nTypeError: only length-1 arrays can be converted to Python scalars\n",
          "calculatedTotalCost": 0.0,
          "environment": "default",
          "promptTokens": 0,
          "totalTokens": 0,
          "costDetails": {},
          "completionTokens": 0,
          "endTime": null,
          "model": null,
          "modelParameters": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null,
          "latency": null
        }
      ],
      "createdAt": "2025-08-20T00:32:20.457Z",
      "environment": "default",
      "updatedAt": "2025-08-20T00:33:44.168Z"
    },
    {
      "id": "718a3615",
      "timestamp": "2025-08-20T00:31:38.414000+00:00",
      "name": "718a_py_sketch_generator",
      "input": null,
      "output": {
        "status": "success",
        "sketch": "import tensorflow as tf\nimport numpy as np\nimport cv2\n\n# Phase 1: Setup\nmodel_path  = \"models/ssd-mobilenet_v1/detect.tflite\"\nlabel_path  = \"models/ssd-mobilenet_v1/labelmap.txt\"\ninput_path  = \"data/object_detection/sheeps.mp4\"\noutput_path  = \"results/object_detection/test_results/sheeps_detections.mp4\"\nconfidence_threshold  = 0.5\n\n# Load labels\nwith open(label_path, 'r') as f:\n    labels = [line.strip() for line in f.readlines()]\n\n# Load interpreter\ninterpreter = tf.lite.Interpreter(model_path=model_path)\ninterpreter.allocate_tensors()\n\n# Get model details\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\n\ninput_shape = input_details[0]['shape']\ninput_dtype = input_details[0]['dtype']\n\n# Phase 2: Input Acquisition & Preprocessing Loop\ncap = cv2.VideoCapture(input_path)\nfourcc = cv2.VideoWriter_fourcc(*'mp4v')\nout = cv2.VideoWriter(output_path, fourcc, 30.0, (int(cap.get(3)), int(cap.get(4))))\n\nwhile cap.isOpened():\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    # Preprocess data\n    input_data = cv2.resize(frame, (input_shape[1], input_shape[2]))\n    input_data = np.expand_dims(input_data, axis=0).astype(np.uint8)  # Convert to uint8\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n\n    # Phase 3: Inference\n    interpreter.invoke()\n\n    # Phase 4: Output Interpretation & Handling Loop\n    boxes = interpreter.get_tensor(output_details[0]['index'])[0]\n    classes = interpreter.get_tensor(output_details[1]['index'])[0].astype(np.int32)\n    scores = interpreter.get_tensor(output_details[2]['index'])[0]\n\n    for i in range(len(scores)):\n        if scores[i] > confidence_threshold:\n            class_name = labels[classes[i]]\n            y_min, x_min, y_max, x_max = boxes[i]\n            y_min = int(y_min * frame.shape[0])\n            x_min = int(x_min * frame.shape[1])\n            y_max = int(y_max * frame.shape[0])\n            x_max = int(x_max * frame.shape[1])\n\n            cv2.rectangle(frame, (x_min, y_min), (x_max, y_max), (0, 255, 0), 2)\n            cv2.putText(frame, f'{class_name}: {scores[i]:.2f}', (x_min, y_min - 10),\n                        cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n\n    out.write(frame)\n\n# Phase 5: Cleanup\ncap.release()\nout.release()\ncv2.destroyAllWindows()"
      },
      "session_id": "qwen2.5-coder:14b_c83f_psg_batch",
      "metadata": {
        "num_run": 5
      },
      "tags": [
        "benchmark",
        "py_sketch_generator",
        "qwen2.5-coder:14b"
      ],
      "latency": 27.476,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-03-31-38-415846_chatcmpl-640c619f-a56c-441d-8963-4cc66bb1b701",
          "traceId": "718a3615",
          "type": "GENERATION",
          "name": "718a_psg_gen_attempt#1",
          "startTime": "2025-08-20T00:31:38.415000+00:00",
          "endTime": "2025-08-20T00:31:48.894000+00:00",
          "model": "qwen2.5-coder:14b",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 10479.0,
          "environment": "default",
          "promptTokens": 1618,
          "totalTokens": 2237,
          "costDetails": {},
          "completionTokens": 619,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-03-31-51-993354_chatcmpl-09747a47-1c4c-46b0-a003-cc4b355d9dea",
          "traceId": "718a3615",
          "type": "GENERATION",
          "name": "718a_psg_gen_attempt#2",
          "startTime": "2025-08-20T00:31:51.993000+00:00",
          "endTime": "2025-08-20T00:32:05.891000+00:00",
          "model": "qwen2.5-coder:14b",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 13898.0,
          "environment": "default",
          "promptTokens": 2048,
          "totalTokens": 2873,
          "costDetails": {},
          "completionTokens": 825,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        }
      ],
      "createdAt": "2025-08-20T00:31:38.934Z",
      "environment": "default",
      "updatedAt": "2025-08-20T00:32:19.558Z"
    },
    {
      "id": "57cf3dd2",
      "timestamp": "2025-08-20T00:30:42.914000+00:00",
      "name": "57cf_py_sketch_generator",
      "input": null,
      "output": {
        "status": "success",
        "sketch": "import numpy as np\nimport cv2\nimport tensorflow as tf\n\n# Phase 1: Setup\nmodel_path   = \"models/ssd-mobilenet_v1/detect.tflite\"\nlabel_path   = \"models/ssd-mobilenet_v1/labelmap.txt\"\ninput_path   = \"data/object_detection/sheeps.mp4\"\noutput_path   = \"results/object_detection/test_results/sheeps_detections.mp4\"\nconfidence_threshold   = 0.5\n\n# Load labels\nwith open(label_path, 'r') as f:\n    labels = [line.strip() for line in f.readlines()]\n\n# Load interpreter and allocate tensors\ninterpreter = tf.lite.Interpreter(model_path=model_path)\ninterpreter.allocate_tensors()\n\n# Get model details\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\n\n# Phase 2: Input Acquisition & Preprocessing Loop\ncap = cv2.VideoCapture(input_path)\nfourcc = cv2.VideoWriter_fourcc(*'mp4v')\nout = cv2.VideoWriter(output_path, fourcc, 30.0, (int(cap.get(3)), int(cap.get(4))))\n\nwhile cap.isOpened():\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    # Preprocess data\n    input_height, input_width = input_details[0]['shape'][1:3]\n    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n    frame_resized = cv2.resize(frame_rgb, (input_width, input_height))\n    input_data = np.expand_dims(frame_resized, axis=0).astype(input_details[0]['dtype'])\n\n    # Phase 3: Inference\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n    interpreter.invoke()\n\n    # Phase 4: Output Interpretation & Handling Loop\n    boxes = interpreter.get_tensor(output_details[0]['index'])[0]  # Assuming the first output is bounding boxes\n    classes = interpreter.get_tensor(output_details[1]['index'])[0].astype(np.int32)  # Assuming the second output is class indices\n    scores = interpreter.get_tensor(output_details[2]['index'])[0]  # Assuming the third output is scores\n\n    for i in range(len(scores)):\n        if scores[i] > confidence_threshold:\n            y_min, x_min, y_max, x_max = boxes[i]\n            label = labels[classes[i]]\n            cv2.rectangle(frame, (int(x_min * input_width), int(y_min * input_height)), \n                             (int(x_max * input_width), int(y_max * input_height)), (0, 255, 0), 2)\n            cv2.putText(frame, f'{label}: {scores[i]:.2f}', \n                         (int(x_min * input_width), int(y_min * input_height) - 10), cv2.FONT_HERSHEY_SIMPLEX, \n                         0.9, (0, 255, 0), 2)\n\n    # Handle Output\n    out.write(frame)\n\n# Phase 5: Cleanup\ncap.release()\nout.release()\ncv2.destroyAllWindows()"
      },
      "session_id": "qwen2.5-coder:14b_c83f_psg_batch",
      "metadata": {
        "num_run": 4
      },
      "tags": [
        "benchmark",
        "py_sketch_generator",
        "qwen2.5-coder:14b"
      ],
      "latency": 41.562,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-03-30-42-916004_chatcmpl-b680a2f6-4dc6-4e1e-8247-2687e3129d3c",
          "traceId": "57cf3dd2",
          "type": "GENERATION",
          "name": "57cf_psg_gen_attempt#1",
          "startTime": "2025-08-20T00:30:42.916000+00:00",
          "endTime": "2025-08-20T00:30:53.491000+00:00",
          "model": "qwen2.5-coder:14b",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 10575.0,
          "environment": "default",
          "promptTokens": 1618,
          "totalTokens": 2242,
          "costDetails": {},
          "completionTokens": 624,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-03-30-53-632066_chatcmpl-473dc724-f237-45ae-9e84-959e98b5ba4d",
          "traceId": "57cf3dd2",
          "type": "GENERATION",
          "name": "57cf_psg_gen_attempt#2",
          "startTime": "2025-08-20T00:30:53.632000+00:00",
          "endTime": "2025-08-20T00:31:06.131000+00:00",
          "model": "qwen2.5-coder:14b",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 12499.0,
          "environment": "default",
          "promptTokens": 2048,
          "totalTokens": 2786,
          "costDetails": {},
          "completionTokens": 738,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-03-31-09-282506_chatcmpl-336952db-5c8e-443a-991f-1d81fd35ad36",
          "traceId": "57cf3dd2",
          "type": "GENERATION",
          "name": "57cf_psg_gen_attempt#3",
          "startTime": "2025-08-20T00:31:09.282000+00:00",
          "endTime": "2025-08-20T00:31:24.478000+00:00",
          "model": "qwen2.5-coder:14b",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 15196.0,
          "environment": "default",
          "promptTokens": 2048,
          "totalTokens": 2956,
          "costDetails": {},
          "completionTokens": 908,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        }
      ],
      "createdAt": "2025-08-20T00:30:43.434Z",
      "environment": "default",
      "updatedAt": "2025-08-20T00:31:38.112Z"
    },
    {
      "id": "1da4229d",
      "timestamp": "2025-08-20T00:29:42.413000+00:00",
      "name": "1da4_py_sketch_generator",
      "input": null,
      "output": {
        "status": "success",
        "sketch": "import numpy as np\nimport cv2\nimport tensorflow.lite as tflite\n\n# Phase 1: Setup\nmodel_path  = \"models/ssd-mobilenet_v1/detect.tflite\"\nlabel_path  = \"models/ssd-mobilenet_v1/labelmap.txt\"\ninput_path  = \"data/object_detection/sheeps.mp4\"\noutput_path  = \"results/object_detection/test_results/sheeps_detections.mp4\"\nconfidence_threshold  = 0.5\n\n# Load labels\nwith open(label_path, 'r') as f:\n    labels = [line.strip() for line in f.readlines()]\n\n# Load interpreter\ninterpreter = tflite.Interpreter(model_path=model_path)\ninterpreter.allocate_tensors()\n\n# Get model details\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\n\n# Phase 2: Input Acquisition & Preprocessing Loop\ncap = cv2.VideoCapture(input_path)\n\n# Define the codec and create VideoWriter object\nfourcc = cv2.VideoWriter_fourcc(*'XVID')\nout = cv2.VideoWriter(output_path, fourcc, 20.0, (int(cap.get(3)), int(cap.get(4))))\n\nwhile cap.isOpened():\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    # Resize and normalize the image\n    input_height, input_width = input_details[0]['shape'][1], input_details[0]['shape'][2]\n    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n    frame_resized = cv2.resize(frame_rgb, (input_width, input_height))\n    \n    # Convert to UINT8 if the model expects it\n    if input_details[0]['dtype'] == np.uint8:\n        input_data = np.expand_dims(frame_resized, axis=0).astype(np.uint8)\n    else:\n        input_data = np.expand_dims(frame_resized / 255.0, axis=0).astype(np.float32)\n\n    # Phase 3: Inference\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n    interpreter.invoke()\n\n    # Phase 4: Output Interpretation & Handling Loop\n    boxes = interpreter.get_tensor(output_details[0]['index'])[0]  # Corrected index access\n    classes = interpreter.get_tensor(output_details[1]['index'])[0].astype(np.int32)  # Corrected index access\n    scores = interpreter.get_tensor(output_details[2]['index'])[0]  # Corrected index access\n\n    for i in range(len(scores)):\n        if scores[i] > confidence_threshold:\n            label = labels[classes[i]]\n            ymin, xmin, ymax, xmax = boxes[i]\n            (left, right, top, bottom) = (xmin * frame.shape[1], xmax * frame.shape[1],\n                                          ymin * frame.shape[0], ymax * frame.shape[0])\n            left, right, top, bottom = int(left), int(right), int(top), int(bottom)\n            cv2.rectangle(frame, (left, top), (right, bottom), (0, 255, 0), 2)\n            cv2.putText(frame, f'{label}: {scores[i]:.2f}', (left, top - 10),\n                        cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n\n    # Write the frame with detections to the output video\n    out.write(frame)\n\n# Phase 5: Cleanup\ncap.release()\nout.release()\ncv2.destroyAllWindows()"
      },
      "session_id": "qwen2.5-coder:14b_c83f_psg_batch",
      "metadata": {
        "num_run": 3
      },
      "tags": [
        "benchmark",
        "py_sketch_generator",
        "qwen2.5-coder:14b"
      ],
      "latency": 46.41,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-03-29-42-414713_chatcmpl-29d47163-da3c-45dc-b015-4d075f8e406c",
          "traceId": "1da4229d",
          "type": "GENERATION",
          "name": "1da4_psg_gen_attempt#1",
          "startTime": "2025-08-20T00:29:42.414000+00:00",
          "endTime": "2025-08-20T00:29:52.928000+00:00",
          "model": "qwen2.5-coder:14b",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 10514.0,
          "environment": "default",
          "promptTokens": 1618,
          "totalTokens": 2237,
          "costDetails": {},
          "completionTokens": 619,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-03-29-53-070118_chatcmpl-28d8dceb-6420-4743-9fb7-08e1e91baacf",
          "traceId": "1da4229d",
          "type": "GENERATION",
          "name": "1da4_psg_gen_attempt#2",
          "startTime": "2025-08-20T00:29:53.070000+00:00",
          "endTime": "2025-08-20T00:30:05.839000+00:00",
          "model": "qwen2.5-coder:14b",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 12769.0,
          "environment": "default",
          "promptTokens": 2048,
          "totalTokens": 2802,
          "costDetails": {},
          "completionTokens": 754,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-03-30-13-173324_chatcmpl-fb9f3b6e-3371-4b53-a085-a01db0aca0fc",
          "traceId": "1da4229d",
          "type": "GENERATION",
          "name": "1da4_psg_gen_attempt#3",
          "startTime": "2025-08-20T00:30:13.173000+00:00",
          "endTime": "2025-08-20T00:30:28.824000+00:00",
          "model": "qwen2.5-coder:14b",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 15651.0,
          "environment": "default",
          "promptTokens": 2048,
          "totalTokens": 2984,
          "costDetails": {},
          "completionTokens": 936,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        }
      ],
      "createdAt": "2025-08-20T00:29:42.934Z",
      "environment": "default",
      "updatedAt": "2025-08-20T00:30:42.620Z"
    },
    {
      "id": "6df1c160",
      "timestamp": "2025-08-20T00:28:53.897000+00:00",
      "name": "6df1_py_sketch_generator",
      "input": null,
      "output": {
        "status": "success",
        "sketch": "import numpy as np\nfrom tflite_runtime.interpreter import Interpreter\nimport cv2\n\n# Phase 1: Setup\nmodel_path  = \"models/ssd-mobilenet_v1/detect.tflite\"\nlabel_path  = \"models/ssd-mobilenet_v1/labelmap.txt\"\ninput_path  = \"data/object_detection/sheeps.mp4\"\noutput_path  = \"results/object_detection/test_results/sheeps_detections.mp4\"\nconfidence_threshold  = 0.5\n\n# Load Labels\nwith open(label_path, 'r') as f:\n    labels = [line.strip() for line in f.readlines()]\n\n# Load Interpreter\ninterpreter = Interpreter(model_path=model_path)\ninterpreter.allocate_tensors()\n\n# Get Model Details\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\n\n# Phase 2: Input Acquisition & Preprocessing Loop\ncap = cv2.VideoCapture(input_path)\nfourcc = cv2.VideoWriter_fourcc(*'mp4v')\nout = cv2.VideoWriter(output_path, fourcc, cap.get(cv2.CAP_PROP_FPS), (int(cap.get(3)), int(cap.get(4))))\n\nwhile cap.isOpened():\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    # Preprocess Data\n    image_np = np.array(frame)\n    input_data = cv2.resize(image_np, (input_details[0]['shape'][1], input_details[0]['shape'][2]))\n    input_data = (input_data - 127.5) / 127.5  # Normalize to [-1, 1]\n    input_data = np.expand_dims(input_data, axis=0)\n    input_data = input_data.astype(input_details[0]['dtype'])\n\n    # Phase 3: Inference\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n    interpreter.invoke()\n\n    # Phase 4: Output Interpretation & Handling Loop\n    boxes = interpreter.get_tensor(output_details[0]['index'])[0]\n    classes = interpreter.get_tensor(output_details[1]['index'])[0]\n    scores = interpreter.get_tensor(output_details[2]['index'])[0]\n\n    for i in range(len(scores)):\n        if scores[i] > confidence_threshold:\n            class_id = int(classes[i])\n            label = labels[class_id]\n            box = boxes[i]\n            y_min, x_min, y_max, x_max = map(int, box * [image_np.shape[1], image_np.shape[0], image_np.shape[1], image_np.shape[0]])\n            cv2.rectangle(image_np, (x_min, y_min), (x_max, y_max), (0, 255, 0), 2)\n            cv2.putText(image_np, f'{label}: {scores[i]:.2f}', (x_min, y_min - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n\n    # Handle Output\n    out.write(image_np)\n\n# Phase 5: Cleanup\ncap.release()\nout.release()\ncv2.destroyAllWindows()"
      },
      "session_id": "qwen2.5-coder:14b_c83f_psg_batch",
      "metadata": {
        "num_run": 2
      },
      "tags": [
        "benchmark",
        "py_sketch_generator",
        "qwen2.5-coder:14b"
      ],
      "latency": 11.022,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-03-28-53-898884_chatcmpl-e6328028-c91a-4b7f-8726-02c469747ece",
          "traceId": "6df1c160",
          "type": "GENERATION",
          "name": "6df1_psg_gen_attempt#1",
          "startTime": "2025-08-20T00:28:53.898000+00:00",
          "endTime": "2025-08-20T00:29:04.920000+00:00",
          "model": "qwen2.5-coder:14b",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 11022.0,
          "environment": "default",
          "promptTokens": 1618,
          "totalTokens": 2269,
          "costDetails": {},
          "completionTokens": 651,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        }
      ],
      "createdAt": "2025-08-20T00:28:54.419Z",
      "environment": "default",
      "updatedAt": "2025-08-20T00:29:42.109Z"
    },
    {
      "id": "37cbf370",
      "timestamp": "2025-08-20T00:27:46.291000+00:00",
      "name": "37cb_py_sketch_generator",
      "input": null,
      "output": {
        "status": "success",
        "sketch": "import numpy as np\nimport cv2\nfrom tflite_runtime.interpreter import Interpreter\n\n# Phase 1: Setup\n\n# Paths/Parameters\nmodel_path  = \"models/ssd-mobilenet_v1/detect.tflite\"\nlabel_path  = \"models/ssd-mobilenet_v1/labelmap.txt\"\ninput_path  = \"data/object_detection/sheeps.mp4\"\noutput_path  = \"results/object_detection/test_results/sheeps_detections.mp4\"\nconfidence_threshold  = 0.5\n\n# Load Labels (Conditional)\nwith open(label_path, 'r') as f:\n    labels = [line.strip() for line in f.readlines()]\n\n# Load Interpreter\ninterpreter = Interpreter(model_path=model_path)\ninterpreter.allocate_tensors()\n\n# Get Model Details\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\n\ninput_shape = input_details[0]['shape']\ninput_dtype = input_details[0]['dtype']\n\n# Phase 2: Input Acquisition & Preprocessing Loop\n\n# Acquire Input Data\ncap = cv2.VideoCapture(input_path)\n\n# Check if video opened successfully\nif not cap.isOpened():\n    print(\"Error opening video stream or file\")\n    exit()\n\nframe_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\nframe_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n\nout = cv2.VideoWriter(output_path, cv2.VideoWriter_fourcc(*'mp4v'), 30.0, (frame_width, frame_height))\n\nwhile cap.isOpened():\n    ret, frame = cap.read()\n    \n    if not ret:\n        break\n\n    # Preprocess Data\n    input_data = cv2.resize(frame, (input_shape[1], input_shape[2]))\n    input_data = input_data[:, :, ::-1]  # Convert BGR to RGB\n    input_data = np.expand_dims(input_data, axis=0)\n    input_data = (input_data / 127.5) - 1.0  # Normalize to [-1, 1]\n    \n    if input_dtype == np.uint8:\n        input_data = input_data.astype(np.uint8)\n    elif input_dtype == np.float32:\n        input_data = input_data.astype(np.float32)\n\n    # Phase 3: Inference\n\n    # Set Input Tensor(s)\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n\n    # Run Inference\n    interpreter.invoke()\n\n    # Phase 4: Output Interpretation & Handling Loop\n\n    # Get Output Tensor(s)\n    boxes = interpreter.get_tensor(output_details[0]['index'])[0]\n    classes = interpreter.get_tensor(output_details[1]['index'])[0].astype(np.int32)\n    scores = interpreter.get_tensor(output_details[2]['index'])[0]\n\n    # Interpret Results\n    for i in range(len(scores)):\n        if scores[i] > confidence_threshold:\n            label = labels[classes[i]]\n            ymin, xmin, ymax, xmax = boxes[i]\n            (startX, startY) = (int(xmin * frame_width), int(ymin * frame_height))\n            (endX, endY) = (int(xmax * frame_width), int(ymax * frame_height))\n\n            # Draw the bounding box and label on the image\n            cv2.rectangle(frame, (startX, startY), (endX, endY), (0, 255, 0), 2)\n            y = startY - 10 if startY - 10 > 10 else startY + 10\n            cv2.putText(frame, f'{label}: {scores[i]:.2f}', (startX, y),\n                        cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n\n    # Handle Output\n    out.write(frame)\n\n# Phase 5: Cleanup\n\ncap.release()\nout.release()\ncv2.destroyAllWindows()"
      },
      "session_id": "qwen2.5-coder:14b_c83f_psg_batch",
      "metadata": {
        "num_run": 1
      },
      "tags": [
        "benchmark",
        "py_sketch_generator",
        "qwen2.5-coder:14b"
      ],
      "latency": 29.451,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-03-27-46-294306_chatcmpl-eb8b2131-76e0-4d4c-af38-12acf256e1aa",
          "traceId": "37cbf370",
          "type": "GENERATION",
          "name": "37cb_psg_gen_attempt#1",
          "startTime": "2025-08-20T00:27:46.294000+00:00",
          "endTime": "2025-08-20T00:27:58.867000+00:00",
          "model": "qwen2.5-coder:14b",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 12573.0,
          "environment": "default",
          "promptTokens": 1618,
          "totalTokens": 2356,
          "costDetails": {},
          "completionTokens": 738,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-03-27-59-161744_chatcmpl-e842a86d-7322-4979-a481-bf48aeac15fe",
          "traceId": "37cbf370",
          "type": "GENERATION",
          "name": "37cb_psg_gen_attempt#2",
          "startTime": "2025-08-20T00:27:59.161000+00:00",
          "endTime": "2025-08-20T00:28:15.745000+00:00",
          "model": "qwen2.5-coder:14b",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 16584.0,
          "environment": "default",
          "promptTokens": 2048,
          "totalTokens": 3044,
          "costDetails": {},
          "completionTokens": 996,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        }
      ],
      "createdAt": "2025-08-20T00:27:46.811Z",
      "environment": "default",
      "updatedAt": "2025-08-20T00:28:53.038Z"
    }
  ],
  "meta": {
    "total_items": 30
  }
}
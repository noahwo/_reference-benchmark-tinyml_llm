{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setting up\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ref: https://langfuse.com/docs/query-traces\n",
    "import os\n",
    "import json\n",
    "from langfuse import Langfuse\n",
    "import json\n",
    "import os\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "LOCAL_HOST = True\n",
    "\n",
    "\"\"\"Define session_id\"\"\"\n",
    "# session_id=\"qwen2.5-coder_f4d4_dp_batch\"\n",
    "session_id_list = [\n",
    "    # \"qwen2.5-coder:32b_4e11_tpsg_batch\",\n",
    "    # \"qwen2.5-coder:32b_ae24_tpsg_batch\"\n",
    "    \"codestral_fc8d_tpusg_batch\",]\n",
    "\n",
    "\n",
    "\"\"\"Define paths\"\"\"\n",
    " \n",
    "parent_dir = os.path.dirname(os.getcwd())\n",
    "\n",
    " \n",
    "# date = os.path.basename(parent_dir)\n",
    "tex_dir = os.path.join(parent_dir, \"tex\")\n",
    "processed_data_dir = os.path.join(parent_dir, \"processed_data\")\n",
    "raw_export_dir = os.path.join(parent_dir, \"raw_export\")\n",
    "ipynb_dir = os.path.join(parent_dir, \"ipynb\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Export raw data\n",
    "\n",
    "Langfuse added a limit of 20 API invocations per minute. https://langfuse.com/faq/all/api-limits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching traces for session codestral_fc8d_tpusg_batch...\n",
      "Fetching observation data for time-14-50-24-133135_chatcmpl-c0ba8da6-6d05-41d5-92fe-c8f8b4035d90...\n",
      "Fetching observation data for time-14-50-58-858479_chatcmpl-f6ac91a2-ed44-4670-87f3-211bebd0ee59...\n",
      "Fetching observation data for time-14-51-28-237298_chatcmpl-a3e15b33-3879-4c20-a26b-99a4acbcd142...\n",
      "Fetching observation data for time-14-52-00-239279_chatcmpl-ed4e7151-2460-4655-a684-9f64f01bd0f1...\n",
      "Fetching observation data for time-14-52-31-960820_chatcmpl-bef5be1d-460e-4a8d-b8a5-c9dc7dfc1271...\n",
      "Fetching observation data for f4f162d3-0c16-4fae-b6e2-f50424dba65b...\n",
      "Fetching observation data for time-14-48-23-584749_chatcmpl-abd3f107-a0ee-445b-84f6-5cd1bedf8969...\n",
      "Fetching observation data for time-14-49-00-167251_chatcmpl-8072d4d0-a20b-40ae-b211-d1988966ac7a...\n",
      "Fetching observation data for time-14-49-06-552168_chatcmpl-db10774b-6036-4574-ba29-c3827323ec14...\n",
      "Fetching observation data for time-14-49-21-071153_chatcmpl-90496051-712b-4362-a86e-b9f5ae850a37...\n",
      "Fetching observation data for time-14-49-48-817443_chatcmpl-2fa2ca03-9b59-4be8-89b5-5cf3acc3cda9...\n",
      "Fetching observation data for a005ad6e-e053-4f1c-94cf-9fa19b0ec5a9...\n",
      "Fetching observation data for time-14-46-39-022177_chatcmpl-b7d21a83-d51f-4799-a2ad-0c731c8434f8...\n",
      "Fetching observation data for time-14-47-15-559372_chatcmpl-603afda3-9ef7-41b1-845c-1ca6616b6c62...\n",
      "Fetching observation data for time-14-47-21-792787_chatcmpl-96088957-f746-4437-b1ac-a16328dde137...\n",
      "Fetching observation data for time-14-47-41-080211_chatcmpl-7ad842f9-da86-4d41-81c9-b2cf8e55eb33...\n",
      "Fetching observation data for time-14-47-59-390716_chatcmpl-8d6849ef-7bad-47cb-a9ee-1a8f1a530039...\n",
      "Fetching observation data for bc584e82-4f20-4153-be60-1703f546d2fa...\n",
      "Fetching observation data for time-14-45-24-491525_chatcmpl-254b2902-4d91-490d-a228-0344853267a0...\n",
      "Fetching observation data for time-14-46-01-057701_chatcmpl-7ce3f5f1-d3ad-4642-9048-ad9fb30f0326...\n",
      "Fetching observation data for time-14-46-08-308928_chatcmpl-b7d00cae-56f0-4214-b33c-15e37045edb6...\n",
      "Fetching observation data for time-14-46-14-444255_chatcmpl-ed91759b-4d28-4f71-824d-ff69df49a6ad...\n",
      "Fetching observation data for time-14-46-21-200444_chatcmpl-49326f85-f869-49fb-a672-0b30942a2791...\n",
      "Fetching observation data for 255ae535-bc8c-48d2-b98f-502001683c67...\n",
      "Fetching observation data for time-14-43-18-952749_chatcmpl-201f61b1-d028-4c88-b183-4e4c95df62c5...\n",
      "Fetching observation data for time-14-43-55-424900_chatcmpl-3dd2fc96-93f0-44e1-9cd3-0af25172559f...\n",
      "Fetching observation data for time-14-44-00-514852_chatcmpl-341a2c8e-b6ba-4f34-9987-5c9dc56b9555...\n",
      "Fetching observation data for time-14-44-24-951338_chatcmpl-037c37de-4758-4ae8-a968-8336fd3c023e...\n",
      "Fetching observation data for time-14-44-45-961220_chatcmpl-a2e1f943-6509-4d7d-9a7d-297b360abc3a...\n",
      "Fetching observation data for 9eb16c28-b027-4da1-ad5e-37aa8fc8f5eb...\n",
      "Fetching observation data for time-14-41-00-378049_chatcmpl-d8497254-9bbb-4a1c-bf6d-671bb2dd2651...\n",
      "Fetching observation data for time-14-41-34-971234_chatcmpl-eff93844-c431-40ab-af45-168ebc46e36e...\n",
      "Fetching observation data for time-14-41-41-003772_chatcmpl-7330278b-f306-40d1-9647-fde7e00d77e9...\n",
      "Fetching observation data for time-14-41-57-307891_chatcmpl-9dd8c7ef-e084-4737-9830-2e9d3a918932...\n",
      "Fetching observation data for time-14-42-35-919027_chatcmpl-213929ff-0f49-475c-bf6c-12ba8ac85830...\n",
      "Fetching observation data for 7645203a-0ab8-4c1c-a61f-6ff8988144d1...\n",
      "Fetching observation data for time-14-37-36-826682_chatcmpl-303d2df2-0c00-4a02-b2d9-9d12cb2c595b...\n",
      "Fetching observation data for time-14-38-13-414814_chatcmpl-a11333be-7696-4e64-89ad-e141b58599ba...\n",
      "Fetching observation data for time-14-38-50-985988_chatcmpl-6750d844-09ab-46c6-af92-2c01f71c9548...\n",
      "Fetching observation data for time-14-39-27-891074_chatcmpl-65b745cf-7790-4cbb-9b1c-ec3b939688b2...\n",
      "Fetching observation data for time-14-34-33-232624_chatcmpl-574ca1c5-6611-4385-bce8-9225029c7802...\n",
      "Fetching observation data for time-14-35-08-028606_chatcmpl-14c74997-2134-4dab-874d-773761f52dbc...\n",
      "Fetching observation data for time-14-35-42-983024_chatcmpl-2d74dec0-2cf5-4fc0-97d6-911190d62261...\n",
      "Fetching observation data for time-14-36-20-855889_chatcmpl-3b6d7cdc-7a3a-4794-8621-29f7ffc64a25...\n",
      "Fetching observation data for time-14-36-54-025075_chatcmpl-d33a94b8-d083-4e71-8a45-c1eb9716ae6e...\n",
      "Fetching observation data for 57175519-3e10-4e56-991b-dcf47f022a6b...\n",
      "Fetching observation data for time-14-33-19-223960_chatcmpl-87aa2fe6-3dd1-475d-bf5b-31e8fe13d8b8...\n",
      "Fetching observation data for time-14-33-55-743779_chatcmpl-97e45c8e-0dc5-40b3-bd34-90381531da4d...\n",
      "Fetching observation data for time-14-34-02-609898_chatcmpl-d8bf4ca3-e019-4652-bac8-1b38c13a6a8c...\n",
      "Fetching observation data for time-14-34-13-891761_chatcmpl-8000d9cd-5ba0-494d-aaa9-256a1604914c...\n",
      "Fetching observation data for time-14-34-20-656870_chatcmpl-83b93216-bcb5-4b8f-aac3-65e3be5db44f...\n",
      "Fetching observation data for c3207b3b-d60d-4da1-811d-bfa9b01782b7...\n",
      "Fetching observation data for time-14-32-03-642726_chatcmpl-ab49f370-5f69-4977-97dc-673ed096dca0...\n",
      "Fetching observation data for time-14-32-40-142655_chatcmpl-d215ab9c-de12-4f35-b586-f040f8a4777f...\n",
      "Fetching observation data for time-14-32-47-071762_chatcmpl-b8b418a7-a46b-44c1-a8f2-34270277b600...\n",
      "Fetching observation data for time-14-32-58-317987_chatcmpl-706fba63-af17-4c59-82a0-b0362306d1f7...\n",
      "Fetching observation data for time-14-33-07-038480_chatcmpl-e770a93b-40bb-4ed5-a7e1-3af6db1680c8...\n",
      "Fetching observation data for 89eab65d-0a4b-4c96-8ac8-0aae2fe4cfc4...\n",
      "Fetching observation data for time-14-29-20-070009_chatcmpl-86377ac5-d1bc-4d4d-bccb-ea521e88f8bf...\n",
      "Fetching observation data for time-14-29-56-614031_chatcmpl-0bb7e166-00d1-41c5-b31b-95905a20dc38...\n",
      "Fetching observation data for time-14-30-32-970850_chatcmpl-f0e68aab-a3a0-4c02-95ad-4970b5a840b6...\n",
      "Fetching observation data for time-14-31-11-048826_chatcmpl-4497d670-fc4a-429a-b6a7-fa93802dc234...\n",
      "Fetching observation data for time-14-31-47-832236_chatcmpl-0fe7c194-a80e-4e0c-bd9e-41785ebab028...\n",
      "Fetching observation data for c7393e82-a74e-4748-bfad-a243828d47c7...\n",
      "Fetching observation data for time-14-27-45-457396_chatcmpl-bd363546-6b1c-466b-906f-f9de7ad9432f...\n",
      "Fetching observation data for time-14-28-21-990615_chatcmpl-5097d7c6-42aa-4577-bb3c-d10d232a7afb...\n",
      "Fetching observation data for time-14-28-27-620433_chatcmpl-e599ea6b-2dd8-49e3-9652-1f1ec3f30c0f...\n",
      "Fetching observation data for time-14-28-46-165183_chatcmpl-e5962fa7-8fcb-4eca-a5d2-f6f4a7e81d55...\n",
      "Fetching observation data for time-14-29-03-900592_chatcmpl-50415662-4eb5-4f40-8070-9ae57e767b1b...\n",
      "Fetching observation data for f7ca5bfd-c84d-4789-aa2c-3a2fc4773f21...\n",
      "Fetching observation data for time-14-26-24-938787_chatcmpl-26592e71-88f1-4341-9682-5e603422c5b6...\n",
      "Fetching observation data for time-14-27-01-554117_chatcmpl-660ae8ca-3a3d-4536-91a5-19c4e0cc2cea...\n",
      "Fetching observation data for time-14-27-10-607248_chatcmpl-6fad5981-6b48-42ed-a067-0d1b8ffe335b...\n",
      "Fetching observation data for time-14-27-21-702962_chatcmpl-f69aaa43-01ab-440f-b1fc-b65f3c6105fe...\n",
      "Fetching observation data for time-14-27-27-844300_chatcmpl-7fa0b9ee-6d1c-437f-a51d-b4a276b46c7b...\n",
      "Fetching observation data for ddbb4e2b-4595-467e-96d3-ef02185b160e...\n",
      "Fetching observation data for time-14-23-46-404673_chatcmpl-317a81ec-0723-4c98-8b36-ddfa025a3ed1...\n",
      "Fetching observation data for time-14-24-22-867249_chatcmpl-cef2455c-1bd0-4eeb-9475-a25792df374f...\n",
      "Fetching observation data for time-14-24-29-598752_chatcmpl-8e5c6f19-51be-49b1-814b-99214cea77f3...\n",
      "Fetching observation data for time-14-25-08-007346_chatcmpl-b635d3dd-1ce4-4bd8-b5e0-a36ef600c031...\n",
      "Fetching observation data for time-14-25-40-610047_chatcmpl-167ee3e3-cdc6-4e1e-8bca-982d8425eb97...\n",
      "Fetching observation data for e9423978-e357-4550-96d8-47d8598242c8...\n",
      "Fetching observation data for time-14-22-28-907756_chatcmpl-e7b4d9e4-77a7-429c-bad1-fc92f4d83e32...\n",
      "Fetching observation data for time-14-23-05-444780_chatcmpl-fd08775b-03b2-466a-a013-eb0d47b3d4d5...\n",
      "Fetching observation data for time-14-23-14-348749_chatcmpl-bf3e385e-9a1f-4d69-9694-b5c00402cf84...\n",
      "Fetching observation data for time-14-23-25-527858_chatcmpl-e0c88c12-bf67-49ad-bb37-18ace431a834...\n",
      "Fetching observation data for time-14-23-33-703328_chatcmpl-937709ac-ecc7-4f1c-b031-2d9ca3276ac3...\n",
      "Fetching observation data for fed4f141-7091-4aa5-822e-218bfacf2d78...\n",
      "Fetching observation data for time-14-20-05-320465_chatcmpl-f3cf6c60-e9c9-447a-9e01-978357ed18cf...\n",
      "Fetching observation data for time-14-20-41-904005_chatcmpl-f9851703-c863-42b5-b99f-8fbd3dea348e...\n",
      "Fetching observation data for time-14-20-47-101276_chatcmpl-51f57df5-0d72-49ed-aaf7-3bc52df49503...\n",
      "Fetching observation data for time-14-21-25-560722_chatcmpl-8010d56a-7c16-4944-8c35-4466edd14dff...\n",
      "Fetching observation data for time-14-22-02-167063_chatcmpl-6b9e7e2f-9560-4417-b900-1980dca5ea55...\n",
      "Fetching observation data for 808bf183-a65b-48c6-b3a0-d074b3de919f...\n",
      "Fetching observation data for time-14-18-07-787732_chatcmpl-96a241e3-f3d4-49c9-b733-eb0f3b0f678f...\n",
      "Fetching observation data for time-14-18-44-383857_chatcmpl-2e5a4a5c-1993-44c7-a9bb-329fc3f9ff8a...\n",
      "Fetching observation data for time-14-18-49-997201_chatcmpl-c7b7873e-3bf9-4d07-abd3-025265ca80e3...\n",
      "Fetching observation data for time-14-19-07-868717_chatcmpl-b4259a2b-029f-4926-962d-a16fa898d8ba...\n",
      "Fetching observation data for time-14-19-26-554235_chatcmpl-f6ee8b44-6df4-4ef0-9a19-e174b32bd247...\n",
      "Fetching observation data for dde50d40-30b8-4ee1-afaf-7ec2a6970725...\n",
      "Fetching observation data for time-14-16-19-202822_chatcmpl-38511a08-2691-4f58-a286-8a2cf8ec119c...\n",
      "Fetching observation data for time-14-16-56-001477_chatcmpl-1b92ca2e-d932-4c46-b479-065b9088fc3e...\n",
      "Fetching observation data for time-14-17-27-098530_chatcmpl-3912b8c7-2a42-414e-a16a-07e1602a2aaf...\n",
      "Fetching observation data for time-14-17-45-733152_chatcmpl-227349ca-996f-4ed4-ae37-5a11f3eac990...\n",
      "Fetching observation data for time-14-17-56-324942_chatcmpl-b6d509f7-932f-4892-8484-4f63e832188a...\n",
      "Fetching observation data for a74e50e2-5fe8-4f36-bc5f-15e01bb6e8df...\n",
      "Fetching observation data for time-14-14-41-622848_chatcmpl-5df48474-f175-47d7-9d71-2e4acfece235...\n",
      "Fetching observation data for time-14-15-16-227163_chatcmpl-f47886ff-2aaf-4fb1-ba85-9645f63e391e...\n",
      "Fetching observation data for time-14-15-36-638091_chatcmpl-7068ee53-08f1-4d4a-a778-005d81630ba7...\n",
      "Fetching observation data for time-14-15-43-766947_chatcmpl-47bf7a28-63a1-4b4c-92a2-0319b75514c6...\n",
      "Fetching observation data for time-14-16-04-590651_chatcmpl-d4f289e4-c87c-43e7-9d12-3286669439e7...\n",
      "Fetching observation data for b0fcb62b-7a7d-42a5-bea1-86e257b9dc11...\n",
      "Fetching observation data for time-14-13-30-986437_chatcmpl-eea4dedb-180e-43b4-88f7-3b703080de73...\n",
      "Fetching observation data for time-14-14-05-532375_chatcmpl-ca77766b-ab48-4d33-a991-f88851173843...\n",
      "Fetching observation data for time-14-14-12-418209_chatcmpl-205a58c5-00f8-432a-ae23-1c8cc3954e4c...\n",
      "Fetching observation data for time-14-14-20-670084_chatcmpl-97b58996-61c8-464b-8dff-0daaedef026c...\n",
      "Fetching observation data for time-14-14-28-098860_chatcmpl-8f283d7f-56ed-4fe0-9503-9dd14412b2f9...\n",
      "Fetching observation data for b7a8ce83-77f5-4f47-9b63-8e5dc51c933d...\n",
      "Fetching observation data for time-14-12-24-878882_chatcmpl-7d7a5e25-97c2-4531-9a25-68dc39357418...\n",
      "Fetching observation data for time-14-12-59-395468_chatcmpl-b2371f50-0eaa-4cf0-b37c-ea0dbbbe8845...\n",
      "Fetching observation data for time-14-13-05-774701_chatcmpl-607efb2f-2653-42bc-b9cc-ddd77302356e...\n",
      "Fetching observation data for time-14-13-10-968209_chatcmpl-bc7d705d-c97c-48bf-a913-09b1fc4b06fc...\n",
      "Fetching observation data for time-14-13-17-405901_chatcmpl-622e7c0a-8d0c-4395-a2a5-cec833b1600f...\n",
      "Fetching observation data for 1268e004-5235-4cbe-baac-576496a9ed8b...\n",
      "Fetching observation data for time-14-10-08-480106_chatcmpl-5acb7ebf-1d28-4631-b34f-546902dd3a62...\n",
      "Fetching observation data for time-14-10-43-088303_chatcmpl-e286b2ef-cdd0-4172-a6a3-271f42c7c1c0...\n",
      "Fetching observation data for time-14-10-52-488078_chatcmpl-16445e5b-635b-4679-9e4c-74ccd4c49d4f...\n",
      "Fetching observation data for time-14-11-08-797082_chatcmpl-48205fa6-7deb-49d4-8977-f52536927d63...\n",
      "Fetching observation data for time-14-11-45-464441_chatcmpl-187f3b95-3d0f-43b0-8f3c-1f96e172208b...\n",
      "Fetching observation data for 377e7bd3-0136-4ae8-96fc-59598b3de3a5...\n",
      "Fetching observation data for time-14-07-41-838997_chatcmpl-fe771f23-6b9d-47d0-8f15-246f2ada8b8f...\n",
      "Fetching observation data for time-14-08-18-424100_chatcmpl-77ba0639-7412-46ae-baf3-6e64a5618350...\n",
      "Fetching observation data for time-14-08-25-330952_chatcmpl-7a11948a-2dcc-4d3a-ba4e-e9f7abac418f...\n",
      "Fetching observation data for time-14-08-56-498246_chatcmpl-8d6cc0d6-1d1f-450e-8501-a3ef78252807...\n",
      "Fetching observation data for time-14-09-29-446861_chatcmpl-51ea25cf-f5c7-43a1-b64d-4594b4358b17...\n",
      "Fetching observation data for c92413e2-c5b9-4872-a692-26bf1ccdacd4...\n",
      "Fetching observation data for time-14-06-09-216495_chatcmpl-db3be06e-17fe-47e8-b0dc-523cb737bd2e...\n",
      "Fetching observation data for time-14-06-45-766239_chatcmpl-4c18e512-9ddd-4e9f-a0c2-44ac0d2a2967...\n",
      "Fetching observation data for time-14-06-52-556749_chatcmpl-a189cfc4-7bba-4466-acf9-43f52e208813...\n",
      "Fetching observation data for time-14-04-11-683398_chatcmpl-f7057224-5de4-4ebf-a04d-11b6641370e1...\n",
      "Fetching observation data for time-14-04-48-224220_chatcmpl-5801ef3c-3140-4e5c-bdd3-55b4f5d17638...\n",
      "Fetching observation data for time-14-04-53-435985_chatcmpl-1fc925d9-5aca-4e7c-bbc9-cf8c9cf4aa98...\n",
      "Fetching observation data for time-14-05-24-290452_chatcmpl-1dbb534a-0feb-4ecf-b04a-1af28ee44df9...\n",
      "Fetching observation data for time-14-05-53-766049_chatcmpl-5c8c79b2-50b8-4525-93f4-ec9cbaeb43fd...\n",
      "Fetching observation data for 5d54a1d0-f68c-4836-b206-b7751bf580d2...\n",
      "Fetching observation data for time-14-01-25-103891_chatcmpl-0937183e-08ac-4d01-af2f-c075c1a9d30a...\n",
      "Fetching observation data for time-14-02-01-686993_chatcmpl-ea0bd096-9ed5-4be4-a677-b9038aaf8689...\n",
      "Fetching observation data for time-14-02-08-433052_chatcmpl-93919a6d-00e3-462e-bbf6-b7159de1d8b0...\n",
      "Fetching observation data for time-14-02-44-832290_chatcmpl-8f97ed01-12bf-46a0-963e-244e835d3347...\n",
      "Fetching observation data for time-14-03-26-025653_chatcmpl-ce374897-b5fc-4876-898d-e405d76a3d39...\n",
      "Fetching observation data for 3d2f0ad3-f059-47fb-9e53-e675adbb8aa4...\n",
      "Fetching observation data for time-13-58-46-525148_chatcmpl-d2dd3da8-8b98-4214-98fd-cff689cb327d...\n",
      "Fetching observation data for time-13-59-23-196228_chatcmpl-fd08bbea-158c-4bbf-8cde-4da29782093f...\n",
      "Fetching observation data for time-13-59-29-286367_chatcmpl-95dc6ea8-0c56-4b09-ba37-3ae7ade823a9...\n",
      "Fetching observation data for time-14-00-05-505188_chatcmpl-e00c23f5-29eb-44c9-86b6-382c1428a667...\n",
      "Fetching observation data for time-14-00-42-103507_chatcmpl-63d14888-0ace-484f-9d3b-d4b6830c3b7f...\n",
      "Fetching observation data for 07f48453-1ef8-4d64-a430-7609f29b9e38...\n",
      "Fetching observation data for time-13-56-39-030556_chatcmpl-e95fb09f-3384-4ff6-8918-bc0a280752aa...\n",
      "Fetching observation data for time-13-57-15-597999_chatcmpl-9b0a7792-b757-4aa5-9a85-d847b3ce526a...\n",
      "Fetching observation data for time-13-57-22-209328_chatcmpl-7d52798e-dd0c-43f1-8cd8-875605f0aab6...\n",
      "Fetching observation data for time-13-57-50-373518_chatcmpl-b1ec3f89-cc00-4d50-a22e-a5b58c4a0f2d...\n",
      "Fetching observation data for time-13-58-18-843689_chatcmpl-cf65a41b-cffc-4497-8031-e8cf4cf12994...\n",
      "Fetching observation data for d1a08897-85da-4036-9c97-012a923b59fd...\n",
      "Fetching observation data for time-13-53-53-265449_chatcmpl-86615482-c569-443f-bcc0-397ddfe22953...\n",
      "Fetching observation data for time-13-54-29-770083_chatcmpl-abc13e71-6665-4ce9-ae9c-17787b1bfd90...\n",
      "Fetching observation data for time-13-54-39-138884_chatcmpl-50232ed4-9406-4259-a0d7-d62f85b25486...\n",
      "Fetching observation data for time-13-55-16-753033_chatcmpl-97f933cf-035f-4da3-9884-23f6c75444a6...\n",
      "Fetching observation data for time-13-55-54-488682_chatcmpl-5fcb7f6c-f243-4255-a081-a441589e680c...\n",
      "Fetching observation data for 9a4c64ae-1922-4e38-af7b-644d1dfb4d5d...\n",
      "Fetching observation data for time-13-50-58-705004_chatcmpl-8315f0ac-17c5-4384-aa18-f063ebfde0cd...\n",
      "Fetching observation data for time-13-52-02-055309_chatcmpl-864ffb77-96cf-4c49-88f7-355efce732a6...\n",
      "Fetching observation data for time-13-52-09-585874_chatcmpl-af390b94-971c-4a27-ac2f-7ba106e0febc...\n",
      "Fetching observation data for time-13-52-46-072966_chatcmpl-54e5271a-08f4-4ab8-be37-de603aa0b228...\n",
      "Fetching observation data for time-13-53-19-347300_chatcmpl-ea5a5c36-3dd8-4b6b-9450-b5d399a0f4f0...\n",
      "Fetching observation data for 3c0fabd1-0d76-4470-b8d0-8b993870d016...\n",
      "Raw JSON saved to: /home/han/Projects/reference-benchmark-tinyml_llm/data_analysis/2025/08.23/raw_export/raw_codestral_fc8d_tpusg_batch.json\n"
     ]
    }
   ],
   "source": [
    "# ALTERNATIVE TO 2.\n",
    "import os\n",
    "import json\n",
    "from time import sleep\n",
    "from langfuse import Langfuse\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "\n",
    "# LANGFUSE_SERVICE_PUBLIC_KEY = \"pk-lf-559a2c0f-ee29-4c32-944c-bf73b5f0ce28\"\n",
    "# LANGFUSE_SERVICE_SECRET_KEY = \"sk-lf-75f8bf7f-a5db-4756-b0dd-d758a2a292c8\"\n",
    "# LANGFUSE_SERVICE_HOST = \"https://langfuse.hann.fi\"\n",
    "\n",
    "\n",
    "if LOCAL_HOST:\n",
    "    langfuse = Langfuse(\n",
    "        secret_key=\"sk-lf-75f8bf7f-a5db-4756-b0dd-d758a2a292c8\",\n",
    "        public_key=\"pk-lf-559a2c0f-ee29-4c32-944c-bf73b5f0ce28\",\n",
    "        host=\"https://langfuse.hann.fi\",\n",
    "    )\n",
    "else:\n",
    "    langfuse = Langfuse(\n",
    "        secret_key=LANGFUSE_SERVICE_SECRET_KEY,\n",
    "        public_key=LANGFUSE_SERVICE_PUBLIC_KEY,\n",
    "        host=LANGFUSE_SERVICE_HOST,\n",
    "    )\n",
    "\n",
    "API_invok_count = 0\n",
    "query_range_num_run = {\"start\": 0, \"end\": 1}\n",
    "\n",
    "\n",
    "class CustomJSONEncoder(json.JSONEncoder):\n",
    "    def __init__(self, *args, LOCAL_HOST=True, **kwargs):\n",
    "        self.LOCAL_HOST = LOCAL_HOST\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "    def default(self, obj):\n",
    "        if isinstance(obj, datetime):\n",
    "            return obj.isoformat()\n",
    "        if hasattr(obj, \"__dict__\"):\n",
    "            data = obj.__dict__.copy()\n",
    "            if \"observations\" in data:\n",
    "                data[\"observations\"] = [\n",
    "                    fetch_observation_data(obs, self.LOCAL_HOST)\n",
    "                    for obs in data[\"observations\"]\n",
    "                ]\n",
    "\n",
    "            return data\n",
    "        return super().default(obj)\n",
    "\n",
    "\n",
    "def fetch_observation_data(observation_id, LOCAL_HOST):\n",
    "    \"\"\"\n",
    "    Fetches observation data from Langfuse and returns its dictionary representation.\n",
    "    \"\"\"\n",
    "    print(f\"Fetching observation data for {observation_id}...\")\n",
    "    global API_invok_count\n",
    "    if API_invok_count >= 0 and not LOCAL_HOST:\n",
    "        print(\"Waiting for 3 seconds to fetch observation data...\")\n",
    "        for _ in tqdm(range(3), desc=\"Progress\", unit=\"s\"):\n",
    "            sleep(1)\n",
    "        API_invok_count = 0\n",
    "\n",
    "    observation_response = langfuse.fetch_observation(observation_id)\n",
    "    API_invok_count += 1\n",
    "\n",
    "    return observation_response.data.dict()\n",
    "\n",
    "\n",
    "def fetch_and_save_complete_data(session_id_list, raw_export_dir, LOCAL_HOST):\n",
    "    \"\"\"\n",
    "    Fetches complete trace data for each session ID and saves it to JSON files.\n",
    "\n",
    "    Parameters:\n",
    "        session_id_list (list): List of session IDs to process.\n",
    "        raw_export_dir (str): Directory path to save raw JSON files.\n",
    "    \"\"\"\n",
    "\n",
    "    def save_complete_data(session_id):\n",
    "        global API_invok_count\n",
    "        if API_invok_count >= 0 and not LOCAL_HOST:\n",
    "            print(\"Waiting for 4 seconds to fetch traces...\")\n",
    "            for _ in tqdm(range(4), desc=\"Progress\", unit=\"s\"):\n",
    "                sleep(1)\n",
    "            API_invok_count = 0\n",
    "\n",
    "        fetch_traces_response = langfuse.fetch_traces(session_id=session_id)\n",
    "        API_invok_count += 1\n",
    "\n",
    "        print(f\"Fetching traces for session {session_id}...\")\n",
    "        # Create directories if they don't exist\n",
    "        os.makedirs(raw_export_dir, exist_ok=True)\n",
    "\n",
    "        # Save complete data to JSON file\n",
    "        # if session_id.startswith(\"da0a\"):\n",
    "        #     session_id = \"phi4_\" + session_id\n",
    "        if \"tpsg\" in session_id:\n",
    "            session_id_ = session_id.replace(\"tpsg\", \"tpusg\")\n",
    "        else:\n",
    "            session_id_ = session_id\n",
    "            \n",
    "        raw_path = os.path.join(raw_export_dir, f\"raw_{session_id_}.json\")\n",
    "        with open(raw_path, \"w\") as f:\n",
    "            json.dump(fetch_traces_response, f, cls=CustomJSONEncoder, indent=2)\n",
    "\n",
    "        print(f\"Raw JSON saved to: {raw_path}\")\n",
    "\n",
    "    for session_id in session_id_list:\n",
    "        save_complete_data(session_id)\n",
    "\n",
    "\n",
    "fetch_and_save_complete_data(session_id_list, raw_export_dir, LOCAL_HOST)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Trim data\n",
    "\n",
    "Here also intercept the runs with fatal errors that need to be excluded from the analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPAN error_09_tpusg_failure_signal_tpu_sketch_generator: Failed: Max retries reached with error. Last error: Traceback (most recent call last):\n",
      "  File \"script_81097f80_1755690775.py\", line 47, in <module>\n",
      "    boxes = interpreter.get_tensor(output_details[0]['index'])[0]\n",
      "TypeError: string indices must be integers.\n",
      "SPAN error_9d_tpusg_failure_signal_tpu_sketch_generator: Failed: Max retries reached with error. Last error: Traceback (most recent call last):\n",
      "  File \"script_8cfd5daa_1755690610.py\", line 17, in <module>\n",
      "    height, width = input_details['shape'][1:3]\n",
      "TypeError: string indices must be integers.\n",
      "SPAN error_5c_tpusg_failure_signal_tpu_sketch_generator: Failed: Max retries reached with exception: Unexpected error during generation: Generated script is not complete. Please ensure to generate a complete Python script..\n",
      "SPAN error_e3_tpusg_failure_signal_tpu_sketch_generator: Failed: Max retries reached with exception: Unexpected error during generation: The output is not a valid code block. Follow the instructions in the prompt return a complete, correct Python script enclosed in a single ```python\n",
      "<generated_code>\n",
      "``` block..\n",
      "SPAN error_c4_tpusg_failure_signal_tpu_sketch_generator: Failed: Max retries reached with error. Last error: Traceback (most recent call last):\n",
      "  File \"script_54395240_1755690310.py\", line 7, in <module>\n",
      "    with open('your_labels_path', 'r') as f:\n",
      "FileNotFoundError: [Errno 2] No such file or directory: 'your_labels_path'.\n",
      "SPAN error_ad_tpusg_failure_signal_tpu_sketch_generator: Failed: Max retries reached with error. Last error: Traceback (most recent call last):\n",
      "  File \"script_8f618de1_1755690185.py\", line 6, in <module>\n",
      "    with open('/home/mendel/tinyml_autopilot/data/labels.txt', 'r') as f:\n",
      "FileNotFoundError: [Errno 2] No such file or directory: '/home/mendel/tinyml_autopilot/data/labels.txt'.\n",
      "SPAN error_38_tpusg_failure_signal_tpu_sketch_generator: Failed: Max retries reached with error. Last error: Traceback (most recent call last):\n",
      "  File \"script_188f3c6d_1755689843.py\", line 13, in <module>\n",
      "    height = input_details[0]['shape'][1]\n",
      "TypeError: string indices must be integers.\n",
      "SPAN error_a1_tpusg_failure_signal_tpu_sketch_generator: Failed: Max retries reached with exception: Unexpected error during generation: The output is not a valid code block. Follow the instructions in the prompt return a complete, correct Python script enclosed in a single ```python\n",
      "<generated_code>\n",
      "``` block..\n",
      "SPAN error_ae_tpusg_failure_signal_tpu_sketch_generator: Failed: Max retries reached with exception: Unexpected error during generation: The output is not a valid code block. Follow the instructions in the prompt return a complete, correct Python script enclosed in a single ```python\n",
      "<generated_code>\n",
      "``` block..\n",
      "SPAN error_99_tpusg_failure_signal_tpu_sketch_generator: Failed: Max retries reached with exception: Unexpected error during generation: Generated script is not complete. Please ensure to generate a complete Python script..\n",
      "SPAN error_04_tpusg_failure_signal_tpu_sketch_generator: Failed: Max retries reached with exception: Unexpected error during generation: The output is not a valid code block. Follow the instructions in the prompt return a complete, correct Python script enclosed in a single ```python\n",
      "<generated_code>\n",
      "``` block..\n",
      "SPAN error_0b_tpusg_failure_signal_tpu_sketch_generator: Failed: Max retries reached with exception: Unexpected error during generation: The output is not a valid code block. Follow the instructions in the prompt return a complete, correct Python script enclosed in a single ```python\n",
      "<generated_code>\n",
      "``` block..\n",
      "SPAN error_09_tpusg_failure_signal_tpu_sketch_generator: Failed: Max retries reached with error. Last error: Traceback (most recent call last):\n",
      "  File \"script_a80c76ae_1755689171.py\", line 3, in <module>\n",
      "    from tensorflow.lite.python.interpreter import Interpreter\n",
      "ModuleNotFoundError: No module named 'tensorflow'.\n",
      "SPAN error_11_tpusg_failure_signal_tpu_sketch_generator: Failed: Max retries reached with exception: Unexpected error during generation: The output is not a valid code block. Follow the instructions in the prompt return a complete, correct Python script enclosed in a single ```python\n",
      "<generated_code>\n",
      "``` block..\n",
      "SPAN error_ca_tpusg_failure_signal_tpu_sketch_generator: Failed: Max retries reached with exception: Unexpected error during generation: Generated script is not complete. Please ensure to generate a complete Python script..\n",
      "SPAN error_be_tpusg_failure_signal_tpu_sketch_generator: Failed: Max retries reached with error. Last error: Traceback (most recent call last):\n",
      "  File \"script_6a9db17c_1755688791.py\", line 18, in <module>\n",
      "    height = input_details[0]['shape'][1]\n",
      "TypeError: string indices must be integers.\n",
      "SPAN error_11_tpusg_failure_signal_tpu_sketch_generator: Failed: Max retries reached with exception: Unexpected error during generation: The output is not a valid code block. Follow the instructions in the prompt return a complete, correct Python script enclosed in a single ```python\n",
      "<generated_code>\n",
      "``` block..\n",
      "SPAN error_62_tpusg_failure_signal_tpu_sketch_generator: Failed: Max retries reached with exception: Unexpected error during generation: The output is not a valid code block. Follow the instructions in the prompt return a complete, correct Python script enclosed in a single ```python\n",
      "<generated_code>\n",
      "``` block..\n",
      "SPAN error_35_tpusg_failure_signal_tpu_sketch_generator: Failed: Max retries reached with exception: Unexpected error during generation: The output is not a valid code block. Follow the instructions in the prompt return a complete, correct Python script enclosed in a single ```python\n",
      "<generated_code>\n",
      "``` block..\n",
      "SPAN error_e2_tpusg_failure_signal_tpu_sketch_generator: Failed: Max retries reached with exception: Unexpected error during generation: The output is not a valid code block. Follow the instructions in the prompt return a complete, correct Python script enclosed in a single ```python\n",
      "<generated_code>\n",
      "``` block..\n",
      "SPAN error_cb_tpusg_failure_signal_tpu_sketch_generator: Failed: Max retries reached with error. Last error: Traceback (most recent call last):\n",
      "  File \"script_d23d7362_1755688330.py\", line 6, in <module>\n",
      "    with open('labels.txt', 'r') as f:\n",
      "FileNotFoundError: [Errno 2] No such file or directory: 'labels.txt'.\n",
      "SPAN error_5c_tpusg_failure_signal_tpu_sketch_generator: Failed: Max retries reached with error. Last error: Traceback (most recent call last):\n",
      "  File \"script_587f7aa7_1755688194.py\", line 10, in <module>\n",
      "    with open(labels_file, 'r') as f:\n",
      "FileNotFoundError: [Errno 2] No such file or directory: 'path/to/your/labels.txt'.\n",
      "SPAN error_a6_tpusg_failure_signal_tpu_sketch_generator: Failed: Max retries reached with exception: Unexpected error during generation: Generated script is not complete. Please ensure to generate a complete Python script..\n",
      "SPAN error_2a_tpusg_failure_signal_tpu_sketch_generator: Failed: Max retries reached with error. Last error: Traceback (most recent call last):\n",
      "  File \"script_43c00805_1755687837.py\", line 7, in <module>\n",
      "    interpreter = Interpreter(model_path=\"detect.tflite\")\n",
      "  File \"/home/mendel/tinyml_autopilot/tinyml-env/lib/python3.7/site-packages/tflite_runtime/interpreter.py\", line 351, in __init__\n",
      "    experimental_preserve_all_tensors))\n",
      "ValueError: Could not open 'detect.tflite'..\n",
      "SPAN error_03_tpusg_failure_signal_tpu_sketch_generator: Failed: Max retries reached with error. Last error: Traceback (most recent call last):\n",
      "  File \"script_b40e1d67_1755687669.py\", line 9, in <module>\n",
      "    labels = read_label_file('/correct/path/to/your/labels.txt')  # Replace '/correct/path/to/your/labels.txt' with the correct path to your labels file\n",
      "  File \"/home/mendel/tinyml_autopilot/tinyml-env/lib/python3.7/site-packages/pycoral/utils/dataset.py\", line 36, in read_label_file\n",
      "    with open(file_path, 'r', encoding='utf-8') as f:\n",
      "FileNotFoundError: [Errno 2] No such file or directory: '/correct/path/to/your/labels.txt'.\n",
      "SPAN error_35_tpusg_failure_signal_tpu_sketch_generator: Failed: Max retries reached with exception: Unexpected error during generation: Generated script is not complete. Please ensure to generate a complete Python script..\n",
      "SPAN error_41_tpusg_failure_signal_tpu_sketch_generator: Failed: Max retries reached with error. Last error: Traceback (most recent call last):\n",
      "  File \"script_fe17e7c9_1755687384.py\", line 3, in <module>\n",
      "    from interpreter import Interpreter, load_delegate\n",
      "ModuleNotFoundError: No module named 'interpreter'.\n",
      "SPAN error_3e_tpusg_failure_signal_tpu_sketch_generator: Failed: Max retries reached with exception: Unexpected error during generation: Generated script is not complete. Please ensure to generate a complete Python script..\n",
      "Successfully processed and saved trimmed data for session codestral_fc8d_tpusg_batch\n",
      "Total 0 traces skipped. They are []\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "skipped_traces = []\n",
    "\n",
    "\n",
    "def process_existing_observation(observation):\n",
    "    \"\"\"\n",
    "    Processes an existing observation dictionary by trimming unwanted keys.\n",
    "    \"\"\"\n",
    "    unwanted_observation_keys = [\n",
    "        \"completionStartTime\",\n",
    "        \"metadata\",\n",
    "        \"timeToFirstToken\",\n",
    "        \"createdAt\",\n",
    "        \"usageDetails\",\n",
    "        \"usage\",\n",
    "        \"projectId\",\n",
    "        \"unit\",\n",
    "        \"updatedAt\",\n",
    "        \"version\",\n",
    "        \"parentObservationId\",\n",
    "        \"promptId\",\n",
    "        \"promptName\",\n",
    "        \"promptVersion\",\n",
    "        \"modelId\",\n",
    "        \"inputPrice\",\n",
    "        \"outputPrice\",\n",
    "        \"totalPrice\",\n",
    "        # \"modelParameters\",\n",
    "        \"input\",\n",
    "        \"output\",\n",
    "    ]\n",
    "\n",
    "    # If observation is a dictionary containing observation data\n",
    "    if isinstance(observation, dict):\n",
    "        trimmed_observation = {\n",
    "            k: v for k, v in observation.items() if k not in unwanted_observation_keys\n",
    "        }\n",
    "        return trimmed_observation\n",
    "    return observation\n",
    "\n",
    "\n",
    "def trim_data(data):\n",
    "    \"\"\"\n",
    "    Recursively trims the data structure.\n",
    "    \"\"\"\n",
    "\n",
    "    if isinstance(data, dict):\n",
    "        # Process the current dictionary\n",
    "        unwanted_trace_keys = [\n",
    "            \"release\",\n",
    "            \"version\",\n",
    "            \"user_id\",\n",
    "            \"public\",\n",
    "            \"html_path\",\n",
    "            \"scores\",\n",
    "            \"bookmarked\",\n",
    "            \"projectId\",\n",
    "            \"externalId\",\n",
    "            \"page\",\n",
    "            \"limit\",\n",
    "            \"total_pages\",\n",
    "        ]\n",
    "\n",
    "        # If this is a trace that contains observations, check for fatal errors\n",
    "        if \"observations\" in data:\n",
    "            # Check for SPAN observations with fatal errors before processing\n",
    "            skip_trace = False\n",
    "            for obs in data[\"observations\"]:\n",
    "                if isinstance(obs, dict) and obs.get(\"name\").startswith(\"error\"):\n",
    "                    status_message = obs.get(\"statusMessage\", \"\")\n",
    "                    ob_name = obs.get(\"name\")\n",
    "                    print(f\"SPAN {ob_name}: {status_message}\")\n",
    "\n",
    "                    if \"Fatal error\" in status_message:\n",
    "                        print(f\"Found Fatal error in SPAN observation, skipping trace\")\n",
    "                        skip_trace = True\n",
    "                        skipped_traces.append(data[\"name\"])\n",
    "                        break\n",
    "\n",
    "            if skip_trace:\n",
    "                return None  # Signal to skip this trace\n",
    "\n",
    "        # Create a new dictionary with wanted keys and recursively process values\n",
    "        trimmed_data = {}\n",
    "        for key, value in data.items():\n",
    "            if key not in unwanted_trace_keys:\n",
    "                if key == \"observations\":\n",
    "                    # Special handling for observations\n",
    "                    trimmed_data[key] = [\n",
    "                        process_existing_observation(obs) for obs in value\n",
    "                    ]\n",
    "                elif isinstance(value, (dict, list)):\n",
    "                    # Recursively process nested structures\n",
    "                    trimmed_data[key] = trim_data(value)\n",
    "                else:\n",
    "                    trimmed_data[key] = value\n",
    "\n",
    "        return trimmed_data\n",
    "\n",
    "    elif isinstance(data, list):\n",
    "        # Recursively process each item in the list\n",
    "        processed_items = []\n",
    "        for item in data:\n",
    "            processed_item = trim_data(item)\n",
    "            if processed_item is not None:  # Only add items that weren't filtered out\n",
    "                processed_items.append(processed_item)\n",
    "        return processed_items\n",
    "\n",
    "    else:\n",
    "        # Return non-dict, non-list values as is\n",
    "        return data\n",
    "\n",
    "\n",
    "def read_and_trim_data(session_id_list, raw_export_dir, trimmed_export_dir):\n",
    "    \"\"\"\n",
    "    Reads complete data from JSON files, trims the data, and saves the trimmed data to new JSON files.\n",
    "    \"\"\"\n",
    "    os.makedirs(trimmed_export_dir, exist_ok=True)\n",
    "\n",
    "    for session_id in session_id_list:\n",
    "        try:\n",
    "            if session_id.startswith(\"da0a\"):\n",
    "                session_id = \"phi4_\" + session_id\n",
    "            # Read raw data\n",
    "            if \"tpsg\" in session_id:\n",
    "                session_id_ = session_id.replace(\"tpsg\", \"tpusg\")\n",
    "            else:\n",
    "                session_id_ = session_id\n",
    "            raw_path = os.path.join(raw_export_dir, f\"raw_{session_id_}.json\")\n",
    "            with open(raw_path, \"r\") as f:\n",
    "                data = json.load(f)\n",
    "\n",
    "            # Process and trim the data\n",
    "            trimmed_data = trim_data(data)\n",
    "\n",
    "            # If the entire data was filtered out (unlikely but possible)\n",
    "            if trimmed_data is None:\n",
    "                print(\n",
    "                    f\"All traces in session {session_id} were filtered due to fatal errors\"\n",
    "                )\n",
    "                continue\n",
    "\n",
    "            # Save trimmed data\n",
    "            if \"tpsg\" in session_id:\n",
    "                session_id_ = session_id.replace(\"tpsg\", \"tpusg\")\n",
    "            else:\n",
    "                session_id_ = session_id\n",
    "            trimmed_path = os.path.join(\n",
    "                trimmed_export_dir, f\"trimmed_{session_id_}.json\"\n",
    "            )\n",
    "            with open(trimmed_path, \"w\") as f:\n",
    "                json.dump(trimmed_data, f, indent=2)\n",
    "\n",
    "            print(\n",
    "                f\"Successfully processed and saved trimmed data for session {session_id}\"\n",
    "            )\n",
    "\n",
    "            # Optional: Verify trimming worked\n",
    "            # print(f\"Verifying trimmed data for session {session_id}...\")\n",
    "            # verify_trimming(trimmed_path)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing session {session_id}: {str(e)}\")\n",
    "\n",
    "\n",
    "def verify_trimming(trimmed_path):\n",
    "    \"\"\"\n",
    "    Verifies that the trimmed data doesn't contain unwanted keys.\n",
    "    \"\"\"\n",
    "    with open(trimmed_path, \"r\") as f:\n",
    "        trimmed_data = json.load(f)\n",
    "\n",
    "    unwanted_keys = [\n",
    "        \"release\",\n",
    "        \"version\",\n",
    "        \"user_id\",\n",
    "        \"public\",\n",
    "        \"html_path\",\n",
    "        \"scores\",\n",
    "        \"bookmarked\",\n",
    "        \"projectId\",\n",
    "        \"externalId\",\n",
    "        \"page\",\n",
    "        \"limit\",\n",
    "        \"total_pages\",\n",
    "        \"completionStartTime\",\n",
    "        \"metadata\",\n",
    "        \"usageDetails\",\n",
    "        \"timeToFirstToken\",\n",
    "        \"createdAt\",\n",
    "        \"completionTokens\",\n",
    "        \"promptTokens\",\n",
    "        \"projectId\",\n",
    "        \"unit\",\n",
    "        \"updatedAt\",\n",
    "        \"version\",\n",
    "        # \"statusMessage\",\n",
    "        \"parentObservationId\",\n",
    "        \"promptId\",\n",
    "        \"promptName\",\n",
    "        \"promptVersion\",\n",
    "        \"modelId\",\n",
    "        \"inputPrice\",\n",
    "        \"outputPrice\",\n",
    "        \"totalPrice\",\n",
    "        \"calculatedInputCost\",\n",
    "        \"calculatedOutputCost\",\n",
    "        \"calculatedTotalCost\",\n",
    "    ]\n",
    "\n",
    "    def check_keys(obj):\n",
    "        if isinstance(obj, dict):\n",
    "            for key in obj.keys():\n",
    "                if key in unwanted_keys:\n",
    "                    print(f\"Warning: Found unwanted key '{key}' in trimmed data\")\n",
    "            for value in obj.values():\n",
    "                check_keys(value)\n",
    "        elif isinstance(obj, list):\n",
    "            for item in obj:\n",
    "                check_keys(item)\n",
    "\n",
    "    check_keys(trimmed_data)\n",
    "    print(\"Verification complete\")\n",
    "\n",
    "\n",
    "# Usage example:\n",
    "read_and_trim_data(session_id_list, raw_export_dir, raw_export_dir)\n",
    "print(f\"Total {len(skipped_traces)} traces skipped. They are {skipped_traces}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Generate CSV files from JSON\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing session codestral_fc8d_tpusg_batch, simple id codestral_fc8d. Look for /home/han/Projects/reference-benchmark-tinyml_llm/data_analysis/2025/08.23/raw_export/trimmed_codestral_fc8d_tpusg_batch.json\n",
      "/home/han/Projects/reference-benchmark-tinyml_llm/data_analysis/2025/08.23/processed_data/codestral_fc8d/clean_codestral_fc8d_tpusg_batch.csv\n",
      "Successfully saved CSV to: /home/han/Projects/reference-benchmark-tinyml_llm/data_analysis/2025/08.23/processed_data/codestral_fc8d/clean_codestral_fc8d_tpusg_batch.csv\n"
     ]
    }
   ],
   "source": [
    "import traceback\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from dateutil import parser\n",
    "\n",
    "\n",
    "def json_to_csv(session_id):\n",
    "    \"\"\"\n",
    "    Convert JSON trace data to CSV format with aggregated metrics.\n",
    "\n",
    "    Args:\n",
    "        session_id (str): Identifier for the session to process\n",
    "    \"\"\"\n",
    "\n",
    "    def extract_observation_details(observations, trace_id):\n",
    "        \"\"\"Extract and aggregate metrics from observations\"\"\"\n",
    "        metrics = {\n",
    "            \"status\": None,\n",
    "            \"latency\": 0,\n",
    "            \"total_tokens\": 0,\n",
    "            \"prompt_tokens\": 0,\n",
    "            \"completion_tokens\": 0,\n",
    "            \"total_cost\": 0,\n",
    "            \"input_cost\": 0,\n",
    "            \"output_cost\": 0,\n",
    "            \"parameters\": set(),\n",
    "        }\n",
    "\n",
    "        # Process GENERATION observations\n",
    "        for obs in (o for o in observations if o[\"type\"] == \"GENERATION\"):\n",
    "            metrics[\"total_tokens\"] += obs[\"totalTokens\"]\n",
    "            metrics[\"prompt_tokens\"] += obs[\"promptTokens\"]\n",
    "            metrics[\"completion_tokens\"] += obs[\"completionTokens\"]\n",
    "            metrics[\"latency\"] += obs[\"latency\"]\n",
    "            for key, value in obs[\"modelParameters\"].items():\n",
    "                metrics[\"parameters\"].add(key + \":\" + value)\n",
    "\n",
    "            # Add costs if present\n",
    "            for cost_type in [\"Total\", \"Input\", \"Output\"]:\n",
    "                key = f\"calculated{cost_type}Cost\"\n",
    "                metric_key = cost_type.lower() + \"_cost\"\n",
    "                if obs.get(key) is not None:\n",
    "                    metrics[metric_key] += obs[key]\n",
    "        if len(metrics[\"parameters\"]) == 0:\n",
    "            metrics[\"parameters\"] = \"N/A\"\n",
    "        # Process SPAN observations for status\n",
    "        status_indicators = [\n",
    "            obs[\"name\"]\n",
    "            for obs in observations\n",
    "            if obs[\"type\"] == \"SPAN\" and \"start_\" not in obs[\"name\"]\n",
    "        ]\n",
    "\n",
    "        #  if later than 2025-05-19, use status_signal_from_output\n",
    "        if datetime.now() > datetime(2025, 5, 19):\n",
    "            pass\n",
    "        else:\n",
    "            # Determine status\n",
    "            success_signals = sum(\"end_\" in name for name in status_indicators)\n",
    "            failure_signals = sum(\n",
    "                \"failure_signal\" in name for name in status_indicators\n",
    "            )\n",
    "\n",
    "            if success_signals + failure_signals > 1:\n",
    "                raise ValueError(\n",
    "                    f\"Multiple status indicators found in trace {trace_id}\"\n",
    "                )\n",
    "\n",
    "            metrics[\"status\"] = (\n",
    "                \"success\"\n",
    "                if success_signals\n",
    "                else \"failure\" if failure_signals else \"unknown\"\n",
    "            )\n",
    "\n",
    "        metrics[\"prompt_cost\"] = metrics.pop(\"input_cost\")\n",
    "        metrics[\"completion_cost\"] = metrics.pop(\"output_cost\")\n",
    "        metrics[\"latency\"] = round(metrics[\"latency\"] / 1000, 2)\n",
    "        return metrics\n",
    "\n",
    "    def cal_time(trace):\n",
    "        time_diff = datetime.fromisoformat(\n",
    "            trace[\"updatedAt\"].replace(\"Z\", \"+00:00\")\n",
    "        ) - datetime.fromisoformat(trace[\"createdAt\"].replace(\"Z\", \"+00:00\"))\n",
    "        seconds_diff = time_diff.total_seconds()\n",
    "        return seconds_diff\n",
    "\n",
    "    try:\n",
    "\n",
    "        if session_id.startswith(\"da0a\"):\n",
    "            session_id = \"phi4_\" + session_id\n",
    "        simple_session_id = session_id.rsplit(\"_\", 2)[0]\n",
    "\n",
    "        \n",
    "        # Load JSON data\n",
    "        if \"tpsg\" in session_id:\n",
    "                session_id_ = session_id.replace(\"tpsg\", \"tpusg\")\n",
    "        else:\n",
    "                session_id_ = session_id\n",
    "        trimmed_path = os.path.join(raw_export_dir, f\"trimmed_{session_id_}.json\")\n",
    "        print(\n",
    "            f\"Processing session {session_id}, simple id {simple_session_id}. Look for {trimmed_path}\"\n",
    "        )\n",
    "        with open(trimmed_path, \"r\") as file:\n",
    "            traces = json.load(file)[\"data\"]\n",
    "\n",
    "        # Process traces\n",
    "        rows = [\n",
    "            {\n",
    "                \"num_run\": trace[\"metadata\"][\"num_run\"],\n",
    "                \"name\": trace[\"name\"],\n",
    "                \"trace_id\": trace[\"id\"],\n",
    "                \"batch_id\": trace[\"session_id\"],\n",
    "                # \"latency\": cal_time(trace),\n",
    "                # \"latency\": round(trace[\"latency\"], 2),\n",
    "                **extract_observation_details(\n",
    "                    trace[\"observations\"],\n",
    "                    trace[\"id\"],\n",
    "                ),\n",
    "                \"status\": (\n",
    "                    \"failure\"\n",
    "                    if trace[\"output\"][\"status\"].lower() == \"failed\"\n",
    "                    else \"success\"\n",
    "                ),\n",
    "                \"tags\": trace[\"tags\"],\n",
    "                \"timestamp\": int(parser.isoparse(trace[\"timestamp\"]).timestamp()),\n",
    "            }\n",
    "            for trace in traces\n",
    "        ]\n",
    "        # print(rows)\n",
    "        # print(rows)\n",
    "        # Create and save DataFrame\n",
    "        df = pd.DataFrame(rows).sort_values(\"num_run\")\n",
    "\n",
    "        output_dir = os.path.join(processed_data_dir, f\"{simple_session_id}\")\n",
    "        if not os.path.exists(output_dir):\n",
    "            os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "        output_path = os.path.join(output_dir, f\"clean_{session_id_}.csv\")\n",
    "\n",
    "        print(output_path)\n",
    "        df.to_csv(output_path, index=False)\n",
    "        print(f\"Successfully saved CSV to: {output_path}\")\n",
    "\n",
    "    except FileNotFoundError as e:\n",
    "        print(\n",
    "            f\"FileNotFoundError: For session {session_id} not found. Looked for {trimmed_path}\\nError info: \\n{e}\\n\\nTraceback: {traceback.format_exc()}\"\n",
    "        )\n",
    "    except json.JSONDecodeError:\n",
    "        print(f\"Error: Invalid JSON format in input file for session {session_id}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing session {session_id}: {str(e)}\")\n",
    "\n",
    "\n",
    "# Example usage\n",
    "for session_id in session_id_list:\n",
    "    json_to_csv(session_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CSV Generation with Generation Counts\n",
    "\n",
    "This section creates CSV files similar to the langfuse_export section 3, but adds a column for the number of generation attempts used for each trace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing sessions: ['codestral_fc8d_tpusg_batch']\n",
      "Looking for raw files in: /home/han/Projects/reference-benchmark-tinyml_llm/data_analysis/2025/08.23/raw_export\n",
      "Will save CSV files to: /home/han/Projects/reference-benchmark-tinyml_llm/data_analysis/2025/08.23/processed_data\n",
      "Processing session codestral_fc8d_tpusg_batch, simple id codestral_fc8d. Look for /home/han/Projects/reference-benchmark-tinyml_llm/data_analysis/2025/08.23/raw_export/trimmed_codestral_fc8d_tpusg_batch.json\n",
      "/home/han/Projects/reference-benchmark-tinyml_llm/data_analysis/2025/08.23/processed_data/codestral_fc8d/clean_codestral_fc8d_tpusg_batch.csv\n",
      "Successfully saved CSV to: /home/han/Projects/reference-benchmark-tinyml_llm/data_analysis/2025/08.23/processed_data/codestral_fc8d/clean_codestral_fc8d_tpusg_batch.csv\n"
     ]
    }
   ],
   "source": [
    "import traceback\n",
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "from datetime import datetime\n",
    "from dateutil import parser\n",
    "\n",
    "# Setup paths - same as langfuse_export\n",
    "parent_dir = os.path.dirname(os.getcwd())\n",
    "raw_export_dir = os.path.join(parent_dir, \"raw_export\")\n",
    "processed_data_dir = os.path.join(parent_dir, \"processed_data\")\n",
    "\n",
    "\n",
    "# Get session id list from data directory\n",
    "session_id_list = []\n",
    "\n",
    "for root, dirs, files in os.walk(raw_export_dir):\n",
    "    for file in files:\n",
    "        file_path = os.path.join(root, file)\n",
    "        if \"trimmed_\" in file_path:\n",
    "            session_id = file_path.split('trimmed_')[1].rstrip('.json')\n",
    "            session_id_list.append(session_id)\n",
    "\n",
    "print(f\"Processing sessions: {session_id_list}\")\n",
    "print(f\"Looking for raw files in: {raw_export_dir}\")\n",
    "print(f\"Will save CSV files to: {processed_data_dir}\")\n",
    "\n",
    "\n",
    "def json_to_csv_weighted(session_id):\n",
    "    \"\"\"\n",
    "    Convert JSON trace data to CSV format with aggregated metrics.\n",
    "    Upgraded version that includes generation_count column.\n",
    "\n",
    "    Args:\n",
    "        session_id (str): Identifier for the session to process\n",
    "    \"\"\"\n",
    "\n",
    "    def extract_observation_details(observations, trace_id):\n",
    "        \"\"\"Extract and aggregate metrics from observations\"\"\"\n",
    "        metrics = {\n",
    "            \"status\": None,\n",
    "            \"latency\": 0,\n",
    "            \"total_tokens\": 0,\n",
    "            \"prompt_tokens\": 0,\n",
    "            \"completion_tokens\": 0,\n",
    "            \"total_cost\": 0,\n",
    "            \"input_cost\": 0,\n",
    "            \"output_cost\": 0,\n",
    "            \"parameters\": set(),\n",
    "            \"generation_count\": 0,  # New field for generation count\n",
    "        }\n",
    "\n",
    "        # Count generations and process GENERATION observations\n",
    "        for obs in (o for o in observations if o[\"type\"] == \"GENERATION\"):\n",
    "            metrics[\"generation_count\"] += 1\n",
    "            metrics[\"total_tokens\"] += obs[\"totalTokens\"]\n",
    "            metrics[\"prompt_tokens\"] += obs[\"promptTokens\"]\n",
    "            metrics[\"completion_tokens\"] += obs[\"completionTokens\"]\n",
    "            metrics[\"latency\"] += obs[\"latency\"]\n",
    "            for key, value in obs[\"modelParameters\"].items():\n",
    "                metrics[\"parameters\"].add(key + \":\" + value)\n",
    "\n",
    "            # Add costs if present\n",
    "            for cost_type in [\"Total\", \"Input\", \"Output\"]:\n",
    "                key = f\"calculated{cost_type}Cost\"\n",
    "                metric_key = cost_type.lower() + \"_cost\"\n",
    "                if obs.get(key) is not None:\n",
    "                    metrics[metric_key] += obs[key]\n",
    "                    \n",
    "        if len(metrics[\"parameters\"]) == 0:\n",
    "            metrics[\"parameters\"] = \"N/A\"\n",
    "            \n",
    "        # Process SPAN observations for status\n",
    "        status_indicators = [\n",
    "            obs[\"name\"]\n",
    "            for obs in observations\n",
    "            if obs[\"type\"] == \"SPAN\" and \"start_\" not in obs[\"name\"]\n",
    "        ]\n",
    "\n",
    "        #  if later than 2025-05-19, use status_signal_from_output\n",
    "        if datetime.now() > datetime(2025, 5, 19):\n",
    "            pass\n",
    "        else:\n",
    "            # Determine status\n",
    "            success_signals = sum(\"end_\" in name for name in status_indicators)\n",
    "            failure_signals = sum(\n",
    "                \"failure_signal\" in name for name in status_indicators\n",
    "            )\n",
    "\n",
    "            if success_signals + failure_signals > 1:\n",
    "                raise ValueError(\n",
    "                    f\"Multiple status indicators found in trace {trace_id}\"\n",
    "                )\n",
    "\n",
    "            metrics[\"status\"] = (\n",
    "                \"success\"\n",
    "                if success_signals\n",
    "                else \"failure\" if failure_signals else \"unknown\"\n",
    "            )\n",
    "\n",
    "        metrics[\"prompt_cost\"] = metrics.pop(\"input_cost\")\n",
    "        metrics[\"completion_cost\"] = metrics.pop(\"output_cost\")\n",
    "        metrics[\"latency\"] = round(metrics[\"latency\"] / 1000, 2)\n",
    "        return metrics\n",
    "\n",
    "    def cal_time(trace):\n",
    "        time_diff = datetime.fromisoformat(\n",
    "            trace[\"updatedAt\"].replace(\"Z\", \"+00:00\")\n",
    "        ) - datetime.fromisoformat(trace[\"createdAt\"].replace(\"Z\", \"+00:00\"))\n",
    "        seconds_diff = time_diff.total_seconds()\n",
    "        return seconds_diff\n",
    "\n",
    "    try:\n",
    "        if session_id.startswith(\"da0a\"):\n",
    "            session_id = \"phi4_\" + session_id\n",
    "        simple_session_id = session_id.rsplit(\"_\", 2)[0]\n",
    "\n",
    "        # Load JSON data\n",
    "        if \"tpsg\" in session_id:\n",
    "            session_id_ = session_id.replace(\"tpsg\", \"tpusg\")\n",
    "        else:\n",
    "            session_id_ = session_id\n",
    "        trimmed_path = os.path.join(raw_export_dir, f\"trimmed_{session_id_}.json\")\n",
    "        print(\n",
    "            f\"Processing session {session_id}, simple id {simple_session_id}. Look for {trimmed_path}\"\n",
    "        )\n",
    "        with open(trimmed_path, \"r\") as file:\n",
    "            traces = json.load(file)[\"data\"]\n",
    "\n",
    "        # Process traces\n",
    "        rows = [\n",
    "            {\n",
    "                \"num_run\": trace[\"metadata\"][\"num_run\"],\n",
    "                \"name\": trace[\"name\"],\n",
    "                \"trace_id\": trace[\"id\"],\n",
    "                \"batch_id\": trace[\"session_id\"],\n",
    "                # \"latency\": cal_time(trace),\n",
    "                # \"latency\": round(trace[\"latency\"], 2),\n",
    "                **extract_observation_details(\n",
    "                    trace[\"observations\"],\n",
    "                    trace[\"id\"],\n",
    "                ),\n",
    "                \"status\": (\n",
    "                    \"failure\"\n",
    "                    if trace[\"output\"][\"status\"].lower() == \"failed\"\n",
    "                    else \"success\"\n",
    "                ),\n",
    "                \"tags\": trace[\"tags\"],\n",
    "                \"timestamp\": int(parser.isoparse(trace[\"timestamp\"]).timestamp()),\n",
    "            }\n",
    "            for trace in traces\n",
    "        ]\n",
    "        \n",
    "        # Create and save DataFrame\n",
    "        df = pd.DataFrame(rows).sort_values(\"num_run\")\n",
    "\n",
    "        output_dir = os.path.join(processed_data_dir, f\"{simple_session_id}\")\n",
    "        if not os.path.exists(output_dir):\n",
    "            os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "        output_path = os.path.join(output_dir, f\"clean_{session_id_}.csv\")\n",
    "\n",
    "        print(output_path)\n",
    "        df.to_csv(output_path, index=False)\n",
    "        print(f\"Successfully saved CSV to: {output_path}\")\n",
    "\n",
    "    except FileNotFoundError as e:\n",
    "        print(\n",
    "            f\"FileNotFoundError: For session {session_id} not found. Looked for {trimmed_path}\\nError info: \\n{e}\\n\\nTraceback: {traceback.format_exc()}\"\n",
    "        )\n",
    "    except json.JSONDecodeError:\n",
    "        print(f\"Error: Invalid JSON format in input file for session {session_id}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing session {session_id}: {str(e)}\")\n",
    "\n",
    "\n",
    "\n",
    "# Example usage\n",
    "for session_id in session_id_list:\n",
    "    json_to_csv_weighted(session_id)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llmdev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
  "data": [
    {
      "id": "0905c994",
      "timestamp": "2025-08-20T11:50:24.131000+00:00",
      "name": "0905_tpu_sketch_generator",
      "input": null,
      "output": {
        "status": "failed",
        "last_code": "import numpy as np\nfrom tflite_runtime.interpreter import Interpreter\nfrom tflite_runtime.interpreter import load_delegate\nimport cv2\n\n# Define paths and thresholds\nlabel_path    = \"/home/mendel/tinyml_autopilot/models/labelmap.txt\"\ninput_path    = \"/home/mendel/tinyml_autopilot/data//sheeps.mp4\"\nmodel_path    = \"/home/mendel/tinyml_autopilot/models/edgetpu_detect.tflite\"\nconfidence_threshold    = 0.5\n\n# Load labels\nwith open(label_path, 'r') as f:\n    labels = [line.strip() for line in f.readlines()]\n\n# Load interpreter with EdgeTPU\ninterpreter = Interpreter(model_path=model_path, experimental_delegates=[load_delegate('/usr/lib/aarch64-linux-gnu/libedgetpu.so.1')])\ninterpreter.allocate_tensors()\n\n# Get model details\ninput_details  = interpreter.get_input_details()\noutput_details  = \"/home/mendel/tinyml_autopilot/results/sheeps_detections.mp4\"\nheight = input_details[0]['shape'][1]\nwidth = input_details[0]['shape'][2]\nfloating_model = (input_details[0]['dtype'] == np.float32)\n\n# Input acquisition and preprocessing loop\ncap = cv2.VideoCapture(input_path)\n\nwhile cap.isOpened():\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    # Preprocess data\n    resized_frame = cv2.resize(frame, (width, height))\n    input_data = np.expand_dims(resized_frame, axis=0)\n\n    if floating_model:\n        input_data = (np.float32(input_data) - 127.5) / 127.5\n\n    # Inference\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n    interpreter.invoke()\n\n    # Output interpretation and handling\n    boxes = interpreter.get_tensor(output_details[0]['index'])[0]\n    classes = interpreter.get_tensor(output_details[1]['index'])[0]\n    scores = interpreter.get_tensor(output_details[2]['index'])[0]\n\n    for i in range(len(scores)):\n        if ((scores[i] > confidence_threshold) and (scores[i] <= 1.0)):\n            ymin = int(max(1, (boxes[i][0] * height)))\n            xmin = int(max(1, (boxes[i][1] * width)))\n            ymax = int(min(height, (boxes[i][2] * height)))\n            xmax = int(min(width, (boxes[i][3] * width)))\n\n            object_name = labels[int(classes[i])]\n            label = '%s: %d%%' % (object_name, int(scores[i]*100))\n\n# Cleanup\ncap.release()",
        "last_error": "Max retries reached with error. Last error: Traceback (most recent call last):\n  File \"script_81097f80_1755690775.py\", line 47, in <module>\n    boxes = interpreter.get_tensor(output_details[0]['index'])[0]\nTypeError: string indices must be integers."
      },
      "session_id": "codestral_fc8d_tpusg_batch",
      "metadata": {
        "num_run": 30
      },
      "tags": [
        "benchmark",
        "codestral:latest",
        "tpu_sketch_generator"
      ],
      "latency": 159.836,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-14-50-24-133135_chatcmpl-c0ba8da6-6d05-41d5-92fe-c8f8b4035d90",
          "traceId": "0905c994",
          "type": "GENERATION",
          "name": "0905_tpusg_gen_attempt#1",
          "startTime": "2025-08-20T11:50:24.133000+00:00",
          "endTime": "2025-08-20T11:50:51.271000+00:00",
          "model": "codestral:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 27138.0,
          "environment": "default",
          "promptTokens": 2048,
          "costDetails": {},
          "totalTokens": 3043,
          "completionTokens": 995,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-14-50-58-858479_chatcmpl-f6ac91a2-ed44-4670-87f3-211bebd0ee59",
          "traceId": "0905c994",
          "type": "GENERATION",
          "name": "0905_tpusg_gen_attempt#2",
          "startTime": "2025-08-20T11:50:58.858000+00:00",
          "endTime": "2025-08-20T11:51:23.895000+00:00",
          "model": "codestral:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 25037.0,
          "environment": "default",
          "promptTokens": 2048,
          "costDetails": {},
          "totalTokens": 2965,
          "completionTokens": 917,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-14-51-28-237298_chatcmpl-a3e15b33-3879-4c20-a26b-99a4acbcd142",
          "traceId": "0905c994",
          "type": "GENERATION",
          "name": "0905_tpusg_gen_attempt#3",
          "startTime": "2025-08-20T11:51:28.237000+00:00",
          "endTime": "2025-08-20T11:51:52.146000+00:00",
          "model": "codestral:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 23909.0,
          "environment": "default",
          "promptTokens": 2048,
          "costDetails": {},
          "totalTokens": 2921,
          "completionTokens": 873,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-14-52-00-239279_chatcmpl-ed4e7151-2460-4655-a684-9f64f01bd0f1",
          "traceId": "0905c994",
          "type": "GENERATION",
          "name": "0905_tpusg_gen_attempt#4",
          "startTime": "2025-08-20T11:52:00.239000+00:00",
          "endTime": "2025-08-20T11:52:23.897000+00:00",
          "model": "codestral:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 23658.0,
          "environment": "default",
          "promptTokens": 2048,
          "costDetails": {},
          "totalTokens": 2909,
          "completionTokens": 861,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-14-52-31-960820_chatcmpl-bef5be1d-460e-4a8d-b8a5-c9dc7dfc1271",
          "traceId": "0905c994",
          "type": "GENERATION",
          "name": "0905_tpusg_gen_attempt#5",
          "startTime": "2025-08-20T11:52:31.960000+00:00",
          "endTime": "2025-08-20T11:52:55.800000+00:00",
          "model": "codestral:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 23840.0,
          "environment": "default",
          "promptTokens": 2048,
          "costDetails": {},
          "totalTokens": 2917,
          "completionTokens": 869,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "f4f162d3-0c16-4fae-b6e2-f50424dba65b",
          "traceId": "0905c994",
          "type": "SPAN",
          "name": "error_09_tpusg_failure_signal_tpu_sketch_generator",
          "startTime": "2025-08-20T11:53:03.969000+00:00",
          "level": "ERROR",
          "statusMessage": "Failed: Max retries reached with error. Last error: Traceback (most recent call last):\n  File \"script_81097f80_1755690775.py\", line 47, in <module>\n    boxes = interpreter.get_tensor(output_details[0]['index'])[0]\nTypeError: string indices must be integers.",
          "calculatedTotalCost": 0.0,
          "environment": "default",
          "promptTokens": 0,
          "costDetails": {},
          "totalTokens": 0,
          "completionTokens": 0,
          "endTime": null,
          "model": null,
          "modelParameters": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null,
          "latency": null
        }
      ],
      "environment": "default",
      "createdAt": "2025-08-20T11:50:24.651Z",
      "updatedAt": "2025-08-20T11:53:09.371Z"
    },
    {
      "id": "9da2e982",
      "timestamp": "2025-08-20T11:48:23.583000+00:00",
      "name": "9da2_tpu_sketch_generator",
      "input": null,
      "output": {
        "status": "failed",
        "last_code": "import cv2\nimport numpy as np\nfrom pycoral.adapters import common\nfrom pycoral.adapters import detect\nfrom pycoral.utils.dataset import read_label_file\nfrom pycoral.utils.edgetpu import make_interpreter\n\n# Phase 1: Load Interpreter with EdgeTPU and Get Model Details\nmodel_path  = \"/home/mendel/tinyml_autopilot/models/edgetpu_detect.tflite\"\nlabel_path  = \"/home/mendel/tinyml_autopilot/models/labelmap.txt\"\n\nlabels = read_label_file(label_path)\ninterpreter = make_interpreter(model_path)\ninterpreter.allocate_tensors()\ninput_details  = \"/home/mendel/tinyml_autopilot/data//sheeps.mp4\"\noutput_details  = \"/home/mendel/tinyml_autopilot/results/sheeps_detections.mp4\"\nheight, width = input_details['shape'][1:3]\nfloating_model = (input_details['dtype'] == np.float32)\n\n# Phase 2: Input Acquisition & Preprocessing Loop\ncap = cv2.VideoCapture(0)\n\nwhile True:\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    # Resize and convert to RGB\n    img = cv2.resize(frame, (width, height))\n    rgb_img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n\n    # Quantization Handling\n    if floating_model:\n        input_data = np.expand_dims((np.float32(rgb_img) - 127.5) / 127.5, axis=0)\n    else:\n        input_data = np.expand_dims(rgb_img, axis=0)\n\n    # Phase 3: Inference (Run per preprocessed input)\n    interpreter.set_tensor(input_details['index'], input_data)\n    interpreter.invoke()\n\n    # Phase 4: Output Interpretation & Handling Loop\n    results = detect.get_objects(interpreter, score_threshold=0.5, image_scale=(width, height))\n\n    for obj in results:\n        bbox = obj.bbox\n        label = labels[obj.id]\n        score = obj.score\n\n        print(f'Label: {label}, Score: {score}, Box: {bbox}')\n\n    # Press 'q' to quit\n    if cv2.waitKey(1) & 0xFF == ord('q'):\n        break\n\n# Phase 5: Cleanup\ncap.release()\ncv2.destroyAllWindows()",
        "last_error": "Max retries reached with error. Last error: Traceback (most recent call last):\n  File \"script_8cfd5daa_1755690610.py\", line 17, in <module>\n    height, width = input_details['shape'][1:3]\nTypeError: string indices must be integers."
      },
      "session_id": "codestral_fc8d_tpusg_batch",
      "metadata": {
        "num_run": 29
      },
      "tags": [
        "benchmark",
        "codestral:latest",
        "tpu_sketch_generator"
      ],
      "latency": 114.819,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-14-48-23-584749_chatcmpl-abd3f107-a0ee-445b-84f6-5cd1bedf8969",
          "traceId": "9da2e982",
          "type": "GENERATION",
          "name": "9da2_tpusg_gen_attempt#1",
          "startTime": "2025-08-20T11:48:23.584000+00:00",
          "endTime": "2025-08-20T11:48:52.547000+00:00",
          "model": "codestral:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 28963.0,
          "environment": "default",
          "promptTokens": 2048,
          "costDetails": {},
          "totalTokens": 3121,
          "completionTokens": 1073,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-14-49-00-167251_chatcmpl-8072d4d0-a20b-40ae-b211-d1988966ac7a",
          "traceId": "9da2e982",
          "type": "GENERATION",
          "name": "9da2_tpusg_gen_attempt#2",
          "startTime": "2025-08-20T11:49:00.167000+00:00",
          "endTime": "2025-08-20T11:49:06.549000+00:00",
          "model": "codestral:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 6382.0,
          "environment": "default",
          "promptTokens": 2048,
          "costDetails": {},
          "totalTokens": 2215,
          "completionTokens": 167,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-14-49-06-552168_chatcmpl-db10774b-6036-4574-ba29-c3827323ec14",
          "traceId": "9da2e982",
          "type": "GENERATION",
          "name": "9da2_tpusg_gen_attempt#3",
          "startTime": "2025-08-20T11:49:06.552000+00:00",
          "endTime": "2025-08-20T11:49:21.069000+00:00",
          "model": "codestral:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 14517.0,
          "environment": "default",
          "promptTokens": 2048,
          "costDetails": {},
          "totalTokens": 2542,
          "completionTokens": 494,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-14-49-21-071153_chatcmpl-90496051-712b-4362-a86e-b9f5ae850a37",
          "traceId": "9da2e982",
          "type": "GENERATION",
          "name": "9da2_tpusg_gen_attempt#4",
          "startTime": "2025-08-20T11:49:21.071000+00:00",
          "endTime": "2025-08-20T11:49:40.934000+00:00",
          "model": "codestral:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 19863.0,
          "environment": "default",
          "promptTokens": 2048,
          "costDetails": {},
          "totalTokens": 2758,
          "completionTokens": 710,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-14-49-48-817443_chatcmpl-2fa2ca03-9b59-4be8-89b5-5cf3acc3cda9",
          "traceId": "9da2e982",
          "type": "GENERATION",
          "name": "9da2_tpusg_gen_attempt#5",
          "startTime": "2025-08-20T11:49:48.817000+00:00",
          "endTime": "2025-08-20T11:50:10.448000+00:00",
          "model": "codestral:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 21631.0,
          "environment": "default",
          "promptTokens": 2048,
          "costDetails": {},
          "totalTokens": 2821,
          "completionTokens": 773,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "a005ad6e-e053-4f1c-94cf-9fa19b0ec5a9",
          "traceId": "9da2e982",
          "type": "SPAN",
          "name": "error_9d_tpusg_failure_signal_tpu_sketch_generator",
          "startTime": "2025-08-20T11:50:18.403000+00:00",
          "level": "ERROR",
          "statusMessage": "Failed: Max retries reached with error. Last error: Traceback (most recent call last):\n  File \"script_8cfd5daa_1755690610.py\", line 17, in <module>\n    height, width = input_details['shape'][1:3]\nTypeError: string indices must be integers.",
          "calculatedTotalCost": 0.0,
          "environment": "default",
          "promptTokens": 0,
          "costDetails": {},
          "totalTokens": 0,
          "completionTokens": 0,
          "endTime": null,
          "model": null,
          "modelParameters": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null,
          "latency": null
        }
      ],
      "environment": "default",
      "createdAt": "2025-08-20T11:48:24.100Z",
      "updatedAt": "2025-08-20T11:50:23.796Z"
    },
    {
      "id": "5cd99309",
      "timestamp": "2025-08-20T11:46:39.020000+00:00",
      "name": "5cd9_tpu_sketch_generator",
      "input": null,
      "output": {
        "status": "failed",
        "last_code": "import cv2\nimport numpy as np\nfrom PIL import Image\nfrom tflite_runtime.interpreter import Interpreter, load_delegate\n\n# Define labels for object detection\nlabels = ['person', 'bicycle', 'car', ...]  # Replace with your actual labels\n\n# Phase 1: Load Interpreter with EdgeTPU\nmodel_path = 'your_model_path'\ntry:\n    interpreter = Interpreter(model_path=model_path, experimental_delegates=[load_delegate('libedgetpu.so.1.0')])\nexcept:\n    interpreter = Interpreter(model_path=model_path, experimental_delegates=[load_delegate('/usr/lib/aarch64-linux-gnu/libedgetpu.so.1.0')])\ninterpreter.allocate_tensors()\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\n\n# Phase 2: Input Acquisition & Preprocessing Loop\nimage_path = 'your_image_path'\nimage = Image.open(image_path).resize((input_details[0]['shape'][1], input_details[0]['shape'][2]))\ninput_data = np.expand_dims(np.array(image), axis=0)\nfloating_model = (input_details[0]['dtype'] == np.float32)\nif floating_model:\n    input_data = (np.float32(input_data) - 127.5) / 127.5\n\n# Phase 3: Inference\ninterpreter.set_tensor(input_details[0]['index'], input_data)\ninterpreter.invoke()\n\n# Phase 4: Output Interpretation & Handling Loop\noutput_data = interpreter.get_tensor(output_details[0]['index'])\nresults = np.squeeze(output_data)\ntop_k = results.argsort()[-5:][::-1]\nconfidence_threshold = 0.5  # Define your confidence threshold\nfor i in top_k:\n    if float(results[i]) > confidence_threshold:  # Apply confidence thresholding\n        print('{:08f}: {}'.format(float(results[i]), labels[i]))  # Use the label list to map indices to names",
        "last_error": "Max retries reached with exception: Unexpected error during generation: Generated script is not complete. Please ensure to generate a complete Python script.."
      },
      "session_id": "codestral_fc8d_tpusg_batch",
      "metadata": {
        "num_run": 28
      },
      "tags": [
        "benchmark",
        "codestral:latest",
        "tpu_sketch_generator"
      ],
      "latency": 97.542,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-14-46-39-022177_chatcmpl-b7d21a83-d51f-4799-a2ad-0c731c8434f8",
          "traceId": "5cd99309",
          "type": "GENERATION",
          "name": "5cd9_tpusg_gen_attempt#1",
          "startTime": "2025-08-20T11:46:39.022000+00:00",
          "endTime": "2025-08-20T11:47:07.964000+00:00",
          "model": "codestral:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 28942.0,
          "environment": "default",
          "promptTokens": 2048,
          "costDetails": {},
          "totalTokens": 3121,
          "completionTokens": 1073,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-14-47-15-559372_chatcmpl-603afda3-9ef7-41b1-845c-1ca6616b6c62",
          "traceId": "5cd99309",
          "type": "GENERATION",
          "name": "5cd9_tpusg_gen_attempt#2",
          "startTime": "2025-08-20T11:47:15.559000+00:00",
          "endTime": "2025-08-20T11:47:21.789000+00:00",
          "model": "codestral:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 6230.0,
          "environment": "default",
          "promptTokens": 2048,
          "costDetails": {},
          "totalTokens": 2208,
          "completionTokens": 160,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-14-47-21-792787_chatcmpl-96088957-f746-4437-b1ac-a16328dde137",
          "traceId": "5cd99309",
          "type": "GENERATION",
          "name": "5cd9_tpusg_gen_attempt#3",
          "startTime": "2025-08-20T11:47:21.792000+00:00",
          "endTime": "2025-08-20T11:47:41.077000+00:00",
          "model": "codestral:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 19285.0,
          "environment": "default",
          "promptTokens": 2048,
          "costDetails": {},
          "totalTokens": 2734,
          "completionTokens": 686,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-14-47-41-080211_chatcmpl-7ad842f9-da86-4d41-81c9-b2cf8e55eb33",
          "traceId": "5cd99309",
          "type": "GENERATION",
          "name": "5cd9_tpusg_gen_attempt#4",
          "startTime": "2025-08-20T11:47:41.080000+00:00",
          "endTime": "2025-08-20T11:47:59.388000+00:00",
          "model": "codestral:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 18308.0,
          "environment": "default",
          "promptTokens": 2048,
          "costDetails": {},
          "totalTokens": 2695,
          "completionTokens": 647,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-14-47-59-390716_chatcmpl-8d6849ef-7bad-47cb-a9ee-1a8f1a530039",
          "traceId": "5cd99309",
          "type": "GENERATION",
          "name": "5cd9_tpusg_gen_attempt#5",
          "startTime": "2025-08-20T11:47:59.390000+00:00",
          "endTime": "2025-08-20T11:48:16.562000+00:00",
          "model": "codestral:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 17172.0,
          "environment": "default",
          "promptTokens": 2048,
          "costDetails": {},
          "totalTokens": 2649,
          "completionTokens": 601,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "bc584e82-4f20-4153-be60-1703f546d2fa",
          "traceId": "5cd99309",
          "type": "SPAN",
          "name": "error_5c_tpusg_failure_signal_tpu_sketch_generator",
          "startTime": "2025-08-20T11:48:16.564000+00:00",
          "level": "ERROR",
          "statusMessage": "Failed: Max retries reached with exception: Unexpected error during generation: Generated script is not complete. Please ensure to generate a complete Python script..",
          "calculatedTotalCost": 0.0,
          "environment": "default",
          "promptTokens": 0,
          "costDetails": {},
          "totalTokens": 0,
          "completionTokens": 0,
          "endTime": null,
          "model": null,
          "modelParameters": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null,
          "latency": null
        }
      ],
      "environment": "default",
      "createdAt": "2025-08-20T11:46:39.538Z",
      "updatedAt": "2025-08-20T11:48:22.567Z"
    },
    {
      "id": "e3b63227",
      "timestamp": "2025-08-20T11:45:24.490000+00:00",
      "name": "e3b6_tpu_sketch_generator",
      "input": null,
      "output": {
        "status": "failed",
        "last_code": "import cv2\nimport numpy as np\nfrom tensorflow.lite import Interpreter\nfrom tensorflow.lite.experimental import load_delegate\n\n# Define paths and parameters\nmodel_path  = \"/home/mendel/tinyml_autopilot/models/edgetpu_detect.tflite\"\ninput_path  = \"/home/mendel/tinyml_autopilot/data//sheeps.mp4\"\nlabel_path  = \"/home/mendel/tinyml_autopilot/models/labelmap.txt\"\noutput_path  = \"/home/mendel/tinyml_autopilot/results/sheeps_detections.mp4\"\nconfidence_threshold  = 0.5\n\n# Load labels\nwith open(label_path, 'r') as f:\n    labels = [line.strip() for line in f.readlines()]\n\n# Load interpreter with EdgeTPU\ntry:\n    interpreter = Interpreter(model_path=model_path, experimental_delegates=[load_delegate('libedgetpu.so.1.0')])\nexcept:\n    interpreter = Interpreter(model_path=model_path, experimental_delegates=[load_delegate('/usr/lib/aarch64-linux-gnu/libedgetpu.so.1.0')])\ninterpreter.allocate_tensors()\n\n# Get model details\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\nheight = input_details[0]['shape'][1]\nwidth = input_details[0]['shape'][2]\nfloating_model = (input_details[0]['dtype'] == np.float32)\n\n# Input acquisition and preprocessing loop\ncap = cv2.VideoCapture(input_path)\nwhile cap.isOpened():\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    # Preprocess data\n    resized_frame = cv2.resize(frame, (width, height))\n    input_data = np.expand_dims(resized_frame, axis=0)\n    if floating_model:\n        input_data = (np.float32(input_data) - 127.5) / 127.5\n\n    # Inference\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n    interpreter.invoke()\n\n    # Output interpretation and handling loop\n    boxes = interpreter.get_tensor(output_details[0]['index'])[0]\n    classes = interpreter.get_tensor(output_details[1]['index'])[0]\n    scores = interpreter.get_tensor(output_details[2]['index'])[0]\n\n    # Interpret results and post-processing\n    for i in range(len(scores)):\n        if ((scores[i] > confidence_threshold) and (scores[i] <= 1.0)):\n            ymin = int(max(1, (boxes[i][0] * frame.shape[0])))\n            xmin = int(max(1, (boxes[i][1] * frame.shape[1])))\n            ymax = int(min(frame.shape[0], (boxes[i][2] * frame.shape[0])))\n            xmax = int(min(frame.shape[1], (boxes[i][3] * frame.shape[1])))\n\n            cv2.rectangle(frame, (xmin, ymin), (xmax, ymax), (10, 255, 0), 4)\n            object_name = labels[int(classes[i])]\n            label = '%s: %d%%' % (object_name, int(scores[i]*100))\n            labelSize, baseLine = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.7, 2)\n            label_ymin = max(ymin, labelSize[1] + 10)\n            cv2.rectangle(frame, (xmin, label_ymin-labelSize[1]-10), (xmin+labelSize[0], label_ymin+baseLine-10), (255, 255, 255), cv2.FILLED)\n            cv2.putText(frame, label, (xmin, label_ymin-7), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 0), 2)\n\n    # Handle output\n    cv2.imshow('Object Detection', frame)\n    if cv2.waitKey(1) & 0xFF == ord('q'):\n        break\n\n# Clean up\ncap.release()\ncv2.destroyAllWindows()",
        "last_error": "Max retries reached with exception: Unexpected error during generation: The output is not a valid code block. Follow the instructions in the prompt return a complete, correct Python script enclosed in a single ```python\n<generated_code>\n``` block.."
      },
      "session_id": "codestral_fc8d_tpusg_batch",
      "metadata": {
        "num_run": 27
      },
      "tags": [
        "benchmark",
        "codestral:latest",
        "tpu_sketch_generator"
      ],
      "latency": 67.79,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-14-45-24-491525_chatcmpl-254b2902-4d91-490d-a228-0344853267a0",
          "traceId": "e3b63227",
          "type": "GENERATION",
          "name": "e3b6_tpusg_gen_attempt#1",
          "startTime": "2025-08-20T11:45:24.491000+00:00",
          "endTime": "2025-08-20T11:45:53.455000+00:00",
          "model": "codestral:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 28964.0,
          "environment": "default",
          "promptTokens": 2048,
          "costDetails": {},
          "totalTokens": 3121,
          "completionTokens": 1073,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-14-46-01-057701_chatcmpl-7ce3f5f1-d3ad-4642-9048-ad9fb30f0326",
          "traceId": "e3b63227",
          "type": "GENERATION",
          "name": "e3b6_tpusg_gen_attempt#2",
          "startTime": "2025-08-20T11:46:01.057000+00:00",
          "endTime": "2025-08-20T11:46:08.302000+00:00",
          "model": "codestral:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 7245.0,
          "environment": "default",
          "promptTokens": 2048,
          "costDetails": {},
          "totalTokens": 2249,
          "completionTokens": 201,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-14-46-08-308928_chatcmpl-b7d00cae-56f0-4214-b33c-15e37045edb6",
          "traceId": "e3b63227",
          "type": "GENERATION",
          "name": "e3b6_tpusg_gen_attempt#3",
          "startTime": "2025-08-20T11:46:08.308000+00:00",
          "endTime": "2025-08-20T11:46:14.441000+00:00",
          "model": "codestral:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 6133.0,
          "environment": "default",
          "promptTokens": 2048,
          "costDetails": {},
          "totalTokens": 2205,
          "completionTokens": 157,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-14-46-14-444255_chatcmpl-ed91759b-4d28-4f71-824d-ff69df49a6ad",
          "traceId": "e3b63227",
          "type": "GENERATION",
          "name": "e3b6_tpusg_gen_attempt#4",
          "startTime": "2025-08-20T11:46:14.444000+00:00",
          "endTime": "2025-08-20T11:46:21.196000+00:00",
          "model": "codestral:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 6752.0,
          "environment": "default",
          "promptTokens": 2048,
          "costDetails": {},
          "totalTokens": 2230,
          "completionTokens": 182,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-14-46-21-200444_chatcmpl-49326f85-f869-49fb-a672-0b30942a2791",
          "traceId": "e3b63227",
          "type": "GENERATION",
          "name": "e3b6_tpusg_gen_attempt#5",
          "startTime": "2025-08-20T11:46:21.200000+00:00",
          "endTime": "2025-08-20T11:46:32.278000+00:00",
          "model": "codestral:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 11078.0,
          "environment": "default",
          "promptTokens": 2048,
          "costDetails": {},
          "totalTokens": 2404,
          "completionTokens": 356,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "255ae535-bc8c-48d2-b98f-502001683c67",
          "traceId": "e3b63227",
          "type": "SPAN",
          "name": "error_e3_tpusg_failure_signal_tpu_sketch_generator",
          "startTime": "2025-08-20T11:46:32.281000+00:00",
          "level": "ERROR",
          "statusMessage": "Failed: Max retries reached with exception: Unexpected error during generation: The output is not a valid code block. Follow the instructions in the prompt return a complete, correct Python script enclosed in a single ```python\n<generated_code>\n``` block..",
          "calculatedTotalCost": 0.0,
          "environment": "default",
          "promptTokens": 0,
          "costDetails": {},
          "totalTokens": 0,
          "completionTokens": 0,
          "endTime": null,
          "model": null,
          "modelParameters": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null,
          "latency": null
        }
      ],
      "environment": "default",
      "createdAt": "2025-08-20T11:45:25.008Z",
      "updatedAt": "2025-08-20T11:46:37.889Z"
    },
    {
      "id": "c44a0087",
      "timestamp": "2025-08-20T11:43:18.951000+00:00",
      "name": "c44a_tpu_sketch_generator",
      "input": null,
      "output": {
        "status": "failed",
        "last_code": "import cv2\nimport numpy as np\nfrom tflite_runtime.interpreter import Interpreter\nfrom tflite_runtime.interpreter import load_delegate\n\n# Load Labels\nwith open('your_labels_path', 'r') as f:\n    labels = [line.strip() for line in f.readlines()]\n\n# Phase 1: Load Interpreter with EdgeTPU and Model Details\ntry:\n    interpreter = Interpreter(model_path='your_model_path',\n                              experimental_delegates=[load_delegate('libedgetpu.so.1')])\nexcept ValueError:\n    interpreter = Interpreter(model_path='your_model_path',\n                              experimental_delegates=[load_delegate('/usr/lib/aarch64-linux-gnu/libedgetpu.so.1')])\ninterpreter.allocate_tensors()\ninput_details  = \"/home/mendel/tinyml_autopilot/data//sheeps.mp4\"\noutput_details  = \"/home/mendel/tinyml_autopilot/results/sheeps_detections.mp4\"\n\n# Phase 2: Input Acquisition & Preprocessing Loop (Reading a Video File)\ncap = cv2.VideoCapture('your_input_path')\nwhile cap.isOpened():\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    # Phase 2.2: Preprocess Data\n    input_data = np.expand_dims(frame, axis=0)\n    floating_model = (input_details[0]['dtype'] == np.float32)\n    if floating_model:\n        input_data = (np.float32(input_data) - 127.5) / 127.5\n\n    # Phase 3: Inference\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n    interpreter.invoke()\n\n    # Phase 4: Output Interpretation & Handling Loop (Drawing Bounding Boxes on Frame)\n    output_data = interpreter.get_output_details()[0]\n    boxes = interpreter.get_tensor(output_data['index'])[0]\n    for i in range(len(boxes)):\n        if boxes[i][2] > 0.5: # Confidence threshold\n            x1, y1, w, h = boxes[i][0], boxes[i][1], boxes[i][2], boxes[i][3]\n            p1 = (int(x1 * frame.shape[1]), int(y1 * frame.shape[0]))\n            p2 = (int((x1 + w) * frame.shape[1]), int((y1 + h) * frame.shape[0]))\n            cv2.rectangle(frame, p1, p2, (0, 255, 0), 3)\n            label_index = np.argmax(boxes[i][4:])\n            label = labels[label_index] if label_index < len(labels) else 'Unknown'\n            cv2.putText(frame, label, p1, cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 2)\n    cv2.imshow('Object Detection', frame)\n    if cv2.waitKey(1) & 0xFF == ord('q'):\n        break\ncap.release()\ncv2.destroyAllWindows()",
        "last_error": "Max retries reached with error. Last error: Traceback (most recent call last):\n  File \"script_54395240_1755690310.py\", line 7, in <module>\n    with open('your_labels_path', 'r') as f:\nFileNotFoundError: [Errno 2] No such file or directory: 'your_labels_path'."
      },
      "session_id": "codestral_fc8d_tpusg_batch",
      "metadata": {
        "num_run": 26
      },
      "tags": [
        "benchmark",
        "codestral:latest",
        "tpu_sketch_generator"
      ],
      "latency": 119.051,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-14-43-18-952749_chatcmpl-201f61b1-d028-4c88-b183-4e4c95df62c5",
          "traceId": "c44a0087",
          "type": "GENERATION",
          "name": "c44a_tpusg_gen_attempt#1",
          "startTime": "2025-08-20T11:43:18.952000+00:00",
          "endTime": "2025-08-20T11:43:47.919000+00:00",
          "model": "codestral:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 28967.0,
          "environment": "default",
          "promptTokens": 2048,
          "costDetails": {},
          "totalTokens": 3121,
          "completionTokens": 1073,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-14-43-55-424900_chatcmpl-3dd2fc96-93f0-44e1-9cd3-0af25172559f",
          "traceId": "c44a0087",
          "type": "GENERATION",
          "name": "c44a_tpusg_gen_attempt#2",
          "startTime": "2025-08-20T11:43:55.424000+00:00",
          "endTime": "2025-08-20T11:44:00.512000+00:00",
          "model": "codestral:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 5088.0,
          "environment": "default",
          "promptTokens": 2048,
          "costDetails": {},
          "totalTokens": 2163,
          "completionTokens": 115,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-14-44-00-514852_chatcmpl-341a2c8e-b6ba-4f34-9987-5c9dc56b9555",
          "traceId": "c44a0087",
          "type": "GENERATION",
          "name": "c44a_tpusg_gen_attempt#3",
          "startTime": "2025-08-20T11:44:00.514000+00:00",
          "endTime": "2025-08-20T11:44:24.948000+00:00",
          "model": "codestral:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 24434.0,
          "environment": "default",
          "promptTokens": 2048,
          "costDetails": {},
          "totalTokens": 2942,
          "completionTokens": 894,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-14-44-24-951338_chatcmpl-037c37de-4758-4ae8-a968-8336fd3c023e",
          "traceId": "c44a0087",
          "type": "GENERATION",
          "name": "c44a_tpusg_gen_attempt#4",
          "startTime": "2025-08-20T11:44:24.951000+00:00",
          "endTime": "2025-08-20T11:44:45.954000+00:00",
          "model": "codestral:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 21003.0,
          "environment": "default",
          "promptTokens": 2048,
          "costDetails": {},
          "totalTokens": 2804,
          "completionTokens": 756,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-14-44-45-961220_chatcmpl-a2e1f943-6509-4d7d-9a7d-297b360abc3a",
          "traceId": "c44a0087",
          "type": "GENERATION",
          "name": "c44a_tpusg_gen_attempt#5",
          "startTime": "2025-08-20T11:44:45.961000+00:00",
          "endTime": "2025-08-20T11:45:10.439000+00:00",
          "model": "codestral:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 24478.0,
          "environment": "default",
          "promptTokens": 2048,
          "costDetails": {},
          "totalTokens": 2943,
          "completionTokens": 895,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "9eb16c28-b027-4da1-ad5e-37aa8fc8f5eb",
          "traceId": "c44a0087",
          "type": "SPAN",
          "name": "error_c4_tpusg_failure_signal_tpu_sketch_generator",
          "startTime": "2025-08-20T11:45:18.003000+00:00",
          "level": "ERROR",
          "statusMessage": "Failed: Max retries reached with error. Last error: Traceback (most recent call last):\n  File \"script_54395240_1755690310.py\", line 7, in <module>\n    with open('your_labels_path', 'r') as f:\nFileNotFoundError: [Errno 2] No such file or directory: 'your_labels_path'.",
          "calculatedTotalCost": 0.0,
          "environment": "default",
          "promptTokens": 0,
          "costDetails": {},
          "totalTokens": 0,
          "completionTokens": 0,
          "endTime": null,
          "model": null,
          "modelParameters": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null,
          "latency": null
        }
      ],
      "environment": "default",
      "createdAt": "2025-08-20T11:43:19.470Z",
      "updatedAt": "2025-08-20T11:45:23.125Z"
    },
    {
      "id": "adcc1de2",
      "timestamp": "2025-08-20T11:41:00.376000+00:00",
      "name": "adcc_tpu_sketch_generator",
      "input": null,
      "output": {
        "status": "failed",
        "last_code": "import cv2\nimport numpy as np\nfrom tflite_runtime.interpreter import load_delegate, Interpreter\n\n# Load labels\nwith open('/home/mendel/tinyml_autopilot/data/labels.txt', 'r') as f:\n    labels = [line.strip() for line in f.readlines()]\n\n# Load the model with EdgeTPU acceleration\ninterpreter = Interpreter(model_path='/home/mendel/tinyml_autopilot/data/model.tflite', experimental_delegates=[load_delegate('libedgetpu.so.1')])\ninterpreter.allocate_tensors()\n\n# Get input and output details\ninput_details  = \"/home/mendel/tinyml_autopilot/data//sheeps.mp4\"\noutput_details  = \"/home/mendel/tinyml_autopilot/results/sheeps_detections.mp4\"\n\n# Open the video file\ncap = cv2.VideoCapture('/home/mendel/tinyml_autopilot/data/sheeps.mp4')\n\n# Define the codec and create VideoWriter object\nfourcc = cv2.VideoWriter_fourcc(*'mp4v')\nout = cv2.VideoWriter('/home/mendel/tinyml_autopilot/results/sheeps_detections.mp4', fourcc, 30.0, (640,  480))\n\n# Loop through the video frames\nwhile cap.isOpened():\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    # Resize the frame to match the model's input shape\n    input_shape = input_details[0]['shape']\n    resized_frame = cv2.resize(frame, (input_shape[1], input_shape[2]))\n\n    # Convert the frame to a numpy array and normalize it\n    input_data = np.array(resized_frame) / 255.0\n    input_data = np.expand_dims(input_data, axis=0).astype(np.float32)\n\n    # Set input tensor\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n\n    # Run inference\n    interpreter.invoke()\n\n    # Get output tensors\n    boxes = interpreter.get_tensor(output_details[0]['index'])[0]\n    classes = interpreter.get_tensor(output_details[1]['index'])[0]\n    scores = interpreter.get_tensor(output_details[2]['index'])[0]\n\n    # Loop over all detections and draw bounding box if confidence is above a threshold\n    for i in range(len(scores)):\n        if ((scores[i] > 0.5) and (scores[i] <= 1.0)):\n            # Get the label of the class\n            label = labels[int(classes[i])]\n\n            # Get the bounding box coordinates and scale them to the original frame size\n            ymin, xmin, ymax, xmax = boxes[i]\n            xmin = int(xmin * frame.shape[1])\n            xmax = int(xmax * frame.shape[1])\n            ymin = int(ymin * frame.shape[0])\n            ymax = int(ymax * frame.shape[0])\n\n            # Draw the bounding box and label on the frame\n            cv2.rectangle(frame, (xmin, ymin), (xmax, ymax), (10, 255, 0), 2)\n            cv2.putText(frame, \"{}: {:.2f}\".format(label, scores[i]), (xmin, ymin - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (10, 255, 0), 2)\n\n    # Write the frame with bounding boxes to the output video file\n    out.write(frame)\n\n# Release resources\ncap.release()\nout.release()\ncv2.destroyAllWindows()",
        "last_error": "Max retries reached with error. Last error: Traceback (most recent call last):\n  File \"script_8f618de1_1755690185.py\", line 6, in <module>\n    with open('/home/mendel/tinyml_autopilot/data/labels.txt', 'r') as f:\nFileNotFoundError: [Errno 2] No such file or directory: '/home/mendel/tinyml_autopilot/data/labels.txt'."
      },
      "session_id": "codestral_fc8d_tpusg_batch",
      "metadata": {
        "num_run": 25
      },
      "tags": [
        "benchmark",
        "codestral:latest",
        "tpu_sketch_generator"
      ],
      "latency": 132.614,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-14-41-00-378049_chatcmpl-d8497254-9bbb-4a1c-bf6d-671bb2dd2651",
          "traceId": "adcc1de2",
          "type": "GENERATION",
          "name": "adcc_tpusg_gen_attempt#1",
          "startTime": "2025-08-20T11:41:00.378000+00:00",
          "endTime": "2025-08-20T11:41:27.396000+00:00",
          "model": "codestral:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 27018.0,
          "environment": "default",
          "promptTokens": 2048,
          "costDetails": {},
          "totalTokens": 3043,
          "completionTokens": 995,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-14-41-34-971234_chatcmpl-eff93844-c431-40ab-af45-168ebc46e36e",
          "traceId": "adcc1de2",
          "type": "GENERATION",
          "name": "adcc_tpusg_gen_attempt#2",
          "startTime": "2025-08-20T11:41:34.971000+00:00",
          "endTime": "2025-08-20T11:41:41.001000+00:00",
          "model": "codestral:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 6030.0,
          "environment": "default",
          "promptTokens": 2048,
          "costDetails": {},
          "totalTokens": 2200,
          "completionTokens": 152,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-14-41-41-003772_chatcmpl-7330278b-f306-40d1-9647-fde7e00d77e9",
          "traceId": "adcc1de2",
          "type": "GENERATION",
          "name": "adcc_tpusg_gen_attempt#3",
          "startTime": "2025-08-20T11:41:41.003000+00:00",
          "endTime": "2025-08-20T11:41:57.303000+00:00",
          "model": "codestral:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 16300.0,
          "environment": "default",
          "promptTokens": 2048,
          "costDetails": {},
          "totalTokens": 2614,
          "completionTokens": 566,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-14-41-57-307891_chatcmpl-9dd8c7ef-e084-4737-9830-2e9d3a918932",
          "traceId": "adcc1de2",
          "type": "GENERATION",
          "name": "adcc_tpusg_gen_attempt#4",
          "startTime": "2025-08-20T11:41:57.307000+00:00",
          "endTime": "2025-08-20T11:42:28.321000+00:00",
          "model": "codestral:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 31014.0,
          "environment": "default",
          "promptTokens": 2048,
          "costDetails": {},
          "totalTokens": 3206,
          "completionTokens": 1158,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-14-42-35-919027_chatcmpl-213929ff-0f49-475c-bf6c-12ba8ac85830",
          "traceId": "adcc1de2",
          "type": "GENERATION",
          "name": "adcc_tpusg_gen_attempt#5",
          "startTime": "2025-08-20T11:42:35.919000+00:00",
          "endTime": "2025-08-20T11:43:05.428000+00:00",
          "model": "codestral:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 29509.0,
          "environment": "default",
          "promptTokens": 2048,
          "costDetails": {},
          "totalTokens": 3143,
          "completionTokens": 1095,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "7645203a-0ab8-4c1c-a61f-6ff8988144d1",
          "traceId": "adcc1de2",
          "type": "SPAN",
          "name": "error_ad_tpusg_failure_signal_tpu_sketch_generator",
          "startTime": "2025-08-20T11:43:12.992000+00:00",
          "level": "ERROR",
          "statusMessage": "Failed: Max retries reached with error. Last error: Traceback (most recent call last):\n  File \"script_8f618de1_1755690185.py\", line 6, in <module>\n    with open('/home/mendel/tinyml_autopilot/data/labels.txt', 'r') as f:\nFileNotFoundError: [Errno 2] No such file or directory: '/home/mendel/tinyml_autopilot/data/labels.txt'.",
          "calculatedTotalCost": 0.0,
          "environment": "default",
          "promptTokens": 0,
          "costDetails": {},
          "totalTokens": 0,
          "completionTokens": 0,
          "endTime": null,
          "model": null,
          "modelParameters": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null,
          "latency": null
        }
      ],
      "environment": "default",
      "createdAt": "2025-08-20T11:41:00.896Z",
      "updatedAt": "2025-08-20T11:43:18.574Z"
    },
    {
      "id": "8ff8fa4e",
      "timestamp": "2025-08-20T11:37:36.825000+00:00",
      "name": "8ff8_tpu_sketch_generator",
      "input": null,
      "output": {
        "status": "success",
        "sketch": "import cv2\nimport numpy as np\nfrom tflite_runtime.interpreter import Interpreter, load_delegate\n\n# Define paths and threshold\nlabel_path  = \"/home/mendel/tinyml_autopilot/models/labelmap.txt\"\nmodel_path  = \"/home/mendel/tinyml_autopilot/models/edgetpu_detect.tflite\"\ninput_path  = \"/home/mendel/tinyml_autopilot/data//sheeps.mp4\"\noutput_path  = \"/home/mendel/tinyml_autopilot/results/sheeps_detections.mp4\"\nconfidence_threshold  = 0.5\n\n# Load labels\nwith open(label_path, 'r') as f:\n    labels = [line.strip() for line in f.readlines()]\n\n# Load interpreter with EdgeTPU\ninterpreter = Interpreter(model_path=model_path, experimental_delegates=[load_delegate('libedgetpu.so.1.0')])\ninterpreter.allocate_tensors()\n\n# Get model details\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\nheight = input_details[0]['shape'][1]\nwidth = input_details[0]['shape'][2]\nfloating_model = (input_details[0]['dtype'] == np.float32)\n\n# Input acquisition and preprocessing loop\ncap = cv2.VideoCapture(input_path)\nfourcc = cv2.VideoWriter_fourcc(*'mp4v')\nout = cv2.VideoWriter(output_path, fourcc, 20.0, (int(cap.get(3)), int(cap.get(4))))\nwhile cap.isOpened():\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    # Preprocess data\n    resized_frame = cv2.resize(frame, (width, height))\n    input_data = np.expand_dims(resized_frame, axis=0)\n    if floating_model:\n        input_data = (np.float32(input_data) - 127.5) / 127.5\n\n    # Inference\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n    interpreter.invoke()\n\n    # Output interpretation and handling loop\n    boxes = interpreter.get_tensor(output_details[0]['index'])[0]\n    classes = interpreter.get_tensor(output_details[1]['index'])[0]\n    scores = interpreter.get_tensor(output_details[2]['index'])[0]\n\n    # Interpret results and post-processing\n    for i in range(len(scores)):\n        if ((scores[i] > confidence_threshold) and (scores[i] <= 1.0)):\n            ymin = int(max(1, (boxes[i][0] * frame.shape[0])))\n            xmin = int(max(1, (boxes[i][1] * frame.shape[1])))\n            ymax = int(min(frame.shape[0], (boxes[i][2] * frame.shape[0])))\n            xmax = int(min(frame.shape[1], (boxes[i][3] * frame.shape[1])))\n\n            cv2.rectangle(frame, (xmin, ymin), (xmax, ymax), (10, 255, 0), 4)\n            object_name = labels[int(classes[i])]\n            label = '%s: %d%%' % (object_name, int(scores[i]*100))\n            labelSize, baseLine = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.7, 2)\n            label_ymin = max(ymin, labelSize[1] + 10)\n            cv2.rectangle(frame, (xmin, label_ymin-labelSize[1]-10), (xmin+labelSize[0], label_ymin+baseLine-10), (255, 255, 255), cv2.FILLED)\n            cv2.putText(frame, label, (xmin, label_ymin-7), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 0), 2)\n    out.write(frame)\n\ncap.release()\nout.release()\ncv2.destroyAllWindows()"
      },
      "session_id": "codestral_fc8d_tpusg_batch",
      "metadata": {
        "num_run": 24
      },
      "tags": [
        "benchmark",
        "codestral:latest",
        "tpu_sketch_generator"
      ],
      "latency": 144.86,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-14-37-36-826682_chatcmpl-303d2df2-0c00-4a02-b2d9-9d12cb2c595b",
          "traceId": "8ff8fa4e",
          "type": "GENERATION",
          "name": "8ff8_tpusg_gen_attempt#1",
          "startTime": "2025-08-20T11:37:36.826000+00:00",
          "endTime": "2025-08-20T11:38:05.797000+00:00",
          "model": "codestral:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 28971.0,
          "environment": "default",
          "promptTokens": 2048,
          "costDetails": {},
          "totalTokens": 3121,
          "completionTokens": 1073,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-14-38-13-414814_chatcmpl-a11333be-7696-4e64-89ad-e141b58599ba",
          "traceId": "8ff8fa4e",
          "type": "GENERATION",
          "name": "8ff8_tpusg_gen_attempt#2",
          "startTime": "2025-08-20T11:38:13.414000+00:00",
          "endTime": "2025-08-20T11:38:43.359000+00:00",
          "model": "codestral:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 29945.0,
          "environment": "default",
          "promptTokens": 2048,
          "costDetails": {},
          "totalTokens": 3163,
          "completionTokens": 1115,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-14-38-50-985988_chatcmpl-6750d844-09ab-46c6-af92-2c01f71c9548",
          "traceId": "8ff8fa4e",
          "type": "GENERATION",
          "name": "8ff8_tpusg_gen_attempt#3",
          "startTime": "2025-08-20T11:38:50.985000+00:00",
          "endTime": "2025-08-20T11:39:20.318000+00:00",
          "model": "codestral:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 29333.0,
          "environment": "default",
          "promptTokens": 2048,
          "costDetails": {},
          "totalTokens": 3139,
          "completionTokens": 1091,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-14-39-27-891074_chatcmpl-65b745cf-7790-4cbb-9b1c-ec3b939688b2",
          "traceId": "8ff8fa4e",
          "type": "GENERATION",
          "name": "8ff8_tpusg_gen_attempt#4",
          "startTime": "2025-08-20T11:39:27.891000+00:00",
          "endTime": "2025-08-20T11:40:01.686000+00:00",
          "model": "codestral:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 33795.0,
          "environment": "default",
          "promptTokens": 2048,
          "costDetails": {},
          "totalTokens": 3318,
          "completionTokens": 1270,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        }
      ],
      "environment": "default",
      "createdAt": "2025-08-20T11:37:37.376Z",
      "updatedAt": "2025-08-20T11:40:59.689Z"
    },
    {
      "id": "389a7fce",
      "timestamp": "2025-08-20T11:34:33.231000+00:00",
      "name": "389a_tpu_sketch_generator",
      "input": null,
      "output": {
        "status": "failed",
        "last_code": "import cv2\nimport numpy as np\nfrom tflite_runtime.interpreter import Interpreter\n\n# Load TFLite model and allocate tensors\nmodel_path  = \"/home/mendel/tinyml_autopilot/models/edgetpu_detect.tflite\"\ninterpreter = Interpreter(model_path)\ninterpreter.allocate_tensors()\n\n# Get model details\ninput_details  = \"/home/mendel/tinyml_autopilot/data//sheeps.mp4\"\noutput_details  = \"/home/mendel/tinyml_autopilot/results/sheeps_detections.mp4\"\nheight = input_details[0]['shape'][1]\nwidth = input_details[0]['shape'][2]\nfloating_model = (input_details[0]['dtype'] == np.float32)\n\n# Input acquisition and preprocessing loop\ninput_path = \"/home/mendel/tinyml_autopilot/data/sheeps.mp4\"  # Replace with the actual input video path\noutput_path = \"/home/mendel/tinyml_autopilot/results/sheeps_detections.mp4\"  # Replace with the desired output video path\nconfidence_threshold  = 0.5\n\nlabels = [\"sheep\"]  # Replace with your actual labels if needed\n\ncap = cv2.VideoCapture(input_path)\nfourcc = cv2.VideoWriter_fourcc(*'XVID')\nout = cv2.VideoWriter(output_path, fourcc, 30.0, (width, height))\n\nwhile cap.isOpened():\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    # Preprocess data\n    resized_frame = cv2.resize(frame, (width, height))\n    input_data = np.expand_dims(resized_frame, axis=0)\n\n    if floating_model:\n        input_data = (np.float32(input_data) - 127.5) / 127.5\n\n    # Inference\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n    interpreter.invoke()\n\n    # Output interpretation and handling\n    boxes = interpreter.get_tensor(output_details[0]['index'])[0]\n    classes = interpreter.get_tensor(output_details[1]['index'])[0]\n    scores = interpreter.get_tensor(output_details[2]['index'])[0]\n\n    for i in range(len(scores)):\n        if ((scores[i] > confidence_threshold) and (scores[i] <= 1.0)):\n            ymin = int(max(1, (boxes[i][0] * height)))\n            xmin = int(max(1, (boxes[i][1] * width)))\n            ymax = int(min(height, (boxes[i][2] * height)))\n            xmax = int(min(width, (boxes[i][3] * width)))\n\n            cv2.rectangle(frame, (xmin, ymin), (xmax, ymax), (10, 255, 0), 4)\n            object_name = labels[int(classes[i])]\n            label = '%s: %d%%' % (object_name, int(scores[i]*100))\n            labelSize, baseLine = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.7, 2)\n            label_ymin = max(ymin, labelSize[1] + 10)\n            cv2.rectangle(frame, (xmin, label_ymin-labelSize[1]-10), (xmin+labelSize[0], label_ymin+baseLine-10), (255, 255, 255), cv2.FILLED)\n            cv2.putText(frame, label, (xmin, label_ymin-7), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (10, 255, 0), 2)\n\n    out.write(frame)\n\ncap.release()\nout.release()\ncv2.destroyAllWindows()",
        "last_error": "Max retries reached with error. Last error: Traceback (most recent call last):\n  File \"script_188f3c6d_1755689843.py\", line 13, in <module>\n    height = input_details[0]['shape'][1]\nTypeError: string indices must be integers."
      },
      "session_id": "codestral_fc8d_tpusg_batch",
      "metadata": {
        "num_run": 23
      },
      "tags": [
        "benchmark",
        "codestral:latest",
        "tpu_sketch_generator"
      ],
      "latency": 177.973,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-14-34-33-232624_chatcmpl-574ca1c5-6611-4385-bce8-9225029c7802",
          "traceId": "389a7fce",
          "type": "GENERATION",
          "name": "389a_tpusg_gen_attempt#1",
          "startTime": "2025-08-20T11:34:33.232000+00:00",
          "endTime": "2025-08-20T11:35:00.423000+00:00",
          "model": "codestral:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 27191.0,
          "environment": "default",
          "promptTokens": 2048,
          "costDetails": {},
          "totalTokens": 3043,
          "completionTokens": 995,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-14-35-08-028606_chatcmpl-14c74997-2134-4dab-874d-773761f52dbc",
          "traceId": "389a7fce",
          "type": "GENERATION",
          "name": "389a_tpusg_gen_attempt#2",
          "startTime": "2025-08-20T11:35:08.028000+00:00",
          "endTime": "2025-08-20T11:35:35.499000+00:00",
          "model": "codestral:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 27471.0,
          "environment": "default",
          "promptTokens": 2048,
          "costDetails": {},
          "totalTokens": 3061,
          "completionTokens": 1013,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-14-35-42-983024_chatcmpl-2d74dec0-2cf5-4fc0-97d6-911190d62261",
          "traceId": "389a7fce",
          "type": "GENERATION",
          "name": "389a_tpusg_gen_attempt#3",
          "startTime": "2025-08-20T11:35:42.983000+00:00",
          "endTime": "2025-08-20T11:36:13.292000+00:00",
          "model": "codestral:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 30309.0,
          "environment": "default",
          "promptTokens": 2048,
          "costDetails": {},
          "totalTokens": 3177,
          "completionTokens": 1129,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-14-36-20-855889_chatcmpl-3b6d7cdc-7a3a-4794-8621-29f7ffc64a25",
          "traceId": "389a7fce",
          "type": "GENERATION",
          "name": "389a_tpusg_gen_attempt#4",
          "startTime": "2025-08-20T11:36:20.855000+00:00",
          "endTime": "2025-08-20T11:36:50.238000+00:00",
          "model": "codestral:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 29383.0,
          "environment": "default",
          "promptTokens": 2048,
          "costDetails": {},
          "totalTokens": 3139,
          "completionTokens": 1091,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-14-36-54-025075_chatcmpl-d33a94b8-d083-4e71-8a45-c1eb9716ae6e",
          "traceId": "389a7fce",
          "type": "GENERATION",
          "name": "389a_tpusg_gen_attempt#5",
          "startTime": "2025-08-20T11:36:54.025000+00:00",
          "endTime": "2025-08-20T11:37:23.649000+00:00",
          "model": "codestral:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 29624.0,
          "environment": "default",
          "promptTokens": 2048,
          "costDetails": {},
          "totalTokens": 3148,
          "completionTokens": 1100,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "57175519-3e10-4e56-991b-dcf47f022a6b",
          "traceId": "389a7fce",
          "type": "SPAN",
          "name": "error_38_tpusg_failure_signal_tpu_sketch_generator",
          "startTime": "2025-08-20T11:37:31.205000+00:00",
          "level": "ERROR",
          "statusMessage": "Failed: Max retries reached with error. Last error: Traceback (most recent call last):\n  File \"script_188f3c6d_1755689843.py\", line 13, in <module>\n    height = input_details[0]['shape'][1]\nTypeError: string indices must be integers.",
          "calculatedTotalCost": 0.0,
          "environment": "default",
          "promptTokens": 0,
          "costDetails": {},
          "totalTokens": 0,
          "completionTokens": 0,
          "endTime": null,
          "model": null,
          "modelParameters": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null,
          "latency": null
        }
      ],
      "environment": "default",
      "createdAt": "2025-08-20T11:34:33.756Z",
      "updatedAt": "2025-08-20T11:37:36.465Z"
    },
    {
      "id": "a163574b",
      "timestamp": "2025-08-20T11:33:19.222000+00:00",
      "name": "a163_tpu_sketch_generator",
      "input": null,
      "output": {
        "status": "failed",
        "last_code": "import cv2\nimport numpy as np\nfrom tensorflow.lite import Interpreter\nfrom tensorflow.lite.experimental import load_delegate\n\n# Define paths and parameters\nmodel_path  = \"/home/mendel/tinyml_autopilot/models/edgetpu_detect.tflite\"\ninput_path  = \"/home/mendel/tinyml_autopilot/data//sheeps.mp4\"\nlabel_path  = \"/home/mendel/tinyml_autopilot/models/labelmap.txt\"\noutput_path  = \"/home/mendel/tinyml_autopilot/results/sheeps_detections.mp4\"\nconfidence_threshold  = 0.5\n\n# Load labels\nwith open(label_path, 'r') as f:\n    labels = [line.strip() for line in f.readlines()]\n\n# Load interpreter with EdgeTPU\ntry:\n    interpreter = Interpreter(model_path=model_path, experimental_delegates=[load_delegate('libedgetpu.so.1.0')])\nexcept:\n    interpreter = Interpreter(model_path=model_path, experimental_delegates=[load_delegate('/usr/lib/aarch64-linux-gnu/libedgetpu.so.1.0')])\ninterpreter.allocate_tensors()\n\n# Get model details\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\nheight = input_details[0]['shape'][1]\nwidth = input_details[0]['shape'][2]\nfloating_model = (input_details[0]['dtype'] == np.float32)\n\n# Input acquisition and preprocessing loop\ncap = cv2.VideoCapture(input_path)\nwhile cap.isOpened():\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    # Preprocess data\n    resized_frame = cv2.resize(frame, (width, height))\n    input_data = np.expand_dims(resized_frame, axis=0)\n    if floating_model:\n        input_data = (np.float32(input_data) - 127.5) / 127.5\n\n    # Inference\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n    interpreter.invoke()\n\n    # Output interpretation and handling loop\n    boxes = interpreter.get_tensor(output_details[0]['index'])[0]\n    classes = interpreter.get_tensor(output_details[1]['index'])[0]\n    scores = interpreter.get_tensor(output_details[2]['index'])[0]\n\n    # Interpret results and post-processing\n    for i in range(len(scores)):\n        if ((scores[i] > confidence_threshold) and (scores[i] <= 1.0)):\n            ymin = int(max(1, (boxes[i][0] * frame.shape[0])))\n            xmin = int(max(1, (boxes[i][1] * frame.shape[1])))\n            ymax = int(min(frame.shape[0], (boxes[i][2] * frame.shape[0])))\n            xmax = int(min(frame.shape[1], (boxes[i][3] * frame.shape[1])))\n\n            cv2.rectangle(frame, (xmin, ymin), (xmax, ymax), (10, 255, 0), 4)\n            object_name = labels[int(classes[i])]\n            label = '%s: %d%%' % (object_name, int(scores[i]*100))\n            labelSize, baseLine = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.7, 2)\n            label_ymin = max(ymin, labelSize[1] + 10)\n            cv2.rectangle(frame, (xmin, label_ymin-labelSize[1]-10), (xmin+labelSize[0], label_ymin+baseLine-10), (255, 255, 255), cv2.FILLED)\n            cv2.putText(frame, label, (xmin, label_ymin-7), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 0), 2)\n\n    # Handle output\n    cv2.imshow('Object Detection', frame)\n    if cv2.waitKey(1) & 0xFF == ord('q'):\n        break\n\n# Clean up\ncap.release()\ncv2.destroyAllWindows()",
        "last_error": "Max retries reached with exception: Unexpected error during generation: The output is not a valid code block. Follow the instructions in the prompt return a complete, correct Python script enclosed in a single ```python\n<generated_code>\n``` block.."
      },
      "session_id": "codestral_fc8d_tpusg_batch",
      "metadata": {
        "num_run": 22
      },
      "tags": [
        "benchmark",
        "codestral:latest",
        "tpu_sketch_generator"
      ],
      "latency": 67.271,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-14-33-19-223960_chatcmpl-87aa2fe6-3dd1-475d-bf5b-31e8fe13d8b8",
          "traceId": "a163574b",
          "type": "GENERATION",
          "name": "a163_tpusg_gen_attempt#1",
          "startTime": "2025-08-20T11:33:19.223000+00:00",
          "endTime": "2025-08-20T11:33:48.161000+00:00",
          "model": "codestral:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 28938.0,
          "environment": "default",
          "promptTokens": 2048,
          "costDetails": {},
          "totalTokens": 3121,
          "completionTokens": 1073,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-14-33-55-743779_chatcmpl-97e45c8e-0dc5-40b3-bd34-90381531da4d",
          "traceId": "a163574b",
          "type": "GENERATION",
          "name": "a163_tpusg_gen_attempt#2",
          "startTime": "2025-08-20T11:33:55.743000+00:00",
          "endTime": "2025-08-20T11:34:02.602000+00:00",
          "model": "codestral:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 6859.0,
          "environment": "default",
          "promptTokens": 2048,
          "costDetails": {},
          "totalTokens": 2227,
          "completionTokens": 179,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-14-34-02-609898_chatcmpl-d8bf4ca3-e019-4652-bac8-1b38c13a6a8c",
          "traceId": "a163574b",
          "type": "GENERATION",
          "name": "a163_tpusg_gen_attempt#3",
          "startTime": "2025-08-20T11:34:02.609000+00:00",
          "endTime": "2025-08-20T11:34:13.887000+00:00",
          "model": "codestral:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 11278.0,
          "environment": "default",
          "promptTokens": 2048,
          "costDetails": {},
          "totalTokens": 2408,
          "completionTokens": 360,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-14-34-13-891761_chatcmpl-8000d9cd-5ba0-494d-aaa9-256a1604914c",
          "traceId": "a163574b",
          "type": "GENERATION",
          "name": "a163_tpusg_gen_attempt#4",
          "startTime": "2025-08-20T11:34:13.891000+00:00",
          "endTime": "2025-08-20T11:34:20.654000+00:00",
          "model": "codestral:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 6763.0,
          "environment": "default",
          "promptTokens": 2048,
          "costDetails": {},
          "totalTokens": 2230,
          "completionTokens": 182,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-14-34-20-656870_chatcmpl-83b93216-bcb5-4b8f-aac3-65e3be5db44f",
          "traceId": "a163574b",
          "type": "GENERATION",
          "name": "a163_tpusg_gen_attempt#5",
          "startTime": "2025-08-20T11:34:20.656000+00:00",
          "endTime": "2025-08-20T11:34:26.492000+00:00",
          "model": "codestral:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 5836.0,
          "environment": "default",
          "promptTokens": 2048,
          "costDetails": {},
          "totalTokens": 2193,
          "completionTokens": 145,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "c3207b3b-d60d-4da1-811d-bfa9b01782b7",
          "traceId": "a163574b",
          "type": "SPAN",
          "name": "error_a1_tpusg_failure_signal_tpu_sketch_generator",
          "startTime": "2025-08-20T11:34:26.494000+00:00",
          "level": "ERROR",
          "statusMessage": "Failed: Max retries reached with exception: Unexpected error during generation: The output is not a valid code block. Follow the instructions in the prompt return a complete, correct Python script enclosed in a single ```python\n<generated_code>\n``` block..",
          "calculatedTotalCost": 0.0,
          "environment": "default",
          "promptTokens": 0,
          "costDetails": {},
          "totalTokens": 0,
          "completionTokens": 0,
          "endTime": null,
          "model": null,
          "modelParameters": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null,
          "latency": null
        }
      ],
      "environment": "default",
      "createdAt": "2025-08-20T11:33:19.741Z",
      "updatedAt": "2025-08-20T11:34:31.895Z"
    },
    {
      "id": "ae70645d",
      "timestamp": "2025-08-20T11:32:03.641000+00:00",
      "name": "ae70_tpu_sketch_generator",
      "input": null,
      "output": {
        "status": "failed",
        "last_code": "import cv2\nimport numpy as np\nfrom tensorflow.lite import Interpreter\nfrom tensorflow.lite.experimental import load_delegate\n\n# Define paths and parameters\nmodel_path  = \"/home/mendel/tinyml_autopilot/models/edgetpu_detect.tflite\"\ninput_path  = \"/home/mendel/tinyml_autopilot/data//sheeps.mp4\"\nlabel_path  = \"/home/mendel/tinyml_autopilot/models/labelmap.txt\"\noutput_path  = \"/home/mendel/tinyml_autopilot/results/sheeps_detections.mp4\"\nconfidence_threshold  = 0.5\n\n# Load labels\nwith open(label_path, 'r') as f:\n    labels = [line.strip() for line in f.readlines()]\n\n# Load interpreter with EdgeTPU\ntry:\n    interpreter = Interpreter(model_path=model_path, experimental_delegates=[load_delegate('libedgetpu.so.1.0')])\nexcept:\n    interpreter = Interpreter(model_path=model_path, experimental_delegates=[load_delegate('/usr/lib/aarch64-linux-gnu/libedgetpu.so.1.0')])\ninterpreter.allocate_tensors()\n\n# Get model details\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\nheight = input_details[0]['shape'][1]\nwidth = input_details[0]['shape'][2]\nfloating_model = (input_details[0]['dtype'] == np.float32)\n\n# Input acquisition and preprocessing loop\ncap = cv2.VideoCapture(input_path)\nwhile cap.isOpened():\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    # Preprocess data\n    resized_frame = cv2.resize(frame, (width, height))\n    input_data = np.expand_dims(resized_frame, axis=0)\n    if floating_model:\n        input_data = (np.float32(input_data) - 127.5) / 127.5\n\n    # Inference\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n    interpreter.invoke()\n\n    # Output interpretation and handling loop\n    boxes = interpreter.get_tensor(output_details[0]['index'])[0]\n    classes = interpreter.get_tensor(output_details[1]['index'])[0]\n    scores = interpreter.get_tensor(output_details[2]['index'])[0]\n\n    # Interpret results and post-processing\n    for i in range(len(scores)):\n        if ((scores[i] > confidence_threshold) and (scores[i] <= 1.0)):\n            ymin = int(max(1, (boxes[i][0] * frame.shape[0])))\n            xmin = int(max(1, (boxes[i][1] * frame.shape[1])))\n            ymax = int(min(frame.shape[0], (boxes[i][2] * frame.shape[0])))\n            xmax = int(min(frame.shape[1], (boxes[i][3] * frame.shape[1])))\n\n            cv2.rectangle(frame, (xmin, ymin), (xmax, ymax), (10, 255, 0), 4)\n            object_name = labels[int(classes[i])]\n            label = '%s: %d%%' % (object_name, int(scores[i]*100))\n            labelSize, baseLine = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.7, 2)\n            label_ymin = max(ymin, labelSize[1] + 10)\n            cv2.rectangle(frame, (xmin, label_ymin-labelSize[1]-10), (xmin+labelSize[0], label_ymin+baseLine-10), (255, 255, 255), cv2.FILLED)\n            cv2.putText(frame, label, (xmin, label_ymin-7), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 0), 2)\n\n    # Handle output\n    cv2.imshow('Object Detection', frame)\n    if cv2.waitKey(1) & 0xFF == ord('q'):\n        break\n\n# Clean up\ncap.release()\ncv2.destroyAllWindows()",
        "last_error": "Max retries reached with exception: Unexpected error during generation: The output is not a valid code block. Follow the instructions in the prompt return a complete, correct Python script enclosed in a single ```python\n<generated_code>\n``` block.."
      },
      "session_id": "codestral_fc8d_tpusg_batch",
      "metadata": {
        "num_run": 21
      },
      "tags": [
        "benchmark",
        "codestral:latest",
        "tpu_sketch_generator"
      ],
      "latency": 69.244,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-14-32-03-642726_chatcmpl-ab49f370-5f69-4977-97dc-673ed096dca0",
          "traceId": "ae70645d",
          "type": "GENERATION",
          "name": "ae70_tpusg_gen_attempt#1",
          "startTime": "2025-08-20T11:32:03.642000+00:00",
          "endTime": "2025-08-20T11:32:32.582000+00:00",
          "model": "codestral:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 28940.0,
          "environment": "default",
          "promptTokens": 2048,
          "costDetails": {},
          "totalTokens": 3121,
          "completionTokens": 1073,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-14-32-40-142655_chatcmpl-d215ab9c-de12-4f35-b586-f040f8a4777f",
          "traceId": "ae70645d",
          "type": "GENERATION",
          "name": "ae70_tpusg_gen_attempt#2",
          "startTime": "2025-08-20T11:32:40.142000+00:00",
          "endTime": "2025-08-20T11:32:47.068000+00:00",
          "model": "codestral:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 6926.0,
          "environment": "default",
          "promptTokens": 2048,
          "costDetails": {},
          "totalTokens": 2236,
          "completionTokens": 188,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-14-32-47-071762_chatcmpl-b8b418a7-a46b-44c1-a8f2-34270277b600",
          "traceId": "ae70645d",
          "type": "GENERATION",
          "name": "ae70_tpusg_gen_attempt#3",
          "startTime": "2025-08-20T11:32:47.071000+00:00",
          "endTime": "2025-08-20T11:32:58.315000+00:00",
          "model": "codestral:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 11244.0,
          "environment": "default",
          "promptTokens": 2048,
          "costDetails": {},
          "totalTokens": 2404,
          "completionTokens": 356,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-14-32-58-317987_chatcmpl-706fba63-af17-4c59-82a0-b0362306d1f7",
          "traceId": "ae70645d",
          "type": "GENERATION",
          "name": "ae70_tpusg_gen_attempt#4",
          "startTime": "2025-08-20T11:32:58.317000+00:00",
          "endTime": "2025-08-20T11:33:07.035000+00:00",
          "model": "codestral:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 8718.0,
          "environment": "default",
          "promptTokens": 2048,
          "costDetails": {},
          "totalTokens": 2303,
          "completionTokens": 255,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-14-33-07-038480_chatcmpl-e770a93b-40bb-4ed5-a7e1-3af6db1680c8",
          "traceId": "ae70645d",
          "type": "GENERATION",
          "name": "ae70_tpusg_gen_attempt#5",
          "startTime": "2025-08-20T11:33:07.038000+00:00",
          "endTime": "2025-08-20T11:33:12.884000+00:00",
          "model": "codestral:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 5846.0,
          "environment": "default",
          "promptTokens": 2048,
          "costDetails": {},
          "totalTokens": 2193,
          "completionTokens": 145,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "89eab65d-0a4b-4c96-8ac8-0aae2fe4cfc4",
          "traceId": "ae70645d",
          "type": "SPAN",
          "name": "error_ae_tpusg_failure_signal_tpu_sketch_generator",
          "startTime": "2025-08-20T11:33:12.886000+00:00",
          "level": "ERROR",
          "statusMessage": "Failed: Max retries reached with exception: Unexpected error during generation: The output is not a valid code block. Follow the instructions in the prompt return a complete, correct Python script enclosed in a single ```python\n<generated_code>\n``` block..",
          "calculatedTotalCost": 0.0,
          "environment": "default",
          "promptTokens": 0,
          "costDetails": {},
          "totalTokens": 0,
          "completionTokens": 0,
          "endTime": null,
          "model": null,
          "modelParameters": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null,
          "latency": null
        }
      ],
      "environment": "default",
      "createdAt": "2025-08-20T11:32:04.159Z",
      "updatedAt": "2025-08-20T11:33:18.330Z"
    },
    {
      "id": "999a2c48",
      "timestamp": "2025-08-20T11:29:20.067000+00:00",
      "name": "999a_tpu_sketch_generator",
      "input": null,
      "output": {
        "status": "failed",
        "last_code": "label_path = \"<path_to_your_label_file>\"\nmodel_path = \"<path_to_your_model_file>\"\ninput_path = \"<path_to_your_input_video_file>\"",
        "last_error": "Max retries reached with exception: Unexpected error during generation: Generated script is not complete. Please ensure to generate a complete Python script.."
      },
      "session_id": "codestral_fc8d_tpusg_batch",
      "metadata": {
        "num_run": 20
      },
      "tags": [
        "benchmark",
        "codestral:latest",
        "tpu_sketch_generator"
      ],
      "latency": 156.6,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-14-29-20-070009_chatcmpl-86377ac5-d1bc-4d4d-bccb-ea521e88f8bf",
          "traceId": "999a2c48",
          "type": "GENERATION",
          "name": "999a_tpusg_gen_attempt#1",
          "startTime": "2025-08-20T11:29:20.070000+00:00",
          "endTime": "2025-08-20T11:29:49.025000+00:00",
          "model": "codestral:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 28955.0,
          "environment": "default",
          "promptTokens": 2048,
          "costDetails": {},
          "totalTokens": 3121,
          "completionTokens": 1073,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-14-29-56-614031_chatcmpl-0bb7e166-00d1-41c5-b31b-95905a20dc38",
          "traceId": "999a2c48",
          "type": "GENERATION",
          "name": "999a_tpusg_gen_attempt#2",
          "startTime": "2025-08-20T11:29:56.614000+00:00",
          "endTime": "2025-08-20T11:30:25.515000+00:00",
          "model": "codestral:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 28901.0,
          "environment": "default",
          "promptTokens": 2048,
          "costDetails": {},
          "totalTokens": 3122,
          "completionTokens": 1074,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-14-30-32-970850_chatcmpl-f0e68aab-a3a0-4c02-95ad-4970b5a840b6",
          "traceId": "999a2c48",
          "type": "GENERATION",
          "name": "999a_tpusg_gen_attempt#3",
          "startTime": "2025-08-20T11:30:32.970000+00:00",
          "endTime": "2025-08-20T11:31:03.358000+00:00",
          "model": "codestral:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 30388.0,
          "environment": "default",
          "promptTokens": 2048,
          "costDetails": {},
          "totalTokens": 3181,
          "completionTokens": 1133,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-14-31-11-048826_chatcmpl-4497d670-fc4a-429a-b6a7-fa93802dc234",
          "traceId": "999a2c48",
          "type": "GENERATION",
          "name": "999a_tpusg_gen_attempt#4",
          "startTime": "2025-08-20T11:31:11.048000+00:00",
          "endTime": "2025-08-20T11:31:40.123000+00:00",
          "model": "codestral:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 29075.0,
          "environment": "default",
          "promptTokens": 2048,
          "costDetails": {},
          "totalTokens": 3129,
          "completionTokens": 1081,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-14-31-47-832236_chatcmpl-0fe7c194-a80e-4e0c-bd9e-41785ebab028",
          "traceId": "999a2c48",
          "type": "GENERATION",
          "name": "999a_tpusg_gen_attempt#5",
          "startTime": "2025-08-20T11:31:47.832000+00:00",
          "endTime": "2025-08-20T11:31:56.668000+00:00",
          "model": "codestral:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 8836.0,
          "environment": "default",
          "promptTokens": 2048,
          "costDetails": {},
          "totalTokens": 2313,
          "completionTokens": 265,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "c7393e82-a74e-4748-bfad-a243828d47c7",
          "traceId": "999a2c48",
          "type": "SPAN",
          "name": "error_99_tpusg_failure_signal_tpu_sketch_generator",
          "startTime": "2025-08-20T11:31:56.670000+00:00",
          "level": "ERROR",
          "statusMessage": "Failed: Max retries reached with exception: Unexpected error during generation: Generated script is not complete. Please ensure to generate a complete Python script..",
          "calculatedTotalCost": 0.0,
          "environment": "default",
          "promptTokens": 0,
          "costDetails": {},
          "totalTokens": 0,
          "completionTokens": 0,
          "endTime": null,
          "model": null,
          "modelParameters": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null,
          "latency": null
        }
      ],
      "environment": "default",
      "createdAt": "2025-08-20T11:29:20.584Z",
      "updatedAt": "2025-08-20T11:32:02.559Z"
    },
    {
      "id": "04e5de12",
      "timestamp": "2025-08-20T11:27:45.456000+00:00",
      "name": "04e5_tpu_sketch_generator",
      "input": null,
      "output": {
        "status": "failed",
        "last_code": "import cv2\nimport numpy as np\nfrom PIL import Image\nfrom tflite_runtime.interpreter import Interpreter, load_delegate\n\n# Phase 1: Load Interpreter with EdgeTPU\nmodel_path = 'your_model_path' # replace with your model path\ntry:\n    interpreter = Interpreter(model_path=model_path, experimental_delegates=[load_delegate('libedgetpu.so.1')])\nexcept ValueError:\n    interpreter = Interpreter(model_path=model_path, experimental_delegates=[load_delegate('/usr/lib/aarch64-linux-gnu/libedgetpu.so.1')])\ninterpreter.allocate_tensors()\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\n\n# Load labels (assuming a label file with one class name per line)\nlabels_path = 'your_label_file_path' # replace with your label file path\nwith open(labels_path, 'r') as f:\n    labels = [line.strip() for line in f.readlines()]\n\n# Phase 2: Input Acquisition & Preprocessing Loop (Reading a single image)\nimage_path = 'your_image_path' # replace with your image path\nimage = Image.open(image_path).resize((input_details[0]['shape'][1], input_details[0]['shape'][2]))\ninput_data = np.expand_dims(np.array(image), axis=0)\nfloating_model = (input_details[0]['dtype'] == np.float32)\nif floating_model:\n    input_data = (np.float32(input_data) - 127.5) / 127.5\n\n# Phase 3: Inference\ninterpreter.set_tensor(input_details[0]['index'], input_data)\ninterpreter.invoke()\n\n# Phase 4: Output Interpretation & Handling (Assuming a classification model)\noutput_data = interpreter.get_tensor(output_details[0]['index'])\nprediction = np.squeeze(output_data).argmax()\nprint('Predicted class:', labels[prediction])",
        "last_error": "Max retries reached with exception: Unexpected error during generation: The output is not a valid code block. Follow the instructions in the prompt return a complete, correct Python script enclosed in a single ```python\n<generated_code>\n``` block.."
      },
      "session_id": "codestral_fc8d_tpusg_batch",
      "metadata": {
        "num_run": 19
      },
      "tags": [
        "benchmark",
        "codestral:latest",
        "tpu_sketch_generator"
      ],
      "latency": 87.315,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-14-27-45-457396_chatcmpl-bd363546-6b1c-466b-906f-f9de7ad9432f",
          "traceId": "04e5de12",
          "type": "GENERATION",
          "name": "04e5_tpusg_gen_attempt#1",
          "startTime": "2025-08-20T11:27:45.457000+00:00",
          "endTime": "2025-08-20T11:28:14.429000+00:00",
          "model": "codestral:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 28972.0,
          "environment": "default",
          "promptTokens": 2048,
          "costDetails": {},
          "totalTokens": 3121,
          "completionTokens": 1073,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-14-28-21-990615_chatcmpl-5097d7c6-42aa-4577-bb3c-d10d232a7afb",
          "traceId": "04e5de12",
          "type": "GENERATION",
          "name": "04e5_tpusg_gen_attempt#2",
          "startTime": "2025-08-20T11:28:21.990000+00:00",
          "endTime": "2025-08-20T11:28:27.601000+00:00",
          "model": "codestral:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 5611.0,
          "environment": "default",
          "promptTokens": 2048,
          "costDetails": {},
          "totalTokens": 2184,
          "completionTokens": 136,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-14-28-27-620433_chatcmpl-e599ea6b-2dd8-49e3-9652-1f1ec3f30c0f",
          "traceId": "04e5de12",
          "type": "GENERATION",
          "name": "04e5_tpusg_gen_attempt#3",
          "startTime": "2025-08-20T11:28:27.620000+00:00",
          "endTime": "2025-08-20T11:28:46.162000+00:00",
          "model": "codestral:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 18542.0,
          "environment": "default",
          "promptTokens": 2048,
          "costDetails": {},
          "totalTokens": 2704,
          "completionTokens": 656,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-14-28-46-165183_chatcmpl-e5962fa7-8fcb-4eca-a5d2-f6f4a7e81d55",
          "traceId": "04e5de12",
          "type": "GENERATION",
          "name": "04e5_tpusg_gen_attempt#4",
          "startTime": "2025-08-20T11:28:46.165000+00:00",
          "endTime": "2025-08-20T11:29:03.897000+00:00",
          "model": "codestral:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 17732.0,
          "environment": "default",
          "promptTokens": 2048,
          "costDetails": {},
          "totalTokens": 2672,
          "completionTokens": 624,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-14-29-03-900592_chatcmpl-50415662-4eb5-4f40-8070-9ae57e767b1b",
          "traceId": "04e5de12",
          "type": "GENERATION",
          "name": "04e5_tpusg_gen_attempt#5",
          "startTime": "2025-08-20T11:29:03.900000+00:00",
          "endTime": "2025-08-20T11:29:12.770000+00:00",
          "model": "codestral:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 8870.0,
          "environment": "default",
          "promptTokens": 2048,
          "costDetails": {},
          "totalTokens": 2315,
          "completionTokens": 267,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "f7ca5bfd-c84d-4789-aa2c-3a2fc4773f21",
          "traceId": "04e5de12",
          "type": "SPAN",
          "name": "error_04_tpusg_failure_signal_tpu_sketch_generator",
          "startTime": "2025-08-20T11:29:12.772000+00:00",
          "level": "ERROR",
          "statusMessage": "Failed: Max retries reached with exception: Unexpected error during generation: The output is not a valid code block. Follow the instructions in the prompt return a complete, correct Python script enclosed in a single ```python\n<generated_code>\n``` block..",
          "calculatedTotalCost": 0.0,
          "environment": "default",
          "promptTokens": 0,
          "costDetails": {},
          "totalTokens": 0,
          "completionTokens": 0,
          "endTime": null,
          "model": null,
          "modelParameters": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null,
          "latency": null
        }
      ],
      "environment": "default",
      "createdAt": "2025-08-20T11:27:45.976Z",
      "updatedAt": "2025-08-20T11:29:18.884Z"
    },
    {
      "id": "0b566322",
      "timestamp": "2025-08-20T11:26:24.937000+00:00",
      "name": "0b56_tpu_sketch_generator",
      "input": null,
      "output": {
        "status": "failed",
        "last_code": "import cv2\nimport numpy as np\nfrom tensorflow.lite import Interpreter\nfrom tensorflow.lite.experimental import load_delegate\n\n# Define paths and parameters\nmodel_path  = \"/home/mendel/tinyml_autopilot/models/edgetpu_detect.tflite\"\ninput_path  = \"/home/mendel/tinyml_autopilot/data//sheeps.mp4\"\nlabel_path  = \"/home/mendel/tinyml_autopilot/models/labelmap.txt\"\noutput_path  = \"/home/mendel/tinyml_autopilot/results/sheeps_detections.mp4\"\nconfidence_threshold  = 0.5\n\n# Load labels\nwith open(label_path, 'r') as f:\n    labels = [line.strip() for line in f.readlines()]\n\n# Load interpreter with EdgeTPU\ntry:\n    interpreter = Interpreter(model_path=model_path, experimental_delegates=[load_delegate('libedgetpu.so.1.0')])\nexcept:\n    interpreter = Interpreter(model_path=model_path, experimental_delegates=[load_delegate('/usr/lib/aarch64-linux-gnu/libedgetpu.so.1.0')])\ninterpreter.allocate_tensors()\n\n# Get model details\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\nheight = input_details[0]['shape'][1]\nwidth = input_details[0]['shape'][2]\nfloating_model = (input_details[0]['dtype'] == np.float32)\n\n# Input acquisition and preprocessing loop\ncap = cv2.VideoCapture(input_path)\nwhile cap.isOpened():\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    # Preprocess data\n    resized_frame = cv2.resize(frame, (width, height))\n    input_data = np.expand_dims(resized_frame, axis=0)\n    if floating_model:\n        input_data = (np.float32(input_data) - 127.5) / 127.5\n\n    # Inference\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n    interpreter.invoke()\n\n    # Output interpretation and handling loop\n    boxes = interpreter.get_tensor(output_details[0]['index'])[0]\n    classes = interpreter.get_tensor(output_details[1]['index'])[0]\n    scores = interpreter.get_tensor(output_details[2]['index'])[0]\n\n    # Interpret results and post-processing\n    for i in range(len(scores)):\n        if ((scores[i] > confidence_threshold) and (scores[i] <= 1.0)):\n            ymin = int(max(1, (boxes[i][0] * frame.shape[0])))\n            xmin = int(max(1, (boxes[i][1] * frame.shape[1])))\n            ymax = int(min(frame.shape[0], (boxes[i][2] * frame.shape[0])))\n            xmax = int(min(frame.shape[1], (boxes[i][3] * frame.shape[1])))\n\n            cv2.rectangle(frame, (xmin, ymin), (xmax, ymax), (10, 255, 0), 4)\n            object_name = labels[int(classes[i])]\n            label = '%s: %d%%' % (object_name, int(scores[i]*100))\n            labelSize, baseLine = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.7, 2)\n            label_ymin = max(ymin, labelSize[1] + 10)\n            cv2.rectangle(frame, (xmin, label_ymin-labelSize[1]-10), (xmin+labelSize[0], label_ymin+baseLine-10), (255, 255, 255), cv2.FILLED)\n            cv2.putText(frame, label, (xmin, label_ymin-7), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 0), 2)\n\n    # Handle output\n    cv2.imshow('Object Detection', frame)\n    if cv2.waitKey(1) & 0xFF == ord('q'):\n        break\n\n# Clean up\ncap.release()\ncv2.destroyAllWindows()",
        "last_error": "Max retries reached with exception: Unexpected error during generation: The output is not a valid code block. Follow the instructions in the prompt return a complete, correct Python script enclosed in a single ```python\n<generated_code>\n``` block.."
      },
      "session_id": "codestral_fc8d_tpusg_batch",
      "metadata": {
        "num_run": 18
      },
      "tags": [
        "benchmark",
        "codestral:latest",
        "tpu_sketch_generator"
      ],
      "latency": 73.986,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-14-26-24-938787_chatcmpl-26592e71-88f1-4341-9682-5e603422c5b6",
          "traceId": "0b566322",
          "type": "GENERATION",
          "name": "0b56_tpusg_gen_attempt#1",
          "startTime": "2025-08-20T11:26:24.938000+00:00",
          "endTime": "2025-08-20T11:26:53.937000+00:00",
          "model": "codestral:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 28999.0,
          "environment": "default",
          "promptTokens": 2048,
          "costDetails": {},
          "totalTokens": 3121,
          "completionTokens": 1073,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-14-27-01-554117_chatcmpl-660ae8ca-3a3d-4536-91a5-19c4e0cc2cea",
          "traceId": "0b566322",
          "type": "GENERATION",
          "name": "0b56_tpusg_gen_attempt#2",
          "startTime": "2025-08-20T11:27:01.554000+00:00",
          "endTime": "2025-08-20T11:27:10.600000+00:00",
          "model": "codestral:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 9046.0,
          "environment": "default",
          "promptTokens": 2048,
          "costDetails": {},
          "totalTokens": 2317,
          "completionTokens": 269,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-14-27-10-607248_chatcmpl-6fad5981-6b48-42ed-a067-0d1b8ffe335b",
          "traceId": "0b566322",
          "type": "GENERATION",
          "name": "0b56_tpusg_gen_attempt#3",
          "startTime": "2025-08-20T11:27:10.607000+00:00",
          "endTime": "2025-08-20T11:27:21.700000+00:00",
          "model": "codestral:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 11093.0,
          "environment": "default",
          "promptTokens": 2048,
          "costDetails": {},
          "totalTokens": 2404,
          "completionTokens": 356,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-14-27-21-702962_chatcmpl-f69aaa43-01ab-440f-b1fc-b65f3c6105fe",
          "traceId": "0b566322",
          "type": "GENERATION",
          "name": "0b56_tpusg_gen_attempt#4",
          "startTime": "2025-08-20T11:27:21.702000+00:00",
          "endTime": "2025-08-20T11:27:27.842000+00:00",
          "model": "codestral:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 6140.0,
          "environment": "default",
          "promptTokens": 2048,
          "costDetails": {},
          "totalTokens": 2205,
          "completionTokens": 157,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-14-27-27-844300_chatcmpl-7fa0b9ee-6d1c-437f-a51d-b4a276b46c7b",
          "traceId": "0b566322",
          "type": "GENERATION",
          "name": "0b56_tpusg_gen_attempt#5",
          "startTime": "2025-08-20T11:27:27.844000+00:00",
          "endTime": "2025-08-20T11:27:38.922000+00:00",
          "model": "codestral:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 11078.0,
          "environment": "default",
          "promptTokens": 2048,
          "costDetails": {},
          "totalTokens": 2404,
          "completionTokens": 356,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "ddbb4e2b-4595-467e-96d3-ef02185b160e",
          "traceId": "0b566322",
          "type": "SPAN",
          "name": "error_0b_tpusg_failure_signal_tpu_sketch_generator",
          "startTime": "2025-08-20T11:27:38.924000+00:00",
          "level": "ERROR",
          "statusMessage": "Failed: Max retries reached with exception: Unexpected error during generation: The output is not a valid code block. Follow the instructions in the prompt return a complete, correct Python script enclosed in a single ```python\n<generated_code>\n``` block..",
          "calculatedTotalCost": 0.0,
          "environment": "default",
          "promptTokens": 0,
          "costDetails": {},
          "totalTokens": 0,
          "completionTokens": 0,
          "endTime": null,
          "model": null,
          "modelParameters": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null,
          "latency": null
        }
      ],
      "environment": "default",
      "createdAt": "2025-08-20T11:26:25.455Z",
      "updatedAt": "2025-08-20T11:27:44.336Z"
    },
    {
      "id": "09c51868",
      "timestamp": "2025-08-20T11:23:46.403000+00:00",
      "name": "09c5_tpu_sketch_generator",
      "input": null,
      "output": {
        "status": "failed",
        "last_code": "import cv2\nimport numpy as np\nfrom tensorflow.lite.python.interpreter import Interpreter\n\n# Load labels\nwith open('labels.txt', 'r') as f:\n    labels = [line.strip() for line in f.readlines()]\n\n# Load the TensorFlow Lite model into memory\ninterpreter = Interpreter(model_path='detect.tflite')\ninterpreter.allocate_tensors()\ninput_details  = \"/home/mendel/tinyml_autopilot/data//sheeps.mp4\"\noutput_details  = \"/home/mendel/tinyml_autopilot/results/sheeps_detections.mp4\"\nheight = input_details[0]['shape'][1]\nwidth = input_details[0]['shape'][2]\nfloating_model = (input_details[0]['dtype'] == np.float32)\n\n# Open video file and create output video writer\ncap = cv2.VideoCapture('/home/mendel/tinyml_autopilot/data//sheeps.mp4')\nfourcc = cv2.VideoWriter_fourcc(*'XVID')\nout = cv2.VideoWriter('/home/mendel/tinyml_autopilot/results/sheeps_detections.mp4', fourcc, 30.0, (int(cap.get(3)), int(cap.get(4))))\n\n# Loop over video frames and perform object detection\nwhile cap.isOpened():\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    # Preprocess frame for input to model\n    img_height, img_width, channels = frame.shape\n    frame_resized = cv2.resize(frame, (width, height))\n    input_data = np.expand_dims(frame_resized, axis=0)\n    if floating_model:\n        input_data = (np.float32(input_data) - 127.5) / 127.5\n\n    # Perform the actual detection by running the model with the frame as input\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n    interpreter.invoke()\n    boxes = interpreter.get_tensor(output_details[0]['index'])[0] # Bounding box coordinates of detected objects\n    classes = interpreter.get_tensor(output_details[1]['index'])[0] # Class index of detected objects\n    scores = interpreter.get_tensor(output_details[2]['index'])[0] # Confidence of detected objects\n\n    # Loop over all detections and draw detection box if confidence is above a threshold\n    for i in range(len(scores)):\n        if ((scores[i] > 0.5) and (scores[i] <= 1.0)):\n            # Get bounding box coordinates and scale them to the image size\n            ymin, xmin, ymax, xmax = boxes[i]\n            xmin = int(xmin * img_width)\n            xmax = int(xmax * img_width)\n            ymin = int(ymin * img_height)\n            ymax = int(ymax * img_height)\n\n            # Draw bounding box and label on frame\n            cv2.rectangle(frame, (xmin, ymin), (xmax, ymax), (10, 255, 0), 2)\n            object_name = labels[int(classes[i])]\n            label = '%s: %d%%' % (object_name, int(scores[i]*100))\n            cv2.putText(frame, label, (xmin, ymin-5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (10, 255, 0), 2)\n\n    # Write frame to output video file\n    out.write(frame)\n\n# Release resources and close windows\ncap.release()\nout.release()\ncv2.destroyAllWindows()",
        "last_error": "Max retries reached with error. Last error: Traceback (most recent call last):\n  File \"script_a80c76ae_1755689171.py\", line 3, in <module>\n    from tensorflow.lite.python.interpreter import Interpreter\nModuleNotFoundError: No module named 'tensorflow'."
      },
      "session_id": "codestral_fc8d_tpusg_batch",
      "metadata": {
        "num_run": 17
      },
      "tags": [
        "benchmark",
        "codestral:latest",
        "tpu_sketch_generator"
      ],
      "latency": 152.209,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-14-23-46-404673_chatcmpl-317a81ec-0723-4c98-8b36-ddfa025a3ed1",
          "traceId": "09c51868",
          "type": "GENERATION",
          "name": "09c5_tpusg_gen_attempt#1",
          "startTime": "2025-08-20T11:23:46.404000+00:00",
          "endTime": "2025-08-20T11:24:15.376000+00:00",
          "model": "codestral:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 28972.0,
          "environment": "default",
          "promptTokens": 2048,
          "costDetails": {},
          "totalTokens": 3121,
          "completionTokens": 1073,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-14-24-22-867249_chatcmpl-cef2455c-1bd0-4eeb-9475-a25792df374f",
          "traceId": "09c51868",
          "type": "GENERATION",
          "name": "09c5_tpusg_gen_attempt#2",
          "startTime": "2025-08-20T11:24:22.867000+00:00",
          "endTime": "2025-08-20T11:24:29.592000+00:00",
          "model": "codestral:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 6725.0,
          "environment": "default",
          "promptTokens": 2048,
          "costDetails": {},
          "totalTokens": 2229,
          "completionTokens": 181,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-14-24-29-598752_chatcmpl-8e5c6f19-51be-49b1-814b-99214cea77f3",
          "traceId": "09c51868",
          "type": "GENERATION",
          "name": "09c5_tpusg_gen_attempt#3",
          "startTime": "2025-08-20T11:24:29.598000+00:00",
          "endTime": "2025-08-20T11:25:00.546000+00:00",
          "model": "codestral:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 30948.0,
          "environment": "default",
          "promptTokens": 2048,
          "costDetails": {},
          "totalTokens": 3204,
          "completionTokens": 1156,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-14-25-08-007346_chatcmpl-b635d3dd-1ce4-4bd8-b5e0-a36ef600c031",
          "traceId": "09c51868",
          "type": "GENERATION",
          "name": "09c5_tpusg_gen_attempt#4",
          "startTime": "2025-08-20T11:25:08.007000+00:00",
          "endTime": "2025-08-20T11:25:36.823000+00:00",
          "model": "codestral:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 28816.0,
          "environment": "default",
          "promptTokens": 2048,
          "costDetails": {},
          "totalTokens": 3117,
          "completionTokens": 1069,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-14-25-40-610047_chatcmpl-167ee3e3-cdc6-4e1e-8bca-982d8425eb97",
          "traceId": "09c51868",
          "type": "GENERATION",
          "name": "09c5_tpusg_gen_attempt#5",
          "startTime": "2025-08-20T11:25:40.610000+00:00",
          "endTime": "2025-08-20T11:26:11.063000+00:00",
          "model": "codestral:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 30453.0,
          "environment": "default",
          "promptTokens": 2048,
          "costDetails": {},
          "totalTokens": 3184,
          "completionTokens": 1136,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "e9423978-e357-4550-96d8-47d8598242c8",
          "traceId": "09c51868",
          "type": "SPAN",
          "name": "error_09_tpusg_failure_signal_tpu_sketch_generator",
          "startTime": "2025-08-20T11:26:18.613000+00:00",
          "level": "ERROR",
          "statusMessage": "Failed: Max retries reached with error. Last error: Traceback (most recent call last):\n  File \"script_a80c76ae_1755689171.py\", line 3, in <module>\n    from tensorflow.lite.python.interpreter import Interpreter\nModuleNotFoundError: No module named 'tensorflow'.",
          "calculatedTotalCost": 0.0,
          "environment": "default",
          "promptTokens": 0,
          "costDetails": {},
          "totalTokens": 0,
          "completionTokens": 0,
          "endTime": null,
          "model": null,
          "modelParameters": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null,
          "latency": null
        }
      ],
      "environment": "default",
      "createdAt": "2025-08-20T11:23:46.922Z",
      "updatedAt": "2025-08-20T11:26:24.135Z"
    },
    {
      "id": "11595b38",
      "timestamp": "2025-08-20T11:22:28.906000+00:00",
      "name": "1159_tpu_sketch_generator",
      "input": null,
      "output": {
        "status": "failed",
        "last_code": "import cv2\nimport numpy as np\nfrom tensorflow.lite import Interpreter\nfrom tensorflow.lite.experimental import load_delegate\n\n# Define paths and parameters\nmodel_path  = \"/home/mendel/tinyml_autopilot/models/edgetpu_detect.tflite\"\ninput_path  = \"/home/mendel/tinyml_autopilot/data//sheeps.mp4\"\nlabel_path  = \"/home/mendel/tinyml_autopilot/models/labelmap.txt\"\noutput_path  = \"/home/mendel/tinyml_autopilot/results/sheeps_detections.mp4\"\nconfidence_threshold  = 0.5\n\n# Load labels\nwith open(label_path, 'r') as f:\n    labels = [line.strip() for line in f.readlines()]\n\n# Load interpreter with EdgeTPU\ntry:\n    interpreter = Interpreter(model_path=model_path, experimental_delegates=[load_delegate('libedgetpu.so.1.0')])\nexcept:\n    interpreter = Interpreter(model_path=model_path, experimental_delegates=[load_delegate('/usr/lib/aarch64-linux-gnu/libedgetpu.so.1.0')])\ninterpreter.allocate_tensors()\n\n# Get model details\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\nheight = input_details[0]['shape'][1]\nwidth = input_details[0]['shape'][2]\nfloating_model = (input_details[0]['dtype'] == np.float32)\n\n# Input acquisition and preprocessing loop\ncap = cv2.VideoCapture(input_path)\nwhile cap.isOpened():\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    # Preprocess data\n    resized_frame = cv2.resize(frame, (width, height))\n    input_data = np.expand_dims(resized_frame, axis=0)\n    if floating_model:\n        input_data = (np.float32(input_data) - 127.5) / 127.5\n\n    # Inference\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n    interpreter.invoke()\n\n    # Output interpretation and handling loop\n    boxes = interpreter.get_tensor(output_details[0]['index'])[0]\n    classes = interpreter.get_tensor(output_details[1]['index'])[0]\n    scores = interpreter.get_tensor(output_details[2]['index'])[0]\n\n    # Interpret results and post-processing\n    for i in range(len(scores)):\n        if ((scores[i] > confidence_threshold) and (scores[i] <= 1.0)):\n            ymin = int(max(1, (boxes[i][0] * frame.shape[0])))\n            xmin = int(max(1, (boxes[i][1] * frame.shape[1])))\n            ymax = int(min(frame.shape[0], (boxes[i][2] * frame.shape[0])))\n            xmax = int(min(frame.shape[1], (boxes[i][3] * frame.shape[1])))\n\n            cv2.rectangle(frame, (xmin, ymin), (xmax, ymax), (10, 255, 0), 4)\n            object_name = labels[int(classes[i])]\n            label = '%s: %d%%' % (object_name, int(scores[i]*100))\n            labelSize, baseLine = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.7, 2)\n            label_ymin = max(ymin, labelSize[1] + 10)\n            cv2.rectangle(frame, (xmin, label_ymin-labelSize[1]-10), (xmin+labelSize[0], label_ymin+baseLine-10), (255, 255, 255), cv2.FILLED)\n            cv2.putText(frame, label, (xmin, label_ymin-7), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 0), 2)\n\n    # Handle output\n    cv2.imshow('Object Detection', frame)\n    if cv2.waitKey(1) & 0xFF == ord('q'):\n        break\n\n# Clean up\ncap.release()\ncv2.destroyAllWindows()",
        "last_error": "Max retries reached with exception: Unexpected error during generation: The output is not a valid code block. Follow the instructions in the prompt return a complete, correct Python script enclosed in a single ```python\n<generated_code>\n``` block.."
      },
      "session_id": "codestral_fc8d_tpusg_batch",
      "metadata": {
        "num_run": 16
      },
      "tags": [
        "benchmark",
        "codestral:latest",
        "tpu_sketch_generator"
      ],
      "latency": 70.628,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-14-22-28-907756_chatcmpl-e7b4d9e4-77a7-429c-bad1-fc92f4d83e32",
          "traceId": "11595b38",
          "type": "GENERATION",
          "name": "1159_tpusg_gen_attempt#1",
          "startTime": "2025-08-20T11:22:28.907000+00:00",
          "endTime": "2025-08-20T11:22:57.835000+00:00",
          "model": "codestral:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 28928.0,
          "environment": "default",
          "promptTokens": 2048,
          "costDetails": {},
          "totalTokens": 3121,
          "completionTokens": 1073,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-14-23-05-444780_chatcmpl-fd08775b-03b2-466a-a013-eb0d47b3d4d5",
          "traceId": "11595b38",
          "type": "GENERATION",
          "name": "1159_tpusg_gen_attempt#2",
          "startTime": "2025-08-20T11:23:05.444000+00:00",
          "endTime": "2025-08-20T11:23:14.343000+00:00",
          "model": "codestral:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 8899.0,
          "environment": "default",
          "promptTokens": 2048,
          "costDetails": {},
          "totalTokens": 2315,
          "completionTokens": 267,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-14-23-14-348749_chatcmpl-bf3e385e-9a1f-4d69-9694-b5c00402cf84",
          "traceId": "11595b38",
          "type": "GENERATION",
          "name": "1159_tpusg_gen_attempt#3",
          "startTime": "2025-08-20T11:23:14.348000+00:00",
          "endTime": "2025-08-20T11:23:25.525000+00:00",
          "model": "codestral:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 11177.0,
          "environment": "default",
          "promptTokens": 2048,
          "costDetails": {},
          "totalTokens": 2408,
          "completionTokens": 360,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-14-23-25-527858_chatcmpl-e0c88c12-bf67-49ad-bb37-18ace431a834",
          "traceId": "11595b38",
          "type": "GENERATION",
          "name": "1159_tpusg_gen_attempt#4",
          "startTime": "2025-08-20T11:23:25.527000+00:00",
          "endTime": "2025-08-20T11:23:33.697000+00:00",
          "model": "codestral:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 8170.0,
          "environment": "default",
          "promptTokens": 2048,
          "costDetails": {},
          "totalTokens": 2287,
          "completionTokens": 239,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-14-23-33-703328_chatcmpl-937709ac-ecc7-4f1c-b031-2d9ca3276ac3",
          "traceId": "11595b38",
          "type": "GENERATION",
          "name": "1159_tpusg_gen_attempt#5",
          "startTime": "2025-08-20T11:23:33.703000+00:00",
          "endTime": "2025-08-20T11:23:39.534000+00:00",
          "model": "codestral:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 5831.0,
          "environment": "default",
          "promptTokens": 2048,
          "costDetails": {},
          "totalTokens": 2193,
          "completionTokens": 145,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "fed4f141-7091-4aa5-822e-218bfacf2d78",
          "traceId": "11595b38",
          "type": "SPAN",
          "name": "error_11_tpusg_failure_signal_tpu_sketch_generator",
          "startTime": "2025-08-20T11:23:39.535000+00:00",
          "level": "ERROR",
          "statusMessage": "Failed: Max retries reached with exception: Unexpected error during generation: The output is not a valid code block. Follow the instructions in the prompt return a complete, correct Python script enclosed in a single ```python\n<generated_code>\n``` block..",
          "calculatedTotalCost": 0.0,
          "environment": "default",
          "promptTokens": 0,
          "costDetails": {},
          "totalTokens": 0,
          "completionTokens": 0,
          "endTime": null,
          "model": null,
          "modelParameters": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null,
          "latency": null
        }
      ],
      "environment": "default",
      "createdAt": "2025-08-20T11:22:29.424Z",
      "updatedAt": "2025-08-20T11:23:45.261Z"
    },
    {
      "id": "ca4f882c",
      "timestamp": "2025-08-20T11:20:05.319000+00:00",
      "name": "ca4f_tpu_sketch_generator",
      "input": null,
      "output": {
        "status": "failed",
        "last_code": "import cv2\nimport numpy as np\nfrom tflite_runtime.interpreter import Interpreter\n\n# Load the TensorFlow Lite model into memory\ninterpreter = Interpreter(model_path='detect.tflite')\ninterpreter.allocate_tensors()\ninput_details  = interpreter.get_input_details()\noutput_details  = interpreter.get_output_details()\nheight = input_details[0]['shape'][1]\nwidth = input_details[0]['shape'][2]\nfloating_model = (input_details[0]['dtype'] == np.float32)\n\n# Load image and preprocess it\nimage = cv2.imread('test.jpg')\nimg_height, img_width, channels = image.shape\nimage_resized = cv2.resize(image, (width, height))\ninput_data = np.expand_dims(image_resized, axis=0)\nif floating_model:\n    input_data = (np.float32(input_data) - 127.5) / 127.5\n\n# Perform the actual detection by running the model with the image as input\ninterpreter.set_tensor(input_details[0]['index'], input_data)\ninterpreter.invoke()\nboxes = interpreter.get_tensor(output_details[0]['index'])[0] # Bounding box coordinates of detected objects\nclasses = interpreter.get_tensor(output_details[1]['index'])[0] # Class index of detected objects\nscores = interpreter.get_tensor(output_details[2]['index'])[0] # Confidence of detected objects\n\n# Loop over all detections and draw detection box if confidence is above a threshold\nfor i in range(len(scores)):\n    if ((scores[i] > 0.5) and (scores[i] <= 1.0)):\n        # Get bounding box coordinates and scale them to the image size\n        ymin, xmin, ymax, xmax = boxes[i]\n        xmin = int(xmin * img_width)\n        xmax = int(xmax * img_width)\n        ymin = int(ymin * img_height)\n        ymax = int(ymax * img_height)\n\n        # Draw bounding box and label on image\n        cv2.rectangle(image, (xmin, ymin), (xmax, ymax), (10, 255, 0), 2)\n\n# Save image with detections\ncv2.imwrite('output.jpg', image)",
        "last_error": "Max retries reached with exception: Unexpected error during generation: Generated script is not complete. Please ensure to generate a complete Python script.."
      },
      "session_id": "codestral_fc8d_tpusg_batch",
      "metadata": {
        "num_run": 15
      },
      "tags": [
        "benchmark",
        "codestral:latest",
        "tpu_sketch_generator"
      ],
      "latency": 137.387,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-14-20-05-320465_chatcmpl-f3cf6c60-e9c9-447a-9e01-978357ed18cf",
          "traceId": "ca4f882c",
          "type": "GENERATION",
          "name": "ca4f_tpusg_gen_attempt#1",
          "startTime": "2025-08-20T11:20:05.320000+00:00",
          "endTime": "2025-08-20T11:20:34.423000+00:00",
          "model": "codestral:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 29103.0,
          "environment": "default",
          "promptTokens": 2048,
          "costDetails": {},
          "totalTokens": 3121,
          "completionTokens": 1073,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-14-20-41-904005_chatcmpl-f9851703-c863-42b5-b99f-8fbd3dea348e",
          "traceId": "ca4f882c",
          "type": "GENERATION",
          "name": "ca4f_tpusg_gen_attempt#2",
          "startTime": "2025-08-20T11:20:41.904000+00:00",
          "endTime": "2025-08-20T11:20:47.098000+00:00",
          "model": "codestral:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 5194.0,
          "environment": "default",
          "promptTokens": 2048,
          "costDetails": {},
          "totalTokens": 2163,
          "completionTokens": 115,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-14-20-47-101276_chatcmpl-51f57df5-0d72-49ed-aaf7-3bc52df49503",
          "traceId": "ca4f882c",
          "type": "GENERATION",
          "name": "ca4f_tpusg_gen_attempt#3",
          "startTime": "2025-08-20T11:20:47.101000+00:00",
          "endTime": "2025-08-20T11:21:18.090000+00:00",
          "model": "codestral:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 30989.0,
          "environment": "default",
          "promptTokens": 2048,
          "costDetails": {},
          "totalTokens": 3204,
          "completionTokens": 1156,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-14-21-25-560722_chatcmpl-8010d56a-7c16-4944-8c35-4466edd14dff",
          "traceId": "ca4f882c",
          "type": "GENERATION",
          "name": "ca4f_tpusg_gen_attempt#4",
          "startTime": "2025-08-20T11:21:25.560000+00:00",
          "endTime": "2025-08-20T11:21:54.592000+00:00",
          "model": "codestral:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 29032.0,
          "environment": "default",
          "promptTokens": 2048,
          "costDetails": {},
          "totalTokens": 3124,
          "completionTokens": 1076,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-14-22-02-167063_chatcmpl-6b9e7e2f-9560-4417-b900-1980dca5ea55",
          "traceId": "ca4f882c",
          "type": "GENERATION",
          "name": "ca4f_tpusg_gen_attempt#5",
          "startTime": "2025-08-20T11:22:02.167000+00:00",
          "endTime": "2025-08-20T11:22:22.705000+00:00",
          "model": "codestral:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 20538.0,
          "environment": "default",
          "promptTokens": 2048,
          "costDetails": {},
          "totalTokens": 2784,
          "completionTokens": 736,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "808bf183-a65b-48c6-b3a0-d074b3de919f",
          "traceId": "ca4f882c",
          "type": "SPAN",
          "name": "error_ca_tpusg_failure_signal_tpu_sketch_generator",
          "startTime": "2025-08-20T11:22:22.707000+00:00",
          "level": "ERROR",
          "statusMessage": "Failed: Max retries reached with exception: Unexpected error during generation: Generated script is not complete. Please ensure to generate a complete Python script..",
          "calculatedTotalCost": 0.0,
          "environment": "default",
          "promptTokens": 0,
          "costDetails": {},
          "totalTokens": 0,
          "completionTokens": 0,
          "endTime": null,
          "model": null,
          "modelParameters": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null,
          "latency": null
        }
      ],
      "environment": "default",
      "createdAt": "2025-08-20T11:20:05.837Z",
      "updatedAt": "2025-08-20T11:22:27.977Z"
    },
    {
      "id": "be1abeba",
      "timestamp": "2025-08-20T11:18:07.786000+00:00",
      "name": "be1a_tpu_sketch_generator",
      "input": null,
      "output": {
        "status": "failed",
        "last_code": "import cv2\nimport numpy as np\nfrom tflite_runtime.interpreter import load_delegate, Interpreter\nfrom tflite_runtime.interpreter import load_delegate\n\n# Phase 1: Load Interpreter with EdgeTPU and Get Model Details\nmodel_path  = \"/home/mendel/tinyml_autopilot/models/edgetpu_detect.tflite\"\nlabel_path  = \"/home/mendel/tinyml_autopilot/models/labelmap.txt\"\n\n# Load the labels from the file.\nwith open(label_path, 'r') as f:\n    labels = [line.strip() for line in f.readlines()]\n\ninterpreter = Interpreter(model_path=model_path, experimental_delegates=[load_delegate('libedgetpu.so.1.0')])\ninterpreter.allocate_tensors()\ninput_details  = \"/home/mendel/tinyml_autopilot/data//sheeps.mp4\"\noutput_details  = \"/home/mendel/tinyml_autopilot/results/sheeps_detections.mp4\"\nheight = input_details[0]['shape'][1]\nwidth = input_details[0]['shape'][2]\n\n# Phase 2: Input Acquisition & Preprocessing Loop (Implement based on main prompt's input description)\ncap = cv2.VideoCapture(\"your_video_file_path\") # Change this to your video file path if not using a camera\n\nwhile True:\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    # Convert the image from BGR to RGB for input processing\n    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n\n    # Resize the frame to a fixed size (300x300 is common for many models)\n    resized_frame = cv2.resize(rgb_frame, (width, height))\n\n    # Normalize pixel values if needed\n    input_data = np.expand_dims(resized_frame, axis=0)\n\n    # Phase 3: Inference (Run per preprocessed input)\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n    interpreter.invoke()\n\n    # Retrieve detection results\n    boxes = interpreter.get_tensor(output_details[0]['index'])[0] # Bounding box coordinates of detected objects\n    classes = interpreter.get_tensor(output_details[1]['index'])[0] # Class index of detected objects\n    scores = interpreter.get_tensor(output_details[2]['index'])[0] # Confidence of detected objects\n\n    # Phase 4: Output Interpretation & Handling Loop (Implement based on main prompt's application and output descriptions)\n    for i in range(len(scores)):\n        if ((scores[i] > 0.5) and (scores[i] <= 1.0)):\n            # Get bounding box coordinates and scale them to the original image size\n            ymin, xmin, ymax, xmax = boxes[i]\n            xmin = int(xmin * frame.shape[1])\n            xmax = int(xmax * frame.shape[1])\n            ymin = int(ymin * frame.shape[0])\n            ymax = int(ymax * frame.shape[0])\n\n            # Get the label of the detected object and its confidence score\n            object_name = labels[int(classes[i])]\n            confidence = scores[i]\n\n            print('Object: ', object_name, ' Confidence: ', confidence)\n\n    # Press 'q' to quit the loop\n    if cv2.waitKey(1) & 0xFF == ord('q'):\n        break\n\n# Phase 5: Cleanup\ncap.release()\ncv2.destroyAllWindows()",
        "last_error": "Max retries reached with error. Last error: Traceback (most recent call last):\n  File \"script_6a9db17c_1755688791.py\", line 18, in <module>\n    height = input_details[0]['shape'][1]\nTypeError: string indices must be integers."
      },
      "session_id": "codestral_fc8d_tpusg_batch",
      "metadata": {
        "num_run": 14
      },
      "tags": [
        "benchmark",
        "codestral:latest",
        "tpu_sketch_generator"
      ],
      "latency": 111.681,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-14-18-07-787732_chatcmpl-96a241e3-f3d4-49c9-b733-eb0f3b0f678f",
          "traceId": "be1abeba",
          "type": "GENERATION",
          "name": "be1a_tpusg_gen_attempt#1",
          "startTime": "2025-08-20T11:18:07.787000+00:00",
          "endTime": "2025-08-20T11:18:36.741000+00:00",
          "model": "codestral:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 28954.0,
          "environment": "default",
          "promptTokens": 2048,
          "costDetails": {},
          "totalTokens": 3121,
          "completionTokens": 1073,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-14-18-44-383857_chatcmpl-2e5a4a5c-1993-44c7-a9bb-329fc3f9ff8a",
          "traceId": "be1abeba",
          "type": "GENERATION",
          "name": "be1a_tpusg_gen_attempt#2",
          "startTime": "2025-08-20T11:18:44.383000+00:00",
          "endTime": "2025-08-20T11:18:49.993000+00:00",
          "model": "codestral:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 5610.0,
          "environment": "default",
          "promptTokens": 2048,
          "costDetails": {},
          "totalTokens": 2184,
          "completionTokens": 136,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-14-18-49-997201_chatcmpl-c7b7873e-3bf9-4d07-abd3-025265ca80e3",
          "traceId": "be1abeba",
          "type": "GENERATION",
          "name": "be1a_tpusg_gen_attempt#3",
          "startTime": "2025-08-20T11:18:49.997000+00:00",
          "endTime": "2025-08-20T11:19:07.862000+00:00",
          "model": "codestral:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 17865.0,
          "environment": "default",
          "promptTokens": 2048,
          "costDetails": {},
          "totalTokens": 2677,
          "completionTokens": 629,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-14-19-07-868717_chatcmpl-b4259a2b-029f-4926-962d-a16fa898d8ba",
          "traceId": "be1abeba",
          "type": "GENERATION",
          "name": "be1a_tpusg_gen_attempt#4",
          "startTime": "2025-08-20T11:19:07.868000+00:00",
          "endTime": "2025-08-20T11:19:26.551000+00:00",
          "model": "codestral:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 18683.0,
          "environment": "default",
          "promptTokens": 2048,
          "costDetails": {},
          "totalTokens": 2710,
          "completionTokens": 662,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-14-19-26-554235_chatcmpl-f6ee8b44-6df4-4ef0-9a19-e174b32bd247",
          "traceId": "be1abeba",
          "type": "GENERATION",
          "name": "be1a_tpusg_gen_attempt#5",
          "startTime": "2025-08-20T11:19:26.554000+00:00",
          "endTime": "2025-08-20T11:19:51.932000+00:00",
          "model": "codestral:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 25378.0,
          "environment": "default",
          "promptTokens": 2048,
          "costDetails": {},
          "totalTokens": 2980,
          "completionTokens": 932,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "dde50d40-30b8-4ee1-afaf-7ec2a6970725",
          "traceId": "be1abeba",
          "type": "SPAN",
          "name": "error_be_tpusg_failure_signal_tpu_sketch_generator",
          "startTime": "2025-08-20T11:19:59.468000+00:00",
          "level": "ERROR",
          "statusMessage": "Failed: Max retries reached with error. Last error: Traceback (most recent call last):\n  File \"script_6a9db17c_1755688791.py\", line 18, in <module>\n    height = input_details[0]['shape'][1]\nTypeError: string indices must be integers.",
          "calculatedTotalCost": 0.0,
          "environment": "default",
          "promptTokens": 0,
          "costDetails": {},
          "totalTokens": 0,
          "completionTokens": 0,
          "endTime": null,
          "model": null,
          "modelParameters": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null,
          "latency": null
        }
      ],
      "environment": "default",
      "createdAt": "2025-08-20T11:18:08.304Z",
      "updatedAt": "2025-08-20T11:20:04.935Z"
    },
    {
      "id": "118f67bd",
      "timestamp": "2025-08-20T11:16:19.201000+00:00",
      "name": "118f_tpu_sketch_generator",
      "input": null,
      "output": {
        "status": "failed",
        "last_code": "import cv2\nimport numpy as np\nfrom PIL import Image\nfrom tflite_runtime.interpreter import Interpreter, load_delegate\n\n# Load labels\nwith open('labels.txt', 'r') as f:\n    labels = [line.strip() for line in f.readlines()]\n\n# Load the model\ntry:\n    interpreter = Interpreter(model_path='model.tflite',\n                              experimental_delegates=[load_delegate('libedgetpu.so.1')])\nexcept ValueError:\n    interpreter = Interpreter(model_path='model.tflite',\n                              experimental_delegates=[load_delegate('/usr/lib/aarch64-linux-gnu/libedgetpu.so.1')])\ninterpreter.allocate_tensors()\n\n# Get model details\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\nheight = input_details[0]['shape'][1]\nwidth = input_details[0]['shape'][2]\n\nfloating_model = (input_details[0]['dtype'] == np.float32)\n\n# Load and preprocess the image\nimage = Image.open('test.jpg').convert('RGB')\nresized_img = image.resize((width, height))\ninput_data = np.expand_dims(resized_img, axis=0)\n\nif floating_model:\n    input_data = (np.float32(input_data) - 127.5) / 127.5\n\n# Run inference\ninterpreter.set_tensor(input_details[0]['index'], input_data)\ninterpreter.invoke()\n\n# Interpret results\noutput_data = interpreter.get_tensor(output_details[0]['index'])\nresults = np.squeeze(output_data)\ntop_k = results.argsort()[-5:][::-1]\nfor i in top_k:\n    if floating_model:\n        print('{:08f}: {}'.format(float(results[i]), labels[i]))\n    else:\n        print('{:08f}: {}'.format(float(results[i] / 255.0), labels[i]))",
        "last_error": "Max retries reached with exception: Unexpected error during generation: The output is not a valid code block. Follow the instructions in the prompt return a complete, correct Python script enclosed in a single ```python\n<generated_code>\n``` block.."
      },
      "session_id": "codestral_fc8d_tpusg_batch",
      "metadata": {
        "num_run": 13
      },
      "tags": [
        "benchmark",
        "codestral:latest",
        "tpu_sketch_generator"
      ],
      "latency": 101.595,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-14-16-19-202822_chatcmpl-38511a08-2691-4f58-a286-8a2cf8ec119c",
          "traceId": "118f67bd",
          "type": "GENERATION",
          "name": "118f_tpusg_gen_attempt#1",
          "startTime": "2025-08-20T11:16:19.202000+00:00",
          "endTime": "2025-08-20T11:16:48.162000+00:00",
          "model": "codestral:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 28960.0,
          "environment": "default",
          "promptTokens": 2048,
          "costDetails": {},
          "totalTokens": 3121,
          "completionTokens": 1073,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-14-16-56-001477_chatcmpl-1b92ca2e-d932-4c46-b479-065b9088fc3e",
          "traceId": "118f67bd",
          "type": "GENERATION",
          "name": "118f_tpusg_gen_attempt#2",
          "startTime": "2025-08-20T11:16:56.001000+00:00",
          "endTime": "2025-08-20T11:17:27.088000+00:00",
          "model": "codestral:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 31087.0,
          "environment": "default",
          "promptTokens": 2048,
          "costDetails": {},
          "totalTokens": 3210,
          "completionTokens": 1162,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-14-17-27-098530_chatcmpl-3912b8c7-2a42-414e-a16a-07e1602a2aaf",
          "traceId": "118f67bd",
          "type": "GENERATION",
          "name": "118f_tpusg_gen_attempt#3",
          "startTime": "2025-08-20T11:17:27.098000+00:00",
          "endTime": "2025-08-20T11:17:45.727000+00:00",
          "model": "codestral:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 18629.0,
          "environment": "default",
          "promptTokens": 2048,
          "costDetails": {},
          "totalTokens": 2708,
          "completionTokens": 660,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-14-17-45-733152_chatcmpl-227349ca-996f-4ed4-ae37-5a11f3eac990",
          "traceId": "118f67bd",
          "type": "GENERATION",
          "name": "118f_tpusg_gen_attempt#4",
          "startTime": "2025-08-20T11:17:45.733000+00:00",
          "endTime": "2025-08-20T11:17:56.316000+00:00",
          "model": "codestral:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 10583.0,
          "environment": "default",
          "promptTokens": 2048,
          "costDetails": {},
          "totalTokens": 2384,
          "completionTokens": 336,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-14-17-56-324942_chatcmpl-b6d509f7-932f-4892-8484-4f63e832188a",
          "traceId": "118f67bd",
          "type": "GENERATION",
          "name": "118f_tpusg_gen_attempt#5",
          "startTime": "2025-08-20T11:17:56.324000+00:00",
          "endTime": "2025-08-20T11:18:00.795000+00:00",
          "model": "codestral:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 4471.0,
          "environment": "default",
          "promptTokens": 2048,
          "costDetails": {},
          "totalTokens": 2138,
          "completionTokens": 90,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "a74e50e2-5fe8-4f36-bc5f-15e01bb6e8df",
          "traceId": "118f67bd",
          "type": "SPAN",
          "name": "error_11_tpusg_failure_signal_tpu_sketch_generator",
          "startTime": "2025-08-20T11:18:00.797000+00:00",
          "level": "ERROR",
          "statusMessage": "Failed: Max retries reached with exception: Unexpected error during generation: The output is not a valid code block. Follow the instructions in the prompt return a complete, correct Python script enclosed in a single ```python\n<generated_code>\n``` block..",
          "calculatedTotalCost": 0.0,
          "environment": "default",
          "promptTokens": 0,
          "costDetails": {},
          "totalTokens": 0,
          "completionTokens": 0,
          "endTime": null,
          "model": null,
          "modelParameters": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null,
          "latency": null
        }
      ],
      "environment": "default",
      "createdAt": "2025-08-20T11:16:19.722Z",
      "updatedAt": "2025-08-20T11:18:06.688Z"
    },
    {
      "id": "62bd3952",
      "timestamp": "2025-08-20T11:14:41.621000+00:00",
      "name": "62bd_tpu_sketch_generator",
      "input": null,
      "output": {
        "status": "failed",
        "last_code": "import numpy as np\nfrom tflite_runtime.interpreter import load_delegate, Interpreter\n\n# Load labels\nwith open(label_path, 'r') as f:\n    labels = [line.strip() for line in f.readlines()]\n\n# Load interpreter with EdgeTPU\ninterpreter = Interpreter(model_path=model_path, experimental_delegates=[load_delegate('/usr/lib/aarch64-linux-gnu/libedgetpu.so.1.0')])\ninterpreter.allocate_tensors()\n\n# Get model details\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\nheight = input_details[0]['shape'][1]\nwidth = input_details[0]['shape'][2]\nfloating_model = (input_details[0]['dtype'] == np.float32)\n\n# Data acquisition and preprocessing loop\nwhile True:  # Replace with your own condition to stop the loop\n    frame = capture_frame()  # Replace with your own function to capture a frame\n    input_data = np.expand_dims(frame, axis=0)\n\n    if floating_model:\n        input_data = (np.float32(input_data) - 127.5) / 127.5\n\n    # Inference\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n    interpreter.invoke()\n\n    # Output interpretation and handling\n    boxes = interpreter.get_tensor(output_details[0]['index'])[0]\n    classes = interpreter.get_tensor(output_details[1]['index'])[0]\n    scores = interpreter.get_tensor(output_details[2]['index'])[0]\n\n    for i in range(len(scores)):\n        if ((scores[i] > confidence_threshold) and (scores[i] <= 1.0)):\n            ymin = int(max(1, (boxes[i][0] * height)))\n            xmin = int(max(1, (boxes[i][1] * width)))\n            ymax = int(min(height, (boxes[i][2] * height)))\n            xmax = int(min(width, (boxes[i][3] * width)))\n\n            object_name = labels[int(classes[i])]\n            label = '%s: %d%%' % (object_name, int(scores[i]*100))\n            handle_output(label)  # Replace with your own function to handle the output",
        "last_error": "Max retries reached with exception: Unexpected error during generation: The output is not a valid code block. Follow the instructions in the prompt return a complete, correct Python script enclosed in a single ```python\n<generated_code>\n``` block.."
      },
      "session_id": "codestral_fc8d_tpusg_batch",
      "metadata": {
        "num_run": 12
      },
      "tags": [
        "benchmark",
        "codestral:latest",
        "tpu_sketch_generator"
      ],
      "latency": 90.697,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-14-14-41-622848_chatcmpl-5df48474-f175-47d7-9d71-2e4acfece235",
          "traceId": "62bd3952",
          "type": "GENERATION",
          "name": "62bd_tpusg_gen_attempt#1",
          "startTime": "2025-08-20T11:14:41.622000+00:00",
          "endTime": "2025-08-20T11:15:08.614000+00:00",
          "model": "codestral:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 26992.0,
          "environment": "default",
          "promptTokens": 2048,
          "costDetails": {},
          "totalTokens": 3043,
          "completionTokens": 995,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-14-15-16-227163_chatcmpl-f47886ff-2aaf-4fb1-ba85-9645f63e391e",
          "traceId": "62bd3952",
          "type": "GENERATION",
          "name": "62bd_tpusg_gen_attempt#2",
          "startTime": "2025-08-20T11:15:16.227000+00:00",
          "endTime": "2025-08-20T11:15:36.635000+00:00",
          "model": "codestral:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 20408.0,
          "environment": "default",
          "promptTokens": 2048,
          "costDetails": {},
          "totalTokens": 2779,
          "completionTokens": 731,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-14-15-36-638091_chatcmpl-7068ee53-08f1-4d4a-a778-005d81630ba7",
          "traceId": "62bd3952",
          "type": "GENERATION",
          "name": "62bd_tpusg_gen_attempt#3",
          "startTime": "2025-08-20T11:15:36.638000+00:00",
          "endTime": "2025-08-20T11:15:43.763000+00:00",
          "model": "codestral:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 7125.0,
          "environment": "default",
          "promptTokens": 2048,
          "costDetails": {},
          "totalTokens": 2245,
          "completionTokens": 197,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-14-15-43-766947_chatcmpl-47bf7a28-63a1-4b4c-92a2-0319b75514c6",
          "traceId": "62bd3952",
          "type": "GENERATION",
          "name": "62bd_tpusg_gen_attempt#4",
          "startTime": "2025-08-20T11:15:43.766000+00:00",
          "endTime": "2025-08-20T11:16:04.584000+00:00",
          "model": "codestral:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 20818.0,
          "environment": "default",
          "promptTokens": 2048,
          "costDetails": {},
          "totalTokens": 2796,
          "completionTokens": 748,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-14-16-04-590651_chatcmpl-d4f289e4-c87c-43e7-9d12-3286669439e7",
          "traceId": "62bd3952",
          "type": "GENERATION",
          "name": "62bd_tpusg_gen_attempt#5",
          "startTime": "2025-08-20T11:16:04.590000+00:00",
          "endTime": "2025-08-20T11:16:12.314000+00:00",
          "model": "codestral:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 7724.0,
          "environment": "default",
          "promptTokens": 2048,
          "costDetails": {},
          "totalTokens": 2269,
          "completionTokens": 221,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "b0fcb62b-7a7d-42a5-bea1-86e257b9dc11",
          "traceId": "62bd3952",
          "type": "SPAN",
          "name": "error_62_tpusg_failure_signal_tpu_sketch_generator",
          "startTime": "2025-08-20T11:16:12.319000+00:00",
          "level": "ERROR",
          "statusMessage": "Failed: Max retries reached with exception: Unexpected error during generation: The output is not a valid code block. Follow the instructions in the prompt return a complete, correct Python script enclosed in a single ```python\n<generated_code>\n``` block..",
          "calculatedTotalCost": 0.0,
          "environment": "default",
          "promptTokens": 0,
          "costDetails": {},
          "totalTokens": 0,
          "completionTokens": 0,
          "endTime": null,
          "model": null,
          "modelParameters": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null,
          "latency": null
        }
      ],
      "environment": "default",
      "createdAt": "2025-08-20T11:14:42.142Z",
      "updatedAt": "2025-08-20T11:16:18.190Z"
    },
    {
      "id": "3570b346",
      "timestamp": "2025-08-20T11:13:30.984000+00:00",
      "name": "3570_tpu_sketch_generator",
      "input": null,
      "output": {
        "status": "failed",
        "last_code": "import cv2\nimport numpy as np\nfrom tensorflow.lite import Interpreter\nfrom tensorflow.lite.experimental import load_delegate\n\n# Define paths and parameters\nmodel_path  = \"/home/mendel/tinyml_autopilot/models/edgetpu_detect.tflite\"\ninput_path  = \"/home/mendel/tinyml_autopilot/data//sheeps.mp4\"\nlabel_path  = \"/home/mendel/tinyml_autopilot/models/labelmap.txt\"\noutput_path  = \"/home/mendel/tinyml_autopilot/results/sheeps_detections.mp4\"\nconfidence_threshold  = 0.5\n\n# Load labels\nwith open(label_path, 'r') as f:\n    labels = [line.strip() for line in f.readlines()]\n\n# Load interpreter with EdgeTPU\ninterpreter = Interpreter(model_path=model_path, experimental_delegates=[load_delegate('/usr/lib/aarch64-linux-gnu/libedgetpu.so.1.0')])\ninterpreter.allocate_tensors()\n\n# Get model details\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\nheight = input_details[0]['shape'][1]\nwidth = input_details[0]['shape'][2]\nfloating_model = (input_details[0]['dtype'] == np.float32)\n\n# Input acquisition and preprocessing loop\ncap = cv2.VideoCapture(input_path)\nout = cv2.VideoWriter(output_path, cv2.VideoWriter_fourcc(*'XVID'), 30.0, (width, height))\n\nwhile cap.isOpened():\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    # Preprocess data\n    resized_frame = cv2.resize(frame, (width, height))\n    input_data = np.expand_dims(resized_frame, axis=0)\n\n    if floating_model:\n        input_data = (np.float32(input_data) - 127.5) / 127.5\n\n    # Inference\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n    interpreter.invoke()\n\n    # Output interpretation and handling\n    boxes = interpreter.get_tensor(output_details[0]['index'])[0]\n    classes = interpreter.get_tensor(output_details[1]['index'])[0]\n    scores = interpreter.get_tensor(output_details[2]['index'])[0]\n\n    for i in range(len(scores)):\n        if ((scores[i] > confidence_threshold) and (scores[i] <= 1.0)):\n            ymin = int(max(1, (boxes[i][0] * height)))\n            xmin = int(max(1, (boxes[i][1] * width)))\n            ymax = int(min(height, (boxes[i][2] * height)))\n            xmax = int(min(width, (boxes[i][3] * width)))\n\n            cv2.rectangle(frame, (xmin, ymin), (xmax, ymax), (10, 255, 0), 4)\n            object_name = labels[int(classes[i])]\n            label = '%s: %d%%' % (object_name, int(scores[i]*100))\n            labelSize, baseLine = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.7, 2)\n            label_ymin = max(ymin, labelSize[1] + 10)\n            cv2.rectangle(frame, (xmin, label_ymin-labelSize[1]-10), (xmin+labelSize[0], label_ymin+baseLine-10), (255, 255, 255), cv2.FILLED)\n            cv2.putText(frame, label, (xmin, label_ymin-7), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 0), 2)\n\n    out.write(frame)\n\n# Cleanup\ncap.release()\nout.release()\ncv2.destroyAllWindows()",
        "last_error": "Max retries reached with exception: Unexpected error during generation: The output is not a valid code block. Follow the instructions in the prompt return a complete, correct Python script enclosed in a single ```python\n<generated_code>\n``` block.."
      },
      "session_id": "codestral_fc8d_tpusg_batch",
      "metadata": {
        "num_run": 11
      },
      "tags": [
        "benchmark",
        "codestral:latest",
        "tpu_sketch_generator"
      ],
      "latency": 63.727,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-14-13-30-986437_chatcmpl-eea4dedb-180e-43b4-88f7-3b703080de73",
          "traceId": "3570b346",
          "type": "GENERATION",
          "name": "3570_tpusg_gen_attempt#1",
          "startTime": "2025-08-20T11:13:30.986000+00:00",
          "endTime": "2025-08-20T11:13:57.973000+00:00",
          "model": "codestral:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 26987.0,
          "environment": "default",
          "promptTokens": 2048,
          "costDetails": {},
          "totalTokens": 3043,
          "completionTokens": 995,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-14-14-05-532375_chatcmpl-ca77766b-ab48-4d33-a991-f88851173843",
          "traceId": "3570b346",
          "type": "GENERATION",
          "name": "3570_tpusg_gen_attempt#2",
          "startTime": "2025-08-20T11:14:05.532000+00:00",
          "endTime": "2025-08-20T11:14:12.411000+00:00",
          "model": "codestral:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 6879.0,
          "environment": "default",
          "promptTokens": 2048,
          "costDetails": {},
          "totalTokens": 2234,
          "completionTokens": 186,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-14-14-12-418209_chatcmpl-205a58c5-00f8-432a-ae23-1c8cc3954e4c",
          "traceId": "3570b346",
          "type": "GENERATION",
          "name": "3570_tpusg_gen_attempt#3",
          "startTime": "2025-08-20T11:14:12.418000+00:00",
          "endTime": "2025-08-20T11:14:20.663000+00:00",
          "model": "codestral:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 8245.0,
          "environment": "default",
          "promptTokens": 2048,
          "costDetails": {},
          "totalTokens": 2290,
          "completionTokens": 242,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-14-14-20-670084_chatcmpl-97b58996-61c8-464b-8dff-0daaedef026c",
          "traceId": "3570b346",
          "type": "GENERATION",
          "name": "3570_tpusg_gen_attempt#4",
          "startTime": "2025-08-20T11:14:20.670000+00:00",
          "endTime": "2025-08-20T11:14:28.083000+00:00",
          "model": "codestral:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 7413.0,
          "environment": "default",
          "promptTokens": 2048,
          "costDetails": {},
          "totalTokens": 2256,
          "completionTokens": 208,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-14-14-28-098860_chatcmpl-8f283d7f-56ed-4fe0-9503-9dd14412b2f9",
          "traceId": "3570b346",
          "type": "GENERATION",
          "name": "3570_tpusg_gen_attempt#5",
          "startTime": "2025-08-20T11:14:28.098000+00:00",
          "endTime": "2025-08-20T11:14:34.709000+00:00",
          "model": "codestral:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 6611.0,
          "environment": "default",
          "promptTokens": 2048,
          "costDetails": {},
          "totalTokens": 2224,
          "completionTokens": 176,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "b7a8ce83-77f5-4f47-9b63-8e5dc51c933d",
          "traceId": "3570b346",
          "type": "SPAN",
          "name": "error_35_tpusg_failure_signal_tpu_sketch_generator",
          "startTime": "2025-08-20T11:14:34.713000+00:00",
          "level": "ERROR",
          "statusMessage": "Failed: Max retries reached with exception: Unexpected error during generation: The output is not a valid code block. Follow the instructions in the prompt return a complete, correct Python script enclosed in a single ```python\n<generated_code>\n``` block..",
          "calculatedTotalCost": 0.0,
          "environment": "default",
          "promptTokens": 0,
          "costDetails": {},
          "totalTokens": 0,
          "completionTokens": 0,
          "endTime": null,
          "model": null,
          "modelParameters": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null,
          "latency": null
        }
      ],
      "environment": "default",
      "createdAt": "2025-08-20T11:13:31.506Z",
      "updatedAt": "2025-08-20T11:14:40.335Z"
    },
    {
      "id": "e2a158af",
      "timestamp": "2025-08-20T11:12:24.870000+00:00",
      "name": "e2a1_tpu_sketch_generator",
      "input": null,
      "output": {
        "status": "failed",
        "last_code": "import cv2\nimport numpy as np\nfrom tensorflow.lite import Interpreter\nfrom tensorflow.lite.experimental import load_delegate\n\n# Define paths and parameters\nmodel_path  = \"/home/mendel/tinyml_autopilot/models/edgetpu_detect.tflite\"\ninput_path  = \"/home/mendel/tinyml_autopilot/data//sheeps.mp4\"\nlabel_path  = \"/home/mendel/tinyml_autopilot/models/labelmap.txt\"\noutput_path  = \"/home/mendel/tinyml_autopilot/results/sheeps_detections.mp4\"\nconfidence_threshold  = 0.5\n\n# Load labels\nwith open(label_path, 'r') as f:\n    labels = [line.strip() for line in f.readlines()]\n\n# Load interpreter with EdgeTPU\ninterpreter = Interpreter(model_path=model_path, experimental_delegates=[load_delegate('/usr/lib/aarch64-linux-gnu/libedgetpu.so.1.0')])\ninterpreter.allocate_tensors()\n\n# Get model details\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\nheight = input_details[0]['shape'][1]\nwidth = input_details[0]['shape'][2]\nfloating_model = (input_details[0]['dtype'] == np.float32)\n\n# Input acquisition and preprocessing loop\ncap = cv2.VideoCapture(input_path)\nout = cv2.VideoWriter(output_path, cv2.VideoWriter_fourcc(*'XVID'), 30.0, (width, height))\n\nwhile cap.isOpened():\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    # Preprocess data\n    resized_frame = cv2.resize(frame, (width, height))\n    input_data = np.expand_dims(resized_frame, axis=0)\n\n    if floating_model:\n        input_data = (np.float32(input_data) - 127.5) / 127.5\n\n    # Inference\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n    interpreter.invoke()\n\n    # Output interpretation and handling\n    boxes = interpreter.get_tensor(output_details[0]['index'])[0]\n    classes = interpreter.get_tensor(output_details[1]['index'])[0]\n    scores = interpreter.get_tensor(output_details[2]['index'])[0]\n\n    for i in range(len(scores)):\n        if ((scores[i] > confidence_threshold) and (scores[i] <= 1.0)):\n            ymin = int(max(1, (boxes[i][0] * height)))\n            xmin = int(max(1, (boxes[i][1] * width)))\n            ymax = int(min(height, (boxes[i][2] * height)))\n            xmax = int(min(width, (boxes[i][3] * width)))\n\n            cv2.rectangle(frame, (xmin, ymin), (xmax, ymax), (10, 255, 0), 4)\n            object_name = labels[int(classes[i])]\n            label = '%s: %d%%' % (object_name, int(scores[i]*100))\n            labelSize, baseLine = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.7, 2)\n            label_ymin = max(ymin, labelSize[1] + 10)\n            cv2.rectangle(frame, (xmin, label_ymin-labelSize[1]-10), (xmin+labelSize[0], label_ymin+baseLine-10), (255, 255, 255), cv2.FILLED)\n            cv2.putText(frame, label, (xmin, label_ymin-7), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 0), 2)\n\n    out.write(frame)\n\n# Cleanup\ncap.release()\nout.release()\ncv2.destroyAllWindows()",
        "last_error": "Max retries reached with exception: Unexpected error during generation: The output is not a valid code block. Follow the instructions in the prompt return a complete, correct Python script enclosed in a single ```python\n<generated_code>\n``` block.."
      },
      "session_id": "codestral_fc8d_tpusg_batch",
      "metadata": {
        "num_run": 10
      },
      "tags": [
        "benchmark",
        "codestral:latest",
        "tpu_sketch_generator"
      ],
      "latency": 58.97,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-14-12-24-878882_chatcmpl-7d7a5e25-97c2-4531-9a25-68dc39357418",
          "traceId": "e2a158af",
          "type": "GENERATION",
          "name": "e2a1_tpusg_gen_attempt#1",
          "startTime": "2025-08-20T11:12:24.878000+00:00",
          "endTime": "2025-08-20T11:12:51.916000+00:00",
          "model": "codestral:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 27038.0,
          "environment": "default",
          "promptTokens": 2048,
          "costDetails": {},
          "totalTokens": 3043,
          "completionTokens": 995,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-14-12-59-395468_chatcmpl-b2371f50-0eaa-4cf0-b37c-ea0dbbbe8845",
          "traceId": "e2a158af",
          "type": "GENERATION",
          "name": "e2a1_tpusg_gen_attempt#2",
          "startTime": "2025-08-20T11:12:59.395000+00:00",
          "endTime": "2025-08-20T11:13:05.768000+00:00",
          "model": "codestral:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 6373.0,
          "environment": "default",
          "promptTokens": 2048,
          "costDetails": {},
          "totalTokens": 2214,
          "completionTokens": 166,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-14-13-05-774701_chatcmpl-607efb2f-2653-42bc-b9cc-ddd77302356e",
          "traceId": "e2a158af",
          "type": "GENERATION",
          "name": "e2a1_tpusg_gen_attempt#3",
          "startTime": "2025-08-20T11:13:05.774000+00:00",
          "endTime": "2025-08-20T11:13:10.962000+00:00",
          "model": "codestral:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 5188.0,
          "environment": "default",
          "promptTokens": 2048,
          "costDetails": {},
          "totalTokens": 2167,
          "completionTokens": 119,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-14-13-10-968209_chatcmpl-bc7d705d-c97c-48bf-a913-09b1fc4b06fc",
          "traceId": "e2a158af",
          "type": "GENERATION",
          "name": "e2a1_tpusg_gen_attempt#4",
          "startTime": "2025-08-20T11:13:10.968000+00:00",
          "endTime": "2025-08-20T11:13:17.402000+00:00",
          "model": "codestral:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 6434.0,
          "environment": "default",
          "promptTokens": 2048,
          "costDetails": {},
          "totalTokens": 2217,
          "completionTokens": 169,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-14-13-17-405901_chatcmpl-622e7c0a-8d0c-4395-a2a5-cec833b1600f",
          "traceId": "e2a158af",
          "type": "GENERATION",
          "name": "e2a1_tpusg_gen_attempt#5",
          "startTime": "2025-08-20T11:13:17.405000+00:00",
          "endTime": "2025-08-20T11:13:23.837000+00:00",
          "model": "codestral:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 6432.0,
          "environment": "default",
          "promptTokens": 2048,
          "costDetails": {},
          "totalTokens": 2217,
          "completionTokens": 169,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "1268e004-5235-4cbe-baac-576496a9ed8b",
          "traceId": "e2a158af",
          "type": "SPAN",
          "name": "error_e2_tpusg_failure_signal_tpu_sketch_generator",
          "startTime": "2025-08-20T11:13:23.848000+00:00",
          "level": "ERROR",
          "statusMessage": "Failed: Max retries reached with exception: Unexpected error during generation: The output is not a valid code block. Follow the instructions in the prompt return a complete, correct Python script enclosed in a single ```python\n<generated_code>\n``` block..",
          "calculatedTotalCost": 0.0,
          "environment": "default",
          "promptTokens": 0,
          "costDetails": {},
          "totalTokens": 0,
          "completionTokens": 0,
          "endTime": null,
          "model": null,
          "modelParameters": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null,
          "latency": null
        }
      ],
      "environment": "default",
      "createdAt": "2025-08-20T11:12:25.390Z",
      "updatedAt": "2025-08-20T11:13:29.275Z"
    },
    {
      "id": "cb160356",
      "timestamp": "2025-08-20T11:10:08.478000+00:00",
      "name": "cb16_tpu_sketch_generator",
      "input": null,
      "output": {
        "status": "failed",
        "last_code": "import cv2\nimport numpy as np\nfrom tflite_runtime.interpreter import load_delegate, Interpreter\n\n# Load labels\nwith open('labels.txt', 'r') as f:\n    labels = [line.strip() for line in f.readlines()]\n\n# Load the model with EdgeTPU acceleration\ninterpreter = Interpreter(model_path='model.tflite', experimental_delegates=[load_delegate('libedgetpu.so.1')])\ninterpreter.allocate_tensors()\n\n# Get input and output details\ninput_details  = \"/home/mendel/tinyml_autopilot/data//sheeps.mp4\"\noutput_details  = \"/home/mendel/tinyml_autopilot/results/sheeps_detections.mp4\"\n\n# Open a video stream (use 0 for webcam)\ncap = cv2.VideoCapture('video.mp4')\n\nwhile cap.isOpened():\n    # Read frame from the video stream\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    # Resize the frame to match the model's input shape\n    input_shape = input_details[0]['shape']\n    resized_frame = cv2.resize(frame, (input_shape[1], input_shape[2]))\n\n    # Convert the frame to a numpy array and normalize it\n    input_data = np.array(resized_frame) / 255.0\n    input_data = np.expand_dims(input_data, axis=0).astype(np.float32)\n\n    # Set input tensor\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n\n    # Run inference\n    interpreter.invoke()\n\n    # Get output tensors\n    boxes = interpreter.get_tensor(output_details[0]['index'])[0]\n    classes = interpreter.get_tensor(output_details[1]['index'])[0]\n    scores = interpreter.get_tensor(output_details[2]['index'])[0]\n\n    # Interpret results\n    for i in range(len(scores)):\n        if scores[i] > 0.5:\n            class_id = int(classes[i])\n            label = labels[class_id]\n            ymin, xmin, ymax, xmax = boxes[i]\n            xmin = int(xmin * frame.shape[1])\n            xmax = int(xmax * frame.shape[1])\n            ymin = int(ymin * frame.shape[0])\n            ymax = int(ymax * frame.shape[0])\n\n            # Draw bounding box and label on the frame\n            cv2.rectangle(frame, (xmin, ymin), (xmax, ymax), (0, 255, 0), 2)\n            cv2.putText(frame, f'{label}: {scores[i]:.2f}', (xmin, ymin - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (36,255,12), 2)\n\n    # Display the frame with bounding boxes\n    cv2.imshow('Object Detection', frame)\n\n    # Break the loop if 'q' is pressed\n    if cv2.waitKey(1) & 0xFF == ord('q'):\n        break\n\n# Release the video stream and close all windows\ncap.release()\ncv2.destroyAllWindows()",
        "last_error": "Max retries reached with error. Last error: Traceback (most recent call last):\n  File \"script_d23d7362_1755688330.py\", line 6, in <module>\n    with open('labels.txt', 'r') as f:\nFileNotFoundError: [Errno 2] No such file or directory: 'labels.txt'."
      },
      "session_id": "codestral_fc8d_tpusg_batch",
      "metadata": {
        "num_run": 9
      },
      "tags": [
        "benchmark",
        "codestral:latest",
        "tpu_sketch_generator"
      ],
      "latency": 129.926,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-14-10-08-480106_chatcmpl-5acb7ebf-1d28-4631-b34f-546902dd3a62",
          "traceId": "cb160356",
          "type": "GENERATION",
          "name": "cb16_tpusg_gen_attempt#1",
          "startTime": "2025-08-20T11:10:08.480000+00:00",
          "endTime": "2025-08-20T11:10:35.475000+00:00",
          "model": "codestral:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 26995.0,
          "environment": "default",
          "promptTokens": 2048,
          "costDetails": {},
          "totalTokens": 3043,
          "completionTokens": 995,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-14-10-43-088303_chatcmpl-e286b2ef-cdd0-4172-a6a3-271f42c7c1c0",
          "traceId": "cb160356",
          "type": "GENERATION",
          "name": "cb16_tpusg_gen_attempt#2",
          "startTime": "2025-08-20T11:10:43.088000+00:00",
          "endTime": "2025-08-20T11:10:52.479000+00:00",
          "model": "codestral:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 9391.0,
          "environment": "default",
          "promptTokens": 2048,
          "costDetails": {},
          "totalTokens": 2335,
          "completionTokens": 287,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-14-10-52-488078_chatcmpl-16445e5b-635b-4679-9e4c-74ccd4c49d4f",
          "traceId": "cb160356",
          "type": "GENERATION",
          "name": "cb16_tpusg_gen_attempt#3",
          "startTime": "2025-08-20T11:10:52.488000+00:00",
          "endTime": "2025-08-20T11:11:08.793000+00:00",
          "model": "codestral:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 16305.0,
          "environment": "default",
          "promptTokens": 2048,
          "costDetails": {},
          "totalTokens": 2614,
          "completionTokens": 566,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-14-11-08-797082_chatcmpl-48205fa6-7deb-49d4-8977-f52536927d63",
          "traceId": "cb160356",
          "type": "GENERATION",
          "name": "cb16_tpusg_gen_attempt#4",
          "startTime": "2025-08-20T11:11:08.797000+00:00",
          "endTime": "2025-08-20T11:11:37.866000+00:00",
          "model": "codestral:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 29069.0,
          "environment": "default",
          "promptTokens": 2048,
          "costDetails": {},
          "totalTokens": 3128,
          "completionTokens": 1080,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-14-11-45-464441_chatcmpl-187f3b95-3d0f-43b0-8f3c-1f96e172208b",
          "traceId": "cb160356",
          "type": "GENERATION",
          "name": "cb16_tpusg_gen_attempt#5",
          "startTime": "2025-08-20T11:11:45.464000+00:00",
          "endTime": "2025-08-20T11:12:10.822000+00:00",
          "model": "codestral:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 25358.0,
          "environment": "default",
          "promptTokens": 2048,
          "costDetails": {},
          "totalTokens": 2978,
          "completionTokens": 930,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "377e7bd3-0136-4ae8-96fc-59598b3de3a5",
          "traceId": "cb160356",
          "type": "SPAN",
          "name": "error_cb_tpusg_failure_signal_tpu_sketch_generator",
          "startTime": "2025-08-20T11:12:18.406000+00:00",
          "level": "ERROR",
          "statusMessage": "Failed: Max retries reached with error. Last error: Traceback (most recent call last):\n  File \"script_d23d7362_1755688330.py\", line 6, in <module>\n    with open('labels.txt', 'r') as f:\nFileNotFoundError: [Errno 2] No such file or directory: 'labels.txt'.",
          "calculatedTotalCost": 0.0,
          "environment": "default",
          "promptTokens": 0,
          "costDetails": {},
          "totalTokens": 0,
          "completionTokens": 0,
          "endTime": null,
          "model": null,
          "modelParameters": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null,
          "latency": null
        }
      ],
      "environment": "default",
      "createdAt": "2025-08-20T11:10:09.000Z",
      "updatedAt": "2025-08-20T11:12:23.738Z"
    },
    {
      "id": "5c7cb804",
      "timestamp": "2025-08-20T11:07:41.837000+00:00",
      "name": "5c7c_tpu_sketch_generator",
      "input": null,
      "output": {
        "status": "failed",
        "last_code": "import cv2\nfrom PIL import Image\nimport numpy as np\nfrom edgetpu.detection.engine import DetectionEngine\n\n# Replace 'coco_labels.txt' with the correct path to your labels file\nlabels_file = 'path/to/your/labels.txt'  # Update this line with the correct path\n\n# Load labels\nwith open(labels_file, 'r') as f:\n    labels = [line.strip() for line in f.readlines()]\n\n# Initialize the detection engine\nengine = DetectionEngine('mobilenet_ssd_v2_coco_quant_edgetpu.tflite')\n\n# Open the video file\ncap = cv2.VideoCapture('input_video.mp4')\n\nwhile(cap.isOpened()):\n    # Read a frame from the video\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    # Convert the image from BGR to RGB for processing\n    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n\n    # Convert the image to a PIL Image object\n    pil_image = Image.fromarray(rgb_frame)\n\n    # Resize the image to 300x300 as required by the model\n    resized_img = pil_image.resize((300, 300), Image.ANTIALIAS)\n\n    # Convert the PIL Image object back to a numpy array\n    input_data = np.expand_dims(resized_img, axis=0)\n\n    # Normalize pixel values if necessary\n    floating_model = (engine.get_input_details()[0]['dtype'] == np.float32)\n    if floating_model:\n        input_data = (np.float32(input_data) - 127.5) / 127.5\n\n    # Perform detection on the image\n    detections = engine.DetectWithImage(input_data, threshold=0.05, keep_aspect_ratio=True, relative_coord=False, top_k=10)\n\n    # Loop over all detections and draw bounding boxes on the frame\n    for i in range(len(detections)):\n        bbox = detections[i].bounding_box.flatten().tolist()\n        cv2.rectangle(frame, (int(bbox[0]), int(bbox[1])), (int(bbox[2]), int(bbox[3])), (255, 0, 0), 2)\n        label = labels[detections[i].label_id]\n        cv2.putText(frame, label, (int(bbox[0]), int(bbox[1])-10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 2)\n\n    # Display the resulting frame\n    cv2.imshow('Object Detection', frame)\n\n    if cv2.waitKey(1) & 0xFF == ord('q'):\n        break\n\n# Release the video capture object and close all windows\ncap.release()\ncv2.destroyAllWindows()",
        "last_error": "Max retries reached with error. Last error: Traceback (most recent call last):\n  File \"script_587f7aa7_1755688194.py\", line 10, in <module>\n    with open(labels_file, 'r') as f:\nFileNotFoundError: [Errno 2] No such file or directory: 'path/to/your/labels.txt'."
      },
      "session_id": "codestral_fc8d_tpusg_batch",
      "metadata": {
        "num_run": 8
      },
      "tags": [
        "benchmark",
        "codestral:latest",
        "tpu_sketch_generator"
      ],
      "latency": 140.94,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-14-07-41-838997_chatcmpl-fe771f23-6b9d-47d0-8f15-246f2ada8b8f",
          "traceId": "5c7cb804",
          "type": "GENERATION",
          "name": "5c7c_tpusg_gen_attempt#1",
          "startTime": "2025-08-20T11:07:41.838000+00:00",
          "endTime": "2025-08-20T11:08:10.819000+00:00",
          "model": "codestral:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 28981.0,
          "environment": "default",
          "promptTokens": 2048,
          "costDetails": {},
          "totalTokens": 3121,
          "completionTokens": 1073,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-14-08-18-424100_chatcmpl-77ba0639-7412-46ae-baf3-6e64a5618350",
          "traceId": "5c7cb804",
          "type": "GENERATION",
          "name": "5c7c_tpusg_gen_attempt#2",
          "startTime": "2025-08-20T11:08:18.424000+00:00",
          "endTime": "2025-08-20T11:08:25.325000+00:00",
          "model": "codestral:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 6901.0,
          "environment": "default",
          "promptTokens": 2048,
          "costDetails": {},
          "totalTokens": 2235,
          "completionTokens": 187,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-14-08-25-330952_chatcmpl-7a11948a-2dcc-4d3a-ba4e-e9f7abac418f",
          "traceId": "5c7cb804",
          "type": "GENERATION",
          "name": "5c7c_tpusg_gen_attempt#3",
          "startTime": "2025-08-20T11:08:25.330000+00:00",
          "endTime": "2025-08-20T11:08:48.432000+00:00",
          "model": "codestral:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 23102.0,
          "environment": "default",
          "promptTokens": 2048,
          "costDetails": {},
          "totalTokens": 2888,
          "completionTokens": 840,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-14-08-56-498246_chatcmpl-8d6cc0d6-1d1f-450e-8501-a3ef78252807",
          "traceId": "5c7cb804",
          "type": "GENERATION",
          "name": "5c7c_tpusg_gen_attempt#4",
          "startTime": "2025-08-20T11:08:56.498000+00:00",
          "endTime": "2025-08-20T11:09:21.040000+00:00",
          "model": "codestral:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 24542.0,
          "environment": "default",
          "promptTokens": 2048,
          "costDetails": {},
          "totalTokens": 2946,
          "completionTokens": 898,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-14-09-29-446861_chatcmpl-51ea25cf-f5c7-43a1-b64d-4594b4358b17",
          "traceId": "5c7cb804",
          "type": "GENERATION",
          "name": "5c7c_tpusg_gen_attempt#5",
          "startTime": "2025-08-20T11:09:29.446000+00:00",
          "endTime": "2025-08-20T11:09:54.842000+00:00",
          "model": "codestral:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 25396.0,
          "environment": "default",
          "promptTokens": 2048,
          "costDetails": {},
          "totalTokens": 2979,
          "completionTokens": 931,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "c92413e2-c5b9-4872-a692-26bf1ccdacd4",
          "traceId": "5c7cb804",
          "type": "SPAN",
          "name": "error_5c_tpusg_failure_signal_tpu_sketch_generator",
          "startTime": "2025-08-20T11:10:02.778000+00:00",
          "level": "ERROR",
          "statusMessage": "Failed: Max retries reached with error. Last error: Traceback (most recent call last):\n  File \"script_587f7aa7_1755688194.py\", line 10, in <module>\n    with open(labels_file, 'r') as f:\nFileNotFoundError: [Errno 2] No such file or directory: 'path/to/your/labels.txt'.",
          "calculatedTotalCost": 0.0,
          "environment": "default",
          "promptTokens": 0,
          "costDetails": {},
          "totalTokens": 0,
          "completionTokens": 0,
          "endTime": null,
          "model": null,
          "modelParameters": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null,
          "latency": null
        }
      ],
      "environment": "default",
      "createdAt": "2025-08-20T11:07:42.359Z",
      "updatedAt": "2025-08-20T11:10:08.057Z"
    },
    {
      "id": "9b79de40",
      "timestamp": "2025-08-20T11:06:09.215000+00:00",
      "name": "9b79_tpu_sketch_generator",
      "input": null,
      "output": {
        "status": "success",
        "sketch": "import cv2\nimport numpy as np\nfrom tflite_runtime.interpreter import Interpreter, load_delegate\n\n# Phase 1: Load Interpreter with EdgeTPU, Get Model Details, and Load Labels (if necessary)\nmodel_path  = \"/home/mendel/tinyml_autopilot/models/edgetpu_detect.tflite\"\nlabel_path  = \"/home/mendel/tinyml_autopilot/models/labelmap.txt\"\ninput_mean  = \"/home/mendel/tinyml_autopilot/data//sheeps.mp4\"\ninput_std = 127.5\n\nwith open(label_path, 'r') as f:\n    labels = [line.strip() for line in f.readlines()]\n\ninterpreter = Interpreter(model_path=model_path, experimental_delegates=[load_delegate('libedgetpu.so.1.0')])\ninterpreter.allocate_tensors()\ninput_details = interpreter.get_input_details()\noutput_details  = \"/home/mendel/tinyml_autopilot/results/sheeps_detections.mp4\"\nheight = input_details[0]['shape'][1]\nwidth = input_details[0]['shape'][2]\nfloating_model = (input_details[0]['dtype'] == np.float32)\n\n# Phase 2: Input Acquisition & Preprocessing Loop\ncap = cv2.VideoCapture('input_video.mp4')\nfourcc = cv2.VideoWriter_fourcc(*'XVID')\nout = cv2.VideoWriter('output_video.avi', fourcc, 30.0, (int(cap.get(3)), int(cap.get(4))))\n\nwhile cap.isOpened():\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    img = cv2.resize(frame, (width, height))\n    input_data = np.expand_dims(img, axis=0)\n\n    # Phase 3: Inference\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n    interpreter.invoke()\n\n    # Phase 4: Output Interpretation & Handling Loop\n    boxes = interpreter.get_tensor(output_details[0]['index'])[0]\n    classes = interpreter.get_tensor(output_details[1]['index'])[0]\n    scores = interpreter.get_tensor(output_details[2]['index'])[0]\n\n    for i in range(len(scores)):\n        if ((scores[i] > 0.5) and (scores[i] <= 1.0)):\n            ymin = int(max(1, (boxes[i][0] * frame.shape[0])))\n            xmin = int(max(1, (boxes[i][1] * frame.shape[1])))\n            ymax = int(min(frame.shape[0], (boxes[i][2] * frame.shape[0])))\n            xmax = int(min(frame.shape[1], (boxes[i][3] * frame.shape[1])))\n\n            cv2.rectangle(frame, (xmin, ymin), (xmax, ymax), (10, 255, 0), 2)\n            object_name = labels[int(classes[i])]\n            label = '%s: %d%%' % (object_name, int(scores[i]*100))\n            labelSize, baseLine = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.7, 2)\n            label_ymin = max(ymin, labelSize[1] + 10)\n            cv2.rectangle(frame, (xmin, label_ymin-labelSize[1]-10), (xmin+labelSize[0], label_ymin+baseLine-10), (255, 255, 255), cv2.FILLED)\n            cv2.putText(frame, label, (xmin, label_ymin-7), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 0), 2)\n\n    out.write(frame)\n\n# Phase 5: Cleanup\ncap.release()\nout.release()\ncv2.destroyAllWindows()"
      },
      "session_id": "codestral_fc8d_tpusg_batch",
      "metadata": {
        "num_run": 7
      },
      "tags": [
        "benchmark",
        "codestral:latest",
        "tpu_sketch_generator"
      ],
      "latency": 78.472,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-14-06-09-216495_chatcmpl-db3be06e-17fe-47e8-b0dc-523cb737bd2e",
          "traceId": "9b79de40",
          "type": "GENERATION",
          "name": "9b79_tpusg_gen_attempt#1",
          "startTime": "2025-08-20T11:06:09.216000+00:00",
          "endTime": "2025-08-20T11:06:38.207000+00:00",
          "model": "codestral:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 28991.0,
          "environment": "default",
          "promptTokens": 2048,
          "costDetails": {},
          "totalTokens": 3121,
          "completionTokens": 1073,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-14-06-45-766239_chatcmpl-4c18e512-9ddd-4e9f-a0c2-44ac0d2a2967",
          "traceId": "9b79de40",
          "type": "GENERATION",
          "name": "9b79_tpusg_gen_attempt#2",
          "startTime": "2025-08-20T11:06:45.766000+00:00",
          "endTime": "2025-08-20T11:06:52.549000+00:00",
          "model": "codestral:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 6783.0,
          "environment": "default",
          "promptTokens": 2048,
          "costDetails": {},
          "totalTokens": 2229,
          "completionTokens": 181,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-14-06-52-556749_chatcmpl-a189cfc4-7bba-4466-acf9-43f52e208813",
          "traceId": "9b79de40",
          "type": "GENERATION",
          "name": "9b79_tpusg_gen_attempt#3",
          "startTime": "2025-08-20T11:06:52.556000+00:00",
          "endTime": "2025-08-20T11:07:27.688000+00:00",
          "model": "codestral:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 35132.0,
          "environment": "default",
          "promptTokens": 2048,
          "costDetails": {},
          "totalTokens": 3372,
          "completionTokens": 1324,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        }
      ],
      "environment": "default",
      "createdAt": "2025-08-20T11:06:09.737Z",
      "updatedAt": "2025-08-20T11:07:40.922Z"
    },
    {
      "id": "a625b929",
      "timestamp": "2025-08-20T11:04:11.681000+00:00",
      "name": "a625_tpu_sketch_generator",
      "input": null,
      "output": {
        "status": "failed",
        "last_code": "import os\n# ... rest of your code ...\n\n# Check if labels file exists\nif not os.path.isfile('coco_labels.txt'):\n    print(\"Error: 'coco_labels.txt' file not found.\")\n    exit()\n\n# Load labels\nlabels = load_label_file('coco_labels.txt')",
        "last_error": "Max retries reached with exception: Unexpected error during generation: Generated script is not complete. Please ensure to generate a complete Python script.."
      },
      "session_id": "codestral_fc8d_tpusg_batch",
      "metadata": {
        "num_run": 6
      },
      "tags": [
        "benchmark",
        "codestral:latest",
        "tpu_sketch_generator"
      ],
      "latency": 110.916,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-14-04-11-683398_chatcmpl-f7057224-5de4-4ebf-a04d-11b6641370e1",
          "traceId": "a625b929",
          "type": "GENERATION",
          "name": "a625_tpusg_gen_attempt#1",
          "startTime": "2025-08-20T11:04:11.683000+00:00",
          "endTime": "2025-08-20T11:04:40.640000+00:00",
          "model": "codestral:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 28957.0,
          "environment": "default",
          "promptTokens": 2048,
          "costDetails": {},
          "totalTokens": 3121,
          "completionTokens": 1073,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-14-04-48-224220_chatcmpl-5801ef3c-3140-4e5c-bdd3-55b4f5d17638",
          "traceId": "a625b929",
          "type": "GENERATION",
          "name": "a625_tpusg_gen_attempt#2",
          "startTime": "2025-08-20T11:04:48.224000+00:00",
          "endTime": "2025-08-20T11:04:53.433000+00:00",
          "model": "codestral:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 5209.0,
          "environment": "default",
          "promptTokens": 2048,
          "costDetails": {},
          "totalTokens": 2168,
          "completionTokens": 120,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-14-04-53-435985_chatcmpl-1fc925d9-5aca-4e7c-bbc9-cf8c9cf4aa98",
          "traceId": "a625b929",
          "type": "GENERATION",
          "name": "a625_tpusg_gen_attempt#3",
          "startTime": "2025-08-20T11:04:53.435000+00:00",
          "endTime": "2025-08-20T11:05:16.312000+00:00",
          "model": "codestral:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 22877.0,
          "environment": "default",
          "promptTokens": 2048,
          "costDetails": {},
          "totalTokens": 2879,
          "completionTokens": 831,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-14-05-24-290452_chatcmpl-1dbb534a-0feb-4ecf-b04a-1af28ee44df9",
          "traceId": "a625b929",
          "type": "GENERATION",
          "name": "a625_tpusg_gen_attempt#4",
          "startTime": "2025-08-20T11:05:24.290000+00:00",
          "endTime": "2025-08-20T11:05:45.748000+00:00",
          "model": "codestral:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 21458.0,
          "environment": "default",
          "promptTokens": 2048,
          "costDetails": {},
          "totalTokens": 2812,
          "completionTokens": 764,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-14-05-53-766049_chatcmpl-5c8c79b2-50b8-4525-93f4-ec9cbaeb43fd",
          "traceId": "a625b929",
          "type": "GENERATION",
          "name": "a625_tpusg_gen_attempt#5",
          "startTime": "2025-08-20T11:05:53.766000+00:00",
          "endTime": "2025-08-20T11:06:02.594000+00:00",
          "model": "codestral:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 8828.0,
          "environment": "default",
          "promptTokens": 2048,
          "costDetails": {},
          "totalTokens": 2310,
          "completionTokens": 262,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "5d54a1d0-f68c-4836-b206-b7751bf580d2",
          "traceId": "a625b929",
          "type": "SPAN",
          "name": "error_a6_tpusg_failure_signal_tpu_sketch_generator",
          "startTime": "2025-08-20T11:06:02.599000+00:00",
          "level": "ERROR",
          "statusMessage": "Failed: Max retries reached with exception: Unexpected error during generation: Generated script is not complete. Please ensure to generate a complete Python script..",
          "calculatedTotalCost": 0.0,
          "environment": "default",
          "promptTokens": 0,
          "costDetails": {},
          "totalTokens": 0,
          "completionTokens": 0,
          "endTime": null,
          "model": null,
          "modelParameters": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null,
          "latency": null
        }
      ],
      "environment": "default",
      "createdAt": "2025-08-20T11:04:12.202Z",
      "updatedAt": "2025-08-20T11:06:08.300Z"
    },
    {
      "id": "2a700122",
      "timestamp": "2025-08-20T11:01:25.102000+00:00",
      "name": "2a70_tpu_sketch_generator",
      "input": null,
      "output": {
        "status": "failed",
        "last_code": "from PIL import Image\nimport cv2\nimport numpy as np\nfrom tflite_runtime.interpreter import Interpreter\n\n# Load TFLite model and allocate tensors.\ninterpreter = Interpreter(model_path=\"detect.tflite\")\ninterpreter.allocate_tensors()\n\n# Get input and output tensors.\ninput_details  = \"/home/mendel/tinyml_autopilot/data//sheeps.mp4\"\noutput_details  = \"/home/mendel/tinyml_autopilot/results/sheeps_detections.mp4\"\nheight = input_details[0]['shape'][1]\nwidth = input_details[0]['shape'][2]\n\nfloating_model = (input_details[0]['dtype'] == np.float32)\n\n# Open the video file\ncap = cv2.VideoCapture(input_video)\n\n# Get the video writer object\nfourcc = cv2.VideoWriter_fourcc(*'mp4v')\nout = cv2.VideoWriter(output_video, fourcc, 30.0, (width, height))\n\nwhile cap.isOpened():\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    # Convert the image from BGR to RGB for processing\n    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n\n    # Resize the image to match expected shape of model's input tensor\n    img = Image.fromarray(rgb_frame).resize((width, height))\n\n    # Preprocess the image data\n    input_data = np.expand_dims(img, axis=0)\n    if floating_model:\n        input_data = (np.float32(input_data) - 127.5) / 127.5\n\n    # Set the tensor to point to the input data to be used for inference\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n\n    # Run inference\n    interpreter.invoke()\n\n    # Get output details\n    boxes = interpreter.get_tensor(output_details[0]['index'])[0]\n    classes = interpreter.get_tensor(output_details[1]['index'])[0]\n    scores = interpreter.get_tensor(output_details[2]['index'])[0]\n\n    # Loop over all detections and draw bounding box on image if confidence is above a threshold\n    for i in range(len(scores)):\n        if ((scores[i] > 0.5) and (scores[i] <= 1.0)):\n            ymin = int(max(1, (boxes[i][0] * img.size[1])))\n            xmin = int(max(1, (boxes[i][1] * img.size[0])))\n            ymax = int(min(img.size[1], (boxes[i][2] * img.size[1])))\n            xmax = int(min(img.size[0], (boxes[i][3] * img.size[0])))\n\n            cv2.rectangle(np.array(img), (xmin, ymin), (xmax, ymax), (10, 255, 0), 2)\n            label = '%d: %d%%' % (classes[i], int(scores[i]*100))\n            labelSize, baseLine = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.7, 2)\n            label_ymin = max(ymin, labelSize[1] + 10)\n            cv2.rectangle(np.array(img), (xmin, label_ymin-labelSize[1]-10), (xmin+labelSize[0], label_ymin+baseLine-10), (10, 255, 0), cv2.FILLED)\n            cv2.putText(np.array(img), label, (xmin, label_ymin-7), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 0), 2)\n\n    # Convert the image back to BGR for writing to video file\n    bgr_frame = cv2.cvtColor(np.array(img), cv2.COLOR_RGB2BGR)\n    out.write(bgr_frame)\n\ncap.release()\nout.release()",
        "last_error": "Max retries reached with error. Last error: Traceback (most recent call last):\n  File \"script_43c00805_1755687837.py\", line 7, in <module>\n    interpreter = Interpreter(model_path=\"detect.tflite\")\n  File \"/home/mendel/tinyml_autopilot/tinyml-env/lib/python3.7/site-packages/tflite_runtime/interpreter.py\", line 351, in __init__\n    experimental_preserve_all_tensors))\nValueError: Could not open 'detect.tflite'.."
      },
      "session_id": "codestral_fc8d_tpusg_batch",
      "metadata": {
        "num_run": 5
      },
      "tags": [
        "benchmark",
        "codestral:latest",
        "tpu_sketch_generator"
      ],
      "latency": 160.388,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-14-01-25-103891_chatcmpl-0937183e-08ac-4d01-af2f-c075c1a9d30a",
          "traceId": "2a700122",
          "type": "GENERATION",
          "name": "2a70_tpusg_gen_attempt#1",
          "startTime": "2025-08-20T11:01:25.103000+00:00",
          "endTime": "2025-08-20T11:01:54.054000+00:00",
          "model": "codestral:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 28951.0,
          "environment": "default",
          "promptTokens": 2048,
          "costDetails": {},
          "totalTokens": 3121,
          "completionTokens": 1073,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-14-02-01-686993_chatcmpl-ea0bd096-9ed5-4be4-a677-b9038aaf8689",
          "traceId": "2a700122",
          "type": "GENERATION",
          "name": "2a70_tpusg_gen_attempt#2",
          "startTime": "2025-08-20T11:02:01.686000+00:00",
          "endTime": "2025-08-20T11:02:08.426000+00:00",
          "model": "codestral:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 6740.0,
          "environment": "default",
          "promptTokens": 2048,
          "costDetails": {},
          "totalTokens": 2229,
          "completionTokens": 181,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-14-02-08-433052_chatcmpl-93919a6d-00e3-462e-bbf6-b7159de1d8b0",
          "traceId": "2a700122",
          "type": "GENERATION",
          "name": "2a70_tpusg_gen_attempt#3",
          "startTime": "2025-08-20T11:02:08.433000+00:00",
          "endTime": "2025-08-20T11:02:37.175000+00:00",
          "model": "codestral:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 28742.0,
          "environment": "default",
          "promptTokens": 2048,
          "costDetails": {},
          "totalTokens": 3116,
          "completionTokens": 1068,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-14-02-44-832290_chatcmpl-8f97ed01-12bf-46a0-963e-244e835d3347",
          "traceId": "2a700122",
          "type": "GENERATION",
          "name": "2a70_tpusg_gen_attempt#4",
          "startTime": "2025-08-20T11:02:44.832000+00:00",
          "endTime": "2025-08-20T11:03:18.263000+00:00",
          "model": "codestral:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 33431.0,
          "environment": "default",
          "promptTokens": 2048,
          "costDetails": {},
          "totalTokens": 3304,
          "completionTokens": 1256,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-14-03-26-025653_chatcmpl-ce374897-b5fc-4876-898d-e405d76a3d39",
          "traceId": "2a700122",
          "type": "GENERATION",
          "name": "2a70_tpusg_gen_attempt#5",
          "startTime": "2025-08-20T11:03:26.025000+00:00",
          "endTime": "2025-08-20T11:03:57.908000+00:00",
          "model": "codestral:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 31883.0,
          "environment": "default",
          "promptTokens": 2048,
          "costDetails": {},
          "totalTokens": 3241,
          "completionTokens": 1193,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "3d2f0ad3-f059-47fb-9e53-e675adbb8aa4",
          "traceId": "2a700122",
          "type": "SPAN",
          "name": "error_2a_tpusg_failure_signal_tpu_sketch_generator",
          "startTime": "2025-08-20T11:04:05.491000+00:00",
          "level": "ERROR",
          "statusMessage": "Failed: Max retries reached with error. Last error: Traceback (most recent call last):\n  File \"script_43c00805_1755687837.py\", line 7, in <module>\n    interpreter = Interpreter(model_path=\"detect.tflite\")\n  File \"/home/mendel/tinyml_autopilot/tinyml-env/lib/python3.7/site-packages/tflite_runtime/interpreter.py\", line 351, in __init__\n    experimental_preserve_all_tensors))\nValueError: Could not open 'detect.tflite'..",
          "calculatedTotalCost": 0.0,
          "environment": "default",
          "promptTokens": 0,
          "costDetails": {},
          "totalTokens": 0,
          "completionTokens": 0,
          "endTime": null,
          "model": null,
          "modelParameters": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null,
          "latency": null
        }
      ],
      "environment": "default",
      "createdAt": "2025-08-20T11:01:25.623Z",
      "updatedAt": "2025-08-20T11:04:10.786Z"
    },
    {
      "id": "030ccfb9",
      "timestamp": "2025-08-20T10:58:46.524000+00:00",
      "name": "030c_tpu_sketch_generator",
      "input": null,
      "output": {
        "status": "failed",
        "last_code": "import cv2\nimport numpy as np\nfrom pycoral.adapters import common\nfrom pycoral.adapters import detect\nfrom pycoral.utils.edgetpu import make_interpreter\nfrom pycoral.utils.dataset import read_label_file\n\n# Load the labels from the file\nlabels = read_label_file('/correct/path/to/your/labels.txt')  # Replace '/correct/path/to/your/labels.txt' with the correct path to your labels file\n\n# Initialize the interpreter with EdgeTPU acceleration\ninterpreter = make_interpreter('/correct/path/to/your/model.tflite')  # Replace '/correct/path/to/your/model.tflite' with the correct path to your model file\ninterpreter.allocate_tensors()\n\n# Get model details\ninput_details  = \"/home/mendel/tinyml_autopilot/data//sheeps.mp4\"\noutput_details  = \"/home/mendel/tinyml_autopilot/results/sheeps_detections.mp4\"\nheight, width = input_details[0]['shape'][1:3]\nfloating_model = (input_details[0]['dtype'] == np.float32)\n\n# Open the video capture device\ncap = cv2.VideoCapture(0)  # Change this to the correct path or index of your video file if needed\n\nwhile cap.isOpened():\n    # Acquire input data\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    # Preprocess data\n    resized_frame = cv2.resize(frame, (width, height))\n    rgb_frame = cv2.cvtColor(resized_frame, cv2.COLOR_BGR2RGB)\n    input_data = np.expand_dims(rgb_frame, axis=0)\n\n    # Quantization handling\n    if floating_model:\n        input_data = (np.float32(input_data) - 127.5) / 127.5\n\n    # Run inference\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n    interpreter.invoke()\n\n    # Get output tensor\n    boxes = interpreter.get_tensor(output_details[0]['index'])[0]\n    classes = interpreter.get_tensor(output_details[1]['index'])[0]\n    scores = interpreter.get_tensor(output_details[2]['index'])[0]\n\n    # Interpret results and handle output\n    for i in range(len(scores)):\n        if ((scores[i] > 0.5) and (scores[i] <= 1.0)):\n            ymin, xmin, ymax, xmax = boxes[i]\n            xmin = int(xmin * frame.shape[1])\n            xmax = int(xmax * frame.shape[1])\n            ymin = int(ymin * frame.shape[0])\n            ymax = int(ymax * frame.shape[0])\n\n            label_id = int(classes[i])\n            label = labels[label_id]\n            score = scores[i]\n\n            # Draw bounding box and label on the frame\n            cv2.rectangle(frame, (xmin, ymin), (xmax, ymax), (10, 255, 0), 4)\n            cv2.putText(frame, f'{label}: {score:.2f}', (xmin, ymin - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (36,255,12), 2)\n\n    # Display the frame\n    cv2.imshow('Object Detection', frame)\n\n    if cv2.waitKey(1) & 0xFF == ord('q'):\n        break\n\n# Cleanup\ncap.release()\ncv2.destroyAllWindows()",
        "last_error": "Max retries reached with error. Last error: Traceback (most recent call last):\n  File \"script_b40e1d67_1755687669.py\", line 9, in <module>\n    labels = read_label_file('/correct/path/to/your/labels.txt')  # Replace '/correct/path/to/your/labels.txt' with the correct path to your labels file\n  File \"/home/mendel/tinyml_autopilot/tinyml-env/lib/python3.7/site-packages/pycoral/utils/dataset.py\", line 36, in read_label_file\n    with open(file_path, 'r', encoding='utf-8') as f:\nFileNotFoundError: [Errno 2] No such file or directory: '/correct/path/to/your/labels.txt'."
      },
      "session_id": "codestral_fc8d_tpusg_batch",
      "metadata": {
        "num_run": 4
      },
      "tags": [
        "benchmark",
        "codestral:latest",
        "tpu_sketch_generator"
      ],
      "latency": 151.466,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-13-58-46-525148_chatcmpl-d2dd3da8-8b98-4214-98fd-cff689cb327d",
          "traceId": "030ccfb9",
          "type": "GENERATION",
          "name": "030c_tpusg_gen_attempt#1",
          "startTime": "2025-08-20T10:58:46.525000+00:00",
          "endTime": "2025-08-20T10:59:15.464000+00:00",
          "model": "codestral:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 28939.0,
          "environment": "default",
          "promptTokens": 2048,
          "costDetails": {},
          "totalTokens": 3121,
          "completionTokens": 1073,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-13-59-23-196228_chatcmpl-fd08bbea-158c-4bbf-8cde-4da29782093f",
          "traceId": "030ccfb9",
          "type": "GENERATION",
          "name": "030c_tpusg_gen_attempt#2",
          "startTime": "2025-08-20T10:59:23.196000+00:00",
          "endTime": "2025-08-20T10:59:29.282000+00:00",
          "model": "codestral:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 6086.0,
          "environment": "default",
          "promptTokens": 2048,
          "costDetails": {},
          "totalTokens": 2202,
          "completionTokens": 154,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-13-59-29-286367_chatcmpl-95dc6ea8-0c56-4b09-ba37-3ae7ade823a9",
          "traceId": "030ccfb9",
          "type": "GENERATION",
          "name": "030c_tpusg_gen_attempt#3",
          "startTime": "2025-08-20T10:59:29.286000+00:00",
          "endTime": "2025-08-20T10:59:57.616000+00:00",
          "model": "codestral:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 28330.0,
          "environment": "default",
          "promptTokens": 2048,
          "costDetails": {},
          "totalTokens": 3099,
          "completionTokens": 1051,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-14-00-05-505188_chatcmpl-e00c23f5-29eb-44c9-86b6-382c1428a667",
          "traceId": "030ccfb9",
          "type": "GENERATION",
          "name": "030c_tpusg_gen_attempt#4",
          "startTime": "2025-08-20T11:00:05.505000+00:00",
          "endTime": "2025-08-20T11:00:34.199000+00:00",
          "model": "codestral:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 28694.0,
          "environment": "default",
          "promptTokens": 2048,
          "costDetails": {},
          "totalTokens": 3112,
          "completionTokens": 1064,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-14-00-42-103507_chatcmpl-63d14888-0ace-484f-9d3b-d4b6830c3b7f",
          "traceId": "030ccfb9",
          "type": "GENERATION",
          "name": "030c_tpusg_gen_attempt#5",
          "startTime": "2025-08-20T11:00:42.103000+00:00",
          "endTime": "2025-08-20T11:01:09.966000+00:00",
          "model": "codestral:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 27863.0,
          "environment": "default",
          "promptTokens": 2048,
          "costDetails": {},
          "totalTokens": 3080,
          "completionTokens": 1032,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "07f48453-1ef8-4d64-a430-7609f29b9e38",
          "traceId": "030ccfb9",
          "type": "SPAN",
          "name": "error_03_tpusg_failure_signal_tpu_sketch_generator",
          "startTime": "2025-08-20T11:01:17.991000+00:00",
          "level": "ERROR",
          "statusMessage": "Failed: Max retries reached with error. Last error: Traceback (most recent call last):\n  File \"script_b40e1d67_1755687669.py\", line 9, in <module>\n    labels = read_label_file('/correct/path/to/your/labels.txt')  # Replace '/correct/path/to/your/labels.txt' with the correct path to your labels file\n  File \"/home/mendel/tinyml_autopilot/tinyml-env/lib/python3.7/site-packages/pycoral/utils/dataset.py\", line 36, in read_label_file\n    with open(file_path, 'r', encoding='utf-8') as f:\nFileNotFoundError: [Errno 2] No such file or directory: '/correct/path/to/your/labels.txt'.",
          "calculatedTotalCost": 0.0,
          "environment": "default",
          "promptTokens": 0,
          "costDetails": {},
          "totalTokens": 0,
          "completionTokens": 0,
          "endTime": null,
          "model": null,
          "modelParameters": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null,
          "latency": null
        }
      ],
      "environment": "default",
      "createdAt": "2025-08-20T10:58:47.045Z",
      "updatedAt": "2025-08-20T11:01:23.300Z"
    },
    {
      "id": "35f02a2c",
      "timestamp": "2025-08-20T10:56:39.028000+00:00",
      "name": "35f0_tpu_sketch_generator",
      "input": null,
      "output": {
        "status": "failed",
        "last_code": "import cv2\nimport numpy as np\nfrom PIL import Image\nfrom edgetpu.detection.engine import DetectionEngine\n\n# Initialize the detection engine with EdgeTPU acceleration\ntry:\n    engine = DetectionEngine('mobilenet_ssd_v2_coco_quant_edgetpu.tflite', threshold=0.5)\nexcept Exception as e:\n    print(f\"Error initializing the detection engine: {e}\")\n    exit()\n\n# Open the video capture device (change this to your input source)\ncap = cv2.VideoCapture(0)\n\nwhile True:\n    # Read a frame from the video capture device\n    ret, frame = cap.read()\n\n    if not ret:\n        break\n\n    # Convert the OpenCV image to PIL Image for EdgeTPU compatibility\n    pil_image = Image.fromarray(frame)\n\n    # Perform inference on the input frame\n    results = engine.detect_with_image(pil_image, threshold=0.5, keep_aspect_ratio=True, relative_coord=False, top_k=10)\n\n    for obj in results:\n        # Extract bounding box coordinates and label index\n        bbox = obj.bounding_box.flatten().tolist()\n        label_index = int(obj.label_id)\n\n        # Get the label name from the labels list included with the model\n        label_name = engine.get_label(label_index)\n\n        # Draw bounding box and label on the frame\n        cv2.rectangle(frame, (int(bbox[0]), int(bbox[1])), (int(bbox[2]), int(bbox[3])), (0, 255, 0), 2)\n        cv2.putText(frame, label_name, (int(bbox[0]), int(bbox[1]) - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (36, 255, 12), 2)\n\n    # Display the frame with bounding boxes and labels\n    cv2.imshow('Object Detection', frame)\n\n    if cv2.waitKey(1) & 0xFF == ord('q'):\n        break\n\n# Release the video capture device and close all windows\ncap.release()\ncv2.destroyAllWindows()",
        "last_error": "Max retries reached with exception: Unexpected error during generation: Generated script is not complete. Please ensure to generate a complete Python script.."
      },
      "session_id": "codestral_fc8d_tpusg_batch",
      "metadata": {
        "num_run": 3
      },
      "tags": [
        "benchmark",
        "codestral:latest",
        "tpu_sketch_generator"
      ],
      "latency": 120.839,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-13-56-39-030556_chatcmpl-e95fb09f-3384-4ff6-8918-bc0a280752aa",
          "traceId": "35f02a2c",
          "type": "GENERATION",
          "name": "35f0_tpusg_gen_attempt#1",
          "startTime": "2025-08-20T10:56:39.030000+00:00",
          "endTime": "2025-08-20T10:57:07.987000+00:00",
          "model": "codestral:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 28957.0,
          "environment": "default",
          "promptTokens": 2048,
          "costDetails": {},
          "totalTokens": 3121,
          "completionTokens": 1073,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-13-57-15-597999_chatcmpl-9b0a7792-b757-4aa5-9a85-d847b3ce526a",
          "traceId": "35f02a2c",
          "type": "GENERATION",
          "name": "35f0_tpusg_gen_attempt#2",
          "startTime": "2025-08-20T10:57:15.597000+00:00",
          "endTime": "2025-08-20T10:57:22.203000+00:00",
          "model": "codestral:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 6606.0,
          "environment": "default",
          "promptTokens": 2048,
          "costDetails": {},
          "totalTokens": 2223,
          "completionTokens": 175,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-13-57-22-209328_chatcmpl-7d52798e-dd0c-43f1-8cd8-875605f0aab6",
          "traceId": "35f02a2c",
          "type": "GENERATION",
          "name": "35f0_tpusg_gen_attempt#3",
          "startTime": "2025-08-20T10:57:22.209000+00:00",
          "endTime": "2025-08-20T10:57:42.519000+00:00",
          "model": "codestral:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 20310.0,
          "environment": "default",
          "promptTokens": 2048,
          "costDetails": {},
          "totalTokens": 2776,
          "completionTokens": 728,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-13-57-50-373518_chatcmpl-b1ec3f89-cc00-4d50-a22e-a5b58c4a0f2d",
          "traceId": "35f02a2c",
          "type": "GENERATION",
          "name": "35f0_tpusg_gen_attempt#4",
          "startTime": "2025-08-20T10:57:50.373000+00:00",
          "endTime": "2025-08-20T10:58:10.739000+00:00",
          "model": "codestral:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 20366.0,
          "environment": "default",
          "promptTokens": 2048,
          "costDetails": {},
          "totalTokens": 2778,
          "completionTokens": 730,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-13-58-18-843689_chatcmpl-cf65a41b-cffc-4497-8031-e8cf4cf12994",
          "traceId": "35f02a2c",
          "type": "GENERATION",
          "name": "35f0_tpusg_gen_attempt#5",
          "startTime": "2025-08-20T10:58:18.843000+00:00",
          "endTime": "2025-08-20T10:58:39.864000+00:00",
          "model": "codestral:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 21021.0,
          "environment": "default",
          "promptTokens": 2048,
          "costDetails": {},
          "totalTokens": 2803,
          "completionTokens": 755,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "d1a08897-85da-4036-9c97-012a923b59fd",
          "traceId": "35f02a2c",
          "type": "SPAN",
          "name": "error_35_tpusg_failure_signal_tpu_sketch_generator",
          "startTime": "2025-08-20T10:58:39.869000+00:00",
          "level": "ERROR",
          "statusMessage": "Failed: Max retries reached with exception: Unexpected error during generation: Generated script is not complete. Please ensure to generate a complete Python script..",
          "calculatedTotalCost": 0.0,
          "environment": "default",
          "promptTokens": 0,
          "costDetails": {},
          "totalTokens": 0,
          "completionTokens": 0,
          "endTime": null,
          "model": null,
          "modelParameters": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null,
          "latency": null
        }
      ],
      "environment": "default",
      "createdAt": "2025-08-20T10:56:39.549Z",
      "updatedAt": "2025-08-20T10:58:45.430Z"
    },
    {
      "id": "41712e67",
      "timestamp": "2025-08-20T10:53:53.263000+00:00",
      "name": "4171_tpu_sketch_generator",
      "input": null,
      "output": {
        "status": "failed",
        "last_code": "import cv2\nimport numpy as np\nfrom interpreter import Interpreter, load_delegate\n\n# Load labels\nwith open('labels.txt', 'r') as f:\n    labels = [line.strip() for line in f.readlines()]\n\n# Load interpreter with EdgeTPU\ninterpreter = Interpreter(model_path='model.tflite', experimental_delegates=[load_delegate('libedgetpu.so.1')])\ninterpreter.allocate_tensors()\ninput_details  = \"/home/mendel/tinyml_autopilot/data//sheeps.mp4\"\noutput_details  = \"/home/mendel/tinyml_autopilot/results/sheeps_detections.mp4\"\n\n# Input acquisition and preprocessing loop\ncap = cv2.VideoCapture(0)  # Use camera as input\nfourcc = cv2.VideoWriter_fourcc(*'mp4v')\nout = cv2.VideoWriter('sheeps_detections.mp4', fourcc, 20.0, (640,  480))\nwhile True:\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    # Preprocess data\n    input_data = np.expand_dims(frame, axis=0)\n    floating_model = (input_details[0]['dtype'] == np.float32)\n    if floating_model:\n        input_data = (np.float32(input_data) - 127.5) / 127.5\n\n    # Inference\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n    interpreter.invoke()\n\n    # Output interpretation and handling loop\n    boxes = interpreter.get_tensor(output_details[0]['index'])[0]  # Bounding box coordinates of detected objects\n    classes = interpreter.get_tensor(output_details[1]['index'])[0]  # Class index of detected objects\n    scores = interpreter.get_tensor(output_details[2]['index'])[0]  # Confidence scores of detected objects\n\n    for i in range(len(scores)):\n        if ((scores[i] > 0.5) and (scores[i] <= 1.0)):\n            ymin = int(max(1, (boxes[i][0] * frame.shape[0])))\n            xmin = int(max(1, (boxes[i][1] * frame.shape[1])))\n            ymax = int(min(frame.shape[0], (boxes[i][2] * frame.shape[0])))\n            xmax = int(min(frame.shape[1], (boxes[i][3] * frame.shape[1])))\n\n            cv2.rectangle(frame, (xmin, ymin), (xmax, ymax), (10, 255, 0), 4)\n            object_name = labels[int(classes[i])]\n            label = '%s: %d%%' % (object_name, int(scores[i]*100))\n            labelSize, baseLine = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.7, 2)\n            label_ymin = max(ymin, labelSize[1] + 10)\n            cv2.rectangle(frame, (xmin, label_ymin-labelSize[1]-10), (xmin+labelSize[0], label_ymin+baseLine-10), (255, 255, 255), cv2.FILLED)\n            cv2.putText(frame, label, (xmin, label_ymin-7), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 0), 2)\n\n    # Write frame into output video file\n    out.write(frame)\n\n    # Display frame\n    cv2.imshow('Object detection', frame)\n\n    if cv2.waitKey(1) == ord('q'):\n        break\n\n# Release the VideoCapture and VideoWriter objects\ncap.release()\nout.release()\ncv2.destroyAllWindows()",
        "last_error": "Max retries reached with error. Last error: Traceback (most recent call last):\n  File \"script_fe17e7c9_1755687384.py\", line 3, in <module>\n    from interpreter import Interpreter, load_delegate\nModuleNotFoundError: No module named 'interpreter'."
      },
      "session_id": "codestral_fc8d_tpusg_batch",
      "metadata": {
        "num_run": 2
      },
      "tags": [
        "benchmark",
        "codestral:latest",
        "tpu_sketch_generator"
      ],
      "latency": 159.36,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-13-53-53-265449_chatcmpl-86615482-c569-443f-bcc0-397ddfe22953",
          "traceId": "41712e67",
          "type": "GENERATION",
          "name": "4171_tpusg_gen_attempt#1",
          "startTime": "2025-08-20T10:53:53.265000+00:00",
          "endTime": "2025-08-20T10:54:22.232000+00:00",
          "model": "codestral:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 28967.0,
          "environment": "default",
          "promptTokens": 2048,
          "costDetails": {},
          "totalTokens": 3121,
          "completionTokens": 1073,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-13-54-29-770083_chatcmpl-abc13e71-6665-4ce9-ae9c-17787b1bfd90",
          "traceId": "41712e67",
          "type": "GENERATION",
          "name": "4171_tpusg_gen_attempt#2",
          "startTime": "2025-08-20T10:54:29.770000+00:00",
          "endTime": "2025-08-20T10:54:39.132000+00:00",
          "model": "codestral:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 9362.0,
          "environment": "default",
          "promptTokens": 2048,
          "costDetails": {},
          "totalTokens": 2335,
          "completionTokens": 287,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-13-54-39-138884_chatcmpl-50232ed4-9406-4259-a0d7-d62f85b25486",
          "traceId": "41712e67",
          "type": "GENERATION",
          "name": "4171_tpusg_gen_attempt#3",
          "startTime": "2025-08-20T10:54:39.138000+00:00",
          "endTime": "2025-08-20T10:55:09.155000+00:00",
          "model": "codestral:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 30017.0,
          "environment": "default",
          "promptTokens": 2048,
          "costDetails": {},
          "totalTokens": 3167,
          "completionTokens": 1119,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-13-55-16-753033_chatcmpl-97f933cf-035f-4da3-9884-23f6c75444a6",
          "traceId": "41712e67",
          "type": "GENERATION",
          "name": "4171_tpusg_gen_attempt#4",
          "startTime": "2025-08-20T10:55:16.753000+00:00",
          "endTime": "2025-08-20T10:55:46.925000+00:00",
          "model": "codestral:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 30172.0,
          "environment": "default",
          "promptTokens": 2048,
          "costDetails": {},
          "totalTokens": 3172,
          "completionTokens": 1124,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-13-55-54-488682_chatcmpl-5fcb7f6c-f243-4255-a081-a441589e680c",
          "traceId": "41712e67",
          "type": "GENERATION",
          "name": "4171_tpusg_gen_attempt#5",
          "startTime": "2025-08-20T10:55:54.488000+00:00",
          "endTime": "2025-08-20T10:56:24.805000+00:00",
          "model": "codestral:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 30317.0,
          "environment": "default",
          "promptTokens": 2048,
          "costDetails": {},
          "totalTokens": 3179,
          "completionTokens": 1131,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "9a4c64ae-1922-4e38-af7b-644d1dfb4d5d",
          "traceId": "41712e67",
          "type": "SPAN",
          "name": "error_41_tpusg_failure_signal_tpu_sketch_generator",
          "startTime": "2025-08-20T10:56:32.625000+00:00",
          "level": "ERROR",
          "statusMessage": "Failed: Max retries reached with error. Last error: Traceback (most recent call last):\n  File \"script_fe17e7c9_1755687384.py\", line 3, in <module>\n    from interpreter import Interpreter, load_delegate\nModuleNotFoundError: No module named 'interpreter'.",
          "calculatedTotalCost": 0.0,
          "environment": "default",
          "promptTokens": 0,
          "costDetails": {},
          "totalTokens": 0,
          "completionTokens": 0,
          "endTime": null,
          "model": null,
          "modelParameters": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null,
          "latency": null
        }
      ],
      "environment": "default",
      "createdAt": "2025-08-20T10:53:53.786Z",
      "updatedAt": "2025-08-20T10:56:37.987Z"
    },
    {
      "id": "3e17f5b0",
      "timestamp": "2025-08-20T10:50:58.704000+00:00",
      "name": "3e17_tpu_sketch_generator",
      "input": null,
      "output": {
        "status": "failed",
        "last_code": "!pip install tflite-runtime",
        "last_error": "Max retries reached with exception: Unexpected error during generation: Generated script is not complete. Please ensure to generate a complete Python script.."
      },
      "session_id": "codestral_fc8d_tpusg_batch",
      "metadata": {
        "num_run": 1
      },
      "tags": [
        "benchmark",
        "codestral:latest",
        "tpu_sketch_generator"
      ],
      "latency": 167.527,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-13-50-58-705004_chatcmpl-8315f0ac-17c5-4384-aa18-f063ebfde0cd",
          "traceId": "3e17f5b0",
          "type": "GENERATION",
          "name": "3e17_tpusg_gen_attempt#1",
          "startTime": "2025-08-20T10:50:58.705000+00:00",
          "endTime": "2025-08-20T10:51:54.050000+00:00",
          "model": "codestral:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 55345.0,
          "environment": "default",
          "promptTokens": 2048,
          "costDetails": {},
          "totalTokens": 3121,
          "completionTokens": 1073,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-13-52-02-055309_chatcmpl-864ffb77-96cf-4c49-88f7-355efce732a6",
          "traceId": "3e17f5b0",
          "type": "GENERATION",
          "name": "3e17_tpusg_gen_attempt#2",
          "startTime": "2025-08-20T10:52:02.055000+00:00",
          "endTime": "2025-08-20T10:52:09.579000+00:00",
          "model": "codestral:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 7524.0,
          "environment": "default",
          "promptTokens": 2048,
          "costDetails": {},
          "totalTokens": 2261,
          "completionTokens": 213,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-13-52-09-585874_chatcmpl-af390b94-971c-4a27-ac2f-7ba106e0febc",
          "traceId": "3e17f5b0",
          "type": "GENERATION",
          "name": "3e17_tpusg_gen_attempt#3",
          "startTime": "2025-08-20T10:52:09.585000+00:00",
          "endTime": "2025-08-20T10:52:38.222000+00:00",
          "model": "codestral:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 28637.0,
          "environment": "default",
          "promptTokens": 2048,
          "costDetails": {},
          "totalTokens": 3111,
          "completionTokens": 1063,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-13-52-46-072966_chatcmpl-54e5271a-08f4-4ab8-be37-de603aa0b228",
          "traceId": "3e17f5b0",
          "type": "GENERATION",
          "name": "3e17_tpusg_gen_attempt#4",
          "startTime": "2025-08-20T10:52:46.072000+00:00",
          "endTime": "2025-08-20T10:53:11.530000+00:00",
          "model": "codestral:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 25458.0,
          "environment": "default",
          "promptTokens": 2048,
          "costDetails": {},
          "totalTokens": 2983,
          "completionTokens": 935,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-13-53-19-347300_chatcmpl-ea5a5c36-3dd8-4b6b-9450-b5d399a0f4f0",
          "traceId": "3e17f5b0",
          "type": "GENERATION",
          "name": "3e17_tpusg_gen_attempt#5",
          "startTime": "2025-08-20T10:53:19.347000+00:00",
          "endTime": "2025-08-20T10:53:46.230000+00:00",
          "model": "codestral:latest",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 26883.0,
          "environment": "default",
          "promptTokens": 2048,
          "costDetails": {},
          "totalTokens": 3041,
          "completionTokens": 993,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "3c0fabd1-0d76-4470-b8d0-8b993870d016",
          "traceId": "3e17f5b0",
          "type": "SPAN",
          "name": "error_3e_tpusg_failure_signal_tpu_sketch_generator",
          "startTime": "2025-08-20T10:53:46.232000+00:00",
          "level": "ERROR",
          "statusMessage": "Failed: Max retries reached with exception: Unexpected error during generation: Generated script is not complete. Please ensure to generate a complete Python script..",
          "calculatedTotalCost": 0.0,
          "environment": "default",
          "promptTokens": 0,
          "costDetails": {},
          "totalTokens": 0,
          "completionTokens": 0,
          "endTime": null,
          "model": null,
          "modelParameters": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null,
          "latency": null
        }
      ],
      "environment": "default",
      "createdAt": "2025-08-20T10:50:59.226Z",
      "updatedAt": "2025-08-20T10:53:52.192Z"
    }
  ],
  "meta": {
    "total_items": 30
  }
}
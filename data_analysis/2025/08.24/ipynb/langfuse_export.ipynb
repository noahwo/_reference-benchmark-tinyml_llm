{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setting up\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ref: https://langfuse.com/docs/query-traces\n",
    "import os\n",
    "import json\n",
    "from langfuse import Langfuse\n",
    "import json\n",
    "import os\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "LOCAL_HOST = True\n",
    "\n",
    "\"\"\"Define session_id\"\"\"\n",
    "# session_id=\"qwen2.5-coder_f4d4_dp_batch\"\n",
    "session_id_list = [\n",
    "    # \"qwen2.5-coder:32b_4e11_tpsg_batch\",\n",
    "    # \"qwen2.5-coder:32b_ae24_tpsg_batch\"\n",
    " \n",
    "    \"codestral_34a5_tpusg_batch\"\n",
    "]\n",
    "\n",
    "\n",
    "\"\"\"Define paths\"\"\"\n",
    " \n",
    "parent_dir = os.path.dirname(os.getcwd())\n",
    "\n",
    " \n",
    "# date = os.path.basename(parent_dir)\n",
    "tex_dir = os.path.join(parent_dir, \"tex\")\n",
    "processed_data_dir = os.path.join(parent_dir, \"processed_data\")\n",
    "raw_export_dir = os.path.join(parent_dir, \"raw_export\")\n",
    "ipynb_dir = os.path.join(parent_dir, \"ipynb\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Export raw data\n",
    "\n",
    "Langfuse added a limit of 20 API invocations per minute. https://langfuse.com/faq/all/api-limits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching traces for session codestral_34a5_tpusg_batch...\n",
      "Fetching observation data for time-17-52-35-498686_chatcmpl-80cc2850-5b21-4f44-8aab-9806aee6f960...\n",
      "Fetching observation data for time-17-53-10-250073_chatcmpl-7fd0cffc-6cd8-451d-b4d3-051be9afb22f...\n",
      "Fetching observation data for time-17-53-14-961906_chatcmpl-c563b8b4-1b4e-4c9d-bbc2-5784836db85f...\n",
      "Fetching observation data for time-17-53-34-138595_chatcmpl-fb9e63c9-bd60-4bac-9670-15d599a253a3...\n",
      "Fetching observation data for time-17-53-45-692666_chatcmpl-4be26a6c-130f-4e58-857e-69c3552e5fb9...\n",
      "Fetching observation data for 520aa6a5-93ed-4b7e-94a1-d8ba03dcc54f...\n",
      "Fetching observation data for time-17-51-25-926780_chatcmpl-16d567e1-425b-4344-b488-9b7f546e4620...\n",
      "Fetching observation data for time-17-52-00-602771_chatcmpl-bd46b69a-2652-49da-a1c0-d1acb5fa7929...\n",
      "Fetching observation data for time-17-52-12-270433_chatcmpl-9d99c501-196f-4ba8-b613-014bb4430cf7...\n",
      "Fetching observation data for time-17-52-18-873808_chatcmpl-ed03bb2c-0496-4955-b33c-c63a4f6e0ad6...\n",
      "Fetching observation data for time-17-52-24-098439_chatcmpl-48df8fab-5927-4675-8d34-389d5d90a259...\n",
      "Fetching observation data for 71e149b9-c672-494f-bc30-0f9b0b2eab70...\n",
      "Fetching observation data for time-17-49-33-909896_chatcmpl-28debb3c-6ab4-414e-8175-fb8f33688d53...\n",
      "Fetching observation data for time-17-50-10-980278_chatcmpl-b129a90c-e210-4da9-acc1-81e1f38d9dbb...\n",
      "Fetching observation data for time-17-50-16-951707_chatcmpl-328679f8-b454-4ca7-bd57-fc7e08441900...\n",
      "Fetching observation data for time-17-50-33-503940_chatcmpl-9190de63-14c3-4fb0-820d-89601a7ac83c...\n",
      "Fetching observation data for time-17-50-50-069503_chatcmpl-1b07b9fa-6d88-42ec-a9de-ac8e85b5af76...\n",
      "Fetching observation data for a304e71b-2a8c-480a-91bb-ffb1dbe68602...\n",
      "Fetching observation data for time-17-47-40-065033_chatcmpl-899da8f3-efc8-4884-9e91-3cdad552210d...\n",
      "Fetching observation data for time-17-48-16-881689_chatcmpl-510653e5-922b-4ecc-b271-f1c2aaf26e5f...\n",
      "Fetching observation data for time-17-48-49-499998_chatcmpl-f9b8a615-b5b9-4003-8682-2d1114c108cd...\n",
      "Fetching observation data for time-17-49-11-573972_chatcmpl-1e0c7c8c-8074-45ad-8050-93db34a60ad9...\n",
      "Fetching observation data for time-17-49-17-559503_chatcmpl-4ca572d0-e722-4f36-b23d-089b604f156a...\n",
      "Fetching observation data for fe744153-08cd-4304-801e-ff7794fcdade...\n",
      "Fetching observation data for time-17-45-11-513658_chatcmpl-65c80c61-4c52-4082-9f02-c6517777d79e...\n",
      "Fetching observation data for time-17-45-46-402014_chatcmpl-1c3bb5d2-82ff-490d-a63a-b3a23a5f9d38...\n",
      "Fetching observation data for time-17-46-12-930714_chatcmpl-be7e9e51-933e-4ab1-8cc1-f81399d1823c...\n",
      "Fetching observation data for time-17-42-54-859055_chatcmpl-29992a89-cdfe-4463-b212-d7008b65b7a8...\n",
      "Fetching observation data for time-17-43-31-712946_chatcmpl-c92ac9ef-0609-4cc1-8aaf-d5b76b79851e...\n",
      "Fetching observation data for time-17-43-38-658091_chatcmpl-63c03c85-3612-4f70-a6c5-eba18aaed458...\n",
      "Fetching observation data for time-17-44-18-822125_chatcmpl-f31cf983-479c-4c98-a5b0-31264f0a1bb0...\n",
      "Fetching observation data for time-17-44-48-518322_chatcmpl-c1f7d126-1ad6-485f-9b35-3159e063fcbf...\n",
      "Fetching observation data for 8104c703-6efe-436b-8f96-15a83c91736d...\n",
      "Fetching observation data for time-17-40-10-859086_chatcmpl-e68c6f77-c740-4360-bb54-05c235ab57e1...\n",
      "Fetching observation data for time-17-40-47-915464_chatcmpl-0925fd0e-deb3-4c56-8057-07877538481c...\n",
      "Fetching observation data for time-17-41-25-122524_chatcmpl-9f7e1c6e-e4e9-4bd8-acaf-560314d083bc...\n",
      "Fetching observation data for time-17-42-02-248023_chatcmpl-7c1ddbc7-a4bb-4c3e-bf59-c87ff34dd6a8...\n",
      "Fetching observation data for time-17-42-42-068300_chatcmpl-46cb7f59-7745-4377-9fa4-e65a340c0e82...\n",
      "Fetching observation data for 0e7cb764-ddae-4064-a9ca-89af7f02dd5e...\n",
      "Fetching observation data for time-17-37-46-305183_chatcmpl-a5d267fd-6402-4aee-81c4-688761407b9d...\n",
      "Fetching observation data for time-17-38-21-002921_chatcmpl-3571ab44-84dd-4bb0-b534-dcc388bb3cd2...\n",
      "Fetching observation data for time-17-38-48-612852_chatcmpl-f76e2634-6b8d-49a4-8e68-ffcd139f873d...\n",
      "Fetching observation data for time-17-39-28-027824_chatcmpl-fef08f32-8206-4752-8dab-a31ca3360ac2...\n",
      "Fetching observation data for time-17-39-37-867365_chatcmpl-2cfade2a-200e-4ae3-ab9c-db300b836f59...\n",
      "Fetching observation data for 177c8c29-f5ee-4797-9923-a2d398bce8c9...\n",
      "Fetching observation data for time-17-34-29-681522_chatcmpl-bdc00bb9-ff9a-4fe6-8a0d-9f7089f8bd2f...\n",
      "Fetching observation data for time-17-35-04-547975_chatcmpl-dd40f90b-2f2f-4f8e-9b4c-6dbe12f65527...\n",
      "Fetching observation data for time-17-35-21-580805_chatcmpl-99a25a0e-cdd1-4c76-8026-f13269990cb9...\n",
      "Fetching observation data for time-17-35-51-760771_chatcmpl-87740f08-40d4-461b-8d73-36e7efbf4380...\n",
      "Fetching observation data for time-17-36-24-735634_chatcmpl-2db2fda2-da33-425d-b53e-7a3ba51cda67...\n",
      "Fetching observation data for time-17-32-57-127799_chatcmpl-1e371dd6-d9a7-4819-9060-f0f8aba496b6...\n",
      "Fetching observation data for time-17-33-33-868658_chatcmpl-b20877b2-f8cd-41a3-ac1e-13ef06ce0aa9...\n",
      "Fetching observation data for time-17-33-39-573886_chatcmpl-0f826450-4149-47cf-8e72-5159603e0583...\n",
      "Fetching observation data for time-17-34-00-393139_chatcmpl-f3c5cdb9-e38d-4124-8de8-5dba6857a0a6...\n",
      "Fetching observation data for time-17-34-13-841367_chatcmpl-fb097e6d-7b01-4cf2-b774-e09145d8434e...\n",
      "Fetching observation data for 5e7cdc40-ad18-40f1-a966-652a5eeaed0a...\n",
      "Fetching observation data for time-17-31-12-558194_chatcmpl-ce94ffd0-d7cc-4747-9154-aab44fe76923...\n",
      "Fetching observation data for time-17-31-47-546787_chatcmpl-0d8d3c5e-e016-420a-9e03-472cfab675b3...\n",
      "Fetching observation data for time-17-31-54-711294_chatcmpl-dddfacad-d762-4a38-9e1b-e4d4ebb9e233...\n",
      "Fetching observation data for time-17-32-01-683132_chatcmpl-11f0ae2d-a78a-45bd-b115-eac1824e1176...\n",
      "Fetching observation data for time-17-32-41-071350_chatcmpl-e9086efc-0c44-4575-ad0f-95d849b6f223...\n",
      "Fetching observation data for d591cdcc-a814-4eb7-b040-e6566a618a1f...\n",
      "Fetching observation data for time-17-29-19-004804_chatcmpl-493d83ca-f4fb-4cf5-9968-cb0e74cfd70d...\n",
      "Fetching observation data for time-17-29-55-820758_chatcmpl-262a0344-2178-4e82-863f-f8e8a0f4f9f1...\n",
      "Fetching observation data for time-17-30-03-146711_chatcmpl-301a3433-ebc3-4c9a-8bd8-a512139835e0...\n",
      "Fetching observation data for time-17-30-13-476147_chatcmpl-37156360-0857-48c8-b35d-4bb17280c25f...\n",
      "Fetching observation data for time-17-30-39-840670_chatcmpl-86420f67-3947-48f4-a1d3-20430a641f76...\n",
      "Fetching observation data for fab24a7f-c1d6-4d82-99f5-de5e591b1223...\n",
      "Fetching observation data for time-17-27-08-099530_chatcmpl-9c046ee6-3bba-4a46-a041-9656d8d6f027...\n",
      "Fetching observation data for time-17-27-44-879755_chatcmpl-14ba9376-bec9-4860-bfa9-17ceedafdb1c...\n",
      "Fetching observation data for time-17-27-54-689613_chatcmpl-cb978dbe-d780-493d-ab0a-46416e3842df...\n",
      "Fetching observation data for time-17-28-22-170194_chatcmpl-32594e79-d752-4ab4-92fe-152006653773...\n",
      "Fetching observation data for time-17-28-47-191413_chatcmpl-f7919a01-49ef-4204-8b95-89c97fdaff75...\n",
      "Fetching observation data for 6c1e0eef-5509-4fd5-8b7c-a6a220ee3816...\n",
      "Fetching observation data for time-17-24-21-481992_chatcmpl-79c275cb-0819-426d-bb90-d55af8c44de4...\n",
      "Fetching observation data for time-17-24-58-464537_chatcmpl-3758c473-7967-4016-9be6-464266d7c0ae...\n",
      "Fetching observation data for time-17-25-05-276832_chatcmpl-c77979e2-a54e-45f7-91f5-d28c00c6e322...\n",
      "Fetching observation data for time-17-25-46-141216_chatcmpl-68c505a0-f4b2-4992-ad46-ec5c58950257...\n",
      "Fetching observation data for time-17-26-25-388523_chatcmpl-f723347b-1081-4921-98a6-bb31114bb641...\n",
      "Fetching observation data for 8f78c018-350f-417f-8b88-698249c11f59...\n",
      "Fetching observation data for time-17-21-38-939579_chatcmpl-c5d5d469-5170-49a7-81bf-cdebee940d5f...\n",
      "Fetching observation data for time-17-22-13-650697_chatcmpl-f9eb292c-8752-4aca-8a1f-372cba1c1bb0...\n",
      "Fetching observation data for time-17-22-19-243129_chatcmpl-ac28c3b6-3c96-4542-8e40-ce3e7bd6a6b3...\n",
      "Fetching observation data for time-17-22-59-929584_chatcmpl-ff4cce58-33d2-43d6-855f-eca7338814b5...\n",
      "Fetching observation data for time-17-23-37-438354_chatcmpl-77d2cec1-20bc-4730-9175-b9ae46dd35d8...\n",
      "Fetching observation data for ad7ac94e-f90f-4821-9114-8eaff22b96c9...\n",
      "Fetching observation data for time-17-20-26-419713_chatcmpl-602918c4-7907-4125-80bd-5419f6c2f26f...\n",
      "Fetching observation data for time-17-21-01-647071_chatcmpl-8c0a038a-4be4-402a-aede-18ecf2d29584...\n",
      "Fetching observation data for time-17-21-12-533907_chatcmpl-1a915c55-1984-4d18-9d6b-994178633a8f...\n",
      "Fetching observation data for time-17-21-20-819168_chatcmpl-266d1414-3991-4893-b1da-fc962c2889aa...\n",
      "Fetching observation data for time-17-21-27-283798_chatcmpl-5ead9863-eda9-49b1-b5ab-c1b0518184a1...\n",
      "Fetching observation data for 51657786-a1a4-4126-a3df-2a0456833f5c...\n",
      "Fetching observation data for time-17-18-36-877669_chatcmpl-5d271a31-22c8-4fa6-aca2-66e04bb5c4ad...\n",
      "Fetching observation data for time-17-19-14-036736_chatcmpl-86969690-0c8e-478a-a503-c9f346301a27...\n",
      "Fetching observation data for time-17-19-20-091051_chatcmpl-b578d317-c4fb-4deb-81ff-bbdb7519d853...\n",
      "Fetching observation data for time-17-19-43-871340_chatcmpl-f0ece6d2-2280-4b0e-9107-4ad63b62ac93...\n",
      "Fetching observation data for time-17-19-55-012573_chatcmpl-36643f15-a615-48d3-9e0b-395bb1db92ad...\n",
      "Fetching observation data for 3531a45a-39f6-4b0a-8ea7-aff00bd305dd...\n",
      "Fetching observation data for time-17-15-21-629950_chatcmpl-1fb7c8c7-e7d0-46dd-a035-71e1986b0ceb...\n",
      "Fetching observation data for time-17-15-58-674669_chatcmpl-c6b231df-56ec-4819-986c-c06a9f84a79f...\n",
      "Fetching observation data for time-17-16-05-275257_chatcmpl-eaaa2451-50f9-4277-a561-8549bb82dc12...\n",
      "Fetching observation data for time-17-16-23-761723_chatcmpl-9be8bb38-f896-466d-883b-be616e1ea9ae...\n",
      "Fetching observation data for time-17-16-34-197373_chatcmpl-a3d4868d-b509-4bd1-bc6b-d1c317b48afc...\n",
      "Fetching observation data for 41379237-6ec2-4bad-a260-f8236dcb54f7...\n",
      "Fetching observation data for time-17-13-01-108283_chatcmpl-63a8c9c0-8921-443e-a1fa-0bb55ecc9208...\n",
      "Fetching observation data for time-17-13-38-007152_chatcmpl-854f3049-33b1-4abb-a68c-5316210056b1...\n",
      "Fetching observation data for time-17-13-44-910915_chatcmpl-4b8a2c6c-40af-4ca5-9c02-47a3c025e71e...\n",
      "Fetching observation data for time-17-14-15-961966_chatcmpl-b0468e63-2faa-4778-adb5-d832a548918f...\n",
      "Fetching observation data for time-17-14-34-587422_chatcmpl-4d23dcd3-790f-43ce-bd5f-abab8f4c74fd...\n",
      "Fetching observation data for 6fea0a45-665b-4c11-92c8-184b2fe590c4...\n",
      "Fetching observation data for time-17-11-03-568781_chatcmpl-7f923ca6-1899-4c22-819b-e2c053c0d6b7...\n",
      "Fetching observation data for time-17-11-38-590638_chatcmpl-ada2a575-8951-426b-a73e-3a053e4a5354...\n",
      "Fetching observation data for time-17-11-43-277255_chatcmpl-d3fbc7cd-1fa7-439c-85b6-064da0d34ecf...\n",
      "Fetching observation data for time-17-12-15-004634_chatcmpl-85ac46b1-5a0e-40c2-83fa-4383129488b5...\n",
      "Fetching observation data for time-17-12-45-654699_chatcmpl-5e0ddd2b-ab57-4121-863a-ca7d63ec41d8...\n",
      "Fetching observation data for 772aba33-d522-4530-94c9-ce9c5f6ba4f2...\n",
      "Fetching observation data for time-17-08-38-992207_chatcmpl-c8d465ea-c1a3-451b-9049-aa69f880361c...\n",
      "Fetching observation data for time-17-09-15-722998_chatcmpl-57f441b9-4bbe-4f18-bb7f-321f17d14899...\n",
      "Fetching observation data for time-17-09-20-584160_chatcmpl-7a0305fe-ef88-4336-b446-f5fcd704ffdb...\n",
      "Fetching observation data for time-17-09-52-192907_chatcmpl-dc3d2a7d-196f-48a0-bb79-91a10f62e10c...\n",
      "Fetching observation data for time-17-10-24-440869_chatcmpl-b7505acd-be62-43b8-8c09-8c08a115562e...\n",
      "Fetching observation data for f9ae99b9-1c49-4295-a936-7bc0d5a18336...\n",
      "Fetching observation data for time-17-07-26-353566_chatcmpl-256ea74a-1f5f-41df-8704-ed5d29825d65...\n",
      "Fetching observation data for time-17-08-03-225884_chatcmpl-4a9f9e85-5d5f-44af-9c76-d6509f13d01a...\n",
      "Fetching observation data for time-17-08-09-206138_chatcmpl-5e241aa8-97f8-4c49-94c8-44309dc1bb10...\n",
      "Fetching observation data for time-17-08-15-369769_chatcmpl-3b94db27-15c1-4005-a49f-1850aeaecbb9...\n",
      "Fetching observation data for time-17-08-21-244238_chatcmpl-b299458a-7abc-4e16-8db2-e9aadcdaef49...\n",
      "Fetching observation data for 6967d3f4-6b16-4215-9a50-7bbc35bdef07...\n",
      "Fetching observation data for time-17-05-47-841856_chatcmpl-f0822ba2-835c-4285-b255-9e783ea5aa7e...\n",
      "Fetching observation data for time-17-06-22-855048_chatcmpl-1afa779d-c8f8-46f5-8de9-38b5234c32a9...\n",
      "Fetching observation data for time-17-06-40-390276_chatcmpl-f44647b7-2e9c-419c-84dc-7b403377b506...\n",
      "Fetching observation data for time-17-07-01-412144_chatcmpl-adb8fca3-f7f0-4b27-8ab5-7ce016f3de08...\n",
      "Fetching observation data for time-17-07-10-676187_chatcmpl-e8b25978-0de9-4229-af4d-c239f9bee4fd...\n",
      "Fetching observation data for 6535f297-7d1b-4a00-b3e6-c861151e3035...\n",
      "Fetching observation data for time-17-02-24-280599_chatcmpl-26956302-5bce-4133-bb96-e3446c8329d8...\n",
      "Fetching observation data for time-17-03-01-148960_chatcmpl-1e88b8d0-52bb-4a3b-9eb2-21f5d40735ec...\n",
      "Fetching observation data for time-17-03-37-920105_chatcmpl-985f115c-f829-4efc-9588-86d7f737c742...\n",
      "Fetching observation data for time-17-04-15-598090_chatcmpl-c28a3131-3dfc-4230-b3a1-664a16c42a76...\n",
      "Fetching observation data for time-16-59-43-766007_chatcmpl-03485abe-e11e-4d7f-96bd-72f639132fb8...\n",
      "Fetching observation data for time-17-00-20-706533_chatcmpl-add8fe6a-e108-4e92-969a-5838d91aa28c...\n",
      "Fetching observation data for time-17-00-26-388757_chatcmpl-41886cbe-e027-4a25-8c55-87bf88828528...\n",
      "Fetching observation data for time-17-01-04-253793_chatcmpl-6cac860f-bc9e-401d-bb72-b9a24b288f64...\n",
      "Fetching observation data for time-17-01-41-801597_chatcmpl-8f92e9d3-2a88-4ca2-b8a5-65bf1bdec993...\n",
      "Fetching observation data for 8cff393a-95c6-4725-9bf1-375f69857941...\n",
      "Fetching observation data for time-16-57-07-250044_chatcmpl-5163a458-e113-4e3d-91c0-b118f2c405da...\n",
      "Fetching observation data for time-16-57-44-121748_chatcmpl-65a25d55-a565-4bdf-808a-1318a96033d9...\n",
      "Fetching observation data for time-16-57-49-037334_chatcmpl-0594baff-5341-46a4-b722-8a7e61124884...\n",
      "Fetching observation data for time-16-58-25-810441_chatcmpl-35ee56c0-7475-4a92-9f44-3d43a14827e1...\n",
      "Fetching observation data for time-16-59-01-343833_chatcmpl-c6be21cb-b66c-4ab3-a73a-4fe4643739d9...\n",
      "Fetching observation data for 89b9d859-2981-4a4a-a2d3-300a45c9c673...\n",
      "Fetching observation data for time-16-54-57-744345_chatcmpl-6c1b53ce-508e-459e-b45e-c57d9aaf7210...\n",
      "Fetching observation data for time-16-55-34-958446_chatcmpl-15d11448-8636-46be-983c-d3bb18480d7c...\n",
      "Fetching observation data for time-16-55-40-134834_chatcmpl-3f573819-1b99-4322-a2c4-10d02a9daf43...\n",
      "Fetching observation data for time-16-56-08-255807_chatcmpl-876014a9-1e11-46bb-aed2-87bd7e59a05b...\n",
      "Fetching observation data for time-16-56-28-467871_chatcmpl-6255f5b5-8373-4c93-bdc7-1998da16eadc...\n",
      "Fetching observation data for ebee3d6b-e216-4b5d-a6be-0f777507d37a...\n",
      "Fetching observation data for time-16-53-54-234711_chatcmpl-12d00c53-87b0-4389-955c-4f85ded40048...\n",
      "Fetching observation data for time-16-54-29-268024_chatcmpl-5f120da5-3393-490f-a3bb-5d8965247052...\n",
      "Fetching observation data for time-16-54-35-646758_chatcmpl-cea751a1-a77a-4b2b-831d-98541806afbe...\n",
      "Fetching observation data for time-16-54-40-856461_chatcmpl-5a3a7da0-52b7-4d79-9925-6110c18c2a17...\n",
      "Fetching observation data for time-16-54-45-561428_chatcmpl-21bdd342-9430-4ddc-801b-96914fb57eb9...\n",
      "Fetching observation data for 71b45620-0da8-4fed-8b6f-c4769ace582b...\n",
      "Fetching observation data for time-16-51-44-688359_chatcmpl-a309d865-ccc4-48ad-a6c8-67da56f9664d...\n",
      "Fetching observation data for time-16-52-21-469254_chatcmpl-6111465b-a15c-43e4-b2d8-598d1937849f...\n",
      "Fetching observation data for time-16-52-28-230708_chatcmpl-5d5fe95e-4c7d-48dd-a3f5-1625f761ed06...\n",
      "Fetching observation data for time-16-52-48-323165_chatcmpl-d112d847-67ce-46c8-97f4-4af0003105e2...\n",
      "Fetching observation data for time-16-53-18-744158_chatcmpl-846766a6-52d3-4453-86d0-6edd7b5c4415...\n",
      "Fetching observation data for ab9f00d3-4f80-4e48-b487-7566470ae89a...\n",
      "Fetching observation data for time-16-49-39-186892_chatcmpl-40d9d573-25b6-4cdf-ac4f-059bbfd537a3...\n",
      "Fetching observation data for time-16-50-42-549438_chatcmpl-506497f5-f99f-4fdd-8c12-84d2b1145a1c...\n",
      "Fetching observation data for time-16-50-48-679797_chatcmpl-8437cd92-6249-4c38-864c-008221c6d47a...\n",
      "Fetching observation data for time-16-51-02-269245_chatcmpl-883afa7d-c9af-41dc-b1d0-12ec4e8cac6a...\n",
      "Fetching observation data for time-16-51-18-137776_chatcmpl-220d647a-0a6e-435e-8c50-30f55eb33638...\n",
      "Fetching observation data for 48b4176a-2a81-47fe-9e9c-616675facd47...\n",
      "Raw JSON saved to: /home/han/Projects/reference-benchmark-tinyml_llm/data_analysis/2025/08.24/raw_export/raw_codestral_34a5_tpusg_batch.json\n"
     ]
    }
   ],
   "source": [
    "# ALTERNATIVE TO 2.\n",
    "import os\n",
    "import json\n",
    "from time import sleep\n",
    "from langfuse import Langfuse\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "\n",
    "# LANGFUSE_SERVICE_PUBLIC_KEY = \"pk-lf-559a2c0f-ee29-4c32-944c-bf73b5f0ce28\"\n",
    "# LANGFUSE_SERVICE_SECRET_KEY = \"sk-lf-75f8bf7f-a5db-4756-b0dd-d758a2a292c8\"\n",
    "# LANGFUSE_SERVICE_HOST = \"https://langfuse.hann.fi\"\n",
    "\n",
    "\n",
    "if LOCAL_HOST:\n",
    "    langfuse = Langfuse(\n",
    "        secret_key=\"sk-lf-75f8bf7f-a5db-4756-b0dd-d758a2a292c8\",\n",
    "        public_key=\"pk-lf-559a2c0f-ee29-4c32-944c-bf73b5f0ce28\",\n",
    "        host=\"https://langfuse.hann.fi\",\n",
    "    )\n",
    "else:\n",
    "    langfuse = Langfuse(\n",
    "        secret_key=LANGFUSE_SERVICE_SECRET_KEY,\n",
    "        public_key=LANGFUSE_SERVICE_PUBLIC_KEY,\n",
    "        host=LANGFUSE_SERVICE_HOST,\n",
    "    )\n",
    "\n",
    "API_invok_count = 0\n",
    "query_range_num_run = {\"start\": 0, \"end\": 1}\n",
    "\n",
    "\n",
    "class CustomJSONEncoder(json.JSONEncoder):\n",
    "    def __init__(self, *args, LOCAL_HOST=True, **kwargs):\n",
    "        self.LOCAL_HOST = LOCAL_HOST\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "    def default(self, obj):\n",
    "        if isinstance(obj, datetime):\n",
    "            return obj.isoformat()\n",
    "        if hasattr(obj, \"__dict__\"):\n",
    "            data = obj.__dict__.copy()\n",
    "            if \"observations\" in data:\n",
    "                data[\"observations\"] = [\n",
    "                    fetch_observation_data(obs, self.LOCAL_HOST)\n",
    "                    for obs in data[\"observations\"]\n",
    "                ]\n",
    "\n",
    "            return data\n",
    "        return super().default(obj)\n",
    "\n",
    "\n",
    "def fetch_observation_data(observation_id, LOCAL_HOST):\n",
    "    \"\"\"\n",
    "    Fetches observation data from Langfuse and returns its dictionary representation.\n",
    "    \"\"\"\n",
    "    print(f\"Fetching observation data for {observation_id}...\")\n",
    "    global API_invok_count\n",
    "    if API_invok_count >= 0 and not LOCAL_HOST:\n",
    "        print(\"Waiting for 3 seconds to fetch observation data...\")\n",
    "        for _ in tqdm(range(3), desc=\"Progress\", unit=\"s\"):\n",
    "            sleep(1)\n",
    "        API_invok_count = 0\n",
    "\n",
    "    observation_response = langfuse.fetch_observation(observation_id)\n",
    "    API_invok_count += 1\n",
    "\n",
    "    return observation_response.data.dict()\n",
    "\n",
    "\n",
    "def fetch_and_save_complete_data(session_id_list, raw_export_dir, LOCAL_HOST):\n",
    "    \"\"\"\n",
    "    Fetches complete trace data for each session ID and saves it to JSON files.\n",
    "\n",
    "    Parameters:\n",
    "        session_id_list (list): List of session IDs to process.\n",
    "        raw_export_dir (str): Directory path to save raw JSON files.\n",
    "    \"\"\"\n",
    "\n",
    "    def save_complete_data(session_id):\n",
    "        global API_invok_count\n",
    "        if API_invok_count >= 0 and not LOCAL_HOST:\n",
    "            print(\"Waiting for 4 seconds to fetch traces...\")\n",
    "            for _ in tqdm(range(4), desc=\"Progress\", unit=\"s\"):\n",
    "                sleep(1)\n",
    "            API_invok_count = 0\n",
    "\n",
    "        fetch_traces_response = langfuse.fetch_traces(session_id=session_id)\n",
    "        API_invok_count += 1\n",
    "\n",
    "        print(f\"Fetching traces for session {session_id}...\")\n",
    "        # Create directories if they don't exist\n",
    "        os.makedirs(raw_export_dir, exist_ok=True)\n",
    "\n",
    "        # Save complete data to JSON file\n",
    "        # if session_id.startswith(\"da0a\"):\n",
    "        #     session_id = \"phi4_\" + session_id\n",
    "        if \"tpsg\" in session_id:\n",
    "            session_id_ = session_id.replace(\"tpsg\", \"tpusg\")\n",
    "        else:\n",
    "            session_id_ = session_id\n",
    "            \n",
    "        raw_path = os.path.join(raw_export_dir, f\"raw_{session_id_}.json\")\n",
    "        with open(raw_path, \"w\") as f:\n",
    "            json.dump(fetch_traces_response, f, cls=CustomJSONEncoder, indent=2)\n",
    "\n",
    "        print(f\"Raw JSON saved to: {raw_path}\")\n",
    "\n",
    "    for session_id in session_id_list:\n",
    "        save_complete_data(session_id)\n",
    "\n",
    "\n",
    "fetch_and_save_complete_data(session_id_list, raw_export_dir, LOCAL_HOST)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Trim data\n",
    "\n",
    "Here also intercept the runs with fatal errors that need to be excluded from the analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPAN error_3b_tpusg_failure_signal_tpu_sketch_generator: Failed: Max retries reached with exception: Unexpected error during generation: The output is not a valid code block. Follow the instructions in the prompt return a complete, correct Python script enclosed in a single ```python\n",
      "<generated_code>\n",
      "``` block..\n",
      "SPAN error_88_tpusg_failure_signal_tpu_sketch_generator: Failed: Max retries reached with exception: Unexpected error during generation: The output is not a valid code block. Follow the instructions in the prompt return a complete, correct Python script enclosed in a single ```python\n",
      "<generated_code>\n",
      "``` block..\n",
      "SPAN error_81_tpusg_failure_signal_tpu_sketch_generator: Failed: Max retries reached with error. Last error: Traceback (most recent call last):\n",
      "  File \"script_8047780a_1755701470.py\", line 4, in <module>\n",
      "    import tensorflow as tf\n",
      "ModuleNotFoundError: No module named 'tensorflow'.\n",
      "SPAN error_6c_tpusg_failure_signal_tpu_sketch_generator: Failed: Max retries reached with exception: Unexpected error during generation: The output is not a valid code block. Follow the instructions in the prompt return a complete, correct Python script enclosed in a single ```python\n",
      "<generated_code>\n",
      "``` block..\n",
      "SPAN error_24_tpusg_failure_signal_tpu_sketch_generator: Failed: Max retries reached with exception: Unexpected error during generation: Generated script is not complete. Please ensure to generate a complete Python script..\n",
      "SPAN error_4f_tpusg_failure_signal_tpu_sketch_generator: Failed: Max retries reached with exception: Unexpected error during generation: Generated script is not complete. Please ensure to generate a complete Python script..\n",
      "SPAN error_d9_tpusg_failure_signal_tpu_sketch_generator: Failed: Max retries reached with exception: Unexpected error during generation: Generated script is not complete. Please ensure to generate a complete Python script..\n",
      "SPAN error_92_tpusg_failure_signal_tpu_sketch_generator: Failed: Max retries reached with exception: Unexpected error during generation: The output is not a valid code block. Follow the instructions in the prompt return a complete, correct Python script enclosed in a single ```python\n",
      "<generated_code>\n",
      "``` block..\n",
      "SPAN error_cb_tpusg_failure_signal_tpu_sketch_generator: Failed: Max retries reached with exception: Unexpected error during generation: Generated script is not complete. Please ensure to generate a complete Python script..\n",
      "SPAN error_66_tpusg_failure_signal_tpu_sketch_generator: Failed: Max retries reached with error. Last error: Traceback (most recent call last):\n",
      "  File \"script_0babd6ea_1755700258.py\", line 7, in <module>\n",
      "    with open('coco_labels.txt', 'r') as f:\n",
      "FileNotFoundError: [Errno 2] No such file or directory: 'coco_labels.txt'.\n",
      "SPAN error_bb_tpusg_failure_signal_tpu_sketch_generator: Failed: Max retries reached with error. Last error: Traceback (most recent call last):\n",
      "  File \"script_e9a32880_1755700144.py\", line 7, in <module>\n",
      "    interpreter = make_interpreter('/path/to/your/model.tflite')  # Replace '/path/to/your/model.tflite' with your actual model path\n",
      "  File \"/home/mendel/tinyml_autopilot/tinyml-env/lib/python3.7/site-packages/pycoral/utils/edgetpu.py\", line 93, in make_interpreter\n",
      "    model_path=model_path_or_content, experimental_delegates=delegates)\n",
      "  File \"/home/mendel/tinyml_autopilot/tinyml-env/lib/python3.7/site-packages/tflite_runtime/interpreter.py\", line 351, in __init__\n",
      "    experimental_preserve_all_tensors))\n",
      "ValueError: Could not open '/path/to/your/model.tflite'..\n",
      "SPAN error_87_tpusg_failure_signal_tpu_sketch_generator: Failed: Max retries reached with error. Last error: Traceback (most recent call last):\n",
      "  File \"script_180f7e32_1755700014.py\", line 3, in <module>\n",
      "    from tensorflow.lite.python.interpreter import load_delegate, Interpreter\n",
      "ModuleNotFoundError: No module named 'tensorflow'.\n",
      "SPAN error_bb_tpusg_failure_signal_tpu_sketch_generator: Failed: Max retries reached with error. Last error: Traceback (most recent call last):\n",
      "  File \"script_ae5ecb35_1755699847.py\", line 7, in <module>\n",
      "    with open('labels.txt', 'r') as f:\n",
      "FileNotFoundError: [Errno 2] No such file or directory: 'labels.txt'.\n",
      "SPAN error_84_tpusg_failure_signal_tpu_sketch_generator: Failed: Max retries reached with exception: Unexpected error during generation: The output is not a valid code block. Follow the instructions in the prompt return a complete, correct Python script enclosed in a single ```python\n",
      "<generated_code>\n",
      "``` block..\n",
      "SPAN error_5c_tpusg_failure_signal_tpu_sketch_generator: Failed: Max retries reached with exception: Unexpected error during generation: Generated script is not complete. Please ensure to generate a complete Python script..\n",
      "SPAN error_fe_tpusg_failure_signal_tpu_sketch_generator: Failed: Max retries reached with error. Last error: Remote execution timeout after 60 seconds.\n",
      "SPAN error_61_tpusg_failure_signal_tpu_sketch_generator: Failed: Max retries reached with error. Last error: Traceback (most recent call last):\n",
      "  File \"script_00896f35_1755699307.py\", line 7, in <module>\n",
      "    with open('labels.txt', 'r') as f:\n",
      "FileNotFoundError: [Errno 2] No such file or directory: 'labels.txt'.\n",
      "SPAN error_3c_tpusg_failure_signal_tpu_sketch_generator: Failed: Max retries reached with exception: Unexpected error during generation: Generated script is not complete. Please ensure to generate a complete Python script..\n",
      "SPAN error_08_tpusg_failure_signal_tpu_sketch_generator: Failed: Max retries reached with error. Last error: Traceback (most recent call last):\n",
      "  File \"script_18593882_1755699049.py\", line 9, in <module>\n",
      "    experimental_delegates=[load_delegate('libedgetpu.so.1')])\n",
      "  File \"/home/mendel/tinyml_autopilot/tinyml-env/lib/python3.7/site-packages/tflite_runtime/interpreter.py\", line 351, in __init__\n",
      "    experimental_preserve_all_tensors))\n",
      "ValueError: Model provided has model identifier 'ftyp', should be 'TFL3'\n",
      "\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"script_18593882_1755699049.py\", line 12, in <module>\n",
      "    experimental_delegates=[load_delegate('/usr/lib/aarch64-linux-gnu/libedgetpu.so.1')])\n",
      "  File \"/home/mendel/tinyml_autopilot/tinyml-env/lib/python3.7/site-packages/tflite_runtime/interpreter.py\", line 351, in __init__\n",
      "    experimental_preserve_all_tensors))\n",
      "ValueError: Model provided has model identifier 'ftyp', should be 'TFL3'\n",
      ".\n",
      "SPAN error_af_tpusg_failure_signal_tpu_sketch_generator: Failed: Max retries reached with exception: Unexpected error during generation: The output is not a valid code block. Follow the instructions in the prompt return a complete, correct Python script enclosed in a single ```python\n",
      "<generated_code>\n",
      "``` block..\n",
      "SPAN error_78_tpusg_failure_signal_tpu_sketch_generator: Failed: Max retries reached with exception: Unexpected error during generation: The output is not a valid code block. Follow the instructions in the prompt return a complete, correct Python script enclosed in a single ```python\n",
      "<generated_code>\n",
      "``` block..\n",
      "SPAN error_b7_tpusg_failure_signal_tpu_sketch_generator: Failed: Max retries reached with error. Last error: Traceback (most recent call last):\n",
      "  File \"script_c3c4ccc3_1755698530.py\", line 3, in <module>\n",
      "    from interpreter import Interpreter, load_delegate\n",
      "ModuleNotFoundError: No module named 'interpreter'.\n",
      "SPAN error_05_tpusg_failure_signal_tpu_sketch_generator: Failed: Max retries reached with error. Last error: Traceback (most recent call last):\n",
      "  File \"script_cd51d698_1755698370.py\", line 9, in <module>\n",
      "    experimental_delegates=[load_delegate('libedgetpu.so.1')])\n",
      "  File \"/home/mendel/tinyml_autopilot/tinyml-env/lib/python3.7/site-packages/tflite_runtime/interpreter.py\", line 351, in __init__\n",
      "    experimental_preserve_all_tensors))\n",
      "ValueError: Could not open 'your_model.tflite'.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"script_cd51d698_1755698370.py\", line 12, in <module>\n",
      "    experimental_delegates=[load_delegate('/usr/lib/aarch64-linux-gnu/libedgetpu.so.1')])\n",
      "  File \"/home/mendel/tinyml_autopilot/tinyml-env/lib/python3.7/site-packages/tflite_runtime/interpreter.py\", line 351, in __init__\n",
      "    experimental_preserve_all_tensors))\n",
      "ValueError: Could not open 'your_model.tflite'..\n",
      "SPAN error_8c_tpusg_failure_signal_tpu_sketch_generator: Failed: Max retries reached with error. Last error: Traceback (most recent call last):\n",
      "  File \"script_9f2e2251_1755698213.py\", line 7, in <module>\n",
      "    interpreter = tflite.Interpreter(model_path='model.tflite')\n",
      "  File \"/home/mendel/tinyml_autopilot/tinyml-env/lib/python3.7/site-packages/tflite_runtime/interpreter.py\", line 351, in __init__\n",
      "    experimental_preserve_all_tensors))\n",
      "ValueError: Could not open 'model.tflite'..\n",
      "SPAN error_d3_tpusg_failure_signal_tpu_sketch_generator: Failed: Max retries reached with exception: Unexpected error during generation: The output is not a valid code block. Follow the instructions in the prompt return a complete, correct Python script enclosed in a single ```python\n",
      "<generated_code>\n",
      "``` block..\n",
      "SPAN error_4a_tpusg_failure_signal_tpu_sketch_generator: Failed: Max retries reached with error. Last error: Traceback (most recent call last):\n",
      "  File \"script_6d4a1042_1755698020.py\", line 5, in <module>\n",
      "    from object_detection.utils import label_map_util\n",
      "ModuleNotFoundError: No module named 'object_detection'.\n",
      "SPAN error_e2_tpusg_failure_signal_tpu_sketch_generator: Failed: Max retries reached with exception: Unexpected error during generation: Generated script is not complete. Please ensure to generate a complete Python script..\n",
      "Successfully processed and saved trimmed data for session codestral_34a5_tpusg_batch\n",
      "Total 0 traces skipped. They are []\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "skipped_traces = []\n",
    "\n",
    "\n",
    "def process_existing_observation(observation):\n",
    "    \"\"\"\n",
    "    Processes an existing observation dictionary by trimming unwanted keys.\n",
    "    \"\"\"\n",
    "    unwanted_observation_keys = [\n",
    "        \"completionStartTime\",\n",
    "        \"metadata\",\n",
    "        \"timeToFirstToken\",\n",
    "        \"createdAt\",\n",
    "        \"usageDetails\",\n",
    "        \"usage\",\n",
    "        \"projectId\",\n",
    "        \"unit\",\n",
    "        \"updatedAt\",\n",
    "        \"version\",\n",
    "        \"parentObservationId\",\n",
    "        \"promptId\",\n",
    "        \"promptName\",\n",
    "        \"promptVersion\",\n",
    "        \"modelId\",\n",
    "        \"inputPrice\",\n",
    "        \"outputPrice\",\n",
    "        \"totalPrice\",\n",
    "        # \"modelParameters\",\n",
    "        \"input\",\n",
    "        \"output\",\n",
    "    ]\n",
    "\n",
    "    # If observation is a dictionary containing observation data\n",
    "    if isinstance(observation, dict):\n",
    "        trimmed_observation = {\n",
    "            k: v for k, v in observation.items() if k not in unwanted_observation_keys\n",
    "        }\n",
    "        return trimmed_observation\n",
    "    return observation\n",
    "\n",
    "\n",
    "def trim_data(data):\n",
    "    \"\"\"\n",
    "    Recursively trims the data structure.\n",
    "    \"\"\"\n",
    "\n",
    "    if isinstance(data, dict):\n",
    "        # Process the current dictionary\n",
    "        unwanted_trace_keys = [\n",
    "            \"release\",\n",
    "            \"version\",\n",
    "            \"user_id\",\n",
    "            \"public\",\n",
    "            \"html_path\",\n",
    "            \"scores\",\n",
    "            \"bookmarked\",\n",
    "            \"projectId\",\n",
    "            \"externalId\",\n",
    "            \"page\",\n",
    "            \"limit\",\n",
    "            \"total_pages\",\n",
    "        ]\n",
    "\n",
    "        # If this is a trace that contains observations, check for fatal errors\n",
    "        if \"observations\" in data:\n",
    "            # Check for SPAN observations with fatal errors before processing\n",
    "            skip_trace = False\n",
    "            for obs in data[\"observations\"]:\n",
    "                if isinstance(obs, dict) and obs.get(\"name\").startswith(\"error\"):\n",
    "                    status_message = obs.get(\"statusMessage\", \"\")\n",
    "                    ob_name = obs.get(\"name\")\n",
    "                    print(f\"SPAN {ob_name}: {status_message}\")\n",
    "\n",
    "                    if \"Fatal error\" in status_message:\n",
    "                        print(f\"Found Fatal error in SPAN observation, skipping trace\")\n",
    "                        skip_trace = True\n",
    "                        skipped_traces.append(data[\"name\"])\n",
    "                        break\n",
    "\n",
    "            if skip_trace:\n",
    "                return None  # Signal to skip this trace\n",
    "\n",
    "        # Create a new dictionary with wanted keys and recursively process values\n",
    "        trimmed_data = {}\n",
    "        for key, value in data.items():\n",
    "            if key not in unwanted_trace_keys:\n",
    "                if key == \"observations\":\n",
    "                    # Special handling for observations\n",
    "                    trimmed_data[key] = [\n",
    "                        process_existing_observation(obs) for obs in value\n",
    "                    ]\n",
    "                elif isinstance(value, (dict, list)):\n",
    "                    # Recursively process nested structures\n",
    "                    trimmed_data[key] = trim_data(value)\n",
    "                else:\n",
    "                    trimmed_data[key] = value\n",
    "\n",
    "        return trimmed_data\n",
    "\n",
    "    elif isinstance(data, list):\n",
    "        # Recursively process each item in the list\n",
    "        processed_items = []\n",
    "        for item in data:\n",
    "            processed_item = trim_data(item)\n",
    "            if processed_item is not None:  # Only add items that weren't filtered out\n",
    "                processed_items.append(processed_item)\n",
    "        return processed_items\n",
    "\n",
    "    else:\n",
    "        # Return non-dict, non-list values as is\n",
    "        return data\n",
    "\n",
    "\n",
    "def read_and_trim_data(session_id_list, raw_export_dir, trimmed_export_dir):\n",
    "    \"\"\"\n",
    "    Reads complete data from JSON files, trims the data, and saves the trimmed data to new JSON files.\n",
    "    \"\"\"\n",
    "    os.makedirs(trimmed_export_dir, exist_ok=True)\n",
    "\n",
    "    for session_id in session_id_list:\n",
    "        try:\n",
    "            if session_id.startswith(\"da0a\"):\n",
    "                session_id = \"phi4_\" + session_id\n",
    "            # Read raw data\n",
    "            if \"tpsg\" in session_id:\n",
    "                session_id_ = session_id.replace(\"tpsg\", \"tpusg\")\n",
    "            else:\n",
    "                session_id_ = session_id\n",
    "            raw_path = os.path.join(raw_export_dir, f\"raw_{session_id_}.json\")\n",
    "            with open(raw_path, \"r\") as f:\n",
    "                data = json.load(f)\n",
    "\n",
    "            # Process and trim the data\n",
    "            trimmed_data = trim_data(data)\n",
    "\n",
    "            # If the entire data was filtered out (unlikely but possible)\n",
    "            if trimmed_data is None:\n",
    "                print(\n",
    "                    f\"All traces in session {session_id} were filtered due to fatal errors\"\n",
    "                )\n",
    "                continue\n",
    "\n",
    "            # Save trimmed data\n",
    "            if \"tpsg\" in session_id:\n",
    "                session_id_ = session_id.replace(\"tpsg\", \"tpusg\")\n",
    "            else:\n",
    "                session_id_ = session_id\n",
    "            trimmed_path = os.path.join(\n",
    "                trimmed_export_dir, f\"trimmed_{session_id_}.json\"\n",
    "            )\n",
    "            with open(trimmed_path, \"w\") as f:\n",
    "                json.dump(trimmed_data, f, indent=2)\n",
    "\n",
    "            print(\n",
    "                f\"Successfully processed and saved trimmed data for session {session_id}\"\n",
    "            )\n",
    "\n",
    "            # Optional: Verify trimming worked\n",
    "            # print(f\"Verifying trimmed data for session {session_id}...\")\n",
    "            # verify_trimming(trimmed_path)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing session {session_id}: {str(e)}\")\n",
    "\n",
    "\n",
    "def verify_trimming(trimmed_path):\n",
    "    \"\"\"\n",
    "    Verifies that the trimmed data doesn't contain unwanted keys.\n",
    "    \"\"\"\n",
    "    with open(trimmed_path, \"r\") as f:\n",
    "        trimmed_data = json.load(f)\n",
    "\n",
    "    unwanted_keys = [\n",
    "        \"release\",\n",
    "        \"version\",\n",
    "        \"user_id\",\n",
    "        \"public\",\n",
    "        \"html_path\",\n",
    "        \"scores\",\n",
    "        \"bookmarked\",\n",
    "        \"projectId\",\n",
    "        \"externalId\",\n",
    "        \"page\",\n",
    "        \"limit\",\n",
    "        \"total_pages\",\n",
    "        \"completionStartTime\",\n",
    "        \"metadata\",\n",
    "        \"usageDetails\",\n",
    "        \"timeToFirstToken\",\n",
    "        \"createdAt\",\n",
    "        \"completionTokens\",\n",
    "        \"promptTokens\",\n",
    "        \"projectId\",\n",
    "        \"unit\",\n",
    "        \"updatedAt\",\n",
    "        \"version\",\n",
    "        # \"statusMessage\",\n",
    "        \"parentObservationId\",\n",
    "        \"promptId\",\n",
    "        \"promptName\",\n",
    "        \"promptVersion\",\n",
    "        \"modelId\",\n",
    "        \"inputPrice\",\n",
    "        \"outputPrice\",\n",
    "        \"totalPrice\",\n",
    "        \"calculatedInputCost\",\n",
    "        \"calculatedOutputCost\",\n",
    "        \"calculatedTotalCost\",\n",
    "    ]\n",
    "\n",
    "    def check_keys(obj):\n",
    "        if isinstance(obj, dict):\n",
    "            for key in obj.keys():\n",
    "                if key in unwanted_keys:\n",
    "                    print(f\"Warning: Found unwanted key '{key}' in trimmed data\")\n",
    "            for value in obj.values():\n",
    "                check_keys(value)\n",
    "        elif isinstance(obj, list):\n",
    "            for item in obj:\n",
    "                check_keys(item)\n",
    "\n",
    "    check_keys(trimmed_data)\n",
    "    print(\"Verification complete\")\n",
    "\n",
    "\n",
    "# Usage example:\n",
    "read_and_trim_data(session_id_list, raw_export_dir, raw_export_dir)\n",
    "print(f\"Total {len(skipped_traces)} traces skipped. They are {skipped_traces}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Generate CSV files from JSON\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing session codestral_34a5_tpusg_batch, simple id codestral_34a5. Look for /home/han/Projects/reference-benchmark-tinyml_llm/data_analysis/2025/08.24/raw_export/trimmed_codestral_34a5_tpusg_batch.json\n",
      "/home/han/Projects/reference-benchmark-tinyml_llm/data_analysis/2025/08.24/processed_data/codestral_34a5/clean_codestral_34a5_tpusg_batch.csv\n",
      "Successfully saved CSV to: /home/han/Projects/reference-benchmark-tinyml_llm/data_analysis/2025/08.24/processed_data/codestral_34a5/clean_codestral_34a5_tpusg_batch.csv\n"
     ]
    }
   ],
   "source": [
    "import traceback\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from dateutil import parser\n",
    "\n",
    "\n",
    "def json_to_csv(session_id):\n",
    "    \"\"\"\n",
    "    Convert JSON trace data to CSV format with aggregated metrics.\n",
    "\n",
    "    Args:\n",
    "        session_id (str): Identifier for the session to process\n",
    "    \"\"\"\n",
    "\n",
    "    def extract_observation_details(observations, trace_id):\n",
    "        \"\"\"Extract and aggregate metrics from observations\"\"\"\n",
    "        metrics = {\n",
    "            \"status\": None,\n",
    "            \"latency\": 0,\n",
    "            \"total_tokens\": 0,\n",
    "            \"prompt_tokens\": 0,\n",
    "            \"completion_tokens\": 0,\n",
    "            \"total_cost\": 0,\n",
    "            \"input_cost\": 0,\n",
    "            \"output_cost\": 0,\n",
    "            \"parameters\": set(),\n",
    "        }\n",
    "\n",
    "        # Process GENERATION observations\n",
    "        for obs in (o for o in observations if o[\"type\"] == \"GENERATION\"):\n",
    "            metrics[\"total_tokens\"] += obs[\"totalTokens\"]\n",
    "            metrics[\"prompt_tokens\"] += obs[\"promptTokens\"]\n",
    "            metrics[\"completion_tokens\"] += obs[\"completionTokens\"]\n",
    "            metrics[\"latency\"] += obs[\"latency\"]\n",
    "            for key, value in obs[\"modelParameters\"].items():\n",
    "                metrics[\"parameters\"].add(key + \":\" + value)\n",
    "\n",
    "            # Add costs if present\n",
    "            for cost_type in [\"Total\", \"Input\", \"Output\"]:\n",
    "                key = f\"calculated{cost_type}Cost\"\n",
    "                metric_key = cost_type.lower() + \"_cost\"\n",
    "                if obs.get(key) is not None:\n",
    "                    metrics[metric_key] += obs[key]\n",
    "        if len(metrics[\"parameters\"]) == 0:\n",
    "            metrics[\"parameters\"] = \"N/A\"\n",
    "        # Process SPAN observations for status\n",
    "        status_indicators = [\n",
    "            obs[\"name\"]\n",
    "            for obs in observations\n",
    "            if obs[\"type\"] == \"SPAN\" and \"start_\" not in obs[\"name\"]\n",
    "        ]\n",
    "\n",
    "        #  if later than 2025-05-19, use status_signal_from_output\n",
    "        if datetime.now() > datetime(2025, 5, 19):\n",
    "            pass\n",
    "        else:\n",
    "            # Determine status\n",
    "            success_signals = sum(\"end_\" in name for name in status_indicators)\n",
    "            failure_signals = sum(\n",
    "                \"failure_signal\" in name for name in status_indicators\n",
    "            )\n",
    "\n",
    "            if success_signals + failure_signals > 1:\n",
    "                raise ValueError(\n",
    "                    f\"Multiple status indicators found in trace {trace_id}\"\n",
    "                )\n",
    "\n",
    "            metrics[\"status\"] = (\n",
    "                \"success\"\n",
    "                if success_signals\n",
    "                else \"failure\" if failure_signals else \"unknown\"\n",
    "            )\n",
    "\n",
    "        metrics[\"prompt_cost\"] = metrics.pop(\"input_cost\")\n",
    "        metrics[\"completion_cost\"] = metrics.pop(\"output_cost\")\n",
    "        metrics[\"latency\"] = round(metrics[\"latency\"] / 1000, 2)\n",
    "        return metrics\n",
    "\n",
    "    def cal_time(trace):\n",
    "        time_diff = datetime.fromisoformat(\n",
    "            trace[\"updatedAt\"].replace(\"Z\", \"+00:00\")\n",
    "        ) - datetime.fromisoformat(trace[\"createdAt\"].replace(\"Z\", \"+00:00\"))\n",
    "        seconds_diff = time_diff.total_seconds()\n",
    "        return seconds_diff\n",
    "\n",
    "    try:\n",
    "\n",
    "        if session_id.startswith(\"da0a\"):\n",
    "            session_id = \"phi4_\" + session_id\n",
    "        simple_session_id = session_id.rsplit(\"_\", 2)[0]\n",
    "\n",
    "        \n",
    "        # Load JSON data\n",
    "        if \"tpsg\" in session_id:\n",
    "                session_id_ = session_id.replace(\"tpsg\", \"tpusg\")\n",
    "        else:\n",
    "                session_id_ = session_id\n",
    "        trimmed_path = os.path.join(raw_export_dir, f\"trimmed_{session_id_}.json\")\n",
    "        print(\n",
    "            f\"Processing session {session_id}, simple id {simple_session_id}. Look for {trimmed_path}\"\n",
    "        )\n",
    "        with open(trimmed_path, \"r\") as file:\n",
    "            traces = json.load(file)[\"data\"]\n",
    "\n",
    "        # Process traces\n",
    "        rows = [\n",
    "            {\n",
    "                \"num_run\": trace[\"metadata\"][\"num_run\"],\n",
    "                \"name\": trace[\"name\"],\n",
    "                \"trace_id\": trace[\"id\"],\n",
    "                \"batch_id\": trace[\"session_id\"],\n",
    "                # \"latency\": cal_time(trace),\n",
    "                # \"latency\": round(trace[\"latency\"], 2),\n",
    "                **extract_observation_details(\n",
    "                    trace[\"observations\"],\n",
    "                    trace[\"id\"],\n",
    "                ),\n",
    "                \"status\": (\n",
    "                    \"failure\"\n",
    "                    if trace[\"output\"][\"status\"].lower() == \"failed\"\n",
    "                    else \"success\"\n",
    "                ),\n",
    "                \"tags\": trace[\"tags\"],\n",
    "                \"timestamp\": int(parser.isoparse(trace[\"timestamp\"]).timestamp()),\n",
    "            }\n",
    "            for trace in traces\n",
    "        ]\n",
    "        # print(rows)\n",
    "        # print(rows)\n",
    "        # Create and save DataFrame\n",
    "        df = pd.DataFrame(rows).sort_values(\"num_run\")\n",
    "\n",
    "        output_dir = os.path.join(processed_data_dir, f\"{simple_session_id}\")\n",
    "        if not os.path.exists(output_dir):\n",
    "            os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "        output_path = os.path.join(output_dir, f\"clean_{session_id_}.csv\")\n",
    "\n",
    "        print(output_path)\n",
    "        df.to_csv(output_path, index=False)\n",
    "        print(f\"Successfully saved CSV to: {output_path}\")\n",
    "\n",
    "    except FileNotFoundError as e:\n",
    "        print(\n",
    "            f\"FileNotFoundError: For session {session_id} not found. Looked for {trimmed_path}\\nError info: \\n{e}\\n\\nTraceback: {traceback.format_exc()}\"\n",
    "        )\n",
    "    except json.JSONDecodeError:\n",
    "        print(f\"Error: Invalid JSON format in input file for session {session_id}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing session {session_id}: {str(e)}\")\n",
    "\n",
    "\n",
    "# Example usage\n",
    "for session_id in session_id_list:\n",
    "    json_to_csv(session_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CSV Generation with Generation Counts\n",
    "\n",
    "This section creates CSV files similar to the langfuse_export section 3, but adds a column for the number of generation attempts used for each trace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing sessions: ['codestral_34a5_tpusg_batch']\n",
      "Looking for raw files in: /home/han/Projects/reference-benchmark-tinyml_llm/data_analysis/2025/08.24/raw_export\n",
      "Will save CSV files to: /home/han/Projects/reference-benchmark-tinyml_llm/data_analysis/2025/08.24/processed_data\n",
      "Processing session codestral_34a5_tpusg_batch, simple id codestral_34a5. Look for /home/han/Projects/reference-benchmark-tinyml_llm/data_analysis/2025/08.24/raw_export/trimmed_codestral_34a5_tpusg_batch.json\n",
      "/home/han/Projects/reference-benchmark-tinyml_llm/data_analysis/2025/08.24/processed_data/codestral_34a5/clean_codestral_34a5_tpusg_batch.csv\n",
      "Successfully saved CSV to: /home/han/Projects/reference-benchmark-tinyml_llm/data_analysis/2025/08.24/processed_data/codestral_34a5/clean_codestral_34a5_tpusg_batch.csv\n"
     ]
    }
   ],
   "source": [
    "import traceback\n",
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "from datetime import datetime\n",
    "from dateutil import parser\n",
    "\n",
    "# Setup paths - same as langfuse_export\n",
    "parent_dir = os.path.dirname(os.getcwd())\n",
    "raw_export_dir = os.path.join(parent_dir, \"raw_export\")\n",
    "processed_data_dir = os.path.join(parent_dir, \"processed_data\")\n",
    "\n",
    "\n",
    "# Get session id list from data directory\n",
    "session_id_list = []\n",
    "\n",
    "for root, dirs, files in os.walk(raw_export_dir):\n",
    "    for file in files:\n",
    "        file_path = os.path.join(root, file)\n",
    "        if \"trimmed_\" in file_path:\n",
    "            session_id = file_path.split('trimmed_')[1].rstrip('.json')\n",
    "            session_id_list.append(session_id)\n",
    "\n",
    "print(f\"Processing sessions: {session_id_list}\")\n",
    "print(f\"Looking for raw files in: {raw_export_dir}\")\n",
    "print(f\"Will save CSV files to: {processed_data_dir}\")\n",
    "\n",
    "\n",
    "def json_to_csv_weighted(session_id):\n",
    "    \"\"\"\n",
    "    Convert JSON trace data to CSV format with aggregated metrics.\n",
    "    Upgraded version that includes generation_count column.\n",
    "\n",
    "    Args:\n",
    "        session_id (str): Identifier for the session to process\n",
    "    \"\"\"\n",
    "\n",
    "    def extract_observation_details(observations, trace_id):\n",
    "        \"\"\"Extract and aggregate metrics from observations\"\"\"\n",
    "        metrics = {\n",
    "            \"status\": None,\n",
    "            \"latency\": 0,\n",
    "            \"total_tokens\": 0,\n",
    "            \"prompt_tokens\": 0,\n",
    "            \"completion_tokens\": 0,\n",
    "            \"total_cost\": 0,\n",
    "            \"input_cost\": 0,\n",
    "            \"output_cost\": 0,\n",
    "            \"parameters\": set(),\n",
    "            \"generation_count\": 0,  # New field for generation count\n",
    "        }\n",
    "\n",
    "        # Count generations and process GENERATION observations\n",
    "        for obs in (o for o in observations if o[\"type\"] == \"GENERATION\"):\n",
    "            metrics[\"generation_count\"] += 1\n",
    "            metrics[\"total_tokens\"] += obs[\"totalTokens\"]\n",
    "            metrics[\"prompt_tokens\"] += obs[\"promptTokens\"]\n",
    "            metrics[\"completion_tokens\"] += obs[\"completionTokens\"]\n",
    "            metrics[\"latency\"] += obs[\"latency\"]\n",
    "            for key, value in obs[\"modelParameters\"].items():\n",
    "                metrics[\"parameters\"].add(key + \":\" + value)\n",
    "\n",
    "            # Add costs if present\n",
    "            for cost_type in [\"Total\", \"Input\", \"Output\"]:\n",
    "                key = f\"calculated{cost_type}Cost\"\n",
    "                metric_key = cost_type.lower() + \"_cost\"\n",
    "                if obs.get(key) is not None:\n",
    "                    metrics[metric_key] += obs[key]\n",
    "                    \n",
    "        if len(metrics[\"parameters\"]) == 0:\n",
    "            metrics[\"parameters\"] = \"N/A\"\n",
    "            \n",
    "        # Process SPAN observations for status\n",
    "        status_indicators = [\n",
    "            obs[\"name\"]\n",
    "            for obs in observations\n",
    "            if obs[\"type\"] == \"SPAN\" and \"start_\" not in obs[\"name\"]\n",
    "        ]\n",
    "\n",
    "        #  if later than 2025-05-19, use status_signal_from_output\n",
    "        if datetime.now() > datetime(2025, 5, 19):\n",
    "            pass\n",
    "        else:\n",
    "            # Determine status\n",
    "            success_signals = sum(\"end_\" in name for name in status_indicators)\n",
    "            failure_signals = sum(\n",
    "                \"failure_signal\" in name for name in status_indicators\n",
    "            )\n",
    "\n",
    "            if success_signals + failure_signals > 1:\n",
    "                raise ValueError(\n",
    "                    f\"Multiple status indicators found in trace {trace_id}\"\n",
    "                )\n",
    "\n",
    "            metrics[\"status\"] = (\n",
    "                \"success\"\n",
    "                if success_signals\n",
    "                else \"failure\" if failure_signals else \"unknown\"\n",
    "            )\n",
    "\n",
    "        metrics[\"prompt_cost\"] = metrics.pop(\"input_cost\")\n",
    "        metrics[\"completion_cost\"] = metrics.pop(\"output_cost\")\n",
    "        metrics[\"latency\"] = round(metrics[\"latency\"] / 1000, 2)\n",
    "        return metrics\n",
    "\n",
    "    def cal_time(trace):\n",
    "        time_diff = datetime.fromisoformat(\n",
    "            trace[\"updatedAt\"].replace(\"Z\", \"+00:00\")\n",
    "        ) - datetime.fromisoformat(trace[\"createdAt\"].replace(\"Z\", \"+00:00\"))\n",
    "        seconds_diff = time_diff.total_seconds()\n",
    "        return seconds_diff\n",
    "\n",
    "    try:\n",
    "        if session_id.startswith(\"da0a\"):\n",
    "            session_id = \"phi4_\" + session_id\n",
    "        simple_session_id = session_id.rsplit(\"_\", 2)[0]\n",
    "\n",
    "        # Load JSON data\n",
    "        if \"tpsg\" in session_id:\n",
    "            session_id_ = session_id.replace(\"tpsg\", \"tpusg\")\n",
    "        else:\n",
    "            session_id_ = session_id\n",
    "        trimmed_path = os.path.join(raw_export_dir, f\"trimmed_{session_id_}.json\")\n",
    "        print(\n",
    "            f\"Processing session {session_id}, simple id {simple_session_id}. Look for {trimmed_path}\"\n",
    "        )\n",
    "        with open(trimmed_path, \"r\") as file:\n",
    "            traces = json.load(file)[\"data\"]\n",
    "\n",
    "        # Process traces\n",
    "        rows = [\n",
    "            {\n",
    "                \"num_run\": trace[\"metadata\"][\"num_run\"],\n",
    "                \"name\": trace[\"name\"],\n",
    "                \"trace_id\": trace[\"id\"],\n",
    "                \"batch_id\": trace[\"session_id\"],\n",
    "                # \"latency\": cal_time(trace),\n",
    "                # \"latency\": round(trace[\"latency\"], 2),\n",
    "                **extract_observation_details(\n",
    "                    trace[\"observations\"],\n",
    "                    trace[\"id\"],\n",
    "                ),\n",
    "                \"status\": (\n",
    "                    \"failure\"\n",
    "                    if trace[\"output\"][\"status\"].lower() == \"failed\"\n",
    "                    else \"success\"\n",
    "                ),\n",
    "                \"tags\": trace[\"tags\"],\n",
    "                \"timestamp\": int(parser.isoparse(trace[\"timestamp\"]).timestamp()),\n",
    "            }\n",
    "            for trace in traces\n",
    "        ]\n",
    "        \n",
    "        # Create and save DataFrame\n",
    "        df = pd.DataFrame(rows).sort_values(\"num_run\")\n",
    "\n",
    "        output_dir = os.path.join(processed_data_dir, f\"{simple_session_id}\")\n",
    "        if not os.path.exists(output_dir):\n",
    "            os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "        output_path = os.path.join(output_dir, f\"clean_{session_id_}.csv\")\n",
    "\n",
    "        print(output_path)\n",
    "        df.to_csv(output_path, index=False)\n",
    "        print(f\"Successfully saved CSV to: {output_path}\")\n",
    "\n",
    "    except FileNotFoundError as e:\n",
    "        print(\n",
    "            f\"FileNotFoundError: For session {session_id} not found. Looked for {trimmed_path}\\nError info: \\n{e}\\n\\nTraceback: {traceback.format_exc()}\"\n",
    "        )\n",
    "    except json.JSONDecodeError:\n",
    "        print(f\"Error: Invalid JSON format in input file for session {session_id}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing session {session_id}: {str(e)}\")\n",
    "\n",
    "\n",
    "\n",
    "# Example usage\n",
    "for session_id in session_id_list:\n",
    "    json_to_csv_weighted(session_id)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llmdev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

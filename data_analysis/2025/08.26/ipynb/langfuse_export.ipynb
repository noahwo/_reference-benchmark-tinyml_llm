{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setting up\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ref: https://langfuse.com/docs/query-traces\n",
    "import os\n",
    "import json\n",
    "from langfuse import Langfuse\n",
    "import json\n",
    "import os\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "LOCAL_HOST = True\n",
    "\n",
    "\"\"\"Define session_id\"\"\"\n",
    "# session_id=\"qwen2.5-coder_f4d4_dp_batch\"\n",
    "session_id_list = [\n",
    "    # \"qwen2.5-coder:32b_4e11_tpsg_batch\",\n",
    "    # \"qwen2.5-coder:32b_ae24_tpsg_batch\"\n",
    "    \"codestral_a277_psg_batch\",\n",
    "    \"codestral_bcbe_psg_batch\"\n",
    "]\n",
    "\n",
    "\n",
    "\"\"\"Define paths\"\"\"\n",
    " \n",
    "parent_dir = os.path.dirname(os.getcwd())\n",
    "\n",
    " \n",
    "# date = os.path.basename(parent_dir)\n",
    "tex_dir = os.path.join(parent_dir, \"tex\")\n",
    "processed_data_dir = os.path.join(parent_dir, \"processed_data\")\n",
    "raw_export_dir = os.path.join(parent_dir, \"raw_export\")\n",
    "ipynb_dir = os.path.join(parent_dir, \"ipynb\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Export raw data\n",
    "\n",
    "Langfuse added a limit of 20 API invocations per minute. https://langfuse.com/faq/all/api-limits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching traces for session codestral_a277_psg_batch...\n",
      "Fetching observation data for time-23-42-44-893706_chatcmpl-6fd1ee5e-6102-4488-bc35-cf103f0443ba...\n",
      "Fetching observation data for time-23-43-00-741979_chatcmpl-429f0e51-54eb-4575-bcae-86d878593771...\n",
      "Fetching observation data for time-23-43-19-103565_chatcmpl-30a00b2d-6d4a-47e8-8266-3caa225f504a...\n",
      "Fetching observation data for time-23-41-33-381739_chatcmpl-e049d5a3-6a02-49f3-b96f-b7215a8d70ef...\n",
      "Fetching observation data for time-23-41-51-044734_chatcmpl-88f45896-6819-4bb2-abca-66b17733ec8c...\n",
      "Fetching observation data for time-23-42-12-921963_chatcmpl-c63cc1d1-63f0-44af-b4f0-56d0348ac8b0...\n",
      "Fetching observation data for time-23-40-59-355809_chatcmpl-f2525d29-74a3-48b5-9c1d-b2cec8443969...\n",
      "Fetching observation data for time-23-40-10-827090_chatcmpl-6e45fcc0-eb16-4d54-b5df-433dd8a8fd1b...\n",
      "Fetching observation data for time-23-40-26-670634_chatcmpl-f8e80989-60fc-4c89-a235-55ed3d5749bb...\n",
      "Fetching observation data for time-23-39-25-930139_chatcmpl-c21e9d68-25f3-4d29-a3d7-13e9ac70149d...\n",
      "Fetching observation data for time-23-39-42-073180_chatcmpl-90e1b3f1-50bd-4c6f-a036-5acba138178e...\n",
      "Fetching observation data for time-23-38-59-295906_chatcmpl-1a00eea1-cb3d-47b3-a338-290169ba61ff...\n",
      "Fetching observation data for time-23-37-52-745441_chatcmpl-2d4a7f24-7806-4184-87d4-e6d161566301...\n",
      "Fetching observation data for time-23-38-08-227789_chatcmpl-dd603015-99a4-4b17-98ab-514cf12a41d0...\n",
      "Fetching observation data for time-23-38-25-841437_chatcmpl-28789cdd-b6fd-42aa-b7aa-b16a001fc1c5...\n",
      "Fetching observation data for time-23-38-35-017357_chatcmpl-50a601c8-63fa-4c20-a461-0aab8742c48d...\n",
      "Fetching observation data for time-23-38-43-728022_chatcmpl-e3c90125-50d6-4d78-944d-b72596dda246...\n",
      "Fetching observation data for 5820687d-6d10-45fb-bfe6-ba1de43327c3...\n",
      "Fetching observation data for time-23-37-08-165931_chatcmpl-8af7b6e3-8a17-4640-8347-cb617dda3ab2...\n",
      "Fetching observation data for time-23-37-23-131396_chatcmpl-84c645bf-2ca9-4d6f-b7ae-93f9626d2998...\n",
      "Fetching observation data for time-23-36-23-608670_chatcmpl-d276f017-d359-40ce-a364-8c375c82e92c...\n",
      "Fetching observation data for time-23-36-39-382514_chatcmpl-5ed4163c-0268-492b-8c64-9ff9152b294f...\n",
      "Fetching observation data for time-23-35-08-080121_chatcmpl-57a858a9-09bf-41b7-9379-23f69bb6a2a2...\n",
      "Fetching observation data for time-23-35-28-180902_chatcmpl-d4bdbbda-5531-4505-9316-3c13c2313f8b...\n",
      "Fetching observation data for time-23-35-48-751191_chatcmpl-6efd446c-7fd0-492d-a96a-a59b20423209...\n",
      "Fetching observation data for time-23-35-53-446243_chatcmpl-d38f25ed-541a-4500-8987-12330d650a58...\n",
      "Fetching observation data for time-23-35-58-188628_chatcmpl-b511db9d-b1f6-4bd8-b60b-0998eb6733d7...\n",
      "Fetching observation data for b68ebb6f-4034-4dd7-8063-3bf2b689a809...\n",
      "Fetching observation data for time-23-34-04-072366_chatcmpl-b87161b8-8b24-43ef-a18e-4618a53e7349...\n",
      "Fetching observation data for time-23-34-15-398267_chatcmpl-58ad8f78-fd5a-4a79-9101-a85ed9b19bd2...\n",
      "Fetching observation data for time-23-34-35-191447_chatcmpl-20985fd1-fe25-41d5-b966-761f0e1f1390...\n",
      "Fetching observation data for time-23-32-57-172521_chatcmpl-4e2ce19b-c7e3-4e30-b167-eddfedfe06d4...\n",
      "Fetching observation data for time-23-33-11-285956_chatcmpl-fd560692-049a-4357-ade6-4ea7f8840262...\n",
      "Fetching observation data for time-23-33-27-757008_chatcmpl-26bc1a6f-cc53-47a3-8d19-69638f69e89e...\n",
      "Fetching observation data for time-23-33-45-258743_chatcmpl-5f48d768-98cb-4c64-9f4d-4f22a18959cd...\n",
      "Fetching observation data for time-23-33-53-150494_chatcmpl-8e395d86-7eb1-41bb-ad8d-50d168948f33...\n",
      "Fetching observation data for 6f873433-efb4-41f5-ad57-145de2631d14...\n",
      "Fetching observation data for time-23-31-37-625082_chatcmpl-89b897b4-b3ae-4ae1-88bb-547146e3dea1...\n",
      "Fetching observation data for time-23-31-54-297039_chatcmpl-ba6fcb32-cbdd-4bca-90f9-4cdcccc6df56...\n",
      "Fetching observation data for time-23-32-14-446061_chatcmpl-4ac4e17c-de19-4bea-b8fd-fc58f1c953a4...\n",
      "Fetching observation data for time-23-32-34-429017_chatcmpl-28a2a29c-e633-48fb-87b2-bdf351164038...\n",
      "Fetching observation data for time-23-32-46-408775_chatcmpl-0b246ebe-70a0-4037-8e0e-ef0d4eff63d0...\n",
      "Fetching observation data for 81c3309d-8919-41f2-a60b-1c40a7d949b3...\n",
      "Fetching observation data for time-23-30-45-045607_chatcmpl-e4b34bc6-3194-4e0e-ae89-739ce94369ff...\n",
      "Fetching observation data for time-23-31-05-014645_chatcmpl-39794936-daed-4923-8fbe-4dcf79e7356b...\n",
      "Fetching observation data for time-23-29-51-515835_chatcmpl-9a362290-49ca-4409-8263-577b6cedb0b1...\n",
      "Fetching observation data for time-23-30-12-540266_chatcmpl-40a23dbf-f87e-4ade-9305-b861b3e9a04b...\n",
      "Fetching observation data for time-23-29-02-946147_chatcmpl-6c01555b-5591-4bcb-8861-bc15d6948d4c...\n",
      "Fetching observation data for time-23-29-20-086647_chatcmpl-6804f1fd-69ed-41da-bb0f-be7a3e6fce8e...\n",
      "Fetching observation data for time-23-28-15-415775_chatcmpl-69fbcef5-0aa0-4504-88dc-94aa62f10de8...\n",
      "Fetching observation data for time-23-28-31-099046_chatcmpl-943f745a-4638-4d7b-9809-737b80063b09...\n",
      "Fetching observation data for time-23-27-22-877967_chatcmpl-5e971451-9013-4088-b460-90b361c5de28...\n",
      "Fetching observation data for time-23-27-41-873457_chatcmpl-e0644f92-3741-4621-9672-99b3d24afe56...\n",
      "Fetching observation data for time-23-26-35-299819_chatcmpl-2d230455-5ee8-4b20-8f27-b7c4f7809a3f...\n",
      "Fetching observation data for time-23-26-51-486942_chatcmpl-1086288d-f81a-44af-bfff-bd6f04c35509...\n",
      "Fetching observation data for time-23-26-08-784582_chatcmpl-eae8006b-0b6f-426e-a5b2-f917ea5540c2...\n",
      "Fetching observation data for time-23-24-49-274805_chatcmpl-57ae04a2-04f7-401e-b266-67f9e548a82d...\n",
      "Fetching observation data for time-23-25-39-433666_chatcmpl-1b49c901-200b-4c61-9fec-ca4f10e56adf...\n",
      "Raw JSON saved to: /home/han/Projects/reference-benchmark-tinyml_llm/data_analysis/2025/08.26/raw_export/raw_codestral_a277_psg_batch.json\n",
      "Fetching traces for session codestral_bcbe_psg_batch...\n",
      "Fetching observation data for time-04-27-53-090187_chatcmpl-b84b7ef8-613c-4143-b4ee-223d1ae12637...\n",
      "Fetching observation data for time-04-26-59-554714_chatcmpl-ccb27557-2c31-48a4-8069-39d0a08563eb...\n",
      "Fetching observation data for time-04-27-20-487352_chatcmpl-380f2dd6-e73e-4cc4-a50e-467e0cbb73e3...\n",
      "Fetching observation data for time-04-25-42-029393_chatcmpl-55b5e8c9-d131-439f-a5f1-f154ce58e179...\n",
      "Fetching observation data for time-04-26-00-443580_chatcmpl-2b2ddab9-b7fd-4e9a-8d32-6ad4b8649d18...\n",
      "Fetching observation data for time-04-26-19-454099_chatcmpl-bd1415a0-8d2a-4cbb-a0aa-33552da051ca...\n",
      "Fetching observation data for time-04-26-28-385692_chatcmpl-3e69e00a-2fae-42be-b40e-7ab34df1e465...\n",
      "Fetching observation data for time-04-26-40-118838_chatcmpl-eb2d9bda-eba8-4a0a-b31f-df40d04fdb5b...\n",
      "Fetching observation data for ce64e4a1-7468-4d28-abaf-16e86636b2cc...\n",
      "Fetching observation data for time-04-24-49-508224_chatcmpl-89e45ebd-e214-41fe-b304-5071cbabe5be...\n",
      "Fetching observation data for time-04-25-07-573167_chatcmpl-02732575-174d-432c-a65f-52135da3f6f6...\n",
      "Fetching observation data for time-04-24-03-957536_chatcmpl-b90eabf5-bf3c-471e-a6f7-78820a3d026a...\n",
      "Fetching observation data for time-04-24-19-466939_chatcmpl-829a4a21-d088-4ede-9863-da683abf1d41...\n",
      "Fetching observation data for time-04-22-59-431343_chatcmpl-3533bd9a-78b8-4715-a805-bfee13b2238d...\n",
      "Fetching observation data for time-04-23-14-826057_chatcmpl-66e574f4-462a-465b-96f6-561500f2f5d7...\n",
      "Fetching observation data for time-04-23-34-456317_chatcmpl-228bf85c-0b29-450d-b158-b2d42239b8bc...\n",
      "Fetching observation data for time-04-21-48-904692_chatcmpl-cfe98a1e-ba12-4709-be06-7c40e7895917...\n",
      "Fetching observation data for time-04-22-03-846050_chatcmpl-98ba54c0-67c3-4fa3-8afb-af22dedc0089...\n",
      "Fetching observation data for time-04-22-25-188966_chatcmpl-82bd4ef2-6509-4ccd-8b4a-7779b6a57c53...\n",
      "Fetching observation data for time-04-22-32-222149_chatcmpl-3ae1e154-9eba-43b9-b426-c98f67207eba...\n",
      "Fetching observation data for time-04-22-41-530214_chatcmpl-f93b8829-ba08-4128-ba20-6a82e0c8e6d8...\n",
      "Fetching observation data for ae1c183d-b42d-40e2-a752-86253863ea3e...\n",
      "Fetching observation data for time-04-20-38-380137_chatcmpl-4bc96bcb-e1b4-4e7a-98da-da2f036b3db1...\n",
      "Fetching observation data for time-04-20-54-901605_chatcmpl-7f1c9dc2-e842-452d-87ca-469ea790a3b4...\n",
      "Fetching observation data for time-04-21-13-940984_chatcmpl-d61c1a23-e1e0-4c15-88f6-5307eadaf125...\n",
      "Fetching observation data for time-04-19-48-821426_chatcmpl-3f49ffe4-3b54-4aec-be20-33b854a92f36...\n",
      "Fetching observation data for time-04-20-06-415654_chatcmpl-32af552c-8151-41fb-bbe3-dd3756c8c340...\n",
      "Fetching observation data for time-04-18-03-042664_chatcmpl-4419ddd1-e7b4-4eb5-9ad9-fa2c3bd28bd3...\n",
      "Fetching observation data for time-04-18-19-391286_chatcmpl-8a791b5a-2696-4456-8469-b298ea8d7b69...\n",
      "Fetching observation data for time-04-18-39-890675_chatcmpl-eaf9a3c3-5a4c-47fd-b0cd-2e33d5513d10...\n",
      "Fetching observation data for time-04-19-00-643241_chatcmpl-b8502377-b89f-4887-86ef-166cb088682b...\n",
      "Fetching observation data for time-04-19-19-097044_chatcmpl-3cd62429-ffb4-472f-a31c-f3f404853ad2...\n",
      "Fetching observation data for time-04-17-02-488780_chatcmpl-0f558cb2-d50c-419e-9e31-9c0095d9bc51...\n",
      "Fetching observation data for time-04-17-19-051215_chatcmpl-34be9d38-fb3f-46ca-b12a-335d09cd148a...\n",
      "Fetching observation data for time-04-17-38-734034_chatcmpl-35d2adec-7c1a-4f6f-9cdf-5e4f950b20b7...\n",
      "Fetching observation data for time-04-17-45-295207_chatcmpl-54d1d106-321e-42a2-83a8-032d12a55a17...\n",
      "Fetching observation data for time-04-17-50-693055_chatcmpl-871eeca0-883c-41ea-8620-5e8b662c487a...\n",
      "Fetching observation data for dbbc7a6d-c94c-42ac-9d1e-dbc4e652ce77...\n",
      "Fetching observation data for time-04-16-14-906085_chatcmpl-52f0b688-a37b-4375-9328-277dd90470c1...\n",
      "Fetching observation data for time-04-16-34-432076_chatcmpl-54301471-6fbb-48e7-9049-8f1156d3ab70...\n",
      "Fetching observation data for time-04-16-43-196027_chatcmpl-d6212ff8-b5ab-4961-b036-1adaa60b7068...\n",
      "Fetching observation data for time-04-15-29-357586_chatcmpl-084249b1-0694-463d-bbae-d7eb155dca6b...\n",
      "Fetching observation data for time-04-15-46-208287_chatcmpl-c152dad7-0ad9-4562-918b-ad2d41298112...\n",
      "Fetching observation data for time-04-13-54-781459_chatcmpl-3470e242-5c6d-4cfe-b7d9-5ed9e57dfb46...\n",
      "Fetching observation data for time-04-14-10-189019_chatcmpl-48f11082-17c0-4014-ae91-77f0b4b8809a...\n",
      "Fetching observation data for time-04-14-27-752692_chatcmpl-8365e4c7-96a1-4ae7-9d28-bb1e91bb9a24...\n",
      "Fetching observation data for time-04-14-47-935440_chatcmpl-697ba74b-b281-4eb0-9549-a54979c89a25...\n",
      "Fetching observation data for time-04-15-05-684112_chatcmpl-1a48fe62-8c6e-436e-bd36-259f61076bac...\n",
      "Fetching observation data for ee590482-c87f-4404-92ee-360380404c00...\n",
      "Fetching observation data for time-04-12-27-167101_chatcmpl-2c25a06c-f430-43ff-b49e-f7dd38477f0e...\n",
      "Fetching observation data for time-04-12-46-968178_chatcmpl-a80e6e8f-fbf7-49c3-9838-3a94a7574af3...\n",
      "Fetching observation data for time-04-12-52-128637_chatcmpl-46868734-238c-4a03-a75a-e685c36ab648...\n",
      "Fetching observation data for time-04-13-03-639126_chatcmpl-248ee198-d3f8-42c8-b8f0-1a04ebed8d2e...\n",
      "Fetching observation data for time-04-11-41-375873_chatcmpl-fbb10099-e32e-42b5-94d8-9a311c157d93...\n",
      "Fetching observation data for time-04-11-56-214106_chatcmpl-bd154376-f77a-4550-a208-ce0c07497fb6...\n",
      "Fetching observation data for time-04-10-53-539974_chatcmpl-8c27ca3b-562d-4c56-8866-f23b5dc11a1e...\n",
      "Fetching observation data for time-04-11-11-144537_chatcmpl-d1708119-9195-40d8-b2ef-33b185e99925...\n",
      "Fetching observation data for time-04-09-31-963118_chatcmpl-b6a4794c-7958-46c2-803c-36f15825205c...\n",
      "Fetching observation data for time-04-09-51-716417_chatcmpl-64b8593a-f33a-4153-9f16-43e271d00d1b...\n",
      "Fetching observation data for time-04-09-56-626771_chatcmpl-fb2c9f48-1261-469a-84da-e3fa9aa72ede...\n",
      "Fetching observation data for time-04-10-13-335270_chatcmpl-517e5f3e-f80d-4bdb-91ba-378f9d2fcf0c...\n",
      "Fetching observation data for time-04-10-31-921663_chatcmpl-7a73c785-90a8-41dd-9532-942c28c1fbbf...\n",
      "Fetching observation data for 8ec9488e-f450-4a88-87d2-0de824d5b4e8...\n",
      "Fetching observation data for time-04-07-48-302568_chatcmpl-a4e6458c-6dcb-4d0b-ad12-6214ed8265b7...\n",
      "Fetching observation data for time-04-08-05-504131_chatcmpl-b5696ff4-a5ef-4b53-b566-750d7d8f13d7...\n",
      "Fetching observation data for time-04-08-24-266647_chatcmpl-fc81ff11-bc8f-4fbb-ac40-384bd598b58d...\n",
      "Fetching observation data for time-04-08-43-387534_chatcmpl-8b24825d-9e31-4cb7-868d-869bb5a33365...\n",
      "Fetching observation data for time-04-09-06-683611_chatcmpl-c908636a-dc2b-436f-a392-f65bd1462c86...\n",
      "Fetching observation data for 4daa698e-3d1d-437d-8280-bfdea0eb5ee9...\n",
      "Fetching observation data for time-04-06-57-641990_chatcmpl-fe161d23-6684-4077-80e9-b11206268bab...\n",
      "Fetching observation data for time-04-07-16-368474_chatcmpl-4e96f480-ef9b-44fd-b5a8-7ba8f1aa05c6...\n",
      "Fetching observation data for time-04-04-52-951535_chatcmpl-a367632a-4f9b-43ee-a939-0f9e656f0fc8...\n",
      "Fetching observation data for time-04-06-04-650879_chatcmpl-1e4978bb-c416-42e4-964e-4a7cf6ac0205...\n",
      "Fetching observation data for time-04-06-11-321289_chatcmpl-9eff0aab-88d0-4881-93cc-73ad106e8bcf...\n",
      "Fetching observation data for time-04-06-16-984792_chatcmpl-134877fd-46b3-45e7-8396-6e8ce2a2c6e3...\n",
      "Fetching observation data for time-04-06-34-151898_chatcmpl-dcdbc656-914f-47f2-93db-81c60cde7127...\n",
      "Fetching observation data for 13c99031-9524-424b-bb54-4103ff4e5087...\n",
      "Raw JSON saved to: /home/han/Projects/reference-benchmark-tinyml_llm/data_analysis/2025/08.26/raw_export/raw_codestral_bcbe_psg_batch.json\n"
     ]
    }
   ],
   "source": [
    "# ALTERNATIVE TO 2.\n",
    "import os\n",
    "import json\n",
    "from time import sleep\n",
    "from langfuse import Langfuse\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "\n",
    "# LANGFUSE_SERVICE_PUBLIC_KEY = \"pk-lf-559a2c0f-ee29-4c32-944c-bf73b5f0ce28\"\n",
    "# LANGFUSE_SERVICE_SECRET_KEY = \"sk-lf-75f8bf7f-a5db-4756-b0dd-d758a2a292c8\"\n",
    "# LANGFUSE_SERVICE_HOST = \"https://langfuse.hann.fi\"\n",
    "\n",
    "\n",
    "if LOCAL_HOST:\n",
    "    langfuse = Langfuse(\n",
    "        secret_key=\"sk-lf-75f8bf7f-a5db-4756-b0dd-d758a2a292c8\",\n",
    "        public_key=\"pk-lf-559a2c0f-ee29-4c32-944c-bf73b5f0ce28\",\n",
    "        host=\"https://langfuse.hann.fi\",\n",
    "    )\n",
    "else:\n",
    "    langfuse = Langfuse(\n",
    "        secret_key=LANGFUSE_SERVICE_SECRET_KEY,\n",
    "        public_key=LANGFUSE_SERVICE_PUBLIC_KEY,\n",
    "        host=LANGFUSE_SERVICE_HOST,\n",
    "    )\n",
    "\n",
    "API_invok_count = 0\n",
    "query_range_num_run = {\"start\": 0, \"end\": 1}\n",
    "\n",
    "\n",
    "class CustomJSONEncoder(json.JSONEncoder):\n",
    "    def __init__(self, *args, LOCAL_HOST=True, **kwargs):\n",
    "        self.LOCAL_HOST = LOCAL_HOST\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "    def default(self, obj):\n",
    "        if isinstance(obj, datetime):\n",
    "            return obj.isoformat()\n",
    "        if hasattr(obj, \"__dict__\"):\n",
    "            data = obj.__dict__.copy()\n",
    "            if \"observations\" in data:\n",
    "                data[\"observations\"] = [\n",
    "                    fetch_observation_data(obs, self.LOCAL_HOST)\n",
    "                    for obs in data[\"observations\"]\n",
    "                ]\n",
    "\n",
    "            return data\n",
    "        return super().default(obj)\n",
    "\n",
    "\n",
    "def fetch_observation_data(observation_id, LOCAL_HOST):\n",
    "    \"\"\"\n",
    "    Fetches observation data from Langfuse and returns its dictionary representation.\n",
    "    \"\"\"\n",
    "    print(f\"Fetching observation data for {observation_id}...\")\n",
    "    global API_invok_count\n",
    "    if API_invok_count >= 0 and not LOCAL_HOST:\n",
    "        print(\"Waiting for 3 seconds to fetch observation data...\")\n",
    "        for _ in tqdm(range(3), desc=\"Progress\", unit=\"s\"):\n",
    "            sleep(1)\n",
    "        API_invok_count = 0\n",
    "\n",
    "    observation_response = langfuse.fetch_observation(observation_id)\n",
    "    API_invok_count += 1\n",
    "\n",
    "    return observation_response.data.dict()\n",
    "\n",
    "\n",
    "def fetch_and_save_complete_data(session_id_list, raw_export_dir, LOCAL_HOST):\n",
    "    \"\"\"\n",
    "    Fetches complete trace data for each session ID and saves it to JSON files.\n",
    "\n",
    "    Parameters:\n",
    "        session_id_list (list): List of session IDs to process.\n",
    "        raw_export_dir (str): Directory path to save raw JSON files.\n",
    "    \"\"\"\n",
    "\n",
    "    def save_complete_data(session_id):\n",
    "        global API_invok_count\n",
    "        if API_invok_count >= 0 and not LOCAL_HOST:\n",
    "            print(\"Waiting for 4 seconds to fetch traces...\")\n",
    "            for _ in tqdm(range(4), desc=\"Progress\", unit=\"s\"):\n",
    "                sleep(1)\n",
    "            API_invok_count = 0\n",
    "\n",
    "        fetch_traces_response = langfuse.fetch_traces(session_id=session_id)\n",
    "        API_invok_count += 1\n",
    "\n",
    "        print(f\"Fetching traces for session {session_id}...\")\n",
    "        # Create directories if they don't exist\n",
    "        os.makedirs(raw_export_dir, exist_ok=True)\n",
    "\n",
    "        # Save complete data to JSON file\n",
    "        # if session_id.startswith(\"da0a\"):\n",
    "        #     session_id = \"phi4_\" + session_id\n",
    "        if \"tpsg\" in session_id:\n",
    "            session_id_ = session_id.replace(\"tpsg\", \"tpusg\")\n",
    "        else:\n",
    "            session_id_ = session_id\n",
    "            \n",
    "        raw_path = os.path.join(raw_export_dir, f\"raw_{session_id_}.json\")\n",
    "        with open(raw_path, \"w\") as f:\n",
    "            json.dump(fetch_traces_response, f, cls=CustomJSONEncoder, indent=2)\n",
    "\n",
    "        print(f\"Raw JSON saved to: {raw_path}\")\n",
    "\n",
    "    for session_id in session_id_list:\n",
    "        save_complete_data(session_id)\n",
    "\n",
    "\n",
    "fetch_and_save_complete_data(session_id_list, raw_export_dir, LOCAL_HOST)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Trim data\n",
    "\n",
    "Here also intercept the runs with fatal errors that need to be excluded from the analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPAN error_04_psg_failure_signal_py_sketch_generator: Failed. Last error: Max retries reached with failure. Last error from execution: Traceback (most recent call last):\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250819233852_psg_codestral:latest/tmp_20250819233852_psg_codestral:latest.py\", line 5, in <module>\n",
      "    for i, confidence in enumerate(output_data[:, 2]):\n",
      "TypeError: string indices must be integers\n",
      "\n",
      "SPAN error_e1_psg_failure_signal_py_sketch_generator: Failed. Last error: Max retries reached with failure. Last error from execution: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250819233617_psg_codestral:latest/tmp_20250819233617_psg_codestral:latest.py\", line 43, in <module>\n",
      "    for i in range(num):\n",
      "TypeError: 'numpy.float32' object cannot be interpreted as an integer\n",
      "\n",
      "SPAN error_e0_psg_failure_signal_py_sketch_generator: Failed. Last error: Max retries reached with failure. Last error from execution: Traceback (most recent call last):\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250819233357_psg_codestral:latest/tmp_20250819233357_psg_codestral:latest.py\", line 2, in <module>\n",
      "    with open(label_path, \"r\") as f:\n",
      "NameError: name 'label_path' is not defined\n",
      "\n",
      "SPAN error_75_psg_failure_signal_py_sketch_generator: Failed. Last error: Max retries reached with failure. Last error from execution: Traceback (most recent call last):\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250819233246_psg_codestral:latest/tmp_20250819233246_psg_codestral:latest.py\", line 2, in <module>\n",
      "    for i, score in enumerate(scores[0]):  # Iterate over each score in the array\n",
      "NameError: name 'scores' is not defined\n",
      "\n",
      "Successfully processed and saved trimmed data for session codestral_a277_psg_batch\n",
      "SPAN error_d7_psg_failure_signal_py_sketch_generator: Failed. Last error: Max retries reached with failure. Last error from execution: Traceback (most recent call last):\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250820042652_psg_codestral:latest/tmp_20250820042652_psg_codestral:latest.py\", line 7, in <module>\n",
      "    interpreter = Interpreter(model_path='models/ssd_mobilenet_v1_1_metadata_1.tflite')  # Corrected path to the model\n",
      "  File \"/home/wuguangh/.conda/envs/tinyml/lib/python3.10/site-packages/tflite_runtime/interpreter.py\", line 464, in __init__\n",
      "    self._interpreter = _interpreter_wrapper.CreateWrapperFromFile(\n",
      "ValueError: Could not open 'models/ssd_mobilenet_v1_1_metadata_1.tflite'.\n",
      "\n",
      "SPAN error_a0_psg_failure_signal_py_sketch_generator: Failed. Last error: Max retries reached with failure. Last error from execution: Traceback (most recent call last):\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250820042252_psg_codestral:latest/tmp_20250820042252_psg_codestral:latest.py\", line 6, in <module>\n",
      "    with open('object_detection_labels.txt', 'r') as f:\n",
      "FileNotFoundError: [Errno 2] No such file or directory: 'object_detection_labels.txt'\n",
      "\n",
      "SPAN error_dd_psg_failure_signal_py_sketch_generator: Failed. Last error: Max retries reached with failure. Last error from execution: Unexpected exception during generation: The output is not a valid code block. Follow the instructions in the prompt return a complete, correct Python script enclosed in a single ```python\n",
      "<generated_code>\n",
      "``` block.\n",
      "Traceback: Traceback (most recent call last):\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/src/processors/pysketch_generator.py\", line 240, in do_pysketch_generation\n",
      "    generated_code = self.extract_code(response_raw, language=\"python\")\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/src/base/base_processor.py\", line 1138, in extract_code\n",
      "    raise ValueError(\"The output is not a valid code block. Follow the instructions in the prompt return a complete, correct Python script enclosed in a single ```python\\n<generated_code>\\n``` block.\")\n",
      "ValueError: The output is not a valid code block. Follow the instructions in the prompt return a complete, correct Python script enclosed in a single ```python\n",
      "<generated_code>\n",
      "``` block.\n",
      "\n",
      "SPAN error_75_psg_failure_signal_py_sketch_generator: Failed. Last error: Max retries reached with failure. Last error from execution: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250820041522_psg_codestral:latest/tmp_20250820041522_psg_codestral:latest.py\", line 47, in <module>\n",
      "    if confidence > confidence_threshold:\n",
      "ValueError: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()\n",
      "\n",
      "SPAN error_fa_psg_failure_signal_py_sketch_generator: Failed. Last error: Max retries reached with failure. Last error from execution: 2025-08-20 04:10:44.744947: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-08-20 04:10:44.749473: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-08-20 04:10:44.763094: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-08-20 04:10:44.783973: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-08-20 04:10:44.790277: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-08-20 04:10:44.806131: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-08-20 04:10:45.650121: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250820041044_psg_codestral:latest/tmp_20250820041044_psg_codestral:latest.py\", line 38, in <module>\n",
      "    interpreter.set_tensor(input_details[0]['index'], input_data)\n",
      "  File \"/home/wuguangh/.conda/envs/tinyml/lib/python3.10/site-packages/tensorflow/lite/python/interpreter.py\", line 732, in set_tensor\n",
      "    self._interpreter.SetTensor(tensor_index, value)\n",
      "ValueError: Cannot set tensor: Got value of type FLOAT32 but expected type UINT8 for input 175, name: normalized_input_image_tensor \n",
      "\n",
      "SPAN error_52_psg_failure_signal_py_sketch_generator: Failed. Last error: Max retries reached with failure. Last error from execution: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250820040925_psg_codestral:latest/tmp_20250820040925_psg_codestral:latest.py\", line 52, in <module>\n",
      "    if np.max(scores[i]) > confidence_threshold:\n",
      "  File \"/home/wuguangh/.conda/envs/tinyml/lib/python3.10/site-packages/numpy/core/fromnumeric.py\", line 2810, in max\n",
      "    return _wrapreduction(a, np.maximum, 'max', axis, None, out,\n",
      "  File \"/home/wuguangh/.conda/envs/tinyml/lib/python3.10/site-packages/numpy/core/fromnumeric.py\", line 88, in _wrapreduction\n",
      "    return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n",
      "ValueError: zero-size array to reduction operation maximum which has no identity\n",
      "\n",
      "SPAN error_d0_psg_failure_signal_py_sketch_generator: Failed. Last error: Max retries reached with failure. Last error from execution: 2025-08-20 04:06:48.792354: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-08-20 04:06:48.796911: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-08-20 04:06:48.810688: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-08-20 04:06:48.831666: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-08-20 04:06:48.838019: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-08-20 04:06:48.854297: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-08-20 04:06:49.772453: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250820040648_psg_codestral:latest/tmp_20250820040648_psg_codestral:latest.py\", line 20, in <module>\n",
      "    with open(LABELS_PATH, 'r') as f:\n",
      "FileNotFoundError: [Errno 2] No such file or directory: 'path/to/your/labels.txt'\n",
      "\n",
      "Successfully processed and saved trimmed data for session codestral_bcbe_psg_batch\n",
      "Total 0 traces skipped. They are []\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "skipped_traces = []\n",
    "\n",
    "\n",
    "def process_existing_observation(observation):\n",
    "    \"\"\"\n",
    "    Processes an existing observation dictionary by trimming unwanted keys.\n",
    "    \"\"\"\n",
    "    unwanted_observation_keys = [\n",
    "        \"completionStartTime\",\n",
    "        \"metadata\",\n",
    "        \"timeToFirstToken\",\n",
    "        \"createdAt\",\n",
    "        \"usageDetails\",\n",
    "        \"usage\",\n",
    "        \"projectId\",\n",
    "        \"unit\",\n",
    "        \"updatedAt\",\n",
    "        \"version\",\n",
    "        \"parentObservationId\",\n",
    "        \"promptId\",\n",
    "        \"promptName\",\n",
    "        \"promptVersion\",\n",
    "        \"modelId\",\n",
    "        \"inputPrice\",\n",
    "        \"outputPrice\",\n",
    "        \"totalPrice\",\n",
    "        # \"modelParameters\",\n",
    "        \"input\",\n",
    "        \"output\",\n",
    "    ]\n",
    "\n",
    "    # If observation is a dictionary containing observation data\n",
    "    if isinstance(observation, dict):\n",
    "        trimmed_observation = {\n",
    "            k: v for k, v in observation.items() if k not in unwanted_observation_keys\n",
    "        }\n",
    "        return trimmed_observation\n",
    "    return observation\n",
    "\n",
    "\n",
    "def trim_data(data):\n",
    "    \"\"\"\n",
    "    Recursively trims the data structure.\n",
    "    \"\"\"\n",
    "\n",
    "    if isinstance(data, dict):\n",
    "        # Process the current dictionary\n",
    "        unwanted_trace_keys = [\n",
    "            \"release\",\n",
    "            \"version\",\n",
    "            \"user_id\",\n",
    "            \"public\",\n",
    "            \"html_path\",\n",
    "            \"scores\",\n",
    "            \"bookmarked\",\n",
    "            \"projectId\",\n",
    "            \"externalId\",\n",
    "            \"page\",\n",
    "            \"limit\",\n",
    "            \"total_pages\",\n",
    "        ]\n",
    "\n",
    "        # If this is a trace that contains observations, check for fatal errors\n",
    "        if \"observations\" in data:\n",
    "            # Check for SPAN observations with fatal errors before processing\n",
    "            skip_trace = False\n",
    "            for obs in data[\"observations\"]:\n",
    "                if isinstance(obs, dict) and obs.get(\"name\").startswith(\"error\"):\n",
    "                    status_message = obs.get(\"statusMessage\", \"\")\n",
    "                    ob_name = obs.get(\"name\")\n",
    "                    print(f\"SPAN {ob_name}: {status_message}\")\n",
    "\n",
    "                    if \"Fatal error\" in status_message:\n",
    "                        print(f\"Found Fatal error in SPAN observation, skipping trace\")\n",
    "                        skip_trace = True\n",
    "                        skipped_traces.append(data[\"name\"])\n",
    "                        break\n",
    "\n",
    "            if skip_trace:\n",
    "                return None  # Signal to skip this trace\n",
    "\n",
    "        # Create a new dictionary with wanted keys and recursively process values\n",
    "        trimmed_data = {}\n",
    "        for key, value in data.items():\n",
    "            if key not in unwanted_trace_keys:\n",
    "                if key == \"observations\":\n",
    "                    # Special handling for observations\n",
    "                    trimmed_data[key] = [\n",
    "                        process_existing_observation(obs) for obs in value\n",
    "                    ]\n",
    "                elif isinstance(value, (dict, list)):\n",
    "                    # Recursively process nested structures\n",
    "                    trimmed_data[key] = trim_data(value)\n",
    "                else:\n",
    "                    trimmed_data[key] = value\n",
    "\n",
    "        return trimmed_data\n",
    "\n",
    "    elif isinstance(data, list):\n",
    "        # Recursively process each item in the list\n",
    "        processed_items = []\n",
    "        for item in data:\n",
    "            processed_item = trim_data(item)\n",
    "            if processed_item is not None:  # Only add items that weren't filtered out\n",
    "                processed_items.append(processed_item)\n",
    "        return processed_items\n",
    "\n",
    "    else:\n",
    "        # Return non-dict, non-list values as is\n",
    "        return data\n",
    "\n",
    "\n",
    "def read_and_trim_data(session_id_list, raw_export_dir, trimmed_export_dir):\n",
    "    \"\"\"\n",
    "    Reads complete data from JSON files, trims the data, and saves the trimmed data to new JSON files.\n",
    "    \"\"\"\n",
    "    os.makedirs(trimmed_export_dir, exist_ok=True)\n",
    "\n",
    "    for session_id in session_id_list:\n",
    "        try:\n",
    "            if session_id.startswith(\"da0a\"):\n",
    "                session_id = \"phi4_\" + session_id\n",
    "            # Read raw data\n",
    "            if \"tpsg\" in session_id:\n",
    "                session_id_ = session_id.replace(\"tpsg\", \"tpusg\")\n",
    "            else:\n",
    "                session_id_ = session_id\n",
    "            raw_path = os.path.join(raw_export_dir, f\"raw_{session_id_}.json\")\n",
    "            with open(raw_path, \"r\") as f:\n",
    "                data = json.load(f)\n",
    "\n",
    "            # Process and trim the data\n",
    "            trimmed_data = trim_data(data)\n",
    "\n",
    "            # If the entire data was filtered out (unlikely but possible)\n",
    "            if trimmed_data is None:\n",
    "                print(\n",
    "                    f\"All traces in session {session_id} were filtered due to fatal errors\"\n",
    "                )\n",
    "                continue\n",
    "\n",
    "            # Save trimmed data\n",
    "            if \"tpsg\" in session_id:\n",
    "                session_id_ = session_id.replace(\"tpsg\", \"tpusg\")\n",
    "            else:\n",
    "                session_id_ = session_id\n",
    "            trimmed_path = os.path.join(\n",
    "                trimmed_export_dir, f\"trimmed_{session_id_}.json\"\n",
    "            )\n",
    "            with open(trimmed_path, \"w\") as f:\n",
    "                json.dump(trimmed_data, f, indent=2)\n",
    "\n",
    "            print(\n",
    "                f\"Successfully processed and saved trimmed data for session {session_id}\"\n",
    "            )\n",
    "\n",
    "            # Optional: Verify trimming worked\n",
    "            # print(f\"Verifying trimmed data for session {session_id}...\")\n",
    "            # verify_trimming(trimmed_path)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing session {session_id}: {str(e)}\")\n",
    "\n",
    "\n",
    "def verify_trimming(trimmed_path):\n",
    "    \"\"\"\n",
    "    Verifies that the trimmed data doesn't contain unwanted keys.\n",
    "    \"\"\"\n",
    "    with open(trimmed_path, \"r\") as f:\n",
    "        trimmed_data = json.load(f)\n",
    "\n",
    "    unwanted_keys = [\n",
    "        \"release\",\n",
    "        \"version\",\n",
    "        \"user_id\",\n",
    "        \"public\",\n",
    "        \"html_path\",\n",
    "        \"scores\",\n",
    "        \"bookmarked\",\n",
    "        \"projectId\",\n",
    "        \"externalId\",\n",
    "        \"page\",\n",
    "        \"limit\",\n",
    "        \"total_pages\",\n",
    "        \"completionStartTime\",\n",
    "        \"metadata\",\n",
    "        \"usageDetails\",\n",
    "        \"timeToFirstToken\",\n",
    "        \"createdAt\",\n",
    "        \"completionTokens\",\n",
    "        \"promptTokens\",\n",
    "        \"projectId\",\n",
    "        \"unit\",\n",
    "        \"updatedAt\",\n",
    "        \"version\",\n",
    "        # \"statusMessage\",\n",
    "        \"parentObservationId\",\n",
    "        \"promptId\",\n",
    "        \"promptName\",\n",
    "        \"promptVersion\",\n",
    "        \"modelId\",\n",
    "        \"inputPrice\",\n",
    "        \"outputPrice\",\n",
    "        \"totalPrice\",\n",
    "        \"calculatedInputCost\",\n",
    "        \"calculatedOutputCost\",\n",
    "        \"calculatedTotalCost\",\n",
    "    ]\n",
    "\n",
    "    def check_keys(obj):\n",
    "        if isinstance(obj, dict):\n",
    "            for key in obj.keys():\n",
    "                if key in unwanted_keys:\n",
    "                    print(f\"Warning: Found unwanted key '{key}' in trimmed data\")\n",
    "            for value in obj.values():\n",
    "                check_keys(value)\n",
    "        elif isinstance(obj, list):\n",
    "            for item in obj:\n",
    "                check_keys(item)\n",
    "\n",
    "    check_keys(trimmed_data)\n",
    "    print(\"Verification complete\")\n",
    "\n",
    "\n",
    "# Usage example:\n",
    "read_and_trim_data(session_id_list, raw_export_dir, raw_export_dir)\n",
    "print(f\"Total {len(skipped_traces)} traces skipped. They are {skipped_traces}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Generate CSV files from JSON\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing session codestral_a277_psg_batch, simple id codestral_a277. Look for /home/han/Projects/reference-benchmark-tinyml_llm/data_analysis/2025/08.26/raw_export/trimmed_codestral_a277_psg_batch.json\n",
      "/home/han/Projects/reference-benchmark-tinyml_llm/data_analysis/2025/08.26/processed_data/codestral_a277/clean_codestral_a277_psg_batch.csv\n",
      "Successfully saved CSV to: /home/han/Projects/reference-benchmark-tinyml_llm/data_analysis/2025/08.26/processed_data/codestral_a277/clean_codestral_a277_psg_batch.csv\n",
      "Processing session codestral_bcbe_psg_batch, simple id codestral_bcbe. Look for /home/han/Projects/reference-benchmark-tinyml_llm/data_analysis/2025/08.26/raw_export/trimmed_codestral_bcbe_psg_batch.json\n",
      "/home/han/Projects/reference-benchmark-tinyml_llm/data_analysis/2025/08.26/processed_data/codestral_bcbe/clean_codestral_bcbe_psg_batch.csv\n",
      "Successfully saved CSV to: /home/han/Projects/reference-benchmark-tinyml_llm/data_analysis/2025/08.26/processed_data/codestral_bcbe/clean_codestral_bcbe_psg_batch.csv\n"
     ]
    }
   ],
   "source": [
    "import traceback\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from dateutil import parser\n",
    "\n",
    "\n",
    "def json_to_csv(session_id):\n",
    "    \"\"\"\n",
    "    Convert JSON trace data to CSV format with aggregated metrics.\n",
    "\n",
    "    Args:\n",
    "        session_id (str): Identifier for the session to process\n",
    "    \"\"\"\n",
    "\n",
    "    def extract_observation_details(observations, trace_id):\n",
    "        \"\"\"Extract and aggregate metrics from observations\"\"\"\n",
    "        metrics = {\n",
    "            \"status\": None,\n",
    "            \"latency\": 0,\n",
    "            \"total_tokens\": 0,\n",
    "            \"prompt_tokens\": 0,\n",
    "            \"completion_tokens\": 0,\n",
    "            \"total_cost\": 0,\n",
    "            \"input_cost\": 0,\n",
    "            \"output_cost\": 0,\n",
    "            \"parameters\": set(),\n",
    "        }\n",
    "\n",
    "        # Process GENERATION observations\n",
    "        for obs in (o for o in observations if o[\"type\"] == \"GENERATION\"):\n",
    "            metrics[\"total_tokens\"] += obs[\"totalTokens\"]\n",
    "            metrics[\"prompt_tokens\"] += obs[\"promptTokens\"]\n",
    "            metrics[\"completion_tokens\"] += obs[\"completionTokens\"]\n",
    "            metrics[\"latency\"] += obs[\"latency\"]\n",
    "            for key, value in obs[\"modelParameters\"].items():\n",
    "                metrics[\"parameters\"].add(key + \":\" + value)\n",
    "\n",
    "            # Add costs if present\n",
    "            for cost_type in [\"Total\", \"Input\", \"Output\"]:\n",
    "                key = f\"calculated{cost_type}Cost\"\n",
    "                metric_key = cost_type.lower() + \"_cost\"\n",
    "                if obs.get(key) is not None:\n",
    "                    metrics[metric_key] += obs[key]\n",
    "        if len(metrics[\"parameters\"]) == 0:\n",
    "            metrics[\"parameters\"] = \"N/A\"\n",
    "        # Process SPAN observations for status\n",
    "        status_indicators = [\n",
    "            obs[\"name\"]\n",
    "            for obs in observations\n",
    "            if obs[\"type\"] == \"SPAN\" and \"start_\" not in obs[\"name\"]\n",
    "        ]\n",
    "\n",
    "        #  if later than 2025-05-19, use status_signal_from_output\n",
    "        if datetime.now() > datetime(2025, 5, 19):\n",
    "            pass\n",
    "        else:\n",
    "            # Determine status\n",
    "            success_signals = sum(\"end_\" in name for name in status_indicators)\n",
    "            failure_signals = sum(\n",
    "                \"failure_signal\" in name for name in status_indicators\n",
    "            )\n",
    "\n",
    "            if success_signals + failure_signals > 1:\n",
    "                raise ValueError(\n",
    "                    f\"Multiple status indicators found in trace {trace_id}\"\n",
    "                )\n",
    "\n",
    "            metrics[\"status\"] = (\n",
    "                \"success\"\n",
    "                if success_signals\n",
    "                else \"failure\" if failure_signals else \"unknown\"\n",
    "            )\n",
    "\n",
    "        metrics[\"prompt_cost\"] = metrics.pop(\"input_cost\")\n",
    "        metrics[\"completion_cost\"] = metrics.pop(\"output_cost\")\n",
    "        metrics[\"latency\"] = round(metrics[\"latency\"] / 1000, 2)\n",
    "        return metrics\n",
    "\n",
    "    def cal_time(trace):\n",
    "        time_diff = datetime.fromisoformat(\n",
    "            trace[\"updatedAt\"].replace(\"Z\", \"+00:00\")\n",
    "        ) - datetime.fromisoformat(trace[\"createdAt\"].replace(\"Z\", \"+00:00\"))\n",
    "        seconds_diff = time_diff.total_seconds()\n",
    "        return seconds_diff\n",
    "\n",
    "    try:\n",
    "\n",
    "        if session_id.startswith(\"da0a\"):\n",
    "            session_id = \"phi4_\" + session_id\n",
    "        simple_session_id = session_id.rsplit(\"_\", 2)[0]\n",
    "\n",
    "        \n",
    "        # Load JSON data\n",
    "        if \"tpsg\" in session_id:\n",
    "                session_id_ = session_id.replace(\"tpsg\", \"tpusg\")\n",
    "        else:\n",
    "                session_id_ = session_id\n",
    "        trimmed_path = os.path.join(raw_export_dir, f\"trimmed_{session_id_}.json\")\n",
    "        print(\n",
    "            f\"Processing session {session_id}, simple id {simple_session_id}. Look for {trimmed_path}\"\n",
    "        )\n",
    "        with open(trimmed_path, \"r\") as file:\n",
    "            traces = json.load(file)[\"data\"]\n",
    "\n",
    "        # Process traces\n",
    "        rows = [\n",
    "            {\n",
    "                \"num_run\": trace[\"metadata\"][\"num_run\"],\n",
    "                \"name\": trace[\"name\"],\n",
    "                \"trace_id\": trace[\"id\"],\n",
    "                \"batch_id\": trace[\"session_id\"],\n",
    "                # \"latency\": cal_time(trace),\n",
    "                # \"latency\": round(trace[\"latency\"], 2),\n",
    "                **extract_observation_details(\n",
    "                    trace[\"observations\"],\n",
    "                    trace[\"id\"],\n",
    "                ),\n",
    "                \"status\": (\n",
    "                    \"failure\"\n",
    "                    if trace[\"output\"][\"status\"].lower() == \"failed\"\n",
    "                    else \"success\"\n",
    "                ),\n",
    "                \"tags\": trace[\"tags\"],\n",
    "                \"timestamp\": int(parser.isoparse(trace[\"timestamp\"]).timestamp()),\n",
    "            }\n",
    "            for trace in traces\n",
    "        ]\n",
    "        # print(rows)\n",
    "        # print(rows)\n",
    "        # Create and save DataFrame\n",
    "        df = pd.DataFrame(rows).sort_values(\"num_run\")\n",
    "\n",
    "        output_dir = os.path.join(processed_data_dir, f\"{simple_session_id}\")\n",
    "        if not os.path.exists(output_dir):\n",
    "            os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "        output_path = os.path.join(output_dir, f\"clean_{session_id_}.csv\")\n",
    "\n",
    "        print(output_path)\n",
    "        df.to_csv(output_path, index=False)\n",
    "        print(f\"Successfully saved CSV to: {output_path}\")\n",
    "\n",
    "    except FileNotFoundError as e:\n",
    "        print(\n",
    "            f\"FileNotFoundError: For session {session_id} not found. Looked for {trimmed_path}\\nError info: \\n{e}\\n\\nTraceback: {traceback.format_exc()}\"\n",
    "        )\n",
    "    except json.JSONDecodeError:\n",
    "        print(f\"Error: Invalid JSON format in input file for session {session_id}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing session {session_id}: {str(e)}\")\n",
    "\n",
    "\n",
    "# Example usage\n",
    "for session_id in session_id_list:\n",
    "    json_to_csv(session_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CSV Generation with Generation Counts\n",
    "\n",
    "This section creates CSV files similar to the langfuse_export section 3, but adds a column for the number of generation attempts used for each trace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing sessions: ['codestral_a277_psg_batch', 'codestral_bcbe_psg_batch']\n",
      "Looking for raw files in: /home/han/Projects/reference-benchmark-tinyml_llm/data_analysis/2025/08.26/raw_export\n",
      "Will save CSV files to: /home/han/Projects/reference-benchmark-tinyml_llm/data_analysis/2025/08.26/processed_data\n",
      "Processing session codestral_a277_psg_batch, simple id codestral_a277. Look for /home/han/Projects/reference-benchmark-tinyml_llm/data_analysis/2025/08.26/raw_export/trimmed_codestral_a277_psg_batch.json\n",
      "/home/han/Projects/reference-benchmark-tinyml_llm/data_analysis/2025/08.26/processed_data/codestral_a277/clean_codestral_a277_psg_batch.csv\n",
      "Successfully saved CSV to: /home/han/Projects/reference-benchmark-tinyml_llm/data_analysis/2025/08.26/processed_data/codestral_a277/clean_codestral_a277_psg_batch.csv\n",
      "Processing session codestral_bcbe_psg_batch, simple id codestral_bcbe. Look for /home/han/Projects/reference-benchmark-tinyml_llm/data_analysis/2025/08.26/raw_export/trimmed_codestral_bcbe_psg_batch.json\n",
      "/home/han/Projects/reference-benchmark-tinyml_llm/data_analysis/2025/08.26/processed_data/codestral_bcbe/clean_codestral_bcbe_psg_batch.csv\n",
      "Successfully saved CSV to: /home/han/Projects/reference-benchmark-tinyml_llm/data_analysis/2025/08.26/processed_data/codestral_bcbe/clean_codestral_bcbe_psg_batch.csv\n"
     ]
    }
   ],
   "source": [
    "import traceback\n",
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "from datetime import datetime\n",
    "from dateutil import parser\n",
    "\n",
    "# Setup paths - same as langfuse_export\n",
    "parent_dir = os.path.dirname(os.getcwd())\n",
    "raw_export_dir = os.path.join(parent_dir, \"raw_export\")\n",
    "processed_data_dir = os.path.join(parent_dir, \"processed_data\")\n",
    "\n",
    "\n",
    "# Get session id list from data directory\n",
    "session_id_list = []\n",
    "\n",
    "for root, dirs, files in os.walk(raw_export_dir):\n",
    "    for file in files:\n",
    "        file_path = os.path.join(root, file)\n",
    "        if \"trimmed_\" in file_path:\n",
    "            session_id = file_path.split('trimmed_')[1].rstrip('.json')\n",
    "            session_id_list.append(session_id)\n",
    "\n",
    "print(f\"Processing sessions: {session_id_list}\")\n",
    "print(f\"Looking for raw files in: {raw_export_dir}\")\n",
    "print(f\"Will save CSV files to: {processed_data_dir}\")\n",
    "\n",
    "\n",
    "def json_to_csv_weighted(session_id):\n",
    "    \"\"\"\n",
    "    Convert JSON trace data to CSV format with aggregated metrics.\n",
    "    Upgraded version that includes generation_count column.\n",
    "\n",
    "    Args:\n",
    "        session_id (str): Identifier for the session to process\n",
    "    \"\"\"\n",
    "\n",
    "    def extract_observation_details(observations, trace_id):\n",
    "        \"\"\"Extract and aggregate metrics from observations\"\"\"\n",
    "        metrics = {\n",
    "            \"status\": None,\n",
    "            \"latency\": 0,\n",
    "            \"total_tokens\": 0,\n",
    "            \"prompt_tokens\": 0,\n",
    "            \"completion_tokens\": 0,\n",
    "            \"total_cost\": 0,\n",
    "            \"input_cost\": 0,\n",
    "            \"output_cost\": 0,\n",
    "            \"parameters\": set(),\n",
    "            \"generation_count\": 0,  # New field for generation count\n",
    "        }\n",
    "\n",
    "        # Count generations and process GENERATION observations\n",
    "        for obs in (o for o in observations if o[\"type\"] == \"GENERATION\"):\n",
    "            metrics[\"generation_count\"] += 1\n",
    "            metrics[\"total_tokens\"] += obs[\"totalTokens\"]\n",
    "            metrics[\"prompt_tokens\"] += obs[\"promptTokens\"]\n",
    "            metrics[\"completion_tokens\"] += obs[\"completionTokens\"]\n",
    "            metrics[\"latency\"] += obs[\"latency\"]\n",
    "            for key, value in obs[\"modelParameters\"].items():\n",
    "                metrics[\"parameters\"].add(key + \":\" + value)\n",
    "\n",
    "            # Add costs if present\n",
    "            for cost_type in [\"Total\", \"Input\", \"Output\"]:\n",
    "                key = f\"calculated{cost_type}Cost\"\n",
    "                metric_key = cost_type.lower() + \"_cost\"\n",
    "                if obs.get(key) is not None:\n",
    "                    metrics[metric_key] += obs[key]\n",
    "                    \n",
    "        if len(metrics[\"parameters\"]) == 0:\n",
    "            metrics[\"parameters\"] = \"N/A\"\n",
    "            \n",
    "        # Process SPAN observations for status\n",
    "        status_indicators = [\n",
    "            obs[\"name\"]\n",
    "            for obs in observations\n",
    "            if obs[\"type\"] == \"SPAN\" and \"start_\" not in obs[\"name\"]\n",
    "        ]\n",
    "\n",
    "        #  if later than 2025-05-19, use status_signal_from_output\n",
    "        if datetime.now() > datetime(2025, 5, 19):\n",
    "            pass\n",
    "        else:\n",
    "            # Determine status\n",
    "            success_signals = sum(\"end_\" in name for name in status_indicators)\n",
    "            failure_signals = sum(\n",
    "                \"failure_signal\" in name for name in status_indicators\n",
    "            )\n",
    "\n",
    "            if success_signals + failure_signals > 1:\n",
    "                raise ValueError(\n",
    "                    f\"Multiple status indicators found in trace {trace_id}\"\n",
    "                )\n",
    "\n",
    "            metrics[\"status\"] = (\n",
    "                \"success\"\n",
    "                if success_signals\n",
    "                else \"failure\" if failure_signals else \"unknown\"\n",
    "            )\n",
    "\n",
    "        metrics[\"prompt_cost\"] = metrics.pop(\"input_cost\")\n",
    "        metrics[\"completion_cost\"] = metrics.pop(\"output_cost\")\n",
    "        metrics[\"latency\"] = round(metrics[\"latency\"] / 1000, 2)\n",
    "        return metrics\n",
    "\n",
    "    def cal_time(trace):\n",
    "        time_diff = datetime.fromisoformat(\n",
    "            trace[\"updatedAt\"].replace(\"Z\", \"+00:00\")\n",
    "        ) - datetime.fromisoformat(trace[\"createdAt\"].replace(\"Z\", \"+00:00\"))\n",
    "        seconds_diff = time_diff.total_seconds()\n",
    "        return seconds_diff\n",
    "\n",
    "    try:\n",
    "        if session_id.startswith(\"da0a\"):\n",
    "            session_id = \"phi4_\" + session_id\n",
    "        simple_session_id = session_id.rsplit(\"_\", 2)[0]\n",
    "\n",
    "        # Load JSON data\n",
    "        if \"tpsg\" in session_id:\n",
    "            session_id_ = session_id.replace(\"tpsg\", \"tpusg\")\n",
    "        else:\n",
    "            session_id_ = session_id\n",
    "        trimmed_path = os.path.join(raw_export_dir, f\"trimmed_{session_id_}.json\")\n",
    "        print(\n",
    "            f\"Processing session {session_id}, simple id {simple_session_id}. Look for {trimmed_path}\"\n",
    "        )\n",
    "        with open(trimmed_path, \"r\") as file:\n",
    "            traces = json.load(file)[\"data\"]\n",
    "\n",
    "        # Process traces\n",
    "        rows = [\n",
    "            {\n",
    "                \"num_run\": trace[\"metadata\"][\"num_run\"],\n",
    "                \"name\": trace[\"name\"],\n",
    "                \"trace_id\": trace[\"id\"],\n",
    "                \"batch_id\": trace[\"session_id\"],\n",
    "                # \"latency\": cal_time(trace),\n",
    "                # \"latency\": round(trace[\"latency\"], 2),\n",
    "                **extract_observation_details(\n",
    "                    trace[\"observations\"],\n",
    "                    trace[\"id\"],\n",
    "                ),\n",
    "                \"status\": (\n",
    "                    \"failure\"\n",
    "                    if trace[\"output\"][\"status\"].lower() == \"failed\"\n",
    "                    else \"success\"\n",
    "                ),\n",
    "                \"tags\": trace[\"tags\"],\n",
    "                \"timestamp\": int(parser.isoparse(trace[\"timestamp\"]).timestamp()),\n",
    "            }\n",
    "            for trace in traces\n",
    "        ]\n",
    "        \n",
    "        # Create and save DataFrame\n",
    "        df = pd.DataFrame(rows).sort_values(\"num_run\")\n",
    "\n",
    "        output_dir = os.path.join(processed_data_dir, f\"{simple_session_id}\")\n",
    "        if not os.path.exists(output_dir):\n",
    "            os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "        output_path = os.path.join(output_dir, f\"clean_{session_id_}.csv\")\n",
    "\n",
    "        print(output_path)\n",
    "        df.to_csv(output_path, index=False)\n",
    "        print(f\"Successfully saved CSV to: {output_path}\")\n",
    "\n",
    "    except FileNotFoundError as e:\n",
    "        print(\n",
    "            f\"FileNotFoundError: For session {session_id} not found. Looked for {trimmed_path}\\nError info: \\n{e}\\n\\nTraceback: {traceback.format_exc()}\"\n",
    "        )\n",
    "    except json.JSONDecodeError:\n",
    "        print(f\"Error: Invalid JSON format in input file for session {session_id}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing session {session_id}: {str(e)}\")\n",
    "\n",
    "\n",
    "\n",
    "# Example usage\n",
    "for session_id in session_id_list:\n",
    "    json_to_csv_weighted(session_id)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llmdev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

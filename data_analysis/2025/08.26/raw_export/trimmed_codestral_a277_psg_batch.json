{
  "data": [
    {
      "id": "0ea3a604",
      "timestamp": "2025-08-19T20:42:44.892000+00:00",
      "name": "0ea3_py_sketch_generator",
      "input": null,
      "output": {
        "status": "success",
        "sketch": "import numpy as np\nfrom ai_edge_litert.interpreter import Interpreter\nimport cv2\n\n# Define paths and parameters\nmodel_path    = \"models/ssd-mobilenet_v1/detect.tflite\"\nlabel_path    = \"models/ssd-mobilenet_v1/labelmap.txt\"\ninput_path    = \"data/object_detection/sheeps.mp4\"\noutput_path    = \"results/object_detection/test_results/sheeps_detections.mp4\"\nconfidence_threshold    = 0.5\n\n# Load labels\nwith open(label_path, 'r') as f:\n    labels = [line.strip() for line in f.readlines()]\n\n# Instantiate the interpreter\ninterpreter = Interpreter(model_path=model_path)\ninterpreter.allocate_tensors()\n\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\n\nheight = input_details[0]['shape'][1]\nwidth = input_details[0]['shape'][2]\n\n# Open video capture and output file\ncap = cv2.VideoCapture(input_path)\nfourcc = cv2.VideoWriter_fourcc(*'mp4v')\nout = cv2.VideoWriter(output_path, fourcc, cap.get(cv2.CAP_PROP_FPS), (width, height))\n\nwhile True:\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    # Preprocess the data with resizing\n    input_frame = cv2.resize(frame, (width, height))\n    input_data = np.expand_dims(input_frame, axis=0)\n    input_data = input_data.astype('uint8')  # Convert to uint8\n\n    # Run inference\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n    interpreter.invoke()\n\n    # Interpret results\n    boxes = interpreter.get_tensor(output_details[0]['index'])[0]\n    classes = interpreter.get_tensor(output_details[1]['index'])[0]\n    scores = interpreter.get_tensor(output_details[2]['index'])[0]\n\n    for i in range(len(scores)):\n        if ((scores[i] > confidence_threshold) and (scores[i] <= 1.0)):\n            ymin = int((boxes[i][0] * height))\n            xmin = int((boxes[i][1] * width))\n            ymax = int((boxes[i][2] * height))\n            xmax = int((boxes[i][3] * width))\n\n            cv2.rectangle(frame, (xmin,ymin), (xmax,ymax), (0, 255, 0), 2)\n            label = '{}: {:.2f}'.format(labels[int(classes[i])], scores[i])\n            cv2.putText(frame, label, (xmin, ymin-10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n\n    # Write frame to output file\n    out.write(frame)\n\n# Release resources\ncap.release()\nout.release()\ncv2.destroyAllWindows()"
      },
      "session_id": "codestral_a277_psg_batch",
      "metadata": {
        "num_run": 30
      },
      "tags": [
        "benchmark",
        "codestral:latest",
        "py_sketch_generator"
      ],
      "latency": 54.522,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-23-42-44-893706_chatcmpl-6fd1ee5e-6102-4488-bc35-cf103f0443ba",
          "traceId": "0ea3a604",
          "type": "GENERATION",
          "name": "0ea3_psg_gen_attempt#1",
          "startTime": "2025-08-19T20:42:44.893000+00:00",
          "endTime": "2025-08-19T20:43:00.554000+00:00",
          "model": "codestral:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 15661.0,
          "environment": "default",
          "completionTokens": 801,
          "totalTokens": 2661,
          "promptTokens": 1860,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-23-43-00-741979_chatcmpl-429f0e51-54eb-4575-bcae-86d878593771",
          "traceId": "0ea3a604",
          "type": "GENERATION",
          "name": "0ea3_psg_gen_attempt#2",
          "startTime": "2025-08-19T20:43:00.741000+00:00",
          "endTime": "2025-08-19T20:43:18.924000+00:00",
          "model": "codestral:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 18183.0,
          "environment": "default",
          "completionTokens": 941,
          "totalTokens": 2989,
          "promptTokens": 2048,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-23-43-19-103565_chatcmpl-30a00b2d-6d4a-47e8-8266-3caa225f504a",
          "traceId": "0ea3a604",
          "type": "GENERATION",
          "name": "0ea3_psg_gen_attempt#3",
          "startTime": "2025-08-19T20:43:19.103000+00:00",
          "endTime": "2025-08-19T20:43:39.415000+00:00",
          "model": "codestral:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 20312.0,
          "environment": "default",
          "completionTokens": 1060,
          "totalTokens": 3108,
          "promptTokens": 2048,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        }
      ],
      "environment": "default",
      "createdAt": "2025-08-19T20:42:45.411Z",
      "updatedAt": "2025-08-19T20:43:50.104Z"
    },
    {
      "id": "265cdce9",
      "timestamp": "2025-08-19T20:41:33.380000+00:00",
      "name": "265c_py_sketch_generator",
      "input": null,
      "output": {
        "status": "success",
        "sketch": "import numpy as np\nfrom ai_edge_litert.interpreter import Interpreter\nimport cv2\n\n# Phase 1: Setup\nmodel_path   = \"models/ssd-mobilenet_v1/detect.tflite\"\nlabel_path   = \"models/ssd-mobilenet_v1/labelmap.txt\"\ninput_path   = \"data/object_detection/sheeps.mp4\"\noutput_path   = \"results/object_detection/test_results/sheeps_detections.mp4\"\nconfidence_threshold   = 0.5\n\n# Load labels\nwith open(label_path, 'r') as f:\n    labels = [line.strip() for line in f.readlines()]\n\n# Load interpreter and get input details\ninterpreter = Interpreter(model_path=model_path)\ninterpreter.allocate_tensors()\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\n\n# Phase 2: Input Acquisition & Preprocessing Loop\ncap = cv2.VideoCapture(input_path)\nwidth = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\nheight = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\nfourcc = cv2.VideoWriter_fourcc(*'mp4v')\nout = cv2.VideoWriter(output_path, fourcc, 30, (width, height))\n\nwhile cap.isOpened():\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    # Preprocess Data\n    input_data = np.expand_dims(frame, axis=0)\n    (input_height, input_width) = input_details[0]['shape'][1:3]\n    resized_input_data = cv2.resize(input_data[0], (input_width, input_height))\n    input_data = np.expand_dims(resized_input_data, axis=0)\n    input_data = input_data.astype('uint8') # Change data type to uint8\n\n    # Phase 3: Inference\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n    interpreter.invoke()\n\n    # Phase 4: Output Interpretation & Handling Loop\n    boxes = interpreter.get_tensor(output_details[0]['index'])[0]\n    classes = interpreter.get_tensor(output_details[1]['index'])[0].astype('int32')\n    scores = interpreter.get_tensor(output_details[2]['index'])[0]\n\n    for i in range(len(scores)):\n        if ((scores[i] > confidence_threshold) and (scores[i] <= 1.0)):\n            ymin, xmin, ymax, xmax = boxes[i]\n            (left, right, top, bottom) = (xmin * width, xmax * width, ymin * height, ymax * height)\n            p1 = (int(left), int(top))\n            p2 = (int(right), int(bottom))\n            cv2.rectangle(frame, p1, p2, (0, 255, 0), 2)\n            text = f\"{labels[classes[i]]}: {int(scores[i]*100)}%\"\n            y = p1[1] - 10 if p1[1] - 10 > 10 else p1[1] + 10\n            cv2.putText(frame, text, (p1[0], y), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n    out.write(frame)\n\ncap.release()\nout.release()\ncv2.destroyAllWindows()"
      },
      "session_id": "codestral_a277_psg_batch",
      "metadata": {
        "num_run": 29
      },
      "tags": [
        "benchmark",
        "codestral:latest",
        "py_sketch_generator"
      ],
      "latency": 59.356,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-23-41-33-381739_chatcmpl-e049d5a3-6a02-49f3-b96f-b7215a8d70ef",
          "traceId": "265cdce9",
          "type": "GENERATION",
          "name": "265c_psg_gen_attempt#1",
          "startTime": "2025-08-19T20:41:33.381000+00:00",
          "endTime": "2025-08-19T20:41:50.820000+00:00",
          "model": "codestral:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 17439.0,
          "environment": "default",
          "completionTokens": 901,
          "totalTokens": 2761,
          "promptTokens": 1860,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-23-41-51-044734_chatcmpl-88f45896-6819-4bb2-abca-66b17733ec8c",
          "traceId": "265cdce9",
          "type": "GENERATION",
          "name": "265c_psg_gen_attempt#2",
          "startTime": "2025-08-19T20:41:51.044000+00:00",
          "endTime": "2025-08-19T20:42:12.141000+00:00",
          "model": "codestral:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 21097.0,
          "environment": "default",
          "completionTokens": 1103,
          "totalTokens": 3151,
          "promptTokens": 2048,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-23-42-12-921963_chatcmpl-c63cc1d1-63f0-44af-b4f0-56d0348ac8b0",
          "traceId": "265cdce9",
          "type": "GENERATION",
          "name": "265c_psg_gen_attempt#3",
          "startTime": "2025-08-19T20:42:12.921000+00:00",
          "endTime": "2025-08-19T20:42:32.737000+00:00",
          "model": "codestral:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 19816.0,
          "environment": "default",
          "completionTokens": 1032,
          "totalTokens": 3080,
          "promptTokens": 2048,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        }
      ],
      "environment": "default",
      "createdAt": "2025-08-19T20:41:33.898Z",
      "updatedAt": "2025-08-19T20:42:43.573Z"
    },
    {
      "id": "c38be04e",
      "timestamp": "2025-08-19T20:40:59.354000+00:00",
      "name": "c38b_py_sketch_generator",
      "input": null,
      "output": {
        "status": "success",
        "sketch": "import cv2\nfrom ai_edge_litert.interpreter import Interpreter\nimport numpy as np\n\n# Phase 1: Setup\nmodel_path  = \"models/ssd-mobilenet_v1/detect.tflite\"\nlabel_path  = \"models/ssd-mobilenet_v1/labelmap.txt\"\ninput_path  = \"data/object_detection/sheeps.mp4\"\noutput_path  = \"results/object_detection/test_results/sheeps_detections.mp4\"\nconfidence_threshold  = 0.5\n\n# Load labels\nwith open(label_path, 'r') as f:\n    labels = [line.strip() for line in f.readlines()]\n\n# Load interpreter\ninterpreter = Interpreter(model_path=model_path)\ninterpreter.allocate_tensors()\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\n\n# Get input shape and dtype\ninput_shape = input_details[0]['shape']\ninput_dtype = input_details[0]['dtype']\n\n# Open video file\nvideo_capture = cv2.VideoCapture(input_path)\n\n# Get frame width, height, and fps for output video writer\nframe_width = int(video_capture.get(3))\nframe_height = int(video_capture.get(4))\nfps = int(video_capture.get(5))\noutput_video = cv2.VideoWriter(output_path, cv2.VideoWriter_fourcc(*'XVID'), fps, (frame_width, frame_height))\n\n# Phase 2: Input Acquisition & Preprocessing Loop\nwhile video_capture.isOpened():\n    ret, frame = video_capture.read()\n    if not ret:\n        break\n\n    # Resize and normalize frame\n    resized_frame = cv2.resize(frame, (input_shape[1], input_shape[2]))\n    normalized_frame = np.array(resized_frame, dtype=np.float32) / 255.0\n\n    # Convert frame to match input tensor shape and dtype\n    input_data = np.expand_dims(normalized_frame, axis=0).astype(input_dtype)\n\n    # Phase 3: Inference\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n    interpreter.invoke()\n\n    # Phase 4: Output Interpretation & Handling\n    output_boxes = interpreter.get_tensor(output_details[0]['index'])\n    output_classes = interpreter.get_tensor(output_details[1]['index'])\n    output_scores = interpreter.get_tensor(output_details[2]['index'])\n    num_detections = int(interpreter.get_tensor(output_details[3]['index']))\n\n    for i in range(num_detections):\n        score = output_scores[0, i]\n        if score >= confidence_threshold:\n            class_id = int(output_classes[0, i])\n            label = labels[class_id]\n            box = output_boxes[0, i] * [frame_height, frame_width, frame_height, frame_width]\n            y1, x1, y2, x2 = box.astype(np.int32)\n\n            # Draw bounding box and label\n            cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n            cv2.putText(frame, f\"{label}: {score:.2f}\", (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n\n    # Write frame to output video\n    output_video.write(frame)\n\n# Phase 5: Cleanup\nvideo_capture.release()\noutput_video.release()\ncv2.destroyAllWindows()"
      },
      "session_id": "codestral_a277_psg_batch",
      "metadata": {
        "num_run": 28
      },
      "tags": [
        "benchmark",
        "codestral:latest",
        "py_sketch_generator"
      ],
      "latency": 21.454,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-23-40-59-355809_chatcmpl-f2525d29-74a3-48b5-9c1d-b2cec8443969",
          "traceId": "c38be04e",
          "type": "GENERATION",
          "name": "c38b_psg_gen_attempt#1",
          "startTime": "2025-08-19T20:40:59.355000+00:00",
          "endTime": "2025-08-19T20:41:20.809000+00:00",
          "model": "codestral:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 21454.0,
          "environment": "default",
          "completionTokens": 1125,
          "totalTokens": 2985,
          "promptTokens": 1860,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        }
      ],
      "environment": "default",
      "createdAt": "2025-08-19T20:40:59.872Z",
      "updatedAt": "2025-08-19T20:41:32.015Z"
    },
    {
      "id": "c873d79f",
      "timestamp": "2025-08-19T20:40:10.825000+00:00",
      "name": "c873_py_sketch_generator",
      "input": null,
      "output": {
        "status": "success",
        "sketch": "import numpy as np\nfrom ai_edge_litert.interpreter import Interpreter\nimport cv2\n\n# Define necessary variables using the provided parameters\nmodel_path   = \"models/ssd-mobilenet_v1/detect.tflite\"\nlabel_path   = \"models/ssd-mobilenet_v1/labelmap.txt\"\ninput_path   = \"data/object_detection/sheeps.mp4\"\noutput_path   = \"results/object_detection/test_results/sheeps_detections.mp4\"\nconfidence_threshold   = 0.5\n\n# Load Labels\nlabels = []\nwith open(label_path, 'r') as f:\n    labels = [line.strip() for line in f]\n\n# Load Interpreter\ninterpreter = Interpreter(model_path=model_path)\ninterpreter.allocate_tensors()\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\n\n# Open Video File and output file for writing\ncap = cv2.VideoCapture(input_path)\nout = cv2.VideoWriter(output_path, cv2.VideoWriter_fourcc(*'mp4v'), cap.get(cv2.CAP_PROP_FPS), (int(cap.get(3)), int(cap.get(4))))\n\nwhile cap.isOpened():\n    ret, frame = cap.read()\n\n    if not ret:\n        break\n\n    # Preprocess Data\n    input_data = cv2.resize(frame, (input_details[0]['shape'][1], input_details[0]['shape'][2]))\n    input_data = np.expand_dims(input_data, axis=0)\n    input_data = (np.float32(input_data) - 127.5) / 127.5 # Normalization here\n    input_data = np.uint8(input_data * 255) # Convert back to UINT8\n\n    # Set Input Tensor and Run Inference\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n    interpreter.invoke()\n\n    # Get Output Tensors\n    boxes = interpreter.get_tensor(output_details[0]['index'])\n    classes = interpreter.get_tensor(output_details[1]['index'])\n    scores = interpreter.get_tensor(output_details[2]['index'])\n    num_detections = int(interpreter.get_tensor(output_details[3]['index']))\n\n    # Interpret Results and Handle Output\n    for i in range(num_detections):\n        if scores[0, i] > confidence_threshold:\n            label = labels[int(classes[0, i])]\n            box = boxes[0, i] * np.array([frame.shape[0], frame.shape[1], frame.shape[0], frame.shape[1]])\n            start_point = (int(box[1]), int(box[0]))\n            end_point = (int(box[3]), int(box[2]))\n            cv2.rectangle(frame, start_point, end_point, (0, 255, 0), 2)\n            cv2.putText(frame, label, start_point, cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2)\n    out.write(frame)\ncap.release()\nout.release()"
      },
      "session_id": "codestral_a277_psg_batch",
      "metadata": {
        "num_run": 27
      },
      "tags": [
        "benchmark",
        "codestral:latest",
        "py_sketch_generator"
      ],
      "latency": 36.217,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-23-40-10-827090_chatcmpl-6e45fcc0-eb16-4d54-b5df-433dd8a8fd1b",
          "traceId": "c873d79f",
          "type": "GENERATION",
          "name": "c873_psg_gen_attempt#1",
          "startTime": "2025-08-19T20:40:10.827000+00:00",
          "endTime": "2025-08-19T20:40:26.487000+00:00",
          "model": "codestral:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 15660.0,
          "environment": "default",
          "completionTokens": 802,
          "totalTokens": 2662,
          "promptTokens": 1860,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-23-40-26-670634_chatcmpl-f8e80989-60fc-4c89-a235-55ed3d5749bb",
          "traceId": "c873d79f",
          "type": "GENERATION",
          "name": "c873_psg_gen_attempt#2",
          "startTime": "2025-08-19T20:40:26.670000+00:00",
          "endTime": "2025-08-19T20:40:47.044000+00:00",
          "model": "codestral:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 20374.0,
          "environment": "default",
          "completionTokens": 1063,
          "totalTokens": 3111,
          "promptTokens": 2048,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        }
      ],
      "environment": "default",
      "createdAt": "2025-08-19T20:40:11.343Z",
      "updatedAt": "2025-08-19T20:40:58.701Z"
    },
    {
      "id": "e2a034f6",
      "timestamp": "2025-08-19T20:39:25.928000+00:00",
      "name": "e2a0_py_sketch_generator",
      "input": null,
      "output": {
        "status": "success",
        "sketch": "input_data  = \"data/object_detection/sheeps.mp4\""
      },
      "session_id": "codestral_a277_psg_batch",
      "metadata": {
        "num_run": 26
      },
      "tags": [
        "benchmark",
        "codestral:latest",
        "py_sketch_generator"
      ],
      "latency": 38.047,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-23-39-25-930139_chatcmpl-c21e9d68-25f3-4d29-a3d7-13e9ac70149d",
          "traceId": "e2a034f6",
          "type": "GENERATION",
          "name": "e2a0_psg_gen_attempt#1",
          "startTime": "2025-08-19T20:39:25.930000+00:00",
          "endTime": "2025-08-19T20:39:41.889000+00:00",
          "model": "codestral:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 15959.0,
          "environment": "default",
          "completionTokens": 805,
          "totalTokens": 2665,
          "promptTokens": 1860,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-23-39-42-073180_chatcmpl-90e1b3f1-50bd-4c6f-a036-5acba138178e",
          "traceId": "e2a034f6",
          "type": "GENERATION",
          "name": "e2a0_psg_gen_attempt#2",
          "startTime": "2025-08-19T20:39:42.073000+00:00",
          "endTime": "2025-08-19T20:40:03.977000+00:00",
          "model": "codestral:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 21904.0,
          "environment": "default",
          "completionTokens": 1148,
          "totalTokens": 3196,
          "promptTokens": 2048,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        }
      ],
      "environment": "default",
      "createdAt": "2025-08-19T20:39:26.448Z",
      "updatedAt": "2025-08-19T20:40:09.520Z"
    },
    {
      "id": "8d7ff800",
      "timestamp": "2025-08-19T20:38:59.294000+00:00",
      "name": "8d7f_py_sketch_generator",
      "input": null,
      "output": {
        "status": "success",
        "sketch": "import cv2\nimport numpy as np\nfrom ai_edge_litert.interpreter import Interpreter\n\n# Load model and labels\nmodel_path  = \"models/ssd-mobilenet_v1/detect.tflite\"\nlabel_path  = \"models/ssd-mobilenet_v1/labelmap.txt\"\ninterpreter = Interpreter(model_path=model_path)\ninterpreter.allocate_tensors()\ninput_details  = \"data/object_detection/sheeps.mp4\"\noutput_details  = \"results/object_detection/test_results/sheeps_detections.mp4\"\nlabels = open(label_path).read().splitlines() # assuming labels are in a text file with one label per line\n\n# Open video file and create output file\nvideo_path = 'your_video_path.mp4'  # replace with your video path\ncap = cv2.VideoCapture(video_path)\noutput_path = 'output_video_path.mp4'   # replace with your desired output video path\nfourcc = cv2.VideoWriter_fourcc(*'MP4V')\nout = cv2.VideoWriter(output_path, fourcc, 30.0, (640, 480))\n\nwhile cap.isOpened():\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    # Preprocess the image for input to our model\n    input_data = cv2.resize(frame, (input_details[0]['shape'][1], input_details[0]['shape'][2]))\n    input_data = np.expand_dims(input_data, axis=0)\n    input_data = (np.float32(input_data) - 127.5) / 127.5 # assuming model expects inputs in range [-1, 1]\n\n    # Perform inference\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n    interpreter.invoke()\n\n    # Interpret results and draw rectangles on the detected objects\n    output_data = interpreter.get_tensor(output_details[0]['index'])\n    predictions = np.squeeze(output_data)\n    label_id = np.argmax(predictions)\n    confidence = predictions[label_id]\n    if confidence > 0.5: # assuming we only care about detections with high confidence\n        label = labels[label_id]\n        cv2.putText(frame, f'{label} {confidence:.2f}', (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n        # assuming model returns bounding boxes in the format [y1, x1, y2, x2] and input shape is [480, 640]\n        h, w = frame.shape[:2]\n        bbox = output_data[0]['locations'][0].numpy() * np.array([h, w, h, w]) # convert to pixels\n        y1, x1, y2, x2 = map(int, bbox)\n        cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n\n    # Write frame to output video file\n    out.write(frame)\n\n# Release resources\ncap.release()\nout.release()\ncv2.destroyAllWindows()"
      },
      "session_id": "codestral_a277_psg_batch",
      "metadata": {
        "num_run": 25
      },
      "tags": [
        "benchmark",
        "codestral:latest",
        "py_sketch_generator"
      ],
      "latency": 19.043,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-23-38-59-295906_chatcmpl-1a00eea1-cb3d-47b3-a338-290169ba61ff",
          "traceId": "8d7ff800",
          "type": "GENERATION",
          "name": "8d7f_psg_gen_attempt#1",
          "startTime": "2025-08-19T20:38:59.295000+00:00",
          "endTime": "2025-08-19T20:39:18.338000+00:00",
          "model": "codestral:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 19043.0,
          "environment": "default",
          "completionTokens": 991,
          "totalTokens": 2851,
          "promptTokens": 1860,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        }
      ],
      "environment": "default",
      "createdAt": "2025-08-19T20:38:59.815Z",
      "updatedAt": "2025-08-19T20:39:24.360Z"
    },
    {
      "id": "049e558d",
      "timestamp": "2025-08-19T20:37:52.743000+00:00",
      "name": "049e_py_sketch_generator",
      "input": null,
      "output": {
        "status": "failed",
        "last_code": "# Get output tensors\noutput_data  = \"results/object_detection/test_results/sheeps_detections.mp4\"\n\n# Interpret results and handle outputs\nfor i, confidence in enumerate(output_data[:, 2]):\n    if confidence > confidence_threshold:\n        x1, y1, x2, y2 = output_data[i, 3:7] * [frame.shape[1], frame.shape[0], frame.shape[1], frame.shape[0]]\n        class_id = int(output_data[i, 1])\n        label = labels[class_id]\n        cv2.rectangle(frame, (int(x1), int(y1)), (int(x2), int(y2)), (0, 255, 0), 2)\n        cv2.putText(frame, label + ': {:.2f}'.format(confidence), (int(x1), int(y1) - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)",
        "last_error": "Max retries reached with failure. Last error from execution: Traceback (most recent call last):\n  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250819233852_psg_codestral:latest/tmp_20250819233852_psg_codestral:latest.py\", line 5, in <module>\n    for i, confidence in enumerate(output_data[:, 2]):\nTypeError: string indices must be integers\n"
      },
      "session_id": "codestral_a277_psg_batch",
      "metadata": {
        "num_run": 24
      },
      "tags": [
        "benchmark",
        "codestral:latest",
        "py_sketch_generator"
      ],
      "latency": 59.426,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-23-37-52-745441_chatcmpl-2d4a7f24-7806-4184-87d4-e6d161566301",
          "traceId": "049e558d",
          "type": "GENERATION",
          "name": "049e_psg_gen_attempt#1",
          "startTime": "2025-08-19T20:37:52.745000+00:00",
          "endTime": "2025-08-19T20:38:08.043000+00:00",
          "model": "codestral:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 15298.0,
          "environment": "default",
          "completionTokens": 782,
          "totalTokens": 2642,
          "promptTokens": 1860,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-23-38-08-227789_chatcmpl-dd603015-99a4-4b17-98ab-514cf12a41d0",
          "traceId": "049e558d",
          "type": "GENERATION",
          "name": "049e_psg_gen_attempt#2",
          "startTime": "2025-08-19T20:38:08.227000+00:00",
          "endTime": "2025-08-19T20:38:25.637000+00:00",
          "model": "codestral:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 17410.0,
          "environment": "default",
          "completionTokens": 899,
          "totalTokens": 2947,
          "promptTokens": 2048,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-23-38-25-841437_chatcmpl-28789cdd-b6fd-42aa-b7aa-b16a001fc1c5",
          "traceId": "049e558d",
          "type": "GENERATION",
          "name": "049e_psg_gen_attempt#3",
          "startTime": "2025-08-19T20:38:25.841000+00:00",
          "endTime": "2025-08-19T20:38:34.997000+00:00",
          "model": "codestral:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 9156.0,
          "environment": "default",
          "completionTokens": 438,
          "totalTokens": 2486,
          "promptTokens": 2048,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-23-38-35-017357_chatcmpl-50a601c8-63fa-4c20-a461-0aab8742c48d",
          "traceId": "049e558d",
          "type": "GENERATION",
          "name": "049e_psg_gen_attempt#4",
          "startTime": "2025-08-19T20:38:35.017000+00:00",
          "endTime": "2025-08-19T20:38:43.707000+00:00",
          "model": "codestral:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 8690.0,
          "environment": "default",
          "completionTokens": 412,
          "totalTokens": 2460,
          "promptTokens": 2048,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-23-38-43-728022_chatcmpl-e3c90125-50d6-4d78-944d-b72596dda246",
          "traceId": "049e558d",
          "type": "GENERATION",
          "name": "049e_psg_gen_attempt#5",
          "startTime": "2025-08-19T20:38:43.728000+00:00",
          "endTime": "2025-08-19T20:38:52.150000+00:00",
          "model": "codestral:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 8422.0,
          "environment": "default",
          "completionTokens": 397,
          "totalTokens": 2445,
          "promptTokens": 2048,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "5820687d-6d10-45fb-bfe6-ba1de43327c3",
          "traceId": "049e558d",
          "type": "SPAN",
          "name": "error_04_psg_failure_signal_py_sketch_generator",
          "startTime": "2025-08-19T20:38:52.171000+00:00",
          "level": "ERROR",
          "statusMessage": "Failed. Last error: Max retries reached with failure. Last error from execution: Traceback (most recent call last):\n  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250819233852_psg_codestral:latest/tmp_20250819233852_psg_codestral:latest.py\", line 5, in <module>\n    for i, confidence in enumerate(output_data[:, 2]):\nTypeError: string indices must be integers\n",
          "calculatedTotalCost": 0.0,
          "environment": "default",
          "completionTokens": 0,
          "totalTokens": 0,
          "promptTokens": 0,
          "costDetails": {},
          "endTime": null,
          "model": null,
          "modelParameters": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null,
          "latency": null
        }
      ],
      "environment": "default",
      "createdAt": "2025-08-19T20:37:53.264Z",
      "updatedAt": "2025-08-19T20:38:58.169Z"
    },
    {
      "id": "af27021c",
      "timestamp": "2025-08-19T20:37:08.164000+00:00",
      "name": "af27_py_sketch_generator",
      "input": null,
      "output": {
        "status": "success",
        "sketch": "import numpy as np\nfrom ai_edge_litert.interpreter import Interpreter\nimport cv2\n\n# Define paths and parameters\nmodel_path   = \"models/ssd-mobilenet_v1/detect.tflite\"\nlabel_path   = \"models/ssd-mobilenet_v1/labelmap.txt\"\ninput_path   = \"data/object_detection/sheeps.mp4\"\noutput_path   = \"results/object_detection/test_results/sheeps_detections.mp4\"\nconfidence_threshold   = 0.5\n\n# Load labels\nwith open(label_path, 'r') as f:\n    labels = [line.strip() for line in f.readlines()]\n\n# Load interpreter and get model details\ninterpreter = Interpreter(model_path=model_path)\ninterpreter.allocate_tensors()\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\n\n# Open video capture and output writer\ncap = cv2.VideoCapture(input_path)\nfourcc = cv2.VideoWriter_fourcc(*'mp4v')\nout = cv2.VideoWriter(output_path, fourcc, cap.get(cv2.CAP_PROP_FPS), (int(cap.get(3)), int(cap.get(4))))\n\n# Process video frames\nwhile cap.isOpened():\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    # Preprocess data\n    input_data = np.expand_dims(cv2.resize(frame, (input_details[0]['shape'][1], input_details[0]['shape'][2])), axis=0)\n\n    # Set input tensor and run inference\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n    interpreter.invoke()\n\n    # Get output tensor and interpret results\n    boxes = interpreter.get_tensor(output_details[0]['index'])[0]\n    class_ids = interpreter.get_tensor(output_details[1]['index'])[0].astype('int')\n    scores = interpreter.get_tensor(output_details[2]['index'])[0]\n\n    # Filter detections based on confidence threshold\n    valid_indices = np.where(scores > confidence_threshold)[0]\n    classes = [labels[i] for i in class_ids[valid_indices]]\n\n    # Draw bounding boxes and labels on frame\n    for box, cls in zip(boxes[valid_indices], classes):\n        ymin, xmin, ymax, xmax = box\n        h, w, _ = frame.shape\n        p1 = (int(xmin * w), int(ymin * h))\n        p2 = (int(xmax * w), int(ymax * h))\n        cv2.rectangle(frame, p1, p2, (0, 255, 0), 2)\n        cv2.putText(frame, cls, p1, cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n\n    # Write frame to output video\n    out.write(frame)\n\n# Release resources\ncap.release()\nout.release()\ncv2.destroyAllWindows()"
      },
      "session_id": "codestral_a277_psg_batch",
      "metadata": {
        "num_run": 23
      },
      "tags": [
        "benchmark",
        "codestral:latest",
        "py_sketch_generator"
      ],
      "latency": 32.399,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-23-37-08-165931_chatcmpl-8af7b6e3-8a17-4640-8347-cb617dda3ab2",
          "traceId": "af27021c",
          "type": "GENERATION",
          "name": "af27_psg_gen_attempt#1",
          "startTime": "2025-08-19T20:37:08.165000+00:00",
          "endTime": "2025-08-19T20:37:22.920000+00:00",
          "model": "codestral:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 14755.0,
          "environment": "default",
          "completionTokens": 752,
          "totalTokens": 2612,
          "promptTokens": 1860,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-23-37-23-131396_chatcmpl-84c645bf-2ca9-4d6f-b7ae-93f9626d2998",
          "traceId": "af27021c",
          "type": "GENERATION",
          "name": "af27_psg_gen_attempt#2",
          "startTime": "2025-08-19T20:37:23.131000+00:00",
          "endTime": "2025-08-19T20:37:40.564000+00:00",
          "model": "codestral:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 17433.0,
          "environment": "default",
          "completionTokens": 900,
          "totalTokens": 2948,
          "promptTokens": 2048,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        }
      ],
      "environment": "default",
      "createdAt": "2025-08-19T20:37:08.684Z",
      "updatedAt": "2025-08-19T20:37:51.830Z"
    },
    {
      "id": "dc6372e8",
      "timestamp": "2025-08-19T20:36:23.607000+00:00",
      "name": "dc63_py_sketch_generator",
      "input": null,
      "output": {
        "status": "success",
        "sketch": "import numpy as np\nfrom ai_edge_litert.interpreter import Interpreter\nimport cv2\n\n# Paths and parameters\nmodel_path   = \"models/ssd-mobilenet_v1/detect.tflite\"\nlabel_path   = \"models/ssd-mobilenet_v1/labelmap.txt\"\ninput_path   = \"data/object_detection/sheeps.mp4\"\noutput_path   = \"results/object_detection/test_results/sheeps_detections.mp4\"\nconfidence_threshold   = 0.5\n\n# Phase 1: Setup\nlabels = open(label_path).read().splitlines()\ninterpreter = Interpreter(model_path=model_path)\ninterpreter.allocate_tensors()\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\nheight, width = input_details[0]['shape'][1:3]\n\n# Phase 2: Input Acquisition & Preprocessing Loop\ncap = cv2.VideoCapture(input_path)\nfourcc = cv2.VideoWriter_fourcc(*'XVID')\nout = cv2.VideoWriter(output_path, fourcc, 30.0, (width, height))\n\nwhile cap.isOpened():\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    # Preprocess Data\n    input_data = cv2.resize(frame, (300, 300))\n    input_data = np.expand_dims(input_data, axis=0).astype(np.uint8)\n\n    # Phase 3: Inference\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n    interpreter.invoke()\n\n    # Phase 4: Output Interpretation & Handling Loop\n    boxes = interpreter.get_tensor(output_details[0]['index'])[0]\n    classes = interpreter.get_tensor(output_details[1]['index'])[0]\n    scores = interpreter.get_tensor(output_details[2]['index'])[0]\n\n    for i in range(len(scores)):\n        if ((scores[i] > confidence_threshold) and (scores[i] <= 1.0)):\n            ymin, xmin, ymax, xmax = boxes[i]\n            xmin = int(xmin * width)\n            ymin = int(ymin * height)\n            xmax = int(xmax * width)\n            ymax = int(ymax * height)\n\n            cv2.rectangle(frame, (xmin, ymin), (xmax, ymax), (0, 255, 0), 2)\n            label = '{}: {:.2f}'.format(labels[int(classes[i])], scores[i])\n            cv2.putText(frame, label, (xmin, ymin-10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n\n    # Handle Output\n    out.write(frame)\n\n# Phase 5: Cleanup\ncap.release()\nout.release()\ncv2.destroyAllWindows()"
      },
      "session_id": "codestral_a277_psg_batch",
      "metadata": {
        "num_run": 22
      },
      "tags": [
        "benchmark",
        "codestral:latest",
        "py_sketch_generator"
      ],
      "latency": 32.975,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-23-36-23-608670_chatcmpl-d276f017-d359-40ce-a364-8c375c82e92c",
          "traceId": "dc6372e8",
          "type": "GENERATION",
          "name": "dc63_psg_gen_attempt#1",
          "startTime": "2025-08-19T20:36:23.608000+00:00",
          "endTime": "2025-08-19T20:36:39.204000+00:00",
          "model": "codestral:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 15596.0,
          "environment": "default",
          "completionTokens": 799,
          "totalTokens": 2659,
          "promptTokens": 1860,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-23-36-39-382514_chatcmpl-5ed4163c-0268-492b-8c64-9ff9152b294f",
          "traceId": "dc6372e8",
          "type": "GENERATION",
          "name": "dc63_psg_gen_attempt#2",
          "startTime": "2025-08-19T20:36:39.382000+00:00",
          "endTime": "2025-08-19T20:36:56.583000+00:00",
          "model": "codestral:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 17201.0,
          "environment": "default",
          "completionTokens": 887,
          "totalTokens": 2935,
          "promptTokens": 2048,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        }
      ],
      "environment": "default",
      "createdAt": "2025-08-19T20:36:24.126Z",
      "updatedAt": "2025-08-19T20:37:07.266Z"
    },
    {
      "id": "e14fc1a1",
      "timestamp": "2025-08-19T20:35:08.078000+00:00",
      "name": "e14f_py_sketch_generator",
      "input": null,
      "output": {
        "status": "failed",
        "last_code": "import cv2\nimport numpy as np\nfrom tflite_runtime.interpreter import Interpreter\n\n# Define paths/parameters\nmodel_path  = \"models/ssd-mobilenet_v1/detect.tflite\"\ninput_path  = \"data/object_detection/sheeps.mp4\"\nlabel_path  = \"models/ssd-mobilenet_v1/labelmap.txt\"\noutput_path  = \"results/object_detection/test_results/sheeps_detections.mp4\"\nthreshold = 0.5 # threshold for filtering out weak detections\n\n# Load labels\nwith open(label_path, 'r') as f:\n    labels = [line.strip() for line in f.readlines()]\n\n# Load interpreter\ninterpreter = Interpreter(model_path=model_path)\ninterpreter.allocate_tensors()\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\nheight = input_details[0]['shape'][1]\nwidth = input_details[0]['shape'][2]\n\n# Input acquisition & preprocessing loop\ncap = cv2.VideoCapture(input_path)\nwhile cap.isOpened():\n    ret, frame = cap.read()\n    if not ret:\n        break\n    resized_frame = cv2.resize(frame, (width, height))\n    input_data = np.expand_dims(resized_frame, axis=0)\n\n    # Inference\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n    interpreter.invoke()\n\n    # Output interpretation & handling loop\n    boxes = interpreter.get_tensor(output_details[0]['index'])[0]\n    classes = interpreter.get_tensor(output_details[1]['index'])[0]\n    scores = interpreter.get_tensor(output_details[2]['index'])[0]\n    num = interpreter.get_tensor(output_details[3]['index'])[0]\n\n    for i in range(num):\n        if ((scores[i] > threshold) and (scores[i] <= 1.0)):\n            ymin, xmin, ymax, xmax = boxes[i]\n            class_id = int(classes[i]) + 1\n            label = labels[class_id]\n            score = scores[i]\n\n            # Handle output (e.g., draw bounding box)\n            startX = int(xmin * frame.shape[1])\n            startY = int(ymin * frame.shape[0])\n            endX = int(xmax * frame.shape[1])\n            endY = int(ymax * frame.shape[0])\n            cv2.rectangle(frame, (startX, startY), (endX, endY), (0, 255, 0), 2)\n            y = startY - 15 if startY - 15 > 15 else startY + 15\n            text = \"{}: {:.2f}\".format(label, score)\n            cv2.putText(frame, text, (startX, y), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 1)\n    # Save frame with bounding boxes to output directory\n    out_path = f'{output_path}{frame_num}.jpg'\n    cv2.imwrite(out_path, frame)\ncap.release()",
        "last_error": "Max retries reached with failure. Last error from execution: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\nTraceback (most recent call last):\n  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250819233617_psg_codestral:latest/tmp_20250819233617_psg_codestral:latest.py\", line 43, in <module>\n    for i in range(num):\nTypeError: 'numpy.float32' object cannot be interpreted as an integer\n"
      },
      "session_id": "codestral_a277_psg_batch",
      "metadata": {
        "num_run": 21
      },
      "tags": [
        "benchmark",
        "codestral:latest",
        "py_sketch_generator"
      ],
      "latency": 69.708,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-23-35-08-080121_chatcmpl-57a858a9-09bf-41b7-9379-23f69bb6a2a2",
          "traceId": "e14fc1a1",
          "type": "GENERATION",
          "name": "e14f_psg_gen_attempt#1",
          "startTime": "2025-08-19T20:35:08.080000+00:00",
          "endTime": "2025-08-19T20:35:27.990000+00:00",
          "model": "codestral:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 19910.0,
          "environment": "default",
          "completionTokens": 1040,
          "totalTokens": 2900,
          "promptTokens": 1860,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-23-35-28-180902_chatcmpl-d4bdbbda-5531-4505-9316-3c13c2313f8b",
          "traceId": "e14fc1a1",
          "type": "GENERATION",
          "name": "e14f_psg_gen_attempt#2",
          "startTime": "2025-08-19T20:35:28.180000+00:00",
          "endTime": "2025-08-19T20:35:48.568000+00:00",
          "model": "codestral:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 20388.0,
          "environment": "default",
          "completionTokens": 1065,
          "totalTokens": 3113,
          "promptTokens": 2048,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-23-35-48-751191_chatcmpl-6efd446c-7fd0-492d-a96a-a59b20423209",
          "traceId": "e14fc1a1",
          "type": "GENERATION",
          "name": "e14f_psg_gen_attempt#3",
          "startTime": "2025-08-19T20:35:48.751000+00:00",
          "endTime": "2025-08-19T20:35:53.420000+00:00",
          "model": "codestral:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 4669.0,
          "environment": "default",
          "completionTokens": 187,
          "totalTokens": 2235,
          "promptTokens": 2048,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-23-35-53-446243_chatcmpl-d38f25ed-541a-4500-8987-12330d650a58",
          "traceId": "e14fc1a1",
          "type": "GENERATION",
          "name": "e14f_psg_gen_attempt#4",
          "startTime": "2025-08-19T20:35:53.446000+00:00",
          "endTime": "2025-08-19T20:35:58.163000+00:00",
          "model": "codestral:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 4717.0,
          "environment": "default",
          "completionTokens": 190,
          "totalTokens": 2238,
          "promptTokens": 2048,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-23-35-58-188628_chatcmpl-b511db9d-b1f6-4bd8-b60b-0998eb6733d7",
          "traceId": "e14fc1a1",
          "type": "GENERATION",
          "name": "e14f_psg_gen_attempt#5",
          "startTime": "2025-08-19T20:35:58.188000+00:00",
          "endTime": "2025-08-19T20:36:17.429000+00:00",
          "model": "codestral:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 19241.0,
          "environment": "default",
          "completionTokens": 1001,
          "totalTokens": 3049,
          "promptTokens": 2048,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "b68ebb6f-4034-4dd7-8063-3bf2b689a809",
          "traceId": "e14fc1a1",
          "type": "SPAN",
          "name": "error_e1_psg_failure_signal_py_sketch_generator",
          "startTime": "2025-08-19T20:36:17.788000+00:00",
          "level": "ERROR",
          "statusMessage": "Failed. Last error: Max retries reached with failure. Last error from execution: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\nTraceback (most recent call last):\n  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250819233617_psg_codestral:latest/tmp_20250819233617_psg_codestral:latest.py\", line 43, in <module>\n    for i in range(num):\nTypeError: 'numpy.float32' object cannot be interpreted as an integer\n",
          "calculatedTotalCost": 0.0,
          "environment": "default",
          "completionTokens": 0,
          "totalTokens": 0,
          "promptTokens": 0,
          "costDetails": {},
          "endTime": null,
          "model": null,
          "modelParameters": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null,
          "latency": null
        }
      ],
      "environment": "default",
      "createdAt": "2025-08-19T20:35:08.598Z",
      "updatedAt": "2025-08-19T20:36:23.217Z"
    },
    {
      "id": "6e89736c",
      "timestamp": "2025-08-19T20:34:04.070000+00:00",
      "name": "6e89_py_sketch_generator",
      "input": null,
      "output": {
        "status": "success",
        "sketch": "import numpy as np\nfrom ai_edge_litert.interpreter import Interpreter\nimport cv2\n\n# Paths and parameters\nmodel_path  = \"models/ssd-mobilenet_v1/detect.tflite\"\nlabel_path  = \"models/ssd-mobilenet_v1/labelmap.txt\"\ninput_path  = \"data/object_detection/sheeps.mp4\"\noutput_path  = \"results/object_detection/test_results/sheeps_detections.mp4\"\nconfidence_threshold  = 0.5\n\n# Load labels\nwith open(label_path, 'r') as f:\n    labels = [line.strip() for line in f.readlines()]\n\n# Load interpreter and allocate tensors\ninterpreter = Interpreter(model_path=model_path)\ninterpreter.allocate_tensors()\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\n\n# Function to draw bounding boxes on the frame\ndef draw_boxes(frame, boxes, classes, scores, labels, confidence_threshold):\n    for i in range(len(scores)):\n        if ((scores[i] > confidence_threshold) and (scores[i] <= 1.0)):\n            # Get the box coordinates\n            ymin = int(max(1,(boxes[i][0] * frame.shape[0])))\n            xmin = int(max(1,(boxes[i][1] * frame.shape[1])))\n            ymax = int(min(frame.shape[0],(boxes[i][2] * frame.shape[0])))\n            xmax = int(min(frame.shape[1],(boxes[i][3] * frame.shape[1])))\n\n            # Draw the box and label on the frame\n            cv2.rectangle(frame, (xmin, ymin), (xmax, ymax), (0, 255, 0), 2)\n            label = '{}: {:.2f}'.format(labels[int(classes[i])], scores[i])\n            cv2.putText(frame, label, (xmin, ymin-10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n    return frame\n\n# Input acquisition and preprocessing loop\ncap = cv2.VideoCapture(input_path)\nwidth = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\nheight = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\nfps = cap.get(cv2.CAP_PROP_FPS)\nfourcc = cv2.VideoWriter_fourcc(*'mp4v')\nout = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\nwhile cap.isOpened():\n    ret, frame = cap.read()\n    if not ret:\n        break\n    # Resize the frame to match the expected input size\n    resized_frame = cv2.resize(frame, (300, 300))\n    input_data = np.expand_dims(resized_frame, axis=0).astype(input_details[0]['dtype'])\n\n    # Inference\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n    interpreter.invoke()\n\n    # Output interpretation and handling loop\n    boxes = interpreter.get_tensor(output_details[0]['index'])\n    classes = interpreter.get_tensor(output_details[1]['index'])\n    scores = interpreter.get_tensor(output_details[2]['index'])\n\n    # Draw bounding boxes on the frame and write to output video file\n    output_frame = draw_boxes(frame, boxes[0], classes[0], scores[0], labels, confidence_threshold)\n    out.write(output_frame)\n\n# Release resources\ncap.release()\nout.release()\ncv2.destroyAllWindows()"
      },
      "session_id": "codestral_a277_psg_batch",
      "metadata": {
        "num_run": 20
      },
      "tags": [
        "benchmark",
        "codestral:latest",
        "py_sketch_generator"
      ],
      "latency": 52.01,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-23-34-04-072366_chatcmpl-b87161b8-8b24-43ef-a18e-4618a53e7349",
          "traceId": "6e89736c",
          "type": "GENERATION",
          "name": "6e89_psg_gen_attempt#1",
          "startTime": "2025-08-19T20:34:04.072000+00:00",
          "endTime": "2025-08-19T20:34:15.271000+00:00",
          "model": "codestral:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 11199.0,
          "environment": "default",
          "completionTokens": 553,
          "totalTokens": 2413,
          "promptTokens": 1860,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-23-34-15-398267_chatcmpl-58ad8f78-fd5a-4a79-9101-a85ed9b19bd2",
          "traceId": "6e89736c",
          "type": "GENERATION",
          "name": "6e89_psg_gen_attempt#2",
          "startTime": "2025-08-19T20:34:15.398000+00:00",
          "endTime": "2025-08-19T20:34:35.011000+00:00",
          "model": "codestral:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 19613.0,
          "environment": "default",
          "completionTokens": 1022,
          "totalTokens": 3070,
          "promptTokens": 2048,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-23-34-35-191447_chatcmpl-20985fd1-fe25-41d5-b966-761f0e1f1390",
          "traceId": "6e89736c",
          "type": "GENERATION",
          "name": "6e89_psg_gen_attempt#3",
          "startTime": "2025-08-19T20:34:35.191000+00:00",
          "endTime": "2025-08-19T20:34:56.082000+00:00",
          "model": "codestral:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 20891.0,
          "environment": "default",
          "completionTokens": 1093,
          "totalTokens": 3141,
          "promptTokens": 2048,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        }
      ],
      "environment": "default",
      "createdAt": "2025-08-19T20:34:04.590Z",
      "updatedAt": "2025-08-19T20:35:07.245Z"
    },
    {
      "id": "e0492242",
      "timestamp": "2025-08-19T20:32:57.171000+00:00",
      "name": "e049_py_sketch_generator",
      "input": null,
      "output": {
        "status": "failed",
        "last_code": "# Define the labels variable\nwith open(label_path, \"r\") as f:\n    labels = [line.strip() for line in f]\n\nlabel = labels[int(classes[i])]",
        "last_error": "Max retries reached with failure. Last error from execution: Traceback (most recent call last):\n  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250819233357_psg_codestral:latest/tmp_20250819233357_psg_codestral:latest.py\", line 2, in <module>\n    with open(label_path, \"r\") as f:\nNameError: name 'label_path' is not defined\n"
      },
      "session_id": "codestral_a277_psg_batch",
      "metadata": {
        "num_run": 19
      },
      "tags": [
        "benchmark",
        "codestral:latest",
        "py_sketch_generator"
      ],
      "latency": 60.036,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-23-32-57-172521_chatcmpl-4e2ce19b-c7e3-4e30-b167-eddfedfe06d4",
          "traceId": "e0492242",
          "type": "GENERATION",
          "name": "e049_psg_gen_attempt#1",
          "startTime": "2025-08-19T20:32:57.172000+00:00",
          "endTime": "2025-08-19T20:33:11.152000+00:00",
          "model": "codestral:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 13980.0,
          "environment": "default",
          "completionTokens": 709,
          "totalTokens": 2569,
          "promptTokens": 1860,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-23-33-11-285956_chatcmpl-fd560692-049a-4357-ade6-4ea7f8840262",
          "traceId": "e0492242",
          "type": "GENERATION",
          "name": "e049_psg_gen_attempt#2",
          "startTime": "2025-08-19T20:33:11.285000+00:00",
          "endTime": "2025-08-19T20:33:27.550000+00:00",
          "model": "codestral:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 16265.0,
          "environment": "default",
          "completionTokens": 835,
          "totalTokens": 2883,
          "promptTokens": 2048,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-23-33-27-757008_chatcmpl-26bc1a6f-cc53-47a3-8d19-69638f69e89e",
          "traceId": "e0492242",
          "type": "GENERATION",
          "name": "e049_psg_gen_attempt#3",
          "startTime": "2025-08-19T20:33:27.757000+00:00",
          "endTime": "2025-08-19T20:33:45.046000+00:00",
          "model": "codestral:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 17289.0,
          "environment": "default",
          "completionTokens": 892,
          "totalTokens": 2940,
          "promptTokens": 2048,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-23-33-45-258743_chatcmpl-5f48d768-98cb-4c64-9f4d-4f22a18959cd",
          "traceId": "e0492242",
          "type": "GENERATION",
          "name": "e049_psg_gen_attempt#4",
          "startTime": "2025-08-19T20:33:45.258000+00:00",
          "endTime": "2025-08-19T20:33:53.128000+00:00",
          "model": "codestral:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 7870.0,
          "environment": "default",
          "completionTokens": 366,
          "totalTokens": 2414,
          "promptTokens": 2048,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-23-33-53-150494_chatcmpl-8e395d86-7eb1-41bb-ad8d-50d168948f33",
          "traceId": "e0492242",
          "type": "GENERATION",
          "name": "e049_psg_gen_attempt#5",
          "startTime": "2025-08-19T20:33:53.150000+00:00",
          "endTime": "2025-08-19T20:33:57.185000+00:00",
          "model": "codestral:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 4035.0,
          "environment": "default",
          "completionTokens": 152,
          "totalTokens": 2200,
          "promptTokens": 2048,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "6f873433-efb4-41f5-ad57-145de2631d14",
          "traceId": "e0492242",
          "type": "SPAN",
          "name": "error_e0_psg_failure_signal_py_sketch_generator",
          "startTime": "2025-08-19T20:33:57.208000+00:00",
          "level": "ERROR",
          "statusMessage": "Failed. Last error: Max retries reached with failure. Last error from execution: Traceback (most recent call last):\n  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250819233357_psg_codestral:latest/tmp_20250819233357_psg_codestral:latest.py\", line 2, in <module>\n    with open(label_path, \"r\") as f:\nNameError: name 'label_path' is not defined\n",
          "calculatedTotalCost": 0.0,
          "environment": "default",
          "completionTokens": 0,
          "totalTokens": 0,
          "promptTokens": 0,
          "costDetails": {},
          "endTime": null,
          "model": null,
          "modelParameters": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null,
          "latency": null
        }
      ],
      "environment": "default",
      "createdAt": "2025-08-19T20:32:57.690Z",
      "updatedAt": "2025-08-19T20:34:02.513Z"
    },
    {
      "id": "757e726a",
      "timestamp": "2025-08-19T20:31:37.623000+00:00",
      "name": "757e_py_sketch_generator",
      "input": null,
      "output": {
        "status": "failed",
        "last_code": "# Draw bounding boxes on the frame based on the inference results\nfor i, score in enumerate(scores[0]):  # Iterate over each score in the array\n    if score > confidence_threshold:\n        box = boxes[0][i]  # Get the bounding box coordinates\n        if len(box) == 4:  # Check if we have the correct number of coordinates\n            (ymin, xmin, ymax, xmax) = tuple([int(b * dimension) for b, dimension in zip(box, frame.shape[:2])])\n            cv2.rectangle(frame, (xmin, ymin), (xmax, ymax), (10, 255, 0), 2)\n            label = labels[classes[0][i]] if classes[0][i] < len(labels) else 'Unknown'\n            cv2.putText(frame, f\"{label}: {int(score*100)}%\", (xmin, ymin - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (10, 255, 0), 2)\n        else:\n            print(\"Invalid bounding box coordinates:\", box)",
        "last_error": "Max retries reached with failure. Last error from execution: Traceback (most recent call last):\n  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250819233246_psg_codestral:latest/tmp_20250819233246_psg_codestral:latest.py\", line 2, in <module>\n    for i, score in enumerate(scores[0]):  # Iterate over each score in the array\nNameError: name 'scores' is not defined\n"
      },
      "session_id": "codestral_a277_psg_batch",
      "metadata": {
        "num_run": 18
      },
      "tags": [
        "benchmark",
        "codestral:latest",
        "py_sketch_generator"
      ],
      "latency": 72.825,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-23-31-37-625082_chatcmpl-89b897b4-b3ae-4ae1-88bb-547146e3dea1",
          "traceId": "757e726a",
          "type": "GENERATION",
          "name": "757e_psg_gen_attempt#1",
          "startTime": "2025-08-19T20:31:37.625000+00:00",
          "endTime": "2025-08-19T20:31:54.113000+00:00",
          "model": "codestral:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 16488.0,
          "environment": "default",
          "completionTokens": 849,
          "totalTokens": 2709,
          "promptTokens": 1860,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-23-31-54-297039_chatcmpl-ba6fcb32-cbdd-4bca-90f9-4cdcccc6df56",
          "traceId": "757e726a",
          "type": "GENERATION",
          "name": "757e_psg_gen_attempt#2",
          "startTime": "2025-08-19T20:31:54.297000+00:00",
          "endTime": "2025-08-19T20:32:14.224000+00:00",
          "model": "codestral:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 19927.0,
          "environment": "default",
          "completionTokens": 1039,
          "totalTokens": 3087,
          "promptTokens": 2048,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-23-32-14-446061_chatcmpl-4ac4e17c-de19-4bea-b8fd-fc58f1c953a4",
          "traceId": "757e726a",
          "type": "GENERATION",
          "name": "757e_psg_gen_attempt#3",
          "startTime": "2025-08-19T20:32:14.446000+00:00",
          "endTime": "2025-08-19T20:32:34.210000+00:00",
          "model": "codestral:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 19764.0,
          "environment": "default",
          "completionTokens": 1030,
          "totalTokens": 3078,
          "promptTokens": 2048,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-23-32-34-429017_chatcmpl-28a2a29c-e633-48fb-87b2-bdf351164038",
          "traceId": "757e726a",
          "type": "GENERATION",
          "name": "757e_psg_gen_attempt#4",
          "startTime": "2025-08-19T20:32:34.429000+00:00",
          "endTime": "2025-08-19T20:32:46.385000+00:00",
          "model": "codestral:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 11956.0,
          "environment": "default",
          "completionTokens": 594,
          "totalTokens": 2642,
          "promptTokens": 2048,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-23-32-46-408775_chatcmpl-0b246ebe-70a0-4037-8e0e-ef0d4eff63d0",
          "traceId": "757e726a",
          "type": "GENERATION",
          "name": "757e_psg_gen_attempt#5",
          "startTime": "2025-08-19T20:32:46.408000+00:00",
          "endTime": "2025-08-19T20:32:50.446000+00:00",
          "model": "codestral:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 4038.0,
          "environment": "default",
          "completionTokens": 152,
          "totalTokens": 2200,
          "promptTokens": 2048,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "81c3309d-8919-41f2-a60b-1c40a7d949b3",
          "traceId": "757e726a",
          "type": "SPAN",
          "name": "error_75_psg_failure_signal_py_sketch_generator",
          "startTime": "2025-08-19T20:32:50.450000+00:00",
          "level": "ERROR",
          "statusMessage": "Failed. Last error: Max retries reached with failure. Last error from execution: Traceback (most recent call last):\n  File \"/home/wuguangh/Projects/tinyml-autopilot/results/object_detection/sketches/tmp_20250819233246_psg_codestral:latest/tmp_20250819233246_psg_codestral:latest.py\", line 2, in <module>\n    for i, score in enumerate(scores[0]):  # Iterate over each score in the array\nNameError: name 'scores' is not defined\n",
          "calculatedTotalCost": 0.0,
          "environment": "default",
          "completionTokens": 0,
          "totalTokens": 0,
          "promptTokens": 0,
          "costDetails": {},
          "endTime": null,
          "model": null,
          "modelParameters": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null,
          "latency": null
        }
      ],
      "environment": "default",
      "createdAt": "2025-08-19T20:31:38.142Z",
      "updatedAt": "2025-08-19T20:32:55.985Z"
    },
    {
      "id": "a8f76dc3",
      "timestamp": "2025-08-19T20:30:45.044000+00:00",
      "name": "a8f7_py_sketch_generator",
      "input": null,
      "output": {
        "status": "success",
        "sketch": "import cv2\nfrom ai_edge_litert.interpreter import Interpreter\nimport numpy as np\n\n# Define variables\nmodel_path   = \"models/ssd-mobilenet_v1/detect.tflite\"\nlabel_path   = \"models/ssd-mobilenet_v1/labelmap.txt\"\ninput_path   = \"data/object_detection/sheeps.mp4\"\noutput_path   = \"results/object_detection/test_results/sheeps_detections.mp4\"\nconfidence_threshold   = 0.5\n\n# Load labels\nwith open(label_path, 'r') as f:\n    labels = [line.strip() for line in f.readlines()]\n\n# Load interpreter and allocate tensors\ninterpreter = Interpreter(model_path=model_path)\ninterpreter.allocate_tensors()\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\n\n# Open video file\ncap = cv2.VideoCapture(input_path)\nframe_width = int(cap.get(3))\nframe_height = int(cap.get(4))\nout = cv2.VideoWriter(output_path, cv2.VideoWriter_fourcc(*'mp4v'), 30, (frame_width, frame_height))\n\n# Process video frames\nwhile cap.isOpened():\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    # Preprocess data\n    input_data = cv2.resize(frame, (input_details[0]['shape'][1], input_details[0]['shape'][2]))\n    input_data = np.expand_dims(input_data, axis=0)\n\n    # Set input tensor and run inference\n    interpreter.set_tensor(input_details[0]['index'], input_data.astype(np.uint8))  # Change to uint8 data type\n    interpreter.invoke()\n\n    # Get output tensor and interpret results\n    boxes = interpreter.get_tensor(output_details[0]['index'])[0]\n    classes = interpreter.get_tensor(output_details[1]['index'])[0].astype(np.int32)\n    scores = interpreter.get_tensor(output_details[2]['index'])[0]\n\n    # Loop over the detections\n    for i in range(len(scores)):\n        if ((scores[i] > confidence_threshold) and (scores[i] <= 1.0)):\n            ymin = int((boxes[i][0] * frame_height))\n            xmin = int((boxes[i][1] * frame_width))\n            ymax = int((boxes[i][2] * frame_height))\n            xmax = int((boxes[i][3] * frame_width))\n\n            cv2.rectangle(frame, (xmin, ymin), (xmax, ymax), (10, 255, 0), 4)\n            object_name = labels[int(classes[i])]\n            label = '%s: %d%%' % (object_name, int(scores[i]*100))\n            labelSize, baseLine = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.7, 2)\n            ymin = max(ymin, labelSize[1])\n            cv2.rectangle(frame, (xmin, ymin - labelSize[1]), (xmin + labelSize[0], ymin + baseLine), (255, 255, 255), cv2.FILLED)\n            cv2.putText(frame, label, (xmin, ymin), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 0), 2)\n\n    # Write frame with detections to output video file\n    out.write(frame)\n\n# Release resources\ncap.release()\nout.release()"
      },
      "session_id": "codestral_a277_psg_batch",
      "metadata": {
        "num_run": 17
      },
      "tags": [
        "benchmark",
        "codestral:latest",
        "py_sketch_generator"
      ],
      "latency": 40.499,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-23-30-45-045607_chatcmpl-e4b34bc6-3194-4e0e-ae89-739ce94369ff",
          "traceId": "a8f76dc3",
          "type": "GENERATION",
          "name": "a8f7_psg_gen_attempt#1",
          "startTime": "2025-08-19T20:30:45.045000+00:00",
          "endTime": "2025-08-19T20:31:04.833000+00:00",
          "model": "codestral:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 19788.0,
          "environment": "default",
          "completionTokens": 1027,
          "totalTokens": 2887,
          "promptTokens": 1860,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-23-31-05-014645_chatcmpl-39794936-daed-4923-8fbe-4dcf79e7356b",
          "traceId": "a8f76dc3",
          "type": "GENERATION",
          "name": "a8f7_psg_gen_attempt#2",
          "startTime": "2025-08-19T20:31:05.014000+00:00",
          "endTime": "2025-08-19T20:31:25.544000+00:00",
          "model": "codestral:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 20530.0,
          "environment": "default",
          "completionTokens": 1073,
          "totalTokens": 3121,
          "promptTokens": 2048,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        }
      ],
      "environment": "default",
      "createdAt": "2025-08-19T20:30:45.564Z",
      "updatedAt": "2025-08-19T20:31:36.696Z"
    },
    {
      "id": "02ccc145",
      "timestamp": "2025-08-19T20:29:51.514000+00:00",
      "name": "02cc_py_sketch_generator",
      "input": null,
      "output": {
        "status": "success",
        "sketch": "import numpy as np\nfrom ai_edge_litert.interpreter import Interpreter\nimport cv2\n\n# Define necessary variables and load label file into a Python list\nmodel_path   = \"models/ssd-mobilenet_v1/detect.tflite\"\nlabel_path   = \"models/ssd-mobilenet_v1/labelmap.txt\"\ninput_path   = \"data/object_detection/sheeps.mp4\"\noutput_path   = \"results/object_detection/test_results/sheeps_detections.mp4\"\nconfidence_threshold   = 0.5\nlabels = open(label_path).read().strip().split('\\n')\n\n# Instantiate the Interpreter and allocate tensors\ninterpreter = Interpreter(model_path=model_path)\ninterpreter.allocate_tensors()\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\n\n# Open input video file and initialize output video writer\ncap = cv2.VideoCapture(input_path)\nfourcc = cv2.VideoWriter_fourcc(*'XVID')\nout = cv2.VideoWriter(output_path, fourcc, 20.0, (int(cap.get(3)), int(cap.get(4))))\n\nwhile cap.isOpened():\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    # Preprocess data for inference\n    input_data = np.expand_dims(cv2.resize(frame, (300, 300)), axis=0).astype('uint8')\n\n    # Set the tensor to point to the input data to be used for inference\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n\n    # Run inference\n    interpreter.invoke()\n\n    # Retrieve detection results\n    boxes = interpreter.get_tensor(output_details[0]['index'])[0]  # Bounding box coordinates of detected objects\n    classes = interpreter.get_tensor(output_details[1]['index'])[0]  # Class index of detected objects\n    scores = interpreter.get_tensor(output_details[2]['index'])[0]  # Confidence of detected objects\n\n    for i in range(len(scores)):\n        if ((scores[i] > confidence_threshold) and (scores[i] <= 1.0)):\n            # Get bounding box coordinates and text size\n            ymin = int(max(1, (boxes[i][0] * frame.shape[0])))\n            xmin = int(max(1, (boxes[i][1] * frame.shape[1])))\n            ymax = int(min(frame.shape[0], (boxes[i][2] * frame.shape[0])))\n            xmax = int(min(frame.shape[1], (boxes[i][3] * frame.shape[1])))\n            (text_width, text_height), baseline = cv2.getTextSize(labels[int(classes[i])], cv2.FONT_HERSHEY_SIMPLEX, 0.5, 2)\n            # Draw box and label for detected object\n            cv2.rectangle(frame, (xmin, ymin), (xmax, ymax), (10, 255, 0), 2)\n            cv2.rectangle(frame, (xmin, ymin - text_height - baseline), (xmin + text_width, ymin), (10, 255, 0), -1)\n            cv2.putText(frame, labels[int(classes[i])], (xmin, ymin - baseline), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0), 2)\n\n    # Write frame with detections to output video file\n    out.write(frame)\n\n# Release resources\ncap.release()\nout.release()\ncv2.destroyAllWindows()"
      },
      "session_id": "codestral_a277_psg_batch",
      "metadata": {
        "num_run": 16
      },
      "tags": [
        "benchmark",
        "codestral:latest",
        "py_sketch_generator"
      ],
      "latency": 41.429,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-23-29-51-515835_chatcmpl-9a362290-49ca-4409-8263-577b6cedb0b1",
          "traceId": "02ccc145",
          "type": "GENERATION",
          "name": "02cc_psg_gen_attempt#1",
          "startTime": "2025-08-19T20:29:51.515000+00:00",
          "endTime": "2025-08-19T20:30:12.355000+00:00",
          "model": "codestral:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 20840.0,
          "environment": "default",
          "completionTokens": 1091,
          "totalTokens": 2951,
          "promptTokens": 1860,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-23-30-12-540266_chatcmpl-40a23dbf-f87e-4ade-9305-b861b3e9a04b",
          "traceId": "02ccc145",
          "type": "GENERATION",
          "name": "02cc_psg_gen_attempt#2",
          "startTime": "2025-08-19T20:30:12.540000+00:00",
          "endTime": "2025-08-19T20:30:32.944000+00:00",
          "model": "codestral:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 20404.0,
          "environment": "default",
          "completionTokens": 1066,
          "totalTokens": 3114,
          "promptTokens": 2048,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        }
      ],
      "environment": "default",
      "createdAt": "2025-08-19T20:29:52.032Z",
      "updatedAt": "2025-08-19T20:30:43.702Z"
    },
    {
      "id": "7e0572ba",
      "timestamp": "2025-08-19T20:29:02.944000+00:00",
      "name": "7e05_py_sketch_generator",
      "input": null,
      "output": {
        "status": "success",
        "sketch": "import numpy as np\nfrom ai_edge_litert.interpreter import Interpreter\nimport cv2\n\n# Define paths and parameters\nmodel_path   = \"models/ssd-mobilenet_v1/detect.tflite\"\nlabel_path   = \"models/ssd-mobilenet_v1/labelmap.txt\"\ninput_path   = \"data/object_detection/sheeps.mp4\"\noutput_path   = \"results/object_detection/test_results/sheeps_detections.mp4\"\nconfidence_threshold   = 0.5\n\n# Load labels\nwith open(label_path, 'r') as f:\n    labels = [line.strip() for line in f.readlines()]\n\n# Load interpreter\ninterpreter = Interpreter(model_path=model_path)\ninterpreter.allocate_tensors()\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\n\n# Open input video\ncap = cv2.VideoCapture(input_path)\n\n# Define output video writer\nfourcc = cv2.VideoWriter_fourcc(*'mp4v')\nout = cv2.VideoWriter(output_path, fourcc, 30, (int(cap.get(3)), int(cap.get(4))))\n\nwhile cap.isOpened():\n    ret, frame = cap.read()\n\n    if not ret:\n        break\n\n    # Preprocess input data\n    resized_frame = cv2.resize(frame, (300, 300))\n    input_data = np.expand_dims(resized_frame, axis=0).astype(input_details[0]['dtype'])\n\n    # Run inference\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n    interpreter.invoke()\n\n    # Get output data\n    boxes = interpreter.get_tensor(output_details[0]['index'])[0]\n    classes = interpreter.get_tensor(output_details[1]['index'])[0]\n    scores = interpreter.get_tensor(output_details[2]['index'])[0]\n\n    # Interpret results and handle output\n    for i in range(len(scores)):\n        if scores[i] > confidence_threshold:\n            class_id = int(classes[i])\n            label = labels[class_id]\n            ymin, xmin, ymax, xmax = boxes[i]\n            height, width = frame.shape[:2]\n            x1 = int(xmin * width)\n            y1 = int(ymin * height)\n            x2 = int(xmax * width)\n            y2 = int(ymax * height)\n\n            # Draw bounding box and label on frame\n            cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n            cv2.putText(frame, label, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n\n    # Write frame to output video\n    out.write(frame)\n\n# Release resources\ncap.release()\nout.release()\ncv2.destroyAllWindows()"
      },
      "session_id": "codestral_a277_psg_batch",
      "metadata": {
        "num_run": 15
      },
      "tags": [
        "benchmark",
        "codestral:latest",
        "py_sketch_generator"
      ],
      "latency": 36.543,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-23-29-02-946147_chatcmpl-6c01555b-5591-4bcb-8861-bc15d6948d4c",
          "traceId": "7e0572ba",
          "type": "GENERATION",
          "name": "7e05_psg_gen_attempt#1",
          "startTime": "2025-08-19T20:29:02.946000+00:00",
          "endTime": "2025-08-19T20:29:19.906000+00:00",
          "model": "codestral:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 16960.0,
          "environment": "default",
          "completionTokens": 874,
          "totalTokens": 2734,
          "promptTokens": 1860,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-23-29-20-086647_chatcmpl-6804f1fd-69ed-41da-bb0f-be7a3e6fce8e",
          "traceId": "7e0572ba",
          "type": "GENERATION",
          "name": "7e05_psg_gen_attempt#2",
          "startTime": "2025-08-19T20:29:20.086000+00:00",
          "endTime": "2025-08-19T20:29:39.489000+00:00",
          "model": "codestral:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 19403.0,
          "environment": "default",
          "completionTokens": 1010,
          "totalTokens": 3058,
          "promptTokens": 2048,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        }
      ],
      "environment": "default",
      "createdAt": "2025-08-19T20:29:03.465Z",
      "updatedAt": "2025-08-19T20:29:50.609Z"
    },
    {
      "id": "dc81721a",
      "timestamp": "2025-08-19T20:28:15.414000+00:00",
      "name": "dc81_py_sketch_generator",
      "input": null,
      "output": {
        "status": "success",
        "sketch": "import numpy as np\nfrom ai_edge_litert.interpreter import Interpreter\nimport cv2\n\n# Phase 1: Setup\nmodel_path   = \"models/ssd-mobilenet_v1/detect.tflite\"\nlabel_path   = \"models/ssd-mobilenet_v1/labelmap.txt\"\ninput_path   = \"data/object_detection/sheeps.mp4\"\noutput_path   = \"results/object_detection/test_results/sheeps_detections.mp4\"\nconfidence_threshold   = 0.5\n\n# Load Labels\nwith open(label_path, 'r') as f:\n    labels = [line.strip() for line in f.readlines()]\n\ninterpreter = Interpreter(model_path=model_path)\ninterpreter.allocate_tensors()\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\n\n# Phase 2: Input Acquisition & Preprocessing Loop\ncap = cv2.VideoCapture(input_path)\nfourcc = cv2.VideoWriter_fourcc(*'mp4v')\nout = cv2.VideoWriter(output_path, fourcc, 20.0, (300, 300)) # Changed output size to match model input shape\n\nwhile cap.isOpened():\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    # Preprocess Data\n    resized_frame = cv2.resize(frame, (300, 300)) # Resize frame to match model input shape\n    input_data = np.expand_dims(resized_frame, axis=0)\n    (height, width) = resized_frame.shape[:2] # Updated height and width variables to use resized frame dimensions\n\n    # Phase 3: Inference\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n    interpreter.invoke()\n\n    # Phase 4: Output Interpretation & Handling Loop\n    boxes = interpreter.get_tensor(output_details[0]['index'])[0]\n    classes = interpreter.get_tensor(output_details[1]['index'])[0]\n    scores = interpreter.get_tensor(output_details[2]['index'])[0]\n\n    for i in range(len(scores)):\n        if ((scores[i] > confidence_threshold) and (scores[i] <= 1.0)):\n            ymin, xmin, ymax, xmax = boxes[i]\n            left = int(xmin * width)\n            top = int(ymin * height)\n            right = int(xmax * width)\n            bottom = int(ymax * height)\n            cv2.rectangle(resized_frame, (left, top), (right, bottom), (0, 255, 0), 2) # Draw rectangle on resized frame\n            cv2.putText(resized_frame, labels[int(classes[i])], (left, top - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (36, 255, 12), 2)\n\n    out.write(resized_frame) # Write resized frame to output video\n\n# Phase 5: Cleanup\ncap.release()\nout.release()"
      },
      "session_id": "codestral_a277_psg_batch",
      "metadata": {
        "num_run": 14
      },
      "tags": [
        "benchmark",
        "codestral:latest",
        "py_sketch_generator"
      ],
      "latency": 36.434,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-23-28-15-415775_chatcmpl-69fbcef5-0aa0-4504-88dc-94aa62f10de8",
          "traceId": "dc81721a",
          "type": "GENERATION",
          "name": "dc81_psg_gen_attempt#1",
          "startTime": "2025-08-19T20:28:15.415000+00:00",
          "endTime": "2025-08-19T20:28:30.920000+00:00",
          "model": "codestral:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 15505.0,
          "environment": "default",
          "completionTokens": 793,
          "totalTokens": 2653,
          "promptTokens": 1860,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-23-28-31-099046_chatcmpl-943f745a-4638-4d7b-9809-737b80063b09",
          "traceId": "dc81721a",
          "type": "GENERATION",
          "name": "dc81_psg_gen_attempt#2",
          "startTime": "2025-08-19T20:28:31.099000+00:00",
          "endTime": "2025-08-19T20:28:51.849000+00:00",
          "model": "codestral:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 20750.0,
          "environment": "default",
          "completionTokens": 1085,
          "totalTokens": 3133,
          "promptTokens": 2048,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        }
      ],
      "environment": "default",
      "createdAt": "2025-08-19T20:28:15.933Z",
      "updatedAt": "2025-08-19T20:29:02.535Z"
    },
    {
      "id": "5bfc7c37",
      "timestamp": "2025-08-19T20:27:22.876000+00:00",
      "name": "5bfc_py_sketch_generator",
      "input": null,
      "output": {
        "status": "success",
        "sketch": "import numpy as np\nfrom ai_edge_litert.interpreter import Interpreter\nimport cv2\n\n# Paths/Parameters\nmodel_path   = \"models/ssd-mobilenet_v1/detect.tflite\"\nlabel_path   = \"models/ssd-mobilenet_v1/labelmap.txt\"\ninput_path   = \"data/object_detection/sheeps.mp4\"\noutput_path   = \"results/object_detection/test_results/sheeps_detections.mp4\"\nconfidence_threshold   = 0.5\n\n# Load Labels\nwith open(label_path, 'r') as f:\n    labels = [line.strip() for line in f.readlines()]\n\n# Load Interpreter\ninterpreter = Interpreter(model_path=model_path)\ninterpreter.allocate_tensors()\n\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\n\nheight = input_details[0]['shape'][1]\nwidth = input_details[0]['shape'][2]\n\n# Input Acquisition & Preprocessing Loop\ncap = cv2.VideoCapture(input_path)\nfps = cap.get(cv2.CAP_PROP_FPS)\nframe_size = (int(cap.get(3)), int(cap.get(4)))\nout = cv2.VideoWriter(output_path, cv2.VideoWriter_fourcc(*'mp4v'), fps, frame_size)\n\nwhile cap.isOpened():\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    # Preprocess Data\n    input_data = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)  # Convert BGR to RGB\n    input_data = cv2.resize(input_data, (width, height))  # Resize\n    input_data = np.expand_dims(input_data, axis=0)  # Expand dimensions\n    input_data = (input_data / 255).astype('uint8')  # Normalize and scale to [0, 255]\n\n    # Run Inference\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n    interpreter.invoke()\n\n    # Output Interpretation & Handling Loop\n    boxes = interpreter.get_tensor(output_details[0]['index'])[0]\n    classes = interpreter.get_tensor(output_details[1]['index'])[0]\n    scores = interpreter.get_tensor(output_details[2]['index'])[0]\n\n    for i, score in enumerate(scores):\n        if score > confidence_threshold:\n            ymin, xmin, ymax, xmax = boxes[i]\n            label = labels[int(classes[i])]\n            cv2.rectangle(frame, (int(xmin * frame_size[0]), int(ymin * frame_size[1])), (int(xmax * frame_size[0]), int(ymax * frame_size[1])), (10, 255, 0), 4)\n            cv2.putText(frame, label, (int(xmin * frame_size[0]), int(ymin * frame_size[1] - 7)), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (10, 255, 0), 2)\n\n    out.write(frame)\n\ncap.release()\nout.release()\ncv2.destroyAllWindows()"
      },
      "session_id": "codestral_a277_psg_batch",
      "metadata": {
        "num_run": 13
      },
      "tags": [
        "benchmark",
        "codestral:latest",
        "py_sketch_generator"
      ],
      "latency": 40.593,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-23-27-22-877967_chatcmpl-5e971451-9013-4088-b460-90b361c5de28",
          "traceId": "5bfc7c37",
          "type": "GENERATION",
          "name": "5bfc_psg_gen_attempt#1",
          "startTime": "2025-08-19T20:27:22.877000+00:00",
          "endTime": "2025-08-19T20:27:41.683000+00:00",
          "model": "codestral:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 18806.0,
          "environment": "default",
          "completionTokens": 905,
          "totalTokens": 2765,
          "promptTokens": 1860,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-23-27-41-873457_chatcmpl-e0644f92-3741-4621-9672-99b3d24afe56",
          "traceId": "5bfc7c37",
          "type": "GENERATION",
          "name": "5bfc_psg_gen_attempt#2",
          "startTime": "2025-08-19T20:27:41.873000+00:00",
          "endTime": "2025-08-19T20:28:03.470000+00:00",
          "model": "codestral:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 21597.0,
          "environment": "default",
          "completionTokens": 1132,
          "totalTokens": 3180,
          "promptTokens": 2048,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        }
      ],
      "environment": "default",
      "createdAt": "2025-08-19T20:27:24.220Z",
      "updatedAt": "2025-08-19T20:28:14.359Z"
    },
    {
      "id": "cdf50d1f",
      "timestamp": "2025-08-19T20:26:35.298000+00:00",
      "name": "cdf5_py_sketch_generator",
      "input": null,
      "output": {
        "status": "success",
        "sketch": "import numpy as np\nfrom ai_edge_litert.interpreter import Interpreter\nimport cv2\n\n# Phase 1: Setup\nmodel_path   = \"models/ssd-mobilenet_v1/detect.tflite\"\nlabel_path   = \"models/ssd-mobilenet_v1/labelmap.txt\"\ninput_path   = \"data/object_detection/sheeps.mp4\"\noutput_path   = \"results/object_detection/test_results/sheeps_detections.mp4\"\nconfidence_threshold   = 0.5\n\n# Load labels\nwith open(label_path, 'r') as f:\n    labels = [line.strip() for line in f.readlines()]\n\ninterpreter = Interpreter(model_path=model_path)\ninterpreter.allocate_tensors()\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\n\n# Phase 2: Input Acquisition & Preprocessing Loop\ncap = cv2.VideoCapture(input_path)\nframe_width = int(cap.get(3))\nframe_height = int(cap.get(4))\nout = cv2.VideoWriter(output_path, cv2.VideoWriter_fourcc(*'mp4v'), 30, (frame_width, frame_height))\n\nwhile cap.isOpened():\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    # Preprocess Data\n    resized_frame = cv2.resize(frame, (300, 300))\n    input_data = np.expand_dims(resized_frame, axis=0).astype('uint8')  # Changed 'float32' to 'uint8'\n\n    # Phase 3: Inference\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n    interpreter.invoke()\n\n    # Phase 4: Output Interpretation & Handling Loop\n    boxes = interpreter.get_tensor(output_details[0]['index'])[0]\n    classes = interpreter.get_tensor(output_details[1]['index'])[0].astype('int32')\n    scores = interpreter.get_tensor(output_details[2]['index'])[0]\n\n    for i in range(len(scores)):\n        if ((scores[i] > confidence_threshold) and (scores[i] <= 1.0)):\n            ymin, xmin, ymax, xmax = boxes[i]\n            xmin = int(xmin * frame_width)\n            xmax = int(xmax * frame_width)\n            ymin = int(ymin * frame_height)\n            ymax = int(ymax * frame_height)\n\n            cv2.rectangle(frame, (xmin, ymin), (xmax, ymax), (10, 255, 0), 4)\n            object_name = labels[int(classes[i])]\n            label = f\"{object_name}: {int(scores[i]*100)}%\"\n            cv2.putText(frame, label, (xmin, ymin-5), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (10, 255, 0), 2)\n\n    out.write(frame)\n\n# Phase 5: Cleanup\ncap.release()\nout.release()"
      },
      "session_id": "codestral_a277_psg_batch",
      "metadata": {
        "num_run": 12
      },
      "tags": [
        "benchmark",
        "codestral:latest",
        "py_sketch_generator"
      ],
      "latency": 35.399,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-23-26-35-299819_chatcmpl-2d230455-5ee8-4b20-8f27-b7c4f7809a3f",
          "traceId": "cdf50d1f",
          "type": "GENERATION",
          "name": "cdf5_psg_gen_attempt#1",
          "startTime": "2025-08-19T20:26:35.299000+00:00",
          "endTime": "2025-08-19T20:26:51.307000+00:00",
          "model": "codestral:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 16008.0,
          "environment": "default",
          "completionTokens": 821,
          "totalTokens": 2681,
          "promptTokens": 1860,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-23-26-51-486942_chatcmpl-1086288d-f81a-44af-bfff-bd6f04c35509",
          "traceId": "cdf50d1f",
          "type": "GENERATION",
          "name": "cdf5_psg_gen_attempt#2",
          "startTime": "2025-08-19T20:26:51.486000+00:00",
          "endTime": "2025-08-19T20:27:10.698000+00:00",
          "model": "codestral:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 19212.0,
          "environment": "default",
          "completionTokens": 999,
          "totalTokens": 3047,
          "promptTokens": 2048,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        }
      ],
      "environment": "default",
      "createdAt": "2025-08-19T20:26:35.817Z",
      "updatedAt": "2025-08-19T20:27:21.972Z"
    },
    {
      "id": "633531fd",
      "timestamp": "2025-08-19T20:26:08.783000+00:00",
      "name": "6335_py_sketch_generator",
      "input": null,
      "output": {
        "status": "success",
        "sketch": "import numpy as np\nfrom ai_edge_litert.interpreter import Interpreter\nimport cv2\n\n# Define necessary variables\nmodel_path  = \"models/ssd-mobilenet_v1/detect.tflite\"\nlabel_path  = \"models/ssd-mobilenet_v1/labelmap.txt\"\ninput_path  = \"data/object_detection/sheeps.mp4\"\noutput_path  = \"results/object_detection/test_results/sheeps_detections.mp4\"\nconfidence_threshold  = 0.5\n\n# Load Labels\nwith open(label_path, \"r\") as f:\n    labels = [line.strip() for line in f.readlines()]\n\n# Instantiate Interpreter\ninterpreter = Interpreter(model_path=model_path)\ninterpreter.allocate_tensors()\n\n# Get Model Details\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\nheight, width = input_details[0]['shape'][1:3]\n\n# Open Video and Output Stream\ncap = cv2.VideoCapture(input_path)\nfourcc = cv2.VideoWriter_fourcc(*'XVID')\nout = cv2.VideoWriter(output_path, fourcc, 20.0, (width, height))\n\nwhile cap.isOpened():\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    # Preprocess Data\n    input_data = np.expand_dims(cv2.resize(frame, (width, height)), axis=0)\n\n    # Run Inference\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n    interpreter.invoke()\n\n    # Get Output Tensor\n    boxes = interpreter.get_tensor(output_details[0]['index'])[0]\n    classes = interpreter.get_tensor(output_details[1]['index'])[0]\n    scores = interpreter.get_tensor(output_details[2]['index'])[0]\n\n    # Interpret Results and Handle Output\n    for i in range(len(scores)):\n        if ((scores[i] > confidence_threshold) and (scores[i] <= 1.0)):\n            ymin, xmin, ymax, xmax = boxes[i]\n            xmin, ymin, xmax, ymax = int(xmin*width), int(ymin*height), int(xmax*width), int(ymax*height)\n            label = labels[int(classes[i])]\n            cv2.rectangle(frame, (xmin, ymin), (xmax, ymax), (0, 255, 0), 2)\n            cv2.putText(frame, label, (xmin, ymin+30), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2, cv2.LINE_AA)\n    out.write(frame)\n\ncap.release()\nout.release()\ncv2.destroyAllWindows()"
      },
      "session_id": "codestral_a277_psg_batch",
      "metadata": {
        "num_run": 11
      },
      "tags": [
        "benchmark",
        "codestral:latest",
        "py_sketch_generator"
      ],
      "latency": 14.667,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-23-26-08-784582_chatcmpl-eae8006b-0b6f-426e-a5b2-f917ea5540c2",
          "traceId": "633531fd",
          "type": "GENERATION",
          "name": "6335_psg_gen_attempt#1",
          "startTime": "2025-08-19T20:26:08.784000+00:00",
          "endTime": "2025-08-19T20:26:23.451000+00:00",
          "model": "codestral:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 14667.0,
          "environment": "default",
          "completionTokens": 746,
          "totalTokens": 2606,
          "promptTokens": 1860,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        }
      ],
      "environment": "default",
      "createdAt": "2025-08-19T20:26:09.302Z",
      "updatedAt": "2025-08-19T20:26:33.900Z"
    },
    {
      "id": "c39e6087",
      "timestamp": "2025-08-19T20:24:49.273000+00:00",
      "name": "c39e_py_sketch_generator",
      "input": null,
      "output": {
        "status": "success",
        "sketch": "import numpy as np\nfrom ai_edge_litert.interpreter import Interpreter\nimport cv2\n\n# Define paths and parameters\nmodel_path   = \"models/ssd-mobilenet_v1/detect.tflite\"\nlabel_path   = \"models/ssd-mobilenet_v1/labelmap.txt\"\ninput_path   = \"data/object_detection/sheeps.mp4\"\noutput_path   = \"results/object_detection/test_results/sheeps_detections.mp4\"\nconfidence_threshold   = 0.5\n\n# Load labels\nwith open(label_path, 'r') as f:\n    labels = [line.strip() for line in f.readlines()]\n\n# Load interpreter and get input/output details\ninterpreter = Interpreter(model_path=model_path)\ninterpreter.allocate_tensors()\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\n\n# Open video capture and output video writer\ncap = cv2.VideoCapture(input_path)\nframe_width = int(cap.get(3))\nframe_height = int(cap.get(4))\nout = cv2.VideoWriter(output_path, cv2.VideoWriter_fourcc(*'MJPG'), 10, (frame_width, frame_height))\n\nwhile cap.isOpened():\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    # Preprocess data: resize and normalize the input image\n    input_data = cv2.resize(frame, (input_details[0]['shape'][1], input_details[0]['shape'][2]))\n    input_data = np.expand_dims(input_data, axis=0)\n    input_data = np.uint8(input_data)  # fix the type error\n\n    # Set input tensor and run inference\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n    interpreter.invoke()\n\n    # Get output tensor and interpret results\n    boxes = interpreter.get_tensor(output_details[0]['index'])[0]\n    classes = interpreter.get_tensor(output_details[1]['index'])[0]\n    scores = interpreter.get_tensor(output_details[2]['index'])[0]\n\n    # Handle output: draw bounding boxes on the frame and write it to the output video\n    for i in range(len(scores)):\n        if ((scores[i] > confidence_threshold) and (scores[i] <= 1.0)):\n            ymin = int(max(1,(boxes[i][0] * frame_height)))\n            xmin = int(max(1,(boxes[i][1] * frame_width)))\n            ymax = int(min(frame_height,(boxes[i][2] * frame_height)))\n            xmax = int(min(frame_width,(boxes[i][3] * frame_width)))\n\n            cv2.rectangle(frame, (xmin,ymin), (xmax,ymax), (10, 255, 0), 2)\n            label = '{}: {:.2f}'.format(labels[int(classes[i])], scores[i])\n            cv2.putText(frame, label, (xmin, min(ymin, frame_height - 5)), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2)\n\n    out.write(frame)\n\n# Release resources\ncap.release()\nout.release()"
      },
      "session_id": "codestral_a277_psg_batch",
      "metadata": {
        "num_run": 10
      },
      "tags": [
        "benchmark",
        "codestral:latest",
        "py_sketch_generator"
      ],
      "latency": 67.273,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-23-24-49-274805_chatcmpl-57ae04a2-04f7-401e-b266-67f9e548a82d",
          "traceId": "c39e6087",
          "type": "GENERATION",
          "name": "c39e_psg_gen_attempt#1",
          "startTime": "2025-08-19T20:24:49.274000+00:00",
          "endTime": "2025-08-19T20:25:38.640000+00:00",
          "model": "codestral:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 49366.0,
          "environment": "default",
          "completionTokens": 885,
          "totalTokens": 2745,
          "promptTokens": 1860,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-23-25-39-433666_chatcmpl-1b49c901-200b-4c61-9fec-ca4f10e56adf",
          "traceId": "c39e6087",
          "type": "GENERATION",
          "name": "c39e_psg_gen_attempt#2",
          "startTime": "2025-08-19T20:25:39.433000+00:00",
          "endTime": "2025-08-19T20:25:56.547000+00:00",
          "model": "codestral:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 17114.0,
          "environment": "default",
          "completionTokens": 882,
          "totalTokens": 2930,
          "promptTokens": 2048,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        }
      ],
      "environment": "default",
      "createdAt": "2025-08-19T20:24:49.794Z",
      "updatedAt": "2025-08-19T20:26:07.907Z"
    }
  ],
  "meta": {
    "total_items": 21
  }
}
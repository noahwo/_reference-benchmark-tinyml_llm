{
  "data": [
    {
      "id": "3a91ec54",
      "timestamp": "2025-09-18T10:44:42.524000+00:00",
      "name": "3a91_model_converter",
      "input": null,
      "output": {
        "status": "success",
        "code": "import tensorflow as tf\nimport numpy as np\n\n# Load the original Keras model\noriginal_model = tf.keras.models.load_model(\"models/fruit_to_emoji/og_model/model.keras\")\n\n# Define conversion parameters for quantization\nconverter = tf.lite.TFLiteConverter.from_keras_model(original_model)\nconverter.optimizations = [tf.lite.Optimize.DEFAULT]\n\n# Define the data type requirements for quantization\ninference_input_type = tf.float32\ninference_output_type = tf.uint8\n\n# Ensure that if any ops can't be quantized, they are still included as float32\nsupported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n\n# Define a representative dataset generator function\ndef representative_dataset_gen():\n    for _ in range(100):\n        # Get sample input data as a numpy array in a method of your choosing.\n        # Here, we assume the input shape is (224, 224, 3) and values are normalized between 0 and 1\n        input_data = np.random.rand(1, 224, 224, 3).astype(np.float32)\n        yield [input_data]\n\nconverter.representative_dataset = representative_dataset_gen\n\n# Set the input and output tensors to int8 (except the input which stays float32)\nconverter.target_spec.supported_types = [tf.int8]\nconverter.inference_input_type = inference_input_type\nconverter.inference_output_type = inference_output_type\nconverter.target_spec.supported_ops = supported_ops\n\n# Convert the model to the TensorFlow Lite format with quantization\ntflite_model_quant = converter.convert()\n\n# Save the converted TFLite model to a file\nwith open(\"models/fruit_to_emoji/tflite_model/model_quant.tflite\", \"wb\") as f:\n    f.write(tflite_model_quant)"
      },
      "session_id": "qwen2.5-coder:32b_363e_mc_batch",
      "metadata": {
        "num_run": 30
      },
      "tags": [
        "benchmark",
        "model_converter",
        "qwen2.5-coder:32b"
      ],
      "latency": 34.048,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-13-44-42-526276_chatcmpl-d9f4b859-f6f8-4963-b144-48646f12ba65",
          "traceId": "3a91ec54",
          "type": "GENERATION",
          "name": "3a_mc_conversion_code_gen",
          "startTime": "2025-09-18T10:44:42.526000+00:00",
          "endTime": "2025-09-18T10:44:51.979000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 9453.0,
          "totalTokens": 802,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 351,
          "promptTokens": 451,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-13-44-55-349982_chatcmpl-68e54442-4104-4c64-9807-af9d441b1029",
          "traceId": "3a91ec54",
          "type": "GENERATION",
          "name": "3a_mc_error_handling_attempt#2",
          "startTime": "2025-09-18T10:44:55.349000+00:00",
          "endTime": "2025-09-18T10:45:05.116000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 9767.0,
          "totalTokens": 2333,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 285,
          "promptTokens": 2048,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-13-45-05-121273_chatcmpl-27649a47-7439-4d6d-a58e-3410f4e198d6",
          "traceId": "3a91ec54",
          "type": "GENERATION",
          "name": "3a_mc_error_handling_attempt#3",
          "startTime": "2025-09-18T10:45:05.121000+00:00",
          "endTime": "2025-09-18T10:45:16.572000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 11451.0,
          "totalTokens": 1271,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 399,
          "promptTokens": 872,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "1ac77fcd-030c-4f90-9cf9-66e80e6ae010",
          "traceId": "3a91ec54",
          "type": "SPAN",
          "name": "start_model_converter",
          "startTime": "2025-09-18T10:44:42.524000+00:00",
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "totalTokens": 0,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 0,
          "promptTokens": 0,
          "endTime": null,
          "model": null,
          "modelParameters": null,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null,
          "latency": null
        }
      ],
      "environment": "default",
      "createdAt": "2025-09-18T10:44:43.049Z",
      "updatedAt": "2025-09-18T10:45:26.188Z"
    },
    {
      "id": "0fd65754",
      "timestamp": "2025-09-18T10:43:38.137000+00:00",
      "name": "0fd6_model_converter",
      "input": null,
      "output": {
        "status": "success",
        "code": "import tensorflow as tf\nimport numpy as np\n\n# Load the original Keras model\noriginal_model = tf.keras.models.load_model(\"models/fruit_to_emoji/og_model/model.keras\")\n\n# Define conversion parameters for quantization\nconverter = tf.lite.TFLiteConverter.from_keras_model(original_model)\nconverter.optimizations = [tf.lite.Optimize.DEFAULT]\n\n# Define the data type requirements for quantization\ninference_input_type = tf.float32\ninference_output_type = tf.uint8\n\n# Ensure that if any ops can't be quantized, they are still included as float32\nsupported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n\n# Define a representative dataset generator function\ndef representative_dataset_gen():\n    for _ in range(100):\n        # Get sample input data as a numpy array in a method of your choosing.\n        # Here, we assume the input shape is (224, 224, 3) and values are normalized between 0 and 1\n        input_data = np.random.rand(1, 224, 224, 3).astype(np.float32)\n        yield [input_data]\n\nconverter.representative_dataset = representative_dataset_gen\n\n# Set the input and output tensors to int8 (except the input which stays float32)\nconverter.target_spec.supported_types = [tf.int8]\nconverter.inference_input_type = inference_input_type\nconverter.inference_output_type = inference_output_type\nconverter.target_spec.supported_ops = supported_ops\n\n# Convert the model to the TensorFlow Lite format with quantization\ntflite_model_quant = converter.convert()\n\n# Save the converted TFLite model to a file\nwith open(\"models/fruit_to_emoji/tflite_model/model_quant.tflite\", \"wb\") as f:\n    f.write(tflite_model_quant)"
      },
      "session_id": "qwen2.5-coder:32b_363e_mc_batch",
      "metadata": {
        "num_run": 29
      },
      "tags": [
        "benchmark",
        "model_converter",
        "qwen2.5-coder:32b"
      ],
      "latency": 34.0,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-13-43-38-139207_chatcmpl-87afde4d-f7c6-49c3-924b-3a28da1cc9bd",
          "traceId": "0fd65754",
          "type": "GENERATION",
          "name": "0f_mc_conversion_code_gen",
          "startTime": "2025-09-18T10:43:38.139000+00:00",
          "endTime": "2025-09-18T10:43:47.563000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 9424.0,
          "totalTokens": 802,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 351,
          "promptTokens": 451,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-13-43-50-947080_chatcmpl-1831d2b8-a1d7-490f-876c-69d31082a935",
          "traceId": "0fd65754",
          "type": "GENERATION",
          "name": "0f_mc_error_handling_attempt#2",
          "startTime": "2025-09-18T10:43:50.947000+00:00",
          "endTime": "2025-09-18T10:44:00.699000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 9752.0,
          "totalTokens": 2333,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 285,
          "promptTokens": 2048,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-13-44-00-701830_chatcmpl-6522f807-005e-4c04-a33d-bdce34191293",
          "traceId": "0fd65754",
          "type": "GENERATION",
          "name": "0f_mc_error_handling_attempt#3",
          "startTime": "2025-09-18T10:44:00.701000+00:00",
          "endTime": "2025-09-18T10:44:12.137000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 11436.0,
          "totalTokens": 1271,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 399,
          "promptTokens": 872,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "ee673984-91af-4a2e-b922-665f368f1adb",
          "traceId": "0fd65754",
          "type": "SPAN",
          "name": "start_model_converter",
          "startTime": "2025-09-18T10:43:38.137000+00:00",
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "totalTokens": 0,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 0,
          "promptTokens": 0,
          "endTime": null,
          "model": null,
          "modelParameters": null,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null,
          "latency": null
        }
      ],
      "environment": "default",
      "createdAt": "2025-09-18T10:43:38.661Z",
      "updatedAt": "2025-09-18T10:44:21.765Z"
    },
    {
      "id": "20958193",
      "timestamp": "2025-09-18T10:42:33.804000+00:00",
      "name": "2095_model_converter",
      "input": null,
      "output": {
        "status": "success",
        "code": "import tensorflow as tf\nimport numpy as np\n\n# Load the original Keras model\noriginal_model = tf.keras.models.load_model(\"models/fruit_to_emoji/og_model/model.keras\")\n\n# Define conversion parameters for quantization\nconverter = tf.lite.TFLiteConverter.from_keras_model(original_model)\nconverter.optimizations = [tf.lite.Optimize.DEFAULT]\n\n# Define the data type requirements for quantization\ninference_input_type = tf.float32\ninference_output_type = tf.uint8\n\n# Ensure that if any ops can't be quantized, they are still included as float32\nsupported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n\n# Define a representative dataset generator function\ndef representative_dataset_gen():\n    for _ in range(100):\n        # Get sample input data as a numpy array in a method of your choosing.\n        # Here, we assume the input shape is (224, 224, 3) and values are normalized between 0 and 1\n        input_data = np.random.rand(1, 224, 224, 3).astype(np.float32)\n        yield [input_data]\n\nconverter.representative_dataset = representative_dataset_gen\n\n# Set the input and output tensors to int8 (except the input which stays float32)\nconverter.target_spec.supported_types = [tf.int8]\nconverter.inference_input_type = inference_input_type\nconverter.inference_output_type = inference_output_type\nconverter.target_spec.supported_ops = supported_ops\n\n# Convert the model to the TensorFlow Lite format with quantization\ntflite_model_quant = converter.convert()\n\n# Save the converted TFLite model to a file\nwith open(\"models/fruit_to_emoji/tflite_model/model_quant.tflite\", \"wb\") as f:\n    f.write(tflite_model_quant)"
      },
      "session_id": "qwen2.5-coder:32b_363e_mc_batch",
      "metadata": {
        "num_run": 28
      },
      "tags": [
        "benchmark",
        "model_converter",
        "qwen2.5-coder:32b"
      ],
      "latency": 33.887,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-13-42-33-805754_chatcmpl-85069c75-c27a-4c4b-9e52-0c1d66e269c9",
          "traceId": "20958193",
          "type": "GENERATION",
          "name": "20_mc_conversion_code_gen",
          "startTime": "2025-09-18T10:42:33.805000+00:00",
          "endTime": "2025-09-18T10:42:43.279000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 9474.0,
          "totalTokens": 802,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 351,
          "promptTokens": 451,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-13-42-46-606282_chatcmpl-5654b6f9-3f9a-46ee-9c51-9f46fdaf360a",
          "traceId": "20958193",
          "type": "GENERATION",
          "name": "20_mc_error_handling_attempt#2",
          "startTime": "2025-09-18T10:42:46.606000+00:00",
          "endTime": "2025-09-18T10:42:56.250000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 9644.0,
          "totalTokens": 2329,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 281,
          "promptTokens": 2048,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-13-42-56-252986_chatcmpl-fc6ec7d7-c402-413a-b1fc-e5bdf8b22d5f",
          "traceId": "20958193",
          "type": "GENERATION",
          "name": "20_mc_error_handling_attempt#3",
          "startTime": "2025-09-18T10:42:56.252000+00:00",
          "endTime": "2025-09-18T10:43:07.692000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 11440.0,
          "totalTokens": 1271,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 399,
          "promptTokens": 872,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "c9f24173-a01c-413d-ac3e-d58bac334793",
          "traceId": "20958193",
          "type": "SPAN",
          "name": "start_model_converter",
          "startTime": "2025-09-18T10:42:33.805000+00:00",
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "totalTokens": 0,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 0,
          "promptTokens": 0,
          "endTime": null,
          "model": null,
          "modelParameters": null,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null,
          "latency": null
        }
      ],
      "environment": "default",
      "createdAt": "2025-09-18T10:42:34.329Z",
      "updatedAt": "2025-09-18T10:43:17.946Z"
    },
    {
      "id": "d6c71003",
      "timestamp": "2025-09-18T10:41:28.417000+00:00",
      "name": "d6c7_model_converter",
      "input": null,
      "output": {
        "status": "success",
        "code": "import tensorflow as tf\nimport numpy as np\n\n# Load the original Keras model\noriginal_model = tf.keras.models.load_model(\"models/fruit_to_emoji/og_model/model.keras\")\n\n# Define conversion parameters for quantization\nconverter = tf.lite.TFLiteConverter.from_keras_model(original_model)\nconverter.optimizations = [tf.lite.Optimize.DEFAULT]\n\n# Define the data type requirements for quantization\ninference_input_type = tf.float32\ninference_output_type = tf.uint8\n\n# Ensure that if any ops can't be quantized, they are still included as float32\nsupported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n\n# Define a representative dataset generator function\ndef representative_dataset_gen():\n    for _ in range(100):\n        # Get sample input data as a numpy array in a method of your choosing.\n        # Here, we assume the input shape is (224, 224, 3) and values are normalized between 0 and 1\n        input_data = np.random.rand(1, 224, 224, 3).astype(np.float32)\n        yield [input_data]\n\nconverter.representative_dataset = representative_dataset_gen\n\n# Set the input and output tensors to int8 (except the input which stays float32)\nconverter.target_spec.supported_types = [tf.int8]\nconverter.inference_input_type = inference_input_type\nconverter.inference_output_type = inference_output_type\nconverter.target_spec.supported_ops = supported_ops\n\n# Convert the model to the TensorFlow Lite format with quantization\ntflite_model_quant = converter.convert()\n\n# Save the converted TFLite model to a file\nwith open(\"models/fruit_to_emoji/tflite_model/model_quant.tflite\", \"wb\") as f:\n    f.write(tflite_model_quant)"
      },
      "session_id": "qwen2.5-coder:32b_363e_mc_batch",
      "metadata": {
        "num_run": 27
      },
      "tags": [
        "benchmark",
        "model_converter",
        "qwen2.5-coder:32b"
      ],
      "latency": 34.201,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-13-41-28-419075_chatcmpl-8ad0d360-5960-489e-b268-5adc5767d437",
          "traceId": "d6c71003",
          "type": "GENERATION",
          "name": "d6_mc_conversion_code_gen",
          "startTime": "2025-09-18T10:41:28.419000+00:00",
          "endTime": "2025-09-18T10:41:37.963000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 9544.0,
          "totalTokens": 802,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 351,
          "promptTokens": 451,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-13-41-41-440599_chatcmpl-518ca38f-0150-47f1-9907-3ae9ec6da4de",
          "traceId": "d6c71003",
          "type": "GENERATION",
          "name": "d6_mc_error_handling_attempt#2",
          "startTime": "2025-09-18T10:41:41.440000+00:00",
          "endTime": "2025-09-18T10:41:51.170000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 9730.0,
          "totalTokens": 2332,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 284,
          "promptTokens": 2048,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-13-41-51-174526_chatcmpl-6f2616c5-08f8-4a02-92d6-fee9d979cc15",
          "traceId": "d6c71003",
          "type": "GENERATION",
          "name": "d6_mc_error_handling_attempt#3",
          "startTime": "2025-09-18T10:41:51.174000+00:00",
          "endTime": "2025-09-18T10:42:02.618000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 11444.0,
          "totalTokens": 1271,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 399,
          "promptTokens": 872,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "0b7dd2b0-c67d-4148-91a1-0acec87dcc33",
          "traceId": "d6c71003",
          "type": "SPAN",
          "name": "start_model_converter",
          "startTime": "2025-09-18T10:41:28.417000+00:00",
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "totalTokens": 0,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 0,
          "promptTokens": 0,
          "endTime": null,
          "model": null,
          "modelParameters": null,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null,
          "latency": null
        }
      ],
      "environment": "default",
      "createdAt": "2025-09-18T10:41:28.942Z",
      "updatedAt": "2025-09-18T10:42:12.624Z"
    },
    {
      "id": "848e0de2",
      "timestamp": "2025-09-18T10:40:20.102000+00:00",
      "name": "848e_model_converter",
      "input": null,
      "output": {
        "status": "success",
        "code": "import tensorflow as tf\nimport numpy as np\n\n# Load the original Keras model\noriginal_model = tf.keras.models.load_model(\"models/fruit_to_emoji/og_model/model.keras\")\n\n# Define conversion parameters for quantization\nconverter = tf.lite.TFLiteConverter.from_keras_model(original_model)\nconverter.optimizations = [tf.lite.Optimize.DEFAULT]\n\n# Define the data type requirements for quantization\ninference_input_type = tf.float32\ninference_output_type = tf.uint8\n\n# Ensure that if any ops can't be quantized, they are still included as float32\nsupported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n\n# Define a representative dataset generator function\ndef representative_dataset_gen():\n    for _ in range(100):\n        # Get sample input data as a numpy array in a method of your choosing.\n        # Here, we assume the input shape is (224, 224, 3) and values are normalized between 0 and 1\n        input_data = np.random.rand(1, 224, 224, 3).astype(np.float32)\n        yield [input_data]\n\nconverter.representative_dataset = representative_dataset_gen\n\n# Set the input and output tensors to int8 (except the input which stays float32)\nconverter.target_spec.supported_types = [tf.int8]\nconverter.inference_input_type = inference_input_type\nconverter.inference_output_type = inference_output_type\nconverter.target_spec.supported_ops = supported_ops\n\n# Convert the model to the TensorFlow Lite format with quantization\ntflite_model_quant = converter.convert()\n\n# Save the converted TFLite model to a file\nwith open(\"models/fruit_to_emoji/tflite_model/model_quant.tflite\", \"wb\") as f:\n    f.write(tflite_model_quant)"
      },
      "session_id": "qwen2.5-coder:32b_363e_mc_batch",
      "metadata": {
        "num_run": 26
      },
      "tags": [
        "benchmark",
        "model_converter",
        "qwen2.5-coder:32b"
      ],
      "latency": 38.501,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-13-40-20-104274_chatcmpl-841040ed-24e4-4146-9d89-6d0132256dc1",
          "traceId": "848e0de2",
          "type": "GENERATION",
          "name": "84_mc_conversion_code_gen",
          "startTime": "2025-09-18T10:40:20.104000+00:00",
          "endTime": "2025-09-18T10:40:29.584000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 9480.0,
          "totalTokens": 802,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 351,
          "promptTokens": 451,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-13-40-33-353793_chatcmpl-ff2ea156-b73e-42bd-a02e-3d4bc7be4bee",
          "traceId": "848e0de2",
          "type": "GENERATION",
          "name": "84_mc_error_handling_attempt#2",
          "startTime": "2025-09-18T10:40:33.353000+00:00",
          "endTime": "2025-09-18T10:40:47.158000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 13805.0,
          "totalTokens": 2369,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 321,
          "promptTokens": 2048,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-13-40-47-166131_chatcmpl-ca4d040a-6069-4088-8a41-c7ba091cf195",
          "traceId": "848e0de2",
          "type": "GENERATION",
          "name": "84_mc_error_handling_attempt#3",
          "startTime": "2025-09-18T10:40:47.166000+00:00",
          "endTime": "2025-09-18T10:40:58.603000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 11437.0,
          "totalTokens": 1271,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 399,
          "promptTokens": 872,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "bb0e4dd9-f357-4958-b845-4f62e4ca2a90",
          "traceId": "848e0de2",
          "type": "SPAN",
          "name": "start_model_converter",
          "startTime": "2025-09-18T10:40:20.102000+00:00",
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "totalTokens": 0,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 0,
          "promptTokens": 0,
          "endTime": null,
          "model": null,
          "modelParameters": null,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null,
          "latency": null
        }
      ],
      "environment": "default",
      "createdAt": "2025-09-18T10:40:20.624Z",
      "updatedAt": "2025-09-18T10:41:08.316Z"
    },
    {
      "id": "a1ca915d",
      "timestamp": "2025-09-18T10:39:16.680000+00:00",
      "name": "a1ca_model_converter",
      "input": null,
      "output": {
        "status": "success",
        "code": "import tensorflow as tf\nimport numpy as np\n\n# Load the original Keras model\noriginal_model = tf.keras.models.load_model(\"models/fruit_to_emoji/og_model/model.keras\")\n\n# Define conversion parameters for quantization\nconverter = tf.lite.TFLiteConverter.from_keras_model(original_model)\nconverter.optimizations = [tf.lite.Optimize.DEFAULT]\n\n# Define the data type requirements for quantization\ninference_input_type = tf.float32\ninference_output_type = tf.uint8\n\n# Ensure that if any ops can't be quantized, they are still included as float32\nsupported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n\n# Define a representative dataset generator function\ndef representative_dataset_gen():\n    for _ in range(100):\n        # Get sample input data as a numpy array in a method of your choosing.\n        # Here, we assume the input shape is (224, 224, 3) and values are normalized between 0 and 1\n        input_data = np.random.rand(1, 224, 224, 3).astype(np.float32)\n        yield [input_data]\n\nconverter.representative_dataset = representative_dataset_gen\n\n# Set the input and output tensors to int8 (except the input which stays float32)\nconverter.target_spec.supported_types = [tf.int8]\nconverter.inference_input_type = inference_input_type\nconverter.inference_output_type = inference_output_type\nconverter.target_spec.supported_ops = supported_ops\n\n# Convert the model to the TensorFlow Lite format with quantization\ntflite_model_quant = converter.convert()\n\n# Save the converted TFLite model to a file\nwith open(\"models/fruit_to_emoji/tflite_model/model_quant.tflite\", \"wb\") as f:\n    f.write(tflite_model_quant)"
      },
      "session_id": "qwen2.5-coder:32b_363e_mc_batch",
      "metadata": {
        "num_run": 25
      },
      "tags": [
        "benchmark",
        "model_converter",
        "qwen2.5-coder:32b"
      ],
      "latency": 33.926,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-13-39-16-681777_chatcmpl-2dfaa365-5230-4fbb-bb7a-6eeac46475d9",
          "traceId": "a1ca915d",
          "type": "GENERATION",
          "name": "a1_mc_conversion_code_gen",
          "startTime": "2025-09-18T10:39:16.681000+00:00",
          "endTime": "2025-09-18T10:39:26.105000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 9424.0,
          "totalTokens": 802,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 351,
          "promptTokens": 451,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-13-39-29-409139_chatcmpl-f6617b17-32b9-4f53-a9e9-422890c90cb0",
          "traceId": "a1ca915d",
          "type": "GENERATION",
          "name": "a1_mc_error_handling_attempt#2",
          "startTime": "2025-09-18T10:39:29.409000+00:00",
          "endTime": "2025-09-18T10:39:39.162000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 9753.0,
          "totalTokens": 2333,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 285,
          "promptTokens": 2048,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-13-39-39-167485_chatcmpl-4863ed71-9310-40d6-b312-8771deabf867",
          "traceId": "a1ca915d",
          "type": "GENERATION",
          "name": "a1_mc_error_handling_attempt#3",
          "startTime": "2025-09-18T10:39:39.167000+00:00",
          "endTime": "2025-09-18T10:39:50.606000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 11439.0,
          "totalTokens": 1271,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 399,
          "promptTokens": 872,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "90b626aa-2e95-4a25-9c8f-8fff80b29d52",
          "traceId": "a1ca915d",
          "type": "SPAN",
          "name": "start_model_converter",
          "startTime": "2025-09-18T10:39:16.680000+00:00",
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "totalTokens": 0,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 0,
          "promptTokens": 0,
          "endTime": null,
          "model": null,
          "modelParameters": null,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null,
          "latency": null
        }
      ],
      "environment": "default",
      "createdAt": "2025-09-18T10:39:17.203Z",
      "updatedAt": "2025-09-18T10:39:59.875Z"
    },
    {
      "id": "7f20dd60",
      "timestamp": "2025-09-18T10:38:12.365000+00:00",
      "name": "7f20_model_converter",
      "input": null,
      "output": {
        "status": "success",
        "code": "import tensorflow as tf\nimport numpy as np\n\n# Load the original Keras model\noriginal_model = tf.keras.models.load_model(\"models/fruit_to_emoji/og_model/model.keras\")\n\n# Define conversion parameters for quantization\nconverter = tf.lite.TFLiteConverter.from_keras_model(original_model)\nconverter.optimizations = [tf.lite.Optimize.DEFAULT]\n\n# Define the data type requirements for quantization\ninference_input_type = tf.float32\ninference_output_type = tf.uint8\n\n# Ensure that if any ops can't be quantized, they are still included as float32\nsupported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n\n# Define a representative dataset generator function\ndef representative_dataset_gen():\n    for _ in range(100):\n        # Get sample input data as a numpy array in a method of your choosing.\n        # Here, we assume the input shape is (224, 224, 3) and values are normalized between 0 and 1\n        input_data = np.random.rand(1, 224, 224, 3).astype(np.float32)\n        yield [input_data]\n\nconverter.representative_dataset = representative_dataset_gen\n\n# Set the input and output tensors to int8 (except the input which stays float32)\nconverter.target_spec.supported_types = [tf.int8]\nconverter.inference_input_type = inference_input_type\nconverter.inference_output_type = inference_output_type\nconverter.target_spec.supported_ops = supported_ops\n\n# Convert the model to the TensorFlow Lite format with quantization\ntflite_model_quant = converter.convert()\n\n# Save the converted TFLite model to a file\nwith open(\"models/fruit_to_emoji/tflite_model/model_quant.tflite\", \"wb\") as f:\n    f.write(tflite_model_quant)"
      },
      "session_id": "qwen2.5-coder:32b_363e_mc_batch",
      "metadata": {
        "num_run": 24
      },
      "tags": [
        "benchmark",
        "model_converter",
        "qwen2.5-coder:32b"
      ],
      "latency": 34.502,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-13-38-12-367586_chatcmpl-aabeb027-2400-4b07-bc38-c22d707ebbb0",
          "traceId": "7f20dd60",
          "type": "GENERATION",
          "name": "7f_mc_conversion_code_gen",
          "startTime": "2025-09-18T10:38:12.367000+00:00",
          "endTime": "2025-09-18T10:38:21.804000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 9437.0,
          "totalTokens": 802,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 351,
          "promptTokens": 451,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-13-38-25-963920_chatcmpl-5006d9a1-2b55-4001-8bbc-44ef98faa323",
          "traceId": "7f20dd60",
          "type": "GENERATION",
          "name": "7f_mc_error_handling_attempt#2",
          "startTime": "2025-09-18T10:38:25.963000+00:00",
          "endTime": "2025-09-18T10:38:35.417000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 9454.0,
          "totalTokens": 2322,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 274,
          "promptTokens": 2048,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-13-38-35-420633_chatcmpl-bde1af90-4e2b-4437-a766-c963f7b3fbf8",
          "traceId": "7f20dd60",
          "type": "GENERATION",
          "name": "7f_mc_error_handling_attempt#3",
          "startTime": "2025-09-18T10:38:35.420000+00:00",
          "endTime": "2025-09-18T10:38:46.868000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 11448.0,
          "totalTokens": 1271,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 399,
          "promptTokens": 872,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "060d4a38-eae6-4f7c-929c-d2fff0a27773",
          "traceId": "7f20dd60",
          "type": "SPAN",
          "name": "start_model_converter",
          "startTime": "2025-09-18T10:38:12.366000+00:00",
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "totalTokens": 0,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 0,
          "promptTokens": 0,
          "endTime": null,
          "model": null,
          "modelParameters": null,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null,
          "latency": null
        }
      ],
      "environment": "default",
      "createdAt": "2025-09-18T10:38:12.890Z",
      "updatedAt": "2025-09-18T10:38:56.502Z"
    },
    {
      "id": "718db284",
      "timestamp": "2025-09-18T10:37:08.010000+00:00",
      "name": "718d_model_converter",
      "input": null,
      "output": {
        "status": "success",
        "code": "import tensorflow as tf\nimport numpy as np\n\n# Load the original Keras model\noriginal_model = tf.keras.models.load_model(\"models/fruit_to_emoji/og_model/model.keras\")\n\n# Define conversion parameters for quantization\nconverter = tf.lite.TFLiteConverter.from_keras_model(original_model)\nconverter.optimizations = [tf.lite.Optimize.DEFAULT]\n\n# Define the data type requirements for quantization\ninference_input_type = tf.float32\ninference_output_type = tf.uint8\n\n# Ensure that if any ops can't be quantized, they are still included as float32\nsupported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n\n# Define a representative dataset generator function\ndef representative_dataset_gen():\n    for _ in range(100):\n        # Get sample input data as a numpy array in a method of your choosing.\n        # Here, we assume the input shape is (224, 224, 3) and values are normalized between 0 and 1\n        input_data = np.random.rand(1, 224, 224, 3).astype(np.float32)\n        yield [input_data]\n\nconverter.representative_dataset = representative_dataset_gen\n\n# Set the input and output tensors to int8 (except the input which stays float32)\nconverter.target_spec.supported_types = [tf.int8]\nconverter.inference_input_type = inference_input_type\nconverter.inference_output_type = inference_output_type\nconverter.target_spec.supported_ops = supported_ops\n\n# Convert the model to the TensorFlow Lite format with quantization\ntflite_model_quant = converter.convert()\n\n# Save the converted TFLite model to a file\nwith open(\"models/fruit_to_emoji/tflite_model/model_quant.tflite\", \"wb\") as f:\n    f.write(tflite_model_quant)"
      },
      "session_id": "qwen2.5-coder:32b_363e_mc_batch",
      "metadata": {
        "num_run": 23
      },
      "tags": [
        "benchmark",
        "model_converter",
        "qwen2.5-coder:32b"
      ],
      "latency": 34.087,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-13-37-08-012639_chatcmpl-4f2d6451-6c48-45cf-a9dd-fa58f9b51c2f",
          "traceId": "718db284",
          "type": "GENERATION",
          "name": "71_mc_conversion_code_gen",
          "startTime": "2025-09-18T10:37:08.012000+00:00",
          "endTime": "2025-09-18T10:37:17.432000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 9420.0,
          "totalTokens": 802,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 351,
          "promptTokens": 451,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-13-37-20-913288_chatcmpl-d326f8f7-1816-49ce-8d17-c789096d28d4",
          "traceId": "718db284",
          "type": "GENERATION",
          "name": "71_mc_error_handling_attempt#2",
          "startTime": "2025-09-18T10:37:20.913000+00:00",
          "endTime": "2025-09-18T10:37:30.663000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 9750.0,
          "totalTokens": 2333,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 285,
          "promptTokens": 2048,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-13-37-30-670630_chatcmpl-9a3eceac-37dd-4251-9771-5dbaa1e23bd4",
          "traceId": "718db284",
          "type": "GENERATION",
          "name": "71_mc_error_handling_attempt#3",
          "startTime": "2025-09-18T10:37:30.670000+00:00",
          "endTime": "2025-09-18T10:37:42.098000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 11428.0,
          "totalTokens": 1271,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 399,
          "promptTokens": 872,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "cbf73cc5-3fb9-4f6f-a9d5-3da56ba7b5e0",
          "traceId": "718db284",
          "type": "SPAN",
          "name": "start_model_converter",
          "startTime": "2025-09-18T10:37:08.011000+00:00",
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "totalTokens": 0,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 0,
          "promptTokens": 0,
          "endTime": null,
          "model": null,
          "modelParameters": null,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null,
          "latency": null
        }
      ],
      "environment": "default",
      "createdAt": "2025-09-18T10:37:08.534Z",
      "updatedAt": "2025-09-18T10:37:51.639Z"
    },
    {
      "id": "6c5b6424",
      "timestamp": "2025-09-18T10:36:03.619000+00:00",
      "name": "6c5b_model_converter",
      "input": null,
      "output": {
        "status": "success",
        "code": "import tensorflow as tf\nimport numpy as np\n\n# Load the original Keras model\noriginal_model = tf.keras.models.load_model(\"models/fruit_to_emoji/og_model/model.keras\")\n\n# Define conversion parameters for quantization\nconverter = tf.lite.TFLiteConverter.from_keras_model(original_model)\nconverter.optimizations = [tf.lite.Optimize.DEFAULT]\n\n# Define the data type requirements for quantization\ninference_input_type = tf.float32\ninference_output_type = tf.uint8\n\n# Ensure that if any ops can't be quantized, they are still included as float32\nsupported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n\n# Define a representative dataset generator function\ndef representative_dataset_gen():\n    for _ in range(100):\n        # Get sample input data as a numpy array in a method of your choosing.\n        # Here, we assume the input shape is (224, 224, 3) and values are normalized between 0 and 1\n        input_data = np.random.rand(1, 224, 224, 3).astype(np.float32)\n        yield [input_data]\n\nconverter.representative_dataset = representative_dataset_gen\n\n# Set the input and output tensors to int8 (except the input which stays float32)\nconverter.target_spec.supported_types = [tf.int8]\nconverter.inference_input_type = inference_input_type\nconverter.inference_output_type = inference_output_type\nconverter.target_spec.supported_ops = supported_ops\n\n# Convert the model to the TensorFlow Lite format with quantization\ntflite_model_quant = converter.convert()\n\n# Save the converted TFLite model to a file\nwith open(\"models/fruit_to_emoji/tflite_model/model_quant.tflite\", \"wb\") as f:\n    f.write(tflite_model_quant)"
      },
      "session_id": "qwen2.5-coder:32b_363e_mc_batch",
      "metadata": {
        "num_run": 22
      },
      "tags": [
        "benchmark",
        "model_converter",
        "qwen2.5-coder:32b"
      ],
      "latency": 34.034,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-13-36-03-621391_chatcmpl-47dc426a-c45c-4f65-a6f9-93f8501947a9",
          "traceId": "6c5b6424",
          "type": "GENERATION",
          "name": "6c_mc_conversion_code_gen",
          "startTime": "2025-09-18T10:36:03.621000+00:00",
          "endTime": "2025-09-18T10:36:13.210000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 9589.0,
          "totalTokens": 802,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 351,
          "promptTokens": 451,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-13-36-16-596268_chatcmpl-45542ec6-c987-4bd0-ae8d-5d55215f4257",
          "traceId": "6c5b6424",
          "type": "GENERATION",
          "name": "6c_mc_error_handling_attempt#2",
          "startTime": "2025-09-18T10:36:16.596000+00:00",
          "endTime": "2025-09-18T10:36:26.206000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 9610.0,
          "totalTokens": 2328,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 280,
          "promptTokens": 2048,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-13-36-26-209164_chatcmpl-24feabfe-f84f-4e3e-a2db-9e09be84ec61",
          "traceId": "6c5b6424",
          "type": "GENERATION",
          "name": "6c_mc_error_handling_attempt#3",
          "startTime": "2025-09-18T10:36:26.209000+00:00",
          "endTime": "2025-09-18T10:36:37.653000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 11444.0,
          "totalTokens": 1271,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 399,
          "promptTokens": 872,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "f171c04f-cb4c-48e9-9aa6-62996400b9ad",
          "traceId": "6c5b6424",
          "type": "SPAN",
          "name": "start_model_converter",
          "startTime": "2025-09-18T10:36:03.619000+00:00",
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "totalTokens": 0,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 0,
          "promptTokens": 0,
          "endTime": null,
          "model": null,
          "modelParameters": null,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null,
          "latency": null
        }
      ],
      "environment": "default",
      "createdAt": "2025-09-18T10:36:04.141Z",
      "updatedAt": "2025-09-18T10:36:47.316Z"
    },
    {
      "id": "8003a7e3",
      "timestamp": "2025-09-18T10:34:54.168000+00:00",
      "name": "8003_model_converter",
      "input": null,
      "output": {
        "status": "success",
        "code": "import tensorflow as tf\nimport numpy as np\n\n# Load the original Keras model\noriginal_model = tf.keras.models.load_model(\"models/fruit_to_emoji/og_model/model.keras\")\n\n# Define conversion parameters for quantization\nconverter = tf.lite.TFLiteConverter.from_keras_model(original_model)\nconverter.optimizations = [tf.lite.Optimize.DEFAULT]\n\n# Define the data type requirements for quantization\ninference_input_type = tf.float32\ninference_output_type = tf.uint8\n\n# Ensure that if any ops can't be quantized, they are still included as float32\nsupported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n\n# Define a representative dataset generator function\ndef representative_dataset_gen():\n    for _ in range(100):\n        # Get sample input data as a numpy array in a method of your choosing.\n        # Here, we assume the input shape is (224, 224, 3) and values are normalized between 0 and 1\n        input_data = np.random.rand(1, 224, 224, 3).astype(np.float32)\n        yield [input_data]\n\nconverter.representative_dataset = representative_dataset_gen\n\n# Set the input and output tensors to int8 (except the input which stays float32)\nconverter.target_spec.supported_types = [tf.int8]\nconverter.inference_input_type = inference_input_type\nconverter.inference_output_type = inference_output_type\nconverter.target_spec.supported_ops = supported_ops\n\n# Convert the model to the TensorFlow Lite format with quantization\ntflite_model_quant = converter.convert()\n\n# Save the converted TFLite model to a file\nwith open(\"models/fruit_to_emoji/tflite_model/model_quant.tflite\", \"wb\") as f:\n    f.write(tflite_model_quant)"
      },
      "session_id": "qwen2.5-coder:32b_363e_mc_batch",
      "metadata": {
        "num_run": 21
      },
      "tags": [
        "benchmark",
        "model_converter",
        "qwen2.5-coder:32b"
      ],
      "latency": 39.611,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-13-34-54-170989_chatcmpl-369f6a3d-0d45-4a84-914d-234b69f40747",
          "traceId": "8003a7e3",
          "type": "GENERATION",
          "name": "80_mc_conversion_code_gen",
          "startTime": "2025-09-18T10:34:54.170000+00:00",
          "endTime": "2025-09-18T10:35:03.595000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 9425.0,
          "totalTokens": 802,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 351,
          "promptTokens": 451,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-13-35-07-018004_chatcmpl-75e390a9-1222-40f3-86d5-ba44ad017288",
          "traceId": "8003a7e3",
          "type": "GENERATION",
          "name": "80_mc_error_handling_attempt#2",
          "startTime": "2025-09-18T10:35:07.018000+00:00",
          "endTime": "2025-09-18T10:35:22.341000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 15323.0,
          "totalTokens": 2534,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 486,
          "promptTokens": 2048,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-13-35-22-344317_chatcmpl-e87112a0-cee0-4f04-9620-e1f31fe3b08c",
          "traceId": "8003a7e3",
          "type": "GENERATION",
          "name": "80_mc_error_handling_attempt#3",
          "startTime": "2025-09-18T10:35:22.344000+00:00",
          "endTime": "2025-09-18T10:35:33.780000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 11436.0,
          "totalTokens": 1271,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 399,
          "promptTokens": 872,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "af48a8b6-492b-4492-aeb5-4ca461760b89",
          "traceId": "8003a7e3",
          "type": "SPAN",
          "name": "start_model_converter",
          "startTime": "2025-09-18T10:34:54.169000+00:00",
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "totalTokens": 0,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 0,
          "promptTokens": 0,
          "endTime": null,
          "model": null,
          "modelParameters": null,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null,
          "latency": null
        }
      ],
      "environment": "default",
      "createdAt": "2025-09-18T10:34:54.691Z",
      "updatedAt": "2025-09-18T10:35:43.294Z"
    },
    {
      "id": "234ac987",
      "timestamp": "2025-09-18T10:33:49.793000+00:00",
      "name": "234a_model_converter",
      "input": null,
      "output": {
        "status": "success",
        "code": "import tensorflow as tf\nimport numpy as np\n\n# Load the original Keras model\noriginal_model = tf.keras.models.load_model(\"models/fruit_to_emoji/og_model/model.keras\")\n\n# Define conversion parameters for quantization\nconverter = tf.lite.TFLiteConverter.from_keras_model(original_model)\nconverter.optimizations = [tf.lite.Optimize.DEFAULT]\n\n# Define the data type requirements for quantization\ninference_input_type = tf.float32\ninference_output_type = tf.uint8\n\n# Ensure that if any ops can't be quantized, they are still included as float32\nsupported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n\n# Define a representative dataset generator function\ndef representative_dataset_gen():\n    for _ in range(100):\n        # Get sample input data as a numpy array in a method of your choosing.\n        # Here, we assume the input shape is (224, 224, 3) and values are normalized between 0 and 1\n        input_data = np.random.rand(1, 224, 224, 3).astype(np.float32)\n        yield [input_data]\n\nconverter.representative_dataset = representative_dataset_gen\n\n# Set the input and output tensors to int8 (except the input which stays float32)\nconverter.target_spec.supported_types = [tf.int8]\nconverter.inference_input_type = inference_input_type\nconverter.inference_output_type = inference_output_type\nconverter.target_spec.supported_ops = supported_ops\n\n# Convert the model to the TensorFlow Lite format with quantization\ntflite_model_quant = converter.convert()\n\n# Save the converted TFLite model to a file\nwith open(\"models/fruit_to_emoji/tflite_model/model_quant.tflite\", \"wb\") as f:\n    f.write(tflite_model_quant)"
      },
      "session_id": "qwen2.5-coder:32b_363e_mc_batch",
      "metadata": {
        "num_run": 20
      },
      "tags": [
        "benchmark",
        "model_converter",
        "qwen2.5-coder:32b"
      ],
      "latency": 34.005,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-13-33-49-794924_chatcmpl-e3853bb6-7bd7-4ca0-a761-5045fb149cd3",
          "traceId": "234ac987",
          "type": "GENERATION",
          "name": "23_mc_conversion_code_gen",
          "startTime": "2025-09-18T10:33:49.794000+00:00",
          "endTime": "2025-09-18T10:33:59.258000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 9464.0,
          "totalTokens": 802,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 351,
          "promptTokens": 451,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-13-34-02-602670_chatcmpl-a2db52e6-5073-42ed-bddf-aaae4eda6719",
          "traceId": "234ac987",
          "type": "GENERATION",
          "name": "23_mc_error_handling_attempt#2",
          "startTime": "2025-09-18T10:34:02.602000+00:00",
          "endTime": "2025-09-18T10:34:12.354000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 9752.0,
          "totalTokens": 2333,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 285,
          "promptTokens": 2048,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-13-34-12-361552_chatcmpl-7ae37538-4ade-45c0-bb21-2cbccf7de99d",
          "traceId": "234ac987",
          "type": "GENERATION",
          "name": "23_mc_error_handling_attempt#3",
          "startTime": "2025-09-18T10:34:12.361000+00:00",
          "endTime": "2025-09-18T10:34:23.798000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 11437.0,
          "totalTokens": 1271,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 399,
          "promptTokens": 872,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "744dcb81-fb46-4ac1-ba12-d6844458ede6",
          "traceId": "234ac987",
          "type": "SPAN",
          "name": "start_model_converter",
          "startTime": "2025-09-18T10:33:49.793000+00:00",
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "totalTokens": 0,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 0,
          "promptTokens": 0,
          "endTime": null,
          "model": null,
          "modelParameters": null,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null,
          "latency": null
        }
      ],
      "environment": "default",
      "createdAt": "2025-09-18T10:33:50.315Z",
      "updatedAt": "2025-09-18T10:34:33.455Z"
    },
    {
      "id": "e3fdf5bf",
      "timestamp": "2025-09-18T10:32:46.448000+00:00",
      "name": "e3fd_model_converter",
      "input": null,
      "output": {
        "status": "success",
        "code": "import tensorflow as tf\nimport numpy as np\n\n# Load the original Keras model\noriginal_model = tf.keras.models.load_model(\"models/fruit_to_emoji/og_model/model.keras\")\n\n# Define conversion parameters for quantization\nconverter = tf.lite.TFLiteConverter.from_keras_model(original_model)\nconverter.optimizations = [tf.lite.Optimize.DEFAULT]\n\n# Define the data type requirements for quantization\ninference_input_type = tf.float32\ninference_output_type = tf.uint8\n\n# Ensure that if any ops can't be quantized, they are still included as float32\nsupported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n\n# Define a representative dataset generator function\ndef representative_dataset_gen():\n    for _ in range(100):\n        # Get sample input data as a numpy array in a method of your choosing.\n        # Here, we assume the input shape is (224, 224, 3) and values are normalized between 0 and 1\n        input_data = np.random.rand(1, 224, 224, 3).astype(np.float32)\n        yield [input_data]\n\nconverter.representative_dataset = representative_dataset_gen\n\n# Set the input and output tensors to int8 (except the input which stays float32)\nconverter.target_spec.supported_types = [tf.int8]\nconverter.inference_input_type = inference_input_type\nconverter.inference_output_type = inference_output_type\nconverter.target_spec.supported_ops = supported_ops\n\n# Convert the model to the TensorFlow Lite format with quantization\ntflite_model_quant = converter.convert()\n\n# Save the converted TFLite model to a file\nwith open(\"models/fruit_to_emoji/tflite_model/model_quant.tflite\", \"wb\") as f:\n    f.write(tflite_model_quant)"
      },
      "session_id": "qwen2.5-coder:32b_363e_mc_batch",
      "metadata": {
        "num_run": 19
      },
      "tags": [
        "benchmark",
        "model_converter",
        "qwen2.5-coder:32b"
      ],
      "latency": 33.55,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-13-32-46-450702_chatcmpl-838892d9-6f96-4aaa-a66a-3f6e83068571",
          "traceId": "e3fdf5bf",
          "type": "GENERATION",
          "name": "e3_mc_conversion_code_gen",
          "startTime": "2025-09-18T10:32:46.450000+00:00",
          "endTime": "2025-09-18T10:32:55.880000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 9430.0,
          "totalTokens": 802,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 351,
          "promptTokens": 451,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-13-32-59-255263_chatcmpl-7fb77352-dd96-460b-8180-72161d244782",
          "traceId": "e3fdf5bf",
          "type": "GENERATION",
          "name": "e3_mc_error_handling_attempt#2",
          "startTime": "2025-09-18T10:32:59.255000+00:00",
          "endTime": "2025-09-18T10:33:08.555000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 9300.0,
          "totalTokens": 2317,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 269,
          "promptTokens": 2048,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-13-33-08-561640_chatcmpl-1c61630a-c446-4a8f-9064-fbbdb9e30b06",
          "traceId": "e3fdf5bf",
          "type": "GENERATION",
          "name": "e3_mc_error_handling_attempt#3",
          "startTime": "2025-09-18T10:33:08.561000+00:00",
          "endTime": "2025-09-18T10:33:19.999000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 11438.0,
          "totalTokens": 1271,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 399,
          "promptTokens": 872,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "66fc6ac9-6166-43ed-8398-652d083dc153",
          "traceId": "e3fdf5bf",
          "type": "SPAN",
          "name": "start_model_converter",
          "startTime": "2025-09-18T10:32:46.449000+00:00",
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "totalTokens": 0,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 0,
          "promptTokens": 0,
          "endTime": null,
          "model": null,
          "modelParameters": null,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null,
          "latency": null
        }
      ],
      "environment": "default",
      "createdAt": "2025-09-18T10:32:46.970Z",
      "updatedAt": "2025-09-18T10:33:29.632Z"
    },
    {
      "id": "1ea522da",
      "timestamp": "2025-09-18T10:31:42.104000+00:00",
      "name": "1ea5_model_converter",
      "input": null,
      "output": {
        "status": "success",
        "code": "import tensorflow as tf\nimport numpy as np\n\n# Load the original Keras model\noriginal_model = tf.keras.models.load_model(\"models/fruit_to_emoji/og_model/model.keras\")\n\n# Define conversion parameters for quantization\nconverter = tf.lite.TFLiteConverter.from_keras_model(original_model)\nconverter.optimizations = [tf.lite.Optimize.DEFAULT]\n\n# Define the data type requirements for quantization\ninference_input_type = tf.float32\ninference_output_type = tf.uint8\n\n# Ensure that if any ops can't be quantized, they are still included as float32\nsupported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n\n# Define a representative dataset generator function\ndef representative_dataset_gen():\n    for _ in range(100):\n        # Get sample input data as a numpy array in a method of your choosing.\n        # Here, we assume the input shape is (224, 224, 3) and values are normalized between 0 and 1\n        input_data = np.random.rand(1, 224, 224, 3).astype(np.float32)\n        yield [input_data]\n\nconverter.representative_dataset = representative_dataset_gen\n\n# Set the input and output tensors to int8 (except the input which stays float32)\nconverter.target_spec.supported_types = [tf.int8]\nconverter.inference_input_type = inference_input_type\nconverter.inference_output_type = inference_output_type\nconverter.target_spec.supported_ops = supported_ops\n\n# Convert the model to the TensorFlow Lite format with quantization\ntflite_model_quant = converter.convert()\n\n# Save the converted TFLite model to a file\nwith open(\"models/fruit_to_emoji/tflite_model/model_quant.tflite\", \"wb\") as f:\n    f.write(tflite_model_quant)"
      },
      "session_id": "qwen2.5-coder:32b_363e_mc_batch",
      "metadata": {
        "num_run": 18
      },
      "tags": [
        "benchmark",
        "model_converter",
        "qwen2.5-coder:32b"
      ],
      "latency": 34.34,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-13-31-42-106998_chatcmpl-8c62df0c-92b9-466f-b957-a9acc516803a",
          "traceId": "1ea522da",
          "type": "GENERATION",
          "name": "1e_mc_conversion_code_gen",
          "startTime": "2025-09-18T10:31:42.106000+00:00",
          "endTime": "2025-09-18T10:31:51.738000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 9632.0,
          "totalTokens": 802,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 351,
          "promptTokens": 451,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-13-31-55-188043_chatcmpl-d508308e-5f73-4c90-8872-da0b09ee9c3a",
          "traceId": "1ea522da",
          "type": "GENERATION",
          "name": "1e_mc_error_handling_attempt#2",
          "startTime": "2025-09-18T10:31:55.188000+00:00",
          "endTime": "2025-09-18T10:32:04.978000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 9790.0,
          "totalTokens": 2333,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 285,
          "promptTokens": 2048,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-13-32-04-982150_chatcmpl-821503e1-d964-4ed1-b469-eee064fe13f0",
          "traceId": "1ea522da",
          "type": "GENERATION",
          "name": "1e_mc_error_handling_attempt#3",
          "startTime": "2025-09-18T10:32:04.982000+00:00",
          "endTime": "2025-09-18T10:32:16.445000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 11463.0,
          "totalTokens": 1271,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 399,
          "promptTokens": 872,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "23b4eff4-8bfd-4914-9b50-9c3c8f82cffb",
          "traceId": "1ea522da",
          "type": "SPAN",
          "name": "start_model_converter",
          "startTime": "2025-09-18T10:31:42.105000+00:00",
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "totalTokens": 0,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 0,
          "promptTokens": 0,
          "endTime": null,
          "model": null,
          "modelParameters": null,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null,
          "latency": null
        }
      ],
      "environment": "default",
      "createdAt": "2025-09-18T10:31:42.627Z",
      "updatedAt": "2025-09-18T10:32:25.710Z"
    },
    {
      "id": "95aa10be",
      "timestamp": "2025-09-18T10:30:38.747000+00:00",
      "name": "95aa_model_converter",
      "input": null,
      "output": {
        "status": "success",
        "code": "import tensorflow as tf\nimport numpy as np\n\n# Load the original Keras model\noriginal_model = tf.keras.models.load_model(\"models/fruit_to_emoji/og_model/model.keras\")\n\n# Define conversion parameters for quantization\nconverter = tf.lite.TFLiteConverter.from_keras_model(original_model)\nconverter.optimizations = [tf.lite.Optimize.DEFAULT]\n\n# Define the data type requirements for quantization\ninference_input_type = tf.float32\ninference_output_type = tf.uint8\n\n# Ensure that if any ops can't be quantized, they are still included as float32\nsupported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n\n# Define a representative dataset generator function\ndef representative_dataset_gen():\n    for _ in range(100):\n        # Get sample input data as a numpy array in a method of your choosing.\n        # Here, we assume the input shape is (224, 224, 3) and values are normalized between 0 and 1\n        input_data = np.random.rand(1, 224, 224, 3).astype(np.float32)\n        yield [input_data]\n\nconverter.representative_dataset = representative_dataset_gen\n\n# Set the input and output tensors to int8 (except the input which stays float32)\nconverter.target_spec.supported_types = [tf.int8]\nconverter.inference_input_type = inference_input_type\nconverter.inference_output_type = inference_output_type\nconverter.target_spec.supported_ops = supported_ops\n\n# Convert the model to the TensorFlow Lite format with quantization\ntflite_model_quant = converter.convert()\n\n# Save the converted TFLite model to a file\nwith open(\"models/fruit_to_emoji/tflite_model/model_quant.tflite\", \"wb\") as f:\n    f.write(tflite_model_quant)"
      },
      "session_id": "qwen2.5-coder:32b_363e_mc_batch",
      "metadata": {
        "num_run": 17
      },
      "tags": [
        "benchmark",
        "model_converter",
        "qwen2.5-coder:32b"
      ],
      "latency": 33.292,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-13-30-38-749390_chatcmpl-bc1ca09b-08c6-4a2c-b70f-712ae990dc27",
          "traceId": "95aa10be",
          "type": "GENERATION",
          "name": "95_mc_conversion_code_gen",
          "startTime": "2025-09-18T10:30:38.749000+00:00",
          "endTime": "2025-09-18T10:30:48.160000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 9411.0,
          "totalTokens": 802,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 351,
          "promptTokens": 451,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-13-30-51-538875_chatcmpl-96322419-72af-4912-ad64-f9b551ae3b81",
          "traceId": "95aa10be",
          "type": "GENERATION",
          "name": "95_mc_error_handling_attempt#2",
          "startTime": "2025-09-18T10:30:51.538000+00:00",
          "endTime": "2025-09-18T10:31:00.592000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 9054.0,
          "totalTokens": 2308,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 260,
          "promptTokens": 2048,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-13-31-00-598864_chatcmpl-98e2fd2b-35d6-4d15-a143-34944b3075d8",
          "traceId": "95aa10be",
          "type": "GENERATION",
          "name": "95_mc_error_handling_attempt#3",
          "startTime": "2025-09-18T10:31:00.598000+00:00",
          "endTime": "2025-09-18T10:31:12.039000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 11441.0,
          "totalTokens": 1271,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 399,
          "promptTokens": 872,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "f9635e43-d09c-425f-a48e-ddf9e354f78f",
          "traceId": "95aa10be",
          "type": "SPAN",
          "name": "start_model_converter",
          "startTime": "2025-09-18T10:30:38.747000+00:00",
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "totalTokens": 0,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 0,
          "promptTokens": 0,
          "endTime": null,
          "model": null,
          "modelParameters": null,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null,
          "latency": null
        }
      ],
      "environment": "default",
      "createdAt": "2025-09-18T10:30:39.269Z",
      "updatedAt": "2025-09-18T10:31:21.386Z"
    },
    {
      "id": "90aeb428",
      "timestamp": "2025-09-18T10:29:32.439000+00:00",
      "name": "90ae_model_converter",
      "input": null,
      "output": {
        "status": "success",
        "code": "import tensorflow as tf\nimport numpy as np\n\n# Load the original Keras model\noriginal_model = tf.keras.models.load_model(\"models/fruit_to_emoji/og_model/model.keras\")\n\n# Define conversion parameters for quantization\nconverter = tf.lite.TFLiteConverter.from_keras_model(original_model)\nconverter.optimizations = [tf.lite.Optimize.DEFAULT]\n\n# Define the data type requirements for quantization\ninference_input_type = tf.float32\ninference_output_type = tf.uint8\n\n# Ensure that if any ops can't be quantized, they are still included as float32\nsupported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n\n# Define a representative dataset generator function\ndef representative_dataset_gen():\n    for _ in range(100):\n        # Get sample input data as a numpy array in a method of your choosing.\n        # Here, we assume the input shape is (224, 224, 3) and values are normalized between 0 and 1\n        input_data = np.random.rand(1, 224, 224, 3).astype(np.float32)\n        yield [input_data]\n\nconverter.representative_dataset = representative_dataset_gen\n\n# Set the input and output tensors to int8 (except the input which stays float32)\nconverter.target_spec.supported_types = [tf.int8]\nconverter.inference_input_type = inference_input_type\nconverter.inference_output_type = inference_output_type\nconverter.target_spec.supported_ops = supported_ops\n\n# Convert the model to the TensorFlow Lite format with quantization\ntflite_model_quant = converter.convert()\n\n# Save the converted TFLite model to a file\nwith open(\"models/fruit_to_emoji/tflite_model/model_quant.tflite\", \"wb\") as f:\n    f.write(tflite_model_quant)"
      },
      "session_id": "qwen2.5-coder:32b_363e_mc_batch",
      "metadata": {
        "num_run": 16
      },
      "tags": [
        "benchmark",
        "model_converter",
        "qwen2.5-coder:32b"
      ],
      "latency": 35.954,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-13-29-32-443409_chatcmpl-09f0d4c4-6710-4ec8-8565-5b440823c116",
          "traceId": "90aeb428",
          "type": "GENERATION",
          "name": "90_mc_conversion_code_gen",
          "startTime": "2025-09-18T10:29:32.443000+00:00",
          "endTime": "2025-09-18T10:29:41.905000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 9462.0,
          "totalTokens": 802,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 351,
          "promptTokens": 451,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-13-29-45-585411_chatcmpl-95b01a72-0da0-4daa-801b-c424d94b7ef6",
          "traceId": "90aeb428",
          "type": "GENERATION",
          "name": "90_mc_error_handling_attempt#2",
          "startTime": "2025-09-18T10:29:45.585000+00:00",
          "endTime": "2025-09-18T10:29:56.948000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 11363.0,
          "totalTokens": 2391,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 343,
          "promptTokens": 2048,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-13-29-56-950658_chatcmpl-0748b987-daca-4cbe-94d4-1b72a18a70ef",
          "traceId": "90aeb428",
          "type": "GENERATION",
          "name": "90_mc_error_handling_attempt#3",
          "startTime": "2025-09-18T10:29:56.950000+00:00",
          "endTime": "2025-09-18T10:30:08.394000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 11444.0,
          "totalTokens": 1271,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 399,
          "promptTokens": 872,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "7bf3c1b5-f01d-4082-bce4-dfdf25d2ed09",
          "traceId": "90aeb428",
          "type": "SPAN",
          "name": "start_model_converter",
          "startTime": "2025-09-18T10:29:32.440000+00:00",
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "totalTokens": 0,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 0,
          "promptTokens": 0,
          "endTime": null,
          "model": null,
          "modelParameters": null,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null,
          "latency": null
        }
      ],
      "environment": "default",
      "createdAt": "2025-09-18T10:29:32.960Z",
      "updatedAt": "2025-09-18T10:30:18.066Z"
    },
    {
      "id": "b2c11c7c",
      "timestamp": "2025-09-18T10:28:26.993000+00:00",
      "name": "b2c1_model_converter",
      "input": null,
      "output": {
        "status": "success",
        "code": "import tensorflow as tf\nimport numpy as np\n\n# Load the original Keras model\noriginal_model = tf.keras.models.load_model(\"models/fruit_to_emoji/og_model/model.keras\")\n\n# Define conversion parameters for quantization\nconverter = tf.lite.TFLiteConverter.from_keras_model(original_model)\nconverter.optimizations = [tf.lite.Optimize.DEFAULT]\n\n# Define the data type requirements for quantization\ninference_input_type = tf.float32\ninference_output_type = tf.uint8\n\n# Ensure that if any ops can't be quantized, they are still included as float32\nsupported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n\n# Define a representative dataset generator function\ndef representative_dataset_gen():\n    for _ in range(100):\n        # Get sample input data as a numpy array in a method of your choosing.\n        # Here, we assume the input shape is (224, 224, 3) and values are normalized between 0 and 1\n        input_data = np.random.rand(1, 224, 224, 3).astype(np.float32)\n        yield [input_data]\n\nconverter.representative_dataset = representative_dataset_gen\n\n# Set the input and output tensors to int8 (except the input which stays float32)\nconverter.target_spec.supported_types = [tf.int8]\nconverter.inference_input_type = inference_input_type\nconverter.inference_output_type = inference_output_type\nconverter.target_spec.supported_ops = supported_ops\n\n# Convert the model to the TensorFlow Lite format with quantization\ntflite_model_quant = converter.convert()\n\n# Save the converted TFLite model to a file\nwith open(\"models/fruit_to_emoji/tflite_model/model_quant.tflite\", \"wb\") as f:\n    f.write(tflite_model_quant)"
      },
      "session_id": "qwen2.5-coder:32b_363e_mc_batch",
      "metadata": {
        "num_run": 15
      },
      "tags": [
        "benchmark",
        "model_converter",
        "qwen2.5-coder:32b"
      ],
      "latency": 35.586,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-13-28-26-995064_chatcmpl-b701341f-7a6b-4884-8abe-7aff8aa43b8b",
          "traceId": "b2c11c7c",
          "type": "GENERATION",
          "name": "b2_mc_conversion_code_gen",
          "startTime": "2025-09-18T10:28:26.995000+00:00",
          "endTime": "2025-09-18T10:28:36.439000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 9444.0,
          "totalTokens": 802,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 351,
          "promptTokens": 451,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-13-28-41-848321_chatcmpl-c4a839e7-7483-4469-a5a9-b974e2d30584",
          "traceId": "b2c11c7c",
          "type": "GENERATION",
          "name": "b2_mc_error_handling_attempt#2",
          "startTime": "2025-09-18T10:28:41.848000+00:00",
          "endTime": "2025-09-18T10:28:51.133000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 9285.0,
          "totalTokens": 2316,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 268,
          "promptTokens": 2048,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-13-28-51-141631_chatcmpl-29e157c1-1f6d-4ff1-983e-bd7edb6a0f60",
          "traceId": "b2c11c7c",
          "type": "GENERATION",
          "name": "b2_mc_error_handling_attempt#3",
          "startTime": "2025-09-18T10:28:51.141000+00:00",
          "endTime": "2025-09-18T10:29:02.579000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 11438.0,
          "totalTokens": 1271,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 399,
          "promptTokens": 872,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "025872a0-f64e-4a42-8ad6-cc7825dccfc3",
          "traceId": "b2c11c7c",
          "type": "SPAN",
          "name": "start_model_converter",
          "startTime": "2025-09-18T10:28:26.993000+00:00",
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "totalTokens": 0,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 0,
          "promptTokens": 0,
          "endTime": null,
          "model": null,
          "modelParameters": null,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null,
          "latency": null
        }
      ],
      "environment": "default",
      "createdAt": "2025-09-18T10:28:27.514Z",
      "updatedAt": "2025-09-18T10:29:12.141Z"
    },
    {
      "id": "58adf4e4",
      "timestamp": "2025-09-18T10:27:21.537000+00:00",
      "name": "58ad_model_converter",
      "input": null,
      "output": {
        "status": "success",
        "code": "import tensorflow as tf\nimport numpy as np\n\n# Load the original Keras model\noriginal_model = tf.keras.models.load_model(\"models/fruit_to_emoji/og_model/model.keras\")\n\n# Define conversion parameters for quantization\nconverter = tf.lite.TFLiteConverter.from_keras_model(original_model)\nconverter.optimizations = [tf.lite.Optimize.DEFAULT]\n\n# Define the data type requirements for quantization\ninference_input_type = tf.float32\ninference_output_type = tf.uint8\n\n# Ensure that if any ops can't be quantized, they are still included as float32\nsupported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n\n# Define a representative dataset generator function\ndef representative_dataset_gen():\n    for _ in range(100):\n        # Get sample input data as a numpy array in a method of your choosing.\n        # Here, we assume the input shape is (224, 224, 3) and values are normalized between 0 and 1\n        input_data = np.random.rand(1, 224, 224, 3).astype(np.float32)\n        yield [input_data]\n\nconverter.representative_dataset = representative_dataset_gen\n\n# Set the input and output tensors to int8 (except the input which stays float32)\nconverter.target_spec.supported_types = [tf.int8]\nconverter.inference_input_type = inference_input_type\nconverter.inference_output_type = inference_output_type\nconverter.target_spec.supported_ops = supported_ops\n\n# Convert the model to the TensorFlow Lite format with quantization\ntflite_model_quant = converter.convert()\n\n# Save the converted TFLite model to a file\nwith open(\"models/fruit_to_emoji/tflite_model/model_quant.tflite\", \"wb\") as f:\n    f.write(tflite_model_quant)"
      },
      "session_id": "qwen2.5-coder:32b_363e_mc_batch",
      "metadata": {
        "num_run": 14
      },
      "tags": [
        "benchmark",
        "model_converter",
        "qwen2.5-coder:32b"
      ],
      "latency": 35.529,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-13-27-21-538944_chatcmpl-f496514f-46ae-4e7b-96b3-70339a4c860b",
          "traceId": "58adf4e4",
          "type": "GENERATION",
          "name": "58_mc_conversion_code_gen",
          "startTime": "2025-09-18T10:27:21.538000+00:00",
          "endTime": "2025-09-18T10:27:31+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 9462.0,
          "totalTokens": 802,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 351,
          "promptTokens": 451,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-13-27-34-440359_chatcmpl-b82914ee-6334-4c73-89a1-7768fc413eb9",
          "traceId": "58adf4e4",
          "type": "GENERATION",
          "name": "58_mc_error_handling_attempt#2",
          "startTime": "2025-09-18T10:27:34.440000+00:00",
          "endTime": "2025-09-18T10:27:45.624000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 11184.0,
          "totalTokens": 2385,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 337,
          "promptTokens": 2048,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-13-27-45-630816_chatcmpl-04d45b2f-a75e-4620-b7cf-a78c2289fbfb",
          "traceId": "58adf4e4",
          "type": "GENERATION",
          "name": "58_mc_error_handling_attempt#3",
          "startTime": "2025-09-18T10:27:45.630000+00:00",
          "endTime": "2025-09-18T10:27:57.066000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 11436.0,
          "totalTokens": 1271,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 399,
          "promptTokens": 872,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "7d75a5cf-624f-4865-ac97-2de9bab17c27",
          "traceId": "58adf4e4",
          "type": "SPAN",
          "name": "start_model_converter",
          "startTime": "2025-09-18T10:27:21.537000+00:00",
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "totalTokens": 0,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 0,
          "promptTokens": 0,
          "endTime": null,
          "model": null,
          "modelParameters": null,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null,
          "latency": null
        }
      ],
      "environment": "default",
      "createdAt": "2025-09-18T10:27:22.060Z",
      "updatedAt": "2025-09-18T10:28:06.714Z"
    },
    {
      "id": "9fdfe7ce",
      "timestamp": "2025-09-18T10:26:18.195000+00:00",
      "name": "9fdf_model_converter",
      "input": null,
      "output": {
        "status": "success",
        "code": "import tensorflow as tf\nimport numpy as np\n\n# Load the original Keras model\noriginal_model = tf.keras.models.load_model(\"models/fruit_to_emoji/og_model/model.keras\")\n\n# Define conversion parameters for quantization\nconverter = tf.lite.TFLiteConverter.from_keras_model(original_model)\nconverter.optimizations = [tf.lite.Optimize.DEFAULT]\n\n# Define the data type requirements for quantization\ninference_input_type = tf.float32\ninference_output_type = tf.uint8\n\n# Ensure that if any ops can't be quantized, they are still included as float32\nsupported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n\n# Define a representative dataset generator function\ndef representative_dataset_gen():\n    for _ in range(100):\n        # Get sample input data as a numpy array in a method of your choosing.\n        # Here, we assume the input shape is (224, 224, 3) and values are normalized between 0 and 1\n        input_data = np.random.rand(1, 224, 224, 3).astype(np.float32)\n        yield [input_data]\n\nconverter.representative_dataset = representative_dataset_gen\n\n# Set the input and output tensors to int8 (except the input which stays float32)\nconverter.target_spec.supported_types = [tf.int8]\nconverter.inference_input_type = inference_input_type\nconverter.inference_output_type = inference_output_type\nconverter.target_spec.supported_ops = supported_ops\n\n# Convert the model to the TensorFlow Lite format with quantization\ntflite_model_quant = converter.convert()\n\n# Save the converted TFLite model to a file\nwith open(\"models/fruit_to_emoji/tflite_model/model_quant.tflite\", \"wb\") as f:\n    f.write(tflite_model_quant)"
      },
      "session_id": "qwen2.5-coder:32b_363e_mc_batch",
      "metadata": {
        "num_run": 13
      },
      "tags": [
        "benchmark",
        "model_converter",
        "qwen2.5-coder:32b"
      ],
      "latency": 33.51,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-13-26-18-197939_chatcmpl-6b855952-935e-4cce-8325-b25a810b12cc",
          "traceId": "9fdfe7ce",
          "type": "GENERATION",
          "name": "9f_mc_conversion_code_gen",
          "startTime": "2025-09-18T10:26:18.197000+00:00",
          "endTime": "2025-09-18T10:26:27.625000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 9428.0,
          "totalTokens": 802,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 351,
          "promptTokens": 451,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-13-26-30-958812_chatcmpl-571df9e2-c013-41f7-b2b6-be573fcc941d",
          "traceId": "9fdfe7ce",
          "type": "GENERATION",
          "name": "9f_mc_error_handling_attempt#2",
          "startTime": "2025-09-18T10:26:30.958000+00:00",
          "endTime": "2025-09-18T10:26:40.270000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 9312.0,
          "totalTokens": 2317,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 269,
          "promptTokens": 2048,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-13-26-40-276110_chatcmpl-3e32fa7e-1c64-4cc8-8585-055dc9cf86e8",
          "traceId": "9fdfe7ce",
          "type": "GENERATION",
          "name": "9f_mc_error_handling_attempt#3",
          "startTime": "2025-09-18T10:26:40.276000+00:00",
          "endTime": "2025-09-18T10:26:51.706000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 11430.0,
          "totalTokens": 1271,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 399,
          "promptTokens": 872,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "c2455511-baee-46a8-8164-21f0471dd7bf",
          "traceId": "9fdfe7ce",
          "type": "SPAN",
          "name": "start_model_converter",
          "startTime": "2025-09-18T10:26:18.196000+00:00",
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "totalTokens": 0,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 0,
          "promptTokens": 0,
          "endTime": null,
          "model": null,
          "modelParameters": null,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null,
          "latency": null
        }
      ],
      "environment": "default",
      "createdAt": "2025-09-18T10:26:18.722Z",
      "updatedAt": "2025-09-18T10:27:01.348Z"
    },
    {
      "id": "c42e682e",
      "timestamp": "2025-09-18T10:25:13.827000+00:00",
      "name": "c42e_model_converter",
      "input": null,
      "output": {
        "status": "success",
        "code": "import tensorflow as tf\nimport numpy as np\n\n# Load the original Keras model\noriginal_model = tf.keras.models.load_model(\"models/fruit_to_emoji/og_model/model.keras\")\n\n# Define conversion parameters for quantization\nconverter = tf.lite.TFLiteConverter.from_keras_model(original_model)\nconverter.optimizations = [tf.lite.Optimize.DEFAULT]\n\n# Define the data type requirements for quantization\ninference_input_type = tf.float32\ninference_output_type = tf.uint8\n\n# Ensure that if any ops can't be quantized, they are still included as float32\nsupported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n\n# Define a representative dataset generator function\ndef representative_dataset_gen():\n    for _ in range(100):\n        # Get sample input data as a numpy array in a method of your choosing.\n        # Here, we assume the input shape is (224, 224, 3) and values are normalized between 0 and 1\n        input_data = np.random.rand(1, 224, 224, 3).astype(np.float32)\n        yield [input_data]\n\nconverter.representative_dataset = representative_dataset_gen\n\n# Set the input and output tensors to int8 (except the input which stays float32)\nconverter.target_spec.supported_types = [tf.int8]\nconverter.inference_input_type = inference_input_type\nconverter.inference_output_type = inference_output_type\nconverter.target_spec.supported_ops = supported_ops\n\n# Convert the model to the TensorFlow Lite format with quantization\ntflite_model_quant = converter.convert()\n\n# Save the converted TFLite model to a file\nwith open(\"models/fruit_to_emoji/tflite_model/model_quant.tflite\", \"wb\") as f:\n    f.write(tflite_model_quant)"
      },
      "session_id": "qwen2.5-coder:32b_363e_mc_batch",
      "metadata": {
        "num_run": 12
      },
      "tags": [
        "benchmark",
        "model_converter",
        "qwen2.5-coder:32b"
      ],
      "latency": 34.137,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-13-25-13-828807_chatcmpl-078b4657-0f83-46b4-abc2-96dcd06eba3a",
          "traceId": "c42e682e",
          "type": "GENERATION",
          "name": "c4_mc_conversion_code_gen",
          "startTime": "2025-09-18T10:25:13.828000+00:00",
          "endTime": "2025-09-18T10:25:23.300000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 9472.0,
          "totalTokens": 802,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 351,
          "promptTokens": 451,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-13-25-26-699218_chatcmpl-6aa8ebbc-bc7a-457b-b1ac-b6ca82f94ecf",
          "traceId": "c42e682e",
          "type": "GENERATION",
          "name": "c4_mc_error_handling_attempt#2",
          "startTime": "2025-09-18T10:25:26.699000+00:00",
          "endTime": "2025-09-18T10:25:36.517000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 9818.0,
          "totalTokens": 2333,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 285,
          "promptTokens": 2048,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-13-25-36-524879_chatcmpl-375c90a1-63b1-43bc-a72d-e63d6a2050f0",
          "traceId": "c42e682e",
          "type": "GENERATION",
          "name": "c4_mc_error_handling_attempt#3",
          "startTime": "2025-09-18T10:25:36.524000+00:00",
          "endTime": "2025-09-18T10:25:47.964000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 11440.0,
          "totalTokens": 1271,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 399,
          "promptTokens": 872,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "7d211be1-4160-4cf0-9273-a764c5afe464",
          "traceId": "c42e682e",
          "type": "SPAN",
          "name": "start_model_converter",
          "startTime": "2025-09-18T10:25:13.827000+00:00",
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "totalTokens": 0,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 0,
          "promptTokens": 0,
          "endTime": null,
          "model": null,
          "modelParameters": null,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null,
          "latency": null
        }
      ],
      "environment": "default",
      "createdAt": "2025-09-18T10:25:14.350Z",
      "updatedAt": "2025-09-18T10:25:57.671Z"
    },
    {
      "id": "58719fb0",
      "timestamp": "2025-09-18T10:24:10.478000+00:00",
      "name": "5871_model_converter",
      "input": null,
      "output": {
        "status": "success",
        "code": "import tensorflow as tf\nimport numpy as np\n\n# Load the original Keras model\noriginal_model = tf.keras.models.load_model(\"models/fruit_to_emoji/og_model/model.keras\")\n\n# Define conversion parameters for quantization\nconverter = tf.lite.TFLiteConverter.from_keras_model(original_model)\nconverter.optimizations = [tf.lite.Optimize.DEFAULT]\n\n# Define the data type requirements for quantization\ninference_input_type = tf.float32\ninference_output_type = tf.uint8\n\n# Ensure that if any ops can't be quantized, they are still included as float32\nsupported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n\n# Define a representative dataset generator function\ndef representative_dataset_gen():\n    for _ in range(100):\n        # Get sample input data as a numpy array in a method of your choosing.\n        # Here, we assume the input shape is (224, 224, 3) and values are normalized between 0 and 1\n        input_data = np.random.rand(1, 224, 224, 3).astype(np.float32)\n        yield [input_data]\n\nconverter.representative_dataset = representative_dataset_gen\n\n# Set the input and output tensors to int8 (except the input which stays float32)\nconverter.target_spec.supported_types = [tf.int8]\nconverter.inference_input_type = inference_input_type\nconverter.inference_output_type = inference_output_type\nconverter.target_spec.supported_ops = supported_ops\n\n# Convert the model to the TensorFlow Lite format with quantization\ntflite_model_quant = converter.convert()\n\n# Save the converted TFLite model to a file\nwith open(\"models/fruit_to_emoji/tflite_model/model_quant.tflite\", \"wb\") as f:\n    f.write(tflite_model_quant)"
      },
      "session_id": "qwen2.5-coder:32b_363e_mc_batch",
      "metadata": {
        "num_run": 11
      },
      "tags": [
        "benchmark",
        "model_converter",
        "qwen2.5-coder:32b"
      ],
      "latency": 33.545,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-13-24-10-481003_chatcmpl-ca60aa4f-3757-47cc-bf4c-a262b7e8d92b",
          "traceId": "58719fb0",
          "type": "GENERATION",
          "name": "58_mc_conversion_code_gen",
          "startTime": "2025-09-18T10:24:10.481000+00:00",
          "endTime": "2025-09-18T10:24:19.912000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 9431.0,
          "totalTokens": 802,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 351,
          "promptTokens": 451,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-13-24-23-353583_chatcmpl-ba555f17-b96e-420d-8b2c-8abc0b202051",
          "traceId": "58719fb0",
          "type": "GENERATION",
          "name": "58_mc_error_handling_attempt#2",
          "startTime": "2025-09-18T10:24:23.353000+00:00",
          "endTime": "2025-09-18T10:24:32.562000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 9209.0,
          "totalTokens": 2313,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 265,
          "promptTokens": 2048,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-13-24-32-565490_chatcmpl-ed9eaacc-db1b-49de-9eb2-bdc5ce309a1a",
          "traceId": "58719fb0",
          "type": "GENERATION",
          "name": "58_mc_error_handling_attempt#3",
          "startTime": "2025-09-18T10:24:32.565000+00:00",
          "endTime": "2025-09-18T10:24:44.024000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 11459.0,
          "totalTokens": 1271,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 399,
          "promptTokens": 872,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "fe6055c3-f9aa-41f8-bd20-769eaf1691c4",
          "traceId": "58719fb0",
          "type": "SPAN",
          "name": "start_model_converter",
          "startTime": "2025-09-18T10:24:10.479000+00:00",
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "totalTokens": 0,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 0,
          "promptTokens": 0,
          "endTime": null,
          "model": null,
          "modelParameters": null,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null,
          "latency": null
        }
      ],
      "environment": "default",
      "createdAt": "2025-09-18T10:24:11.006Z",
      "updatedAt": "2025-09-18T10:24:53.653Z"
    },
    {
      "id": "780e2788",
      "timestamp": "2025-09-18T10:23:07.094000+00:00",
      "name": "780e_model_converter",
      "input": null,
      "output": {
        "status": "success",
        "code": "import tensorflow as tf\nimport numpy as np\n\n# Load the original Keras model\noriginal_model = tf.keras.models.load_model(\"models/fruit_to_emoji/og_model/model.keras\")\n\n# Define conversion parameters for quantization\nconverter = tf.lite.TFLiteConverter.from_keras_model(original_model)\nconverter.optimizations = [tf.lite.Optimize.DEFAULT]\n\n# Define the data type requirements for quantization\ninference_input_type = tf.float32\ninference_output_type = tf.uint8\n\n# Ensure that if any ops can't be quantized, they are still included as float32\nsupported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n\n# Define a representative dataset generator function\ndef representative_dataset_gen():\n    for _ in range(100):\n        # Get sample input data as a numpy array in a method of your choosing.\n        # Here, we assume the input shape is (224, 224, 3) and values are normalized between 0 and 1\n        input_data = np.random.rand(1, 224, 224, 3).astype(np.float32)\n        yield [input_data]\n\nconverter.representative_dataset = representative_dataset_gen\n\n# Set the input and output tensors to int8 (except the input which stays float32)\nconverter.target_spec.supported_types = [tf.int8]\nconverter.inference_input_type = inference_input_type\nconverter.inference_output_type = inference_output_type\nconverter.target_spec.supported_ops = supported_ops\n\n# Convert the model to the TensorFlow Lite format with quantization\ntflite_model_quant = converter.convert()\n\n# Save the converted TFLite model to a file\nwith open(\"models/fruit_to_emoji/tflite_model/model_quant.tflite\", \"wb\") as f:\n    f.write(tflite_model_quant)"
      },
      "session_id": "qwen2.5-coder:32b_363e_mc_batch",
      "metadata": {
        "num_run": 10
      },
      "tags": [
        "benchmark",
        "model_converter",
        "qwen2.5-coder:32b"
      ],
      "latency": 33.968,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-13-23-07-096023_chatcmpl-379823cd-9f88-4a29-9e32-fd3c82e6579c",
          "traceId": "780e2788",
          "type": "GENERATION",
          "name": "78_mc_conversion_code_gen",
          "startTime": "2025-09-18T10:23:07.096000+00:00",
          "endTime": "2025-09-18T10:23:16.538000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 9442.0,
          "totalTokens": 802,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 351,
          "promptTokens": 451,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-13-23-20-407876_chatcmpl-48d29ed0-e432-464c-88c6-115b75993f44",
          "traceId": "780e2788",
          "type": "GENERATION",
          "name": "78_mc_error_handling_attempt#2",
          "startTime": "2025-09-18T10:23:20.407000+00:00",
          "endTime": "2025-09-18T10:23:29.609000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 9202.0,
          "totalTokens": 2313,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 265,
          "promptTokens": 2048,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-13-23-29-611690_chatcmpl-8d5bd816-d3e6-48e2-981e-3c5821e5f81d",
          "traceId": "780e2788",
          "type": "GENERATION",
          "name": "78_mc_error_handling_attempt#3",
          "startTime": "2025-09-18T10:23:29.611000+00:00",
          "endTime": "2025-09-18T10:23:41.062000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 11451.0,
          "totalTokens": 1271,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 399,
          "promptTokens": 872,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "1c3d6e9e-527c-4e53-8865-0d3e9d1f4ecc",
          "traceId": "780e2788",
          "type": "SPAN",
          "name": "start_model_converter",
          "startTime": "2025-09-18T10:23:07.094000+00:00",
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "totalTokens": 0,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 0,
          "promptTokens": 0,
          "endTime": null,
          "model": null,
          "modelParameters": null,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null,
          "latency": null
        }
      ],
      "environment": "default",
      "createdAt": "2025-09-18T10:23:07.620Z",
      "updatedAt": "2025-09-18T10:23:50.232Z"
    },
    {
      "id": "ae5e4d56",
      "timestamp": "2025-09-18T10:21:55.759000+00:00",
      "name": "ae5e_model_converter",
      "input": null,
      "output": {
        "status": "success",
        "code": "import tensorflow as tf\nimport numpy as np\n\n# Load the original Keras model\noriginal_model = tf.keras.models.load_model(\"models/fruit_to_emoji/og_model/model.keras\")\n\n# Define conversion parameters for quantization\nconverter = tf.lite.TFLiteConverter.from_keras_model(original_model)\nconverter.optimizations = [tf.lite.Optimize.DEFAULT]\n\n# Define the data type requirements for quantization\ninference_input_type = tf.float32\ninference_output_type = tf.uint8\n\n# Ensure that if any ops can't be quantized, they are still included as float32\nsupported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n\n# Define a representative dataset generator function\ndef representative_dataset_gen():\n    for _ in range(100):\n        # Get sample input data as a numpy array in a method of your choosing.\n        # Here, we assume the input shape is (224, 224, 3) and values are normalized between 0 and 1\n        input_data = np.random.rand(1, 224, 224, 3).astype(np.float32)\n        yield [input_data]\n\nconverter.representative_dataset = representative_dataset_gen\n\n# Set the input and output tensors to int8 (except the input which stays float32)\nconverter.target_spec.supported_types = [tf.int8]\nconverter.inference_input_type = inference_input_type\nconverter.inference_output_type = inference_output_type\nconverter.target_spec.supported_ops = supported_ops\n\n# Convert the model to the TensorFlow Lite format with quantization\ntflite_model_quant = converter.convert()\n\n# Save the converted TFLite model to a file\nwith open(\"models/fruit_to_emoji/tflite_model/model_quant.tflite\", \"wb\") as f:\n    f.write(tflite_model_quant)"
      },
      "session_id": "qwen2.5-coder:32b_363e_mc_batch",
      "metadata": {
        "num_run": 9
      },
      "tags": [
        "benchmark",
        "model_converter",
        "qwen2.5-coder:32b"
      ],
      "latency": 41.128,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-13-21-55-761590_chatcmpl-11baf222-ed1c-43f8-b1ab-ad20f291991e",
          "traceId": "ae5e4d56",
          "type": "GENERATION",
          "name": "ae_mc_conversion_code_gen",
          "startTime": "2025-09-18T10:21:55.761000+00:00",
          "endTime": "2025-09-18T10:22:05.194000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 9433.0,
          "totalTokens": 802,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 351,
          "promptTokens": 451,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-13-22-08-595596_chatcmpl-804a3917-8066-4624-858e-a3ef58206c7f",
          "traceId": "ae5e4d56",
          "type": "GENERATION",
          "name": "ae_mc_error_handling_attempt#2",
          "startTime": "2025-09-18T10:22:08.595000+00:00",
          "endTime": "2025-09-18T10:22:25.435000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 16840.0,
          "totalTokens": 2589,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 541,
          "promptTokens": 2048,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-13-22-25-441628_chatcmpl-780d5ab5-f159-47aa-a8aa-ce4b5602722e",
          "traceId": "ae5e4d56",
          "type": "GENERATION",
          "name": "ae_mc_error_handling_attempt#3",
          "startTime": "2025-09-18T10:22:25.441000+00:00",
          "endTime": "2025-09-18T10:22:36.888000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 11447.0,
          "totalTokens": 1271,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 399,
          "promptTokens": 872,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "50118d62-6128-4d6e-b7a6-96dd1f5a2a78",
          "traceId": "ae5e4d56",
          "type": "SPAN",
          "name": "start_model_converter",
          "startTime": "2025-09-18T10:21:55.760000+00:00",
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "totalTokens": 0,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 0,
          "promptTokens": 0,
          "endTime": null,
          "model": null,
          "modelParameters": null,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null,
          "latency": null
        }
      ],
      "environment": "default",
      "createdAt": "2025-09-18T10:21:56.284Z",
      "updatedAt": "2025-09-18T10:22:46.409Z"
    },
    {
      "id": "64ceef31",
      "timestamp": "2025-09-18T10:20:50.313000+00:00",
      "name": "64ce_model_converter",
      "input": null,
      "output": {
        "status": "success",
        "code": "import tensorflow as tf\nimport numpy as np\n\n# Load the original Keras model\noriginal_model = tf.keras.models.load_model(\"models/fruit_to_emoji/og_model/model.keras\")\n\n# Define conversion parameters for quantization\nconverter = tf.lite.TFLiteConverter.from_keras_model(original_model)\nconverter.optimizations = [tf.lite.Optimize.DEFAULT]\n\n# Define the data type requirements for quantization\ninference_input_type = tf.float32\ninference_output_type = tf.uint8\n\n# Ensure that if any ops can't be quantized, they are still included as float32\nsupported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n\n# Define a representative dataset generator function\ndef representative_dataset_gen():\n    for _ in range(100):\n        # Get sample input data as a numpy array in a method of your choosing.\n        # Here, we assume the input shape is (224, 224, 3) and values are normalized between 0 and 1\n        input_data = np.random.rand(1, 224, 224, 3).astype(np.float32)\n        yield [input_data]\n\nconverter.representative_dataset = representative_dataset_gen\n\n# Set the input and output tensors to int8 (except the input which stays float32)\nconverter.target_spec.supported_types = [tf.int8]\nconverter.inference_input_type = inference_input_type\nconverter.inference_output_type = inference_output_type\nconverter.target_spec.supported_ops = supported_ops\n\n# Convert the model to the TensorFlow Lite format with quantization\ntflite_model_quant = converter.convert()\n\n# Save the converted TFLite model to a file\nwith open(\"models/fruit_to_emoji/tflite_model/model_quant.tflite\", \"wb\") as f:\n    f.write(tflite_model_quant)"
      },
      "session_id": "qwen2.5-coder:32b_363e_mc_batch",
      "metadata": {
        "num_run": 8
      },
      "tags": [
        "benchmark",
        "model_converter",
        "qwen2.5-coder:32b"
      ],
      "latency": 34.621,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-13-20-50-314830_chatcmpl-137d4cfe-b176-4ee3-8566-c295392f78d5",
          "traceId": "64ceef31",
          "type": "GENERATION",
          "name": "64_mc_conversion_code_gen",
          "startTime": "2025-09-18T10:20:50.314000+00:00",
          "endTime": "2025-09-18T10:20:59.912000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 9598.0,
          "totalTokens": 802,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 351,
          "promptTokens": 451,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-13-21-04-140756_chatcmpl-4f4daae1-3034-4279-aa49-b4396a4522a8",
          "traceId": "64ceef31",
          "type": "GENERATION",
          "name": "64_mc_error_handling_attempt#2",
          "startTime": "2025-09-18T10:21:04.140000+00:00",
          "endTime": "2025-09-18T10:21:13.487000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 9347.0,
          "totalTokens": 2317,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 269,
          "promptTokens": 2048,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-13-21-13-491655_chatcmpl-cc39c352-e514-440e-9ace-7362ad0cd68a",
          "traceId": "64ceef31",
          "type": "GENERATION",
          "name": "64_mc_error_handling_attempt#3",
          "startTime": "2025-09-18T10:21:13.491000+00:00",
          "endTime": "2025-09-18T10:21:24.934000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 11443.0,
          "totalTokens": 1271,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 399,
          "promptTokens": 872,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "0a46388f-5454-497c-819b-43ab0bb0c974",
          "traceId": "64ceef31",
          "type": "SPAN",
          "name": "start_model_converter",
          "startTime": "2025-09-18T10:20:50.313000+00:00",
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "totalTokens": 0,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 0,
          "promptTokens": 0,
          "endTime": null,
          "model": null,
          "modelParameters": null,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null,
          "latency": null
        }
      ],
      "environment": "default",
      "createdAt": "2025-09-18T10:20:50.836Z",
      "updatedAt": "2025-09-18T10:21:34.962Z"
    },
    {
      "id": "6ee204d5",
      "timestamp": "2025-09-18T10:19:45.939000+00:00",
      "name": "6ee2_model_converter",
      "input": null,
      "output": {
        "status": "success",
        "code": "import tensorflow as tf\nimport numpy as np\n\n# Load the original Keras model\noriginal_model = tf.keras.models.load_model(\"models/fruit_to_emoji/og_model/model.keras\")\n\n# Define conversion parameters for quantization\nconverter = tf.lite.TFLiteConverter.from_keras_model(original_model)\nconverter.optimizations = [tf.lite.Optimize.DEFAULT]\n\n# Define the data type requirements for quantization\ninference_input_type = tf.float32\ninference_output_type = tf.uint8\n\n# Ensure that if any ops can't be quantized, they are still included as float32\nsupported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n\n# Define a representative dataset generator function\ndef representative_dataset_gen():\n    for _ in range(100):\n        # Get sample input data as a numpy array in a method of your choosing.\n        # Here, we assume the input shape is (224, 224, 3) and values are normalized between 0 and 1\n        input_data = np.random.rand(1, 224, 224, 3).astype(np.float32)\n        yield [input_data]\n\nconverter.representative_dataset = representative_dataset_gen\n\n# Set the input and output tensors to int8 (except the input which stays float32)\nconverter.target_spec.supported_types = [tf.int8]\nconverter.inference_input_type = inference_input_type\nconverter.inference_output_type = inference_output_type\nconverter.target_spec.supported_ops = supported_ops\n\n# Convert the model to the TensorFlow Lite format with quantization\ntflite_model_quant = converter.convert()\n\n# Save the converted TFLite model to a file\nwith open(\"models/fruit_to_emoji/tflite_model/model_quant.tflite\", \"wb\") as f:\n    f.write(tflite_model_quant)"
      },
      "session_id": "qwen2.5-coder:32b_363e_mc_batch",
      "metadata": {
        "num_run": 7
      },
      "tags": [
        "benchmark",
        "model_converter",
        "qwen2.5-coder:32b"
      ],
      "latency": 33.884,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-13-19-45-941702_chatcmpl-a1ca4ecd-c862-49f6-bdf4-9714f0d4dd9f",
          "traceId": "6ee204d5",
          "type": "GENERATION",
          "name": "6e_mc_conversion_code_gen",
          "startTime": "2025-09-18T10:19:45.941000+00:00",
          "endTime": "2025-09-18T10:19:55.371000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 9430.0,
          "totalTokens": 802,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 351,
          "promptTokens": 451,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-13-19-58-714169_chatcmpl-33073515-d15c-4217-87d2-814d8ed91db8",
          "traceId": "6ee204d5",
          "type": "GENERATION",
          "name": "6e_mc_error_handling_attempt#2",
          "startTime": "2025-09-18T10:19:58.714000+00:00",
          "endTime": "2025-09-18T10:20:08.379000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 9665.0,
          "totalTokens": 2330,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 282,
          "promptTokens": 2048,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-13-20-08-381899_chatcmpl-31b2cea3-92e4-42ae-badc-751e1a78c643",
          "traceId": "6ee204d5",
          "type": "GENERATION",
          "name": "6e_mc_error_handling_attempt#3",
          "startTime": "2025-09-18T10:20:08.381000+00:00",
          "endTime": "2025-09-18T10:20:19.824000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 11443.0,
          "totalTokens": 1271,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 399,
          "promptTokens": 872,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "13857871-dab8-4feb-9148-6852a44c2a44",
          "traceId": "6ee204d5",
          "type": "SPAN",
          "name": "start_model_converter",
          "startTime": "2025-09-18T10:19:45.940000+00:00",
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "totalTokens": 0,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 0,
          "promptTokens": 0,
          "endTime": null,
          "model": null,
          "modelParameters": null,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null,
          "latency": null
        }
      ],
      "environment": "default",
      "createdAt": "2025-09-18T10:19:46.461Z",
      "updatedAt": "2025-09-18T10:20:29.639Z"
    },
    {
      "id": "e48fa2fa",
      "timestamp": "2025-09-18T10:18:36.625000+00:00",
      "name": "e48f_model_converter",
      "input": null,
      "output": {
        "status": "success",
        "code": "import tensorflow as tf\nimport numpy as np\n\n# Load the original Keras model\noriginal_model = tf.keras.models.load_model(\"models/fruit_to_emoji/og_model/model.keras\")\n\n# Define conversion parameters for quantization\nconverter = tf.lite.TFLiteConverter.from_keras_model(original_model)\nconverter.optimizations = [tf.lite.Optimize.DEFAULT]\n\n# Define the data type requirements for quantization\ninference_input_type = tf.float32\ninference_output_type = tf.uint8\n\n# Ensure that if any ops can't be quantized, they are still included as float32\nsupported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n\n# Define a representative dataset generator function\ndef representative_dataset_gen():\n    for _ in range(100):\n        # Get sample input data as a numpy array in a method of your choosing.\n        # Here, we assume the input shape is (224, 224, 3) and values are normalized between 0 and 1\n        input_data = np.random.rand(1, 224, 224, 3).astype(np.float32)\n        yield [input_data]\n\nconverter.representative_dataset = representative_dataset_gen\n\n# Set the input and output tensors to int8 (except the input which stays float32)\nconverter.target_spec.supported_types = [tf.int8]\nconverter.inference_input_type = inference_input_type\nconverter.inference_output_type = inference_output_type\nconverter.target_spec.supported_ops = supported_ops\n\n# Convert the model to the TensorFlow Lite format with quantization\ntflite_model_quant = converter.convert()\n\n# Save the converted TFLite model to a file\nwith open(\"models/fruit_to_emoji/tflite_model/model_quant.tflite\", \"wb\") as f:\n    f.write(tflite_model_quant)"
      },
      "session_id": "qwen2.5-coder:32b_363e_mc_batch",
      "metadata": {
        "num_run": 6
      },
      "tags": [
        "benchmark",
        "model_converter",
        "qwen2.5-coder:32b"
      ],
      "latency": 39.571,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-13-18-36-627445_chatcmpl-11d5d745-7848-4ed9-a015-7afdac9a9b0c",
          "traceId": "e48fa2fa",
          "type": "GENERATION",
          "name": "e4_mc_conversion_code_gen",
          "startTime": "2025-09-18T10:18:36.627000+00:00",
          "endTime": "2025-09-18T10:18:47.108000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 10481.0,
          "totalTokens": 802,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 351,
          "promptTokens": 451,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-13-18-50-440710_chatcmpl-593a5e89-86cf-47f4-ae63-2cd6235f6dfb",
          "traceId": "e48fa2fa",
          "type": "GENERATION",
          "name": "e4_mc_error_handling_attempt#2",
          "startTime": "2025-09-18T10:18:50.440000+00:00",
          "endTime": "2025-09-18T10:19:04.760000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 14320.0,
          "totalTokens": 2498,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 450,
          "promptTokens": 2048,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-13-19-04-763033_chatcmpl-4bba5fff-cacf-43cf-8c8f-243926c7d895",
          "traceId": "e48fa2fa",
          "type": "GENERATION",
          "name": "e4_mc_error_handling_attempt#3",
          "startTime": "2025-09-18T10:19:04.763000+00:00",
          "endTime": "2025-09-18T10:19:16.196000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 11433.0,
          "totalTokens": 1271,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 399,
          "promptTokens": 872,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "5ec70942-f09f-4231-b6ad-1268f491d668",
          "traceId": "e48fa2fa",
          "type": "SPAN",
          "name": "start_model_converter",
          "startTime": "2025-09-18T10:18:36.625000+00:00",
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "totalTokens": 0,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 0,
          "promptTokens": 0,
          "endTime": null,
          "model": null,
          "modelParameters": null,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null,
          "latency": null
        }
      ],
      "environment": "default",
      "createdAt": "2025-09-18T10:18:37.703Z",
      "updatedAt": "2025-09-18T10:19:25.823Z"
    },
    {
      "id": "6f66c1f8",
      "timestamp": "2025-09-18T10:17:32.259000+00:00",
      "name": "6f66_model_converter",
      "input": null,
      "output": {
        "status": "success",
        "code": "import tensorflow as tf\nimport numpy as np\n\n# Load the original Keras model\noriginal_model = tf.keras.models.load_model(\"models/fruit_to_emoji/og_model/model.keras\")\n\n# Define conversion parameters for quantization\nconverter = tf.lite.TFLiteConverter.from_keras_model(original_model)\nconverter.optimizations = [tf.lite.Optimize.DEFAULT]\n\n# Define the data type requirements for quantization\ninference_input_type = tf.float32\ninference_output_type = tf.uint8\n\n# Ensure that if any ops can't be quantized, they are still included as float32\nsupported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n\n# Define a representative dataset generator function\ndef representative_dataset_gen():\n    for _ in range(100):\n        # Get sample input data as a numpy array in a method of your choosing.\n        # Here, we assume the input shape is (224, 224, 3) and values are normalized between 0 and 1\n        input_data = np.random.rand(1, 224, 224, 3).astype(np.float32)\n        yield [input_data]\n\nconverter.representative_dataset = representative_dataset_gen\n\n# Set the input and output tensors to int8 (except the input which stays float32)\nconverter.target_spec.supported_types = [tf.int8]\nconverter.inference_input_type = inference_input_type\nconverter.inference_output_type = inference_output_type\nconverter.target_spec.supported_ops = supported_ops\n\n# Convert the model to the TensorFlow Lite format with quantization\ntflite_model_quant = converter.convert()\n\n# Save the converted TFLite model to a file\nwith open(\"models/fruit_to_emoji/tflite_model/model_quant.tflite\", \"wb\") as f:\n    f.write(tflite_model_quant)"
      },
      "session_id": "qwen2.5-coder:32b_363e_mc_batch",
      "metadata": {
        "num_run": 5
      },
      "tags": [
        "benchmark",
        "model_converter",
        "qwen2.5-coder:32b"
      ],
      "latency": 34.596,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-13-17-32-260417_chatcmpl-f41b3eab-a5b2-4023-a00f-1bfeaab7b278",
          "traceId": "6f66c1f8",
          "type": "GENERATION",
          "name": "6f_mc_conversion_code_gen",
          "startTime": "2025-09-18T10:17:32.260000+00:00",
          "endTime": "2025-09-18T10:17:41.702000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 9442.0,
          "totalTokens": 802,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 351,
          "promptTokens": 451,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-13-17-45-667353_chatcmpl-4ff01ee3-e41d-4c47-9581-51c798db9a58",
          "traceId": "6f66c1f8",
          "type": "GENERATION",
          "name": "6f_mc_error_handling_attempt#2",
          "startTime": "2025-09-18T10:17:45.667000+00:00",
          "endTime": "2025-09-18T10:17:55.409000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 9742.0,
          "totalTokens": 2333,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 285,
          "promptTokens": 2048,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-13-17-55-414955_chatcmpl-97074506-89d1-42a0-b72b-eb8afeaf376e",
          "traceId": "6f66c1f8",
          "type": "GENERATION",
          "name": "6f_mc_error_handling_attempt#3",
          "startTime": "2025-09-18T10:17:55.414000+00:00",
          "endTime": "2025-09-18T10:18:06.855000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 11441.0,
          "totalTokens": 1271,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 399,
          "promptTokens": 872,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "0a514235-554f-4a78-9503-19653dd6e088",
          "traceId": "6f66c1f8",
          "type": "SPAN",
          "name": "start_model_converter",
          "startTime": "2025-09-18T10:17:32.259000+00:00",
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "totalTokens": 0,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 0,
          "promptTokens": 0,
          "endTime": null,
          "model": null,
          "modelParameters": null,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null,
          "latency": null
        }
      ],
      "environment": "default",
      "createdAt": "2025-09-18T10:17:32.781Z",
      "updatedAt": "2025-09-18T10:18:16.382Z"
    },
    {
      "id": "c1803c9b",
      "timestamp": "2025-09-18T10:16:27.550000+00:00",
      "name": "c180_model_converter",
      "input": null,
      "output": {
        "status": "success",
        "code": "import tensorflow as tf\nimport numpy as np\n\n# Load the original Keras model\noriginal_model = tf.keras.models.load_model(\"models/fruit_to_emoji/og_model/model.keras\")\n\n# Define conversion parameters for quantization\nconverter = tf.lite.TFLiteConverter.from_keras_model(original_model)\nconverter.optimizations = [tf.lite.Optimize.DEFAULT]\n\n# Define the data type requirements for quantization\ninference_input_type = tf.float32\ninference_output_type = tf.uint8\n\n# Ensure that if any ops can't be quantized, they are still included as float32\nsupported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n\n# Define a representative dataset generator function\ndef representative_dataset_gen():\n    for _ in range(100):\n        # Get sample input data as a numpy array in a method of your choosing.\n        # Here, we assume the input shape is (224, 224, 3) and values are normalized between 0 and 1\n        input_data = np.random.rand(1, 224, 224, 3).astype(np.float32)\n        yield [input_data]\n\nconverter.representative_dataset = representative_dataset_gen\n\n# Set the input and output tensors to int8 (except the input which stays float32)\nconverter.target_spec.supported_types = [tf.int8]\nconverter.inference_input_type = inference_input_type\nconverter.inference_output_type = inference_output_type\nconverter.target_spec.supported_ops = supported_ops\n\n# Convert the model to the TensorFlow Lite format with quantization\ntflite_model_quant = converter.convert()\n\n# Save the converted TFLite model to a file\nwith open(\"models/fruit_to_emoji/tflite_model/model_quant.tflite\", \"wb\") as f:\n    f.write(tflite_model_quant)"
      },
      "session_id": "qwen2.5-coder:32b_363e_mc_batch",
      "metadata": {
        "num_run": 4
      },
      "tags": [
        "benchmark",
        "model_converter",
        "qwen2.5-coder:32b"
      ],
      "latency": 33.98,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-13-16-27-552078_chatcmpl-e761eaef-5524-4dbf-af0d-747756ed36e6",
          "traceId": "c1803c9b",
          "type": "GENERATION",
          "name": "c1_mc_conversion_code_gen",
          "startTime": "2025-09-18T10:16:27.552000+00:00",
          "endTime": "2025-09-18T10:16:36.999000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 9447.0,
          "totalTokens": 802,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 351,
          "promptTokens": 451,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-13-16-40-478048_chatcmpl-2c0e4c04-f250-4f9d-9ec5-2ee0d3efbdd5",
          "traceId": "c1803c9b",
          "type": "GENERATION",
          "name": "c1_mc_error_handling_attempt#2",
          "startTime": "2025-09-18T10:16:40.478000+00:00",
          "endTime": "2025-09-18T10:16:50.078000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 9600.0,
          "totalTokens": 2328,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 280,
          "promptTokens": 2048,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-13-16-50-084792_chatcmpl-565bdcb7-8cad-42dd-ad67-9877e6b9358e",
          "traceId": "c1803c9b",
          "type": "GENERATION",
          "name": "c1_mc_error_handling_attempt#3",
          "startTime": "2025-09-18T10:16:50.084000+00:00",
          "endTime": "2025-09-18T10:17:01.530000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 11446.0,
          "totalTokens": 1271,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 399,
          "promptTokens": 872,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "87a53f25-6b8d-4377-9488-092cf7ef18c3",
          "traceId": "c1803c9b",
          "type": "SPAN",
          "name": "start_model_converter",
          "startTime": "2025-09-18T10:16:27.550000+00:00",
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "totalTokens": 0,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 0,
          "promptTokens": 0,
          "endTime": null,
          "model": null,
          "modelParameters": null,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null,
          "latency": null
        }
      ],
      "environment": "default",
      "createdAt": "2025-09-18T10:16:28.075Z",
      "updatedAt": "2025-09-18T10:17:11.256Z"
    },
    {
      "id": "a9debb96",
      "timestamp": "2025-09-18T10:15:23.187000+00:00",
      "name": "a9de_model_converter",
      "input": null,
      "output": {
        "status": "success",
        "code": "import tensorflow as tf\nimport numpy as np\n\n# Load the original Keras model\noriginal_model = tf.keras.models.load_model(\"models/fruit_to_emoji/og_model/model.keras\")\n\n# Define conversion parameters for quantization\nconverter = tf.lite.TFLiteConverter.from_keras_model(original_model)\nconverter.optimizations = [tf.lite.Optimize.DEFAULT]\n\n# Define the data type requirements for quantization\ninference_input_type = tf.float32\ninference_output_type = tf.uint8\n\n# Ensure that if any ops can't be quantized, they are still included as float32\nsupported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n\n# Define a representative dataset generator function\ndef representative_dataset_gen():\n    for _ in range(100):\n        # Get sample input data as a numpy array in a method of your choosing.\n        # Here, we assume the input shape is (224, 224, 3) and values are normalized between 0 and 1\n        input_data = np.random.rand(1, 224, 224, 3).astype(np.float32)\n        yield [input_data]\n\nconverter.representative_dataset = representative_dataset_gen\n\n# Set the input and output tensors to int8 (except the input which stays float32)\nconverter.target_spec.supported_types = [tf.int8]\nconverter.inference_input_type = inference_input_type\nconverter.inference_output_type = inference_output_type\nconverter.target_spec.supported_ops = supported_ops\n\n# Convert the model to the TensorFlow Lite format with quantization\ntflite_model_quant = converter.convert()\n\n# Save the converted TFLite model to a file\nwith open(\"models/fruit_to_emoji/tflite_model/model_quant.tflite\", \"wb\") as f:\n    f.write(tflite_model_quant)"
      },
      "session_id": "qwen2.5-coder:32b_363e_mc_batch",
      "metadata": {
        "num_run": 3
      },
      "tags": [
        "benchmark",
        "model_converter",
        "qwen2.5-coder:32b"
      ],
      "latency": 34.04,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-13-15-23-189210_chatcmpl-6734f0ce-d2b3-47c9-be4e-3ff2db1ba9cd",
          "traceId": "a9debb96",
          "type": "GENERATION",
          "name": "a9_mc_conversion_code_gen",
          "startTime": "2025-09-18T10:15:23.189000+00:00",
          "endTime": "2025-09-18T10:15:32.626000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 9437.0,
          "totalTokens": 802,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 351,
          "promptTokens": 451,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-13-15-36-049238_chatcmpl-f546b938-4722-441e-9dc7-bb1c795383ef",
          "traceId": "a9debb96",
          "type": "GENERATION",
          "name": "a9_mc_error_handling_attempt#2",
          "startTime": "2025-09-18T10:15:36.049000+00:00",
          "endTime": "2025-09-18T10:15:45.794000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 9745.0,
          "totalTokens": 2333,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 285,
          "promptTokens": 2048,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-13-15-45-797227_chatcmpl-8218d856-8819-4308-a5c1-bcb1521a6bb0",
          "traceId": "a9debb96",
          "type": "GENERATION",
          "name": "a9_mc_error_handling_attempt#3",
          "startTime": "2025-09-18T10:15:45.797000+00:00",
          "endTime": "2025-09-18T10:15:57.227000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 11430.0,
          "totalTokens": 1271,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 399,
          "promptTokens": 872,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "6706a729-8754-4e43-a347-63fbb491d881",
          "traceId": "a9debb96",
          "type": "SPAN",
          "name": "start_model_converter",
          "startTime": "2025-09-18T10:15:23.187000+00:00",
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "totalTokens": 0,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 0,
          "promptTokens": 0,
          "endTime": null,
          "model": null,
          "modelParameters": null,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null,
          "latency": null
        }
      ],
      "environment": "default",
      "createdAt": "2025-09-18T10:15:23.708Z",
      "updatedAt": "2025-09-18T10:16:06.829Z"
    },
    {
      "id": "2e07160a",
      "timestamp": "2025-09-18T10:14:18.729000+00:00",
      "name": "2e07_model_converter",
      "input": null,
      "output": {
        "status": "success",
        "code": "import tensorflow as tf\nimport numpy as np\n\n# Load the original Keras model\noriginal_model = tf.keras.models.load_model(\"models/fruit_to_emoji/og_model/model.keras\")\n\n# Define conversion parameters for quantization\nconverter = tf.lite.TFLiteConverter.from_keras_model(original_model)\nconverter.optimizations = [tf.lite.Optimize.DEFAULT]\n\n# Define the data type requirements for quantization\ninference_input_type = tf.float32\ninference_output_type = tf.uint8\n\n# Ensure that if any ops can't be quantized, they are still included as float32\nsupported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n\n# Define a representative dataset generator function\ndef representative_dataset_gen():\n    for _ in range(100):\n        # Get sample input data as a numpy array in a method of your choosing.\n        # Here, we assume the input shape is (224, 224, 3) and values are normalized between 0 and 1\n        input_data = np.random.rand(1, 224, 224, 3).astype(np.float32)\n        yield [input_data]\n\nconverter.representative_dataset = representative_dataset_gen\n\n# Set the input and output tensors to int8 (except the input which stays float32)\nconverter.target_spec.supported_types = [tf.int8]\nconverter.inference_input_type = inference_input_type\nconverter.inference_output_type = inference_output_type\nconverter.target_spec.supported_ops = supported_ops\n\n# Convert the model to the TensorFlow Lite format with quantization\ntflite_model_quant = converter.convert()\n\n# Save the converted TFLite model to a file\nwith open(\"models/fruit_to_emoji/tflite_model/model_quant.tflite\", \"wb\") as f:\n    f.write(tflite_model_quant)"
      },
      "session_id": "qwen2.5-coder:32b_363e_mc_batch",
      "metadata": {
        "num_run": 2
      },
      "tags": [
        "benchmark",
        "model_converter",
        "qwen2.5-coder:32b"
      ],
      "latency": 34.07,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-13-14-18-731395_chatcmpl-03a55e53-2c89-4cfa-9a79-8f8b053bb45d",
          "traceId": "2e07160a",
          "type": "GENERATION",
          "name": "2e_mc_conversion_code_gen",
          "startTime": "2025-09-18T10:14:18.731000+00:00",
          "endTime": "2025-09-18T10:14:28.260000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 9529.0,
          "totalTokens": 802,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 351,
          "promptTokens": 451,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-13-14-31-632742_chatcmpl-dcfce405-66b1-4ddc-ab87-5e8bd599a72c",
          "traceId": "2e07160a",
          "type": "GENERATION",
          "name": "2e_mc_error_handling_attempt#2",
          "startTime": "2025-09-18T10:14:31.632000+00:00",
          "endTime": "2025-09-18T10:14:41.354000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 9722.0,
          "totalTokens": 2332,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 284,
          "promptTokens": 2048,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-13-14-41-364670_chatcmpl-688feb08-5779-45c7-a2ce-dc539923f50c",
          "traceId": "2e07160a",
          "type": "GENERATION",
          "name": "2e_mc_error_handling_attempt#3",
          "startTime": "2025-09-18T10:14:41.364000+00:00",
          "endTime": "2025-09-18T10:14:52.799000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 11435.0,
          "totalTokens": 1271,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 399,
          "promptTokens": 872,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "f983f6a1-ef92-4dd1-8147-8e3b7ba6d8a5",
          "traceId": "2e07160a",
          "type": "SPAN",
          "name": "start_model_converter",
          "startTime": "2025-09-18T10:14:18.729000+00:00",
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "totalTokens": 0,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 0,
          "promptTokens": 0,
          "endTime": null,
          "model": null,
          "modelParameters": null,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null,
          "latency": null
        }
      ],
      "environment": "default",
      "createdAt": "2025-09-18T10:14:19.250Z",
      "updatedAt": "2025-09-18T10:15:02.404Z"
    },
    {
      "id": "0bc1fd66",
      "timestamp": "2025-09-18T10:13:08.343000+00:00",
      "name": "0bc1_model_converter",
      "input": null,
      "output": {
        "status": "success",
        "code": "import tensorflow as tf\nimport numpy as np\n\n# Load the original Keras model\noriginal_model = tf.keras.models.load_model(\"models/fruit_to_emoji/og_model/model.keras\")\n\n# Define conversion parameters for quantization\nconverter = tf.lite.TFLiteConverter.from_keras_model(original_model)\nconverter.optimizations = [tf.lite.Optimize.DEFAULT]\n\n# Define the input and output types for quantization\ninference_input_type = tf.float32\ninference_output_type = tf.uint8\n\n# Ensure that if any ops can't be quantized, the converter throws an error\nconverter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n\n# Define a representative dataset generator function\ndef representative_dataset_gen():\n    for _ in range(100):\n        # Get sample input data as a numpy array in a method of your choosing.\n        # Here, we assume input_data is predefined or can be generated.\n        input_data = np.random.rand(1, 224, 224, 3)  # Example shape for image data\n        yield [np.array(input_data, dtype=np.float32)]\n\n# Set the representative dataset for quantization\nconverter.representative_dataset = representative_dataset_gen\n\n# Set the input and output tensors to int8 (optional)\nconverter.inference_input_type = inference_input_type\nconverter.inference_output_type = inference_output_type\n\n# Convert the model to the TensorFlow Lite format with quantization\ntflite_model_quant = converter.convert()\n\n# Save the converted TFLite model to a file\nwith open(\"models/fruit_to_emoji/tflite_model/model_quant.tflite\", \"wb\") as f:\n    f.write(tflite_model_quant)"
      },
      "session_id": "qwen2.5-coder:32b_363e_mc_batch",
      "metadata": {
        "num_run": 1
      },
      "tags": [
        "benchmark",
        "model_converter",
        "qwen2.5-coder:32b"
      ],
      "latency": 40.334,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-13-13-08-344950_chatcmpl-a2f36e8e-d465-45f3-96bb-3916ce36b01f",
          "traceId": "0bc1fd66",
          "type": "GENERATION",
          "name": "0b_mc_conversion_code_gen",
          "startTime": "2025-09-18T10:13:08.344000+00:00",
          "endTime": "2025-09-18T10:13:18.354000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 10010.0,
          "totalTokens": 813,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 362,
          "promptTokens": 451,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-13-13-21-767312_chatcmpl-f22ac39e-8343-48d0-a6c9-cf037baa79c5",
          "traceId": "0bc1fd66",
          "type": "GENERATION",
          "name": "0b_mc_error_handling_attempt#2",
          "startTime": "2025-09-18T10:13:21.767000+00:00",
          "endTime": "2025-09-18T10:13:37.957000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 16190.0,
          "totalTokens": 2565,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 517,
          "promptTokens": 2048,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-13-13-37-959524_chatcmpl-d77ee08d-dc9b-4ee6-9d1e-b13736ebb66c",
          "traceId": "0bc1fd66",
          "type": "GENERATION",
          "name": "0b_mc_error_handling_attempt#3",
          "startTime": "2025-09-18T10:13:37.959000+00:00",
          "endTime": "2025-09-18T10:13:48.677000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {
            "temperature": "0.1",
            "top_p": "0.3"
          },
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 10718.0,
          "totalTokens": 1255,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 372,
          "promptTokens": 883,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "af22e066-90d5-46c4-883d-16a5f8dce13c",
          "traceId": "0bc1fd66",
          "type": "SPAN",
          "name": "start_model_converter",
          "startTime": "2025-09-18T10:13:08.343000+00:00",
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "totalTokens": 0,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 0,
          "promptTokens": 0,
          "endTime": null,
          "model": null,
          "modelParameters": null,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null,
          "latency": null
        }
      ],
      "environment": "default",
      "createdAt": "2025-09-18T10:13:08.864Z",
      "updatedAt": "2025-09-18T10:13:58.481Z"
    }
  ],
  "meta": {
    "total_items": 30
  }
}
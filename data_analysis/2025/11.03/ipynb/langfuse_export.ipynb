{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setting up\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ref: https://langfuse.com/docs/query-traces\n",
    "import os\n",
    "import json\n",
    "from langfuse import Langfuse\n",
    "import json\n",
    "import os\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "LOCAL_HOST = True\n",
    "\n",
    "\"\"\"Define session_id\"\"\"\n",
    "# session_id=\"qwen2.5-coder_f4d4_dp_batch\"\n",
    "session_id_list = [\n",
    "    # \"qwen2.5-coder:32b_4e11_tpsg_batch\",\n",
    "    # \"qwen2.5-coder:32b_ae24_tpsg_batch\"\n",
    "   \n",
    "    \"qwen2.5-coder:32b_bf8c_dp_batch\"\n",
    "]\n",
    "\n",
    "\n",
    "\"\"\"Define paths\"\"\"\n",
    " \n",
    "parent_dir = os.path.dirname(os.getcwd())\n",
    "\n",
    " \n",
    "# date = os.path.basename(parent_dir)\n",
    "tex_dir = os.path.join(parent_dir, \"tex\")\n",
    "processed_data_dir = os.path.join(parent_dir, \"processed_data\")\n",
    "raw_export_dir = os.path.join(parent_dir, \"raw_export\")\n",
    "ipynb_dir = os.path.join(parent_dir, \"ipynb\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Export raw data\n",
    "\n",
    "Langfuse added a limit of 20 API invocations per minute. https://langfuse.com/faq/all/api-limits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching traces for session qwen2.5-coder:32b_bf8c_dp_batch...\n",
      "Fetching observation data for time-11-49-34-677734_chatcmpl-7544f1d7-3699-4d1e-977b-bece552edcc0...\n",
      "Fetching observation data for time-11-49-41-694552_chatcmpl-00ef26d5-89eb-42f2-a0bf-4859cb4e2133...\n",
      "Fetching observation data for time-11-49-49-114048_chatcmpl-b057319b-c8f8-4c9a-99ad-0f44b2dbc0c1...\n",
      "Fetching observation data for time-11-49-55-617442_chatcmpl-b611028a-5520-4af8-bfbb-272afef5574c...\n",
      "Fetching observation data for time-11-50-02-429282_chatcmpl-648a935f-39e1-4111-b76b-d3834434981b...\n",
      "Fetching observation data for time-11-50-13-484524_chatcmpl-a82e9efd-0759-4c8d-8276-5e918177c7c4...\n",
      "Fetching observation data for time-11-50-24-585392_chatcmpl-14cea095-1a1e-4faa-812c-cf98d678e4d8...\n",
      "Fetching observation data for time-11-50-38-471141_chatcmpl-15b8ace5-1db8-42a8-a467-60a864300e46...\n",
      "Fetching observation data for time-11-50-52-821693_chatcmpl-5364906f-bfb0-4f75-8434-6899b3845989...\n",
      "Fetching observation data for time-11-47-43-254246_chatcmpl-d372d00b-1805-4666-818c-fc0019e538bb...\n",
      "Fetching observation data for time-11-47-49-056352_chatcmpl-28d3bf77-4600-4fba-997f-3b044d8efddc...\n",
      "Fetching observation data for time-11-47-56-195233_chatcmpl-a29371cb-0222-4775-8024-507eb88ff130...\n",
      "Fetching observation data for time-11-48-02-638294_chatcmpl-c73663a2-7319-4b3c-a1d2-9b4e85d220ce...\n",
      "Fetching observation data for time-11-48-09-408588_chatcmpl-908df6c7-f067-43ba-a399-bca023dd41b6...\n",
      "Fetching observation data for time-11-48-20-469519_chatcmpl-ee1e18b2-f4fb-4b25-b0f3-85772474f8fa...\n",
      "Fetching observation data for time-11-48-31-487354_chatcmpl-e6cda269-705b-46c3-9937-2812f76ae424...\n",
      "Fetching observation data for time-11-48-44-839366_chatcmpl-4bd0985c-2e89-490c-bc6b-bbb00fa8d2e2...\n",
      "Fetching observation data for time-11-48-59-167815_chatcmpl-0812ed7c-6347-43f6-91f7-e14d5d92d986...\n",
      "Fetching observation data for time-11-45-50-563518_chatcmpl-4d3a29a6-d59b-4a3a-8de4-3604e8a6da96...\n",
      "Fetching observation data for time-11-45-56-373233_chatcmpl-8ee0b608-d23b-4d74-9af0-e43a593bccd9...\n",
      "Fetching observation data for time-11-46-03-529735_chatcmpl-502dcc6f-5144-45ed-a130-11e6cc14be71...\n",
      "Fetching observation data for time-11-46-09-977482_chatcmpl-44873154-5a66-4ef4-b536-aaeb20d749cd...\n",
      "Fetching observation data for time-11-46-16-868896_chatcmpl-28698fa0-15d5-45a1-bdc9-71a58f1c2179...\n",
      "Fetching observation data for time-11-46-28-059548_chatcmpl-6eb45370-151f-4857-a233-5924d0fde34c...\n",
      "Fetching observation data for time-11-46-39-034702_chatcmpl-e02dc1fa-402f-44ff-9453-cfc15de3c1f4...\n",
      "Fetching observation data for time-11-46-52-458586_chatcmpl-7a4a27c0-61e7-4448-a6cb-4e31bbeedd0a...\n",
      "Fetching observation data for time-11-47-06-827978_chatcmpl-9723f6d7-ef25-4dca-bf8c-dc2bf6b9509a...\n",
      "Fetching observation data for time-11-44-11-080085_chatcmpl-a87af5d8-339a-425f-9552-0cd3eb965327...\n",
      "Fetching observation data for time-11-44-15-333682_chatcmpl-fb4c9941-ecf2-42cd-babe-0439f53bf44f...\n",
      "Fetching observation data for time-11-44-21-461014_chatcmpl-f22ce4ab-5bbc-42b3-add0-9e8cf38b215e...\n",
      "Fetching observation data for time-11-44-26-632168_chatcmpl-040aa84e-07a5-4ffe-b199-0232596edf30...\n",
      "Fetching observation data for time-11-44-32-866198_chatcmpl-79594236-7a86-4077-bb8c-f6a5b46dc710...\n",
      "Fetching observation data for time-11-44-39-614697_chatcmpl-7a3c49a4-04a3-43f8-a1c3-ad51cd00531e...\n",
      "Fetching observation data for time-11-44-50-348960_chatcmpl-f0cfba4d-84ef-4a3f-86dc-f5f83e2df4cf...\n",
      "Fetching observation data for time-11-44-59-954681_chatcmpl-7da791eb-b8a6-4b78-bbd9-a497d65b8da4...\n",
      "Fetching observation data for time-11-45-11-879687_chatcmpl-bd57c6da-4e69-4755-985b-42cf102b72bb...\n",
      "Fetching observation data for time-11-42-19-639919_chatcmpl-9da532ba-d2d5-4500-aa1d-13e34f8d32bd...\n",
      "Fetching observation data for time-11-42-25-441939_chatcmpl-e753c559-9da7-4693-935b-92fd1b117e20...\n",
      "Fetching observation data for time-11-42-32-833841_chatcmpl-f654f1f6-6a64-4000-ab67-46f2f27b167c...\n",
      "Fetching observation data for time-11-42-39-272171_chatcmpl-c7cee6ee-5b81-40a4-a73a-2a8fd51f3822...\n",
      "Fetching observation data for time-11-42-46-028516_chatcmpl-947f91bb-338d-439c-9ab7-e1f7cf13a703...\n",
      "Fetching observation data for time-11-42-57-038983_chatcmpl-c11b5d58-8b6d-4549-9b94-d22b951e1de8...\n",
      "Fetching observation data for time-11-43-08-012247_chatcmpl-4175fc8e-1c07-4e8a-bffb-22d2f88e30a0...\n",
      "Fetching observation data for time-11-43-21-389675_chatcmpl-d6ffd1e1-1729-45db-80ff-e3747cc4bb51...\n",
      "Fetching observation data for time-11-43-35-713473_chatcmpl-24fdc2fd-c4e7-4607-9991-8d00845603ba...\n",
      "Fetching observation data for time-11-40-28-196911_chatcmpl-0ea39abb-dd35-4c04-bd66-98531904caeb...\n",
      "Fetching observation data for time-11-40-34-028022_chatcmpl-3da326c3-0ddf-4633-bc2e-b41a1350032f...\n",
      "Fetching observation data for time-11-40-41-181173_chatcmpl-f310dc31-e534-46fe-aa69-56c04477f49b...\n",
      "Fetching observation data for time-11-40-47-612820_chatcmpl-2ace21d0-ec57-4ba8-88b6-689974b83913...\n",
      "Fetching observation data for time-11-40-54-358041_chatcmpl-ceb8f353-37b4-4e06-a2bc-1e5d3b624dc7...\n",
      "Fetching observation data for time-11-41-05-399356_chatcmpl-cf2c8aaf-824f-43e5-b65b-df2d0597d3dd...\n",
      "Fetching observation data for time-11-41-16-415804_chatcmpl-5f72bc44-4001-43c1-a6fc-22997c93f784...\n",
      "Fetching observation data for time-11-41-29-791352_chatcmpl-87cba7b0-6a52-47fe-a235-556e4cee3989...\n",
      "Fetching observation data for time-11-41-44-108303_chatcmpl-bfb0b50b-c194-411f-9d64-018cbeb5454e...\n",
      "Fetching observation data for time-11-38-36-713091_chatcmpl-b7b4d7fa-3a76-4e1b-a777-5a2f693c607a...\n",
      "Fetching observation data for time-11-38-42-518035_chatcmpl-4c6c1c25-9f31-427a-96ce-21bba3d30664...\n",
      "Fetching observation data for time-11-38-49-661993_chatcmpl-49e61595-da83-43b0-8d01-9d5cc61df0c4...\n",
      "Fetching observation data for time-11-38-56-125319_chatcmpl-18db21db-4f0b-4345-bb67-762d9b2963a2...\n",
      "Fetching observation data for time-11-39-02-951485_chatcmpl-72f99700-3316-442c-8bd7-cb3581e559a7...\n",
      "Fetching observation data for time-11-39-14-051347_chatcmpl-da423c3d-30eb-4d02-8818-360381088ac4...\n",
      "Fetching observation data for time-11-39-24-988686_chatcmpl-13bb35be-9b08-4a32-854c-76c05a2cb087...\n",
      "Fetching observation data for time-11-39-38-344481_chatcmpl-e45b8f53-06ee-430c-b6d2-196f03e774e8...\n",
      "Fetching observation data for time-11-39-52-653425_chatcmpl-53759e8a-4668-49e3-a8d2-d98298037c1f...\n",
      "Fetching observation data for time-11-36-45-003647_chatcmpl-d8caa48d-7ab3-4430-8ac0-30085ef11efb...\n",
      "Fetching observation data for time-11-36-50-831723_chatcmpl-2a89686b-b459-4483-a63e-ba4297cef40f...\n",
      "Fetching observation data for time-11-36-57-963515_chatcmpl-244483ba-a60f-4d90-a8fb-8f22d0cea2b4...\n",
      "Fetching observation data for time-11-37-04-381433_chatcmpl-2baa9200-3a70-42af-a79c-d8d5624085e5...\n",
      "Fetching observation data for time-11-37-11-273812_chatcmpl-4b3f90e9-2a27-4983-8225-7f504db8c6f3...\n",
      "Fetching observation data for time-11-37-22-374035_chatcmpl-d8fb56c0-2014-4d96-8916-210fe2421b31...\n",
      "Fetching observation data for time-11-37-33-321833_chatcmpl-f5eb6abd-48f5-4777-9f70-0a9a2bea65c2...\n",
      "Fetching observation data for time-11-37-46-665668_chatcmpl-aa975ef9-794e-432e-bda2-62b7d781cd10...\n",
      "Fetching observation data for time-11-38-01-046907_chatcmpl-de3666a1-3a22-4892-a541-f43e8914fe9b...\n",
      "Fetching observation data for time-11-34-52-553951_chatcmpl-01961726-d869-4358-882f-113ae41794c7...\n",
      "Fetching observation data for time-11-34-58-347744_chatcmpl-5ec52a84-0c88-45fb-84b8-7db03ebe01f6...\n",
      "Fetching observation data for time-11-35-05-482087_chatcmpl-d5b27528-4f48-40bf-b10e-a523a2d3b21e...\n",
      "Fetching observation data for time-11-35-11-983452_chatcmpl-025b71db-5d5b-497c-820b-88c6e1bbfb71...\n",
      "Fetching observation data for time-11-35-18-748206_chatcmpl-631ebb2d-a37e-449b-a3e6-87033fd080a1...\n",
      "Fetching observation data for time-11-35-29-975958_chatcmpl-6989644a-170f-4f6b-a04c-73ecbbc85208...\n",
      "Fetching observation data for time-11-35-41-040823_chatcmpl-0c14e5a9-6285-4914-8ed2-0533358143cf...\n",
      "Fetching observation data for time-11-35-54-542234_chatcmpl-49c2d55c-74eb-43e3-a790-b76ac5ad8631...\n",
      "Fetching observation data for time-11-36-08-925324_chatcmpl-a8f53a35-b52c-4779-900c-9fb4e716d89c...\n",
      "Fetching observation data for time-11-33-13-154761_chatcmpl-765c84e9-c62f-46fd-9a8a-6088e647f841...\n",
      "Fetching observation data for time-11-33-17-392763_chatcmpl-fcf46482-0c8c-4472-a9a5-a8fa483052ac...\n",
      "Fetching observation data for time-11-33-23-474645_chatcmpl-09134bb2-19e0-45ff-8def-c4052eb45063...\n",
      "Fetching observation data for time-11-33-28-650182_chatcmpl-7426d5ec-951c-4b27-97de-5a726fe1e957...\n",
      "Fetching observation data for time-11-33-34-725679_chatcmpl-4f53dad2-fd9f-4992-bdd3-d5ec47f938b8...\n",
      "Fetching observation data for time-11-33-41-458189_chatcmpl-776bf8ac-0010-4f3c-b1c8-87a8fe1038ed...\n",
      "Fetching observation data for time-11-33-52-194940_chatcmpl-e7d9d0b6-817c-48dc-9dbb-97e6447909e8...\n",
      "Fetching observation data for time-11-34-01-773289_chatcmpl-593c228c-381c-4361-bf73-5be99ee732e7...\n",
      "Fetching observation data for time-11-34-13-675092_chatcmpl-ed21e61e-a042-4619-a5ab-19b922953449...\n",
      "Fetching observation data for time-11-31-21-735879_chatcmpl-3e15ea4e-cf4c-4566-bce5-8677a31ea831...\n",
      "Fetching observation data for time-11-31-27-541098_chatcmpl-84373faa-7185-416b-9cf6-6eb9ac051841...\n",
      "Fetching observation data for time-11-31-34-666646_chatcmpl-e5f57293-283f-4cdf-8003-8ee3db78e8d3...\n",
      "Fetching observation data for time-11-31-41-131129_chatcmpl-0bddee5f-62f7-433d-b6ec-072f69c37bcb...\n",
      "Fetching observation data for time-11-31-47-874000_chatcmpl-4e76470e-87b5-45fc-bf6a-ce868f2bf50c...\n",
      "Fetching observation data for time-11-31-59-019159_chatcmpl-cb2c139c-6ae5-423c-ab8b-a4dca1554a9b...\n",
      "Fetching observation data for time-11-32-09-969052_chatcmpl-f858409a-9d38-4c65-b5d4-301a02c39d86...\n",
      "Fetching observation data for time-11-32-23-327968_chatcmpl-981c3d1a-50e6-46b8-a9a1-333b18734322...\n",
      "Fetching observation data for time-11-32-37-621719_chatcmpl-e0b6942a-8d46-41b4-a20c-b1b9aefe4b81...\n",
      "Fetching observation data for time-11-29-30-343848_chatcmpl-97472f18-0153-4558-9cbe-1bf16cc3e79b...\n",
      "Fetching observation data for time-11-29-36-168429_chatcmpl-cce2560e-98d6-49c1-8cd8-738f2da4f1db...\n",
      "Fetching observation data for time-11-29-43-300424_chatcmpl-4a805e0b-a1a6-4f28-a691-40ce02f18341...\n",
      "Fetching observation data for time-11-29-49-707703_chatcmpl-d47a8fa4-9c53-49f9-8505-463be1add29b...\n",
      "Fetching observation data for time-11-29-56-432388_chatcmpl-9606ea36-c417-48b5-9bc0-811cbe553cb2...\n",
      "Fetching observation data for time-11-30-07-421600_chatcmpl-771a52b1-5a4e-4a72-96d8-566149a65ed2...\n",
      "Fetching observation data for time-11-30-18-404183_chatcmpl-7640865c-1c8a-4a50-bb6d-1dbf2f00b12d...\n",
      "Fetching observation data for time-11-30-31-721148_chatcmpl-fbd1c6cc-358a-4d05-826f-042cf0a31b4d...\n",
      "Fetching observation data for time-11-30-46-040223_chatcmpl-244597b7-9f71-4cf2-b2c6-d5c55eb88dd0...\n",
      "Fetching observation data for time-11-27-39-024926_chatcmpl-9d503193-e7ea-45b2-a0cb-b4e40139bde9...\n",
      "Fetching observation data for time-11-27-44-813769_chatcmpl-5573d2a0-6e58-4b09-b9e9-c8448f6f6a57...\n",
      "Fetching observation data for time-11-27-51-942067_chatcmpl-be7f2c8c-0a07-4695-b128-fc2ab690a393...\n",
      "Fetching observation data for time-11-27-58-358298_chatcmpl-e029bb1a-40a4-4887-b850-0a74b816d619...\n",
      "Fetching observation data for time-11-28-05-079670_chatcmpl-70bbdc96-76eb-4b1a-a7bc-ad740b5ea4a9...\n",
      "Fetching observation data for time-11-28-16-101804_chatcmpl-6b20c8e0-1de1-442f-9ccd-05b0f7253bce...\n",
      "Fetching observation data for time-11-28-27-043146_chatcmpl-02eaa94e-41c1-44f9-a31f-fe29f15ba2e3...\n",
      "Fetching observation data for time-11-28-40-397158_chatcmpl-0633343b-d1be-458f-8154-3c9d15d517aa...\n",
      "Fetching observation data for time-11-28-54-713521_chatcmpl-415a6427-56e9-4ac9-b6ac-cfda41a894c8...\n",
      "Fetching observation data for time-11-25-47-567616_chatcmpl-333c30a2-9d82-4a3b-a0fe-5618930ff1c0...\n",
      "Fetching observation data for time-11-25-53-376845_chatcmpl-4e4ac856-8d49-4dff-8a5f-d79237b67842...\n",
      "Fetching observation data for time-11-26-00-522623_chatcmpl-63bda716-5e63-4240-8fbf-7ccdc264d6cd...\n",
      "Fetching observation data for time-11-26-06-947464_chatcmpl-528a76af-27d1-4522-a8d0-f97d4bde1542...\n",
      "Fetching observation data for time-11-26-13-880481_chatcmpl-b0990a03-6c83-4406-b12a-442139b8c66b...\n",
      "Fetching observation data for time-11-26-24-906070_chatcmpl-f666f8d2-77d7-448e-bf7f-2cc47bb44802...\n",
      "Fetching observation data for time-11-26-35-875822_chatcmpl-08df87a2-632d-4a37-aa59-746a4d53531a...\n",
      "Fetching observation data for time-11-26-49-241422_chatcmpl-a56d961c-f265-4c79-b1c6-7074d19ef406...\n",
      "Fetching observation data for time-11-27-03-533086_chatcmpl-30c54880-a0c5-45f6-a1e4-e0431eafe942...\n",
      "Fetching observation data for time-11-23-54-869293_chatcmpl-537e38cb-8f0e-4478-98a7-c26d94b99f35...\n",
      "Fetching observation data for time-11-24-00-664774_chatcmpl-945fb115-75c3-42a7-8d6f-4dc984c7bc97...\n",
      "Fetching observation data for time-11-24-07-796636_chatcmpl-287fd570-0f0c-4245-aa17-b0040791a4ec...\n",
      "Fetching observation data for time-11-24-14-210788_chatcmpl-f743328d-0b7d-491f-b9d8-2ac24a75400a...\n",
      "Fetching observation data for time-11-24-20-943264_chatcmpl-35133405-04fa-4f82-b00e-d56da148e502...\n",
      "Fetching observation data for time-11-24-31-936426_chatcmpl-cc41ef07-0be6-45e2-80f0-243b181241a6...\n",
      "Fetching observation data for time-11-24-42-889787_chatcmpl-bb828566-04e8-4072-9def-4c7ce0504a20...\n",
      "Fetching observation data for time-11-24-56-757433_chatcmpl-b8d75b0f-88ab-4283-ba89-0518cf5ec8e8...\n",
      "Fetching observation data for time-11-25-11-388096_chatcmpl-0134332c-1505-45af-8799-9450f9d139a7...\n",
      "Fetching observation data for time-11-22-03-228905_chatcmpl-2cb5b5d8-03f2-46ea-bed2-c573454856a7...\n",
      "Fetching observation data for time-11-22-09-152677_chatcmpl-44bc4589-8fa1-4a1f-92bc-c9f9fa57814c...\n",
      "Fetching observation data for time-11-22-16-283110_chatcmpl-81043219-a967-4713-8fc8-6a703f8ecc04...\n",
      "Fetching observation data for time-11-22-22-711647_chatcmpl-20673447-b8ac-471f-819f-63da3502898f...\n",
      "Fetching observation data for time-11-22-29-445707_chatcmpl-d9bf7a96-b8c1-4a3d-a0fe-6e5eadda8cac...\n",
      "Fetching observation data for time-11-22-40-438588_chatcmpl-384ec37f-e339-4649-85af-2304553fdb87...\n",
      "Fetching observation data for time-11-22-51-435159_chatcmpl-97cb8f6d-828c-433d-bc3b-a7b77e1c3d28...\n",
      "Fetching observation data for time-11-23-04-800641_chatcmpl-46013fa2-f69e-4839-b7c0-50882b0292a1...\n",
      "Fetching observation data for time-11-23-19-100529_chatcmpl-078a8666-7258-4e7b-8df1-dd8d2953e7d1...\n",
      "Fetching observation data for time-11-20-11-776740_chatcmpl-01c0af98-9688-4782-a869-91e85cfad872...\n",
      "Fetching observation data for time-11-20-17-572734_chatcmpl-50184145-fd02-4f97-8974-e804853c3ca6...\n",
      "Fetching observation data for time-11-20-24-707602_chatcmpl-29288e4c-76a9-45f4-8109-d1adb5d74124...\n",
      "Fetching observation data for time-11-20-31-133250_chatcmpl-d40dc61b-7484-4a2c-b5f7-d8e1176baecb...\n",
      "Fetching observation data for time-11-20-37-887753_chatcmpl-b842718f-936c-4386-97e3-f44d377e0df8...\n",
      "Fetching observation data for time-11-20-48-897020_chatcmpl-732db558-32d5-4d0d-8a6b-1d384f0e9e51...\n",
      "Fetching observation data for time-11-20-59-872726_chatcmpl-70579ccd-01a3-45fd-9f73-c284fbbe875c...\n",
      "Fetching observation data for time-11-21-13-227055_chatcmpl-27c42169-692d-42e7-ae64-0a43fe31bb78...\n",
      "Fetching observation data for time-11-21-27-542875_chatcmpl-d7f4adee-197f-4209-821b-f8f5ba03cb81...\n",
      "Fetching observation data for time-11-18-20-313735_chatcmpl-cb373061-e699-46c6-9e26-eb7431ceb5e1...\n",
      "Fetching observation data for time-11-18-26-126415_chatcmpl-e313d1f1-b247-4616-ab58-48d0d99f2ba3...\n",
      "Fetching observation data for time-11-18-33-258447_chatcmpl-1a58d0f6-2f70-4ac4-ae38-afda66e34807...\n",
      "Fetching observation data for time-11-18-39-717648_chatcmpl-baa675d0-185e-4bb7-8acd-8e07f3db979c...\n",
      "Fetching observation data for time-11-18-46-534325_chatcmpl-320b0bfc-0881-400a-9aee-7381e7a64a48...\n",
      "Fetching observation data for time-11-18-57-612539_chatcmpl-33746f17-bf8f-4534-917c-76ef68f6cc6f...\n",
      "Fetching observation data for time-11-19-08-664843_chatcmpl-c00ad91b-8aee-4153-8ec1-de45583dd77c...\n",
      "Fetching observation data for time-11-19-22-005719_chatcmpl-8202996c-c929-4435-9124-1211cd8b2676...\n",
      "Fetching observation data for time-11-19-36-310877_chatcmpl-81495c1e-fdb1-4236-9e51-a86a7051dce8...\n",
      "Fetching observation data for time-11-16-40-732721_chatcmpl-b81fa0bb-23ba-41da-8c83-847ae34813b0...\n",
      "Fetching observation data for time-11-16-45-120271_chatcmpl-abed193c-1e49-4418-962b-c8d68f9a8c93...\n",
      "Fetching observation data for time-11-16-51-204937_chatcmpl-64484fab-4234-413a-8aec-78e9becbb5df...\n",
      "Fetching observation data for time-11-16-56-365192_chatcmpl-528076eb-5675-4d6d-97d1-ae177c0ae104...\n",
      "Fetching observation data for time-11-17-02-410950_chatcmpl-8f8d5192-9316-4117-8c39-811f5571c1b4...\n",
      "Fetching observation data for time-11-17-09-127455_chatcmpl-6117205c-e8aa-4504-acff-ba96f03fc983...\n",
      "Fetching observation data for time-11-17-19-856830_chatcmpl-357d6f6d-4970-436b-ba45-43dce526b59d...\n",
      "Fetching observation data for time-11-17-29-448308_chatcmpl-08f3c3cb-18ae-4f82-8689-6bea02b41a30...\n",
      "Fetching observation data for time-11-17-41-276651_chatcmpl-a6b9d572-c8dd-49d4-bb18-3f257d21c587...\n",
      "Fetching observation data for time-11-14-49-277997_chatcmpl-2bd3a6e6-67a5-4070-8e50-78d592de307f...\n",
      "Fetching observation data for time-11-14-55-101131_chatcmpl-1160a450-2b13-4f2c-bc77-7691e939cf7f...\n",
      "Fetching observation data for time-11-15-02-238190_chatcmpl-51856ce0-4245-4347-a85c-5c2895e6789b...\n",
      "Fetching observation data for time-11-15-08-676272_chatcmpl-22948803-6cbc-476b-b267-e2c8e237c1b5...\n",
      "Fetching observation data for time-11-15-15-427539_chatcmpl-2ad11aa9-0020-45b9-ab07-274b48531a5f...\n",
      "Fetching observation data for time-11-15-26-454439_chatcmpl-7c5cc205-7910-4a8f-9476-a8d01006f58e...\n",
      "Fetching observation data for time-11-15-37-415717_chatcmpl-fffb5e0a-46e7-48b0-a5d8-05cbc7848af3...\n",
      "Fetching observation data for time-11-15-50-775023_chatcmpl-95fa6dd6-434e-4df9-b1c0-99cb4be7315b...\n",
      "Fetching observation data for time-11-16-05-086231_chatcmpl-9f421501-8f84-450c-9c1b-5c3451a8ef0a...\n",
      "Fetching observation data for time-11-13-09-798337_chatcmpl-d2d333d3-6fd8-426d-aaba-d158fc3f41f6...\n",
      "Fetching observation data for time-11-13-14-031830_chatcmpl-8a795918-1133-4487-8d03-3e98199b98f1...\n",
      "Fetching observation data for time-11-13-20-155633_chatcmpl-7d8455a7-308c-43cb-a0a1-4da394602e2b...\n",
      "Fetching observation data for time-11-13-25-321519_chatcmpl-15f5f2e0-29f4-4325-93c4-3ddc56b7ced9...\n",
      "Fetching observation data for time-11-13-31-368717_chatcmpl-558534cc-8ccc-46e9-bae7-461e4fabc146...\n",
      "Fetching observation data for time-11-13-38-078480_chatcmpl-14a0576f-153c-476b-8e5a-023c4cfd5e60...\n",
      "Fetching observation data for time-11-13-48-816662_chatcmpl-62ff8ca4-1219-4c5b-8842-971bf72b8ae0...\n",
      "Fetching observation data for time-11-13-58-430372_chatcmpl-020f1bd1-977f-4144-936f-566e07ba262f...\n",
      "Fetching observation data for time-11-14-10-269759_chatcmpl-ceb32af6-23ad-48d0-98b0-2a323f890d69...\n",
      "Fetching observation data for time-11-11-17-396393_chatcmpl-e6df9bdb-1403-4fb7-b5f1-66e1ff628b67...\n",
      "Fetching observation data for time-11-11-24-132799_chatcmpl-75fbbd85-4a6c-49ab-a4c8-d29f3940d156...\n",
      "Fetching observation data for time-11-11-31-270982_chatcmpl-94bf7703-9bc5-4c5f-b6f2-350eae255f53...\n",
      "Fetching observation data for time-11-11-37-692637_chatcmpl-d7b806f1-4f06-40db-87cb-9060bda1bd23...\n",
      "Fetching observation data for time-11-11-44-448231_chatcmpl-32993053-3505-4fa4-b34a-58c72708e565...\n",
      "Fetching observation data for time-11-11-55-466597_chatcmpl-ed6d9a28-6c7f-4f51-881e-8a623ec35c0e...\n",
      "Fetching observation data for time-11-12-06-413195_chatcmpl-3c376a46-1c11-4499-9310-944a06299394...\n",
      "Fetching observation data for time-11-12-19-759234_chatcmpl-abfdc86e-c465-4d10-a737-c88cbd0c5b71...\n",
      "Fetching observation data for time-11-12-34-051175_chatcmpl-1496c0e9-65b8-4179-a35c-33a7413224ad...\n",
      "Fetching observation data for time-11-09-25-010909_chatcmpl-58f45c97-34d4-4b73-971b-861944a680aa...\n",
      "Fetching observation data for time-11-09-31-126807_chatcmpl-d1ea2fbd-af3f-4853-b88f-0c7e5eb0e7cc...\n",
      "Fetching observation data for time-11-09-38-391115_chatcmpl-9f8dbfd3-c31e-4bb6-ac3c-b66ff9a68f6e...\n",
      "Fetching observation data for time-11-09-44-804105_chatcmpl-72081220-3557-4ecc-98ae-7088e9f2c926...\n",
      "Fetching observation data for time-11-09-51-536962_chatcmpl-f625e1d9-9e8b-4cb2-9c4a-d9d475fb3d29...\n",
      "Fetching observation data for time-11-10-03-189219_chatcmpl-00032eb0-4311-49a0-8eb1-6fc86feba95f...\n",
      "Fetching observation data for time-11-10-14-236608_chatcmpl-00bef9bb-46df-4987-af36-9f8c5545c8eb...\n",
      "Fetching observation data for time-11-10-27-586083_chatcmpl-6e7a022b-4b00-4d5a-86ad-f47cd0d88982...\n",
      "Fetching observation data for time-11-10-41-883930_chatcmpl-8ed6c90e-8657-4cf5-8ccc-85346b6ae246...\n",
      "Fetching observation data for time-11-07-33-374382_chatcmpl-e550a2ac-ad11-4543-8b60-01ca4cee61b8...\n",
      "Fetching observation data for time-11-07-39-190548_chatcmpl-af8ef5f9-500d-4c96-88ba-6dc955315ece...\n",
      "Fetching observation data for time-11-07-46-326965_chatcmpl-6f1d31e6-31d3-4f23-ad76-82711c2e3bb9...\n",
      "Fetching observation data for time-11-07-52-815388_chatcmpl-5ba418be-2d8b-404c-9456-41a191252a17...\n",
      "Fetching observation data for time-11-07-59-582656_chatcmpl-0047b7ac-3f2c-48a4-b6c2-16947885efdd...\n",
      "Fetching observation data for time-11-08-10-583373_chatcmpl-0cb5287f-3300-4e39-9aff-52f263016564...\n",
      "Fetching observation data for time-11-08-21-537593_chatcmpl-96cfc27c-a032-4956-8986-624e82ffd386...\n",
      "Fetching observation data for time-11-08-34-875614_chatcmpl-d9af1df4-fa20-4cee-8dc9-38189c7306f0...\n",
      "Fetching observation data for time-11-08-49-173969_chatcmpl-7471bc9d-a468-4fb7-a588-a646e4e6bdf6...\n",
      "Fetching observation data for time-11-05-41-704714_chatcmpl-7ef18e2e-f4e0-4f0f-ae71-49313051cead...\n",
      "Fetching observation data for time-11-05-47-511736_chatcmpl-13fb8f4c-b6b8-4d87-9ab7-0ae823efda01...\n",
      "Fetching observation data for time-11-05-54-638033_chatcmpl-5fb32e6b-2047-488f-ba40-25386fa0de39...\n",
      "Fetching observation data for time-11-06-01-065180_chatcmpl-4125b2d8-11eb-437f-bc3d-4fb2b3da8f00...\n",
      "Fetching observation data for time-11-06-07-805866_chatcmpl-dc8386cb-fa1d-45d7-a849-d640fc20a0a4...\n",
      "Fetching observation data for time-11-06-18-820082_chatcmpl-533b899c-8884-4408-bbc8-45dd3f39b741...\n",
      "Fetching observation data for time-11-06-29-771808_chatcmpl-8689c36b-16b9-4d6d-957f-7310d92b3ade...\n",
      "Fetching observation data for time-11-06-43-138675_chatcmpl-561a6825-dfe5-4f10-aada-6eee16251fec...\n",
      "Fetching observation data for time-11-06-57-441228_chatcmpl-ca7be83a-36f2-4a71-8c3c-0de5edb2fe33...\n",
      "Fetching observation data for time-11-03-50-295671_chatcmpl-fad4fbdc-5a5a-4ff3-8882-bef431ec44d0...\n",
      "Fetching observation data for time-11-03-56-097841_chatcmpl-e70c5fc2-ed8a-4062-acc8-e474afcfa458...\n",
      "Fetching observation data for time-11-04-03-257539_chatcmpl-22820ce9-939e-47ce-8693-1b84947a9e34...\n",
      "Fetching observation data for time-11-04-09-694627_chatcmpl-f49c9279-ad87-4dbb-873c-789470b95883...\n",
      "Fetching observation data for time-11-04-16-523310_chatcmpl-3f745b7b-4761-4645-b748-12869f17a071...\n",
      "Fetching observation data for time-11-04-27-525428_chatcmpl-6b2476d3-316e-4e2e-97fe-35f3fda0c5de...\n",
      "Fetching observation data for time-11-04-38-495684_chatcmpl-6a5aaf70-d968-4d96-8573-bf46d674d267...\n",
      "Fetching observation data for time-11-04-51-855215_chatcmpl-52162874-09e7-400b-ac0e-224022210b28...\n",
      "Fetching observation data for time-11-05-06-164630_chatcmpl-e2b70af5-a4da-4a22-af84-3cc6ea3f02bf...\n",
      "Fetching observation data for time-11-01-58-801814_chatcmpl-bdd09421-6b31-489e-af3c-dfeb56cee456...\n",
      "Fetching observation data for time-11-02-04-601525_chatcmpl-05f3b1dc-c860-4286-86ee-07df344999e8...\n",
      "Fetching observation data for time-11-02-11-737644_chatcmpl-e84b0269-834d-4be4-b386-79ac174b3639...\n",
      "Fetching observation data for time-11-02-18-156290_chatcmpl-ae8ccc8a-f759-4eaf-9388-2e911a734c78...\n",
      "Fetching observation data for time-11-02-24-929946_chatcmpl-ca085ab9-bc83-45da-94c7-30c005a39684...\n",
      "Fetching observation data for time-11-02-35-942595_chatcmpl-8776a49c-2f6e-430d-a671-c1ed1d8f058a...\n",
      "Fetching observation data for time-11-02-46-894216_chatcmpl-d7e9a10c-56ef-4c56-9a3e-e74e552a226b...\n",
      "Fetching observation data for time-11-03-00-258482_chatcmpl-270c20d2-9d9f-491a-bfa6-f09b49303bac...\n",
      "Fetching observation data for time-11-03-14-557742_chatcmpl-6007fc79-296f-44ab-9b72-5ad606a5f9d6...\n",
      "Fetching observation data for time-11-00-07-441512_chatcmpl-d21f700c-48e9-41e3-b628-1e93f9930aa6...\n",
      "Fetching observation data for time-11-00-13-277233_chatcmpl-f97662c6-3ecf-4373-8665-41d02ff63cd8...\n",
      "Fetching observation data for time-11-00-20-458111_chatcmpl-593e88d8-1d93-4214-a1ad-35e2ed36020b...\n",
      "Fetching observation data for time-11-00-26-883730_chatcmpl-7c97eb69-e6b7-413e-a007-2b870685c77a...\n",
      "Fetching observation data for time-11-00-33-627601_chatcmpl-fd4f0f3b-60c7-4652-afde-d5bcf02e9ff2...\n",
      "Fetching observation data for time-11-00-44-655585_chatcmpl-30963b8e-59b9-4f18-aa54-55d044dfbb92...\n",
      "Fetching observation data for time-11-00-55-624908_chatcmpl-412d5fd9-807c-45a5-9624-6dcf5bc79e85...\n",
      "Fetching observation data for time-11-01-08-985966_chatcmpl-25368f7a-2f70-49ed-a16d-575365b8ae20...\n",
      "Fetching observation data for time-11-01-23-305805_chatcmpl-cd3315bb-44aa-4d42-b26a-9da66a32e664...\n",
      "Fetching observation data for time-10-58-15-038718_chatcmpl-1d518c84-9fb7-48df-b99d-d18191e388e3...\n",
      "Fetching observation data for time-10-58-20-826811_chatcmpl-848107be-3d63-4fb4-b078-e9ff82aa2e83...\n",
      "Fetching observation data for time-10-58-27-978297_chatcmpl-aee49f4d-1f5d-4a0e-a443-da981be0ad59...\n",
      "Fetching observation data for time-10-58-34-458653_chatcmpl-ad1be7ce-cdf7-4277-8aea-0d0abd85b48b...\n",
      "Fetching observation data for time-10-58-41-215188_chatcmpl-d15dc448-eedd-4e99-8d57-228b778b50ae...\n",
      "Fetching observation data for time-10-58-52-243327_chatcmpl-94623032-7995-44ac-9250-72819719f5ae...\n",
      "Fetching observation data for time-10-59-03-225468_chatcmpl-9f88913a-d0e4-430f-8680-15cec4017b91...\n",
      "Fetching observation data for time-10-59-16-605564_chatcmpl-ba8bff82-5981-4cf2-aa0e-a0d42c8aeb0c...\n",
      "Fetching observation data for time-10-59-30-924945_chatcmpl-5e409244-2aad-40ef-a847-39c7644adfa4...\n",
      "Fetching observation data for time-10-55-45-636290_chatcmpl-12c6551f-9f91-4304-933c-ef25053f0546...\n",
      "Fetching observation data for time-10-56-27-668068_chatcmpl-55b0c9df-abe0-4721-b573-484a550d7ed8...\n",
      "Fetching observation data for time-10-56-34-864201_chatcmpl-48c50815-3578-472e-b893-3388ba5f9bc4...\n",
      "Fetching observation data for time-10-56-41-211958_chatcmpl-eae8ad6f-9b37-4a65-bac8-4ef58a7feb8a...\n",
      "Fetching observation data for time-10-56-51-213616_chatcmpl-783796b3-0c85-4133-b3c4-0a60a47a14a8...\n",
      "Fetching observation data for time-10-57-03-468955_chatcmpl-775b8f6a-72c5-4bec-a3db-18a9724fcc1d...\n",
      "Fetching observation data for time-10-57-13-494252_chatcmpl-fd6db489-f6d7-43e8-8a32-dbfeccad8a67...\n",
      "Fetching observation data for time-10-57-24-615632_chatcmpl-e7d47420-bd79-4952-9854-ca7a5b7dfdf7...\n",
      "Fetching observation data for time-10-57-37-469541_chatcmpl-f7ea9b18-f884-48f6-a5cc-5d1e3b938e92...\n",
      "Raw JSON saved to: /home/han/Projects/reference-benchmark-tinyml_llm/data_analysis/2025/11.03/raw_export/raw_qwen2.5-coder:32b_bf8c_dp_batch.json\n"
     ]
    }
   ],
   "source": [
    "# ALTERNATIVE TO 2.\n",
    "import os\n",
    "import json\n",
    "from time import sleep\n",
    "from langfuse import Langfuse\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "\n",
    "# LANGFUSE_SERVICE_PUBLIC_KEY = \"pk-lf-559a2c0f-ee29-4c32-944c-bf73b5f0ce28\"\n",
    "# LANGFUSE_SERVICE_SECRET_KEY = \"sk-lf-75f8bf7f-a5db-4756-b0dd-d758a2a292c8\"\n",
    "# LANGFUSE_SERVICE_HOST = \"https://langfuse.hann.fi\"\n",
    "\n",
    "\n",
    "if LOCAL_HOST:\n",
    "    langfuse = Langfuse(\n",
    "        secret_key=\"sk-lf-75f8bf7f-a5db-4756-b0dd-d758a2a292c8\",\n",
    "        public_key=\"pk-lf-559a2c0f-ee29-4c32-944c-bf73b5f0ce28\",\n",
    "        host=\"https://langfuse.hann.fi\",\n",
    "    )\n",
    "else:\n",
    "    langfuse = Langfuse(\n",
    "        secret_key=LANGFUSE_SERVICE_SECRET_KEY,\n",
    "        public_key=LANGFUSE_SERVICE_PUBLIC_KEY,\n",
    "        host=LANGFUSE_SERVICE_HOST,\n",
    "    )\n",
    "\n",
    "API_invok_count = 0\n",
    "query_range_num_run = {\"start\": 0, \"end\": 1}\n",
    "\n",
    "\n",
    "class CustomJSONEncoder(json.JSONEncoder):\n",
    "    def __init__(self, *args, LOCAL_HOST=True, **kwargs):\n",
    "        self.LOCAL_HOST = LOCAL_HOST\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "    def default(self, obj):\n",
    "        if isinstance(obj, datetime):\n",
    "            return obj.isoformat()\n",
    "        if hasattr(obj, \"__dict__\"):\n",
    "            data = obj.__dict__.copy()\n",
    "            if \"observations\" in data:\n",
    "                data[\"observations\"] = [\n",
    "                    fetch_observation_data(obs, self.LOCAL_HOST)\n",
    "                    for obs in data[\"observations\"]\n",
    "                ]\n",
    "\n",
    "            return data\n",
    "        return super().default(obj)\n",
    "\n",
    "\n",
    "def fetch_observation_data(observation_id, LOCAL_HOST):\n",
    "    \"\"\"\n",
    "    Fetches observation data from Langfuse and returns its dictionary representation.\n",
    "    \"\"\"\n",
    "    print(f\"Fetching observation data for {observation_id}...\")\n",
    "    global API_invok_count\n",
    "    if API_invok_count >= 0 and not LOCAL_HOST:\n",
    "        print(\"Waiting for 3 seconds to fetch observation data...\")\n",
    "        for _ in tqdm(range(3), desc=\"Progress\", unit=\"s\"):\n",
    "            sleep(1)\n",
    "        API_invok_count = 0\n",
    "\n",
    "    observation_response = langfuse.fetch_observation(observation_id)\n",
    "    API_invok_count += 1\n",
    "\n",
    "    return observation_response.data.dict()\n",
    "\n",
    "\n",
    "def fetch_and_save_complete_data(session_id_list, raw_export_dir, LOCAL_HOST):\n",
    "    \"\"\"\n",
    "    Fetches complete trace data for each session ID and saves it to JSON files.\n",
    "\n",
    "    Parameters:\n",
    "        session_id_list (list): List of session IDs to process.\n",
    "        raw_export_dir (str): Directory path to save raw JSON files.\n",
    "    \"\"\"\n",
    "\n",
    "    def save_complete_data(session_id):\n",
    "        global API_invok_count\n",
    "        if API_invok_count >= 0 and not LOCAL_HOST:\n",
    "            print(\"Waiting for 4 seconds to fetch traces...\")\n",
    "            for _ in tqdm(range(4), desc=\"Progress\", unit=\"s\"):\n",
    "                sleep(1)\n",
    "            API_invok_count = 0\n",
    "\n",
    "        fetch_traces_response = langfuse.fetch_traces(session_id=session_id)\n",
    "        API_invok_count += 1\n",
    "\n",
    "        print(f\"Fetching traces for session {session_id}...\")\n",
    "        # Create directories if they don't exist\n",
    "        os.makedirs(raw_export_dir, exist_ok=True)\n",
    "\n",
    "        # Save complete data to JSON file\n",
    "        # if session_id.startswith(\"da0a\"):\n",
    "        #     session_id = \"phi4_\" + session_id\n",
    "        if \"tpsg\" in session_id:\n",
    "            session_id_ = session_id.replace(\"tpsg\", \"tpusg\")\n",
    "        else:\n",
    "            session_id_ = session_id\n",
    "            \n",
    "        raw_path = os.path.join(raw_export_dir, f\"raw_{session_id_}.json\")\n",
    "        with open(raw_path, \"w\") as f:\n",
    "            json.dump(fetch_traces_response, f, cls=CustomJSONEncoder, indent=2)\n",
    "\n",
    "        print(f\"Raw JSON saved to: {raw_path}\")\n",
    "\n",
    "    for session_id in session_id_list:\n",
    "        save_complete_data(session_id)\n",
    "\n",
    "\n",
    "fetch_and_save_complete_data(session_id_list, raw_export_dir, LOCAL_HOST)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Trim data\n",
    "\n",
    "Here also intercept the runs with fatal errors that need to be excluded from the analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully processed and saved trimmed data for session qwen2.5-coder:32b_bf8c_dp_batch\n",
      "Total 0 traces skipped. They are []\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "skipped_traces = []\n",
    "\n",
    "\n",
    "def process_existing_observation(observation):\n",
    "    \"\"\"\n",
    "    Processes an existing observation dictionary by trimming unwanted keys.\n",
    "    \"\"\"\n",
    "    unwanted_observation_keys = [\n",
    "        \"completionStartTime\",\n",
    "        \"metadata\",\n",
    "        \"timeToFirstToken\",\n",
    "        \"createdAt\",\n",
    "        \"usageDetails\",\n",
    "        \"usage\",\n",
    "        \"projectId\",\n",
    "        \"unit\",\n",
    "        \"updatedAt\",\n",
    "        \"version\",\n",
    "        \"parentObservationId\",\n",
    "        \"promptId\",\n",
    "        \"promptName\",\n",
    "        \"promptVersion\",\n",
    "        \"modelId\",\n",
    "        \"inputPrice\",\n",
    "        \"outputPrice\",\n",
    "        \"totalPrice\",\n",
    "        # \"modelParameters\",\n",
    "        \"input\",\n",
    "        \"output\",\n",
    "    ]\n",
    "\n",
    "    # If observation is a dictionary containing observation data\n",
    "    if isinstance(observation, dict):\n",
    "        trimmed_observation = {\n",
    "            k: v for k, v in observation.items() if k not in unwanted_observation_keys\n",
    "        }\n",
    "        return trimmed_observation\n",
    "    return observation\n",
    "\n",
    "\n",
    "def trim_data(data):\n",
    "    \"\"\"\n",
    "    Recursively trims the data structure.\n",
    "    \"\"\"\n",
    "\n",
    "    if isinstance(data, dict):\n",
    "        # Process the current dictionary\n",
    "        unwanted_trace_keys = [\n",
    "            \"release\",\n",
    "            \"version\",\n",
    "            \"user_id\",\n",
    "            \"public\",\n",
    "            \"html_path\",\n",
    "            \"scores\",\n",
    "            \"bookmarked\",\n",
    "            \"projectId\",\n",
    "            \"externalId\",\n",
    "            \"page\",\n",
    "            \"limit\",\n",
    "            \"total_pages\",\n",
    "        ]\n",
    "\n",
    "        # If this is a trace that contains observations, check for fatal errors\n",
    "        if \"observations\" in data:\n",
    "            # Check for SPAN observations with fatal errors before processing\n",
    "            skip_trace = False\n",
    "            for obs in data[\"observations\"]:\n",
    "                if isinstance(obs, dict) and obs.get(\"name\").startswith(\"error\"):\n",
    "                    status_message = obs.get(\"statusMessage\", \"\")\n",
    "                    ob_name = obs.get(\"name\")\n",
    "                    print(f\"SPAN {ob_name}: {status_message}\")\n",
    "\n",
    "                    if \"Fatal error\" in status_message:\n",
    "                        print(f\"Found Fatal error in SPAN observation, skipping trace\")\n",
    "                        skip_trace = True\n",
    "                        skipped_traces.append(data[\"name\"])\n",
    "                        break\n",
    "\n",
    "            if skip_trace:\n",
    "                return None  # Signal to skip this trace\n",
    "\n",
    "        # Create a new dictionary with wanted keys and recursively process values\n",
    "        trimmed_data = {}\n",
    "        for key, value in data.items():\n",
    "            if key not in unwanted_trace_keys:\n",
    "                if key == \"observations\":\n",
    "                    # Special handling for observations\n",
    "                    trimmed_data[key] = [\n",
    "                        process_existing_observation(obs) for obs in value\n",
    "                    ]\n",
    "                elif isinstance(value, (dict, list)):\n",
    "                    # Recursively process nested structures\n",
    "                    trimmed_data[key] = trim_data(value)\n",
    "                else:\n",
    "                    trimmed_data[key] = value\n",
    "\n",
    "        return trimmed_data\n",
    "\n",
    "    elif isinstance(data, list):\n",
    "        # Recursively process each item in the list\n",
    "        processed_items = []\n",
    "        for item in data:\n",
    "            processed_item = trim_data(item)\n",
    "            if processed_item is not None:  # Only add items that weren't filtered out\n",
    "                processed_items.append(processed_item)\n",
    "        return processed_items\n",
    "\n",
    "    else:\n",
    "        # Return non-dict, non-list values as is\n",
    "        return data\n",
    "\n",
    "\n",
    "def read_and_trim_data(session_id_list, raw_export_dir, trimmed_export_dir):\n",
    "    \"\"\"\n",
    "    Reads complete data from JSON files, trims the data, and saves the trimmed data to new JSON files.\n",
    "    \"\"\"\n",
    "    os.makedirs(trimmed_export_dir, exist_ok=True)\n",
    "\n",
    "    for session_id in session_id_list:\n",
    "        try:\n",
    "            if session_id.startswith(\"da0a\"):\n",
    "                session_id = \"phi4_\" + session_id\n",
    "            # Read raw data\n",
    "            if \"tpsg\" in session_id:\n",
    "                session_id_ = session_id.replace(\"tpsg\", \"tpusg\")\n",
    "            else:\n",
    "                session_id_ = session_id\n",
    "            raw_path = os.path.join(raw_export_dir, f\"raw_{session_id_}.json\")\n",
    "            with open(raw_path, \"r\") as f:\n",
    "                data = json.load(f)\n",
    "\n",
    "            # Process and trim the data\n",
    "            trimmed_data = trim_data(data)\n",
    "\n",
    "            # If the entire data was filtered out (unlikely but possible)\n",
    "            if trimmed_data is None:\n",
    "                print(\n",
    "                    f\"All traces in session {session_id} were filtered due to fatal errors\"\n",
    "                )\n",
    "                continue\n",
    "\n",
    "            # Save trimmed data\n",
    "            if \"tpsg\" in session_id:\n",
    "                session_id_ = session_id.replace(\"tpsg\", \"tpusg\")\n",
    "            else:\n",
    "                session_id_ = session_id\n",
    "            trimmed_path = os.path.join(\n",
    "                trimmed_export_dir, f\"trimmed_{session_id_}.json\"\n",
    "            )\n",
    "            with open(trimmed_path, \"w\") as f:\n",
    "                json.dump(trimmed_data, f, indent=2)\n",
    "\n",
    "            print(\n",
    "                f\"Successfully processed and saved trimmed data for session {session_id}\"\n",
    "            )\n",
    "\n",
    "            # Optional: Verify trimming worked\n",
    "            # print(f\"Verifying trimmed data for session {session_id}...\")\n",
    "            # verify_trimming(trimmed_path)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing session {session_id}: {str(e)}\")\n",
    "\n",
    "\n",
    "def verify_trimming(trimmed_path):\n",
    "    \"\"\"\n",
    "    Verifies that the trimmed data doesn't contain unwanted keys.\n",
    "    \"\"\"\n",
    "    with open(trimmed_path, \"r\") as f:\n",
    "        trimmed_data = json.load(f)\n",
    "\n",
    "    unwanted_keys = [\n",
    "        \"release\",\n",
    "        \"version\",\n",
    "        \"user_id\",\n",
    "        \"public\",\n",
    "        \"html_path\",\n",
    "        \"scores\",\n",
    "        \"bookmarked\",\n",
    "        \"projectId\",\n",
    "        \"externalId\",\n",
    "        \"page\",\n",
    "        \"limit\",\n",
    "        \"total_pages\",\n",
    "        \"completionStartTime\",\n",
    "        \"metadata\",\n",
    "        \"usageDetails\",\n",
    "        \"timeToFirstToken\",\n",
    "        \"createdAt\",\n",
    "        \"completionTokens\",\n",
    "        \"promptTokens\",\n",
    "        \"projectId\",\n",
    "        \"unit\",\n",
    "        \"updatedAt\",\n",
    "        \"version\",\n",
    "        # \"statusMessage\",\n",
    "        \"parentObservationId\",\n",
    "        \"promptId\",\n",
    "        \"promptName\",\n",
    "        \"promptVersion\",\n",
    "        \"modelId\",\n",
    "        \"inputPrice\",\n",
    "        \"outputPrice\",\n",
    "        \"totalPrice\",\n",
    "        \"calculatedInputCost\",\n",
    "        \"calculatedOutputCost\",\n",
    "        \"calculatedTotalCost\",\n",
    "    ]\n",
    "\n",
    "    def check_keys(obj):\n",
    "        if isinstance(obj, dict):\n",
    "            for key in obj.keys():\n",
    "                if key in unwanted_keys:\n",
    "                    print(f\"Warning: Found unwanted key '{key}' in trimmed data\")\n",
    "            for value in obj.values():\n",
    "                check_keys(value)\n",
    "        elif isinstance(obj, list):\n",
    "            for item in obj:\n",
    "                check_keys(item)\n",
    "\n",
    "    check_keys(trimmed_data)\n",
    "    print(\"Verification complete\")\n",
    "\n",
    "\n",
    "# Usage example:\n",
    "read_and_trim_data(session_id_list, raw_export_dir, raw_export_dir)\n",
    "print(f\"Total {len(skipped_traces)} traces skipped. They are {skipped_traces}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Generate CSV files from JSON\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing session qwen2.5-coder:32b_bf8c_dp_batch, simple id qwen2.5-coder:32b_bf8c. Look for /home/han/Projects/reference-benchmark-tinyml_llm/data_analysis/2025/11.03/raw_export/trimmed_qwen2.5-coder:32b_bf8c_dp_batch.json\n",
      "/home/han/Projects/reference-benchmark-tinyml_llm/data_analysis/2025/11.03/processed_data/qwen2.5-coder:32b_bf8c/clean_qwen2.5-coder:32b_bf8c_dp_batch.csv\n",
      "Successfully saved CSV to: /home/han/Projects/reference-benchmark-tinyml_llm/data_analysis/2025/11.03/processed_data/qwen2.5-coder:32b_bf8c/clean_qwen2.5-coder:32b_bf8c_dp_batch.csv\n"
     ]
    }
   ],
   "source": [
    "import traceback\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from dateutil import parser\n",
    "\n",
    "\n",
    "def json_to_csv(session_id):\n",
    "    \"\"\"\n",
    "    Convert JSON trace data to CSV format with aggregated metrics.\n",
    "\n",
    "    Args:\n",
    "        session_id (str): Identifier for the session to process\n",
    "    \"\"\"\n",
    "\n",
    "    def extract_observation_details(observations, trace_id):\n",
    "        \"\"\"Extract and aggregate metrics from observations\"\"\"\n",
    "        metrics = {\n",
    "            \"status\": None,\n",
    "            \"latency\": 0,\n",
    "            \"total_tokens\": 0,\n",
    "            \"prompt_tokens\": 0,\n",
    "            \"completion_tokens\": 0,\n",
    "            \"total_cost\": 0,\n",
    "            \"input_cost\": 0,\n",
    "            \"output_cost\": 0,\n",
    "            \"parameters\": set(),\n",
    "        }\n",
    "\n",
    "        # Process GENERATION observations\n",
    "        for obs in (o for o in observations if o[\"type\"] == \"GENERATION\"):\n",
    "            metrics[\"total_tokens\"] += obs[\"totalTokens\"]\n",
    "            metrics[\"prompt_tokens\"] += obs[\"promptTokens\"]\n",
    "            metrics[\"completion_tokens\"] += obs[\"completionTokens\"]\n",
    "            metrics[\"latency\"] += obs[\"latency\"]\n",
    "            for key, value in obs[\"modelParameters\"].items():\n",
    "                metrics[\"parameters\"].add(key + \":\" + value)\n",
    "\n",
    "            # Add costs if present\n",
    "            for cost_type in [\"Total\", \"Input\", \"Output\"]:\n",
    "                key = f\"calculated{cost_type}Cost\"\n",
    "                metric_key = cost_type.lower() + \"_cost\"\n",
    "                if obs.get(key) is not None:\n",
    "                    metrics[metric_key] += obs[key]\n",
    "        if len(metrics[\"parameters\"]) == 0:\n",
    "            metrics[\"parameters\"] = \"N/A\"\n",
    "        # Process SPAN observations for status\n",
    "        status_indicators = [\n",
    "            obs[\"name\"]\n",
    "            for obs in observations\n",
    "            if obs[\"type\"] == \"SPAN\" and \"start_\" not in obs[\"name\"]\n",
    "        ]\n",
    "\n",
    "        #  if later than 2025-05-19, use status_signal_from_output\n",
    "        if datetime.now() > datetime(2025, 5, 19):\n",
    "            pass\n",
    "        else:\n",
    "            # Determine status\n",
    "            success_signals = sum(\"end_\" in name for name in status_indicators)\n",
    "            failure_signals = sum(\n",
    "                \"failure_signal\" in name for name in status_indicators\n",
    "            )\n",
    "\n",
    "            if success_signals + failure_signals > 1:\n",
    "                raise ValueError(\n",
    "                    f\"Multiple status indicators found in trace {trace_id}\"\n",
    "                )\n",
    "\n",
    "            metrics[\"status\"] = (\n",
    "                \"success\"\n",
    "                if success_signals\n",
    "                else \"failure\" if failure_signals else \"unknown\"\n",
    "            )\n",
    "\n",
    "        metrics[\"prompt_cost\"] = metrics.pop(\"input_cost\")\n",
    "        metrics[\"completion_cost\"] = metrics.pop(\"output_cost\")\n",
    "        metrics[\"latency\"] = round(metrics[\"latency\"] / 1000, 2)\n",
    "        return metrics\n",
    "\n",
    "    def cal_time(trace):\n",
    "        time_diff = datetime.fromisoformat(\n",
    "            trace[\"updatedAt\"].replace(\"Z\", \"+00:00\")\n",
    "        ) - datetime.fromisoformat(trace[\"createdAt\"].replace(\"Z\", \"+00:00\"))\n",
    "        seconds_diff = time_diff.total_seconds()\n",
    "        return seconds_diff\n",
    "\n",
    "    try:\n",
    "\n",
    "        if session_id.startswith(\"da0a\"):\n",
    "            session_id = \"phi4_\" + session_id\n",
    "        simple_session_id = session_id.rsplit(\"_\", 2)[0]\n",
    "\n",
    "        \n",
    "        # Load JSON data\n",
    "        if \"tpsg\" in session_id:\n",
    "                session_id_ = session_id.replace(\"tpsg\", \"tpusg\")\n",
    "        else:\n",
    "                session_id_ = session_id\n",
    "        trimmed_path = os.path.join(raw_export_dir, f\"trimmed_{session_id_}.json\")\n",
    "        print(\n",
    "            f\"Processing session {session_id}, simple id {simple_session_id}. Look for {trimmed_path}\"\n",
    "        )\n",
    "        with open(trimmed_path, \"r\") as file:\n",
    "            traces = json.load(file)[\"data\"]\n",
    "\n",
    "        # Process traces\n",
    "        rows = [\n",
    "            {\n",
    "                \"num_run\": trace[\"metadata\"][\"num_run\"],\n",
    "                \"name\": trace[\"name\"],\n",
    "                \"trace_id\": trace[\"id\"],\n",
    "                \"batch_id\": trace[\"session_id\"],\n",
    "                # \"latency\": cal_time(trace),\n",
    "                # \"latency\": round(trace[\"latency\"], 2),\n",
    "                **extract_observation_details(\n",
    "                    trace[\"observations\"],\n",
    "                    trace[\"id\"],\n",
    "                ),\n",
    "                \"status\": (\n",
    "                    \"failure\"\n",
    "                    if trace[\"output\"][\"status\"].lower() == \"failed\"\n",
    "                    else \"success\"\n",
    "                ),\n",
    "                \"tags\": trace[\"tags\"],\n",
    "                \"timestamp\": int(parser.isoparse(trace[\"timestamp\"]).timestamp()),\n",
    "            }\n",
    "            for trace in traces\n",
    "        ]\n",
    "        # print(rows)\n",
    "        # print(rows)\n",
    "        # Create and save DataFrame\n",
    "        df = pd.DataFrame(rows).sort_values(\"num_run\")\n",
    "\n",
    "        output_dir = os.path.join(processed_data_dir, f\"{simple_session_id}\")\n",
    "        if not os.path.exists(output_dir):\n",
    "            os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "        output_path = os.path.join(output_dir, f\"clean_{session_id_}.csv\")\n",
    "\n",
    "        print(output_path)\n",
    "        df.to_csv(output_path, index=False)\n",
    "        print(f\"Successfully saved CSV to: {output_path}\")\n",
    "\n",
    "    except FileNotFoundError as e:\n",
    "        print(\n",
    "            f\"FileNotFoundError: For session {session_id} not found. Looked for {trimmed_path}\\nError info: \\n{e}\\n\\nTraceback: {traceback.format_exc()}\"\n",
    "        )\n",
    "    except json.JSONDecodeError:\n",
    "        print(f\"Error: Invalid JSON format in input file for session {session_id}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing session {session_id}: {str(e)}\")\n",
    "\n",
    "\n",
    "# Example usage\n",
    "for session_id in session_id_list:\n",
    "    json_to_csv(session_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CSV Generation with Generation Counts\n",
    "\n",
    "This section creates CSV files similar to the langfuse_export section 3, but adds a column for the number of generation attempts used for each trace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing sessions: ['qwen2.5-coder:32b_bf8c_dp_batch']\n",
      "Looking for raw files in: /home/han/Projects/reference-benchmark-tinyml_llm/data_analysis/2025/11.03/raw_export\n",
      "Will save CSV files to: /home/han/Projects/reference-benchmark-tinyml_llm/data_analysis/2025/11.03/processed_data\n",
      "Processing session qwen2.5-coder:32b_bf8c_dp_batch, simple id qwen2.5-coder:32b_bf8c. Look for /home/han/Projects/reference-benchmark-tinyml_llm/data_analysis/2025/11.03/raw_export/trimmed_qwen2.5-coder:32b_bf8c_dp_batch.json\n",
      "/home/han/Projects/reference-benchmark-tinyml_llm/data_analysis/2025/11.03/processed_data/qwen2.5-coder:32b_bf8c/clean_qwen2.5-coder:32b_bf8c_dp_batch.csv\n",
      "Successfully saved CSV to: /home/han/Projects/reference-benchmark-tinyml_llm/data_analysis/2025/11.03/processed_data/qwen2.5-coder:32b_bf8c/clean_qwen2.5-coder:32b_bf8c_dp_batch.csv\n"
     ]
    }
   ],
   "source": [
    "import traceback\n",
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "from datetime import datetime\n",
    "from dateutil import parser\n",
    "\n",
    "# Setup paths - same as langfuse_export\n",
    "parent_dir = os.path.dirname(os.getcwd())\n",
    "raw_export_dir = os.path.join(parent_dir, \"raw_export\")\n",
    "processed_data_dir = os.path.join(parent_dir, \"processed_data\")\n",
    "\n",
    "\n",
    "# Get session id list from data directory\n",
    "session_id_list = []\n",
    "\n",
    "for root, dirs, files in os.walk(raw_export_dir):\n",
    "    for file in files:\n",
    "        file_path = os.path.join(root, file)\n",
    "        if \"trimmed_\" in file_path:\n",
    "            session_id = file_path.split('trimmed_')[1].rstrip('.json')\n",
    "            session_id_list.append(session_id)\n",
    "\n",
    "print(f\"Processing sessions: {session_id_list}\")\n",
    "print(f\"Looking for raw files in: {raw_export_dir}\")\n",
    "print(f\"Will save CSV files to: {processed_data_dir}\")\n",
    "\n",
    "\n",
    "def json_to_csv_weighted(session_id):\n",
    "    \"\"\"\n",
    "    Convert JSON trace data to CSV format with aggregated metrics.\n",
    "    Upgraded version that includes generation_count column.\n",
    "\n",
    "    Args:\n",
    "        session_id (str): Identifier for the session to process\n",
    "    \"\"\"\n",
    "\n",
    "    def extract_observation_details(observations, trace_id):\n",
    "        \"\"\"Extract and aggregate metrics from observations\"\"\"\n",
    "        metrics = {\n",
    "            \"status\": None,\n",
    "            \"latency\": 0,\n",
    "            \"total_tokens\": 0,\n",
    "            \"prompt_tokens\": 0,\n",
    "            \"completion_tokens\": 0,\n",
    "            \"total_cost\": 0,\n",
    "            \"input_cost\": 0,\n",
    "            \"output_cost\": 0,\n",
    "            \"parameters\": set(),\n",
    "            \"generation_count\": 0,  # New field for generation count\n",
    "        }\n",
    "\n",
    "        # Count generations and process GENERATION observations\n",
    "        for obs in (o for o in observations if o[\"type\"] == \"GENERATION\"):\n",
    "            metrics[\"generation_count\"] += 1\n",
    "            metrics[\"total_tokens\"] += obs[\"totalTokens\"]\n",
    "            metrics[\"prompt_tokens\"] += obs[\"promptTokens\"]\n",
    "            metrics[\"completion_tokens\"] += obs[\"completionTokens\"]\n",
    "            metrics[\"latency\"] += obs[\"latency\"]\n",
    "            for key, value in obs[\"modelParameters\"].items():\n",
    "                metrics[\"parameters\"].add(key + \":\" + value)\n",
    "\n",
    "            # Add costs if present\n",
    "            for cost_type in [\"Total\", \"Input\", \"Output\"]:\n",
    "                key = f\"calculated{cost_type}Cost\"\n",
    "                metric_key = cost_type.lower() + \"_cost\"\n",
    "                if obs.get(key) is not None:\n",
    "                    metrics[metric_key] += obs[key]\n",
    "                    \n",
    "        if len(metrics[\"parameters\"]) == 0:\n",
    "            metrics[\"parameters\"] = \"N/A\"\n",
    "            \n",
    "        # Process SPAN observations for status\n",
    "        status_indicators = [\n",
    "            obs[\"name\"]\n",
    "            for obs in observations\n",
    "            if obs[\"type\"] == \"SPAN\" and \"start_\" not in obs[\"name\"]\n",
    "        ]\n",
    "\n",
    "        #  if later than 2025-05-19, use status_signal_from_output\n",
    "        if datetime.now() > datetime(2025, 5, 19):\n",
    "            pass\n",
    "        else:\n",
    "            # Determine status\n",
    "            success_signals = sum(\"end_\" in name for name in status_indicators)\n",
    "            failure_signals = sum(\n",
    "                \"failure_signal\" in name for name in status_indicators\n",
    "            )\n",
    "\n",
    "            if success_signals + failure_signals > 1:\n",
    "                raise ValueError(\n",
    "                    f\"Multiple status indicators found in trace {trace_id}\"\n",
    "                )\n",
    "\n",
    "            metrics[\"status\"] = (\n",
    "                \"success\"\n",
    "                if success_signals\n",
    "                else \"failure\" if failure_signals else \"unknown\"\n",
    "            )\n",
    "\n",
    "        metrics[\"prompt_cost\"] = metrics.pop(\"input_cost\")\n",
    "        metrics[\"completion_cost\"] = metrics.pop(\"output_cost\")\n",
    "        metrics[\"latency\"] = round(metrics[\"latency\"] / 1000, 2)\n",
    "        return metrics\n",
    "\n",
    "    def cal_time(trace):\n",
    "        time_diff = datetime.fromisoformat(\n",
    "            trace[\"updatedAt\"].replace(\"Z\", \"+00:00\")\n",
    "        ) - datetime.fromisoformat(trace[\"createdAt\"].replace(\"Z\", \"+00:00\"))\n",
    "        seconds_diff = time_diff.total_seconds()\n",
    "        return seconds_diff\n",
    "\n",
    "    try:\n",
    "        if session_id.startswith(\"da0a\"):\n",
    "            session_id = \"phi4_\" + session_id\n",
    "        simple_session_id = session_id.rsplit(\"_\", 2)[0]\n",
    "\n",
    "        # Load JSON data\n",
    "        if \"tpsg\" in session_id:\n",
    "            session_id_ = session_id.replace(\"tpsg\", \"tpusg\")\n",
    "        else:\n",
    "            session_id_ = session_id\n",
    "        trimmed_path = os.path.join(raw_export_dir, f\"trimmed_{session_id_}.json\")\n",
    "        print(\n",
    "            f\"Processing session {session_id}, simple id {simple_session_id}. Look for {trimmed_path}\"\n",
    "        )\n",
    "        with open(trimmed_path, \"r\") as file:\n",
    "            traces = json.load(file)[\"data\"]\n",
    "\n",
    "        # Process traces\n",
    "        rows = [\n",
    "            {\n",
    "                \"num_run\": trace[\"metadata\"][\"num_run\"],\n",
    "                \"name\": trace[\"name\"],\n",
    "                \"trace_id\": trace[\"id\"],\n",
    "                \"batch_id\": trace[\"session_id\"],\n",
    "                # \"latency\": cal_time(trace),\n",
    "                # \"latency\": round(trace[\"latency\"], 2),\n",
    "                **extract_observation_details(\n",
    "                    trace[\"observations\"],\n",
    "                    trace[\"id\"],\n",
    "                ),\n",
    "                \"status\": (\n",
    "                    \"failure\"\n",
    "                    if trace[\"output\"][\"status\"].lower() == \"failed\"\n",
    "                    else \"success\"\n",
    "                ),\n",
    "                \"tags\": trace[\"tags\"],\n",
    "                \"timestamp\": int(parser.isoparse(trace[\"timestamp\"]).timestamp()),\n",
    "            }\n",
    "            for trace in traces\n",
    "        ]\n",
    "        \n",
    "        # Create and save DataFrame\n",
    "        df = pd.DataFrame(rows).sort_values(\"num_run\")\n",
    "\n",
    "        output_dir = os.path.join(processed_data_dir, f\"{simple_session_id}\")\n",
    "        if not os.path.exists(output_dir):\n",
    "            os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "        output_path = os.path.join(output_dir, f\"clean_{session_id_}.csv\")\n",
    "\n",
    "        print(output_path)\n",
    "        df.to_csv(output_path, index=False)\n",
    "        print(f\"Successfully saved CSV to: {output_path}\")\n",
    "\n",
    "    except FileNotFoundError as e:\n",
    "        print(\n",
    "            f\"FileNotFoundError: For session {session_id} not found. Looked for {trimmed_path}\\nError info: \\n{e}\\n\\nTraceback: {traceback.format_exc()}\"\n",
    "        )\n",
    "    except json.JSONDecodeError:\n",
    "        print(f\"Error: Invalid JSON format in input file for session {session_id}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing session {session_id}: {str(e)}\")\n",
    "\n",
    "\n",
    "\n",
    "# Example usage\n",
    "for session_id in session_id_list:\n",
    "    json_to_csv_weighted(session_id)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llmdev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

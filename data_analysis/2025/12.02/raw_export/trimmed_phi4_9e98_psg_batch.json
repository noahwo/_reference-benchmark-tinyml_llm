{
  "data": [
    {
      "id": "eb6ff404",
      "timestamp": "2025-12-10T21:41:11.713000+00:00",
      "name": "eb6f_py_sketch_generator",
      "input": null,
      "output": {
        "status": "failed",
        "last_code": "import cv2\nimport numpy as np\nimport tflite_runtime.interpreter as tflite\nfrom PIL import ImageDraw, ImageFont\n\n# Configuration parameters\nmodel_path  = \"models/ssd-mobilenet_v1/detect.tflite\"\nlabel_path  = \"models/ssd-mobilenet_v1/labelmap.txt\"\ninput_path  = \"data/object_detection/sheeps.mp4\"\noutput_path  = \"results/object_detection/test_results/sheeps_detections.mp4\"\nconfidence_threshold  = 0.5\n\n# Load labels from the label map file\nwith open(label_path, 'r') as f:\n    labels = [line.strip() for line in f.readlines()]\n\ndef load_labels(path):\n    with open(path, 'r', encoding='utf-8') as f:\n        return {i: line.strip() for i, line in enumerate(f.readlines())}\n\ndef set_input_tensor(interpreter, image):\n    tensor_index = interpreter.get_input_details()[0]['index']\n    input_tensor = interpreter.tensor(tensor_index)()[0]\n    input_tensor[:, :] = image\n\ndef get_output(interpreter, score_threshold):\n    boxes = interpreter.get_output_details()[0]['index']\n    classes = interpreter.get_output_details()[1]['index']\n    scores = interpreter.get_output_details()[2]['index']\n\n    box_data = interpreter.get_tensor(boxes)\n    class_data = interpreter.get_tensor(classes)\n    score_data = interpreter.get_tensor(scores)\n\n    results = []\n    for i in range(len(score_data[0])):\n        if score_data[0][i] >= score_threshold:\n            result = {\n                'bounding_box': box_data[0][i],\n                'class_id': class_data[0][i],\n                'score': score_data[0][i]\n            }\n            results.append(result)\n    return results\n\ndef draw_bounding_boxes(frame, results):\n    font = ImageFont.load_default()\n    for obj in results:\n        ymin, xmin, ymax, xmax = tuple(obj['bounding_box'])\n        xmin *= frame.shape[1]\n        xmax *= frame.shape[1]\n        ymin *= frame.shape[0]\n        ymax *= frame.shape[0]\n\n        label = f\"{labels[int(obj['class_id'])]} {int(100 * obj['score'])}%\"\n        draw = ImageDraw.Draw(Image.fromarray(frame))\n        draw.rectangle([(xmin, ymin), (xmax, ymax)], outline=(255, 0, 0))\n        text_size = draw.textsize(label, font=font)\n        draw.rectangle(\n            [(xmin, ymin - text_size[1]), (xmin + text_size[0], ymin)],\n            fill=(255, 0, 0),\n            outline=(255, 0, 0)\n        )\n        draw.text((xmin, ymin - text_size[1]), label, fill=(255, 255, 255), font=font)\n\ndef main():\n    # Load TFLite model and allocate tensors\n    interpreter = tflite.Interpreter(model_path=model_path)\n    interpreter.allocate_tensors()\n\n    input_details = interpreter.get_input_details()\n    output_details = interpreter.get_output_details()\n    height = input_details[0]['shape'][1]\n    width = input_details[0]['shape'][2]\n\n    # Open video file\n    cap = cv2.VideoCapture(input_path)\n    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n    out = cv2.VideoWriter(output_path, fourcc, 20.0, (int(cap.get(3)), int(cap.get(4))))\n\n    while cap.isOpened():\n        ret, frame = cap.read()\n        if not ret:\n            break\n\n        # Preprocess the image\n        img_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n        input_frame = cv2.resize(img_rgb, (width, height))\n        input_frame = np.expand_dims(input_frame, axis=0)\n\n        # Set the tensor to point to the input data to be inferred\n        set_input_tensor(interpreter, input_frame)\n\n        # Run inference\n        interpreter.invoke()\n\n        # Get detection results\n        detections = get_output(interpreter, confidence_threshold)\n\n        # Draw bounding boxes on the frame\n        draw_bounding_boxes(frame, detections)\n\n        # Write the frame with detections to output video\n        out.write(frame)\n\n    cap.release()\n    out.release()\n\nif __name__ == '__main__':\n    main()",
        "last_error": "Max retries reached with failure. Last error from execution: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\nTraceback (most recent call last):\n  File \"/home/wuguangh/Projects/03.12/tinyml-autopilot-pm.03.12.2025/results/object_detection/sketches/tmp_20251210234234_psg_phi4:latest/tmp_20251210234234_psg_phi4:latest.py\", line 110, in <module>\n    main()\n  File \"/home/wuguangh/Projects/03.12/tinyml-autopilot-pm.03.12.2025/results/object_detection/sketches/tmp_20251210234234_psg_phi4:latest/tmp_20251210234234_psg_phi4:latest.py\", line 101, in main\n    draw_bounding_boxes(frame, detections)\n  File \"/home/wuguangh/Projects/03.12/tinyml-autopilot-pm.03.12.2025/results/object_detection/sketches/tmp_20251210234234_psg_phi4:latest/tmp_20251210234234_psg_phi4:latest.py\", line 56, in draw_bounding_boxes\n    draw = ImageDraw.Draw(Image.fromarray(frame))\nNameError: name 'Image' is not defined\n"
      },
      "session_id": "phi4_9e98_psg_batch",
      "metadata": {
        "num_run": 30
      },
      "tags": [
        "ablation",
        "benchmark",
        "phi4:latest",
        "py_sketch_generator"
      ],
      "latency": 83.168,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-23-41-11-714975_chatcmpl-b11b7d83-34da-4ec6-bae9-3162b01426b6",
          "traceId": "eb6ff404",
          "type": "GENERATION",
          "name": "eb6f_psg_gen_attempt#1",
          "startTime": "2025-12-10T21:41:11.714000+00:00",
          "endTime": "2025-12-10T21:41:25.155000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 13441.0,
          "totalTokens": 984,
          "costDetails": {},
          "environment": "default",
          "promptTokens": 245,
          "completionTokens": 739,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-23-41-25-304306_chatcmpl-9c469035-3f71-472f-a887-52fe2d847311",
          "traceId": "eb6ff404",
          "type": "GENERATION",
          "name": "eb6f_psg_gen_attempt#2",
          "startTime": "2025-12-10T21:41:25.304000+00:00",
          "endTime": "2025-12-10T21:41:39.371000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 14067.0,
          "totalTokens": 1023,
          "costDetails": {},
          "environment": "default",
          "promptTokens": 245,
          "completionTokens": 778,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-23-41-43-486930_chatcmpl-809081fe-b355-49c0-9d29-a8bc50f89d05",
          "traceId": "eb6ff404",
          "type": "GENERATION",
          "name": "eb6f_psg_gen_attempt#3",
          "startTime": "2025-12-10T21:41:43.486000+00:00",
          "endTime": "2025-12-10T21:41:56.805000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 13319.0,
          "totalTokens": 981,
          "costDetails": {},
          "environment": "default",
          "promptTokens": 245,
          "completionTokens": 736,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-23-41-59-787661_chatcmpl-ef117189-c606-40a3-ac94-6b04c1f94a9d",
          "traceId": "eb6ff404",
          "type": "GENERATION",
          "name": "eb6f_psg_gen_attempt#4",
          "startTime": "2025-12-10T21:41:59.787000+00:00",
          "endTime": "2025-12-10T21:42:14.785000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 14998.0,
          "totalTokens": 1074,
          "costDetails": {},
          "environment": "default",
          "promptTokens": 245,
          "completionTokens": 829,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-23-42-18-036599_chatcmpl-1de13a8e-db08-42f5-bf05-b5e8c5e85cbc",
          "traceId": "eb6ff404",
          "type": "GENERATION",
          "name": "eb6f_psg_gen_attempt#5",
          "startTime": "2025-12-10T21:42:18.036000+00:00",
          "endTime": "2025-12-10T21:42:34.522000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 16486.0,
          "totalTokens": 1156,
          "costDetails": {},
          "environment": "default",
          "promptTokens": 245,
          "completionTokens": 911,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "d7d4977e-2d74-4030-bfd3-a881a4b0b138",
          "traceId": "eb6ff404",
          "type": "SPAN",
          "name": "error_eb_psg_failure_signal_py_sketch_generator",
          "startTime": "2025-12-10T21:42:34.882000+00:00",
          "level": "ERROR",
          "statusMessage": "Failed. Last error: Max retries reached with failure. Last error from execution: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\nTraceback (most recent call last):\n  File \"/home/wuguangh/Projects/03.12/tinyml-autopilot-pm.03.12.2025/results/object_detection/sketches/tmp_20251210234234_psg_phi4:latest/tmp_20251210234234_psg_phi4:latest.py\", line 110, in <module>\n    main()\n  File \"/home/wuguangh/Projects/03.12/tinyml-autopilot-pm.03.12.2025/results/object_detection/sketches/tmp_20251210234234_psg_phi4:latest/tmp_20251210234234_psg_phi4:latest.py\", line 101, in main\n    draw_bounding_boxes(frame, detections)\n  File \"/home/wuguangh/Projects/03.12/tinyml-autopilot-pm.03.12.2025/results/object_detection/sketches/tmp_20251210234234_psg_phi4:latest/tmp_20251210234234_psg_phi4:latest.py\", line 56, in draw_bounding_boxes\n    draw = ImageDraw.Draw(Image.fromarray(frame))\nNameError: name 'Image' is not defined\n",
          "calculatedTotalCost": 0.0,
          "totalTokens": 0,
          "costDetails": {},
          "environment": "default",
          "promptTokens": 0,
          "completionTokens": 0,
          "endTime": null,
          "model": null,
          "modelParameters": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null,
          "latency": null
        }
      ],
      "createdAt": "2025-12-10T21:41:12.234Z",
      "updatedAt": "2025-12-10T21:42:40.387Z",
      "environment": "default"
    },
    {
      "id": "92e6650d",
      "timestamp": "2025-12-10T21:39:15.743000+00:00",
      "name": "92e6_py_sketch_generator",
      "input": null,
      "output": {
        "status": "failed",
        "last_code": "import cv2\nimport numpy as np\nimport tflite_runtime.interpreter as tflite\nfrom pycocotools.coco import COCO\n\n# Configuration parameters\nmodel_path  = \"models/ssd-mobilenet_v1/detect.tflite\"\nlabel_path  = \"models/ssd-mobilenet_v1/labelmap.txt\"\ninput_path  = \"data/object_detection/sheeps.mp4\"\noutput_path  = \"results/object_detection/test_results/sheeps_detections.mp4\"\nconfidence_threshold  = 0.5\n\n# Setup phase: Load TFLite model and labels\ndef load_labels(label_file):\n    with open(label_file, 'r') as file:\n        return [line.strip() for line in file.readlines()]\n\ndef load_interpreter(model_path):\n    interpreter = tflite.Interpreter(model_path=model_path)\n    interpreter.allocate_tensors()\n    return interpreter\n\ninterpreter = load_interpreter(model_path)\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\n\nlabels = load_labels(label_path)\n\n# Preprocessing phase: Read input and prepare frames\ncap = cv2.VideoCapture(input_path)\nframe_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\nframe_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\nfps = cap.get(cv2.CAP_PROP_FPS)\noutput_video = cv2.VideoWriter(output_path, cv2.VideoWriter_fourcc(*'mp4v'), fps, (frame_width, frame_height))\n\n# Inference phase: Process each frame\ndef run_inference(frame):\n    input_data = cv2.resize(frame, (input_details[0]['shape'][2], input_details[0]['shape'][1]))\n    input_data = np.expand_dims(input_data, axis=0)\n    input_data = (np.float32(input_data) - 127.5) / 127.5\n\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n    interpreter.invoke()\n\n    boxes = interpreter.get_tensor(output_details[0]['index'])[0]\n    classes = interpreter.get_tensor(output_details[1]['index'])[0]\n    scores = interpreter.get_tensor(output_details[2]['index'])[0]\n\n    return boxes, classes, scores\n\n# Output handling phase: Draw detections and compute mAP\ndef draw_boxes(frame, boxes, classes, scores):\n    height, width, _ = frame.shape\n    for i in range(len(scores)):\n        if scores[i] > confidence_threshold:\n            ymin, xmin, ymax, xmax = boxes[i]\n            (left, right, top, bottom) = (xmin * width, xmax * width, ymin * height, ymax * height)\n            cv2.rectangle(frame, (int(left), int(top)), (int(right), int(bottom)), (0, 255, 0), 2)\n            label = f'{labels[int(classes[i])]}: {scores[i]:.2f}'\n            cv2.putText(frame, label, (int(left), int(top - 10)), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 1)\n\nwhile cap.isOpened():\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    boxes, classes, scores = run_inference(frame)\n    draw_boxes(frame, boxes, classes, scores)\n\n    output_video.write(frame)\n\ncap.release()\noutput_video.release()\n\n# Compute mAP (requires ground truth annotations and predictions in COCO format)\ndef compute_map(ground_truth_path, detection_results):\n    coco_gt = COCO(ground_truth_path)\n    coco_dt = coco_gt.loadRes(detection_results)\n    coco_eval = coco_gt.evaluate(coco_dt, 'bbox')\n    return coco_eval\n\n# Assuming ground truth annotations and detection results are prepared\n# map_score = compute_map('path_to_ground_truth_annotations.json', 'path_to_detection_results.json')\n# print(f'mAP: {map_score}')",
        "last_error": "Max retries reached with failure. Last error from execution: Traceback (most recent call last):\n  File \"/home/wuguangh/Projects/03.12/tinyml-autopilot-pm.03.12.2025/results/object_detection/sketches/tmp_20251210234045_psg_phi4:latest/tmp_20251210234045_psg_phi4:latest.py\", line 4, in <module>\n    from pycocotools.coco import COCO\nModuleNotFoundError: No module named 'pycocotools'\n"
      },
      "session_id": "phi4_9e98_psg_batch",
      "metadata": {
        "num_run": 29
      },
      "tags": [
        "ablation",
        "benchmark",
        "phi4:latest",
        "py_sketch_generator"
      ],
      "latency": 89.688,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-23-39-15-744444_chatcmpl-1e04ef48-9276-4149-b838-244b0a4beded",
          "traceId": "92e6650d",
          "type": "GENERATION",
          "name": "92e6_psg_gen_attempt#1",
          "startTime": "2025-12-10T21:39:15.744000+00:00",
          "endTime": "2025-12-10T21:39:30.419000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 14675.0,
          "totalTokens": 1053,
          "costDetails": {},
          "environment": "default",
          "promptTokens": 245,
          "completionTokens": 808,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-23-39-33-371153_chatcmpl-07267d49-59d7-4a5c-8f5f-0e65a4af37b4",
          "traceId": "92e6650d",
          "type": "GENERATION",
          "name": "92e6_psg_gen_attempt#2",
          "startTime": "2025-12-10T21:39:33.371000+00:00",
          "endTime": "2025-12-10T21:39:50.735000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 17364.0,
          "totalTokens": 1203,
          "costDetails": {},
          "environment": "default",
          "promptTokens": 245,
          "completionTokens": 958,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-23-39-53-972209_chatcmpl-3b86cde0-5533-4d78-ac84-902cc8eb38ee",
          "traceId": "92e6650d",
          "type": "GENERATION",
          "name": "92e6_psg_gen_attempt#3",
          "startTime": "2025-12-10T21:39:53.972000+00:00",
          "endTime": "2025-12-10T21:40:09.691000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 15719.0,
          "totalTokens": 1113,
          "costDetails": {},
          "environment": "default",
          "promptTokens": 245,
          "completionTokens": 868,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-23-40-12-673948_chatcmpl-cb3a3a44-7f79-4565-aeb2-14b4a2d06ae0",
          "traceId": "92e6650d",
          "type": "GENERATION",
          "name": "92e6_psg_gen_attempt#4",
          "startTime": "2025-12-10T21:40:12.673000+00:00",
          "endTime": "2025-12-10T21:40:25.747000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 13074.0,
          "totalTokens": 968,
          "costDetails": {},
          "environment": "default",
          "promptTokens": 245,
          "completionTokens": 723,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-23-40-29-559540_chatcmpl-3ea230e4-1a8c-4df4-8cde-6bafa0a47cdf",
          "traceId": "92e6650d",
          "type": "GENERATION",
          "name": "92e6_psg_gen_attempt#5",
          "startTime": "2025-12-10T21:40:29.559000+00:00",
          "endTime": "2025-12-10T21:40:45.309000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 15750.0,
          "totalTokens": 1115,
          "costDetails": {},
          "environment": "default",
          "promptTokens": 245,
          "completionTokens": 870,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "b74f65c9-7984-4988-88d4-93606f7fe31b",
          "traceId": "92e6650d",
          "type": "SPAN",
          "name": "error_92_psg_failure_signal_py_sketch_generator",
          "startTime": "2025-12-10T21:40:45.432000+00:00",
          "level": "ERROR",
          "statusMessage": "Failed. Last error: Max retries reached with failure. Last error from execution: Traceback (most recent call last):\n  File \"/home/wuguangh/Projects/03.12/tinyml-autopilot-pm.03.12.2025/results/object_detection/sketches/tmp_20251210234045_psg_phi4:latest/tmp_20251210234045_psg_phi4:latest.py\", line 4, in <module>\n    from pycocotools.coco import COCO\nModuleNotFoundError: No module named 'pycocotools'\n",
          "calculatedTotalCost": 0.0,
          "totalTokens": 0,
          "costDetails": {},
          "environment": "default",
          "promptTokens": 0,
          "completionTokens": 0,
          "endTime": null,
          "model": null,
          "modelParameters": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null,
          "latency": null
        }
      ],
      "createdAt": "2025-12-10T21:39:16.264Z",
      "updatedAt": "2025-12-10T21:40:51.095Z",
      "environment": "default"
    },
    {
      "id": "b6547599",
      "timestamp": "2025-12-10T21:37:52.767000+00:00",
      "name": "b654_py_sketch_generator",
      "input": null,
      "output": {
        "status": "success",
        "sketch": "import cv2\nimport numpy as np\nimport tensorflow as tf\n\n# Configuration parameters\nmodel_path  = \"models/ssd-mobilenet_v1/detect.tflite\"\nlabel_path  = \"models/ssd-mobilenet_v1/labelmap.txt\"\ninput_path  = \"data/object_detection/sheeps.mp4\"\noutput_path  = \"results/object_detection/test_results/sheeps_detections.mp4\"\nconfidence_threshold  = 0.5\n\n# Phase 1: Setup\ndef load_labels(label_file):\n    with open(label_file, 'r') as file:\n        return [line.strip() for line in file.readlines()]\n\nlabels = load_labels(label_path)\n\ninterpreter = tf.lite.Interpreter(model_path=model_path)\ninterpreter.allocate_tensors()\n\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\n\ninput_shape = input_details[0]['shape']\nheight, width = input_shape[1], input_shape[2]\n\n# Phase 2: Preprocessing\ndef preprocess_frame(frame):\n    frame_resized = cv2.resize(frame, (width, height))\n    return np.expand_dims(cv2.cvtColor(frame_resized, cv2.COLOR_BGR2RGB), axis=0)\n\n# Phase 3: Inference\ndef run_inference(interpreter, input_data):\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n    interpreter.invoke()\n    \n    boxes = interpreter.get_tensor(output_details[0]['index'])[0]\n    classes = interpreter.get_tensor(output_details[1]['index'])[0].astype(np.uint8)\n    scores = interpreter.get_tensor(output_details[2]['index'])[0]\n\n    return boxes, classes, scores\n\n# Phase 4: Output Handling\ndef draw_boxes(frame, boxes, classes, scores):\n    for i in range(len(scores)):\n        if scores[i] >= confidence_threshold:\n            ymin, xmin, ymax, xmax = boxes[i]\n            (left, right, top, bottom) = (xmin * frame.shape[1], xmax * frame.shape[1],\n                                          ymin * frame.shape[0], ymax * frame.shape[0])\n            \n            cv2.rectangle(frame, (int(left), int(top)), (int(right), int(bottom)),\n                          (10, 255, 0), 2)\n            \n            label = f'{labels[classes[i]]}: {scores[i]:.2f}'\n            cv2.putText(frame, label, (int(left), int(top) - 5),\n                        cv2.FONT_HERSHEY_SIMPLEX, 0.7, (10, 255, 0), 2)\n\n# Video processing\ncap = cv2.VideoCapture(input_path)\nfourcc = cv2.VideoWriter_fourcc(*'mp4v')\nout = cv2.VideoWriter(output_path, fourcc, cap.get(cv2.CAP_PROP_FPS),\n                      (int(cap.get(3)), int(cap.get(4))))\n\nwhile cap.isOpened():\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    input_data = preprocess_frame(frame)\n    boxes, classes, scores = run_inference(interpreter, input_data)\n    \n    draw_boxes(frame, boxes, classes, scores)\n\n    out.write(frame)\n\ncap.release()\nout.release()\n\nprint(\"Processing complete. Output saved to:\", output_path)"
      },
      "session_id": "phi4_9e98_psg_batch",
      "metadata": {
        "num_run": 28
      },
      "tags": [
        "ablation",
        "benchmark",
        "phi4:latest",
        "py_sketch_generator"
      ],
      "latency": 49.595,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-23-37-52-768970_chatcmpl-340ab5cb-3365-4ac7-af19-662699de2b87",
          "traceId": "b6547599",
          "type": "GENERATION",
          "name": "b654_psg_gen_attempt#1",
          "startTime": "2025-12-10T21:37:52.768000+00:00",
          "endTime": "2025-12-10T21:38:10.923000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 18155.0,
          "totalTokens": 1232,
          "costDetails": {},
          "environment": "default",
          "promptTokens": 245,
          "completionTokens": 987,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-23-38-11-051199_chatcmpl-84b3086f-5e0a-4bb7-b364-1f17b980388a",
          "traceId": "b6547599",
          "type": "GENERATION",
          "name": "b654_psg_gen_attempt#2",
          "startTime": "2025-12-10T21:38:11.051000+00:00",
          "endTime": "2025-12-10T21:38:26.458000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 15407.0,
          "totalTokens": 1096,
          "costDetails": {},
          "environment": "default",
          "promptTokens": 245,
          "completionTokens": 851,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-23-38-29-410698_chatcmpl-6307208e-023f-4b06-821b-3ccd281d204f",
          "traceId": "b6547599",
          "type": "GENERATION",
          "name": "b654_psg_gen_attempt#3",
          "startTime": "2025-12-10T21:38:29.410000+00:00",
          "endTime": "2025-12-10T21:38:42.363000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 12953.0,
          "totalTokens": 961,
          "costDetails": {},
          "environment": "default",
          "promptTokens": 245,
          "completionTokens": 716,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        }
      ],
      "createdAt": "2025-12-10T21:37:53.288Z",
      "updatedAt": "2025-12-10T21:38:55.977Z",
      "environment": "default"
    },
    {
      "id": "d5d1e9e0",
      "timestamp": "2025-12-10T21:36:40.811000+00:00",
      "name": "d5d1_py_sketch_generator",
      "input": null,
      "output": {
        "status": "success",
        "sketch": "import cv2\nimport numpy as np\nimport tflite_runtime.interpreter as tflite\nfrom collections import defaultdict\n\n# Configuration parameters\nmodel_path  = \"models/ssd-mobilenet_v1/detect.tflite\"\nlabel_path  = \"models/ssd-mobilenet_v1/labelmap.txt\"\ninput_path  = \"data/object_detection/sheeps.mp4\"\noutput_path  = \"results/object_detection/test_results/sheeps_detections.mp4\"\nconfidence_threshold  = 0.5\n\n# Phase 1: Setup\ninterpreter = tflite.Interpreter(model_path=model_path)\ninterpreter.allocate_tensors()\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\n\nheight, width = input_details[0]['shape'][1], input_details[0]['shape'][2]\n\n# Load labels\nwith open(label_path, 'r') as f:\n    labels = [line.strip() for line in f.readlines()]\n\n# Phase 2: Preprocessing\ndef preprocess_frame(frame):\n    frame_resized = cv2.resize(frame, (width, height))\n    input_data = np.expand_dims(frame_resized, axis=0)\n    return input_data\n\n# Phase 3: Inference\ndef run_inference(input_data):\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n    interpreter.invoke()\n    \n    boxes = interpreter.get_tensor(output_details[0]['index'])[0]  # Bounding box coordinates of detected objects\n    classes = interpreter.get_tensor(output_details[1]['index'])[0]  # Class index of detected objects\n    scores = interpreter.get_tensor(output_details[2]['index'])[0]   # Confidence of detected objects\n    \n    return boxes, classes, scores\n\n# Phase 4: Output handling\ndef draw_boxes(frame, boxes, classes, scores):\n    for i in range(len(scores)):\n        if scores[i] > confidence_threshold:\n            ymin, xmin, ymax, xmax = boxes[i]\n            (left, right, top, bottom) = (xmin * frame.shape[1], xmax * frame.shape[1],\n                                          ymin * frame.shape[0], ymax * frame.shape[0])\n            \n            cv2.rectangle(frame, (int(left), int(top)), (int(right), int(bottom)), (10, 255, 0), 2)\n            label = f\"{labels[int(classes[i])]}: {int(scores[i] * 100)}%\"\n            cv2.putText(frame, label, (int(left), int(top - 5)), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)\n\n# Initialize video capture and writer\ncap = cv2.VideoCapture(input_path)\nframe_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\nframe_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\nfps = cap.get(cv2.CAP_PROP_FPS)\n\nout = cv2.VideoWriter(output_path, cv2.VideoWriter_fourcc(*'mp4v'), fps, (frame_width, frame_height))\n\n# Process video\nwhile cap.isOpened():\n    ret, frame = cap.read()\n    if not ret:\n        break\n    \n    input_data = preprocess_frame(frame)\n    boxes, classes, scores = run_inference(input_data)\n    draw_boxes(frame, boxes, classes, scores)\n    \n    out.write(frame)\n\ncap.release()\nout.release()\n\n# Compute mAP (Mean Average Precision) - Placeholder for demonstration purposes\ndef compute_map():\n    # This function is a placeholder. In practice, you would compare detections with ground truth annotations.\n    print(\"mAP computation is not implemented in this script.\")\n\ncompute_map()"
      },
      "session_id": "phi4_9e98_psg_batch",
      "metadata": {
        "num_run": 27
      },
      "tags": [
        "ablation",
        "benchmark",
        "phi4:latest",
        "py_sketch_generator"
      ],
      "latency": 14.796,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-23-36-40-812018_chatcmpl-4353612c-658d-4b37-ac12-b0913cd06f02",
          "traceId": "d5d1e9e0",
          "type": "GENERATION",
          "name": "d5d1_psg_gen_attempt#1",
          "startTime": "2025-12-10T21:36:40.812000+00:00",
          "endTime": "2025-12-10T21:36:55.608000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 14796.0,
          "totalTokens": 1056,
          "costDetails": {},
          "environment": "default",
          "promptTokens": 245,
          "completionTokens": 811,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        }
      ],
      "createdAt": "2025-12-10T21:36:41.331Z",
      "updatedAt": "2025-12-10T21:37:32.485Z",
      "environment": "default"
    },
    {
      "id": "15bf8b6c",
      "timestamp": "2025-12-10T21:35:53.792000+00:00",
      "name": "15bf_py_sketch_generator",
      "input": null,
      "output": {
        "status": "success",
        "sketch": "import cv2\nimport numpy as np\nimport tensorflow as tf\n\n# Configuration parameters\nmodel_path  = \"models/ssd-mobilenet_v1/detect.tflite\"\nlabel_path  = \"models/ssd-mobilenet_v1/labelmap.txt\"\ninput_path  = \"data/object_detection/sheeps.mp4\"\noutput_path  = \"results/object_detection/test_results/sheeps_detections.mp4\"\nconfidence_threshold  = 0.5\n\n# Setup phase\ndef load_labels(label_path):\n    with open(label_path, 'r') as file:\n        return [line.strip() for line in file.readlines()]\n\nlabels = load_labels(label_path)\ninterpreter = tf.lite.Interpreter(model_path=model_path)\ninterpreter.allocate_tensors()\n\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\n_, input_height, input_width, _ = input_details[0]['shape']\n\n# Preprocessing phase\ndef preprocess_frame(frame, target_size):\n    frame_resized = cv2.resize(frame, target_size)\n    return np.expand_dims(cv2.cvtColor(frame_resized, cv2.COLOR_BGR2RGB), axis=0)\n\n# Inference phase\ndef run_inference(interpreter, frame):\n    input_data = preprocess_frame(frame, (input_width, input_height))\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n    interpreter.invoke()\n\n    boxes = interpreter.get_tensor(output_details[0]['index'])[0] # Bounding box coordinates of detected objects\n    classes = interpreter.get_tensor(output_details[1]['index'])[0] # Class index of detected objects\n    scores = interpreter.get_tensor(output_details[2]['index'])[0] # Confidence of detected objects\n\n    return boxes, classes, scores\n\n# Output handling phase\ndef draw_boxes(frame, boxes, classes, scores):\n    height, width, _ = frame.shape\n    for i in range(len(scores)):\n        if scores[i] >= confidence_threshold:\n            ymin, xmin, ymax, xmax = boxes[i]\n            (left, right, top, bottom) = (xmin * width, xmax * width, ymin * height, ymax * height)\n            cv2.rectangle(frame, (int(left), int(top)), (int(right), int(bottom)), (10, 255, 0), 2)\n\n            label = f\"{labels[int(classes[i])]}: {int(scores[i] * 100)}%\"\n            cv2.putText(frame, label, (int(left), int(top) - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (10, 255, 0), 2)\n\n    return frame\n\n# Main processing loop\ncap = cv2.VideoCapture(input_path)\nfourcc = cv2.VideoWriter_fourcc(*'mp4v')\nout = cv2.VideoWriter(output_path, fourcc, 20.0, (int(cap.get(3)), int(cap.get(4))))\n\nwhile cap.isOpened():\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    boxes, classes, scores = run_inference(interpreter, frame)\n    frame_with_boxes = draw_boxes(frame, boxes, classes, scores)\n\n    out.write(frame_with_boxes)\n\ncap.release()\nout.release()\ncv2.destroyAllWindows()\n\n# Note: mAP computation is typically done on a test dataset with ground truth annotations.\n# This script focuses on running inference and visualizing results. For mAP calculation,\n# you would need to compare the predictions against annotated ground truths using a library\n# like pycocotools, which requires additional setup and data not provided here."
      },
      "session_id": "phi4_9e98_psg_batch",
      "metadata": {
        "num_run": 26
      },
      "tags": [
        "ablation",
        "benchmark",
        "phi4:latest",
        "py_sketch_generator"
      ],
      "latency": 13.371,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-23-35-53-793114_chatcmpl-11b44a78-c75e-44f2-b5b1-84f756690a86",
          "traceId": "15bf8b6c",
          "type": "GENERATION",
          "name": "15bf_psg_gen_attempt#1",
          "startTime": "2025-12-10T21:35:53.793000+00:00",
          "endTime": "2025-12-10T21:36:07.164000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 13371.0,
          "totalTokens": 980,
          "costDetails": {},
          "environment": "default",
          "promptTokens": 245,
          "completionTokens": 735,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        }
      ],
      "createdAt": "2025-12-10T21:35:54.313Z",
      "updatedAt": "2025-12-10T21:36:20.927Z",
      "environment": "default"
    },
    {
      "id": "d426111c",
      "timestamp": "2025-12-10T21:34:04.878000+00:00",
      "name": "d426_py_sketch_generator",
      "input": null,
      "output": {
        "status": "failed",
        "last_code": "import cv2\nfrom tflite_runtime.interpreter import Interpreter\nimport numpy as np\n\ndef load_labels(label_path):\n    with open(label_path, 'r') as file:\n        labels = {i: line.strip() for i, line in enumerate(file.readlines())}\n    return labels\n\ndef set_input_tensor(interpreter, image):\n    tensor_index = interpreter.get_input_details()[0]['index']\n    input_shape = interpreter.get_input_details()[0]['shape']\n    \n    # Preprocess the image to required shape\n    image = cv2.resize(image, (input_shape[1], input_shape[2]))\n    image = np.expand_dims(image, axis=0)\n    image = (image - 127.5) / 127.5\n    \n    interpreter.set_tensor(tensor_index, image)\n\ndef get_output(interpreter, score_threshold):\n    boxes = interpreter.get_tensor(interpreter.get_output_details()[0]['index'])[0] # Bounding box coordinates of detected objects\n    classes = interpreter.get_tensor(interpreter.get_output_details()[1]['index'])[0] # Class index of detected objects\n    scores = interpreter.get_tensor(interpreter.get_output_details()[2]['index'])[0] # Confidence of detected objects\n    \n    results = []\n    for i in range(len(scores)):\n        if scores[i] >= score_threshold:\n            result = {\n                'bounding_box': boxes[i],\n                'class_id': classes[i],\n                'score': scores[i]\n            }\n            results.append(result)\n    \n    return results\n\ndef draw_detections(frame, results, labels):\n    for obj in results:\n        ymin, xmin, ymax, xmax = tuple(obj['bounding_box'])\n        \n        # Convert to pixel values\n        (left, right, top, bottom) = (xmin * frame.shape[1], xmax * frame.shape[1],\n                                      ymin * frame.shape[0], ymax * frame.shape[0])\n        \n        # Draw bounding box and label on the image\n        cv2.rectangle(frame, (int(left), int(top)), (int(right), int(bottom)), (10, 255, 0), thickness=4)\n        \n        # Calculate text size\n        text = f\"{labels[int(obj['class_id'])]}: {round(obj['score'] * 100)}%\"\n        label_size, base_line = cv2.getTextSize(text, cv2.FONT_HERSHEY_SIMPLEX, 0.7, 2)\n        \n        # Place the label background\n        top = max(top, label_size[1])\n        cv2.rectangle(frame, (int(left), int(top - label_size[1])), \n                      (int(left + label_size[0]), int(top + base_line)), \n                      (255, 255, 255), cv2.FILLED)\n        \n        # Put text on the image\n        cv2.putText(frame, text, (int(left), int(top)),\n                    cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 0), thickness=2)\n\ndef main():\n    # Configuration parameters\n    model_path = 'models/ssd-mobilenet_v1/detect.tflite'\n    label_path = 'models/ssd-mobilenet_v1/labelmap.txt'\n    input_path = 'data/object_detection/sheeps.mp4'\n    output_path = 'results/object_detection/test_results/sheeps_detections.mp4'\n    confidence_threshold = 0.5\n    \n    # Load labels\n    labels = load_labels(label_path)\n    \n    # Initialize TFLite interpreter\n    interpreter = Interpreter(model_path=model_path)\n    interpreter.allocate_tensors()\n    \n    # Video capture and writer setup\n    cap = cv2.VideoCapture(input_path)\n    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n    out = cv2.VideoWriter(output_path, fourcc, 30.0, (int(cap.get(3)), int(cap.get(4))))\n    \n    while cap.isOpened():\n        ret, frame = cap.read()\n        \n        if not ret:\n            break\n        \n        # Preprocess and run inference\n        set_input_tensor(interpreter, frame)\n        interpreter.invoke()\n        \n        # Get output results\n        results = get_output(interpreter, confidence_threshold)\n        \n        # Draw detections on the frame\n        draw_detections(frame, results, labels)\n        \n        # Write the frame with detected objects to output video\n        out.write(frame)\n    \n    cap.release()\n    out.release()\n\nif __name__ == \"__main__\":\n    main()",
        "last_error": "Max retries reached with failure. Last error from execution: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\nTraceback (most recent call last):\n  File \"/home/wuguangh/Projects/03.12/tinyml-autopilot-pm.03.12.2025/results/object_detection/sketches/tmp_20251210233527_psg_phi4:latest/tmp_20251210233527_psg_phi4:latest.py\", line 106, in <module>\n    main()\n  File \"/home/wuguangh/Projects/03.12/tinyml-autopilot-pm.03.12.2025/results/object_detection/sketches/tmp_20251210233527_psg_phi4:latest/tmp_20251210233527_psg_phi4:latest.py\", line 90, in main\n    set_input_tensor(interpreter, frame)\n  File \"/home/wuguangh/Projects/03.12/tinyml-autopilot-pm.03.12.2025/results/object_detection/sketches/tmp_20251210233527_psg_phi4:latest/tmp_20251210233527_psg_phi4:latest.py\", line 19, in set_input_tensor\n    interpreter.set_tensor(tensor_index, image)\n  File \"/home/wuguangh/.conda/envs/tinyml/lib/python3.10/site-packages/tflite_runtime/interpreter.py\", line 720, in set_tensor\n    self._interpreter.SetTensor(tensor_index, value)\nValueError: Cannot set tensor: Got value of type FLOAT64 but expected type UINT8 for input 175, name: normalized_input_image_tensor \n"
      },
      "session_id": "phi4_9e98_psg_batch",
      "metadata": {
        "num_run": 25
      },
      "tags": [
        "ablation",
        "benchmark",
        "phi4:latest",
        "py_sketch_generator"
      ],
      "latency": 83.194,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-23-34-04-879147_chatcmpl-e5572022-65b8-45f9-b527-086f8ae0037c",
          "traceId": "d426111c",
          "type": "GENERATION",
          "name": "d426_psg_gen_attempt#1",
          "startTime": "2025-12-10T21:34:04.879000+00:00",
          "endTime": "2025-12-10T21:34:20.556000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 15677.0,
          "totalTokens": 1107,
          "costDetails": {},
          "environment": "default",
          "promptTokens": 245,
          "completionTokens": 862,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-23-34-23-509284_chatcmpl-d46b5558-7de5-4718-8995-2110030f82ac",
          "traceId": "d426111c",
          "type": "GENERATION",
          "name": "d426_psg_gen_attempt#2",
          "startTime": "2025-12-10T21:34:23.509000+00:00",
          "endTime": "2025-12-10T21:34:38.153000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 14644.0,
          "totalTokens": 1054,
          "costDetails": {},
          "environment": "default",
          "promptTokens": 245,
          "completionTokens": 809,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-23-34-41-141534_chatcmpl-1ef87def-9898-4dd8-8c49-821cd728c962",
          "traceId": "d426111c",
          "type": "GENERATION",
          "name": "d426_psg_gen_attempt#3",
          "startTime": "2025-12-10T21:34:41.141000+00:00",
          "endTime": "2025-12-10T21:34:54.624000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 13483.0,
          "totalTokens": 991,
          "costDetails": {},
          "environment": "default",
          "promptTokens": 245,
          "completionTokens": 746,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-23-34-57-580562_chatcmpl-583b8366-07a6-4cb7-8a69-a4a24186cde9",
          "traceId": "d426111c",
          "type": "GENERATION",
          "name": "d426_psg_gen_attempt#4",
          "startTime": "2025-12-10T21:34:57.580000+00:00",
          "endTime": "2025-12-10T21:35:11.023000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 13443.0,
          "totalTokens": 989,
          "costDetails": {},
          "environment": "default",
          "promptTokens": 245,
          "completionTokens": 744,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-23-35-11-178929_chatcmpl-67ea54f8-5b36-4412-8c1f-e2203d21a9ac",
          "traceId": "d426111c",
          "type": "GENERATION",
          "name": "d426_psg_gen_attempt#5",
          "startTime": "2025-12-10T21:35:11.178000+00:00",
          "endTime": "2025-12-10T21:35:27.928000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 16750.0,
          "totalTokens": 1170,
          "costDetails": {},
          "environment": "default",
          "promptTokens": 245,
          "completionTokens": 925,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "b68fa8a8-b25a-4bc0-8413-6c5ce9fa31c1",
          "traceId": "d426111c",
          "type": "SPAN",
          "name": "error_d4_psg_failure_signal_py_sketch_generator",
          "startTime": "2025-12-10T21:35:28.073000+00:00",
          "level": "ERROR",
          "statusMessage": "Failed. Last error: Max retries reached with failure. Last error from execution: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\nTraceback (most recent call last):\n  File \"/home/wuguangh/Projects/03.12/tinyml-autopilot-pm.03.12.2025/results/object_detection/sketches/tmp_20251210233527_psg_phi4:latest/tmp_20251210233527_psg_phi4:latest.py\", line 106, in <module>\n    main()\n  File \"/home/wuguangh/Projects/03.12/tinyml-autopilot-pm.03.12.2025/results/object_detection/sketches/tmp_20251210233527_psg_phi4:latest/tmp_20251210233527_psg_phi4:latest.py\", line 90, in main\n    set_input_tensor(interpreter, frame)\n  File \"/home/wuguangh/Projects/03.12/tinyml-autopilot-pm.03.12.2025/results/object_detection/sketches/tmp_20251210233527_psg_phi4:latest/tmp_20251210233527_psg_phi4:latest.py\", line 19, in set_input_tensor\n    interpreter.set_tensor(tensor_index, image)\n  File \"/home/wuguangh/.conda/envs/tinyml/lib/python3.10/site-packages/tflite_runtime/interpreter.py\", line 720, in set_tensor\n    self._interpreter.SetTensor(tensor_index, value)\nValueError: Cannot set tensor: Got value of type FLOAT64 but expected type UINT8 for input 175, name: normalized_input_image_tensor \n",
          "calculatedTotalCost": 0.0,
          "totalTokens": 0,
          "costDetails": {},
          "environment": "default",
          "promptTokens": 0,
          "completionTokens": 0,
          "endTime": null,
          "model": null,
          "modelParameters": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null,
          "latency": null
        }
      ],
      "createdAt": "2025-12-10T21:34:05.398Z",
      "updatedAt": "2025-12-10T21:35:33.522Z",
      "environment": "default"
    },
    {
      "id": "7dc278a1",
      "timestamp": "2025-12-10T21:32:09.923000+00:00",
      "name": "7dc2_py_sketch_generator",
      "input": null,
      "output": {
        "status": "failed",
        "last_code": "import cv2\nfrom tflite_runtime.interpreter import Interpreter\nimport numpy as np\n\n# Configuration parameters\nmodel_path  = \"models/ssd-mobilenet_v1/detect.tflite\"\nlabel_path  = \"models/ssd-mobilenet_v1/labelmap.txt\"\ninput_path  = \"data/object_detection/sheeps.mp4\"\noutput_path  = \"results/object_detection/test_results/sheeps_detections.mp4\"\nconfidence_threshold  = 0.5\n\n# Load labels\nwith open(label_path, 'r') as f:\n    labels = [line.strip() for line in f.readlines()]\n\n# Setup TFLite interpreter\ninterpreter = Interpreter(model_path=model_path)\ninterpreter.allocate_tensors()\n\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\n\ninput_shape = input_details[0]['shape']\ninput_type = input_details[0]['dtype']\n\n# Function to preprocess frame\ndef preprocess_frame(frame):\n    image_height, image_width, _ = frame.shape\n    resize_ratio = min(input_shape[1] / image_width, input_shape[2] / image_height)\n    target_size = (int(resize_ratio * image_width), int(resize_ratio * image_height))\n    \n    resized_image = cv2.resize(frame, target_size)\n    canvas = np.full(input_shape[1:], 128)\n    top_pad = int((input_shape[1] - target_size[0]) / 2)\n    bottom_pad = input_shape[1] - target_size[0] - top_pad\n    left_pad = int((input_shape[2] - target_size[1]) / 2)\n    right_pad = input_shape[2] - target_size[1] - left_pad\n    \n    canvas[top_pad:top_pad+target_size[0], left_pad:left_pad+target_size[1]] = resized_image\n    return cv2.cvtColor(canvas, cv2.COLOR_BGR2RGB)\n\n# Inference function\ndef run_inference(frame):\n    input_data = preprocess_frame(frame)\n    input_data = np.expand_dims(input_data, axis=0).astype(input_type)\n    \n    interpreter.set_tensor(input_details[0]['index'], input_data)\n    interpreter.invoke()\n    \n    boxes = interpreter.get_tensor(output_details[0]['index'])[0]\n    classes = interpreter.get_tensor(output_details[1]['index'])[0]\n    scores = interpreter.get_tensor(output_details[2]['index'])[0]\n\n    return boxes, classes, scores\n\n# Output handling\ndef draw_detections(frame, boxes, classes, scores):\n    image_height, image_width, _ = frame.shape\n    \n    for i in range(len(scores)):\n        if scores[i] >= confidence_threshold:\n            ymin, xmin, ymax, xmax = boxes[i]\n            (left, right, top, bottom) = (xmin * image_width, xmax * image_width,\n                                          ymin * image_height, ymax * image_height)\n            \n            label = f'{labels[int(classes[i])]}: {int(scores[i]*100)}%'\n            cv2.rectangle(frame, (int(left), int(top)), (int(right), int(bottom)), (10, 255, 0), 2)\n            cv2.putText(frame, label, (int(left), int(top-5)), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (10, 255, 0), 1)\n\n# Video processing\ncap = cv2.VideoCapture(input_path)\nfourcc = cv2.VideoWriter_fourcc(*'mp4v')\nout = cv2.VideoWriter(output_path, fourcc, 20.0, (int(cap.get(3)), int(cap.get(4))))\n\nwhile cap.isOpened():\n    ret, frame = cap.read()\n    if not ret:\n        break\n    \n    boxes, classes, scores = run_inference(frame)\n    draw_detections(frame, boxes, classes, scores)\n    \n    out.write(frame)\n\ncap.release()\nout.release()",
        "last_error": "Max retries reached with failure. Last error from execution: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\nTraceback (most recent call last):\n  File \"/home/wuguangh/Projects/03.12/tinyml-autopilot-pm.03.12.2025/results/object_detection/sketches/tmp_20251210233338_psg_phi4:latest/tmp_20251210233338_psg_phi4:latest.py\", line 80, in <module>\n    boxes, classes, scores = run_inference(frame)\n  File \"/home/wuguangh/Projects/03.12/tinyml-autopilot-pm.03.12.2025/results/object_detection/sketches/tmp_20251210233338_psg_phi4:latest/tmp_20251210233338_psg_phi4:latest.py\", line 44, in run_inference\n    input_data = preprocess_frame(frame)\n  File \"/home/wuguangh/Projects/03.12/tinyml-autopilot-pm.03.12.2025/results/object_detection/sketches/tmp_20251210233338_psg_phi4:latest/tmp_20251210233338_psg_phi4:latest.py\", line 39, in preprocess_frame\n    canvas[top_pad:top_pad+target_size[0], left_pad:left_pad+target_size[1]] = resized_image\nValueError: could not broadcast input array from shape (300,168,3) into shape (168,300,3)\n"
      },
      "session_id": "phi4_9e98_psg_batch",
      "metadata": {
        "num_run": 24
      },
      "tags": [
        "ablation",
        "benchmark",
        "phi4:latest",
        "py_sketch_generator"
      ],
      "latency": 88.913,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-23-32-09-924923_chatcmpl-a1c82368-d835-40f9-9b28-3b6dc946ee06",
          "traceId": "7dc278a1",
          "type": "GENERATION",
          "name": "7dc2_psg_gen_attempt#1",
          "startTime": "2025-12-10T21:32:09.924000+00:00",
          "endTime": "2025-12-10T21:32:27.532000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 17608.0,
          "totalTokens": 1212,
          "costDetails": {},
          "environment": "default",
          "promptTokens": 245,
          "completionTokens": 967,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-23-32-30-527490_chatcmpl-aa008dec-baff-440e-a931-477c4f643b9c",
          "traceId": "7dc278a1",
          "type": "GENERATION",
          "name": "7dc2_psg_gen_attempt#2",
          "startTime": "2025-12-10T21:32:30.527000+00:00",
          "endTime": "2025-12-10T21:32:46.339000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 15812.0,
          "totalTokens": 1119,
          "costDetails": {},
          "environment": "default",
          "promptTokens": 245,
          "completionTokens": 874,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-23-32-46-463655_chatcmpl-e13e4483-13c3-4c7d-ad78-c8e8b00110c3",
          "traceId": "7dc278a1",
          "type": "GENERATION",
          "name": "7dc2_psg_gen_attempt#3",
          "startTime": "2025-12-10T21:32:46.463000+00:00",
          "endTime": "2025-12-10T21:33:02.871000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 16408.0,
          "totalTokens": 1151,
          "costDetails": {},
          "environment": "default",
          "promptTokens": 245,
          "completionTokens": 906,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-23-33-05-849269_chatcmpl-276672a6-6c52-476f-b724-e5b7b52ae405",
          "traceId": "7dc278a1",
          "type": "GENERATION",
          "name": "7dc2_psg_gen_attempt#4",
          "startTime": "2025-12-10T21:33:05.849000+00:00",
          "endTime": "2025-12-10T21:33:21.087000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 15238.0,
          "totalTokens": 1088,
          "costDetails": {},
          "environment": "default",
          "promptTokens": 245,
          "completionTokens": 843,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-23-33-24-118786_chatcmpl-45fea586-65cf-4b6b-95ec-a6754f1ac679",
          "traceId": "7dc278a1",
          "type": "GENERATION",
          "name": "7dc2_psg_gen_attempt#5",
          "startTime": "2025-12-10T21:33:24.118000+00:00",
          "endTime": "2025-12-10T21:33:38.691000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 14573.0,
          "totalTokens": 1051,
          "costDetails": {},
          "environment": "default",
          "promptTokens": 245,
          "completionTokens": 806,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "2d46954e-900a-4f4c-ac7d-cc67aad5ea4b",
          "traceId": "7dc278a1",
          "type": "SPAN",
          "name": "error_7d_psg_failure_signal_py_sketch_generator",
          "startTime": "2025-12-10T21:33:38.837000+00:00",
          "level": "ERROR",
          "statusMessage": "Failed. Last error: Max retries reached with failure. Last error from execution: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\nTraceback (most recent call last):\n  File \"/home/wuguangh/Projects/03.12/tinyml-autopilot-pm.03.12.2025/results/object_detection/sketches/tmp_20251210233338_psg_phi4:latest/tmp_20251210233338_psg_phi4:latest.py\", line 80, in <module>\n    boxes, classes, scores = run_inference(frame)\n  File \"/home/wuguangh/Projects/03.12/tinyml-autopilot-pm.03.12.2025/results/object_detection/sketches/tmp_20251210233338_psg_phi4:latest/tmp_20251210233338_psg_phi4:latest.py\", line 44, in run_inference\n    input_data = preprocess_frame(frame)\n  File \"/home/wuguangh/Projects/03.12/tinyml-autopilot-pm.03.12.2025/results/object_detection/sketches/tmp_20251210233338_psg_phi4:latest/tmp_20251210233338_psg_phi4:latest.py\", line 39, in preprocess_frame\n    canvas[top_pad:top_pad+target_size[0], left_pad:left_pad+target_size[1]] = resized_image\nValueError: could not broadcast input array from shape (300,168,3) into shape (168,300,3)\n",
          "calculatedTotalCost": 0.0,
          "totalTokens": 0,
          "costDetails": {},
          "environment": "default",
          "promptTokens": 0,
          "completionTokens": 0,
          "endTime": null,
          "model": null,
          "modelParameters": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null,
          "latency": null
        }
      ],
      "createdAt": "2025-12-10T21:32:10.444Z",
      "updatedAt": "2025-12-10T21:33:44.478Z",
      "environment": "default"
    },
    {
      "id": "91c618be",
      "timestamp": "2025-12-10T21:31:04.016000+00:00",
      "name": "91c6_py_sketch_generator",
      "input": null,
      "output": {
        "status": "success",
        "sketch": "import cv2\nimport numpy as np\nimport tensorflow as tf\nfrom sklearn.metrics import average_precision_score\n\n# Configuration parameters\nmodel_path  = \"models/ssd-mobilenet_v1/detect.tflite\"\nlabel_path  = \"models/ssd-mobilenet_v1/labelmap.txt\"\ninput_path  = \"data/object_detection/sheeps.mp4\"\noutput_path  = \"results/object_detection/test_results/sheeps_detections.mp4\"\nconfidence_threshold  = 0.5\n\n# Phase 1: Setup\ndef load_labels(label_path):\n    with open(label_path, 'r') as file:\n        labels = [line.strip() for line in file.readlines()]\n    return labels\n\ndef load_tflite_interpreter(model_path):\n    interpreter = tf.lite.Interpreter(model_path=model_path)\n    interpreter.allocate_tensors()\n    return interpreter\n\n# Phase 2: Preprocessing\ndef preprocess_frame(frame, input_shape):\n    frame_resized = cv2.resize(frame, (input_shape[1], input_shape[0]))\n    input_data = np.expand_dims(frame_resized, axis=0).astype(np.float32)\n    input_data = tf.image.convert_image_dtype(input_data, dtype=tf.uint8) * 255\n    return input_data\n\n# Phase 3: Inference\ndef run_inference(interpreter, input_data):\n    input_details = interpreter.get_input_details()\n    output_details = interpreter.get_output_details()\n\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n    interpreter.invoke()\n\n    boxes = interpreter.get_tensor(output_details[0]['index'])[0]\n    classes = interpreter.get_tensor(output_details[1]['index'])[0].astype(np.int64)\n    scores = interpreter.get_tensor(output_details[2]['index'])[0]\n\n    return boxes, classes, scores\n\n# Phase 4: Output Handling\ndef draw_detections(frame, boxes, classes, scores, labels):\n    for i in range(len(scores)):\n        if scores[i] >= confidence_threshold:\n            ymin, xmin, ymax, xmax = boxes[i]\n            (left, right, top, bottom) = (xmin * frame.shape[1], xmax * frame.shape[1],\n                                          ymin * frame.shape[0], ymax * frame.shape[0])\n            cv2.rectangle(frame, (int(left), int(top)), (int(right), int(bottom)), (0, 255, 0), 2)\n            label = f'{labels[classes[i]]}: {scores[i]:.2f}'\n            cv2.putText(frame, label, (int(left), int(top) - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n\ndef compute_map(gt_boxes, pred_boxes):\n    # Placeholder for computing mAP\n    # Assuming ground truth boxes are available in gt_boxes and predicted boxes in pred_boxes\n    ap_scores = []\n    for class_id in range(len(labels)):\n        y_true = np.zeros((len(gt_boxes), len(pred_boxes)))\n        y_score = np.zeros(len(pred_boxes))\n        \n        for i, box in enumerate(gt_boxes):\n            if box['class'] == class_id:\n                y_true[i] = 1\n        \n        for j, pred_box in enumerate(pred_boxes):\n            if pred_box['class'] == class_id:\n                y_score[j] = pred_box['score']\n        \n        ap = average_precision_score(y_true, y_score)\n        ap_scores.append(ap)\n    \n    return np.mean(ap_scores)\n\n# Main execution\ndef main():\n    labels = load_labels(label_path)\n    interpreter = load_tflite_interpreter(model_path)\n    input_details = interpreter.get_input_details()\n    output_details = interpreter.get_output_details()\n\n    cap = cv2.VideoCapture(input_path)\n    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n    out = cv2.VideoWriter(output_path, fourcc, 20.0, (int(cap.get(3)), int(cap.get(4))))\n\n    while cap.isOpened():\n        ret, frame = cap.read()\n        if not ret:\n            break\n\n        input_data = preprocess_frame(frame, input_details[0]['shape'][1:3])\n        boxes, classes, scores = run_inference(interpreter, input_data)\n        \n        draw_detections(frame, boxes, classes, scores, labels)\n        out.write(frame)\n\n    cap.release()\n    out.release()\n\nif __name__ == '__main__':\n    main()"
      },
      "session_id": "phi4_9e98_psg_batch",
      "metadata": {
        "num_run": 23
      },
      "tags": [
        "ablation",
        "benchmark",
        "phi4:latest",
        "py_sketch_generator"
      ],
      "latency": 31.24,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-23-31-04-017464_chatcmpl-fad82f6e-d60f-4009-a569-03de170b3817",
          "traceId": "91c618be",
          "type": "GENERATION",
          "name": "91c6_psg_gen_attempt#1",
          "startTime": "2025-12-10T21:31:04.017000+00:00",
          "endTime": "2025-12-10T21:31:18.469000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 14452.0,
          "totalTokens": 1040,
          "costDetails": {},
          "environment": "default",
          "promptTokens": 245,
          "completionTokens": 795,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-23-31-18-598738_chatcmpl-a5882445-db86-4d50-a3e9-e1875598ca4a",
          "traceId": "91c618be",
          "type": "GENERATION",
          "name": "91c6_psg_gen_attempt#2",
          "startTime": "2025-12-10T21:31:18.598000+00:00",
          "endTime": "2025-12-10T21:31:35.257000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 16659.0,
          "totalTokens": 1165,
          "costDetails": {},
          "environment": "default",
          "promptTokens": 245,
          "completionTokens": 920,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        }
      ],
      "createdAt": "2025-12-10T21:31:04.536Z",
      "updatedAt": "2025-12-10T21:31:49.661Z",
      "environment": "default"
    },
    {
      "id": "a6e9d9a3",
      "timestamp": "2025-12-10T21:29:51.034000+00:00",
      "name": "a6e9_py_sketch_generator",
      "input": null,
      "output": {
        "status": "success",
        "sketch": "import cv2\nimport numpy as np\nimport tensorflow as tf\nfrom tflite_runtime.interpreter import Interpreter\n\n# Configuration parameters\nmodel_path  = \"models/ssd-mobilenet_v1/detect.tflite\"\nlabel_path  = \"models/ssd-mobilenet_v1/labelmap.txt\"\ninput_path  = \"data/object_detection/sheeps.mp4\"\noutput_path  = \"results/object_detection/test_results/sheeps_detections.mp4\"\nconfidence_threshold  = 0.5\n\n# Phase 1: Setup\ndef load_labels(label_file):\n    with open(label_file, 'r') as f:\n        return [line.strip() for line in f.readlines()]\n\ndef load_tflite_model(model_path):\n    interpreter = Interpreter(model_path=model_path)\n    interpreter.allocate_tensors()\n    return interpreter\n\nlabels = load_labels(label_path)\ninterpreter = load_tflite_model(model_path)\n\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\n\nheight, width, channel = input_details[0]['shape'][1:4]\n\n# Phase 2: Preprocessing\ndef preprocess_frame(frame):\n    frame_resized = cv2.resize(frame, (width, height))\n    input_data = np.expand_dims(frame_resized, axis=0)\n    return input_data\n\n# Phase 3: Inference\ndef run_inference(interpreter, input_data):\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n    interpreter.invoke()\n    boxes = interpreter.get_tensor(output_details[0]['index'])[0]\n    classes = interpreter.get_tensor(output_details[1]['index'])[0]\n    scores = interpreter.get_tensor(output_details[2]['index'])[0]\n    return boxes, classes, scores\n\n# Phase 4: Output Handling\ndef draw_detections(frame, boxes, classes, scores):\n    for i in range(len(scores)):\n        if scores[i] >= confidence_threshold:\n            ymin, xmin, ymax, xmax = boxes[i]\n            (left, right, top, bottom) = (xmin * frame.shape[1], xmax * frame.shape[1],\n                                          ymin * frame.shape[0], ymax * frame.shape[0])\n            cv2.rectangle(frame, (int(left), int(top)), (int(right), int(bottom)), (10, 255, 0), 2)\n            label = f\"{labels[int(classes[i])]}: {int(scores[i]*100)}%\"\n            cv2.putText(frame, label, (int(left), int(top-5)), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (10, 255, 0), 1)\n\ndef compute_map(ground_truths, detections):\n    # Dummy function for mAP computation\n    return 0.5  # Placeholder value\n\n# Main execution\ncap = cv2.VideoCapture(input_path)\nout = None\n\nwhile cap.isOpened():\n    ret, frame = cap.read()\n    if not ret:\n        break\n    \n    input_data = preprocess_frame(frame)\n    boxes, classes, scores = run_inference(interpreter, input_data)\n    draw_detections(frame, boxes, classes, scores)\n\n    if out is None:\n        fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n        out = cv2.VideoWriter(output_path, fourcc, 30.0, (frame.shape[1], frame.shape[0]))\n\n    out.write(frame)\n\ncap.release()\nout.release()\n\n# Compute mAP\nmap_score = compute_map([], [])  # Placeholder for ground truths and detections\nprint(f\"mAP Score: {map_score}\")"
      },
      "session_id": "phi4_9e98_psg_batch",
      "metadata": {
        "num_run": 22
      },
      "tags": [
        "ablation",
        "benchmark",
        "phi4:latest",
        "py_sketch_generator"
      ],
      "latency": 13.432,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-23-29-51-035529_chatcmpl-1cf22522-5401-4392-b3a7-6ddcf4fbc8c2",
          "traceId": "a6e9d9a3",
          "type": "GENERATION",
          "name": "a6e9_psg_gen_attempt#1",
          "startTime": "2025-12-10T21:29:51.035000+00:00",
          "endTime": "2025-12-10T21:30:04.467000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 13432.0,
          "totalTokens": 982,
          "costDetails": {},
          "environment": "default",
          "promptTokens": 245,
          "completionTokens": 737,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        }
      ],
      "createdAt": "2025-12-10T21:29:51.555Z",
      "updatedAt": "2025-12-10T21:30:44.234Z",
      "environment": "default"
    },
    {
      "id": "97d28964",
      "timestamp": "2025-12-10T21:28:46.098000+00:00",
      "name": "97d2_py_sketch_generator",
      "input": null,
      "output": {
        "status": "success",
        "sketch": "import cv2\nimport numpy as np\nimport tensorflow as tf\n\n# Configuration parameters\nmodel_path  = \"models/ssd-mobilenet_v1/detect.tflite\"\nlabel_path  = \"models/ssd-mobilenet_v1/labelmap.txt\"\ninput_path  = \"data/object_detection/sheeps.mp4\"\noutput_path  = \"results/object_detection/test_results/sheeps_detections.mp4\"\nconfidence_threshold  = 0.5\n\n# Setup\ninterpreter = tf.lite.Interpreter(model_path=model_path)\ninterpreter.allocate_tensors()\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\n\n# Load labels\nwith open(label_path, 'r') as file:\n    labels = [line.strip() for line in file.readlines()]\n\ndef preprocess_frame(frame):\n    input_shape = input_details[0]['shape']\n    frame_resized = cv2.resize(frame, (input_shape[1], input_shape[2]))\n    input_data = np.expand_dims(frame_resized, axis=0)\n    return input_data.astype(input_details[0]['dtype'])\n\ndef draw_detections(frame, boxes, classes, scores):\n    for i in range(len(scores)):\n        if scores[i] >= confidence_threshold:\n            ymin, xmin, ymax, xmax = boxes[i]\n            (left, right, top, bottom) = (xmin * frame.shape[1], xmax * frame.shape[1],\n                                          ymin * frame.shape[0], ymax * frame.shape[0])\n            cv2.rectangle(frame, (int(left), int(top)), (int(right), int(bottom)), (10, 255, 0), 2)\n            label = f'{labels[int(classes[i])]}: {scores[i]:.2f}'\n            cv2.putText(frame, label, (int(left), int(top - 5)), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (10, 255, 0), 2)\n\ndef compute_mAP(ground_truths, predictions):\n    # Placeholder for mAP computation logic\n    # Implement the actual mAP calculation based on ground truths and predictions\n    return 0.0\n\n# Preprocessing\ncap = cv2.VideoCapture(input_path)\nfps = cap.get(cv2.CAP_PROP_FPS)\nframe_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\nframe_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\nout = cv2.VideoWriter(output_path, cv2.VideoWriter_fourcc(*'mp4v'), fps, (frame_width, frame_height))\n\n# Inference\nwhile cap.isOpened():\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    input_data = preprocess_frame(frame)\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n    interpreter.invoke()\n\n    boxes = interpreter.get_tensor(output_details[0]['index'])[0]\n    classes = interpreter.get_tensor(output_details[1]['index'])[0]\n    scores = interpreter.get_tensor(output_details[2]['index'])[0]\n\n    draw_detections(frame, boxes, classes, scores)\n\n    out.write(frame)\n\ncap.release()\nout.release()\n\n# Output handling\n# Assuming ground_truths are available for mAP computation\nground_truths = []  # Placeholder: load or define your ground truths\npredictions = []    # Placeholder: collect predictions if needed\n\nmAP = compute_mAP(ground_truths, predictions)\nprint(f'mAP: {mAP}')\n\ncv2.destroyAllWindows()"
      },
      "session_id": "phi4_9e98_psg_batch",
      "metadata": {
        "num_run": 21
      },
      "tags": [
        "ablation",
        "benchmark",
        "phi4:latest",
        "py_sketch_generator"
      ],
      "latency": 31.342,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-23-28-46-099634_chatcmpl-c2e3b6e7-bb06-4b79-a2c1-8ab41365e916",
          "traceId": "97d28964",
          "type": "GENERATION",
          "name": "97d2_psg_gen_attempt#1",
          "startTime": "2025-12-10T21:28:46.099000+00:00",
          "endTime": "2025-12-10T21:29:00.663000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 14564.0,
          "totalTokens": 1045,
          "costDetails": {},
          "environment": "default",
          "promptTokens": 245,
          "completionTokens": 800,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-23-29-03-642536_chatcmpl-83927452-5916-4a76-8f1c-c568c0147292",
          "traceId": "97d28964",
          "type": "GENERATION",
          "name": "97d2_psg_gen_attempt#2",
          "startTime": "2025-12-10T21:29:03.642000+00:00",
          "endTime": "2025-12-10T21:29:17.441000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 13799.0,
          "totalTokens": 1008,
          "costDetails": {},
          "environment": "default",
          "promptTokens": 245,
          "completionTokens": 763,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        }
      ],
      "createdAt": "2025-12-10T21:28:46.619Z",
      "updatedAt": "2025-12-10T21:29:31.273Z",
      "environment": "default"
    },
    {
      "id": "104c98c7",
      "timestamp": "2025-12-10T21:27:02.176000+00:00",
      "name": "104c_py_sketch_generator",
      "input": null,
      "output": {
        "status": "success",
        "sketch": "import cv2\nfrom tflite_runtime.interpreter import Interpreter\nimport numpy as np\n\n# Configuration parameters\nmodel_path  = \"models/ssd-mobilenet_v1/detect.tflite\"\nlabel_path  = \"models/ssd-mobilenet_v1/labelmap.txt\"\ninput_path  = \"data/object_detection/sheeps.mp4\"\noutput_path  = \"results/object_detection/test_results/sheeps_detections.mp4\"\nconfidence_threshold  = 0.5\n\n# Setup phase\ndef load_labels(path):\n    with open(path, 'r') as f:\n        return {i: line.strip() for i, line in enumerate(f.readlines())}\n\ndef load_interpreter(model_path):\n    interpreter = Interpreter(model_path=model_path)\n    interpreter.allocate_tensors()\n    return interpreter\n\nlabels = load_labels(label_path)\ninterpreter = load_interpreter(model_path)\n\n# Preprocessing phase\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\n\nheight, width = input_details[0]['shape'][1:3]\nfloating_model = input_details[0]['dtype'] == np.float32\n\ndef preprocess_frame(frame):\n    frame_resized = cv2.resize(frame, (width, height))\n    input_data = np.expand_dims(frame_resized, axis=0)\n    if floating_model:\n        input_data = (np.float32(input_data) - 127.5) / 127.5\n    return input_data\n\n# Inference phase\ndef run_inference(frame):\n    interpreter.set_tensor(input_details[0]['index'], frame)\n    interpreter.invoke()\n    boxes = interpreter.get_tensor(output_details[0]['index'])[0]\n    classes = interpreter.get_tensor(output_details[1]['index'])[0]\n    scores = interpreter.get_tensor(output_details[2]['index'])[0]\n    \n    results = []\n    for i in range(len(scores)):\n        if scores[i] >= confidence_threshold:\n            result = {\n                'box': boxes[i],\n                'class_id': int(classes[i]),\n                'score': scores[i]\n            }\n            results.append(result)\n    return results\n\n# Output handling phase\ndef draw_boxes(frame, detections):\n    for detection in detections:\n        ymin, xmin, ymax, xmax = detection['box']\n        (left, right, top, bottom) = (xmin * width, xmax * width, ymin * height, ymax * height)\n\n        # Draw rectangle and label on the frame\n        cv2.rectangle(frame, (int(left), int(top)), (int(right), int(bottom)), (0, 255, 0), 2)\n        text = f\"{labels[detection['class_id']]}: {int(detection['score']*100)}%\"\n        cv2.putText(frame, text, (int(left), int(top-5)), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n\ndef main():\n    cap = cv2.VideoCapture(input_path)\n    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n    out = cv2.VideoWriter(output_path, fourcc, 30.0, (int(cap.get(3)), int(cap.get(4))))\n\n    while cap.isOpened():\n        ret, frame = cap.read()\n        if not ret:\n            break\n\n        input_data = preprocess_frame(frame)\n        detections = run_inference(input_data)\n        draw_boxes(frame, detections)\n\n        out.write(frame)\n\n    cap.release()\n    out.release()\n\nif __name__ == '__main__':\n    main()"
      },
      "session_id": "phi4_9e98_psg_batch",
      "metadata": {
        "num_run": 20
      },
      "tags": [
        "ablation",
        "benchmark",
        "phi4:latest",
        "py_sketch_generator"
      ],
      "latency": 46.735,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-23-27-02-177867_chatcmpl-ad39f4d8-deb5-4808-911b-50ec3afb2421",
          "traceId": "104c98c7",
          "type": "GENERATION",
          "name": "104c_psg_gen_attempt#1",
          "startTime": "2025-12-10T21:27:02.177000+00:00",
          "endTime": "2025-12-10T21:27:16.410000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 14233.0,
          "totalTokens": 1028,
          "costDetails": {},
          "environment": "default",
          "promptTokens": 245,
          "completionTokens": 783,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-23-27-16-559589_chatcmpl-8c614072-78ab-4447-9706-3c6995a919bb",
          "traceId": "104c98c7",
          "type": "GENERATION",
          "name": "104c_psg_gen_attempt#2",
          "startTime": "2025-12-10T21:27:16.559000+00:00",
          "endTime": "2025-12-10T21:27:32.723000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 16164.0,
          "totalTokens": 1137,
          "costDetails": {},
          "environment": "default",
          "promptTokens": 245,
          "completionTokens": 892,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-23-27-35-776062_chatcmpl-31b19aeb-8429-4a81-b237-50280641dbf1",
          "traceId": "104c98c7",
          "type": "GENERATION",
          "name": "104c_psg_gen_attempt#3",
          "startTime": "2025-12-10T21:27:35.776000+00:00",
          "endTime": "2025-12-10T21:27:48.912000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 13136.0,
          "totalTokens": 971,
          "costDetails": {},
          "environment": "default",
          "promptTokens": 245,
          "completionTokens": 726,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        }
      ],
      "createdAt": "2025-12-10T21:27:02.696Z",
      "updatedAt": "2025-12-10T21:28:25.837Z",
      "environment": "default"
    },
    {
      "id": "afb38402",
      "timestamp": "2025-12-10T21:25:50.227000+00:00",
      "name": "afb3_py_sketch_generator",
      "input": null,
      "output": {
        "status": "success",
        "sketch": "import cv2\nfrom tflite_runtime.interpreter import Interpreter\nimport numpy as np\n\n# Configuration parameters\nmodel_path  = \"models/ssd-mobilenet_v1/detect.tflite\"\nlabel_path  = \"models/ssd-mobilenet_v1/labelmap.txt\"\ninput_path  = \"data/object_detection/sheeps.mp4\"\noutput_path  = \"results/object_detection/test_results/sheeps_detections.mp4\"\nconfidence_threshold  = 0.5\n\n# Phase 1: Setup\ndef load_labels(label_path):\n    with open(label_path, 'r') as file:\n        return [line.strip() for line in file.readlines()]\n\ndef load_tflite_model(model_path):\n    interpreter = Interpreter(model_path=model_path)\n    interpreter.allocate_tensors()\n    return interpreter\n\nlabels = load_labels(label_path)\ninterpreter = load_tflite_model(model_path)\n\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\n\n# Phase 2: Preprocessing\ndef preprocess_frame(frame, input_size):\n    frame_resized = cv2.resize(frame, (input_size[1], input_size[0]))\n    input_data = np.expand_dims(frame_resized, axis=0)\n    return input_data.astype(input_details[0]['dtype'])\n\ndef get_output(interpreter, score_threshold):\n    boxes = interpreter.get_tensor(output_details[0]['index'])[0]  # Bounding box coordinates of detected objects\n    classes = interpreter.get_tensor(output_details[1]['index'])[0]  # Class index of detected objects\n    scores = interpreter.get_tensor(output_details[2]['index'])[0]  # Confidence of detected objects\n\n    results = []\n    for i in range(len(scores)):\n        if scores[i] >= score_threshold:\n            result = {\n                'bounding_box': boxes[i],\n                'class_id': classes[i],\n                'score': scores[i]\n            }\n            results.append(result)\n    return results\n\n# Phase 3: Inference\ndef draw_detections(frame, detections):\n    for detection in detections:\n        bbox = detection['bounding_box']\n        class_id = int(detection['class_id'])\n        score = detection['score']\n\n        ymin, xmin, ymax, xmax = bbox\n        (left, right, top, bottom) = (xmin * frame.shape[1], xmax * frame.shape[1],\n                                      ymin * frame.shape[0], ymax * frame.shape[0])\n        \n        cv2.rectangle(frame, (int(left), int(top)), (int(right), int(bottom)), (10, 255, 0), 2)\n        label = f'{labels[class_id]}: {int(score * 100)}%'\n        cv2.putText(frame, label, (int(left), int(top - 5)), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (10, 255, 0), 2)\n\ndef compute_map(predictions, ground_truths):\n    # Placeholder function for mAP computation\n    # Implement actual mAP calculation based on predictions and ground truths if needed\n    pass\n\n# Phase 4: Output Handling\ncap = cv2.VideoCapture(input_path)\nframe_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\nframe_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\noutput_video = cv2.VideoWriter(output_path, cv2.VideoWriter_fourcc(*'mp4v'), 30, (frame_width, frame_height))\n\nwhile cap.isOpened():\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    input_data = preprocess_frame(frame, interpreter.get_input_details()[0]['shape'][1:3])\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n    interpreter.invoke()\n\n    detections = get_output(interpreter, confidence_threshold)\n    draw_detections(frame, detections)\n\n    output_video.write(frame)\n\ncap.release()\noutput_video.release()\ncv2.destroyAllWindows()"
      },
      "session_id": "phi4_9e98_psg_batch",
      "metadata": {
        "num_run": 19
      },
      "tags": [
        "ablation",
        "benchmark",
        "phi4:latest",
        "py_sketch_generator"
      ],
      "latency": 14.577,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-23-25-50-228494_chatcmpl-407477b8-5b5d-4e6e-a26b-53e8ac06fb67",
          "traceId": "afb38402",
          "type": "GENERATION",
          "name": "afb3_psg_gen_attempt#1",
          "startTime": "2025-12-10T21:25:50.228000+00:00",
          "endTime": "2025-12-10T21:26:04.805000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 14577.0,
          "totalTokens": 1047,
          "costDetails": {},
          "environment": "default",
          "promptTokens": 245,
          "completionTokens": 802,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        }
      ],
      "createdAt": "2025-12-10T21:25:50.747Z",
      "updatedAt": "2025-12-10T21:26:41.872Z",
      "environment": "default"
    },
    {
      "id": "c969618d",
      "timestamp": "2025-12-10T21:23:44.211000+00:00",
      "name": "c969_py_sketch_generator",
      "input": null,
      "output": {
        "status": "failed",
        "last_code": "import cv2\nimport numpy as np\nimport tensorflow as tf\nfrom collections import defaultdict\nfrom sklearn.metrics import average_precision_score\n\n# Configuration parameters\nmodel_path  = \"models/ssd-mobilenet_v1/detect.tflite\"\nlabel_path  = \"models/ssd-mobilenet_v1/labelmap.txt\"\ninput_path  = \"data/object_detection/sheeps.mp4\"\noutput_path  = \"results/object_detection/test_results/sheeps_detections.mp4\"\nconfidence_threshold  = 0.5\n\n# Phase 1: Setup\ndef load_labels(label_file):\n    with open(label_file, 'r') as f:\n        return [line.strip() for line in f.readlines()]\n\ndef create_interpreter(model_path):\n    interpreter = tf.lite.Interpreter(model_path=model_path)\n    interpreter.allocate_tensors()\n    return interpreter\n\n# Phase 2: Preprocessing\ndef preprocess_frame(frame, input_size):\n    frame_resized = cv2.resize(frame, input_size)\n    input_data = np.expand_dims(frame_resized, axis=0).astype(np.float32)\n    return input_data\n\n# Phase 3: Inference\ndef run_inference(interpreter, input_data):\n    input_details = interpreter.get_input_details()\n    output_details = interpreter.get_output_details()\n\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n\n    interpreter.invoke()\n\n    boxes = interpreter.get_tensor(output_details[0]['index'])[0]\n    classes = interpreter.get_tensor(output_details[1]['index'])[0]\n    scores = interpreter.get_tensor(output_details[2]['index'])[0]\n\n    return boxes, classes, scores\n\n# Phase 4: Output Handling\ndef draw_detections(frame, boxes, classes, scores, labels):\n    for i in range(len(scores)):\n        if scores[i] > confidence_threshold:\n            ymin, xmin, ymax, xmax = boxes[i]\n            (left, right, top, bottom) = (xmin * frame.shape[1], xmax * frame.shape[1],\n                                          ymin * frame.shape[0], ymax * frame.shape[0])\n            cv2.rectangle(frame, (int(left), int(top)), (int(right), int(bottom)), (255, 0, 0), 2)\n            label = f\"{labels[int(classes[i])]}: {scores[i]:.2f}\"\n            cv2.putText(frame, label, (int(left), int(top) - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 2)\n\ndef compute_mAP(gts, preds):\n    all_aps = []\n    for class_id in gts.keys():\n        gt_boxes = gts[class_id]\n        pred_boxes = preds[class_id]\n\n        if len(gt_boxes) == 0 and len(pred_boxes) == 0:\n            continue\n\n        iou_thresholds = np.linspace(0.5, 0.95, 10)\n        aps = []\n        for threshold in iou_thresholds:\n            tp = fp = 0\n            matched_gt = set()\n            for pred_box in pred_boxes:\n                best_iou = 0\n                best_gt_idx = -1\n                for idx, gt_box in enumerate(gt_boxes):\n                    if idx in matched_gt:\n                        continue\n\n                    iou = compute_iou(pred_box[:4], gt_box[:4])\n                    if iou > best_iou:\n                        best_iou = iou\n                        best_gt_idx = idx\n\n                if best_iou >= threshold:\n                    tp += 1\n                    matched_gt.add(best_gt_idx)\n                else:\n                    fp += 1\n\n            fn = len(gt_boxes) - len(matched_gt)\n            precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n            recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n            aps.append(precision)\n\n        all_aps.append(np.mean(aps))\n\n    return np.mean(all_aps) if all_aps else 0\n\ndef compute_iou(box1, box2):\n    ymin1, xmin1, ymax1, xmax1 = box1\n    ymin2, xmin2, ymax2, xmax2 = box2\n\n    intersect_ymin = max(ymin1, ymin2)\n    intersect_xmin = max(xmin1, xmin2)\n    intersect_ymax = min(ymax1, ymax2)\n    intersect_xmax = min(xmax1, xmax2)\n\n    intersect_area = max(0, intersect_ymax - intersect_ymin) * max(0, intersect_xmax - intersect_xmin)\n\n    area1 = (xmax1 - xmin1) * (ymax1 - ymin1)\n    area2 = (xmax2 - xmin2) * (ymax2 - ymin2)\n\n    union_area = area1 + area2 - intersect_area\n\n    return intersect_area / union_area if union_area > 0 else 0\n\ndef main():\n    labels = load_labels(label_path)\n    interpreter = create_interpreter(model_path)\n    input_details = interpreter.get_input_details()\n    input_size = input_details[0]['shape'][1:3]\n\n    cap = cv2.VideoCapture(input_path)\n    out = None\n    fps = int(cap.get(cv2.CAP_PROP_FPS))\n    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n\n    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n    out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n\n    gts = defaultdict(list)\n    preds = defaultdict(list)\n\n    frame_idx = 0\n    while cap.isOpened():\n        ret, frame = cap.read()\n        if not ret:\n            break\n\n        input_data = preprocess_frame(frame, input_size)\n        boxes, classes, scores = run_inference(interpreter, input_data)\n        \n        # Assuming ground truth data is available for mAP computation\n        # This part should be replaced with actual ground truth extraction logic\n        # gts[class_id].append([ymin, xmin, ymax, xmax])\n\n        preds_classes = classes[scores > confidence_threshold]\n        preds_boxes = boxes[scores > confidence_threshold]\n\n        for class_id in preds_classes:\n            preds[int(class_id)].append(preds_boxes[classes == class_id][0])\n\n        draw_detections(frame, boxes, classes, scores, labels)\n        out.write(frame)\n\n    cap.release()\n    out.release()\n\n    mAP = compute_mAP(gts, preds)\n    print(f\"Mean Average Precision (mAP): {mAP:.4f}\")\n\nif __name__ == \"__main__\":\n    main()",
        "last_error": "Max retries reached with failure. Last error from execution: 2025-12-10 23:25:21.631649: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n2025-12-10 23:25:21.635025: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n2025-12-10 23:25:21.646465: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2025-12-10 23:25:21.664685: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2025-12-10 23:25:21.670135: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n2025-12-10 23:25:21.683707: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\nTo enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n2025-12-10 23:25:22.489371: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\nINFO: Created TensorFlow Lite XNNPACK delegate for CPU.\nTraceback (most recent call last):\n  File \"/home/wuguangh/Projects/03.12/tinyml-autopilot-pm.03.12.2025/results/object_detection/sketches/tmp_20251210232521_psg_phi4:latest/tmp_20251210232521_psg_phi4:latest.py\", line 162, in <module>\n    main()\n  File \"/home/wuguangh/Projects/03.12/tinyml-autopilot-pm.03.12.2025/results/object_detection/sketches/tmp_20251210232521_psg_phi4:latest/tmp_20251210232521_psg_phi4:latest.py\", line 140, in main\n    boxes, classes, scores = run_inference(interpreter, input_data)\n  File \"/home/wuguangh/Projects/03.12/tinyml-autopilot-pm.03.12.2025/results/object_detection/sketches/tmp_20251210232521_psg_phi4:latest/tmp_20251210232521_psg_phi4:latest.py\", line 35, in run_inference\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n  File \"/home/wuguangh/.conda/envs/tinyml/lib/python3.10/site-packages/tensorflow/lite/python/interpreter.py\", line 732, in set_tensor\n    self._interpreter.SetTensor(tensor_index, value)\nValueError: Cannot set tensor: Got value of type FLOAT32 but expected type UINT8 for input 175, name: normalized_input_image_tensor \n"
      },
      "session_id": "phi4_9e98_psg_batch",
      "metadata": {
        "num_run": 18
      },
      "tags": [
        "ablation",
        "benchmark",
        "phi4:latest",
        "py_sketch_generator"
      ],
      "latency": 100.426,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-23-23-44-212061_chatcmpl-eea9894c-b797-4c45-889b-18b4305d0039",
          "traceId": "c969618d",
          "type": "GENERATION",
          "name": "c969_psg_gen_attempt#1",
          "startTime": "2025-12-10T21:23:44.212000+00:00",
          "endTime": "2025-12-10T21:23:57.877000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 13665.0,
          "totalTokens": 997,
          "costDetails": {},
          "environment": "default",
          "promptTokens": 245,
          "completionTokens": 752,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-23-23-58-023626_chatcmpl-328dc407-5396-41ae-9480-321d8cfa82f0",
          "traceId": "c969618d",
          "type": "GENERATION",
          "name": "c969_psg_gen_attempt#2",
          "startTime": "2025-12-10T21:23:58.023000+00:00",
          "endTime": "2025-12-10T21:24:14.676000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 16653.0,
          "totalTokens": 1164,
          "costDetails": {},
          "environment": "default",
          "promptTokens": 245,
          "completionTokens": 919,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-23-24-17-924879_chatcmpl-eca02c66-2e16-4d12-a60e-e240e501ce68",
          "traceId": "c969618d",
          "type": "GENERATION",
          "name": "c969_psg_gen_attempt#3",
          "startTime": "2025-12-10T21:24:17.924000+00:00",
          "endTime": "2025-12-10T21:24:34.300000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 16376.0,
          "totalTokens": 1149,
          "costDetails": {},
          "environment": "default",
          "promptTokens": 245,
          "completionTokens": 904,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-23-24-34-450172_chatcmpl-dd69737b-9d51-4fca-956a-3e9b75aa7862",
          "traceId": "c969618d",
          "type": "GENERATION",
          "name": "c969_psg_gen_attempt#4",
          "startTime": "2025-12-10T21:24:34.450000+00:00",
          "endTime": "2025-12-10T21:24:52.791000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 18341.0,
          "totalTokens": 1257,
          "costDetails": {},
          "environment": "default",
          "promptTokens": 245,
          "completionTokens": 1012,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-23-24-55-729384_chatcmpl-d301a09b-e52c-433e-9c89-bafcf125af4a",
          "traceId": "c969618d",
          "type": "GENERATION",
          "name": "c969_psg_gen_attempt#5",
          "startTime": "2025-12-10T21:24:55.729000+00:00",
          "endTime": "2025-12-10T21:25:21.313000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 25584.0,
          "totalTokens": 1646,
          "costDetails": {},
          "environment": "default",
          "promptTokens": 245,
          "completionTokens": 1401,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "3fea9589-90ea-4264-9a9f-0329d6f8c092",
          "traceId": "c969618d",
          "type": "SPAN",
          "name": "error_c9_psg_failure_signal_py_sketch_generator",
          "startTime": "2025-12-10T21:25:24.638000+00:00",
          "level": "ERROR",
          "statusMessage": "Failed. Last error: Max retries reached with failure. Last error from execution: 2025-12-10 23:25:21.631649: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n2025-12-10 23:25:21.635025: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n2025-12-10 23:25:21.646465: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2025-12-10 23:25:21.664685: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2025-12-10 23:25:21.670135: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n2025-12-10 23:25:21.683707: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\nTo enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n2025-12-10 23:25:22.489371: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\nINFO: Created TensorFlow Lite XNNPACK delegate for CPU.\nTraceback (most recent call last):\n  File \"/home/wuguangh/Projects/03.12/tinyml-autopilot-pm.03.12.2025/results/object_detection/sketches/tmp_20251210232521_psg_phi4:latest/tmp_20251210232521_psg_phi4:latest.py\", line 162, in <module>\n    main()\n  File \"/home/wuguangh/Projects/03.12/tinyml-autopilot-pm.03.12.2025/results/object_detection/sketches/tmp_20251210232521_psg_phi4:latest/tmp_20251210232521_psg_phi4:latest.py\", line 140, in main\n    boxes, classes, scores = run_inference(interpreter, input_data)\n  File \"/home/wuguangh/Projects/03.12/tinyml-autopilot-pm.03.12.2025/results/object_detection/sketches/tmp_20251210232521_psg_phi4:latest/tmp_20251210232521_psg_phi4:latest.py\", line 35, in run_inference\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n  File \"/home/wuguangh/.conda/envs/tinyml/lib/python3.10/site-packages/tensorflow/lite/python/interpreter.py\", line 732, in set_tensor\n    self._interpreter.SetTensor(tensor_index, value)\nValueError: Cannot set tensor: Got value of type FLOAT32 but expected type UINT8 for input 175, name: normalized_input_image_tensor \n",
          "calculatedTotalCost": 0.0,
          "totalTokens": 0,
          "costDetails": {},
          "environment": "default",
          "promptTokens": 0,
          "completionTokens": 0,
          "endTime": null,
          "model": null,
          "modelParameters": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null,
          "latency": null
        }
      ],
      "createdAt": "2025-12-10T21:23:44.731Z",
      "updatedAt": "2025-12-10T21:25:29.908Z",
      "environment": "default"
    },
    {
      "id": "bec62906",
      "timestamp": "2025-12-10T21:22:00.288000+00:00",
      "name": "bec6_py_sketch_generator",
      "input": null,
      "output": {
        "status": "failed",
        "last_code": "import cv2\nimport numpy as np\nimport tflite_runtime.interpreter as tflite\nfrom google.protobuf import text_format\nfrom object_detection.utils import visualization_utils as vis_util\nfrom object_detection.utils import label_map_util\n\n# Configuration parameters\nmodel_path  = \"models/ssd-mobilenet_v1/detect.tflite\"\nlabel_path  = \"models/ssd-mobilenet_v1/labelmap.txt\"\ninput_path  = \"data/object_detection/sheeps.mp4\"\noutput_path  = \"results/object_detection/test_results/sheeps_detections.mp4\"\nconfidence_threshold  = 0.5\n\n# Phase 1: Setup\ndef load_labels(label_file):\n    label_map = label_map_util.load_labelmap(label_file)\n    categories = label_map_util.convert_label_map_to_categories(\n        label_map, max_num_classes=90, use_display_name=True)\n    category_index = label_map_util.create_category_index(categories)\n    return category_index\n\ndef load_interpreter(model_path):\n    interpreter = tflite.Interpreter(model_path=model_path)\n    interpreter.allocate_tensors()\n    input_details = interpreter.get_input_details()\n    output_details = interpreter.get_output_details()\n    return interpreter, input_details, output_details\n\n# Phase 2: Preprocessing\ndef preprocess_frame(frame, input_shape):\n    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n    frame_resized = cv2.resize(frame_rgb, (input_shape[1], input_shape[0]))\n    input_data = np.expand_dims(frame_resized, axis=0).astype(np.float32)\n    return input_data\n\n# Phase 3: Inference\ndef run_inference(interpreter, input_data):\n    interpreter.set_tensor(interpreter.get_input_details()[0]['index'], input_data)\n    interpreter.invoke()\n    boxes = interpreter.get_tensor(interpreter.get_output_details()[0]['index'])[0]\n    classes = interpreter.get_tensor(interpreter.get_output_details()[1]['index'])[0]\n    scores = interpreter.get_tensor(interpreter.get_output_details()[2]['index'])[0]\n    return boxes, classes, scores\n\n# Phase 4: Output Handling\ndef draw_boxes(frame, boxes, classes, scores, category_index, confidence_threshold):\n    vis_util.visualize_boxes_and_labels_on_image_array(\n        frame,\n        np.squeeze(boxes),\n        np.squeeze(classes).astype(np.int32),\n        np.squeeze(scores),\n        category_index,\n        use_normalized_coordinates=True,\n        line_thickness=8,\n        min_score_thresh=confidence_threshold)\n\ndef main():\n    # Setup\n    interpreter, input_details, output_details = load_interpreter(model_path)\n    category_index = load_labels(label_path)\n    input_shape = input_details[0]['shape'][1:3]\n\n    # Video capture and writer setup\n    cap = cv2.VideoCapture(input_path)\n    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n    out = cv2.VideoWriter(output_path, fourcc, 20.0, (int(cap.get(3)), int(cap.get(4))))\n\n    while cap.isOpened():\n        ret, frame = cap.read()\n        if not ret:\n            break\n\n        # Preprocessing\n        input_data = preprocess_frame(frame, input_shape)\n\n        # Inference\n        boxes, classes, scores = run_inference(interpreter, input_data)\n\n        # Output Handling\n        draw_boxes(frame, boxes, classes, scores, category_index, confidence_threshold)\n        \n        out.write(frame)\n        cv2.imshow('Object Detection', frame)\n        if cv2.waitKey(1) & 0xFF == ord('q'):\n            break\n\n    cap.release()\n    out.release()\n    cv2.destroyAllWindows()\n\nif __name__ == '__main__':\n    main()",
        "last_error": "Max retries reached with failure. Last error from execution: Traceback (most recent call last):\n  File \"/home/wuguangh/Projects/03.12/tinyml-autopilot-pm.03.12.2025/results/object_detection/sketches/tmp_20251210232318_psg_phi4:latest/tmp_20251210232318_psg_phi4:latest.py\", line 5, in <module>\n    from object_detection.utils import visualization_utils as vis_util\nModuleNotFoundError: No module named 'object_detection'\n"
      },
      "session_id": "phi4_9e98_psg_batch",
      "metadata": {
        "num_run": 17
      },
      "tags": [
        "ablation",
        "benchmark",
        "phi4:latest",
        "py_sketch_generator"
      ],
      "latency": 78.087,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-23-22-00-289337_chatcmpl-7a855bc9-d16c-4d2b-b467-f748089e081d",
          "traceId": "bec62906",
          "type": "GENERATION",
          "name": "bec6_psg_gen_attempt#1",
          "startTime": "2025-12-10T21:22:00.289000+00:00",
          "endTime": "2025-12-10T21:22:15.810000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 15521.0,
          "totalTokens": 1099,
          "costDetails": {},
          "environment": "default",
          "promptTokens": 245,
          "completionTokens": 854,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-23-22-15-959294_chatcmpl-58c0d162-76fe-408c-8ef8-d07622a8579b",
          "traceId": "bec62906",
          "type": "GENERATION",
          "name": "bec6_psg_gen_attempt#2",
          "startTime": "2025-12-10T21:22:15.959000+00:00",
          "endTime": "2025-12-10T21:22:28.246000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 12287.0,
          "totalTokens": 925,
          "costDetails": {},
          "environment": "default",
          "promptTokens": 245,
          "completionTokens": 680,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-23-22-28-379850_chatcmpl-67df2683-3f00-45df-9016-3d2e9f767b09",
          "traceId": "bec62906",
          "type": "GENERATION",
          "name": "bec6_psg_gen_attempt#3",
          "startTime": "2025-12-10T21:22:28.379000+00:00",
          "endTime": "2025-12-10T21:22:42.564000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 14185.0,
          "totalTokens": 1029,
          "costDetails": {},
          "environment": "default",
          "promptTokens": 245,
          "completionTokens": 784,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-23-22-46-667365_chatcmpl-8f78e7ea-4b92-4d98-b933-1c1e63a69f0c",
          "traceId": "bec62906",
          "type": "GENERATION",
          "name": "bec6_psg_gen_attempt#4",
          "startTime": "2025-12-10T21:22:46.667000+00:00",
          "endTime": "2025-12-10T21:23:01.184000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 14517.0,
          "totalTokens": 1048,
          "costDetails": {},
          "environment": "default",
          "promptTokens": 245,
          "completionTokens": 803,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-23-23-04-341421_chatcmpl-d10ec67c-8319-487f-9ec4-a87edfe434d2",
          "traceId": "bec62906",
          "type": "GENERATION",
          "name": "bec6_psg_gen_attempt#5",
          "startTime": "2025-12-10T21:23:04.341000+00:00",
          "endTime": "2025-12-10T21:23:18.239000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 13898.0,
          "totalTokens": 1014,
          "costDetails": {},
          "environment": "default",
          "promptTokens": 245,
          "completionTokens": 769,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "72e4d1cf-4441-4bdd-9ca7-e8aea5ec41c1",
          "traceId": "bec62906",
          "type": "SPAN",
          "name": "error_be_psg_failure_signal_py_sketch_generator",
          "startTime": "2025-12-10T21:23:18.376000+00:00",
          "level": "ERROR",
          "statusMessage": "Failed. Last error: Max retries reached with failure. Last error from execution: Traceback (most recent call last):\n  File \"/home/wuguangh/Projects/03.12/tinyml-autopilot-pm.03.12.2025/results/object_detection/sketches/tmp_20251210232318_psg_phi4:latest/tmp_20251210232318_psg_phi4:latest.py\", line 5, in <module>\n    from object_detection.utils import visualization_utils as vis_util\nModuleNotFoundError: No module named 'object_detection'\n",
          "calculatedTotalCost": 0.0,
          "totalTokens": 0,
          "costDetails": {},
          "environment": "default",
          "promptTokens": 0,
          "completionTokens": 0,
          "endTime": null,
          "model": null,
          "modelParameters": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null,
          "latency": null
        }
      ],
      "createdAt": "2025-12-10T21:22:00.807Z",
      "updatedAt": "2025-12-10T21:23:23.964Z",
      "environment": "default"
    },
    {
      "id": "d84fe193",
      "timestamp": "2025-12-10T21:20:01.280000+00:00",
      "name": "d84f_py_sketch_generator",
      "input": null,
      "output": {
        "status": "success",
        "sketch": "import cv2\nimport numpy as np\nimport tensorflow as tf\n\n# Configuration parameters\nmodel_path  = \"models/ssd-mobilenet_v1/detect.tflite\"\nlabel_path  = \"models/ssd-mobilenet_v1/labelmap.txt\"\ninput_path  = \"data/object_detection/sheeps.mp4\"\noutput_path  = \"results/object_detection/test_results/sheeps_detections.mp4\"\nconfidence_threshold  = 0.5\n\n# Phase 1: Setup\ndef load_labels(label_file):\n    with open(label_file, 'r', encoding='utf-8') as f:\n        return {i: line.strip() for i, line in enumerate(f.readlines())}\n\nlabels = load_labels(label_path)\ninterpreter = tf.lite.Interpreter(model_path=model_path)\ninterpreter.allocate_tensors()\n\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\n_, input_height, input_width, _ = input_details[0]['shape']\n\n# Phase 2: Preprocessing\ndef preprocess_frame(frame):\n    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n    frame_resized = cv2.resize(frame_rgb, (input_width, input_height))\n    return np.expand_dims(frame_resized, axis=0)\n\n# Phase 3: Inference\ndef run_inference(interpreter, frame):\n    interpreter.set_tensor(input_details[0]['index'], frame)\n    interpreter.invoke()\n    \n    boxes = interpreter.get_tensor(output_details[0]['index'])[0]\n    classes = interpreter.get_tensor(output_details[1]['index'])[0]\n    scores = interpreter.get_tensor(output_details[2]['index'])[0]\n    \n    return boxes, classes, scores\n\n# Phase 4: Output handling\ndef draw_boxes(frame, boxes, classes, scores, labels):\n    for i in range(len(scores)):\n        if scores[i] > confidence_threshold:\n            ymin, xmin, ymax, xmax = boxes[i]\n            (left, right, top, bottom) = (xmin * frame.shape[1], xmax * frame.shape[1],\n                                          ymin * frame.shape[0], ymax * frame.shape[0])\n            \n            label = f'{labels[int(classes[i])]}: {int(scores[i]*100)}%'\n            cv2.rectangle(frame, (int(left), int(top)), (int(right), int(bottom)), (10, 255, 0), 2)\n            cv2.putText(frame, label, (int(left), int(top) - 10),\n                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (10, 255, 0), 2)\n\ndef compute_map():\n    # Dummy function for mAP computation placeholder\n    print(\"Mean Average Precision (mAP) calculation is not implemented.\")\n\n# Main processing loop\ncap = cv2.VideoCapture(input_path)\nfourcc = cv2.VideoWriter_fourcc(*'mp4v')\nout = cv2.VideoWriter(output_path, fourcc, 20.0, (int(cap.get(3)), int(cap.get(4))))\n\nwhile cap.isOpened():\n    ret, frame = cap.read()\n    if not ret:\n        break\n    \n    preprocessed_frame = preprocess_frame(frame)\n    boxes, classes, scores = run_inference(interpreter, preprocessed_frame)\n    draw_boxes(frame, boxes, classes, scores, labels)\n    \n    out.write(frame)\n\ncap.release()\nout.release()\n\ncompute_map()  # Placeholder for mAP computation"
      },
      "session_id": "phi4_9e98_psg_batch",
      "metadata": {
        "num_run": 16
      },
      "tags": [
        "ablation",
        "benchmark",
        "phi4:latest",
        "py_sketch_generator"
      ],
      "latency": 84.991,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-23-20-01-281839_chatcmpl-d080fde1-2f7c-4ec6-afd9-7a3b06e35ba4",
          "traceId": "d84fe193",
          "type": "GENERATION",
          "name": "d84f_psg_gen_attempt#1",
          "startTime": "2025-12-10T21:20:01.281000+00:00",
          "endTime": "2025-12-10T21:20:16.170000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 14889.0,
          "totalTokens": 1064,
          "costDetails": {},
          "environment": "default",
          "promptTokens": 245,
          "completionTokens": 819,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-23-20-19-205199_chatcmpl-a1f05bd7-a9e1-4cd4-8803-b7010c8ab566",
          "traceId": "d84fe193",
          "type": "GENERATION",
          "name": "d84f_psg_gen_attempt#2",
          "startTime": "2025-12-10T21:20:19.205000+00:00",
          "endTime": "2025-12-10T21:20:36.303000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 17098.0,
          "totalTokens": 1189,
          "costDetails": {},
          "environment": "default",
          "promptTokens": 245,
          "completionTokens": 944,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-23-20-36-436747_chatcmpl-91cfded6-2aad-429b-86b7-33e20328bbaa",
          "traceId": "d84fe193",
          "type": "GENERATION",
          "name": "d84f_psg_gen_attempt#3",
          "startTime": "2025-12-10T21:20:36.436000+00:00",
          "endTime": "2025-12-10T21:20:52.112000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 15676.0,
          "totalTokens": 1111,
          "costDetails": {},
          "environment": "default",
          "promptTokens": 245,
          "completionTokens": 866,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-23-20-55-464863_chatcmpl-52b3af38-50d9-47df-af79-869b9eabafcc",
          "traceId": "d84fe193",
          "type": "GENERATION",
          "name": "d84f_psg_gen_attempt#4",
          "startTime": "2025-12-10T21:20:55.464000+00:00",
          "endTime": "2025-12-10T21:21:09.004000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 13540.0,
          "totalTokens": 994,
          "costDetails": {},
          "environment": "default",
          "promptTokens": 245,
          "completionTokens": 749,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-23-21-11-972181_chatcmpl-8108b40e-06cc-4bbe-a075-8ac2df674823",
          "traceId": "d84fe193",
          "type": "GENERATION",
          "name": "d84f_psg_gen_attempt#5",
          "startTime": "2025-12-10T21:21:11.972000+00:00",
          "endTime": "2025-12-10T21:21:26.272000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 14300.0,
          "totalTokens": 1035,
          "costDetails": {},
          "environment": "default",
          "promptTokens": 245,
          "completionTokens": 790,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        }
      ],
      "createdAt": "2025-12-10T21:20:01.802Z",
      "updatedAt": "2025-12-10T21:21:39.925Z",
      "environment": "default"
    },
    {
      "id": "2cb2b227",
      "timestamp": "2025-12-10T21:18:06.312000+00:00",
      "name": "2cb2_py_sketch_generator",
      "input": null,
      "output": {
        "status": "failed",
        "last_code": "import cv2\nimport numpy as np\nimport tensorflow as tf\n\ndef load_labels(label_path):\n    with open(label_path, 'r') as f:\n        labels = [line.strip() for line in f.readlines()]\n    return labels\n\ndef load_tflite_interpreter(model_path):\n    interpreter = tf.lite.Interpreter(model_path=model_path)\n    interpreter.allocate_tensors()\n    return interpreter\n\ndef preprocess_input(interpreter, frame):\n    input_details = interpreter.get_input_details()\n    input_shape = input_details[0]['shape']\n    input_frame = cv2.resize(frame, (input_shape[1], input_shape[2]))\n    input_frame = np.expand_dims(input_frame, axis=0).astype(np.float32)\n    return input_frame\n\ndef run_inference(interpreter, frame):\n    interpreter.set_tensor(interpreter.get_input_details()[0]['index'], frame)\n    interpreter.invoke()\n    \n    output_details = interpreter.get_output_details()\n    boxes = interpreter.get_tensor(output_details[0]['index'])[0]\n    classes = interpreter.get_tensor(output_details[1]['index'])[0]\n    scores = interpreter.get_tensor(output_details[2]['index'])[0]\n\n    return boxes, classes, scores\n\ndef draw_detections(frame, boxes, classes, scores, labels, confidence_threshold):\n    for i in range(len(scores)):\n        if scores[i] >= confidence_threshold:\n            ymin, xmin, ymax, xmax = boxes[i]\n            (left, right, top, bottom) = (xmin * frame.shape[1], xmax * frame.shape[1],\n                                          ymin * frame.shape[0], ymax * frame.shape[0])\n            \n            cv2.rectangle(frame, (int(left), int(top)), (int(right), int(bottom)), (10, 255, 0), 2)\n            label = f\"{labels[int(classes[i])]}: {scores[i]:.2f}\"\n            cv2.putText(frame, label, (int(left), int(top) - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (10, 255, 0), 2)\n\ndef compute_map(predictions, ground_truths):\n    # Placeholder for mAP computation logic\n    return \"mAP: Not Implemented\"\n\ndef main():\n    model_path = 'models/ssd-mobilenet_v1/detect.tflite'\n    label_path = 'models/ssd-mobilenet_v1/labelmap.txt'\n    input_path = 'data/object_detection/sheeps.mp4'\n    output_path = 'results/object_detection/test_results/sheeps_detections.mp4'\n    confidence_threshold = 0.5\n\n    labels = load_labels(label_path)\n    interpreter = load_tflite_interpreter(model_path)\n\n    cap = cv2.VideoCapture(input_path)\n    frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n    frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n    out = cv2.VideoWriter(output_path, cv2.VideoWriter_fourcc(*'mp4v'), 30, (frame_width, frame_height))\n\n    while cap.isOpened():\n        ret, frame = cap.read()\n        if not ret:\n            break\n\n        preprocessed_frame = preprocess_input(interpreter, frame)\n        boxes, classes, scores = run_inference(interpreter, preprocessed_frame)\n        draw_detections(frame, boxes, classes, scores, labels, confidence_threshold)\n\n        out.write(frame)\n\n    cap.release()\n    out.release()\n    cv2.destroyAllWindows()\n\nif __name__ == '__main__':\n    main()",
        "last_error": "Max retries reached with failure. Last error from execution: 2025-12-10 23:19:32.942759: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n2025-12-10 23:19:32.946310: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n2025-12-10 23:19:32.957929: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2025-12-10 23:19:32.976468: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2025-12-10 23:19:32.982105: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n2025-12-10 23:19:32.995963: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\nTo enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n2025-12-10 23:19:33.820194: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\nINFO: Created TensorFlow Lite XNNPACK delegate for CPU.\nTraceback (most recent call last):\n  File \"/home/wuguangh/Projects/03.12/tinyml-autopilot-pm.03.12.2025/results/object_detection/sketches/tmp_20251210231932_psg_phi4:latest/tmp_20251210231932_psg_phi4:latest.py\", line 79, in <module>\n    main()\n  File \"/home/wuguangh/Projects/03.12/tinyml-autopilot-pm.03.12.2025/results/object_detection/sketches/tmp_20251210231932_psg_phi4:latest/tmp_20251210231932_psg_phi4:latest.py\", line 69, in main\n    boxes, classes, scores = run_inference(interpreter, preprocessed_frame)\n  File \"/home/wuguangh/Projects/03.12/tinyml-autopilot-pm.03.12.2025/results/object_detection/sketches/tmp_20251210231932_psg_phi4:latest/tmp_20251210231932_psg_phi4:latest.py\", line 23, in run_inference\n    interpreter.set_tensor(interpreter.get_input_details()[0]['index'], frame)\n  File \"/home/wuguangh/.conda/envs/tinyml/lib/python3.10/site-packages/tensorflow/lite/python/interpreter.py\", line 732, in set_tensor\n    self._interpreter.SetTensor(tensor_index, value)\nValueError: Cannot set tensor: Got value of type FLOAT32 but expected type UINT8 for input 175, name: normalized_input_image_tensor \n"
      },
      "session_id": "phi4_9e98_psg_batch",
      "metadata": {
        "num_run": 15
      },
      "tags": [
        "ablation",
        "benchmark",
        "phi4:latest",
        "py_sketch_generator"
      ],
      "latency": 89.421,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-23-18-06-313332_chatcmpl-5fae178d-fb27-4065-bb3d-6c423565e590",
          "traceId": "2cb2b227",
          "type": "GENERATION",
          "name": "2cb2_psg_gen_attempt#1",
          "startTime": "2025-12-10T21:18:06.313000+00:00",
          "endTime": "2025-12-10T21:18:23.316000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 17003.0,
          "totalTokens": 1178,
          "costDetails": {},
          "environment": "default",
          "promptTokens": 245,
          "completionTokens": 933,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-23-18-26-584516_chatcmpl-15924c4d-ea06-4c80-be46-8a0be79f1bf4",
          "traceId": "2cb2b227",
          "type": "GENERATION",
          "name": "2cb2_psg_gen_attempt#2",
          "startTime": "2025-12-10T21:18:26.584000+00:00",
          "endTime": "2025-12-10T21:18:41.610000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 15026.0,
          "totalTokens": 1076,
          "costDetails": {},
          "environment": "default",
          "promptTokens": 245,
          "completionTokens": 831,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-23-18-44-604781_chatcmpl-98b2dbf4-694a-4838-a605-577cbb917a24",
          "traceId": "2cb2b227",
          "type": "GENERATION",
          "name": "2cb2_psg_gen_attempt#3",
          "startTime": "2025-12-10T21:18:44.604000+00:00",
          "endTime": "2025-12-10T21:18:58.970000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 14366.0,
          "totalTokens": 1039,
          "costDetails": {},
          "environment": "default",
          "promptTokens": 245,
          "completionTokens": 794,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-23-18-59-115583_chatcmpl-b37ee5b5-e53b-426c-a16a-acf6460abc5a",
          "traceId": "2cb2b227",
          "type": "GENERATION",
          "name": "2cb2_psg_gen_attempt#4",
          "startTime": "2025-12-10T21:18:59.115000+00:00",
          "endTime": "2025-12-10T21:19:16.430000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 17315.0,
          "totalTokens": 1201,
          "costDetails": {},
          "environment": "default",
          "promptTokens": 245,
          "completionTokens": 956,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-23-19-19-448444_chatcmpl-91e9b859-f5fc-4f50-b5e5-fe22c854dc4f",
          "traceId": "2cb2b227",
          "type": "GENERATION",
          "name": "2cb2_psg_gen_attempt#5",
          "startTime": "2025-12-10T21:19:19.448000+00:00",
          "endTime": "2025-12-10T21:19:32.611000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 13163.0,
          "totalTokens": 974,
          "costDetails": {},
          "environment": "default",
          "promptTokens": 245,
          "completionTokens": 729,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "3b780fad-7f35-4fd8-a5b4-5b71368d6d4d",
          "traceId": "2cb2b227",
          "type": "SPAN",
          "name": "error_2c_psg_failure_signal_py_sketch_generator",
          "startTime": "2025-12-10T21:19:35.734000+00:00",
          "level": "ERROR",
          "statusMessage": "Failed. Last error: Max retries reached with failure. Last error from execution: 2025-12-10 23:19:32.942759: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n2025-12-10 23:19:32.946310: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n2025-12-10 23:19:32.957929: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2025-12-10 23:19:32.976468: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2025-12-10 23:19:32.982105: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n2025-12-10 23:19:32.995963: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\nTo enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n2025-12-10 23:19:33.820194: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\nINFO: Created TensorFlow Lite XNNPACK delegate for CPU.\nTraceback (most recent call last):\n  File \"/home/wuguangh/Projects/03.12/tinyml-autopilot-pm.03.12.2025/results/object_detection/sketches/tmp_20251210231932_psg_phi4:latest/tmp_20251210231932_psg_phi4:latest.py\", line 79, in <module>\n    main()\n  File \"/home/wuguangh/Projects/03.12/tinyml-autopilot-pm.03.12.2025/results/object_detection/sketches/tmp_20251210231932_psg_phi4:latest/tmp_20251210231932_psg_phi4:latest.py\", line 69, in main\n    boxes, classes, scores = run_inference(interpreter, preprocessed_frame)\n  File \"/home/wuguangh/Projects/03.12/tinyml-autopilot-pm.03.12.2025/results/object_detection/sketches/tmp_20251210231932_psg_phi4:latest/tmp_20251210231932_psg_phi4:latest.py\", line 23, in run_inference\n    interpreter.set_tensor(interpreter.get_input_details()[0]['index'], frame)\n  File \"/home/wuguangh/.conda/envs/tinyml/lib/python3.10/site-packages/tensorflow/lite/python/interpreter.py\", line 732, in set_tensor\n    self._interpreter.SetTensor(tensor_index, value)\nValueError: Cannot set tensor: Got value of type FLOAT32 but expected type UINT8 for input 175, name: normalized_input_image_tensor \n",
          "calculatedTotalCost": 0.0,
          "totalTokens": 0,
          "costDetails": {},
          "environment": "default",
          "promptTokens": 0,
          "completionTokens": 0,
          "endTime": null,
          "model": null,
          "modelParameters": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null,
          "latency": null
        }
      ],
      "createdAt": "2025-12-10T21:18:06.832Z",
      "updatedAt": "2025-12-10T21:19:41.035Z",
      "environment": "default"
    },
    {
      "id": "2448f5e4",
      "timestamp": "2025-12-10T21:16:12.323000+00:00",
      "name": "2448_py_sketch_generator",
      "input": null,
      "output": {
        "status": "failed",
        "last_code": "import cv2\nimport numpy as np\nfrom tflite_runtime.interpreter import Interpreter\nfrom pycocotools.coco import COCO\nfrom pycocotools.cocoeval import COCOeval\n\ndef load_labels(label_path):\n    with open(label_path, 'r') as f:\n        labels = [line.strip() for line in f.readlines()]\n    return labels\n\ndef set_input_tensor(interpreter, image):\n    tensor_index = interpreter.get_input_details()[0]['index']\n    input_tensor = interpreter.tensor(tensor_index)()[0]\n    input_tensor[:, :] = image\n\ndef get_output_tensor(interpreter, index):\n    output_detail = interpreter.get_output_details()[index]\n    return np.squeeze(interpreter.get_tensor(output_detail['index']))\n\ndef load_labels(label_path):\n    with open(label_path, 'r') as file:\n        labels = [line.strip() for line in file.readlines()]\n    return labels\n\ndef setup_interpreter(model_path):\n    interpreter = Interpreter(model_path=model_path)\n    interpreter.allocate_tensors()\n    return interpreter\n\ndef preprocess_image(image, input_size):\n    image = cv2.resize(image, input_size)\n    image = np.expand_dims(image, axis=0).astype(np.float32)\n    return image\n\ndef draw_boxes_and_labels(frame, boxes, classes, scores, labels, threshold):\n    for i in range(len(scores)):\n        if scores[i] > threshold:\n            ymin, xmin, ymax, xmax = boxes[i]\n            (left, right, top, bottom) = (xmin * frame.shape[1], xmax * frame.shape[1],\n                                          ymin * frame.shape[0], ymax * frame.shape[0])\n            cv2.rectangle(frame, (int(left), int(top)), (int(right), int(bottom)),\n                          color=(0, 255, 0), thickness=2)\n            label = f'{labels[int(classes[i])]}: {scores[i]:.2f}'\n            cv2.putText(frame, label, (int(left), int(top) - 10),\n                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n\ndef compute_map(gt_annotations, pred_annotations):\n    coco_gt = COCO()\n    coco_gt.dataset['annotations'] = gt_annotations\n    coco_gt.createIndex()\n\n    coco_dt = coco_gt.loadRes(pred_annotations)\n    coco_eval = COCOeval(coco_gt, coco_dt, 'bbox')\n    coco_eval.evaluate()\n    coco_eval.accumulate()\n    coco_eval.summarize()\n    return coco_eval.stats[0]  # mAP\n\ndef main():\n    model_path = 'models/ssd-mobilenet_v1/detect.tflite'\n    label_path = 'models/ssd-mobilenet_v1/labelmap.txt'\n    input_path = 'data/object_detection/sheeps.mp4'\n    output_path = 'results/object_detection/test_results/sheeps_detections.mp4'\n    confidence_threshold = 0.5\n\n    labels = load_labels(label_path)\n    interpreter = setup_interpreter(model_path)\n\n    _, input_height, input_width, _ = interpreter.get_input_details()[0]['shape']\n    cap = cv2.VideoCapture(input_path)\n    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n    out = cv2.VideoWriter(output_path, fourcc, 20.0, (int(cap.get(3)), int(cap.get(4))))\n\n    while cap.isOpened():\n        ret, frame = cap.read()\n        if not ret:\n            break\n\n        image = preprocess_image(frame, (input_width, input_height))\n        set_input_tensor(interpreter, image)\n        interpreter.invoke()\n\n        boxes = get_output_tensor(interpreter, 0)\n        classes = get_output_tensor(interpreter, 1)\n        scores = get_output_tensor(interpreter, 2)\n\n        draw_boxes_and_labels(frame, boxes, classes, scores, labels, confidence_threshold)\n        \n        out.write(frame)\n\n    cap.release()\n    out.release()\n\nif __name__ == \"__main__\":\n    main()",
        "last_error": "Max retries reached with failure. Last error from execution: Traceback (most recent call last):\n  File \"/home/wuguangh/Projects/03.12/tinyml-autopilot-pm.03.12.2025/results/object_detection/sketches/tmp_20251210231740_psg_phi4:latest/tmp_20251210231740_psg_phi4:latest.py\", line 4, in <module>\n    from pycocotools.coco import COCO\nModuleNotFoundError: No module named 'pycocotools'\n"
      },
      "session_id": "phi4_9e98_psg_batch",
      "metadata": {
        "num_run": 14
      },
      "tags": [
        "ablation",
        "benchmark",
        "phi4:latest",
        "py_sketch_generator"
      ],
      "latency": 87.809,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-23-16-12-324604_chatcmpl-ebb13cf1-bd1d-4cbe-964c-bcb124ba84a2",
          "traceId": "2448f5e4",
          "type": "GENERATION",
          "name": "2448_psg_gen_attempt#1",
          "startTime": "2025-12-10T21:16:12.324000+00:00",
          "endTime": "2025-12-10T21:16:31.696000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 19372.0,
          "totalTokens": 1306,
          "costDetails": {},
          "environment": "default",
          "promptTokens": 245,
          "completionTokens": 1061,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-23-16-34-700825_chatcmpl-01121f29-319e-43b0-994d-2a63785a029d",
          "traceId": "2448f5e4",
          "type": "GENERATION",
          "name": "2448_psg_gen_attempt#2",
          "startTime": "2025-12-10T21:16:34.700000+00:00",
          "endTime": "2025-12-10T21:16:48.080000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 13380.0,
          "totalTokens": 985,
          "costDetails": {},
          "environment": "default",
          "promptTokens": 245,
          "completionTokens": 740,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-23-16-48-228440_chatcmpl-9ce3c61b-2cb4-4d71-a788-ea48ede2ec97",
          "traceId": "2448f5e4",
          "type": "GENERATION",
          "name": "2448_psg_gen_attempt#3",
          "startTime": "2025-12-10T21:16:48.228000+00:00",
          "endTime": "2025-12-10T21:17:03.733000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 15505.0,
          "totalTokens": 1101,
          "costDetails": {},
          "environment": "default",
          "promptTokens": 245,
          "completionTokens": 856,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-23-17-06-772965_chatcmpl-5a2b1907-6371-48fe-87cd-0f22673fbc29",
          "traceId": "2448f5e4",
          "type": "GENERATION",
          "name": "2448_psg_gen_attempt#4",
          "startTime": "2025-12-10T21:17:06.772000+00:00",
          "endTime": "2025-12-10T21:17:24.689000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 17917.0,
          "totalTokens": 1235,
          "costDetails": {},
          "environment": "default",
          "promptTokens": 245,
          "completionTokens": 990,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-23-17-24-838412_chatcmpl-30a904b9-3293-4dcb-9820-63f25b01c6d0",
          "traceId": "2448f5e4",
          "type": "GENERATION",
          "name": "2448_psg_gen_attempt#5",
          "startTime": "2025-12-10T21:17:24.838000+00:00",
          "endTime": "2025-12-10T21:17:40.009000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 15171.0,
          "totalTokens": 1084,
          "costDetails": {},
          "environment": "default",
          "promptTokens": 245,
          "completionTokens": 839,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "3d2300aa-a539-4352-b82c-056653b3a53d",
          "traceId": "2448f5e4",
          "type": "SPAN",
          "name": "error_24_psg_failure_signal_py_sketch_generator",
          "startTime": "2025-12-10T21:17:40.133000+00:00",
          "level": "ERROR",
          "statusMessage": "Failed. Last error: Max retries reached with failure. Last error from execution: Traceback (most recent call last):\n  File \"/home/wuguangh/Projects/03.12/tinyml-autopilot-pm.03.12.2025/results/object_detection/sketches/tmp_20251210231740_psg_phi4:latest/tmp_20251210231740_psg_phi4:latest.py\", line 4, in <module>\n    from pycocotools.coco import COCO\nModuleNotFoundError: No module named 'pycocotools'\n",
          "calculatedTotalCost": 0.0,
          "totalTokens": 0,
          "costDetails": {},
          "environment": "default",
          "promptTokens": 0,
          "completionTokens": 0,
          "endTime": null,
          "model": null,
          "modelParameters": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null,
          "latency": null
        }
      ],
      "createdAt": "2025-12-10T21:16:12.843Z",
      "updatedAt": "2025-12-10T21:17:45.907Z",
      "environment": "default"
    },
    {
      "id": "0e58a737",
      "timestamp": "2025-12-10T21:14:59.162000+00:00",
      "name": "0e58_py_sketch_generator",
      "input": null,
      "output": {
        "status": "success",
        "sketch": "import cv2\nimport numpy as np\nimport tflite_runtime.interpreter as tflite\nfrom sklearn.metrics import average_precision_score\n\ndef load_labels(label_path):\n    with open(label_path, 'r') as f:\n        return {i: line.strip() for i, line in enumerate(f.readlines())}\n\ndef set_input_tensor(interpreter, image):\n    tensor_index = interpreter.get_input_details()[0]['index']\n    input_shape = interpreter.get_input_details()[0]['shape']\n    input_data = cv2.resize(image, (input_shape[1], input_shape[2]))\n    input_data = np.expand_dims(input_data, axis=0)\n    interpreter.set_tensor(tensor_index, input_data)\n\ndef get_output(interpreter):\n    boxes = interpreter.get_tensor(interpreter.get_output_details()[0]['index'])[0]\n    classes = interpreter.get_tensor(interpreter.get_output_details()[1]['index'])[0]\n    scores = interpreter.get_tensor(interpreter.get_output_details()[2]['index'])[0]\n    count = int(interpreter.get_tensor(interpreter.get_output_details()[3]['index'])[0])\n    return boxes, classes, scores, count\n\ndef draw_detections(frame, boxes, classes, scores, labels, threshold):\n    for i in range(len(scores)):\n        if scores[i] >= threshold:\n            ymin, xmin, ymax, xmax = boxes[i]\n            (left, right, top, bottom) = (xmin * frame.shape[1], xmax * frame.shape[1],\n                                          ymin * frame.shape[0], ymax * frame.shape[0])\n            cv2.rectangle(frame, (int(left), int(top)), (int(right), int(bottom)), (10, 255, 0), 2)\n            label = f'{labels[int(classes[i])]}: {int(scores[i]*100)}%'\n            cv2.putText(frame, label, (int(left), int(top)-10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)\n\ndef compute_map(ground_truths, predictions):\n    average_precisions = {}\n    for label in ground_truths:\n        true_positives = np.array([float(d['score']) if d['label'] == label else 0 for d in ground_truths[label]])\n        scores = [d['score'] for d in predictions[label]]\n        average_precisions[label] = average_precision_score(true_positives, scores)\n    return np.mean(list(average_precisions.values()))\n\ndef main():\n    model_path = 'models/ssd-mobilenet_v1/detect.tflite'\n    label_path = 'models/ssd-mobilenet_v1/labelmap.txt'\n    input_path = 'data/object_detection/sheeps.mp4'\n    output_path = 'results/object_detection/test_results/sheeps_detections.mp4'\n    confidence_threshold = 0.5\n\n    labels = load_labels(label_path)\n    \n    interpreter = tflite.Interpreter(model_path=model_path)\n    interpreter.allocate_tensors()\n    \n    video_capture = cv2.VideoCapture(input_path)\n    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n    out = cv2.VideoWriter(output_path, fourcc, 20.0, (int(video_capture.get(3)), int(video_capture.get(4))))\n\n    ground_truths = {}\n    predictions = {label: [] for label in labels.values()}\n\n    while video_capture.isOpened():\n        ret, frame = video_capture.read()\n        if not ret:\n            break\n\n        set_input_tensor(interpreter, frame)\n        interpreter.invoke()\n\n        boxes, classes, scores, count = get_output(interpreter)\n\n        draw_detections(frame, boxes, classes, scores, labels, confidence_threshold)\n\n        for i in range(count):\n            class_id = int(classes[i])\n            score = float(scores[i])\n            if score >= confidence_threshold:\n                label = labels[class_id]\n                predictions[label].append({'score': score})\n        \n        out.write(frame)\n\n    map_score = compute_map(ground_truths, predictions)\n    print(f\"Mean Average Precision (mAP): {map_score}\")\n\n    video_capture.release()\n    out.release()\n\nif __name__ == \"__main__\":\n    main()"
      },
      "session_id": "phi4_9e98_psg_batch",
      "metadata": {
        "num_run": 13
      },
      "tags": [
        "ablation",
        "benchmark",
        "phi4:latest",
        "py_sketch_generator"
      ],
      "latency": 15.814,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-23-14-59-163442_chatcmpl-259a57b3-a9f1-4f59-a354-c668cba4c0d3",
          "traceId": "0e58a737",
          "type": "GENERATION",
          "name": "0e58_psg_gen_attempt#1",
          "startTime": "2025-12-10T21:14:59.163000+00:00",
          "endTime": "2025-12-10T21:15:14.977000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 15814.0,
          "totalTokens": 1114,
          "costDetails": {},
          "environment": "default",
          "promptTokens": 245,
          "completionTokens": 869,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        }
      ],
      "createdAt": "2025-12-10T21:14:59.682Z",
      "updatedAt": "2025-12-10T21:15:52.295Z",
      "environment": "default"
    },
    {
      "id": "c2511ebf",
      "timestamp": "2025-12-10T21:13:08.217000+00:00",
      "name": "c251_py_sketch_generator",
      "input": null,
      "output": {
        "status": "failed",
        "last_code": "import cv2\nimport numpy as np\nimport tensorflow as tf\n\n# Configuration parameters\nmodel_path  = \"models/ssd-mobilenet_v1/detect.tflite\"\nlabel_path  = \"models/ssd-mobilenet_v1/labelmap.txt\"\ninput_path  = \"data/object_detection/sheeps.mp4\"\noutput_path  = \"results/object_detection/test_results/sheeps_detections.mp4\"\nconfidence_threshold  = 0.5\n\n# Setup\ninterpreter = tf.lite.Interpreter(model_path=model_path)\ninterpreter.allocate_tensors()\n\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\n\nheight, width, channels = input_details[0]['shape'][1:4]\n\nlabel_map = {}\nwith open(label_path, 'r') as f:\n    for line in f.readlines():\n        id_, name = line.strip().split(maxsplit=1)\n        label_map[int(id_)] = name\n\n# Preprocessing\ndef preprocess_frame(frame):\n    frame_resized = cv2.resize(frame, (width, height))\n    input_data = np.expand_dims(frame_resized, axis=0).astype(np.float32)\n    return input_data\n\n# Inference\ndef run_inference(input_data):\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n    interpreter.invoke()\n\n    boxes = interpreter.get_tensor(output_details[0]['index'])[0] # Bounding box coordinates of detected objects\n    classes = interpreter.get_tensor(output_details[1]['index'])[0] # Class index of detected objects\n    scores = interpreter.get_tensor(output_details[2]['index'])[0] # Confidence of detected objects\n\n    return boxes, classes, scores\n\n# Compute mAP (Mean Average Precision)\ndef compute_map(boxes, classes, scores, frame):\n    true_positive = 0\n    false_positive = 0\n    for i in range(len(scores)):\n        if scores[i] > confidence_threshold:\n            class_id = int(classes[i])\n            box = boxes[i]\n            x1, y1, x2, y2 = box\n\n            # Draw bounding box and label on frame\n            cv2.rectangle(frame, (int(x1 * width), int(y1 * height)), \n                          (int(x2 * width), int(y2 * height)), (0, 255, 0), 2)\n            label = f'{label_map[class_id]}: {scores[i]:.2f}'\n            cv2.putText(frame, label, (int(x1 * width), int((y1 - 10) * height)),\n                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n\n    # Here you would calculate mAP using ground truth data and detected boxes\n    # This is a placeholder for actual mAP computation\n    map_value = true_positive / (true_positive + false_positive) if (true_positive + false_positive) > 0 else 0\n\n    return map_value, frame\n\n# Output handling\ncap = cv2.VideoCapture(input_path)\nfourcc = cv2.VideoWriter_fourcc(*'mp4v')\nout = cv2.VideoWriter(output_path, fourcc, 20.0, (int(cap.get(3)), int(cap.get(4))))\n\nwhile cap.isOpened():\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    input_data = preprocess_frame(frame)\n    boxes, classes, scores = run_inference(input_data)\n    map_value, frame_with_boxes = compute_map(boxes, classes, scores, frame)\n\n    out.write(frame_with_boxes)\n    print(f\"Frame processed with mAP: {map_value:.2f}\")\n\ncap.release()\nout.release()\n\nprint(\"Video processing complete.\")",
        "last_error": "Max retries reached with failure. Last error from execution: 2025-12-10 23:14:30.625164: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n2025-12-10 23:14:30.628557: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n2025-12-10 23:14:30.639842: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2025-12-10 23:14:30.658313: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2025-12-10 23:14:30.663792: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n2025-12-10 23:14:30.677288: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\nTo enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n2025-12-10 23:14:31.485091: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\nINFO: Created TensorFlow Lite XNNPACK delegate for CPU.\nTraceback (most recent call last):\n  File \"/home/wuguangh/Projects/03.12/tinyml-autopilot-pm.03.12.2025/results/object_detection/sketches/tmp_20251210231430_psg_phi4:latest/tmp_20251210231430_psg_phi4:latest.py\", line 24, in <module>\n    id_, name = line.strip().split(maxsplit=1)\nValueError: not enough values to unpack (expected 2, got 1)\n"
      },
      "session_id": "phi4_9e98_psg_batch",
      "metadata": {
        "num_run": 12
      },
      "tags": [
        "ablation",
        "benchmark",
        "phi4:latest",
        "py_sketch_generator"
      ],
      "latency": 85.087,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-23-13-08-218678_chatcmpl-f26fa398-2b0e-4fd4-8b46-e7060cd971c2",
          "traceId": "c2511ebf",
          "type": "GENERATION",
          "name": "c251_psg_gen_attempt#1",
          "startTime": "2025-12-10T21:13:08.218000+00:00",
          "endTime": "2025-12-10T21:13:23.263000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 15045.0,
          "totalTokens": 1073,
          "costDetails": {},
          "environment": "default",
          "promptTokens": 245,
          "completionTokens": 828,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-23-13-26-249934_chatcmpl-30826925-7ea1-44b9-936e-41f1df8e2ee0",
          "traceId": "c2511ebf",
          "type": "GENERATION",
          "name": "c251_psg_gen_attempt#2",
          "startTime": "2025-12-10T21:13:26.249000+00:00",
          "endTime": "2025-12-10T21:13:39.754000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 13505.0,
          "totalTokens": 992,
          "costDetails": {},
          "environment": "default",
          "promptTokens": 245,
          "completionTokens": 747,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-23-13-39-914625_chatcmpl-3655816e-2e4f-42b5-bbc6-2b36571110b3",
          "traceId": "c2511ebf",
          "type": "GENERATION",
          "name": "c251_psg_gen_attempt#3",
          "startTime": "2025-12-10T21:13:39.914000+00:00",
          "endTime": "2025-12-10T21:13:53.496000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 13582.0,
          "totalTokens": 996,
          "costDetails": {},
          "environment": "default",
          "promptTokens": 245,
          "completionTokens": 751,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-23-13-56-503200_chatcmpl-3f71000a-ddaf-4b79-83f1-2678b1a8f135",
          "traceId": "c2511ebf",
          "type": "GENERATION",
          "name": "c251_psg_gen_attempt#4",
          "startTime": "2025-12-10T21:13:56.503000+00:00",
          "endTime": "2025-12-10T21:14:15.624000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 19121.0,
          "totalTokens": 1298,
          "costDetails": {},
          "environment": "default",
          "promptTokens": 245,
          "completionTokens": 1053,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-23-14-16-345796_chatcmpl-457515c2-95e3-4516-ade6-6bc475dd37d1",
          "traceId": "c2511ebf",
          "type": "GENERATION",
          "name": "c251_psg_gen_attempt#5",
          "startTime": "2025-12-10T21:14:16.345000+00:00",
          "endTime": "2025-12-10T21:14:30.304000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 13959.0,
          "totalTokens": 1017,
          "costDetails": {},
          "environment": "default",
          "promptTokens": 245,
          "completionTokens": 772,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "6e6a4d89-1492-431f-a3eb-d2611a1b34e1",
          "traceId": "c2511ebf",
          "type": "SPAN",
          "name": "error_c2_psg_failure_signal_py_sketch_generator",
          "startTime": "2025-12-10T21:14:33.305000+00:00",
          "level": "ERROR",
          "statusMessage": "Failed. Last error: Max retries reached with failure. Last error from execution: 2025-12-10 23:14:30.625164: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n2025-12-10 23:14:30.628557: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n2025-12-10 23:14:30.639842: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2025-12-10 23:14:30.658313: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2025-12-10 23:14:30.663792: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n2025-12-10 23:14:30.677288: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\nTo enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n2025-12-10 23:14:31.485091: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\nINFO: Created TensorFlow Lite XNNPACK delegate for CPU.\nTraceback (most recent call last):\n  File \"/home/wuguangh/Projects/03.12/tinyml-autopilot-pm.03.12.2025/results/object_detection/sketches/tmp_20251210231430_psg_phi4:latest/tmp_20251210231430_psg_phi4:latest.py\", line 24, in <module>\n    id_, name = line.strip().split(maxsplit=1)\nValueError: not enough values to unpack (expected 2, got 1)\n",
          "calculatedTotalCost": 0.0,
          "totalTokens": 0,
          "costDetails": {},
          "environment": "default",
          "promptTokens": 0,
          "completionTokens": 0,
          "endTime": null,
          "model": null,
          "modelParameters": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null,
          "latency": null
        }
      ],
      "createdAt": "2025-12-10T21:13:08.738Z",
      "updatedAt": "2025-12-10T21:14:38.933Z",
      "environment": "default"
    },
    {
      "id": "602dec17",
      "timestamp": "2025-12-10T21:11:11.201000+00:00",
      "name": "602d_py_sketch_generator",
      "input": null,
      "output": {
        "status": "failed",
        "last_code": "import cv2\nimport numpy as np\nimport tflite_runtime.interpreter as tflite\nfrom collections import defaultdict\n\n# Configuration parameters\nmodel_path  = \"models/ssd-mobilenet_v1/detect.tflite\"\nlabel_path  = \"models/ssd-mobilenet_v1/labelmap.txt\"\ninput_path  = \"data/object_detection/sheeps.mp4\"\noutput_path  = \"results/object_detection/test_results/sheeps_detections.mp4\"\nconfidence_threshold  = 0.5\n\n# Phase 1: Setup\ndef load_labels(path):\n    with open(path, 'r') as file:\n        return [line.strip() for line in file.readlines()]\n\ndef load_interpreter(model_path):\n    interpreter = tflite.Interpreter(model_path=model_path)\n    interpreter.allocate_tensors()\n    input_details = interpreter.get_input_details()\n    output_details = interpreter.get_output_details()\n    return interpreter, input_details, output_details\n\n# Phase 2: Preprocessing\ndef preprocess_frame(frame, input_size):\n    frame_resized = cv2.resize(frame, (input_size[1], input_size[0]))\n    input_data = np.expand_dims(frame_resized, axis=0).astype(np.float32)\n    return input_data\n\n# Phase 3: Inference\ndef run_inference(interpreter, input_data):\n    interpreter.set_tensor(interpreter.get_input_details()[0]['index'], input_data)\n    interpreter.invoke()\n    boxes = interpreter.get_tensor(interpreter.get_output_details()[0]['index'])[0]\n    classes = interpreter.get_tensor(interpreter.get_output_details()[1]['index'])[0]\n    scores = interpreter.get_tensor(interpreter.get_output_details()[2]['index'])[0]\n    return boxes, classes, scores\n\n# Phase 4: Output Handling\ndef draw_boxes(frame, boxes, classes, scores, labels, input_size):\n    height, width, _ = frame.shape\n    for i in range(len(scores)):\n        if scores[i] >= confidence_threshold:\n            ymin, xmin, ymax, xmax = boxes[i]\n            (left, right, top, bottom) = (xmin * width, xmax * width,\n                                          ymin * height, ymax * height)\n            left, right, top, bottom = int(left), int(right), int(top), int(bottom)\n            cv2.rectangle(frame, (left, top), (right, bottom), (0, 255, 0), 2)\n            label = f\"{labels[int(classes[i])]}: {int(scores[i] * 100)}%\"\n            cv2.putText(frame, label, (left, top - 10), cv2.FONT_HERSHEY_SIMPLEX,\n                        0.5, (0, 255, 0), 1)\n\ndef compute_map(ground_truths, predictions):\n    # Placeholder for mAP computation logic\n    return 0.0\n\n# Main execution\nif __name__ == \"__main__\":\n    labels = load_labels(label_path)\n    interpreter, input_details, output_details = load_interpreter(model_path)\n    cap = cv2.VideoCapture(input_path)\n    out = None\n    frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n    frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n    fps = int(cap.get(cv2.CAP_PROP_FPS))\n    \n    if output_path:\n        out = cv2.VideoWriter(output_path, cv2.VideoWriter_fourcc(*'mp4v'), fps,\n                              (frame_width, frame_height))\n\n    ground_truths = []  # This would be populated with actual ground truths\n    all_predictions = defaultdict(list)\n\n    while cap.isOpened():\n        ret, frame = cap.read()\n        if not ret:\n            break\n\n        input_data = preprocess_frame(frame, input_details[0]['shape'][1:3])\n        boxes, classes, scores = run_inference(interpreter, input_data)\n        \n        draw_boxes(frame, boxes, classes, scores, labels, input_details[0]['shape'][1:3])\n\n        # Collect predictions for mAP computation\n        all_predictions['detections'].append((boxes, classes, scores))\n\n        if out:\n            out.write(frame)\n\n    cap.release()\n    if out:\n        out.release()\n\n    map_score = compute_map(ground_truths, all_predictions)\n    print(f\"Mean Average Precision (mAP): {map_score}\")",
        "last_error": "Max retries reached with failure. Last error from execution: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\nTraceback (most recent call last):\n  File \"/home/wuguangh/Projects/03.12/tinyml-autopilot-pm.03.12.2025/results/object_detection/sketches/tmp_20251210231242_psg_phi4:latest/tmp_20251210231242_psg_phi4:latest.py\", line 81, in <module>\n    boxes, classes, scores = run_inference(interpreter, input_data)\n  File \"/home/wuguangh/Projects/03.12/tinyml-autopilot-pm.03.12.2025/results/object_detection/sketches/tmp_20251210231242_psg_phi4:latest/tmp_20251210231242_psg_phi4:latest.py\", line 33, in run_inference\n    interpreter.set_tensor(interpreter.get_input_details()[0]['index'], input_data)\n  File \"/home/wuguangh/.conda/envs/tinyml/lib/python3.10/site-packages/tflite_runtime/interpreter.py\", line 720, in set_tensor\n    self._interpreter.SetTensor(tensor_index, value)\nValueError: Cannot set tensor: Got value of type FLOAT32 but expected type UINT8 for input 175, name: normalized_input_image_tensor \n"
      },
      "session_id": "phi4_9e98_psg_batch",
      "metadata": {
        "num_run": 11
      },
      "tags": [
        "ablation",
        "benchmark",
        "phi4:latest",
        "py_sketch_generator"
      ],
      "latency": 91.529,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-23-11-11-202535_chatcmpl-d2183fa0-1103-406d-9548-a3ea5bf83ebf",
          "traceId": "602dec17",
          "type": "GENERATION",
          "name": "602d_psg_gen_attempt#1",
          "startTime": "2025-12-10T21:11:11.202000+00:00",
          "endTime": "2025-12-10T21:11:28.505000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 17303.0,
          "totalTokens": 1196,
          "costDetails": {},
          "environment": "default",
          "promptTokens": 245,
          "completionTokens": 951,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-23-11-31-514709_chatcmpl-638d3cc6-248e-4e74-a5ce-eacfdec744cc",
          "traceId": "602dec17",
          "type": "GENERATION",
          "name": "602d_psg_gen_attempt#2",
          "startTime": "2025-12-10T21:11:31.514000+00:00",
          "endTime": "2025-12-10T21:11:45.426000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 13912.0,
          "totalTokens": 1014,
          "costDetails": {},
          "environment": "default",
          "promptTokens": 245,
          "completionTokens": 769,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-23-11-48-460288_chatcmpl-3b781296-3e78-4ff3-bdc5-0f201b775629",
          "traceId": "602dec17",
          "type": "GENERATION",
          "name": "602d_psg_gen_attempt#3",
          "startTime": "2025-12-10T21:11:48.460000+00:00",
          "endTime": "2025-12-10T21:12:06.604000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 18144.0,
          "totalTokens": 1245,
          "costDetails": {},
          "environment": "default",
          "promptTokens": 245,
          "completionTokens": 1000,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-23-12-06-729601_chatcmpl-c5013675-747c-4bd4-970c-804337ee62da",
          "traceId": "602dec17",
          "type": "GENERATION",
          "name": "602d_psg_gen_attempt#4",
          "startTime": "2025-12-10T21:12:06.729000+00:00",
          "endTime": "2025-12-10T21:12:23.353000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 16624.0,
          "totalTokens": 1163,
          "costDetails": {},
          "environment": "default",
          "promptTokens": 245,
          "completionTokens": 918,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-23-12-26-291468_chatcmpl-c0e024f1-74e7-4291-8ad0-6adc8e2ed776",
          "traceId": "602dec17",
          "type": "GENERATION",
          "name": "602d_psg_gen_attempt#5",
          "startTime": "2025-12-10T21:12:26.291000+00:00",
          "endTime": "2025-12-10T21:12:42.581000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 16290.0,
          "totalTokens": 1145,
          "costDetails": {},
          "environment": "default",
          "promptTokens": 245,
          "completionTokens": 900,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "d78f82eb-1e0b-4e0e-91dc-afefd1faf307",
          "traceId": "602dec17",
          "type": "SPAN",
          "name": "error_60_psg_failure_signal_py_sketch_generator",
          "startTime": "2025-12-10T21:12:42.731000+00:00",
          "level": "ERROR",
          "statusMessage": "Failed. Last error: Max retries reached with failure. Last error from execution: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\nTraceback (most recent call last):\n  File \"/home/wuguangh/Projects/03.12/tinyml-autopilot-pm.03.12.2025/results/object_detection/sketches/tmp_20251210231242_psg_phi4:latest/tmp_20251210231242_psg_phi4:latest.py\", line 81, in <module>\n    boxes, classes, scores = run_inference(interpreter, input_data)\n  File \"/home/wuguangh/Projects/03.12/tinyml-autopilot-pm.03.12.2025/results/object_detection/sketches/tmp_20251210231242_psg_phi4:latest/tmp_20251210231242_psg_phi4:latest.py\", line 33, in run_inference\n    interpreter.set_tensor(interpreter.get_input_details()[0]['index'], input_data)\n  File \"/home/wuguangh/.conda/envs/tinyml/lib/python3.10/site-packages/tflite_runtime/interpreter.py\", line 720, in set_tensor\n    self._interpreter.SetTensor(tensor_index, value)\nValueError: Cannot set tensor: Got value of type FLOAT32 but expected type UINT8 for input 175, name: normalized_input_image_tensor \n",
          "calculatedTotalCost": 0.0,
          "totalTokens": 0,
          "costDetails": {},
          "environment": "default",
          "promptTokens": 0,
          "completionTokens": 0,
          "endTime": null,
          "model": null,
          "modelParameters": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null,
          "latency": null
        }
      ],
      "createdAt": "2025-12-10T21:11:11.720Z",
      "updatedAt": "2025-12-10T21:12:47.835Z",
      "environment": "default"
    },
    {
      "id": "a1c22ac3",
      "timestamp": "2025-12-10T21:09:24.251000+00:00",
      "name": "a1c2_py_sketch_generator",
      "input": null,
      "output": {
        "status": "failed",
        "last_code": "import cv2\nfrom tflite_runtime.interpreter import Interpreter\nimport numpy as np\n\n# Configuration parameters\nmodel_path  = \"models/ssd-mobilenet_v1/detect.tflite\"\nlabel_path  = \"models/ssd-mobilenet_v1/labelmap.txt\"\ninput_path  = \"data/object_detection/sheeps.mp4\"\noutput_path  = \"results/object_detection/test_results/sheeps_detections.mp4\"\nconfidence_threshold  = 0.5\n\n# Phase 1: Setup\ndef load_labels(label_file):\n    with open(label_file, 'r') as file:\n        labels = [line.strip() for line in file.readlines()]\n    return labels\n\ndef load_interpreter(model_path):\n    interpreter = Interpreter(model_path=model_path)\n    interpreter.allocate_tensors()\n    return interpreter\n\n# Phase 2: Preprocessing\ndef preprocess_frame(frame, input_size):\n    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n    frame_resized = cv2.resize(frame_rgb, (input_size[1], input_size[0]))\n    input_data = np.expand_dims(frame_resized, axis=0).astype(np.float32)\n    return input_data\n\n# Phase 3: Inference\ndef set_input_tensor(interpreter, input_data):\n    input_details = interpreter.get_input_details()\n    tensor_index = input_details[0]['index']\n    interpreter.set_tensor(tensor_index, input_data)\n\ndef get_output_tensors(interpreter):\n    boxes = interpreter.get_tensor(interpreter.get_output_details()[0]['index'])[0]\n    classes = interpreter.get_tensor(interpreter.get_output_details()[1]['index'])[0]\n    scores = interpreter.get_tensor(interpreter.get_output_details()[2]['index'])[0]\n    return boxes, classes, scores\n\n# Phase 4: Output Handling\ndef draw_boxes(frame, boxes, classes, scores, labels, confidence_threshold):\n    input_height, input_width, _ = frame.shape\n    for i in range(len(scores)):\n        if scores[i] >= confidence_threshold:\n            ymin, xmin, ymax, xmax = boxes[i]\n            (left, right, top, bottom) = (xmin * input_width, xmax * input_width,\n                                          ymin * input_height, ymax * input_height)\n            cv2.rectangle(frame, (int(left), int(top)), (int(right), int(bottom)),\n                          color=(0, 255, 0), thickness=2)\n            label = f\"{labels[int(classes[i])]}: {int(scores[i] * 100)}%\"\n            cv2.putText(frame, label, (int(left), int(top) - 10),\n                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 1)\n    return frame\n\ndef calculate_mAP(boxes, classes, scores, labels):\n    # Placeholder for mAP calculation logic\n    # Implement the mAP calculation based on ground truth and predictions\n    # This is a simplified placeholder implementation\n    true_positive = sum(1 for score in scores if score >= confidence_threshold)\n    false_positive = len(scores) - true_positive\n    precision = true_positive / (true_positive + false_positive) if (true_positive + false_positive) > 0 else 0\n    return precision\n\ndef main():\n    labels = load_labels(label_path)\n    interpreter = load_interpreter(model_path)\n\n    input_details = interpreter.get_input_details()\n    output_details = interpreter.get_output_details()\n\n    cap = cv2.VideoCapture(input_path)\n    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n    out = cv2.VideoWriter(output_path, fourcc, 20.0, (int(cap.get(3)), int(cap.get(4))))\n\n    while cap.isOpened():\n        ret, frame = cap.read()\n        if not ret:\n            break\n\n        input_data = preprocess_frame(frame, input_details[0]['shape'][1:3])\n        set_input_tensor(interpreter, input_data)\n        interpreter.invoke()\n\n        boxes, classes, scores = get_output_tensors(interpreter)\n\n        frame_with_boxes = draw_boxes(frame, boxes, classes, scores, labels, confidence_threshold)\n\n        mAP = calculate_mAP(boxes, classes, scores, labels)\n        print(f\"Current Frame mAP: {mAP}\")\n\n        out.write(frame_with_boxes)\n\n    cap.release()\n    out.release()\n\nif __name__ == '__main__':\n    main()",
        "last_error": "Max retries reached with failure. Last error from execution: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\nTraceback (most recent call last):\n  File \"/home/wuguangh/Projects/03.12/tinyml-autopilot-pm.03.12.2025/results/object_detection/sketches/tmp_20251210231044_psg_phi4:latest/tmp_20251210231044_psg_phi4:latest.py\", line 99, in <module>\n    main()\n  File \"/home/wuguangh/Projects/03.12/tinyml-autopilot-pm.03.12.2025/results/object_detection/sketches/tmp_20251210231044_psg_phi4:latest/tmp_20251210231044_psg_phi4:latest.py\", line 83, in main\n    set_input_tensor(interpreter, input_data)\n  File \"/home/wuguangh/Projects/03.12/tinyml-autopilot-pm.03.12.2025/results/object_detection/sketches/tmp_20251210231044_psg_phi4:latest/tmp_20251210231044_psg_phi4:latest.py\", line 34, in set_input_tensor\n    interpreter.set_tensor(tensor_index, input_data)\n  File \"/home/wuguangh/.conda/envs/tinyml/lib/python3.10/site-packages/tflite_runtime/interpreter.py\", line 720, in set_tensor\n    self._interpreter.SetTensor(tensor_index, value)\nValueError: Cannot set tensor: Got value of type FLOAT32 but expected type UINT8 for input 175, name: normalized_input_image_tensor \n"
      },
      "session_id": "phi4_9e98_psg_batch",
      "metadata": {
        "num_run": 10
      },
      "tags": [
        "ablation",
        "benchmark",
        "phi4:latest",
        "py_sketch_generator"
      ],
      "latency": 80.782,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-23-09-24-252620_chatcmpl-826f615f-4956-4e40-97fd-2271c9ad1fd2",
          "traceId": "a1c22ac3",
          "type": "GENERATION",
          "name": "a1c2_psg_gen_attempt#1",
          "startTime": "2025-12-10T21:09:24.252000+00:00",
          "endTime": "2025-12-10T21:09:39.194000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 14942.0,
          "totalTokens": 1066,
          "costDetails": {},
          "environment": "default",
          "promptTokens": 245,
          "completionTokens": 821,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-23-09-39-374213_chatcmpl-587f2020-aa4a-4c48-ac1c-0adc43266751",
          "traceId": "a1c22ac3",
          "type": "GENERATION",
          "name": "a1c2_psg_gen_attempt#2",
          "startTime": "2025-12-10T21:09:39.374000+00:00",
          "endTime": "2025-12-10T21:09:54.030000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 14656.0,
          "totalTokens": 1055,
          "costDetails": {},
          "environment": "default",
          "promptTokens": 245,
          "completionTokens": 810,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-23-09-57-098569_chatcmpl-6dd94273-74d1-4853-a2ba-ff0a3ae21843",
          "traceId": "a1c22ac3",
          "type": "GENERATION",
          "name": "a1c2_psg_gen_attempt#3",
          "startTime": "2025-12-10T21:09:57.098000+00:00",
          "endTime": "2025-12-10T21:10:10.130000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 13032.0,
          "totalTokens": 966,
          "costDetails": {},
          "environment": "default",
          "promptTokens": 245,
          "completionTokens": 721,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-23-10-10-295641_chatcmpl-bd46051f-130a-4d57-b786-0627cbadc553",
          "traceId": "a1c22ac3",
          "type": "GENERATION",
          "name": "a1c2_psg_gen_attempt#4",
          "startTime": "2025-12-10T21:10:10.295000+00:00",
          "endTime": "2025-12-10T21:10:24.323000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 14028.0,
          "totalTokens": 1021,
          "costDetails": {},
          "environment": "default",
          "promptTokens": 245,
          "completionTokens": 776,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-23-10-27-328921_chatcmpl-04ed9763-76ea-4e6a-a942-407bebcb2eaa",
          "traceId": "a1c22ac3",
          "type": "GENERATION",
          "name": "a1c2_psg_gen_attempt#5",
          "startTime": "2025-12-10T21:10:27.328000+00:00",
          "endTime": "2025-12-10T21:10:44.890000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 17562.0,
          "totalTokens": 1214,
          "costDetails": {},
          "environment": "default",
          "promptTokens": 245,
          "completionTokens": 969,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "5830d8a7-5343-4fac-9b11-a5850bd1bbac",
          "traceId": "a1c22ac3",
          "type": "SPAN",
          "name": "error_a1_psg_failure_signal_py_sketch_generator",
          "startTime": "2025-12-10T21:10:45.034000+00:00",
          "level": "ERROR",
          "statusMessage": "Failed. Last error: Max retries reached with failure. Last error from execution: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\nTraceback (most recent call last):\n  File \"/home/wuguangh/Projects/03.12/tinyml-autopilot-pm.03.12.2025/results/object_detection/sketches/tmp_20251210231044_psg_phi4:latest/tmp_20251210231044_psg_phi4:latest.py\", line 99, in <module>\n    main()\n  File \"/home/wuguangh/Projects/03.12/tinyml-autopilot-pm.03.12.2025/results/object_detection/sketches/tmp_20251210231044_psg_phi4:latest/tmp_20251210231044_psg_phi4:latest.py\", line 83, in main\n    set_input_tensor(interpreter, input_data)\n  File \"/home/wuguangh/Projects/03.12/tinyml-autopilot-pm.03.12.2025/results/object_detection/sketches/tmp_20251210231044_psg_phi4:latest/tmp_20251210231044_psg_phi4:latest.py\", line 34, in set_input_tensor\n    interpreter.set_tensor(tensor_index, input_data)\n  File \"/home/wuguangh/.conda/envs/tinyml/lib/python3.10/site-packages/tflite_runtime/interpreter.py\", line 720, in set_tensor\n    self._interpreter.SetTensor(tensor_index, value)\nValueError: Cannot set tensor: Got value of type FLOAT32 but expected type UINT8 for input 175, name: normalized_input_image_tensor \n",
          "calculatedTotalCost": 0.0,
          "totalTokens": 0,
          "costDetails": {},
          "environment": "default",
          "promptTokens": 0,
          "completionTokens": 0,
          "endTime": null,
          "model": null,
          "modelParameters": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null,
          "latency": null
        }
      ],
      "createdAt": "2025-12-10T21:09:24.770Z",
      "updatedAt": "2025-12-10T21:10:50.605Z",
      "environment": "default"
    },
    {
      "id": "73a286de",
      "timestamp": "2025-12-10T21:07:51.304000+00:00",
      "name": "73a2_py_sketch_generator",
      "input": null,
      "output": {
        "status": "success",
        "sketch": "import cv2\nimport numpy as np\nfrom tflite_runtime.interpreter import Interpreter\nimport time\n\n# Configuration parameters\nmodel_path  = \"models/ssd-mobilenet_v1/detect.tflite\"\nlabel_path  = \"models/ssd-mobilenet_v1/labelmap.txt\"\ninput_path  = \"data/object_detection/sheeps.mp4\"\noutput_path  = \"results/object_detection/test_results/sheeps_detections.mp4\"\nconfidence_threshold  = 0.5\n\n# Phase 1: Setup\ndef load_labels(label_file):\n    with open(label_file, 'r') as file:\n        return [line.strip() for line in file.readlines()]\n\ndef load_interpreter(model_path):\n    interpreter = Interpreter(model_path=model_path)\n    interpreter.allocate_tensors()\n    return interpreter\n\ninterpreter = load_interpreter(model_path)\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\n\nlabels = load_labels(label_path)\n\n# Phase 2: Preprocessing\ndef preprocess_frame(frame, input_shape):\n    frame_resized = cv2.resize(frame, (input_shape[1], input_shape[0]))\n    frame_normalized = frame_resized / 255.0\n    return np.expand_dims(frame_normalized, axis=0).astype(np.float32)\n\n# Phase 3: Inference\ndef set_input_tensor(interpreter, image):\n    tensor_index = interpreter.get_input_details()[0]['index']\n    input_tensor = interpreter.tensor(tensor_index)()[0]\n    input_tensor[:, :] = image\n\ndef get_output(interpreter):\n    boxes = interpreter.get_tensor(output_details[0]['index'])[0]  # Bounding box coordinates of detected objects\n    classes = interpreter.get_tensor(output_details[1]['index'])[0]  # Class index of detected objects\n    scores = interpreter.get_tensor(output_details[2]['index'])[0]   # Confidence of detected objects\n\n    return boxes, classes, scores\n\n# Phase 4: Output Handling\ndef draw_detections(frame, boxes, classes, scores, labels):\n    for i in range(len(scores)):\n        if scores[i] >= confidence_threshold:\n            ymin, xmin, ymax, xmax = boxes[i]\n            (left, right, top, bottom) = (xmin * frame.shape[1], xmax * frame.shape[1],\n                                          ymin * frame.shape[0], ymax * frame.shape[0])\n            cv2.rectangle(frame, (int(left), int(top)), (int(right), int(bottom)), (10, 255, 0), 2)\n            label = f\"{labels[int(classes[i])]}: {int(scores[i] * 100)}%\"\n            cv2.putText(frame, label, (int(left), int(top) - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (10, 255, 0), 2)\n\ndef main():\n    cap = cv2.VideoCapture(input_path)\n    out = None\n    frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n    frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n    fps = cap.get(cv2.CAP_PROP_FPS)\n    \n    if not out:\n        fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n        out = cv2.VideoWriter(output_path, fourcc, fps, (frame_width, frame_height))\n\n    input_shape = input_details[0]['shape'][1:3]\n\n    while cap.isOpened():\n        ret, frame = cap.read()\n        if not ret:\n            break\n\n        preprocessed_frame = preprocess_frame(frame, input_shape)\n        set_input_tensor(interpreter, preprocessed_frame)\n        interpreter.invoke()\n\n        boxes, classes, scores = get_output(interpreter)\n\n        draw_detections(frame, boxes, classes, scores, labels)\n        \n        out.write(frame)\n    \n    cap.release()\n    if out:\n        out.release()\n\nif __name__ == \"__main__\":\n    main()"
      },
      "session_id": "phi4_9e98_psg_batch",
      "metadata": {
        "num_run": 9
      },
      "tags": [
        "ablation",
        "benchmark",
        "phi4:latest",
        "py_sketch_generator"
      ],
      "latency": 35.872,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-23-07-51-305999_chatcmpl-3f52691f-b0cf-4de0-b7dc-fdf82a1c21bf",
          "traceId": "73a286de",
          "type": "GENERATION",
          "name": "73a2_psg_gen_attempt#1",
          "startTime": "2025-12-10T21:07:51.305000+00:00",
          "endTime": "2025-12-10T21:08:09.250000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 17945.0,
          "totalTokens": 1228,
          "costDetails": {},
          "environment": "default",
          "promptTokens": 245,
          "completionTokens": 983,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-23-08-12-497397_chatcmpl-89539225-ba07-4719-8d65-76f571d3ad0c",
          "traceId": "73a286de",
          "type": "GENERATION",
          "name": "73a2_psg_gen_attempt#2",
          "startTime": "2025-12-10T21:08:12.497000+00:00",
          "endTime": "2025-12-10T21:08:27.177000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 14680.0,
          "totalTokens": 1056,
          "costDetails": {},
          "environment": "default",
          "promptTokens": 245,
          "completionTokens": 811,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        }
      ],
      "createdAt": "2025-12-10T21:07:51.822Z",
      "updatedAt": "2025-12-10T21:09:04.015Z",
      "environment": "default"
    },
    {
      "id": "9c887978",
      "timestamp": "2025-12-10T21:05:47.278000+00:00",
      "name": "9c88_py_sketch_generator",
      "input": null,
      "output": {
        "status": "failed",
        "last_code": "import cv2\nimport numpy as np\nimport tensorflow as tf\nfrom sklearn.metrics import average_precision_score\n\n# Configuration parameters\nmodel_path  = \"models/ssd-mobilenet_v1/detect.tflite\"\nlabel_path  = \"models/ssd-mobilenet_v1/labelmap.txt\"\ninput_path  = \"data/object_detection/sheeps.mp4\"\noutput_path  = \"results/object_detection/test_results/sheeps_detections.mp4\"\nconfidence_threshold  = 0.5\n\n# Phase 1: Setup\ndef load_labels(label_file):\n    with open(label_file, 'r') as file:\n        labels = [line.strip() for line in file.readlines()]\n    return labels\n\nlabels = load_labels(label_path)\ninterpreter = tf.lite.Interpreter(model_path=model_path)\ninterpreter.allocate_tensors()\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\n\n# Phase 2: Preprocessing\ndef preprocess_frame(frame):\n    frame_resized = cv2.resize(frame, (300, 300))\n    input_data = np.expand_dims(frame_resized, axis=0).astype(np.float32)\n    return input_data\n\n# Phase 3: Inference\ndef run_inference(input_data):\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n    interpreter.invoke()\n    boxes = interpreter.get_tensor(output_details[0]['index'])[0]\n    classes = interpreter.get_tensor(output_details[1]['index'])[0]\n    scores = interpreter.get_tensor(output_details[2]['index'])[0]\n    return boxes, classes, scores\n\n# Phase 4: Output Handling\ndef draw_detections(frame, boxes, classes, scores, labels):\n    for i in range(len(scores)):\n        if scores[i] > confidence_threshold:\n            ymin, xmin, ymax, xmax = boxes[i]\n            (left, right, top, bottom) = (xmin * frame.shape[1], xmax * frame.shape[1],\n                                          ymin * frame.shape[0], ymax * frame.shape[0])\n            cv2.rectangle(frame, (int(left), int(top)), (int(right), int(bottom)),\n                          (0, 255, 0), 2)\n            label = f\"{labels[int(classes[i])]}: {scores[i]:.2f}\"\n            cv2.putText(frame, label, (int(left), int(top) - 10),\n                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n\ndef compute_map(ground_truths, predictions):\n    # Placeholder for mAP computation\n    return average_precision_score(ground_truths, predictions)\n\n# Main processing loop\ncap = cv2.VideoCapture(input_path)\nfourcc = cv2.VideoWriter_fourcc(*'mp4v')\nout = cv2.VideoWriter(output_path, fourcc, 30.0, (int(cap.get(3)), int(cap.get(4))))\n\nground_truths = []\npredictions = []\n\nwhile cap.isOpened():\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    input_data = preprocess_frame(frame)\n    boxes, classes, scores = run_inference(input_data)\n\n    draw_detections(frame, boxes, classes, scores, labels)\n\n    # Collect ground truths and predictions for mAP computation\n    # This is a simplified example; in practice, you'd need actual ground truth data\n    ground_truths.append([1] * len(scores))  # Placeholder for actual ground truths\n    predictions.append(scores)  # Assuming all detections are relevant\n\n    out.write(frame)\n\ncap.release()\nout.release()\n\n# Compute mAP (placeholder logic)\nmap_score = compute_map(ground_truths, predictions)\nprint(f\"Mean Average Precision: {map_score:.2f}\")",
        "last_error": "Max retries reached with failure. Last error from execution: 2025-12-10 23:07:22.373832: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n2025-12-10 23:07:22.377261: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n2025-12-10 23:07:22.388507: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2025-12-10 23:07:22.406794: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2025-12-10 23:07:22.412343: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n2025-12-10 23:07:22.425706: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\nTo enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n2025-12-10 23:07:23.207171: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\nINFO: Created TensorFlow Lite XNNPACK delegate for CPU.\nTraceback (most recent call last):\n  File \"/home/wuguangh/Projects/03.12/tinyml-autopilot-pm.03.12.2025/results/object_detection/sketches/tmp_20251210230722_psg_phi4:latest/tmp_20251210230722_psg_phi4:latest.py\", line 71, in <module>\n    boxes, classes, scores = run_inference(input_data)\n  File \"/home/wuguangh/Projects/03.12/tinyml-autopilot-pm.03.12.2025/results/object_detection/sketches/tmp_20251210230722_psg_phi4:latest/tmp_20251210230722_psg_phi4:latest.py\", line 33, in run_inference\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n  File \"/home/wuguangh/.conda/envs/tinyml/lib/python3.10/site-packages/tensorflow/lite/python/interpreter.py\", line 732, in set_tensor\n    self._interpreter.SetTensor(tensor_index, value)\nValueError: Cannot set tensor: Got value of type FLOAT32 but expected type UINT8 for input 175, name: normalized_input_image_tensor \n"
      },
      "session_id": "phi4_9e98_psg_batch",
      "metadata": {
        "num_run": 8
      },
      "tags": [
        "ablation",
        "benchmark",
        "phi4:latest",
        "py_sketch_generator"
      ],
      "latency": 98.067,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-23-05-47-279282_chatcmpl-4bbfea71-11bf-431b-aa37-e4abe2960d9b",
          "traceId": "9c887978",
          "type": "GENERATION",
          "name": "9c88_psg_gen_attempt#1",
          "startTime": "2025-12-10T21:05:47.279000+00:00",
          "endTime": "2025-12-10T21:06:05.449000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 18170.0,
          "totalTokens": 1240,
          "costDetails": {},
          "environment": "default",
          "promptTokens": 245,
          "completionTokens": 995,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-23-06-05-586776_chatcmpl-431b174d-598f-49cf-8369-a9a1aefb21e8",
          "traceId": "9c887978",
          "type": "GENERATION",
          "name": "9c88_psg_gen_attempt#2",
          "startTime": "2025-12-10T21:06:05.586000+00:00",
          "endTime": "2025-12-10T21:06:23.397000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 17811.0,
          "totalTokens": 1229,
          "costDetails": {},
          "environment": "default",
          "promptTokens": 245,
          "completionTokens": 984,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-23-06-26-374016_chatcmpl-37d1398e-c5ea-4c6f-935f-ca3b2df12ba4",
          "traceId": "9c887978",
          "type": "GENERATION",
          "name": "9c88_psg_gen_attempt#3",
          "startTime": "2025-12-10T21:06:26.374000+00:00",
          "endTime": "2025-12-10T21:06:46.407000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 20033.0,
          "totalTokens": 1347,
          "costDetails": {},
          "environment": "default",
          "promptTokens": 245,
          "completionTokens": 1102,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-23-06-49-441766_chatcmpl-a83ab535-e9e6-48df-9e99-ee01e80feae5",
          "traceId": "9c887978",
          "type": "GENERATION",
          "name": "9c88_psg_gen_attempt#4",
          "startTime": "2025-12-10T21:06:49.441000+00:00",
          "endTime": "2025-12-10T21:07:06.289000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 16848.0,
          "totalTokens": 1175,
          "costDetails": {},
          "environment": "default",
          "promptTokens": 245,
          "completionTokens": 930,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-23-07-07-010963_chatcmpl-9c1401cf-82b7-4dcc-a1a8-ce96d037dd1e",
          "traceId": "9c887978",
          "type": "GENERATION",
          "name": "9c88_psg_gen_attempt#5",
          "startTime": "2025-12-10T21:07:07.010000+00:00",
          "endTime": "2025-12-10T21:07:22.060000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 15050.0,
          "totalTokens": 1076,
          "costDetails": {},
          "environment": "default",
          "promptTokens": 245,
          "completionTokens": 831,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "52a0afb4-8b5f-40a8-8771-1b046305e900",
          "traceId": "9c887978",
          "type": "SPAN",
          "name": "error_9c_psg_failure_signal_py_sketch_generator",
          "startTime": "2025-12-10T21:07:25.346000+00:00",
          "level": "ERROR",
          "statusMessage": "Failed. Last error: Max retries reached with failure. Last error from execution: 2025-12-10 23:07:22.373832: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n2025-12-10 23:07:22.377261: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n2025-12-10 23:07:22.388507: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2025-12-10 23:07:22.406794: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2025-12-10 23:07:22.412343: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n2025-12-10 23:07:22.425706: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\nTo enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n2025-12-10 23:07:23.207171: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\nINFO: Created TensorFlow Lite XNNPACK delegate for CPU.\nTraceback (most recent call last):\n  File \"/home/wuguangh/Projects/03.12/tinyml-autopilot-pm.03.12.2025/results/object_detection/sketches/tmp_20251210230722_psg_phi4:latest/tmp_20251210230722_psg_phi4:latest.py\", line 71, in <module>\n    boxes, classes, scores = run_inference(input_data)\n  File \"/home/wuguangh/Projects/03.12/tinyml-autopilot-pm.03.12.2025/results/object_detection/sketches/tmp_20251210230722_psg_phi4:latest/tmp_20251210230722_psg_phi4:latest.py\", line 33, in run_inference\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n  File \"/home/wuguangh/.conda/envs/tinyml/lib/python3.10/site-packages/tensorflow/lite/python/interpreter.py\", line 732, in set_tensor\n    self._interpreter.SetTensor(tensor_index, value)\nValueError: Cannot set tensor: Got value of type FLOAT32 but expected type UINT8 for input 175, name: normalized_input_image_tensor \n",
          "calculatedTotalCost": 0.0,
          "totalTokens": 0,
          "costDetails": {},
          "environment": "default",
          "promptTokens": 0,
          "completionTokens": 0,
          "endTime": null,
          "model": null,
          "modelParameters": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null,
          "latency": null
        }
      ],
      "createdAt": "2025-12-10T21:05:47.797Z",
      "updatedAt": "2025-12-10T21:07:30.978Z",
      "environment": "default"
    },
    {
      "id": "d655781d",
      "timestamp": "2025-12-10T21:04:11.311000+00:00",
      "name": "d655_py_sketch_generator",
      "input": null,
      "output": {
        "status": "success",
        "sketch": "import cv2\nimport numpy as np\nimport tensorflow as tf\nfrom tflite_runtime.interpreter import Interpreter\n\n# Configuration parameters\nmodel_path  = \"models/ssd-mobilenet_v1/detect.tflite\"\nlabel_path  = \"models/ssd-mobilenet_v1/labelmap.txt\"\ninput_path  = \"data/object_detection/sheeps.mp4\"\noutput_path  = \"results/object_detection/test_results/sheeps_detections.mp4\"\nconfidence_threshold  = 0.5\n\n# Setup phase\ndef load_labels(label_path):\n    with open(label_path, 'r') as f:\n        labels = [line.strip() for line in f.readlines()]\n    return labels\n\ndef load_interpreter(model_path):\n    interpreter = Interpreter(model_path=model_path)\n    interpreter.allocate_tensors()\n    return interpreter\n\ninterpreter = load_interpreter(model_path)\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\n\nheight, width, channels = input_details[0]['shape'][1:]\nlabels = load_labels(label_path)\n\n# Preprocessing phase\ndef preprocess_frame(frame):\n    frame_resized = cv2.resize(frame, (width, height))\n    input_data = np.expand_dims(frame_resized, axis=0)\n    return input_data\n\n# Inference phase\ndef run_inference(interpreter, input_data):\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n    interpreter.invoke()\n    boxes = interpreter.get_tensor(output_details[0]['index'])[0]\n    classes = interpreter.get_tensor(output_details[1]['index'])[0]\n    scores = interpreter.get_tensor(output_details[2]['index'])[0]\n\n    return boxes, classes, scores\n\n# Output handling phase\ndef draw_boxes(frame, boxes, classes, scores):\n    for i in range(len(scores)):\n        if scores[i] > confidence_threshold:\n            ymin, xmin, ymax, xmax = boxes[i]\n            (left, right, top, bottom) = (xmin * frame.shape[1], xmax * frame.shape[1],\n                                          ymin * frame.shape[0], ymax * frame.shape[0])\n            cv2.rectangle(frame, (int(left), int(top)), (int(right), int(bottom)),\n                          (10, 255, 0), 2)\n\n            class_id = int(classes[i])\n            label = f\"{labels[class_id]}: {scores[i]:.2f}\"\n            cv2.putText(frame, label, (int(left), int(top) - 5),\n                        cv2.FONT_HERSHEY_SIMPLEX, 0.7, (10, 255, 0), 2)\n    return frame\n\ndef compute_map(boxes, classes, scores):\n    # Placeholder function for mAP computation\n    # This requires ground truth data and a more complex implementation.\n    print(\"mAP computation would be implemented here.\")\n    pass\n\n# Main processing loop\ncap = cv2.VideoCapture(input_path)\nfourcc = cv2.VideoWriter_fourcc(*'mp4v')\nout = cv2.VideoWriter(output_path, fourcc, 20.0, (int(cap.get(3)), int(cap.get(4))))\n\nwhile cap.isOpened():\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    input_data = preprocess_frame(frame)\n    boxes, classes, scores = run_inference(interpreter, input_data)\n    draw_boxes(frame, boxes, classes, scores)\n\n    # Compute mAP (requires ground truth data)\n    compute_map(boxes, classes, scores)\n\n    out.write(frame)\n\ncap.release()\nout.release()\ncv2.destroyAllWindows()"
      },
      "session_id": "phi4_9e98_psg_batch",
      "metadata": {
        "num_run": 7
      },
      "tags": [
        "ablation",
        "benchmark",
        "phi4:latest",
        "py_sketch_generator"
      ],
      "latency": 36.181,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-23-04-11-312372_chatcmpl-e5d8ef55-137c-499f-b138-24f67877a69b",
          "traceId": "d655781d",
          "type": "GENERATION",
          "name": "d655_psg_gen_attempt#1",
          "startTime": "2025-12-10T21:04:11.312000+00:00",
          "endTime": "2025-12-10T21:04:29.962000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 18650.0,
          "totalTokens": 1268,
          "costDetails": {},
          "environment": "default",
          "promptTokens": 245,
          "completionTokens": 1023,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-23-04-32-957619_chatcmpl-9f4fe14c-a3e5-4823-9130-fd28bb6ee431",
          "traceId": "d655781d",
          "type": "GENERATION",
          "name": "d655_psg_gen_attempt#2",
          "startTime": "2025-12-10T21:04:32.957000+00:00",
          "endTime": "2025-12-10T21:04:47.493000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 14536.0,
          "totalTokens": 1048,
          "costDetails": {},
          "environment": "default",
          "promptTokens": 245,
          "completionTokens": 803,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        }
      ],
      "createdAt": "2025-12-10T21:04:11.830Z",
      "updatedAt": "2025-12-10T21:05:27.436Z",
      "environment": "default"
    },
    {
      "id": "b5f0b2ec",
      "timestamp": "2025-12-10T21:02:59.386000+00:00",
      "name": "b5f0_py_sketch_generator",
      "input": null,
      "output": {
        "status": "success",
        "sketch": "import cv2\nfrom tflite_runtime.interpreter import Interpreter\nimport numpy as np\n\ndef load_labels(label_path):\n    with open(label_path, 'r') as f:\n        return [line.strip() for line in f.readlines()]\n\ndef set_input_tensor(interpreter, image):\n    tensor_index = interpreter.get_input_details()[0]['index']\n    input_shape = interpreter.get_input_details()[0]['shape']\n    image = cv2.resize(image, (input_shape[2], input_shape[1]))\n    image = np.expand_dims(image, axis=0)\n    interpreter.set_tensor(tensor_index, image)\n\ndef get_output(interpreter):\n    boxes = interpreter.get_tensor(interpreter.get_output_details()[0]['index'])[0]\n    classes = interpreter.get_tensor(interpreter.get_output_details()[1]['index'])[0]\n    scores = interpreter.get_tensor(interpreter.get_output_details()[2]['index'])[0]\n    count = int(interpreter.get_tensor(interpreter.get_output_details()[3]['index'])[0])\n    return boxes, classes, scores, count\n\ndef draw_detections(image, boxes, class_ids, scores, labels, confidence_threshold):\n    height, width, _ = image.shape\n    for i in range(len(scores)):\n        if scores[i] >= confidence_threshold:\n            ymin, xmin, ymax, xmax = boxes[i]\n            left, right, top, bottom = int(xmin * width), int(xmax * width), int(ymin * height), int(ymax * height)\n            cv2.rectangle(image, (left, top), (right, bottom), (0, 255, 0), 2)\n            label = f'{labels[int(class_ids[i])]}: {int(scores[i] * 100)}%'\n            cv2.putText(image, label, (left, top - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 1)\n\ndef compute_map(ground_truths, predictions):\n    # Placeholder for mAP computation logic\n    # This function should be implemented with actual mAP calculation based on ground truths and predictions\n    return 0.0\n\n# Configuration parameters\nmodel_path  = \"models/ssd-mobilenet_v1/detect.tflite\"\nlabel_path  = \"models/ssd-mobilenet_v1/labelmap.txt\"\ninput_path  = \"data/object_detection/sheeps.mp4\"\noutput_path  = \"results/object_detection/test_results/sheeps_detections.mp4\"\nconfidence_threshold  = 0.5\n\n# Setup\ninterpreter = Interpreter(model_path=model_path)\ninterpreter.allocate_tensors()\nlabels = load_labels(label_path)\n\n# Preprocessing and Inference\ncap = cv2.VideoCapture(input_path)\nfourcc = cv2.VideoWriter_fourcc(*'mp4v')\nout = cv2.VideoWriter(output_path, fourcc, 20.0, (int(cap.get(3)), int(cap.get(4))))\n\nwhile cap.isOpened():\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    set_input_tensor(interpreter, frame)\n    interpreter.invoke()\n    boxes, class_ids, scores, count = get_output(interpreter)\n\n    draw_detections(frame, boxes[:count], class_ids[:count], scores[:count], labels, confidence_threshold)\n\n    out.write(frame)\n\ncap.release()\nout.release()\n\n# Output handling\n# Assuming ground_truths is available for mAP calculation\nground_truths = []  # This should be replaced with actual ground truth data\npredictions = []  # Collect predictions in a suitable format during inference\n\nmap_score = compute_map(ground_truths, predictions)\nprint(f'mAP: {map_score}')"
      },
      "session_id": "phi4_9e98_psg_batch",
      "metadata": {
        "num_run": 6
      },
      "tags": [
        "ablation",
        "benchmark",
        "phi4:latest",
        "py_sketch_generator"
      ],
      "latency": 14.934,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-23-02-59-387914_chatcmpl-bdaa6aba-c956-4e38-b0f1-dd91bf3f70d8",
          "traceId": "b5f0b2ec",
          "type": "GENERATION",
          "name": "b5f0_psg_gen_attempt#1",
          "startTime": "2025-12-10T21:02:59.387000+00:00",
          "endTime": "2025-12-10T21:03:14.321000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 14934.0,
          "totalTokens": 1065,
          "costDetails": {},
          "environment": "default",
          "promptTokens": 245,
          "completionTokens": 820,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        }
      ],
      "createdAt": "2025-12-10T21:02:59.907Z",
      "updatedAt": "2025-12-10T21:03:51.087Z",
      "environment": "default"
    },
    {
      "id": "c9f55bbd",
      "timestamp": "2025-12-10T21:01:03.296000+00:00",
      "name": "c9f5_py_sketch_generator",
      "input": null,
      "output": {
        "status": "success",
        "sketch": "import cv2\nfrom tflite_runtime.interpreter import Interpreter\nimport numpy as np\nimport tensorflow as tf\n\n# Configuration parameters\nmodel_path  = \"models/ssd-mobilenet_v1/detect.tflite\"\nlabel_path  = \"models/ssd-mobilenet_v1/labelmap.txt\"\ninput_path  = \"data/object_detection/sheeps.mp4\"\noutput_path  = \"results/object_detection/test_results/sheeps_detections.mp4\"\nconfidence_threshold  = 0.5\n\n# 1. Setup\ninterpreter = Interpreter(model_path=model_path)\ninterpreter.allocate_tensors()\n\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\n\n_, input_height, input_width, _ = input_details[0]['shape']\n\nlabel_map = [line.strip() for line in open(label_path)]\n\ndef load_labels(path):\n    with open(path, 'r') as file:\n        return [line.strip() for line in file.readlines()]\n\n# 2. Preprocessing\ndef preprocess_frame(frame, input_size):\n    frame_resized = cv2.resize(frame, (input_size[1], input_size[0]))\n    input_data = np.expand_dims(frame_resized, axis=0)\n    return input_data\n\n# 3. Inference\ndef set_input_tensor(interpreter, image):\n    tensor_index = interpreter.get_input_details()[0]['index']\n    input_shape = interpreter.get_input_details()[0]['shape']\n    input_data = cv2.resize(image, (input_shape[1], input_shape[2]))\n    input_data = np.expand_dims(input_data, axis=0)\n    interpreter.set_tensor(tensor_index, input_data)\n\ndef get_output(interpreter):\n    boxes = interpreter.get_tensor(output_details[0]['index'])[0]\n    classes = interpreter.get_tensor(output_details[1]['index'])[0]\n    scores = interpreter.get_tensor(output_details[2]['index'])[0]\n    count = int(interpreter.get_tensor(output_details[3]['index'])[0])\n    return boxes, classes, scores, count\n\n# 4. Output handling\ndef draw_boxes(frame, boxes, classes, scores, label_map, threshold):\n    for i in range(len(scores)):\n        if scores[i] >= threshold:\n            ymin, xmin, ymax, xmax = boxes[i]\n            left, right, top, bottom = int(xmin * frame.shape[1]), int(xmax * frame.shape[1]), int(ymin * frame.shape[0]), int(ymax * frame.shape[0])\n            cv2.rectangle(frame, (left, top), (right, bottom), (10, 255, 0), thickness=4)\n            label = f\"{label_map[int(classes[i])]}: {int(scores[i]*100)}%\"\n            label_size, base_line = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.7, 2)\n            top = max(top, label_size[1])\n            cv2.rectangle(frame, (left, top - round(1.5*label_size[1])), (left + round(1.5*label_size[0]), top + base_line), (255, 255, 255), cv2.FILLED)\n            cv2.putText(frame, label, (left, top), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 0), thickness=2)\n\ndef compute_mAP(detections, ground_truths):\n    # Placeholder for mAP computation logic\n    pass\n\n# Main processing loop\ncap = cv2.VideoCapture(input_path)\nfourcc = cv2.VideoWriter_fourcc(*'mp4v')\nout = cv2.VideoWriter(output_path, fourcc, 20.0, (int(cap.get(3)), int(cap.get(4))))\n\nwhile cap.isOpened():\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    input_data = preprocess_frame(frame, (input_height, input_width))\n    set_input_tensor(interpreter, frame)\n    interpreter.invoke()\n\n    boxes, classes, scores, count = get_output(interpreter)\n\n    draw_boxes(frame, boxes, classes, scores, label_map, confidence_threshold)\n\n    out.write(frame)\n\ncap.release()\nout.release()\ncv2.destroyAllWindows()"
      },
      "session_id": "phi4_9e98_psg_batch",
      "metadata": {
        "num_run": 5
      },
      "tags": [
        "ablation",
        "benchmark",
        "phi4:latest",
        "py_sketch_generator"
      ],
      "latency": 55.547,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-23-01-03-297656_chatcmpl-ceba05ef-9977-400a-b43d-33a2bd9d20e5",
          "traceId": "c9f55bbd",
          "type": "GENERATION",
          "name": "c9f5_psg_gen_attempt#1",
          "startTime": "2025-12-10T21:01:03.297000+00:00",
          "endTime": "2025-12-10T21:01:23.806000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 20509.0,
          "totalTokens": 1368,
          "costDetails": {},
          "environment": "default",
          "promptTokens": 245,
          "completionTokens": 1123,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-23-01-26-803393_chatcmpl-bd4478cf-0b9c-4084-82a5-923b234de726",
          "traceId": "c9f55bbd",
          "type": "GENERATION",
          "name": "c9f5_psg_gen_attempt#2",
          "startTime": "2025-12-10T21:01:26.803000+00:00",
          "endTime": "2025-12-10T21:01:39.151000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 12348.0,
          "totalTokens": 928,
          "costDetails": {},
          "environment": "default",
          "promptTokens": 245,
          "completionTokens": 683,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-23-01-42-130055_chatcmpl-427c0ce0-0489-4ac8-9dc5-25a7197e387a",
          "traceId": "c9f55bbd",
          "type": "GENERATION",
          "name": "c9f5_psg_gen_attempt#3",
          "startTime": "2025-12-10T21:01:42.130000+00:00",
          "endTime": "2025-12-10T21:01:58.844000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 16714.0,
          "totalTokens": 1168,
          "costDetails": {},
          "environment": "default",
          "promptTokens": 245,
          "completionTokens": 923,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        }
      ],
      "createdAt": "2025-12-10T21:01:03.816Z",
      "updatedAt": "2025-12-10T21:02:39.533Z",
      "environment": "default"
    },
    {
      "id": "c0020904",
      "timestamp": "2025-12-10T20:59:51.364000+00:00",
      "name": "c002_py_sketch_generator",
      "input": null,
      "output": {
        "status": "success",
        "sketch": "import cv2\nfrom tflite_runtime.interpreter import Interpreter\nimport numpy as np\n\n# Configuration parameters\nmodel_path  = \"models/ssd-mobilenet_v1/detect.tflite\"\nlabel_path  = \"models/ssd-mobilenet_v1/labelmap.txt\"\ninput_path  = \"data/object_detection/sheeps.mp4\"\noutput_path  = \"results/object_detection/test_results/sheeps_detections.mp4\"\nconfidence_threshold  = 0.5\n\n# Setup\ndef load_labels(label_path):\n    with open(label_path, 'r') as f:\n        return [line.strip() for line in f.readlines()]\n\nlabels = load_labels(label_path)\n\ninterpreter = Interpreter(model_path=model_path)\ninterpreter.allocate_tensors()\n\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\n\nheight = input_details[0]['shape'][1]\nwidth = input_details[0]['shape'][2]\n\n# Preprocessing\ndef preprocess_frame(frame):\n    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n    resized_frame = cv2.resize(frame_rgb, (width, height))\n    input_data = np.expand_dims(resized_frame, axis=0)\n    return input_data\n\n# Inference\ndef set_input_tensor(interpreter, image):\n    tensor_index = interpreter.get_input_details()[0]['index']\n    input_tensor = interpreter.tensor(tensor_index)()[0]\n    input_tensor[:, :] = image\n\ndef get_output(interpreter):\n    boxes = interpreter.get_output_details()[0]['index']\n    classes = interpreter.get_output_details()[1]['index']\n    scores = interpreter.get_output_details()[2]['index']\n\n    box_data = interpreter.get_tensor(boxes)[0]\n    class_data = interpreter.get_tensor(classes)[0]\n    score_data = interpreter.get_tensor(scores)[0]\n\n    return box_data, class_data, score_data\n\ndef draw_detections(frame, boxes, classes, scores, labels):\n    for i in range(len(scores)):\n        if scores[i] >= confidence_threshold:\n            ymin, xmin, ymax, xmax = boxes[i]\n            (left, right, top, bottom) = (xmin * frame.shape[1], xmax * frame.shape[1],\n                                          ymin * frame.shape[0], ymax * frame.shape[0])\n            cv2.rectangle(frame, (int(left), int(top)), (int(right), int(bottom)), (10, 255, 0), 2)\n\n            label = '%s: %d%%' % (labels[int(classes[i])], int(scores[i] * 100))\n            label_size, base_line = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.7, 2)\n            top = max(top, label_size[1])\n            cv2.rectangle(frame, (int(left), int(top - label_size[1])), \n                          (int(left + label_size[0]), int(top + base_line)), \n                          (255, 255, 10), cv2.FILLED)\n            cv2.putText(frame, label, (int(left), int(top)), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 0), 2)\n\n# Output handling\ndef main():\n    cap = cv2.VideoCapture(input_path)\n    out = None\n\n    while cap.isOpened():\n        ret, frame = cap.read()\n        if not ret:\n            break\n\n        input_data = preprocess_frame(frame)\n        set_input_tensor(interpreter, input_data)\n        interpreter.invoke()\n\n        boxes, classes, scores = get_output(interpreter)\n        draw_detections(frame, boxes, classes, scores, labels)\n\n        if out is None:\n            fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n            out = cv2.VideoWriter(output_path, fourcc, 30.0, (frame.shape[1], frame.shape[0]))\n\n        out.write(frame)\n\n    cap.release()\n    out.release()\n\nif __name__ == '__main__':\n    main()"
      },
      "session_id": "phi4_9e98_psg_batch",
      "metadata": {
        "num_run": 4
      },
      "tags": [
        "ablation",
        "benchmark",
        "phi4:latest",
        "py_sketch_generator"
      ],
      "latency": 14.935,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-22-59-51-365200_chatcmpl-90a64a92-765d-44a6-a56a-b0eada9b357c",
          "traceId": "c0020904",
          "type": "GENERATION",
          "name": "c002_psg_gen_attempt#1",
          "startTime": "2025-12-10T20:59:51.365000+00:00",
          "endTime": "2025-12-10T21:00:06.300000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 14935.0,
          "totalTokens": 1066,
          "costDetails": {},
          "environment": "default",
          "promptTokens": 245,
          "completionTokens": 821,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        }
      ],
      "createdAt": "2025-12-10T20:59:51.883Z",
      "updatedAt": "2025-12-10T21:00:43.009Z",
      "environment": "default"
    },
    {
      "id": "342c7cd1",
      "timestamp": "2025-12-10T20:58:13.365000+00:00",
      "name": "342c_py_sketch_generator",
      "input": null,
      "output": {
        "status": "success",
        "sketch": "import cv2\nimport numpy as np\nfrom tflite_runtime.interpreter import Interpreter\nfrom sklearn.metrics import average_precision_score\n\n# Configuration parameters\nmodel_path  = \"models/ssd-mobilenet_v1/detect.tflite\"\nlabel_path  = \"models/ssd-mobilenet_v1/labelmap.txt\"\ninput_path  = \"data/object_detection/sheeps.mp4\"\noutput_path  = \"results/object_detection/test_results/sheeps_detections.mp4\"\nconfidence_threshold  = 0.5\n\n# Phase 1: Setup\ndef load_labels(label_file):\n    with open(label_file, 'r') as file:\n        labels = [line.strip() for line in file.readlines()]\n    return labels\n\ndef load_tflite_model(model_path):\n    interpreter = Interpreter(model_path=model_path)\n    interpreter.allocate_tensors()\n    return interpreter\n\n# Phase 2: Preprocessing\ndef preprocess_frame(frame, input_details):\n    img_height, img_width = input_details[0]['shape'][1:3]\n    frame_resized = cv2.resize(frame, (img_width, img_height))\n    input_data = np.expand_dims(frame_resized, axis=0)\n    return input_data\n\n# Phase 3: Inference\ndef set_input_tensor(interpreter, input_data):\n    input_details = interpreter.get_input_details()\n    tensor_index = input_details[0]['index']\n    interpreter.set_tensor(tensor_index, input_data)\n\ndef get_output(interpreter):\n    output_details = interpreter.get_output_details()\n    boxes = interpreter.get_tensor(output_details[0]['index'])[0]  # Bounding box coordinates\n    classes = interpreter.get_tensor(output_details[1]['index'])[0]  # Class index\n    scores = interpreter.get_tensor(output_details[2]['index'])[0]   # Confidence score\n    return boxes, classes, scores\n\n# Phase 4: Output handling\ndef draw_boxes(frame, boxes, classes, scores, labels, threshold):\n    frame_height, frame_width, _ = frame.shape\n    for i in range(len(scores)):\n        if scores[i] >= threshold:\n            ymin, xmin, ymax, xmax = boxes[i]\n            (left, right, top, bottom) = (xmin * frame_width, xmax * frame_width,\n                                          ymin * frame_height, ymax * frame_height)\n            cv2.rectangle(frame, (int(left), int(top)), (int(right), int(bottom)), (10, 255, 0), 2)\n            label = f\"{labels[int(classes[i])]}: {int(scores[i] * 100)}%\"\n            cv2.putText(frame, label, (int(left), int(top) - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (10, 255, 0), 2)\n\ndef compute_map(true_labels, pred_scores):\n    return average_precision_score(true_labels, pred_scores)\n\n# Main processing\nlabels = load_labels(label_path)\ninterpreter = load_tflite_model(model_path)\ninput_details = interpreter.get_input_details()\n\ncap = cv2.VideoCapture(input_path)\nfourcc = cv2.VideoWriter_fourcc(*'mp4v')\nout = cv2.VideoWriter(output_path, fourcc, 30.0, (int(cap.get(3)), int(cap.get(4))))\n\nall_true_labels = []\nall_pred_scores = []\n\nwhile cap.isOpened():\n    ret, frame = cap.read()\n    if not ret:\n        break\n    \n    input_data = preprocess_frame(frame, input_details)\n    set_input_tensor(interpreter, input_data)\n    interpreter.invoke()\n    boxes, classes, scores = get_output(interpreter)\n\n    draw_boxes(frame, boxes, classes, scores, labels, confidence_threshold)\n    \n    # Collect data for mAP computation\n    true_labels = [1 if score >= confidence_threshold else 0 for score in scores]\n    all_true_labels.extend(true_labels)\n    all_pred_scores.extend(scores)\n\n    out.write(frame)\n\ncap.release()\nout.release()\n\n# Compute mAP\nmean_ap = compute_map(all_true_labels, all_pred_scores)\nprint(f\"Mean Average Precision (mAP): {mean_ap}\")"
      },
      "session_id": "phi4_9e98_psg_batch",
      "metadata": {
        "num_run": 3
      },
      "tags": [
        "ablation",
        "benchmark",
        "phi4:latest",
        "py_sketch_generator"
      ],
      "latency": 40.595,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-22-58-13-366838_chatcmpl-b9185b1e-b38d-4f3b-bf12-06f6b227fa19",
          "traceId": "342c7cd1",
          "type": "GENERATION",
          "name": "342c_psg_gen_attempt#1",
          "startTime": "2025-12-10T20:58:13.366000+00:00",
          "endTime": "2025-12-10T20:58:34.216000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 20850.0,
          "totalTokens": 1388,
          "costDetails": {},
          "environment": "default",
          "promptTokens": 245,
          "completionTokens": 1143,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-22-58-37-187853_chatcmpl-f52a15e0-d63b-412d-9d9b-8739a1557f76",
          "traceId": "342c7cd1",
          "type": "GENERATION",
          "name": "342c_psg_gen_attempt#2",
          "startTime": "2025-12-10T20:58:37.187000+00:00",
          "endTime": "2025-12-10T20:58:53.961000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 16774.0,
          "totalTokens": 1171,
          "costDetails": {},
          "environment": "default",
          "promptTokens": 245,
          "completionTokens": 926,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        }
      ],
      "createdAt": "2025-12-10T20:58:13.884Z",
      "updatedAt": "2025-12-10T20:59:31.552Z",
      "environment": "default"
    },
    {
      "id": "38fe5dcf",
      "timestamp": "2025-12-10T20:56:15.397000+00:00",
      "name": "38fe_py_sketch_generator",
      "input": null,
      "output": {
        "status": "failed",
        "last_code": "import cv2\nimport numpy as np\nfrom tflite_runtime.interpreter import Interpreter\n\n# Configuration parameters\nmodel_path  = \"models/ssd-mobilenet_v1/detect.tflite\"\nlabel_path  = \"models/ssd-mobilenet_v1/labelmap.txt\"\ninput_path  = \"data/object_detection/sheeps.mp4\"\noutput_path  = \"results/object_detection/test_results/sheeps_detections.mp4\"\nconfidence_threshold  = 0.5\n\n# Phase 1: Setup\ndef load_labels(label_file):\n    with open(label_file, 'r') as file:\n        labels = [line.strip() for line in file.readlines()]\n    return labels\n\nlabels = load_labels(label_path)\n\ndef load_model(model_file):\n    interpreter = Interpreter(model_path=model_file)\n    interpreter.allocate_tensors()\n    return interpreter\n\ninterpreter = load_model(model_path)\n\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\n\n# Phase 2: Preprocessing\ndef preprocess_frame(frame, input_shape):\n    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n    resized_frame = cv2.resize(frame_rgb, (input_shape[1], input_shape[0]))\n    input_data = np.expand_dims(resized_frame, axis=0).astype(np.float32)\n    return input_data\n\ndef get_output(interpreter):\n    boxes = interpreter.get_tensor(output_details[0]['index'])[0] # Bounding box coordinates of detected objects\n    classes = interpreter.get_tensor(output_details[1]['index'])[0] # Class index of detected objects\n    scores = interpreter.get_tensor(output_details[2]['index'])[0] # Confidence of detected objects\n    return boxes, classes, scores\n\n# Phase 3: Inference\ndef run_inference(frame):\n    input_data = preprocess_frame(frame, input_details[0]['shape'][1:3])\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n    interpreter.invoke()\n    return get_output(interpreter)\n\n# Phase 4: Output Handling\ndef draw_boxes(frame, boxes, classes, scores, labels):\n    for i in range(len(scores)):\n        if scores[i] >= confidence_threshold:\n            ymin, xmin, ymax, xmax = boxes[i]\n            (left, right, top, bottom) = (xmin * frame.shape[1], xmax * frame.shape[1],\n                                          ymin * frame.shape[0], ymax * frame.shape[0])\n            cv2.rectangle(frame, (int(left), int(top)), (int(right), int(bottom)),\n                          (10, 255, 0), 2)\n            label = f'{labels[int(classes[i])]}: {int(scores[i]*100)}%'\n            cv2.putText(frame, label, (int(left), int(top)-10),\n                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2)\n    return frame\n\ndef compute_map(ground_truths, predictions):\n    # Placeholder for mAP computation logic\n    pass\n\ncap = cv2.VideoCapture(input_path)\nfourcc = cv2.VideoWriter_fourcc(*'mp4v')\nout = None\n\nwhile cap.isOpened():\n    ret, frame = cap.read()\n    if not ret:\n        break\n    \n    boxes, classes, scores = run_inference(frame)\n    frame_with_boxes = draw_boxes(frame, boxes, classes, scores, labels)\n\n    if out is None:\n        height, width, _ = frame.shape\n        out = cv2.VideoWriter(output_path, fourcc, 20.0, (width, height))\n    \n    out.write(frame_with_boxes)\n\ncap.release()\nout.release()\n\n# Placeholder for mAP computation at the end of processing all frames\n# compute_map(ground_truths, predictions)",
        "last_error": "Max retries reached with failure. Last error from execution: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\nTraceback (most recent call last):\n  File \"/home/wuguangh/Projects/03.12/tinyml-autopilot-pm.03.12.2025/results/object_detection/sketches/tmp_20251210225747_psg_phi4:latest/tmp_20251210225747_psg_phi4:latest.py\", line 77, in <module>\n    boxes, classes, scores = run_inference(frame)\n  File \"/home/wuguangh/Projects/03.12/tinyml-autopilot-pm.03.12.2025/results/object_detection/sketches/tmp_20251210225747_psg_phi4:latest/tmp_20251210225747_psg_phi4:latest.py\", line 46, in run_inference\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n  File \"/home/wuguangh/.conda/envs/tinyml/lib/python3.10/site-packages/tflite_runtime/interpreter.py\", line 720, in set_tensor\n    self._interpreter.SetTensor(tensor_index, value)\nValueError: Cannot set tensor: Got value of type FLOAT32 but expected type UINT8 for input 175, name: normalized_input_image_tensor \n"
      },
      "session_id": "phi4_9e98_psg_batch",
      "metadata": {
        "num_run": 2
      },
      "tags": [
        "ablation",
        "benchmark",
        "phi4:latest",
        "py_sketch_generator"
      ],
      "latency": 91.965,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-22-56-15-398725_chatcmpl-2aa6b2bb-fec2-4fe1-b88b-2f9622039242",
          "traceId": "38fe5dcf",
          "type": "GENERATION",
          "name": "38fe_psg_gen_attempt#1",
          "startTime": "2025-12-10T20:56:15.398000+00:00",
          "endTime": "2025-12-10T20:56:31.951000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 16553.0,
          "totalTokens": 1154,
          "costDetails": {},
          "environment": "default",
          "promptTokens": 245,
          "completionTokens": 909,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-22-56-35-243862_chatcmpl-8a1d134b-9abe-4cff-9d80-0e2e4e187f0b",
          "traceId": "38fe5dcf",
          "type": "GENERATION",
          "name": "38fe_psg_gen_attempt#2",
          "startTime": "2025-12-10T20:56:35.243000+00:00",
          "endTime": "2025-12-10T20:56:58.816000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 23573.0,
          "totalTokens": 1539,
          "costDetails": {},
          "environment": "default",
          "promptTokens": 245,
          "completionTokens": 1294,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-22-56-58-960485_chatcmpl-d49d2e9f-3df3-4868-baba-6fcf5af802a4",
          "traceId": "38fe5dcf",
          "type": "GENERATION",
          "name": "38fe_psg_gen_attempt#3",
          "startTime": "2025-12-10T20:56:58.960000+00:00",
          "endTime": "2025-12-10T20:57:13.359000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 14399.0,
          "totalTokens": 1041,
          "costDetails": {},
          "environment": "default",
          "promptTokens": 245,
          "completionTokens": 796,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-22-57-16-316541_chatcmpl-97a831f1-def2-438f-be3b-58cbba5ee070",
          "traceId": "38fe5dcf",
          "type": "GENERATION",
          "name": "38fe_psg_gen_attempt#4",
          "startTime": "2025-12-10T20:57:16.316000+00:00",
          "endTime": "2025-12-10T20:57:32.987000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 16671.0,
          "totalTokens": 1165,
          "costDetails": {},
          "environment": "default",
          "promptTokens": 245,
          "completionTokens": 920,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-22-57-33-113028_chatcmpl-10d711d2-babf-490e-95d9-0305143e2879",
          "traceId": "38fe5dcf",
          "type": "GENERATION",
          "name": "38fe_psg_gen_attempt#5",
          "startTime": "2025-12-10T20:57:33.113000+00:00",
          "endTime": "2025-12-10T20:57:47.220000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 14107.0,
          "totalTokens": 1025,
          "costDetails": {},
          "environment": "default",
          "promptTokens": 245,
          "completionTokens": 780,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "d91b711b-dffb-42c2-949e-72153baa98e2",
          "traceId": "38fe5dcf",
          "type": "SPAN",
          "name": "error_38_psg_failure_signal_py_sketch_generator",
          "startTime": "2025-12-10T20:57:47.363000+00:00",
          "level": "ERROR",
          "statusMessage": "Failed. Last error: Max retries reached with failure. Last error from execution: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\nTraceback (most recent call last):\n  File \"/home/wuguangh/Projects/03.12/tinyml-autopilot-pm.03.12.2025/results/object_detection/sketches/tmp_20251210225747_psg_phi4:latest/tmp_20251210225747_psg_phi4:latest.py\", line 77, in <module>\n    boxes, classes, scores = run_inference(frame)\n  File \"/home/wuguangh/Projects/03.12/tinyml-autopilot-pm.03.12.2025/results/object_detection/sketches/tmp_20251210225747_psg_phi4:latest/tmp_20251210225747_psg_phi4:latest.py\", line 46, in run_inference\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n  File \"/home/wuguangh/.conda/envs/tinyml/lib/python3.10/site-packages/tflite_runtime/interpreter.py\", line 720, in set_tensor\n    self._interpreter.SetTensor(tensor_index, value)\nValueError: Cannot set tensor: Got value of type FLOAT32 but expected type UINT8 for input 175, name: normalized_input_image_tensor \n",
          "calculatedTotalCost": 0.0,
          "totalTokens": 0,
          "costDetails": {},
          "environment": "default",
          "promptTokens": 0,
          "completionTokens": 0,
          "endTime": null,
          "model": null,
          "modelParameters": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null,
          "latency": null
        }
      ],
      "createdAt": "2025-12-10T20:56:15.919Z",
      "updatedAt": "2025-12-10T20:57:52.901Z",
      "environment": "default"
    },
    {
      "id": "e1cdf02a",
      "timestamp": "2025-12-10T20:54:15.417000+00:00",
      "name": "e1cd_py_sketch_generator",
      "input": null,
      "output": {
        "status": "failed",
        "last_code": "import cv2\nimport numpy as np\nimport tflite_runtime.interpreter as tflite\nfrom pycocotools.coco import COCO\nfrom pycocotools.cocoeval import COCOeval\n\n# Configuration parameters\nmodel_path  = \"models/ssd-mobilenet_v1/detect.tflite\"\nlabel_path  = \"models/ssd-mobilenet_v1/labelmap.txt\"\ninput_path  = \"data/object_detection/sheeps.mp4\"\noutput_path  = \"results/object_detection/test_results/sheeps_detections.mp4\"\nconfidence_threshold  = 0.5\n\n# Load TFLite model and allocate tensors\ninterpreter = tflite.Interpreter(model_path=model_path)\ninterpreter.allocate_tensors()\n\n# Get input and output details\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\n\n# Read labels from label map file\nwith open(label_path, 'r') as f:\n    labels = [line.strip() for line in f.readlines()]\n\ndef preprocess_frame(frame):\n    \"\"\"Preprocess the frame to the required input shape.\"\"\"\n    input_shape = input_details[0]['shape']\n    frame_resized = cv2.resize(frame, (input_shape[1], input_shape[2]))\n    input_data = np.expand_dims(frame_resized, axis=0)\n    return input_data\n\ndef run_inference(input_data):\n    \"\"\"Run inference on the input data.\"\"\"\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n    interpreter.invoke()\n    \n    # Extract output\n    boxes = interpreter.get_tensor(output_details[0]['index'])[0]  # Bounding box coordinates\n    classes = interpreter.get_tensor(output_details[1]['index'])[0]  # Class index\n    scores = interpreter.get_tensor(output_details[2]['index'])[0]  # Confidence score\n    \n    return boxes, classes, scores\n\ndef draw_detections(frame, boxes, classes, scores):\n    \"\"\"Draw bounding boxes and labels on the frame.\"\"\"\n    height, width, _ = frame.shape\n    for i in range(len(scores)):\n        if scores[i] >= confidence_threshold:\n            ymin, xmin, ymax, xmax = boxes[i]\n            (left, right, top, bottom) = (xmin * width, xmax * width,\n                                          ymin * height, ymax * height)\n            \n            # Draw rectangle and label\n            cv2.rectangle(frame, (int(left), int(top)), (int(right), int(bottom)),\n                          (0, 255, 0), 2)\n            label = f'{labels[int(classes[i])]}: {scores[i]:.2f}'\n            cv2.putText(frame, label, (int(left), int(top) - 10),\n                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n\ndef compute_map(results, ground_truth_path):\n    \"\"\"Compute mean Average Precision (mAP).\"\"\"\n    coco_gt = COCO(ground_truth_path)\n    coco_dt = coco_gt.loadRes(results)\n    \n    coco_eval = COCOeval(coco_gt, coco_dt, 'bbox')\n    coco_eval.evaluate()\n    coco_eval.accumulate()\n    coco_eval.summarize()\n    \n    return coco_eval.stats[0]\n\n# Setup video capture and writer\ncap = cv2.VideoCapture(input_path)\nframe_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\nframe_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\nfps = cap.get(cv2.CAP_PROP_FPS)\n\nout = cv2.VideoWriter(output_path, cv2.VideoWriter_fourcc(*'mp4v'), fps,\n                      (frame_width, frame_height))\n\n# Process video frames\nwhile cap.isOpened():\n    ret, frame = cap.read()\n    if not ret:\n        break\n    \n    # Preprocess the frame\n    input_data = preprocess_frame(frame)\n    \n    # Run inference\n    boxes, classes, scores = run_inference(input_data)\n    \n    # Draw detections on the frame\n    draw_detections(frame, boxes, classes, scores)\n    \n    # Write the processed frame to output video\n    out.write(frame)\n\n# Release resources\ncap.release()\nout.release()\n\n# Compute mAP (assuming ground truth data is available at 'data/object_detection/annotations.json')\nresults = []  # Collect results in COCO format if needed for mAP computation\nmap_value = compute_map(results, 'data/object_detection/annotations.json')\nprint(f'mAP: {map_value:.4f}')",
        "last_error": "Max retries reached with failure. Last error from execution: Traceback (most recent call last):\n  File \"/home/wuguangh/Projects/03.12/tinyml-autopilot-pm.03.12.2025/results/object_detection/sketches/tmp_20251210225549_psg_phi4:latest/tmp_20251210225549_psg_phi4:latest.py\", line 4, in <module>\n    from pycocotools.coco import COCO\nModuleNotFoundError: No module named 'pycocotools'\n"
      },
      "session_id": "phi4_9e98_psg_batch",
      "metadata": {
        "num_run": 1
      },
      "tags": [
        "ablation",
        "benchmark",
        "phi4:latest",
        "py_sketch_generator"
      ],
      "latency": 94.021,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-22-54-15-418559_chatcmpl-2c3cb168-ec2c-44fc-a3a6-b7773730b445",
          "traceId": "e1cdf02a",
          "type": "GENERATION",
          "name": "e1cd_psg_gen_attempt#1",
          "startTime": "2025-12-10T20:54:15.418000+00:00",
          "endTime": "2025-12-10T20:54:34.486000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 19068.0,
          "totalTokens": 1278,
          "costDetails": {},
          "environment": "default",
          "promptTokens": 245,
          "completionTokens": 1033,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-22-54-34-612862_chatcmpl-a84e7b65-ab99-405a-91cd-4aa5c0f54b6f",
          "traceId": "e1cdf02a",
          "type": "GENERATION",
          "name": "e1cd_psg_gen_attempt#2",
          "startTime": "2025-12-10T20:54:34.612000+00:00",
          "endTime": "2025-12-10T20:54:47.042000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 12430.0,
          "totalTokens": 933,
          "costDetails": {},
          "environment": "default",
          "promptTokens": 245,
          "completionTokens": 688,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-22-54-48-122094_chatcmpl-7c2c9404-0bbf-4f04-abbb-05ae3a9ad569",
          "traceId": "e1cdf02a",
          "type": "GENERATION",
          "name": "e1cd_psg_gen_attempt#3",
          "startTime": "2025-12-10T20:54:48.122000+00:00",
          "endTime": "2025-12-10T20:55:06.322000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 18200.0,
          "totalTokens": 1249,
          "costDetails": {},
          "environment": "default",
          "promptTokens": 245,
          "completionTokens": 1004,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-22-55-16-659790_chatcmpl-35f908e8-e30c-4240-b0aa-47fef06490d7",
          "traceId": "e1cdf02a",
          "type": "GENERATION",
          "name": "e1cd_psg_gen_attempt#4",
          "startTime": "2025-12-10T20:55:16.659000+00:00",
          "endTime": "2025-12-10T20:55:31.566000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 14907.0,
          "totalTokens": 1069,
          "costDetails": {},
          "environment": "default",
          "promptTokens": 245,
          "completionTokens": 824,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-22-55-31-694147_chatcmpl-c48f404b-f5ea-42f2-b484-2c90d9c1873d",
          "traceId": "e1cdf02a",
          "type": "GENERATION",
          "name": "e1cd_psg_gen_attempt#5",
          "startTime": "2025-12-10T20:55:31.694000+00:00",
          "endTime": "2025-12-10T20:55:49.307000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 17613.0,
          "totalTokens": 1216,
          "costDetails": {},
          "environment": "default",
          "promptTokens": 245,
          "completionTokens": 971,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "b4cb70b2-5cac-4c84-96b9-fc4b81b51531",
          "traceId": "e1cdf02a",
          "type": "SPAN",
          "name": "error_e1_psg_failure_signal_py_sketch_generator",
          "startTime": "2025-12-10T20:55:49.439000+00:00",
          "level": "ERROR",
          "statusMessage": "Failed. Last error: Max retries reached with failure. Last error from execution: Traceback (most recent call last):\n  File \"/home/wuguangh/Projects/03.12/tinyml-autopilot-pm.03.12.2025/results/object_detection/sketches/tmp_20251210225549_psg_phi4:latest/tmp_20251210225549_psg_phi4:latest.py\", line 4, in <module>\n    from pycocotools.coco import COCO\nModuleNotFoundError: No module named 'pycocotools'\n",
          "calculatedTotalCost": 0.0,
          "totalTokens": 0,
          "costDetails": {},
          "environment": "default",
          "promptTokens": 0,
          "completionTokens": 0,
          "endTime": null,
          "model": null,
          "modelParameters": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null,
          "latency": null
        }
      ],
      "createdAt": "2025-12-10T20:54:15.935Z",
      "updatedAt": "2025-12-10T20:55:54.768Z",
      "environment": "default"
    }
  ],
  "meta": {
    "total_items": 30
  }
}
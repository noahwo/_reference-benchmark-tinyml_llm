{
  "data": [
    {
      "id": "996b2c37",
      "timestamp": "2025-12-10T20:53:01.140000+00:00",
      "name": "996b_tpu_sketch_generator",
      "input": null,
      "output": {
        "status": "success",
        "sketch": "import cv2\nfrom tflite_runtime.interpreter import Interpreter\nfrom tflite_runtime.interpreter import load_delegate\nimport numpy as np\nimport os\n\n# Configuration parameters\nmodel_path  = \"/home/mendel/tinyml_autopilot/models/edgetpu_detect.tflite\"\nlabel_path  = \"/home/mendel/tinyml_autopilot/models/labelmap.txt\"\ninput_path  = \"/home/mendel/tinyml_autopilot/data//sheeps.mp4\"\noutput_path  = \"/home/mendel/tinyml_autopilot/results/sheeps_detections.mp4\"\nconfidence_threshold  = 0.5\n\n# Phase 1: Setup\ndef load_labels(label_file):\n    with open(label_file, 'r') as file:\n        return [line.strip() for line in file.readlines()]\n\nlabels = load_labels(label_path)\n\ninterpreter = Interpreter(\n    model_path=model_path,\n    experimental_delegates=[load_delegate('/usr/lib/aarch64-linux-gnu/libedgetpu.so.1.0')]\n)\ninterpreter.allocate_tensors()\n\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\n\ninput_shape = input_details[0]['shape']\ninput_index = input_details[0]['index']\n\n# Phase 2: Preprocessing\ndef preprocess_frame(frame, target_size):\n    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n    frame_resized = cv2.resize(frame_rgb, (target_size[1], target_size[0]))\n    return np.expand_dims(frame_resized, axis=0)\n\n# Phase 3: Inference\ndef run_inference(interpreter, image):\n    interpreter.set_tensor(input_index, image)\n    interpreter.invoke()\n    \n    boxes = interpreter.get_tensor(output_details[0]['index'])[0] # Bounding box coordinates of detected objects\n    classes = interpreter.get_tensor(output_details[1]['index'])[0] # Class index of detected objects\n    scores = interpreter.get_tensor(output_details[2]['index'])[0] # Confidence of detected objects\n    \n    return boxes, classes, scores\n\n# Phase 4: Output handling\ndef draw_boxes(frame, boxes, classes, scores, labels):\n    frame_height, frame_width, _ = frame.shape\n    for i in range(len(scores)):\n        if scores[i] >= confidence_threshold:\n            ymin, xmin, ymax, xmax = boxes[i]\n            (left, right, top, bottom) = (xmin * frame_width, xmax * frame_width,\n                                          ymin * frame_height, ymax * frame_height)\n            \n            cv2.rectangle(frame, (int(left), int(top)), (int(right), int(bottom)), (10, 255, 0), 2)\n            \n            label = f'{labels[int(classes[i])]}: {int(scores[i] * 100)}%'\n            label_size, base_line = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.7, 2)\n            top = max(top, label_size[1])\n            cv2.rectangle(frame, (int(left), int(top - round(1.5*label_size[1]))),\n                          (int(left + round(1.5*label_size[0])), int(top + base_line)),\n                          (255, 255, 255), cv2.FILLED)\n            cv2.putText(frame, label, (int(left), int(top)), cv2.FONT_HERSHEY_SIMPLEX,\n                        0.7, (0, 0, 0), 2)\n\ndef main():\n    cap = cv2.VideoCapture(input_path)\n    \n    if not os.path.exists(os.path.dirname(output_path)):\n        os.makedirs(os.path.dirname(output_path))\n        \n    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n    out = cv2.VideoWriter(output_path, fourcc, 20.0, (int(cap.get(3)), int(cap.get(4))))\n\n    while cap.isOpened():\n        ret, frame = cap.read()\n        if not ret:\n            break\n        \n        image = preprocess_frame(frame, input_shape[1:3])\n        \n        boxes, classes, scores = run_inference(interpreter, image)\n        \n        draw_boxes(frame, boxes, classes, scores, labels)\n        \n        out.write(frame)\n\n    cap.release()\n    out.release()\n\nif __name__ == '__main__':\n    main()"
      },
      "session_id": "phi4_9e98_tpusg_batch",
      "metadata": {
        "num_run": 30
      },
      "tags": [
        "ablation",
        "benchmark",
        "phi4:latest",
        "tpu_sketch_generator"
      ],
      "latency": 15.896,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-22-53-01-141429_chatcmpl-e69e586a-94df-4842-9406-afad74162861",
          "traceId": "996b2c37",
          "type": "GENERATION",
          "name": "996b_tpusg_gen_attempt#1",
          "startTime": "2025-12-10T20:53:01.141000+00:00",
          "endTime": "2025-12-10T20:53:17.037000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 15896.0,
          "totalTokens": 1146,
          "costDetails": {},
          "environment": "default",
          "promptTokens": 273,
          "completionTokens": 873,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        }
      ],
      "createdAt": "2025-12-10T20:53:01.659Z",
      "updatedAt": "2025-12-10T20:54:15.277Z",
      "environment": "default"
    },
    {
      "id": "8609c31f",
      "timestamp": "2025-12-10T20:50:39.201000+00:00",
      "name": "8609_tpu_sketch_generator",
      "input": null,
      "output": {
        "status": "failed",
        "last_code": "import cv2\nfrom tflite_runtime.interpreter import Interpreter\nfrom tflite_runtime.interpreter import load_delegate\nimport numpy as np\n\n# Configuration parameters\nmodel_path  = \"/home/mendel/tinyml_autopilot/models/edgetpu_detect.tflite\"\nlabel_path  = \"/home/mendel/tinyml_autopilot/models/labelmap.txt\"\ninput_path  = \"/home/mendel/tinyml_autopilot/data//sheeps.mp4\"\noutput_path  = \"/home/mendel/tinyml_autopilot/results/sheeps_detections.mp4\"\nconfidence_threshold  = 0.5\n\n# Load labels\nwith open(label_path, 'r') as f:\n    labels = [line.strip() for line in f.readlines()]\n\ndef load_model():\n    # Setup TFLite interpreter with Coral Edge TPU delegate\n    interpreter = Interpreter(\n        model_path=model_path,\n        experimental_delegates=[load_delegate('/usr/lib/aarch64-linux-gnu/libedgetpu.so.1.0')]\n    )\n    interpreter.allocate_tensors()\n    return interpreter\n\ndef get_input_details(interpreter):\n    input_details = interpreter.get_input_details()\n    output_details = interpreter.get_output_details()\n    return input_details, output_details\n\ndef preprocess_frame(frame, input_size):\n    frame_resized = cv2.resize(frame, (input_size[1], input_size[0]))\n    input_data = np.expand_dims(frame_resized, axis=0).astype(np.float32)\n    return input_data\n\ndef postprocess(output_data, frame, confidence_threshold, labels):\n    # Extract output tensors\n    boxes = np.squeeze(output_data[0])\n    classes = np.squeeze(output_data[1])\n    scores = np.squeeze(output_data[2])\n\n    height, width, _ = frame.shape\n\n    for i in range(len(scores)):\n        if scores[i] > confidence_threshold:\n            ymin, xmin, ymax, xmax = boxes[i]\n            (left, right, top, bottom) = (xmin * width, xmax * width,\n                                          ymin * height, ymax * height)\n\n            # Draw bounding box and label\n            cv2.rectangle(frame, (int(left), int(top)), (int(right), int(bottom)), (0, 255, 0), 2)\n            text = f'{labels[int(classes[i])]}: {int(scores[i]*100)}%'\n            cv2.putText(frame, text, (int(left), int(top-10)),\n                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n\n    return frame\n\ndef main():\n    # Load model and input/output details\n    interpreter = load_model()\n    input_details, output_details = get_input_details(interpreter)\n    input_size = tuple(input_details[0]['shape'][1:3])\n\n    # Open video files for reading and writing\n    cap = cv2.VideoCapture(input_path)\n    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n    out = cv2.VideoWriter(output_path, fourcc, 20.0, (int(cap.get(3)), int(cap.get(4))))\n\n    while cap.isOpened():\n        ret, frame = cap.read()\n        if not ret:\n            break\n\n        # Preprocess the frame\n        input_data = preprocess_frame(frame, input_size)\n\n        # Inference\n        interpreter.set_tensor(input_details[0]['index'], input_data)\n        interpreter.invoke()\n\n        # Extract output tensors\n        output_data = [interpreter.get_tensor(output_detail['index']) for output_detail in output_details]\n\n        # Postprocess results\n        frame_with_detections = postprocess(output_data, frame, confidence_threshold, labels)\n\n        # Write the frame with detections to the output video file\n        out.write(frame_with_detections)\n        \n    # Release resources\n    cap.release()\n    out.release()\n\nif __name__ == '__main__':\n    main()",
        "last_error": "Max retries reached with error. Last error: Traceback (most recent call last):\n  File \"script_6cc9dd40_1765399947.py\", line 95, in <module>\n    main()\n  File \"script_6cc9dd40_1765399947.py\", line 78, in main\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n  File \"/home/mendel/tinyml_autopilot/tinyml-env/lib/python3.7/site-packages/tflite_runtime/interpreter.py\", line 572, in set_tensor\n    self._interpreter.SetTensor(tensor_index, value)\nValueError: Cannot set tensor: Got value of type FLOAT32 but expected type UINT8 for input 175, name: normalized_input_image_tensor ."
      },
      "session_id": "phi4_9e98_tpusg_batch",
      "metadata": {
        "num_run": 29
      },
      "tags": [
        "ablation",
        "benchmark",
        "phi4:latest",
        "tpu_sketch_generator"
      ],
      "latency": 116.9,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-22-50-39-202814_chatcmpl-214c8732-114c-41da-894f-adbee542aeac",
          "traceId": "8609c31f",
          "type": "GENERATION",
          "name": "8609_tpusg_gen_attempt#1",
          "startTime": "2025-12-10T20:50:39.202000+00:00",
          "endTime": "2025-12-10T20:50:53.548000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 14346.0,
          "totalTokens": 1061,
          "costDetails": {},
          "environment": "default",
          "promptTokens": 273,
          "completionTokens": 788,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-22-51-01-794326_chatcmpl-7ba8a294-e8ff-47f8-bae8-9bdbe59cdaec",
          "traceId": "8609c31f",
          "type": "GENERATION",
          "name": "8609_tpusg_gen_attempt#2",
          "startTime": "2025-12-10T20:51:01.794000+00:00",
          "endTime": "2025-12-10T20:51:16.008000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 14214.0,
          "totalTokens": 1058,
          "costDetails": {},
          "environment": "default",
          "promptTokens": 273,
          "completionTokens": 785,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-22-51-23-750260_chatcmpl-f619a4e4-ff92-4a01-814e-21c37cea3d35",
          "traceId": "8609c31f",
          "type": "GENERATION",
          "name": "8609_tpusg_gen_attempt#3",
          "startTime": "2025-12-10T20:51:23.750000+00:00",
          "endTime": "2025-12-10T20:51:40.936000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 17186.0,
          "totalTokens": 1221,
          "costDetails": {},
          "environment": "default",
          "promptTokens": 273,
          "completionTokens": 948,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-22-51-48-914690_chatcmpl-a04df2a9-b108-49d6-b746-2c4c0f9c1866",
          "traceId": "8609c31f",
          "type": "GENERATION",
          "name": "8609_tpusg_gen_attempt#4",
          "startTime": "2025-12-10T20:51:48.914000+00:00",
          "endTime": "2025-12-10T20:52:04.539000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 15625.0,
          "totalTokens": 1135,
          "costDetails": {},
          "environment": "default",
          "promptTokens": 273,
          "completionTokens": 862,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-22-52-12-479354_chatcmpl-486d4ce2-22a3-43c8-b299-26c636a74949",
          "traceId": "8609c31f",
          "type": "GENERATION",
          "name": "8609_tpusg_gen_attempt#5",
          "startTime": "2025-12-10T20:52:12.479000+00:00",
          "endTime": "2025-12-10T20:52:27.809000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 15330.0,
          "totalTokens": 1119,
          "costDetails": {},
          "environment": "default",
          "promptTokens": 273,
          "completionTokens": 846,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "da1c1c0e-67ee-478b-9c40-559b40c5549c",
          "traceId": "8609c31f",
          "type": "SPAN",
          "name": "error_86_tpusg_failure_signal_tpu_sketch_generator",
          "startTime": "2025-12-10T20:52:36.102000+00:00",
          "level": "ERROR",
          "statusMessage": "Failed: Max retries reached with error. Last error: Traceback (most recent call last):\n  File \"script_6cc9dd40_1765399947.py\", line 95, in <module>\n    main()\n  File \"script_6cc9dd40_1765399947.py\", line 78, in main\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n  File \"/home/mendel/tinyml_autopilot/tinyml-env/lib/python3.7/site-packages/tflite_runtime/interpreter.py\", line 572, in set_tensor\n    self._interpreter.SetTensor(tensor_index, value)\nValueError: Cannot set tensor: Got value of type FLOAT32 but expected type UINT8 for input 175, name: normalized_input_image_tensor .",
          "calculatedTotalCost": 0.0,
          "totalTokens": 0,
          "costDetails": {},
          "environment": "default",
          "promptTokens": 0,
          "completionTokens": 0,
          "endTime": null,
          "model": null,
          "modelParameters": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null,
          "latency": null
        }
      ],
      "createdAt": "2025-12-10T20:50:39.721Z",
      "updatedAt": "2025-12-10T20:52:41.370Z",
      "environment": "default"
    },
    {
      "id": "90df73eb",
      "timestamp": "2025-12-10T20:48:17.230000+00:00",
      "name": "90df_tpu_sketch_generator",
      "input": null,
      "output": {
        "status": "failed",
        "last_code": "import cv2\nimport numpy as np\nfrom tflite_runtime.interpreter import Interpreter\nfrom pycoral.utils.edgetpu import make_interpreter\nfrom pycoral.adapters.common import input_size\nfrom pycoral.adapters import detect, classification\nfrom pycoral.metrics import detection_accuracy\n\n# Configuration parameters\nmodel_path  = \"/home/mendel/tinyml_autopilot/models/edgetpu_detect.tflite\"\nlabel_path  = \"/home/mendel/tinyml_autopilot/models/labelmap.txt\"\ninput_path  = \"/home/mendel/tinyml_autopilot/data//sheeps.mp4\"\noutput_path  = \"/home/mendel/tinyml_autopilot/results/sheeps_detections.mp4\"\nconfidence_threshold  = 0.5\n\n# Phase 1: Setup\ninterpreter = make_interpreter(model_path, device_path=\"/usr/lib/aarch64-linux-gnu/libedgetpu.so.1.0\")\ninterpreter.allocate_tensors()\n\n# Read labels\nwith open(label_path, 'r') as f:\n    labels = [line.strip() for line in f.readlines()]\n\n# Input and output details\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\n_, input_height, input_width, _ = input_details[0]['shape']\n\n# Phase 2: Preprocessing\ndef preprocess_frame(frame):\n    return cv2.resize(frame, (input_width, input_height))\n\n# Phase 3: Inference\ndef run_inference(frame):\n    preprocessed_frame = preprocess_frame(frame)\n    interpreter.set_tensor(input_details[0]['index'], [preprocessed_frame])\n    interpreter.invoke()\n    \n    # Get output details\n    boxes = interpreter.get_tensor(output_details[0]['index'])[0]  # Bounding box coordinates of detected objects\n    classes = interpreter.get_tensor(output_details[1]['index'])[0]  # Class index of detected objects\n    scores = interpreter.get_tensor(output_details[2]['index'])[0]   # Confidence of detected objects\n    \n    return boxes, classes, scores\n\n# Phase 4: Output Handling\ndef draw_detections(frame, boxes, classes, scores):\n    for i in range(len(scores)):\n        if scores[i] >= confidence_threshold:\n            ymin, xmin, ymax, xmax = boxes[i]\n            (left, right, top, bottom) = (xmin * frame.shape[1], xmax * frame.shape[1],\n                                          ymin * frame.shape[0], ymax * frame.shape[0])\n            \n            cv2.rectangle(frame, (int(left), int(top)), (int(right), int(bottom)), (10, 255, 0), 2)\n            label = f'{labels[int(classes[i])]}: {int(scores[i] * 100)}%'\n            cv2.putText(frame, label, (int(left), int(top) - 10),\n                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (10, 255, 0), 1)\n\ndef compute_map(results):\n    # Initialize accuracy metrics\n    ground_truths = detection_accuracy.PrecisionRecallCurve()\n    predictions = detection_accuracy.PrecisionRecallCurve()\n    \n    for frame_num, detections in enumerate(results):\n        for box, class_id, score in detections:\n            if score >= confidence_threshold:\n                predictions.add((frame_num, score, class_id))\n                # Assuming ground truth data is available; you would need to add actual ground truths\n                # For demonstration, using the same as prediction\n                ground_truths.add((frame_num, 1.0, class_id))  # Assuming perfect match for demo\n    \n    return detection_accuracy.compute_map(ground_truths, predictions)\n\n# Main processing loop\ncap = cv2.VideoCapture(input_path)\noutput_video = cv2.VideoWriter(output_path, \n                               cv2.VideoWriter_fourcc(*'mp4v'), \n                               cap.get(cv2.CAP_PROP_FPS), \n                               (int(cap.get(cv2.CAP_PROP_FRAME_WIDTH)), int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))))\n\nresults = []\nwhile cap.isOpened():\n    ret, frame = cap.read()\n    if not ret:\n        break\n    \n    boxes, classes, scores = run_inference(frame)\n    detections = [(box, cls, score) for box, cls, score in zip(boxes, classes, scores)]\n    \n    # Filter and draw detections\n    filtered_detections = [(box, cls, score) for box, cls, score in detections if score >= confidence_threshold]\n    results.append(filtered_detections)\n    \n    draw_detections(frame, *zip(*filtered_detections))\n    \n    output_video.write(frame)\n\ncap.release()\noutput_video.release()\n\n# Compute mAP\nmap_value = compute_map(results)\nprint(f\"Mean Average Precision (mAP): {map_value:.4f}\")\n\n# Note: This script assumes that the necessary TFLite model and label files are available at the specified paths.\n# It also assumes that ground truth data for computing mAP is available, which would need to be provided in a real scenario.",
        "last_error": "Max retries reached with error. Last error: Traceback (most recent call last):\n  File \"script_f124e4cf_1765399805.py\", line 6, in <module>\n    from pycoral.adapters import detect, classification\nImportError: cannot import name 'classification' from 'pycoral.adapters' (/home/mendel/tinyml_autopilot/tinyml-env/lib/python3.7/site-packages/pycoral/adapters/__init__.py)."
      },
      "session_id": "phi4_9e98_tpusg_batch",
      "metadata": {
        "num_run": 28
      },
      "tags": [
        "ablation",
        "benchmark",
        "phi4:latest",
        "tpu_sketch_generator"
      ],
      "latency": 116.057,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-22-48-17-231227_chatcmpl-edfbc8a6-bf33-43fa-ba79-2de97151262e",
          "traceId": "90df73eb",
          "type": "GENERATION",
          "name": "90df_tpusg_gen_attempt#1",
          "startTime": "2025-12-10T20:48:17.231000+00:00",
          "endTime": "2025-12-10T20:48:31.999000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 14768.0,
          "totalTokens": 1084,
          "costDetails": {},
          "environment": "default",
          "promptTokens": 273,
          "completionTokens": 811,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-22-48-39-699028_chatcmpl-427af4cb-50f0-4dfb-8d6a-623c6aeb30af",
          "traceId": "90df73eb",
          "type": "GENERATION",
          "name": "90df_tpusg_gen_attempt#2",
          "startTime": "2025-12-10T20:48:39.699000+00:00",
          "endTime": "2025-12-10T20:48:57.253000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 17554.0,
          "totalTokens": 1240,
          "costDetails": {},
          "environment": "default",
          "promptTokens": 273,
          "completionTokens": 967,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-22-49-04-970332_chatcmpl-64b6bebd-f7d0-4f47-a8ed-d0f7b455487f",
          "traceId": "90df73eb",
          "type": "GENERATION",
          "name": "90df_tpusg_gen_attempt#3",
          "startTime": "2025-12-10T20:49:04.970000+00:00",
          "endTime": "2025-12-10T20:49:17.253000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 12283.0,
          "totalTokens": 952,
          "costDetails": {},
          "environment": "default",
          "promptTokens": 273,
          "completionTokens": 679,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-22-49-24-978082_chatcmpl-d5567673-a14e-4879-b624-0881984a3089",
          "traceId": "90df73eb",
          "type": "GENERATION",
          "name": "90df_tpusg_gen_attempt#4",
          "startTime": "2025-12-10T20:49:24.978000+00:00",
          "endTime": "2025-12-10T20:49:38.445000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 13467.0,
          "totalTokens": 1017,
          "costDetails": {},
          "environment": "default",
          "promptTokens": 273,
          "completionTokens": 744,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-22-49-46-687193_chatcmpl-1a4d6e1a-8b2b-4b0d-970d-c7ab8ba38078",
          "traceId": "90df73eb",
          "type": "GENERATION",
          "name": "90df_tpusg_gen_attempt#5",
          "startTime": "2025-12-10T20:49:46.687000+00:00",
          "endTime": "2025-12-10T20:50:05.165000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 18478.0,
          "totalTokens": 1290,
          "costDetails": {},
          "environment": "default",
          "promptTokens": 273,
          "completionTokens": 1017,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "4192b038-e96e-430d-b9ca-915fc6ea6582",
          "traceId": "90df73eb",
          "type": "SPAN",
          "name": "error_90_tpusg_failure_signal_tpu_sketch_generator",
          "startTime": "2025-12-10T20:50:13.288000+00:00",
          "level": "ERROR",
          "statusMessage": "Failed: Max retries reached with error. Last error: Traceback (most recent call last):\n  File \"script_f124e4cf_1765399805.py\", line 6, in <module>\n    from pycoral.adapters import detect, classification\nImportError: cannot import name 'classification' from 'pycoral.adapters' (/home/mendel/tinyml_autopilot/tinyml-env/lib/python3.7/site-packages/pycoral/adapters/__init__.py).",
          "calculatedTotalCost": 0.0,
          "totalTokens": 0,
          "costDetails": {},
          "environment": "default",
          "promptTokens": 0,
          "completionTokens": 0,
          "endTime": null,
          "model": null,
          "modelParameters": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null,
          "latency": null
        }
      ],
      "createdAt": "2025-12-10T20:48:17.748Z",
      "updatedAt": "2025-12-10T20:50:18.456Z",
      "environment": "default"
    },
    {
      "id": "002c89a5",
      "timestamp": "2025-12-10T20:45:56.297000+00:00",
      "name": "002c_tpu_sketch_generator",
      "input": null,
      "output": {
        "status": "failed",
        "last_code": "import cv2\nfrom tflite_runtime.interpreter import Interpreter\nfrom tflite_runtime.interpreter import load_delegate\nimport numpy as np\nimport os\n\n# Configuration parameters\nmodel_path  = \"/home/mendel/tinyml_autopilot/models/edgetpu_detect.tflite\"\nlabel_path  = \"/home/mendel/tinyml_autopilot/models/labelmap.txt\"\ninput_path  = \"/home/mendel/tinyml_autopilot/data//sheeps.mp4\"\noutput_path  = \"/home/mendel/tinyml_autopilot/results/sheeps_detections.mp4\"\nconfidence_threshold  = 0.5\n\n# Load labels\ndef load_labels(label_file):\n    with open(label_file, 'r', encoding='utf-8') as f:\n        lines = f.readlines()\n    return [line.strip() for line in lines]\n\nlabels = load_labels(label_path)\n\n# Setup TFLite interpreter on Coral Dev Board with TPU\ninterpreter = Interpreter(\n    model_path=model_path,\n    experimental_delegates=[load_delegate('/usr/lib/aarch64-linux-gnu/libedgetpu.so.1.0')]\n)\ninterpreter.allocate_tensors()\n\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\n\ninput_shape = input_details[0]['shape']\nheight, width = input_shape[1], input_shape[2]\n\n# Preprocessing\ndef preprocess_frame(frame):\n    frame_resized = cv2.resize(frame, (width, height))\n    input_data = np.expand_dims(frame_resized, axis=0).astype(np.float32)\n    return input_data\n\n# Inference\ndef run_inference(interpreter, frame):\n    interpreter.set_tensor(input_details[0]['index'], frame)\n    interpreter.invoke()\n    \n    boxes = interpreter.get_tensor(output_details[0]['index'])[0]  # Bounding box coordinates of detected objects\n    classes = interpreter.get_tensor(output_details[1]['index'])[0]  # Class index of detected objects\n    scores = interpreter.get_tensor(output_details[2]['index'])[0]  # Confidence of detected objects\n    \n    return boxes, classes, scores\n\n# Output handling\ndef draw_boxes(frame, boxes, classes, scores):\n    for i in range(len(scores)):\n        if scores[i] >= confidence_threshold:\n            ymin, xmin, ymax, xmax = boxes[i]\n            (left, right, top, bottom) = (xmin * frame.shape[1], xmax * frame.shape[1],\n                                          ymin * frame.shape[0], ymax * frame.shape[0])\n            \n            label = f'{labels[int(classes[i])]}: {int(scores[i]*100)}%'\n            cv2.rectangle(frame, (int(left), int(top)), (int(right), int(bottom)), (10, 255, 0), 2)\n            cv2.putText(frame, label, (int(left), int(top-10)), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 255), 2)\n\ndef main():\n    # Open input video\n    cap = cv2.VideoCapture(input_path)\n    if not cap.isOpened():\n        print(\"Error opening video stream or file\")\n        return\n\n    # Define the codec and create VideoWriter object\n    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n    out = cv2.VideoWriter(output_path, fourcc, 20.0, (int(cap.get(3)), int(cap.get(4))))\n\n    while cap.isOpened():\n        ret, frame = cap.read()\n        if not ret:\n            break\n\n        # Preprocess and run inference\n        input_data = preprocess_frame(frame)\n        boxes, classes, scores = run_inference(interpreter, input_data)\n\n        # Draw detection boxes with labels\n        draw_boxes(frame, boxes, classes, scores)\n\n        # Write the frame into the output file\n        out.write(frame)\n\n    cap.release()\n    out.release()\n    cv2.destroyAllWindows()\n\nif __name__ == '__main__':\n    main()",
        "last_error": "Max retries reached with error. Last error: Traceback (most recent call last):\n  File \"script_5ff2ac68_1765399663.py\", line 95, in <module>\n    main()\n  File \"script_5ff2ac68_1765399663.py\", line 82, in main\n    boxes, classes, scores = run_inference(interpreter, input_data)\n  File \"script_5ff2ac68_1765399663.py\", line 43, in run_inference\n    interpreter.set_tensor(input_details[0]['index'], frame)\n  File \"/home/mendel/tinyml_autopilot/tinyml-env/lib/python3.7/site-packages/tflite_runtime/interpreter.py\", line 572, in set_tensor\n    self._interpreter.SetTensor(tensor_index, value)\nValueError: Cannot set tensor: Got value of type FLOAT32 but expected type UINT8 for input 175, name: normalized_input_image_tensor ."
      },
      "session_id": "phi4_9e98_tpusg_batch",
      "metadata": {
        "num_run": 27
      },
      "tags": [
        "ablation",
        "benchmark",
        "phi4:latest",
        "tpu_sketch_generator"
      ],
      "latency": 115.782,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-22-45-56-298861_chatcmpl-1d8d36c8-b740-46a4-8f23-77f5a5be8896",
          "traceId": "002c89a5",
          "type": "GENERATION",
          "name": "002c_tpusg_gen_attempt#1",
          "startTime": "2025-12-10T20:45:56.298000+00:00",
          "endTime": "2025-12-10T20:46:11.628000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 15330.0,
          "totalTokens": 1107,
          "costDetails": {},
          "environment": "default",
          "promptTokens": 273,
          "completionTokens": 834,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-22-46-19-839730_chatcmpl-e2f25b32-c2a0-4b87-844e-a22406c9fcc0",
          "traceId": "002c89a5",
          "type": "GENERATION",
          "name": "002c_tpusg_gen_attempt#2",
          "startTime": "2025-12-10T20:46:19.839000+00:00",
          "endTime": "2025-12-10T20:46:33.882000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 14043.0,
          "totalTokens": 1048,
          "costDetails": {},
          "environment": "default",
          "promptTokens": 273,
          "completionTokens": 775,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-22-46-42-118706_chatcmpl-33c4d5ce-296c-49d5-8373-efb9fd123b37",
          "traceId": "002c89a5",
          "type": "GENERATION",
          "name": "002c_tpusg_gen_attempt#3",
          "startTime": "2025-12-10T20:46:42.118000+00:00",
          "endTime": "2025-12-10T20:46:57.495000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 15377.0,
          "totalTokens": 1122,
          "costDetails": {},
          "environment": "default",
          "promptTokens": 273,
          "completionTokens": 849,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-22-47-05-214185_chatcmpl-76ff8ee7-05a7-4a22-9b36-be4287467f27",
          "traceId": "002c89a5",
          "type": "GENERATION",
          "name": "002c_tpusg_gen_attempt#4",
          "startTime": "2025-12-10T20:47:05.214000+00:00",
          "endTime": "2025-12-10T20:47:21.106000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 15892.0,
          "totalTokens": 1149,
          "costDetails": {},
          "environment": "default",
          "promptTokens": 273,
          "completionTokens": 876,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-22-47-29-310219_chatcmpl-7c2d725b-b484-4409-8175-6f3a7b4a9b0a",
          "traceId": "002c89a5",
          "type": "GENERATION",
          "name": "002c_tpusg_gen_attempt#5",
          "startTime": "2025-12-10T20:47:29.310000+00:00",
          "endTime": "2025-12-10T20:47:43.900000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 14590.0,
          "totalTokens": 1079,
          "costDetails": {},
          "environment": "default",
          "promptTokens": 273,
          "completionTokens": 806,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "85690a92-c67f-4324-9905-acddf045e26e",
          "traceId": "002c89a5",
          "type": "SPAN",
          "name": "error_00_tpusg_failure_signal_tpu_sketch_generator",
          "startTime": "2025-12-10T20:47:52.080000+00:00",
          "level": "ERROR",
          "statusMessage": "Failed: Max retries reached with error. Last error: Traceback (most recent call last):\n  File \"script_5ff2ac68_1765399663.py\", line 95, in <module>\n    main()\n  File \"script_5ff2ac68_1765399663.py\", line 82, in main\n    boxes, classes, scores = run_inference(interpreter, input_data)\n  File \"script_5ff2ac68_1765399663.py\", line 43, in run_inference\n    interpreter.set_tensor(input_details[0]['index'], frame)\n  File \"/home/mendel/tinyml_autopilot/tinyml-env/lib/python3.7/site-packages/tflite_runtime/interpreter.py\", line 572, in set_tensor\n    self._interpreter.SetTensor(tensor_index, value)\nValueError: Cannot set tensor: Got value of type FLOAT32 but expected type UINT8 for input 175, name: normalized_input_image_tensor .",
          "calculatedTotalCost": 0.0,
          "totalTokens": 0,
          "costDetails": {},
          "environment": "default",
          "promptTokens": 0,
          "completionTokens": 0,
          "endTime": null,
          "model": null,
          "modelParameters": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null,
          "latency": null
        }
      ],
      "createdAt": "2025-12-10T20:45:56.816Z",
      "updatedAt": "2025-12-10T20:47:57.538Z",
      "environment": "default"
    },
    {
      "id": "9f1febd5",
      "timestamp": "2025-12-10T20:43:27.369000+00:00",
      "name": "9f1f_tpu_sketch_generator",
      "input": null,
      "output": {
        "status": "success",
        "sketch": "import cv2\nimport numpy as np\nfrom tflite_runtime.interpreter import load_delegate\nfrom tflite_runtime.interpreter import Interpreter\n\n# Configuration parameters\nmodel_path  = \"/home/mendel/tinyml_autopilot/models/edgetpu_detect.tflite\"\nlabel_path  = \"/home/mendel/tinyml_autopilot/models/labelmap.txt\"\ninput_path  = \"/home/mendel/tinyml_autopilot/data//sheeps.mp4\"\noutput_path  = \"/home/mendel/tinyml_autopilot/results/sheeps_detections.mp4\"\nconfidence_threshold  = 0.5\n\n# Phase 1: Setup\ndef load_labels(path):\n    with open(path, 'r', encoding='utf-8') as f:\n        lines = f.readlines()\n    return {i: line.strip() for i, line in enumerate(lines)}\n\ndef set_input_tensor(interpreter, image):\n    tensor_index = interpreter.get_input_details()[0]['index']\n    input_shape = interpreter.get_input_details()[0]['shape']\n    image = cv2.resize(image, (input_shape[1], input_shape[2]))\n    input_data = np.expand_dims(image, axis=0)\n    interpreter.set_tensor(tensor_index, input_data)\n\ndef get_output(interpreter, score_threshold):\n    boxes = interpreter.get_tensor(interpreter.get_output_details()[0]['index'])[0] # Bounding box coordinates of detected objects\n    classes = interpreter.get_tensor(interpreter.get_output_details()[1]['index'])[0] # Class index of detected objects\n    scores = interpreter.get_tensor(interpreter.get_output_details()[2]['index'])[0] # Confidence of detected objects\n    count = int(interpreter.get_tensor(interpreter.get_output_details()[3]['index'])[0]) # Number of objects detected\n    results = []\n    for i in range(count):\n        if scores[i] >= score_threshold:\n            result = {\n                'bounding_box': boxes[i],\n                'class_id': classes[i],\n                'score': scores[i]\n            }\n            results.append(result)\n    return results\n\n# Initialize the interpreter with TPU delegate\ninterpreter = Interpreter(\n    model_path=model_path,\n    experimental_delegates=[load_delegate('/usr/lib/aarch64-linux-gnu/libedgetpu.so.1.0')]\n)\n\ninterpreter.allocate_tensors()\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\n\n# Load labels\nlabels = load_labels(label_path)\n\n# Phase 2: Preprocessing and reading input\ncap = cv2.VideoCapture(input_path)\nwidth = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\nheight = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\nfps = cap.get(cv2.CAP_PROP_FPS)\nfourcc = cv2.VideoWriter_fourcc(*'mp4v')\nout = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n\n# Phase 3: Inference\nwhile cap.isOpened():\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    set_input_tensor(interpreter, frame)\n    interpreter.invoke()\n    detections = get_output(interpreter, confidence_threshold)\n\n    # Draw detection boxes and labels\n    for detection in detections:\n        bbox = detection['bounding_box']\n        class_id = int(detection['class_id'])\n        score = detection['score']\n\n        ymin, xmin, ymax, xmax = bbox\n        xmin = int(xmin * width)\n        xmax = int(xmax * width)\n        ymin = int(ymin * height)\n        ymax = int(ymax * height)\n\n        cv2.rectangle(frame, (xmin, ymin), (xmax, ymax), (0, 255, 0), 2)\n        label = f'{labels[class_id]}: {int(score * 100)}%'\n        cv2.putText(frame, label, (xmin, ymin - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n\n    out.write(frame)\n\n# Release resources\ncap.release()\nout.release()\n\nprint(\"Inference completed and output saved to:\", output_path)"
      },
      "session_id": "phi4_9e98_tpusg_batch",
      "metadata": {
        "num_run": 26
      },
      "tags": [
        "ablation",
        "benchmark",
        "phi4:latest",
        "tpu_sketch_generator"
      ],
      "latency": 71.122,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-22-43-27-370134_chatcmpl-4ed0d8fc-024b-4852-9454-990a223be6ee",
          "traceId": "9f1febd5",
          "type": "GENERATION",
          "name": "9f1f_tpusg_gen_attempt#1",
          "startTime": "2025-12-10T20:43:27.370000+00:00",
          "endTime": "2025-12-10T20:43:47.741000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 20371.0,
          "totalTokens": 1386,
          "costDetails": {},
          "environment": "default",
          "promptTokens": 273,
          "completionTokens": 1113,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-22-43-55-458450_chatcmpl-2cc5c6d5-2ec6-4974-8370-db9caaba2870",
          "traceId": "9f1febd5",
          "type": "GENERATION",
          "name": "9f1f_tpusg_gen_attempt#2",
          "startTime": "2025-12-10T20:43:55.458000+00:00",
          "endTime": "2025-12-10T20:44:14.325000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 18867.0,
          "totalTokens": 1311,
          "costDetails": {},
          "environment": "default",
          "promptTokens": 273,
          "completionTokens": 1038,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-22-44-22-491882_chatcmpl-8240627a-fce4-46d3-9dc4-e0a890177a34",
          "traceId": "9f1febd5",
          "type": "GENERATION",
          "name": "9f1f_tpusg_gen_attempt#3",
          "startTime": "2025-12-10T20:44:22.491000+00:00",
          "endTime": "2025-12-10T20:44:38.492000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 16001.0,
          "totalTokens": 1156,
          "costDetails": {},
          "environment": "default",
          "promptTokens": 273,
          "completionTokens": 883,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        }
      ],
      "createdAt": "2025-12-10T20:43:27.886Z",
      "updatedAt": "2025-12-10T20:45:36.625Z",
      "environment": "default"
    },
    {
      "id": "b12285ca",
      "timestamp": "2025-12-10T20:41:09.385000+00:00",
      "name": "b122_tpu_sketch_generator",
      "input": null,
      "output": {
        "status": "success",
        "sketch": "import cv2\nfrom tflite_runtime.interpreter import Interpreter\nfrom tflite_runtime.interpreter import load_delegate\nimport numpy as np\n\n# Configuration parameters\nmodel_path  = \"/home/mendel/tinyml_autopilot/models/edgetpu_detect.tflite\"\nlabel_path  = \"/home/mendel/tinyml_autopilot/models/labelmap.txt\"\ninput_path  = \"/home/mendel/tinyml_autopilot/data//sheeps.mp4\"\noutput_path  = \"/home/mendel/tinyml_autopilot/results/sheeps_detections.mp4\"\nconfidence_threshold  = 0.5\n\n# Load labels\nwith open(label_path, 'r') as f:\n    labels = [line.strip() for line in f.readlines()]\n\n# Setup: Load the TFLite interpreter with EdgeTPU support\ninterpreter = Interpreter(\n    model_path=model_path,\n    experimental_delegates=[load_delegate('/usr/lib/aarch64-linux-gnu/libedgetpu.so.1.0')]\n)\ninterpreter.allocate_tensors()\n\n# Get input and output details\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\n\n# Helper functions\ndef set_input_tensor(interpreter, image):\n    tensor_index = input_details[0]['index']\n    input_shape = input_details[0]['shape']\n    image = cv2.resize(image, (input_shape[1], input_shape[2]))\n    image = np.expand_dims(image, axis=0)\n    interpreter.set_tensor(tensor_index, image)\n\ndef get_output(interpreter):\n    boxes = interpreter.get_tensor(output_details[0]['index'])[0]  # Bounding box coordinates\n    classes = interpreter.get_tensor(output_details[1]['index'])[0]  # Class index\n    scores = interpreter.get_tensor(output_details[2]['index'])[0]  # Confidence score\n    return boxes, classes, scores\n\ndef draw_detections(frame, boxes, classes, scores):\n    for i in range(len(scores)):\n        if scores[i] >= confidence_threshold:\n            ymin, xmin, ymax, xmax = boxes[i]\n            (left, right, top, bottom) = (xmin * frame.shape[1], xmax * frame.shape[1],\n                                          ymin * frame.shape[0], ymax * frame.shape[0])\n            cv2.rectangle(frame, (int(left), int(top)), (int(right), int(bottom)),\n                          (10, 255, 0), 2)\n            label = f'{labels[int(classes[i])]}: {scores[i]:.2f}'\n            cv2.putText(frame, label, (int(left), int(top) - 5),\n                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (10, 255, 0), 1)\n\n# Preprocessing and inference\ncap = cv2.VideoCapture(input_path)\nfourcc = cv2.VideoWriter_fourcc(*'mp4v')\nout = cv2.VideoWriter(output_path, fourcc, 20.0, (int(cap.get(3)), int(cap.get(4))))\n\nwhile cap.isOpened():\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    # Preprocessing\n    set_input_tensor(interpreter, frame)\n\n    # Inference\n    interpreter.invoke()\n\n    # Postprocessing\n    boxes, classes, scores = get_output(interpreter)\n    draw_detections(frame, boxes, classes, scores)\n\n    # Output handling\n    out.write(frame)\n\ncap.release()\nout.release()\ncv2.destroyAllWindows()"
      },
      "session_id": "phi4_9e98_tpusg_batch",
      "metadata": {
        "num_run": 25
      },
      "tags": [
        "ablation",
        "benchmark",
        "phi4:latest",
        "tpu_sketch_generator"
      ],
      "latency": 59.943,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-22-41-09-386965_chatcmpl-54f3c778-26bd-4eb8-8395-d218b6237665",
          "traceId": "b12285ca",
          "type": "GENERATION",
          "name": "b122_tpusg_gen_attempt#1",
          "startTime": "2025-12-10T20:41:09.386000+00:00",
          "endTime": "2025-12-10T20:41:27.825000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 18439.0,
          "totalTokens": 1284,
          "costDetails": {},
          "environment": "default",
          "promptTokens": 273,
          "completionTokens": 1011,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-22-41-35-677111_chatcmpl-4d027206-b3b0-44d9-8725-7f1c2e0bbb0b",
          "traceId": "b12285ca",
          "type": "GENERATION",
          "name": "b122_tpusg_gen_attempt#2",
          "startTime": "2025-12-10T20:41:35.677000+00:00",
          "endTime": "2025-12-10T20:41:48.721000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 13044.0,
          "totalTokens": 993,
          "costDetails": {},
          "environment": "default",
          "promptTokens": 273,
          "completionTokens": 720,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-22-41-56-667437_chatcmpl-8b97650e-0510-4a45-b68d-7a002f2c1375",
          "traceId": "b12285ca",
          "type": "GENERATION",
          "name": "b122_tpusg_gen_attempt#3",
          "startTime": "2025-12-10T20:41:56.667000+00:00",
          "endTime": "2025-12-10T20:42:09.329000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 12662.0,
          "totalTokens": 973,
          "costDetails": {},
          "environment": "default",
          "promptTokens": 273,
          "completionTokens": 700,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        }
      ],
      "createdAt": "2025-12-10T20:41:09.906Z",
      "updatedAt": "2025-12-10T20:43:07.099Z",
      "environment": "default"
    },
    {
      "id": "ea612262",
      "timestamp": "2025-12-10T20:38:23.462000+00:00",
      "name": "ea61_tpu_sketch_generator",
      "input": null,
      "output": {
        "status": "failed",
        "last_code": "import cv2\nimport numpy as np\nimport tflite_runtime.interpreter as tflite\nfrom pycoral.utils.edgetpu import make_interpreter\nfrom pycoral.adapters.common.input import preprocess_input\nfrom pycoral.adapters.object_detection import \\\n    get_objects_from_interpreter, \\\n    adapt_input_frame\nfrom pycoral.metrics.metrics_calculator import MetricsCalculator\n\n# Configuration parameters\nmodel_path  = \"/home/mendel/tinyml_autopilot/models/edgetpu_detect.tflite\"\nlabel_path  = \"/home/mendel/tinyml_autopilot/models/labelmap.txt\"\ninput_path  = \"/home/mendel/tinyml_autopilot/data//sheeps.mp4\"\noutput_path  = \"/home/mendel/tinyml_autopilot/results/sheeps_detections.mp4\"\nconfidence_threshold  = 0.5\n\n# Phase 1: Setup\ninterpreter = make_interpreter(model_path, device='/usr/lib/aarch64-linux-gnu/libedgetpu.so.1.0')\ninterpreter.allocate_tensors()\n\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\n\n# Load labels\nwith open(label_path, 'r') as f:\n    labels = [line.strip() for line in f.readlines()]\n\n# Phase 2: Preprocessing\ndef draw_boxes(frame, objects):\n    \"\"\"Draw bounding boxes and labels on the frame.\"\"\"\n    for obj in objects:\n        bbox = obj.bounding_box.flatten().tolist()\n        class_id = int(obj.class_id)\n        score = obj.score\n\n        # Calculate coordinates of bounding box\n        ih, iw, _ = frame.shape\n        bbox = [int(iw * bbox[1]), int(ih * bbox[0]),\n                int(iw * bbox[3]), int(ih * bbox[2])]\n\n        cv2.rectangle(frame, (bbox[0], bbox[1]), (bbox[2], bbox[3]), (255, 165, 20), thickness=2)\n\n        # Prepare label\n        label = f'{labels[class_id]}: {int(score * 100)}%'\n        label_size, base_line = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.7, 2)\n        top = max(bbox[1], label_size[1])\n        bottom = min(bbox[3], frame.shape[0] - label_size[1])\n\n        # Draw background rectangle for text\n        cv2.rectangle(frame, (bbox[0], top - label_size[1]), (bbox[0] + label_size[0], bottom + base_line), (255, 165, 20), thickness=cv2.FILLED)\n        \n        # Put label text on image\n        cv2.putText(frame, label, (bbox[0], bottom), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), thickness=1)\n\n    return frame\n\n# Phase 3: Inference and processing\ncap = cv2.VideoCapture(input_path)\nfourcc = cv2.VideoWriter_fourcc(*'mp4v')\nout = cv2.VideoWriter(output_path, fourcc, cap.get(cv2.CAP_PROP_FPS),\n                      (int(cap.get(3)), int(cap.get(4))))\n\nmetrics_calculator = MetricsCalculator(labels=labels, iou_threshold=0.5)\n\nwhile cap.isOpened():\n    ret, frame = cap.read()\n    \n    if not ret:\n        break\n\n    # Preprocess the frame\n    pil_image = adapt_input_frame(frame)\n    preprocess_input(pil_image, input_details[0]['index'], input_scale=input_details[0]['quantization'][0], input_zero_point=input_details[0]['quantization'][1])\n\n    interpreter.invoke()\n\n    # Get inference results\n    objs = get_objects_from_interpreter(interpreter,\n                                        score_threshold=confidence_threshold)\n    \n    # Compute metrics (mAP)\n    ground_truth = []  # Implement this part if you have ground truth data\n    metrics_calculator.add(frame, objs, ground_truth)\n\n    # Draw boxes and labels on the frame\n    output_frame = draw_boxes(frame, objs)\n\n    # Write to output video file\n    out.write(output_frame)\n\n# Finish metrics computation\nmetrics = metrics_calculator.compute_metrics()\nprint(\"mAP:\", metrics.mAP)\n\ncap.release()\nout.release()",
        "last_error": "Max retries reached with error. Last error: Traceback (most recent call last):\n  File \"script_d8a446f2_1765399235.py\", line 5, in <module>\n    from pycoral.adapters.common.input import preprocess_input\nModuleNotFoundError: No module named 'pycoral.adapters.common.input'; 'pycoral.adapters.common' is not a package."
      },
      "session_id": "phi4_9e98_tpusg_batch",
      "metadata": {
        "num_run": 24
      },
      "tags": [
        "ablation",
        "benchmark",
        "phi4:latest",
        "tpu_sketch_generator"
      ],
      "latency": 140.413,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-22-38-23-463266_chatcmpl-0f8616fd-ecc1-4aab-b62b-eeae69203cc5",
          "traceId": "ea612262",
          "type": "GENERATION",
          "name": "ea61_tpusg_gen_attempt#1",
          "startTime": "2025-12-10T20:38:23.463000+00:00",
          "endTime": "2025-12-10T20:38:38.096000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 14633.0,
          "totalTokens": 1077,
          "costDetails": {},
          "environment": "default",
          "promptTokens": 273,
          "completionTokens": 804,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-22-38-46-386920_chatcmpl-3aa31d12-ae22-4421-9269-7230a316f316",
          "traceId": "ea612262",
          "type": "GENERATION",
          "name": "ea61_tpusg_gen_attempt#2",
          "startTime": "2025-12-10T20:38:46.386000+00:00",
          "endTime": "2025-12-10T20:38:59.434000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 13048.0,
          "totalTokens": 993,
          "costDetails": {},
          "environment": "default",
          "promptTokens": 273,
          "completionTokens": 720,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-22-39-07-407250_chatcmpl-455d30cd-74a1-4fb1-adff-d191d5cc7c8f",
          "traceId": "ea612262",
          "type": "GENERATION",
          "name": "ea61_tpusg_gen_attempt#3",
          "startTime": "2025-12-10T20:39:07.407000+00:00",
          "endTime": "2025-12-10T20:39:40.014000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 32607.0,
          "totalTokens": 2042,
          "costDetails": {},
          "environment": "default",
          "promptTokens": 273,
          "completionTokens": 1769,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-22-39-51-795340_chatcmpl-76ae7129-baa5-44fb-b641-b973b7ff569d",
          "traceId": "ea612262",
          "type": "GENERATION",
          "name": "ea61_tpusg_gen_attempt#4",
          "startTime": "2025-12-10T20:39:51.795000+00:00",
          "endTime": "2025-12-10T20:40:10.585000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 18790.0,
          "totalTokens": 1307,
          "costDetails": {},
          "environment": "default",
          "promptTokens": 273,
          "completionTokens": 1034,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-22-40-18-341871_chatcmpl-8294ab5b-f6de-4bd2-99bf-27bb4a2897f1",
          "traceId": "ea612262",
          "type": "GENERATION",
          "name": "ea61_tpusg_gen_attempt#5",
          "startTime": "2025-12-10T20:40:18.341000+00:00",
          "endTime": "2025-12-10T20:40:35.735000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 17394.0,
          "totalTokens": 1231,
          "costDetails": {},
          "environment": "default",
          "promptTokens": 273,
          "completionTokens": 958,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "456afc24-cf53-4af7-8c9e-a4c1139997a8",
          "traceId": "ea612262",
          "type": "SPAN",
          "name": "error_ea_tpusg_failure_signal_tpu_sketch_generator",
          "startTime": "2025-12-10T20:40:43.876000+00:00",
          "level": "ERROR",
          "statusMessage": "Failed: Max retries reached with error. Last error: Traceback (most recent call last):\n  File \"script_d8a446f2_1765399235.py\", line 5, in <module>\n    from pycoral.adapters.common.input import preprocess_input\nModuleNotFoundError: No module named 'pycoral.adapters.common.input'; 'pycoral.adapters.common' is not a package.",
          "calculatedTotalCost": 0.0,
          "totalTokens": 0,
          "costDetails": {},
          "environment": "default",
          "promptTokens": 0,
          "completionTokens": 0,
          "endTime": null,
          "model": null,
          "modelParameters": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null,
          "latency": null
        }
      ],
      "createdAt": "2025-12-10T20:38:23.979Z",
      "updatedAt": "2025-12-10T20:40:49.202Z",
      "environment": "default"
    },
    {
      "id": "78ed4061",
      "timestamp": "2025-12-10T20:35:52.513000+00:00",
      "name": "78ed_tpu_sketch_generator",
      "input": null,
      "output": {
        "status": "failed",
        "last_code": "import cv2\nimport numpy as np\nimport tflite_runtime.interpreter as tflite\nfrom tflite_runtime.interpreter import load_delegate\nfrom google.protobuf.text_format import Parse\n\n# Configuration parameters\nmodel_path  = \"/home/mendel/tinyml_autopilot/models/edgetpu_detect.tflite\"\nlabel_path  = \"/home/mendel/tinyml_autopilot/models/labelmap.txt\"\ninput_path  = \"/home/mendel/tinyml_autopilot/data//sheeps.mp4\"\noutput_path  = \"/home/mendel/tinyml_autopilot/results/sheeps_detections.mp4\"\nconfidence_threshold  = 0.5\n\n# Setup phase: Load the TFLite interpreter for Coral TPU\ndef load_interpreter(model):\n    return tflite.Interpreter(\n        model_path=model,\n        experimental_delegates=[load_delegate('/usr/lib/aarch64-linux-gnu/libedgetpu.so.1.0')]\n    )\n\n# Preprocessing: Read input video, prepare labels\ndef read_labels(label_file):\n    with open(label_file, 'r') as file:\n        lines = file.readlines()\n    return [line.strip() for line in lines]\n\ndef preprocess_input(input_video_path):\n    cap = cv2.VideoCapture(input_video_path)\n    if not cap.isOpened():\n        raise IOError(f\"Cannot open video {input_video_path}\")\n    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n    fps = cap.get(cv2.CAP_PROP_FPS)\n    return cap, width, height, fps\n\n# Inference phase: Run the object detection model\ndef run_inference(interpreter, frame):\n    input_details = interpreter.get_input_details()\n    output_details = interpreter.get_output_details()\n\n    # Resize and normalize input frame\n    frame_resized = cv2.resize(frame, (input_details[0]['shape'][2], input_details[0]['shape'][1]))\n    input_data = np.expand_dims(frame_resized, axis=0).astype(np.float32)\n    \n    # Set the tensor to point to the input data to be inferred\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n\n    # Run inference\n    interpreter.invoke()\n\n    # Retrieve detection results\n    boxes = interpreter.get_tensor(output_details[0]['index'])[0]  # Bounding box coordinates of detected objects\n    classes = interpreter.get_tensor(output_details[1]['index'])[0]  # Class index of detected objects\n    scores = interpreter.get_tensor(output_details[2]['index'])[0]  # Confidence of detected objects\n\n    return boxes, classes, scores\n\n# Output handling: Draw bounding boxes and save the video\ndef draw_detections(frame, boxes, classes, scores, labels):\n    for i in range(len(scores)):\n        if scores[i] >= confidence_threshold:\n            ymin, xmin, ymax, xmax = boxes[i]\n            (left, right, top, bottom) = (xmin * frame.shape[1], xmax * frame.shape[1],\n                                          ymin * frame.shape[0], ymax * frame.shape[0])\n            cv2.rectangle(frame, (int(left), int(top)), (int(right), int(bottom)), (10, 255, 0), 2)\n            \n            label = f\"{labels[int(classes[i])]}: {int(scores[i] * 100)}%\"\n            label_size, base_line = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.7, 2)\n            top = max(top, label_size[1])\n            cv2.rectangle(frame, (int(left), int(top - label_size[1])), (int(left + label_size[0]), int(top + base_line)), (255, 255, 255), cv2.FILLED)\n            cv2.putText(frame, label, (int(left), int(top)), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 0), 2)\n\ndef save_output(output_video_path, cap, width, height, fps):\n    out = cv2.VideoWriter(output_video_path, cv2.VideoWriter_fourcc(*'mp4v'), fps, (width, height))\n    while cap.isOpened():\n        ret, frame = cap.read()\n        if not ret:\n            break\n        out.write(frame)\n    cap.release()\n    out.release()\n\ndef main():\n    # Load labels and interpreter\n    labels = read_labels(label_path)\n    interpreter = load_interpreter(model_path)\n    interpreter.allocate_tensors()\n\n    # Prepare input video\n    cap, width, height, fps = preprocess_input(input_path)\n\n    # Process video frame by frame\n    while True:\n        ret, frame = cap.read()\n        if not ret:\n            break\n\n        boxes, classes, scores = run_inference(interpreter, frame)\n        draw_detections(frame, boxes, classes, scores, labels)\n\n        cv2.imshow('Object Detection', frame)\n        if cv2.waitKey(1) & 0xFF == ord('q'):\n            break\n\n    cap.release()\n    cv2.destroyAllWindows()\n\n    # Save the output video\n    save_output(output_path, cap, width, height, fps)\n\nif __name__ == '__main__':\n    main()",
        "last_error": "Max retries reached with error. Last error: Traceback (most recent call last):\n  File \"script_a0bc6edc_1765399068.py\", line 112, in <module>\n    main()\n  File \"script_a0bc6edc_1765399068.py\", line 98, in main\n    boxes, classes, scores = run_inference(interpreter, frame)\n  File \"script_a0bc6edc_1765399068.py\", line 46, in run_inference\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n  File \"/home/mendel/tinyml_autopilot/tinyml-env/lib/python3.7/site-packages/tflite_runtime/interpreter.py\", line 572, in set_tensor\n    self._interpreter.SetTensor(tensor_index, value)\nValueError: Cannot set tensor: Got value of type FLOAT32 but expected type UINT8 for input 175, name: normalized_input_image_tensor ."
      },
      "session_id": "phi4_9e98_tpusg_batch",
      "metadata": {
        "num_run": 23
      },
      "tags": [
        "ablation",
        "benchmark",
        "phi4:latest",
        "tpu_sketch_generator"
      ],
      "latency": 125.166,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-22-35-52-514836_chatcmpl-aa27a7d3-2706-4c24-a28b-0d3bc61efc70",
          "traceId": "78ed4061",
          "type": "GENERATION",
          "name": "78ed_tpusg_gen_attempt#1",
          "startTime": "2025-12-10T20:35:52.514000+00:00",
          "endTime": "2025-12-10T20:36:12.221000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 19707.0,
          "totalTokens": 1351,
          "costDetails": {},
          "environment": "default",
          "promptTokens": 273,
          "completionTokens": 1078,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-22-36-20-155070_chatcmpl-9a567793-7caa-4667-ad39-b8a48e4aca23",
          "traceId": "78ed4061",
          "type": "GENERATION",
          "name": "78ed_tpusg_gen_attempt#2",
          "startTime": "2025-12-10T20:36:20.155000+00:00",
          "endTime": "2025-12-10T20:36:36.548000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 16393.0,
          "totalTokens": 1177,
          "costDetails": {},
          "environment": "default",
          "promptTokens": 273,
          "completionTokens": 904,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-22-36-44-301946_chatcmpl-aabf8048-bb79-4805-84a3-54ddc615e50a",
          "traceId": "78ed4061",
          "type": "GENERATION",
          "name": "78ed_tpusg_gen_attempt#3",
          "startTime": "2025-12-10T20:36:44.301000+00:00",
          "endTime": "2025-12-10T20:36:58.315000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 14014.0,
          "totalTokens": 1047,
          "costDetails": {},
          "environment": "default",
          "promptTokens": 273,
          "completionTokens": 774,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-22-37-06-355147_chatcmpl-c4752098-f692-4140-ac4c-ac7a30eb3d33",
          "traceId": "78ed4061",
          "type": "GENERATION",
          "name": "78ed_tpusg_gen_attempt#4",
          "startTime": "2025-12-10T20:37:06.355000+00:00",
          "endTime": "2025-12-10T20:37:21.411000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 15056.0,
          "totalTokens": 1104,
          "costDetails": {},
          "environment": "default",
          "promptTokens": 273,
          "completionTokens": 831,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-22-37-29-437159_chatcmpl-0326e16d-cf70-4b6f-a70b-579e0be31995",
          "traceId": "78ed4061",
          "type": "GENERATION",
          "name": "78ed_tpusg_gen_attempt#5",
          "startTime": "2025-12-10T20:37:29.437000+00:00",
          "endTime": "2025-12-10T20:37:48.901000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 19464.0,
          "totalTokens": 1344,
          "costDetails": {},
          "environment": "default",
          "promptTokens": 273,
          "completionTokens": 1071,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "552a239a-8055-4cc7-b854-81f222e2ed3b",
          "traceId": "78ed4061",
          "type": "SPAN",
          "name": "error_78_tpusg_failure_signal_tpu_sketch_generator",
          "startTime": "2025-12-10T20:37:57.680000+00:00",
          "level": "ERROR",
          "statusMessage": "Failed: Max retries reached with error. Last error: Traceback (most recent call last):\n  File \"script_a0bc6edc_1765399068.py\", line 112, in <module>\n    main()\n  File \"script_a0bc6edc_1765399068.py\", line 98, in main\n    boxes, classes, scores = run_inference(interpreter, frame)\n  File \"script_a0bc6edc_1765399068.py\", line 46, in run_inference\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n  File \"/home/mendel/tinyml_autopilot/tinyml-env/lib/python3.7/site-packages/tflite_runtime/interpreter.py\", line 572, in set_tensor\n    self._interpreter.SetTensor(tensor_index, value)\nValueError: Cannot set tensor: Got value of type FLOAT32 but expected type UINT8 for input 175, name: normalized_input_image_tensor .",
          "calculatedTotalCost": 0.0,
          "totalTokens": 0,
          "costDetails": {},
          "environment": "default",
          "promptTokens": 0,
          "completionTokens": 0,
          "endTime": null,
          "model": null,
          "modelParameters": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null,
          "latency": null
        }
      ],
      "createdAt": "2025-12-10T20:35:53.034Z",
      "updatedAt": "2025-12-10T20:38:03.203Z",
      "environment": "default"
    },
    {
      "id": "0ff3416f",
      "timestamp": "2025-12-10T20:33:09.603000+00:00",
      "name": "0ff3_tpu_sketch_generator",
      "input": null,
      "output": {
        "status": "success",
        "sketch": "import cv2\nimport numpy as np\nimport time\nfrom tflite_runtime.interpreter import Interpreter\nfrom tflite_runtime.interpreter import load_delegate\n\n# Configuration parameters\nmodel_path  = \"/home/mendel/tinyml_autopilot/models/edgetpu_detect.tflite\"\nlabel_path  = \"/home/mendel/tinyml_autopilot/models/labelmap.txt\"\ninput_path  = \"/home/mendel/tinyml_autopilot/data//sheeps.mp4\"\noutput_path  = \"/home/mendel/tinyml_autopilot/results/sheeps_detections.mp4\"\nconfidence_threshold  = 0.5\n\n# Phase 1: Setup\ndef load_labels(path):\n    with open(path, 'r') as f:\n        return [line.strip() for line in f.readlines()]\n\nlabels = load_labels(label_path)\ninterpreter = Interpreter(\n    model_path=model_path,\n    experimental_delegates=[load_delegate('/usr/lib/aarch64-linux-gnu/libedgetpu.so.1.0')]\n)\ninterpreter.allocate_tensors()\n\n# Get input and output details\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\n\ninput_shape = input_details[0]['shape']\ninput_index = input_details[0]['index']\n\n# Phase 2: Preprocessing\ndef preprocess_frame(frame):\n    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n    frame_resized = cv2.resize(frame_rgb, (input_shape[1], input_shape[2]))\n    return np.expand_dims(frame_resized, axis=0)\n\n# Phase 3: Inference\ndef run_inference(frame):\n    interpreter.set_tensor(input_details[0]['index'], frame)\n    start_time = time.time()\n    interpreter.invoke()\n    inference_time = time.time() - start_time\n\n    boxes = interpreter.get_tensor(output_details[0]['index'])[0]  # Bounding box coordinates of detected objects\n    classes = interpreter.get_tensor(output_details[1]['index'])[0]  # Class index of detected objects\n    scores = interpreter.get_tensor(output_details[2]['index'])[0]  # Confidence of detected objects\n\n    return boxes, classes, scores, inference_time\n\n# Phase 4: Output Handling\ndef draw_boxes(frame, boxes, classes, scores):\n    height, width, _ = frame.shape\n    for i in range(len(scores)):\n        if scores[i] >= confidence_threshold:\n            ymin, xmin, ymax, xmax = boxes[i]\n            (left, right, top, bottom) = (xmin * width, xmax * width, ymin * height, ymax * height)\n            cv2.rectangle(frame, (int(left), int(top)), (int(right), int(bottom)), (0, 255, 0), 2)\n\n            label = f\"{labels[int(classes[i])]}: {int(scores[i] * 100)}%\"\n            label_size, base_line = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.7, 2)\n            top = max(top, label_size[1])\n            cv2.rectangle(frame, (int(left), int(top - round(1.5*label_size[1]))), \n                          (int(left + label_size[0]), int(top + base_line)), (255, 255, 255), cv2.FILLED)\n            cv2.putText(frame, label, (int(left), int(top)), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 0), 2)\n\ndef main():\n    cap = cv2.VideoCapture(input_path)\n    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n    out = cv2.VideoWriter(output_path, fourcc, 20.0, (int(cap.get(3)), int(cap.get(4))))\n\n    frame_count = 0\n    total_inference_time = 0\n\n    while cap.isOpened():\n        ret, frame = cap.read()\n        if not ret:\n            break\n\n        preprocessed_frame = preprocess_frame(frame)\n        boxes, classes, scores, inference_time = run_inference(preprocessed_frame)\n\n        draw_boxes(frame, boxes, classes, scores)\n\n        out.write(frame)\n\n        frame_count += 1\n        total_inference_time += inference_time\n\n    cap.release()\n    out.release()\n\n    print(f\"Processed {frame_count} frames\")\n    if frame_count > 0:\n        print(f\"Average inference time per frame: {total_inference_time / frame_count:.4f} seconds\")\n\nif __name__ == '__main__':\n    main()"
      },
      "session_id": "phi4_9e98_tpusg_batch",
      "metadata": {
        "num_run": 22
      },
      "tags": [
        "ablation",
        "benchmark",
        "phi4:latest",
        "tpu_sketch_generator"
      ],
      "latency": 84.743,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-22-33-09-604042_chatcmpl-1dbe104a-b296-4f92-a588-b42f8966746b",
          "traceId": "0ff3416f",
          "type": "GENERATION",
          "name": "0ff3_tpusg_gen_attempt#1",
          "startTime": "2025-12-10T20:33:09.604000+00:00",
          "endTime": "2025-12-10T20:33:29.208000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 19604.0,
          "totalTokens": 1348,
          "costDetails": {},
          "environment": "default",
          "promptTokens": 273,
          "completionTokens": 1075,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-22-33-37-060441_chatcmpl-c9a1a2ad-41ab-4ba2-a5d9-218104113565",
          "traceId": "0ff3416f",
          "type": "GENERATION",
          "name": "0ff3_tpusg_gen_attempt#2",
          "startTime": "2025-12-10T20:33:37.060000+00:00",
          "endTime": "2025-12-10T20:33:48.757000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 11697.0,
          "totalTokens": 919,
          "costDetails": {},
          "environment": "default",
          "promptTokens": 273,
          "completionTokens": 646,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-22-33-56-411782_chatcmpl-e91a0781-0990-40a6-9063-59b6275cf7be",
          "traceId": "0ff3416f",
          "type": "GENERATION",
          "name": "0ff3_tpusg_gen_attempt#3",
          "startTime": "2025-12-10T20:33:56.411000+00:00",
          "endTime": "2025-12-10T20:34:09.830000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 13419.0,
          "totalTokens": 1014,
          "costDetails": {},
          "environment": "default",
          "promptTokens": 273,
          "completionTokens": 741,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-22-34-17-583051_chatcmpl-5495dd29-e9df-4467-9c3a-2959df8b1bcb",
          "traceId": "0ff3416f",
          "type": "GENERATION",
          "name": "0ff3_tpusg_gen_attempt#4",
          "startTime": "2025-12-10T20:34:17.583000+00:00",
          "endTime": "2025-12-10T20:34:34.347000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 16764.0,
          "totalTokens": 1198,
          "costDetails": {},
          "environment": "default",
          "promptTokens": 273,
          "completionTokens": 925,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        }
      ],
      "createdAt": "2025-12-10T20:33:10.120Z",
      "updatedAt": "2025-12-10T20:35:32.955Z",
      "environment": "default"
    },
    {
      "id": "1d2c5cf8",
      "timestamp": "2025-12-10T20:31:14.677000+00:00",
      "name": "1d2c_tpu_sketch_generator",
      "input": null,
      "output": {
        "status": "success",
        "sketch": "import cv2\nimport numpy as np\nfrom tflite_runtime.interpreter import Interpreter\nfrom tflite_runtime.interpreter import load_delegate\n\n# Configuration parameters\nmodel_path  = \"/home/mendel/tinyml_autopilot/models/edgetpu_detect.tflite\"\nlabel_path  = \"/home/mendel/tinyml_autopilot/models/labelmap.txt\"\ninput_path  = \"/home/mendel/tinyml_autopilot/data//sheeps.mp4\"\noutput_path  = \"/home/mendel/tinyml_autopilot/results/sheeps_detections.mp4\"\nconfidence_threshold  = 0.5\n\n# Load labels\nwith open(label_path, 'r') as f:\n    labels = [line.strip() for line in f.readlines()]\n\n# Setup TFLite interpreter with Coral Edge TPU delegate\ninterpreter = Interpreter(\n    model_path=model_path,\n    experimental_delegates=[load_delegate('/usr/lib/aarch64-linux-gnu/libedgetpu.so.1.0')]\n)\ninterpreter.allocate_tensors()\n\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\n\n# Helper functions\ndef set_input_tensor(interpreter, image):\n    tensor_index = input_details[0]['index']\n    input_shape = input_details[0]['shape']\n    image = cv2.resize(image, (input_shape[1], input_shape[2]))\n    input_data = np.expand_dims(image, axis=0)\n    interpreter.set_tensor(tensor_index, input_data)\n\ndef get_output(interpreter):\n    boxes = interpreter.get_tensor(output_details[0]['index'])[0]  # Bounding box coordinates of detected objects\n    classes = interpreter.get_tensor(output_details[1]['index'])[0]  # Class index of detected objects\n    scores = interpreter.get_tensor(output_details[2]['index'])[0]  # Confidence of detected objects\n    return boxes, classes, scores\n\ndef draw_detections(image, boxes, classes, scores):\n    height, width, _ = image.shape\n    for i in range(len(scores)):\n        if scores[i] >= confidence_threshold:\n            ymin, xmin, ymax, xmax = boxes[i]\n            (left, right, top, bottom) = (xmin * width, xmax * width,\n                                          ymin * height, ymax * height)\n            cv2.rectangle(image, (int(left), int(top)), (int(right), int(bottom)),\n                          (10, 255, 0), thickness=4)\n            label = f'{labels[int(classes[i])]}: {scores[i]:.2f}'\n            label_size, base_line = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.7, 2)\n            top = max(top, label_size[1])\n            cv2.rectangle(image, (int(left), int(top - label_size[1])),\n                          (int(left + label_size[0]), int(top + base_line)), (255, 255, 255), cv2.FILLED)\n            cv2.putText(image, label, (int(left), int(top)),\n                        cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 0), thickness=2)\n\n# Read input video\ncap = cv2.VideoCapture(input_path)\nfourcc = cv2.VideoWriter_fourcc(*'mp4v')\nout = cv2.VideoWriter(output_path, fourcc, 30.0, (int(cap.get(3)), int(cap.get(4))))\n\nwhile cap.isOpened():\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    # Inference\n    set_input_tensor(interpreter, frame)\n    interpreter.invoke()\n    boxes, classes, scores = get_output(interpreter)\n\n    # Draw detections on the frame\n    draw_detections(frame, boxes, classes, scores)\n\n    # Write the output frame\n    out.write(frame)\n\ncap.release()\nout.release()\n\n# Note: The mAP computation is not included in this script as it requires ground truth annotations and a more complex setup."
      },
      "session_id": "phi4_9e98_tpusg_batch",
      "metadata": {
        "num_run": 21
      },
      "tags": [
        "ablation",
        "benchmark",
        "phi4:latest",
        "tpu_sketch_generator"
      ],
      "latency": 36.916,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-22-31-14-678982_chatcmpl-962f5bf7-9a7e-4a95-a82b-6b7b14c8ca24",
          "traceId": "1d2c5cf8",
          "type": "GENERATION",
          "name": "1d2c_tpusg_gen_attempt#1",
          "startTime": "2025-12-10T20:31:14.678000+00:00",
          "endTime": "2025-12-10T20:31:27.790000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 13112.0,
          "totalTokens": 993,
          "costDetails": {},
          "environment": "default",
          "promptTokens": 273,
          "completionTokens": 720,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-22-31-35-499023_chatcmpl-c53a6a85-5c00-4478-b884-d0f0f5fc683d",
          "traceId": "1d2c5cf8",
          "type": "GENERATION",
          "name": "1d2c_tpusg_gen_attempt#2",
          "startTime": "2025-12-10T20:31:35.499000+00:00",
          "endTime": "2025-12-10T20:31:51.594000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 16095.0,
          "totalTokens": 1161,
          "costDetails": {},
          "environment": "default",
          "promptTokens": 273,
          "completionTokens": 888,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        }
      ],
      "createdAt": "2025-12-10T20:31:15.195Z",
      "updatedAt": "2025-12-10T20:32:49.864Z",
      "environment": "default"
    },
    {
      "id": "25017acb",
      "timestamp": "2025-12-10T20:28:46.685000+00:00",
      "name": "2501_tpu_sketch_generator",
      "input": null,
      "output": {
        "status": "failed",
        "last_code": "import cv2\nimport numpy as np\nimport tensorflow as tf\nfrom tflite_runtime.interpreter import Interpreter\nfrom utils import label_map_util, visualization_utils_cv2\n\n# Configuration parameters\nmodel_path  = \"/home/mendel/tinyml_autopilot/models/edgetpu_detect.tflite\"\nlabel_path  = \"/home/mendel/tinyml_autopilot/models/labelmap.txt\"\ninput_path  = \"/home/mendel/tinyml_autopilot/data//sheeps.mp4\"\noutput_path  = \"/home/mendel/tinyml_autopilot/results/sheeps_detections.mp4\"\nconfidence_threshold  = 0.5\n\n# Phase 1: Setup - Load the TFLite interpreter for TPU\ndef load_interpreter():\n    # Specify the TPU library path for Coral Dev Board\n    tpu_lib = '/usr/lib/aarch64-linux-gnu/libedgetpu.so.1.0'\n    \n    # Set up the Interpreter with TPU delegate\n    return Interpreter(\n        model_path=model_path,\n        experimental_delegates=[tf.lite.experimental.load_delegate(tpu_lib)]\n    )\n\ninterpreter = load_interpreter()\ninterpreter.allocate_tensors()\n\n# Get input and output tensors.\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\n\n# Phase 2: Preprocessing - Load labels\ndef load_labels(label_path):\n    label_map = label_map_util.load_labelmap(label_path)\n    categories = label_map_util.convert_label_map_to_categories(\n        label_map, max_num_classes=interpreter.get_output_details()[0]['dtype'])\n    category_index = label_map_util.create_category_index(categories)\n    return category_index\n\ncategory_index = load_labels(label_path)\n\n# Function to run inference\ndef run_inference(image):\n    # Preprocess the image\n    input_shape = input_details[0]['shape']\n    image_resized = cv2.resize(image, (input_shape[1], input_shape[2]))\n    input_data = np.expand_dims(image_resized, axis=0).astype(np.float32)\n    \n    # Set the tensor to point to the input data\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n    \n    # Run inference\n    interpreter.invoke()\n    \n    # Extract output data\n    boxes = interpreter.get_tensor(output_details[0]['index'])[0]  # Bounding box coordinates of detected objects\n    classes = interpreter.get_tensor(output_details[1]['index'])[0]  # Class index of detected objects\n    scores = interpreter.get_tensor(output_details[2]['index'])[0]  # Confidence of detected objects\n    \n    return boxes, classes, scores\n\n# Phase 3: Inference - Process video and run inference\ndef process_video(input_path, output_path):\n    cap = cv2.VideoCapture(input_path)\n    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n    out = cv2.VideoWriter(output_path, fourcc, 30.0, (int(cap.get(3)), int(cap.get(4))))\n    \n    while cap.isOpened():\n        ret, frame = cap.read()\n        if not ret:\n            break\n        \n        # Run inference\n        boxes, classes, scores = run_inference(frame)\n        \n        # Filter out low confidence detections\n        valid_detections = [\n            (box, score, category_index[cls]['name'])\n            for box, cls, score in zip(boxes, classes, scores)\n            if score >= confidence_threshold and cls in category_index\n        ]\n        \n        # Draw boxes on the frame\n        visualization_utils_cv2.draw_boxes_on_image_with_labels(\n            frame,\n            valid_detections,\n            use_normalized_coordinates=True,\n            max_boxes_to_draw=100,\n            min_score_thresh=confidence_threshold,\n            line_thickness=4\n        )\n        \n        out.write(frame)\n    \n    cap.release()\n    out.release()\n\n# Phase 4: Output Handling - Run the process and output results\nprocess_video(input_path, output_path)\n\nprint(f\"Processed video saved to {output_path}\")",
        "last_error": "Max retries reached with error. Last error: Traceback (most recent call last):\n  File \"script_3148fa3f_1765398641.py\", line 3, in <module>\n    import tensorflow as tf\nModuleNotFoundError: No module named 'tensorflow'."
      },
      "session_id": "phi4_9e98_tpusg_batch",
      "metadata": {
        "num_run": 20
      },
      "tags": [
        "ablation",
        "benchmark",
        "phi4:latest",
        "tpu_sketch_generator"
      ],
      "latency": 123.005,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-22-28-46-686830_chatcmpl-ec885a48-b8dc-464c-9f32-5efd659470d7",
          "traceId": "25017acb",
          "type": "GENERATION",
          "name": "2501_tpusg_gen_attempt#1",
          "startTime": "2025-12-10T20:28:46.686000+00:00",
          "endTime": "2025-12-10T20:29:03.407000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 16721.0,
          "totalTokens": 1190,
          "costDetails": {},
          "environment": "default",
          "promptTokens": 273,
          "completionTokens": 917,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-22-29-11-681233_chatcmpl-a8c3c245-8c57-40b3-8b3a-162f1d15ed5d",
          "traceId": "25017acb",
          "type": "GENERATION",
          "name": "2501_tpusg_gen_attempt#2",
          "startTime": "2025-12-10T20:29:11.681000+00:00",
          "endTime": "2025-12-10T20:29:27.220000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 15539.0,
          "totalTokens": 1130,
          "costDetails": {},
          "environment": "default",
          "promptTokens": 273,
          "completionTokens": 857,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-22-29-35-435205_chatcmpl-5b7fb6cb-a814-4eae-8ca8-3eec1f5fa5e7",
          "traceId": "25017acb",
          "type": "GENERATION",
          "name": "2501_tpusg_gen_attempt#3",
          "startTime": "2025-12-10T20:29:35.435000+00:00",
          "endTime": "2025-12-10T20:29:49.455000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 14020.0,
          "totalTokens": 1046,
          "costDetails": {},
          "environment": "default",
          "promptTokens": 273,
          "completionTokens": 773,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-22-29-57-192980_chatcmpl-932c7504-c0d7-44ca-89ea-49e1a730c9da",
          "traceId": "25017acb",
          "type": "GENERATION",
          "name": "2501_tpusg_gen_attempt#4",
          "startTime": "2025-12-10T20:29:57.192000+00:00",
          "endTime": "2025-12-10T20:30:18.113000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 20921.0,
          "totalTokens": 1421,
          "costDetails": {},
          "environment": "default",
          "promptTokens": 273,
          "completionTokens": 1148,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-22-30-26-235106_chatcmpl-a85bdc52-e181-48c4-8858-ff2f567f899d",
          "traceId": "25017acb",
          "type": "GENERATION",
          "name": "2501_tpusg_gen_attempt#5",
          "startTime": "2025-12-10T20:30:26.235000+00:00",
          "endTime": "2025-12-10T20:30:41.975000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 15740.0,
          "totalTokens": 1141,
          "costDetails": {},
          "environment": "default",
          "promptTokens": 273,
          "completionTokens": 868,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "a0f5eec5-420c-4c9e-9f53-cea9b64bbb9c",
          "traceId": "25017acb",
          "type": "SPAN",
          "name": "error_25_tpusg_failure_signal_tpu_sketch_generator",
          "startTime": "2025-12-10T20:30:49.691000+00:00",
          "level": "ERROR",
          "statusMessage": "Failed: Max retries reached with error. Last error: Traceback (most recent call last):\n  File \"script_3148fa3f_1765398641.py\", line 3, in <module>\n    import tensorflow as tf\nModuleNotFoundError: No module named 'tensorflow'.",
          "calculatedTotalCost": 0.0,
          "totalTokens": 0,
          "costDetails": {},
          "environment": "default",
          "promptTokens": 0,
          "completionTokens": 0,
          "endTime": null,
          "model": null,
          "modelParameters": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null,
          "latency": null
        }
      ],
      "createdAt": "2025-12-10T20:28:47.202Z",
      "updatedAt": "2025-12-10T20:30:54.857Z",
      "environment": "default"
    },
    {
      "id": "067bd47a",
      "timestamp": "2025-12-10T20:27:16.695000+00:00",
      "name": "067b_tpu_sketch_generator",
      "input": null,
      "output": {
        "status": "success",
        "sketch": "import cv2\nimport numpy as np\nfrom tflite_runtime.interpreter import Interpreter\nfrom tflite_runtime.interpreter import load_delegate\n\n# Configuration parameters\nmodel_path  = \"/home/mendel/tinyml_autopilot/models/edgetpu_detect.tflite\"\nlabel_path  = \"/home/mendel/tinyml_autopilot/models/labelmap.txt\"\ninput_path  = \"/home/mendel/tinyml_autopilot/data//sheeps.mp4\"\noutput_path  = \"/home/mendel/tinyml_autopilot/results/sheeps_detections.mp4\"\nconfidence_threshold  = 0.5\n\n# Load labels\ndef load_labels(path):\n    with open(path, 'r') as f:\n        return {i: line.strip() for i, line in enumerate(f.readlines())}\n\nlabels = load_labels(label_path)\n\n# Initialize the TPU interpreter\ninterpreter = Interpreter(\n    model_path=model_path,\n    experimental_delegates=[load_delegate('/usr/lib/aarch64-linux-gnu/libedgetpu.so.1.0')]\n)\ninterpreter.allocate_tensors()\n\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\n\nheight, width = input_details[0]['shape'][1:3]\n\ndef preprocess(frame):\n    frame_resized = cv2.resize(frame, (width, height))\n    input_data = np.expand_dims(frame_resized, axis=0)\n    return input_data\n\ndef postprocess(results, frame, conf_threshold):\n    boxes = results[0][0]  # Bounding box coordinates\n    classes = results[1][0].astype(np.int32)  # Class index\n    scores = results[2][0]  # Confidence score\n    \n    for i in range(len(scores)):\n        if scores[i] > conf_threshold:\n            ymin, xmin, ymax, xmax = boxes[i]\n            (left, right, top, bottom) = (xmin * frame.shape[1], xmax * frame.shape[1],\n                                          ymin * frame.shape[0], ymax * frame.shape[0])\n            \n            label = f\"{labels[classes[i]]}: {int(scores[i] * 100)}%\"\n            cv2.rectangle(frame, (int(left), int(top)), (int(right), int(bottom)), (10, 255, 0), 2)\n            cv2.putText(frame, label, (int(left), int(top-5)), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (10, 255, 0), 1)\n\ndef main():\n    cap = cv2.VideoCapture(input_path)\n    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n    out = cv2.VideoWriter(output_path, fourcc, 30.0, (int(cap.get(3)), int(cap.get(4))))\n\n    while True:\n        ret, frame = cap.read()\n        if not ret:\n            break\n\n        input_data = preprocess(frame)\n        interpreter.set_tensor(input_details[0]['index'], input_data)\n\n        interpreter.invoke()\n\n        results = [\n            interpreter.get_tensor(output_details[i]['index']) for i in range(len(output_details))\n        ]\n\n        postprocess(results, frame, confidence_threshold)\n        \n        out.write(frame)\n\n    cap.release()\n    out.release()\n    cv2.destroyAllWindows()\n\nif __name__ == \"__main__\":\n    main()"
      },
      "session_id": "phi4_9e98_tpusg_batch",
      "metadata": {
        "num_run": 19
      },
      "tags": [
        "ablation",
        "benchmark",
        "phi4:latest",
        "tpu_sketch_generator"
      ],
      "latency": 12.11,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-22-27-16-697004_chatcmpl-60055f70-2b58-4a1d-b29a-e6c6a55366d3",
          "traceId": "067bd47a",
          "type": "GENERATION",
          "name": "067b_tpusg_gen_attempt#1",
          "startTime": "2025-12-10T20:27:16.697000+00:00",
          "endTime": "2025-12-10T20:27:28.807000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 12110.0,
          "totalTokens": 939,
          "costDetails": {},
          "environment": "default",
          "promptTokens": 273,
          "completionTokens": 666,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        }
      ],
      "createdAt": "2025-12-10T20:27:17.213Z",
      "updatedAt": "2025-12-10T20:28:26.411Z",
      "environment": "default"
    },
    {
      "id": "a68806c6",
      "timestamp": "2025-12-10T20:24:52.738000+00:00",
      "name": "a688_tpu_sketch_generator",
      "input": null,
      "output": {
        "status": "failed",
        "last_code": "import cv2\nimport numpy as np\nimport os\nfrom tflite_runtime.interpreter import Interpreter\n\n# Configuration parameters\nmodel_path  = \"/home/mendel/tinyml_autopilot/models/edgetpu_detect.tflite\"\nlabel_path  = \"/home/mendel/tinyml_autopilot/models/labelmap.txt\"\ninput_path  = \"/home/mendel/tinyml_autopilot/data//sheeps.mp4\"\noutput_path  = \"/home/mendel/tinyml_autopilot/results/sheeps_detections.mp4\"\nconfidence_threshold  = 0.5\n\n# Load labels\ndef load_labels(path):\n    with open(path, 'r', encoding='utf-8') as file:\n        return {i: line.strip() for i, line in enumerate(file.readlines())}\n\nlabels = load_labels(label_path)\n\n# Setup TFLite interpreter for Coral Dev Board with TPU\ninterpreter = Interpreter(\n    model_path=model_path,\n    experimental_delegates=[np.load('/usr/lib/aarch64-linux-gnu/libedgetpu.so.1.0')]\n)\ninterpreter.allocate_tensors()\n\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\n\n# Preprocessing: Resize input image to match the model's input size\ndef preprocess_image(frame):\n    height, width, _ = frame.shape\n    model_height, model_width = input_details[0]['shape'][1:3]\n    resized_frame = cv2.resize(frame, (model_width, model_height))\n    input_data = np.expand_dims(resized_frame, axis=0).astype(np.float32)\n    return input_data\n\n# Inference: Run object detection\ndef detect_objects(input_data):\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n    interpreter.invoke()\n    \n    boxes = interpreter.get_tensor(output_details[0]['index'])[0] # Bounding box coordinates of detected objects\n    classes = interpreter.get_tensor(output_details[1]['index'])[0] # Class index of detected objects\n    scores = interpreter.get_tensor(output_details[2]['index'])[0] # Confidence of detected objects\n    \n    return boxes, classes, scores\n\n# Output handling: Draw detection boxes with labels and compute mAP\ndef draw_detections(frame, boxes, classes, scores):\n    for i in range(len(scores)):\n        if scores[i] > confidence_threshold:\n            ymin, xmin, ymax, xmax = boxes[i]\n            (left, right, top, bottom) = (xmin * frame.shape[1], xmax * frame.shape[1],\n                                          ymin * frame.shape[0], ymax * frame.shape[0])\n            \n            # Draw rectangle and label\n            cv2.rectangle(frame, (int(left), int(top)), (int(right), int(bottom)), (10, 255, 0), 2)\n            object_name = labels[int(classes[i])] + f' {int(scores[i]*100)}%'\n            label_size, base_line = cv2.getTextSize(object_name, cv2.FONT_HERSHEY_SIMPLEX, 0.7, 2)\n            top = max(top, label_size[1])\n            cv2.rectangle(frame, (int(left), int(top - label_size[1])), (int(left + label_size[0]), int(top + base_line)), (255, 255, 255), cv2.FILLED)\n            cv2.putText(frame, object_name, (int(left), int(top)), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 0), 2)\n\n# Process video\ncap = cv2.VideoCapture(input_path)\nfourcc = cv2.VideoWriter_fourcc(*'mp4v')\nout = cv2.VideoWriter(output_path, fourcc, 20.0, (int(cap.get(3)), int(cap.get(4))))\n\nwhile cap.isOpened():\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    input_data = preprocess_image(frame)\n    boxes, classes, scores = detect_objects(input_data)\n    draw_detections(frame, boxes, classes, scores)\n\n    out.write(frame)\n\ncap.release()\nout.release()\ncv2.destroyAllWindows()",
        "last_error": "Max retries reached with error. Last error: Traceback (most recent call last):\n  File \"script_255ef863_1765398403.py\", line 23, in <module>\n    experimental_delegates=[np.load('/usr/lib/aarch64-linux-gnu/libedgetpu.so.1.0')]\n  File \"/home/mendel/tinyml_autopilot/tinyml-env/lib/python3.7/site-packages/numpy/lib/npyio.py\", line 445, in load\n    raise ValueError(\"Cannot load file containing pickled data \"\nValueError: Cannot load file containing pickled data when allow_pickle=False."
      },
      "session_id": "phi4_9e98_tpusg_batch",
      "metadata": {
        "num_run": 18
      },
      "tags": [
        "ablation",
        "benchmark",
        "phi4:latest",
        "tpu_sketch_generator"
      ],
      "latency": 118.763,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-22-24-52-739812_chatcmpl-f12d0e4f-d59c-4ee4-9863-a82e1c107822",
          "traceId": "a68806c6",
          "type": "GENERATION",
          "name": "a688_tpusg_gen_attempt#1",
          "startTime": "2025-12-10T20:24:52.739000+00:00",
          "endTime": "2025-12-10T20:25:08.251000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 15512.0,
          "totalTokens": 1117,
          "costDetails": {},
          "environment": "default",
          "promptTokens": 273,
          "completionTokens": 844,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-22-25-15-987828_chatcmpl-076fd9cd-c024-46e0-962b-fa9e85084c87",
          "traceId": "a68806c6",
          "type": "GENERATION",
          "name": "a688_tpusg_gen_attempt#2",
          "startTime": "2025-12-10T20:25:15.987000+00:00",
          "endTime": "2025-12-10T20:25:32.387000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 16400.0,
          "totalTokens": 1177,
          "costDetails": {},
          "environment": "default",
          "promptTokens": 273,
          "completionTokens": 904,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-22-25-40-159228_chatcmpl-9dd47eb0-232e-4241-b2d9-c6888a9fd885",
          "traceId": "a68806c6",
          "type": "GENERATION",
          "name": "a688_tpusg_gen_attempt#3",
          "startTime": "2025-12-10T20:25:40.159000+00:00",
          "endTime": "2025-12-10T20:25:55.191000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 15032.0,
          "totalTokens": 1103,
          "costDetails": {},
          "environment": "default",
          "promptTokens": 273,
          "completionTokens": 830,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-22-26-03-348838_chatcmpl-8cadcea8-2a93-43a0-b8d4-ef6ce8592370",
          "traceId": "a68806c6",
          "type": "GENERATION",
          "name": "a688_tpusg_gen_attempt#4",
          "startTime": "2025-12-10T20:26:03.348000+00:00",
          "endTime": "2025-12-10T20:26:20.021000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 16673.0,
          "totalTokens": 1192,
          "costDetails": {},
          "environment": "default",
          "promptTokens": 273,
          "completionTokens": 919,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-22-26-28-374690_chatcmpl-339b62f0-6fbb-4f97-893e-9ba11739a9c2",
          "traceId": "a68806c6",
          "type": "GENERATION",
          "name": "a688_tpusg_gen_attempt#5",
          "startTime": "2025-12-10T20:26:28.374000+00:00",
          "endTime": "2025-12-10T20:26:43.405000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 15031.0,
          "totalTokens": 1103,
          "costDetails": {},
          "environment": "default",
          "promptTokens": 273,
          "completionTokens": 830,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "2ffd8fe8-3df3-4e1d-89f3-186532c60a8b",
          "traceId": "a68806c6",
          "type": "SPAN",
          "name": "error_a6_tpusg_failure_signal_tpu_sketch_generator",
          "startTime": "2025-12-10T20:26:51.502000+00:00",
          "level": "ERROR",
          "statusMessage": "Failed: Max retries reached with error. Last error: Traceback (most recent call last):\n  File \"script_255ef863_1765398403.py\", line 23, in <module>\n    experimental_delegates=[np.load('/usr/lib/aarch64-linux-gnu/libedgetpu.so.1.0')]\n  File \"/home/mendel/tinyml_autopilot/tinyml-env/lib/python3.7/site-packages/numpy/lib/npyio.py\", line 445, in load\n    raise ValueError(\"Cannot load file containing pickled data \"\nValueError: Cannot load file containing pickled data when allow_pickle=False.",
          "calculatedTotalCost": 0.0,
          "totalTokens": 0,
          "costDetails": {},
          "environment": "default",
          "promptTokens": 0,
          "completionTokens": 0,
          "endTime": null,
          "model": null,
          "modelParameters": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null,
          "latency": null
        }
      ],
      "createdAt": "2025-12-10T20:24:53.255Z",
      "updatedAt": "2025-12-10T20:26:56.895Z",
      "environment": "default"
    },
    {
      "id": "d969d458",
      "timestamp": "2025-12-10T20:22:10.715000+00:00",
      "name": "d969_tpu_sketch_generator",
      "input": null,
      "output": {
        "status": "failed",
        "last_code": "import cv2\nimport numpy as np\nimport tflite_runtime.interpreter as tflite\nfrom google.protobuf import text_format\nfrom object_detection.protos.string_int_label_map_pb2 import StringIntLabelMap\nfrom object_detection.utils import visualization_utils as vis_util\n\n# Configuration parameters\nmodel_path  = \"/home/mendel/tinyml_autopilot/models/edgetpu_detect.tflite\"\nlabel_path  = \"/home/mendel/tinyml_autopilot/models/labelmap.txt\"\ninput_path  = \"/home/mendel/tinyml_autopilot/data//sheeps.mp4\"\noutput_path  = \"/home/mendel/tinyml_autopilot/results/sheeps_detections.mp4\"\nconfidence_threshold  = 0.5\n\n# Phase 1: Setup - Load TFLite Interpreter for Coral Edge TPU\ndef load_interpreter(model_path):\n    # Load the interpreter with Coral's EdgeTPU library\n    return tflite.Interpreter(\n        model_path=model_path,\n        experimental_delegates=[tflite.load_delegate('/usr/lib/aarch64-linux-gnu/libedgetpu.so.1.0')]\n    )\n\n# Phase 2: Preprocessing - Read labels from label map\ndef load_labels(label_path):\n    with open(label_path, 'r', encoding='utf-8') as file:\n        lines = file.readlines()\n    \n    # Parse the label map\n    label_map = StringIntLabelMap()\n    text_format.Parse('\\n'.join(lines), label_map)\n    \n    return {item.id: item.name for item in label_map.item}\n\n# Function to process a frame and run inference\ndef preprocess_frame(frame, input_details):\n    # Resize frame to model's input size\n    height, width = input_details[0]['shape'][1], input_details[0]['shape'][2]\n    frame_resized = cv2.resize(frame, (width, height))\n    \n    # Normalize pixel values if necessary and convert to float32\n    frame_normalized = np.expand_dims(frame_resized / 255.0, axis=0).astype(np.float32)\n    return frame_normalized\n\ndef run_inference(interpreter, input_data):\n    input_details = interpreter.get_input_details()\n    output_details = interpreter.get_output_details()\n\n    # Set the tensor to point to the input data to be inferred\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n\n    # Run inference and get the results\n    interpreter.invoke()\n\n    # Extract detection boxes, scores, classes, and number of detections\n    boxes = interpreter.get_tensor(output_details[0]['index'])[0]  # Bounding box coordinates\n    class_ids = interpreter.get_tensor(output_details[1]['index'])[0].astype(np.int32)  # Class index\n    scores = interpreter.get_tensor(output_details[2]['index'])[0]  # Confidence score\n    num_detections = int(interpreter.get_tensor(output_details[3]['index'])[0])  # Number of detections\n\n    return boxes, class_ids, scores, num_detections\n\n# Phase 4: Output handling - Draw boxes and compute mAP\ndef draw_boxes(frame, boxes, class_ids, scores, label_map, confidence_threshold):\n    vis_util.visualize_boxes_and_labels_on_image_array(\n        frame,\n        boxes,\n        classes=class_ids,\n        scores=scores,\n        category_index=label_map,\n        use_normalized_coordinates=True,\n        line_thickness=4,\n        min_score_thresh=confidence_threshold\n    )\n\ndef main():\n    # Load the TFLite model and allocate tensors.\n    interpreter = load_interpreter(model_path)\n    interpreter.allocate_tensors()\n\n    input_details = interpreter.get_input_details()\n    output_details = interpreter.get_output_details()\n\n    label_map = load_labels(label_path)\n\n    # Open video file or stream\n    cap = cv2.VideoCapture(input_path)\n    if not cap.isOpened():\n        print(\"Error: Could not open video.\")\n        return\n\n    # Define the codec and create VideoWriter object\n    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n    out = cv2.VideoWriter(output_path, fourcc, 20.0, (int(cap.get(3)), int(cap.get(4))))\n\n    while cap.isOpened():\n        ret, frame = cap.read()\n        \n        if not ret:\n            break\n\n        # Preprocess the frame\n        input_data = preprocess_frame(frame, input_details)\n\n        # Run inference\n        boxes, class_ids, scores, num_detections = run_inference(interpreter, input_data)\n        \n        # Filter out detections below the confidence threshold and draw boxes\n        for i in range(num_detections):\n            if scores[i] >= confidence_threshold:\n                box = tuple(boxes[i].tolist())\n                class_id = int(class_ids[i])\n                label = f\"{label_map.get(class_id, 'Unknown')} {int(scores[i]*100)}%\"\n                \n                vis_util.draw_bounding_box_on_image_array(\n                    frame,\n                    ymin=box[0], xmin=box[1],\n                    ymax=box[2], xmax=box[3],\n                    color=(0, 255, 0), thickness=4,\n                    display_str_list=[label]\n                )\n\n        # Write the frame with boxes\n        out.write(frame)\n\n    cap.release()\n    out.release()\n\nif __name__ == '__main__':\n    main()",
        "last_error": "Max retries reached with error. Last error: Traceback (most recent call last):\n  File \"script_0daf6516_1765398258.py\", line 5, in <module>\n    from object_detection.protos.string_int_label_map_pb2 import StringIntLabelMap\nModuleNotFoundError: No module named 'object_detection'."
      },
      "session_id": "phi4_9e98_tpusg_batch",
      "metadata": {
        "num_run": 17
      },
      "tags": [
        "ablation",
        "benchmark",
        "phi4:latest",
        "tpu_sketch_generator"
      ],
      "latency": 136.036,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-22-22-10-716414_chatcmpl-05e4cb60-b3c0-4094-93c5-c5bacf5e5c89",
          "traceId": "d969d458",
          "type": "GENERATION",
          "name": "d969_tpusg_gen_attempt#1",
          "startTime": "2025-12-10T20:22:10.716000+00:00",
          "endTime": "2025-12-10T20:22:33.031000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 22315.0,
          "totalTokens": 1493,
          "costDetails": {},
          "environment": "default",
          "promptTokens": 273,
          "completionTokens": 1220,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-22-22-40-754043_chatcmpl-72e2694a-9320-40ec-8af1-67b890469a91",
          "traceId": "d969d458",
          "type": "GENERATION",
          "name": "d969_tpusg_gen_attempt#2",
          "startTime": "2025-12-10T20:22:40.754000+00:00",
          "endTime": "2025-12-10T20:23:00.721000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 19967.0,
          "totalTokens": 1370,
          "costDetails": {},
          "environment": "default",
          "promptTokens": 273,
          "completionTokens": 1097,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-22-23-09-004041_chatcmpl-320f9b07-37af-4613-bcba-6fed997a5c00",
          "traceId": "d969d458",
          "type": "GENERATION",
          "name": "d969_tpusg_gen_attempt#3",
          "startTime": "2025-12-10T20:23:09.004000+00:00",
          "endTime": "2025-12-10T20:23:28.667000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 19663.0,
          "totalTokens": 1354,
          "costDetails": {},
          "environment": "default",
          "promptTokens": 273,
          "completionTokens": 1081,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-22-23-36-409932_chatcmpl-ebbd68f4-934d-450f-aff8-b8a2a2158e19",
          "traceId": "d969d458",
          "type": "GENERATION",
          "name": "d969_tpusg_gen_attempt#4",
          "startTime": "2025-12-10T20:23:36.409000+00:00",
          "endTime": "2025-12-10T20:23:50.878000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 14469.0,
          "totalTokens": 1072,
          "costDetails": {},
          "environment": "default",
          "promptTokens": 273,
          "completionTokens": 799,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-22-23-58-599274_chatcmpl-95c19eb7-94b7-425d-9ab0-24f279d0c19c",
          "traceId": "d969d458",
          "type": "GENERATION",
          "name": "d969_tpusg_gen_attempt#5",
          "startTime": "2025-12-10T20:23:58.599000+00:00",
          "endTime": "2025-12-10T20:24:18.430000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 19831.0,
          "totalTokens": 1362,
          "costDetails": {},
          "environment": "default",
          "promptTokens": 273,
          "completionTokens": 1089,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "b1da8bcf-c8d5-460e-91dc-f194ef01cb80",
          "traceId": "d969d458",
          "type": "SPAN",
          "name": "error_d9_tpusg_failure_signal_tpu_sketch_generator",
          "startTime": "2025-12-10T20:24:26.752000+00:00",
          "level": "ERROR",
          "statusMessage": "Failed: Max retries reached with error. Last error: Traceback (most recent call last):\n  File \"script_0daf6516_1765398258.py\", line 5, in <module>\n    from object_detection.protos.string_int_label_map_pb2 import StringIntLabelMap\nModuleNotFoundError: No module named 'object_detection'.",
          "calculatedTotalCost": 0.0,
          "totalTokens": 0,
          "costDetails": {},
          "environment": "default",
          "promptTokens": 0,
          "completionTokens": 0,
          "endTime": null,
          "model": null,
          "modelParameters": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null,
          "latency": null
        }
      ],
      "createdAt": "2025-12-10T20:22:11.231Z",
      "updatedAt": "2025-12-10T20:24:31.875Z",
      "environment": "default"
    },
    {
      "id": "62701bd0",
      "timestamp": "2025-12-10T20:19:49.521000+00:00",
      "name": "6270_tpu_sketch_generator",
      "input": null,
      "output": {
        "status": "failed",
        "last_code": "import cv2\nimport numpy as np\nimport tflite_runtime.interpreter as tflite\nfrom google.protobuf import text_format\nfrom object_detection.utils import label_map_util\nfrom object_detection.utils import visualization_utils as vis_util\n\n# Configuration parameters\nmodel_path  = \"/home/mendel/tinyml_autopilot/models/edgetpu_detect.tflite\"\nlabel_path  = \"/home/mendel/tinyml_autopilot/models/labelmap.txt\"\ninput_path  = \"/home/mendel/tinyml_autopilot/data//sheeps.mp4\"\noutput_path  = \"/home/mendel/tinyml_autopilot/results/sheeps_detections.mp4\"\nconfidence_threshold  = 0.5\n\n# Phase 1: Setup\ndef load_interpreter():\n    # Load the TFLite model and allocate tensors.\n    interpreter = tflite.Interpreter(\n        model_path=model_path,\n        experimental_delegates=[tflite.load_delegate('/usr/lib/aarch64-linux-gnu/libedgetpu.so.1.0')]\n    )\n    interpreter.allocate_tensors()\n    return interpreter\n\ndef load_labels(label_file):\n    # Load the labels from the label file\n    with open(label_file, 'r') as f:\n        lines = [line.strip() for line in f.readlines()]\n    return {i: line for i, line in enumerate(lines)}\n\n# Phase 2: Preprocessing\ndef preprocess_frame(frame, input_size):\n    # Resize and normalize frame to model's input size\n    frame_resized = cv2.resize(frame, input_size)\n    input_data = np.expand_dims(frame_resized, axis=0).astype(np.float32)\n    return input_data\n\n# Phase 3: Inference\ndef run_inference(interpreter, input_data):\n    # Get input and output tensors.\n    input_details = interpreter.get_input_details()\n    output_details = interpreter.get_output_details()\n\n    # Point the data to be used for testing and run inference.\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n    interpreter.invoke()\n\n    # Retrieve detection results\n    boxes = interpreter.get_tensor(output_details[0]['index'])[0]  # Bounding box coordinates of detected objects\n    classes = interpreter.get_tensor(output_details[1]['index'])[0].astype(np.int32)  # Class index of detected objects\n    scores = interpreter.get_tensor(output_details[2]['index'])[0]  # Confidence of detected objects\n\n    return boxes, classes, scores\n\n# Phase 4: Output handling\ndef compute_mAP(boxes, classes, scores, labels):\n    # Placeholder for mAP computation logic if needed\n    pass\n\ndef draw_detections(frame, boxes, classes, scores, category_index):\n    # Visualization of the results of a detection.\n    vis_util.visualize_boxes_and_labels_on_image_array(\n        frame,\n        boxes,\n        classes,\n        scores,\n        category_index,\n        use_normalized_coordinates=True,\n        line_thickness=8,\n        min_score_thresh=confidence_threshold\n    )\n\ndef process_video(input_path, output_path):\n    # Load the interpreter and labels\n    interpreter = load_interpreter()\n    label_map = load_labels(label_path)\n    category_index = label_map_util.create_category_index_from_labelmap(label_path, use_display_name=True)\n\n    # Get model input size\n    _, height, width, _ = interpreter.get_input_details()[0]['shape']\n    \n    cap = cv2.VideoCapture(input_path)\n    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n    out = cv2.VideoWriter(output_path, fourcc, 30.0, (width, height))\n\n    while cap.isOpened():\n        ret, frame = cap.read()\n        if not ret:\n            break\n\n        # Preprocess the frame\n        input_data = preprocess_frame(frame, (width, height))\n        \n        # Run inference\n        boxes, classes, scores = run_inference(interpreter, input_data)\n\n        # Draw detections on the frame\n        draw_detections(frame, boxes, classes, scores, category_index)\n\n        out.write(frame)\n\n    cap.release()\n    out.release()\n\n# Main execution\nif __name__ == '__main__':\n    process_video(input_path, output_path)",
        "last_error": "Max retries reached with error. Last error: Traceback (most recent call last):\n  File \"script_cd4822bc_1765398097.py\", line 5, in <module>\n    from object_detection.utils import label_map_util\nModuleNotFoundError: No module named 'object_detection'."
      },
      "session_id": "phi4_9e98_tpusg_batch",
      "metadata": {
        "num_run": 16
      },
      "tags": [
        "ablation",
        "benchmark",
        "phi4:latest",
        "tpu_sketch_generator"
      ],
      "latency": 115.909,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-22-19-49-523102_chatcmpl-b50fc423-8a62-4023-b83b-c65dc5c315bb",
          "traceId": "62701bd0",
          "type": "GENERATION",
          "name": "6270_tpusg_gen_attempt#1",
          "startTime": "2025-12-10T20:19:49.523000+00:00",
          "endTime": "2025-12-10T20:20:04.200000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 14677.0,
          "totalTokens": 1070,
          "costDetails": {},
          "environment": "default",
          "promptTokens": 273,
          "completionTokens": 797,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-22-20-11-910235_chatcmpl-152aa65f-db0f-4cfc-8ef7-87e1fb6bbc91",
          "traceId": "62701bd0",
          "type": "GENERATION",
          "name": "6270_tpusg_gen_attempt#2",
          "startTime": "2025-12-10T20:20:11.910000+00:00",
          "endTime": "2025-12-10T20:20:27.221000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 15311.0,
          "totalTokens": 1118,
          "costDetails": {},
          "environment": "default",
          "promptTokens": 273,
          "completionTokens": 845,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-22-20-35-597512_chatcmpl-789bf4ce-da5a-4c90-a23f-0f830e83c0ad",
          "traceId": "62701bd0",
          "type": "GENERATION",
          "name": "6270_tpusg_gen_attempt#3",
          "startTime": "2025-12-10T20:20:35.597000+00:00",
          "endTime": "2025-12-10T20:20:50.832000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 15235.0,
          "totalTokens": 1113,
          "costDetails": {},
          "environment": "default",
          "promptTokens": 273,
          "completionTokens": 840,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-22-20-58-783194_chatcmpl-b0982edb-e219-4418-8840-e270e6dbb9ef",
          "traceId": "62701bd0",
          "type": "GENERATION",
          "name": "6270_tpusg_gen_attempt#4",
          "startTime": "2025-12-10T20:20:58.783000+00:00",
          "endTime": "2025-12-10T20:21:12.351000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 13568.0,
          "totalTokens": 1022,
          "costDetails": {},
          "environment": "default",
          "promptTokens": 273,
          "completionTokens": 749,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-22-21-20-558855_chatcmpl-35179892-7b39-4e56-9917-165cc68bedff",
          "traceId": "62701bd0",
          "type": "GENERATION",
          "name": "6270_tpusg_gen_attempt#5",
          "startTime": "2025-12-10T20:21:20.558000+00:00",
          "endTime": "2025-12-10T20:21:37.198000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 16640.0,
          "totalTokens": 1190,
          "costDetails": {},
          "environment": "default",
          "promptTokens": 273,
          "completionTokens": 917,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "0543b97e-ff55-4daa-83e3-50ec3c6151c2",
          "traceId": "62701bd0",
          "type": "SPAN",
          "name": "error_62_tpusg_failure_signal_tpu_sketch_generator",
          "startTime": "2025-12-10T20:21:45.432000+00:00",
          "level": "ERROR",
          "statusMessage": "Failed: Max retries reached with error. Last error: Traceback (most recent call last):\n  File \"script_cd4822bc_1765398097.py\", line 5, in <module>\n    from object_detection.utils import label_map_util\nModuleNotFoundError: No module named 'object_detection'.",
          "calculatedTotalCost": 0.0,
          "totalTokens": 0,
          "costDetails": {},
          "environment": "default",
          "promptTokens": 0,
          "completionTokens": 0,
          "endTime": null,
          "model": null,
          "modelParameters": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null,
          "latency": null
        }
      ],
      "createdAt": "2025-12-10T20:19:50.041Z",
      "updatedAt": "2025-12-10T20:21:50.701Z",
      "environment": "default"
    },
    {
      "id": "2dc2cdca",
      "timestamp": "2025-12-10T20:17:31.560000+00:00",
      "name": "2dc2_tpu_sketch_generator",
      "input": null,
      "output": {
        "status": "failed",
        "last_code": "import cv2\nimport numpy as np\nfrom tflite_runtime.interpreter import Interpreter\nfrom tflite_runtime.interpreter import load_delegate\n\n# Configuration parameters\nmodel_path  = \"/home/mendel/tinyml_autopilot/models/edgetpu_detect.tflite\"\nlabel_path  = \"/home/mendel/tinyml_autopilot/models/labelmap.txt\"\ninput_path  = \"/home/mendel/tinyml_autopilot/data//sheeps.mp4\"\noutput_path  = \"/home/mendel/tinyml_autopilot/results/sheeps_detections.mp4\"\nconfidence_threshold  = 0.5\n\n# Load labels\nwith open(label_path, 'r') as f:\n    labels = [line.strip() for line in f.readlines()]\n\ndef load_model():\n    # Load the TFLite model and allocate tensors.\n    interpreter = Interpreter(\n        model_path=model_path,\n        experimental_delegates=[load_delegate('/usr/lib/aarch64-linux-gnu/libedgetpu.so.1.0')]\n    )\n    interpreter.allocate_tensors()\n    return interpreter\n\ndef preprocess_input(interpreter, frame):\n    # Get input size\n    _, height, width, _ = interpreter.get_input_details()[0]['shape']\n    \n    # Resize and normalize the image\n    frame_resized = cv2.resize(frame, (width, height))\n    input_data = np.expand_dims(frame_resized, axis=0).astype(np.float32)\n    input_data /= 255.0\n    \n    return input_data\n\ndef postprocess_output(interpreter, width, height):\n    # Get output details\n    boxes = interpreter.get_tensor(interpreter.get_output_details()[0]['index'])[0]  # Bounding box coordinates of detected objects\n    classes = interpreter.get_tensor(interpreter.get_output_details()[1]['index'])[0] + 1  # Class index of detected objects\n    scores = interpreter.get_tensor(interpreter.get_output_details()[2]['index'])[0]  # Confidence of detected objects\n    \n    results = []\n    \n    for i in range(len(scores)):\n        if scores[i] >= confidence_threshold:\n            ymin, xmin, ymax, xmax = boxes[i]\n            (left, right, top, bottom) = (xmin * width, xmax * width,\n                                          ymin * height, ymax * height)\n            results.append((int(left), int(right), int(top), int(bottom),\n                            scores[i], labels[int(classes[i] - 1)]))\n    \n    return results\n\ndef compute_map(detections):\n    # Placeholder for mAP computation logic\n    # This is a simplified placeholder. In practice, you would need to compare with ground truth annotations.\n    print(\"Mean Average Precision (mAP) computation not implemented.\")\n    return None\n\ndef draw_detections(frame, detections):\n    for left, right, top, bottom, score, label in detections:\n        cv2.rectangle(frame, (left, top), (right, bottom), (0, 255, 0), 2)\n        text = f'{label}: {score:.2f}'\n        cv2.putText(frame, text, (left, top - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n\ndef main():\n    # Setup\n    interpreter = load_model()\n    \n    # Open input video\n    cap = cv2.VideoCapture(input_path)\n    if not cap.isOpened():\n        print(\"Error opening video file\")\n        return\n    \n    # Get video properties\n    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n    \n    # Define the codec and create VideoWriter object\n    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n    out = cv2.VideoWriter(output_path, fourcc, 20.0, (width, height))\n    \n    while cap.isOpened():\n        ret, frame = cap.read()\n        if not ret:\n            break\n        \n        # Preprocessing\n        input_data = preprocess_input(interpreter, frame)\n        \n        # Inference\n        interpreter.set_tensor(interpreter.get_input_details()[0]['index'], input_data)\n        interpreter.invoke()\n        \n        # Postprocessing\n        detections = postprocess_output(interpreter, width, height)\n        \n        # Draw detections\n        draw_detections(frame, detections)\n        \n        # Write the frame with detections\n        out.write(frame)\n    \n    # Release everything if job is finished\n    cap.release()\n    out.release()\n    \n    # Compute mAP (placeholder)\n    compute_map(detections)\n\nif __name__ == \"__main__\":\n    main()",
        "last_error": "Max retries reached with error. Last error: Traceback (most recent call last):\n  File \"script_2a2e3282_1765397956.py\", line 114, in <module>\n    main()\n  File \"script_2a2e3282_1765397956.py\", line 94, in main\n    interpreter.set_tensor(interpreter.get_input_details()[0]['index'], input_data)\n  File \"/home/mendel/tinyml_autopilot/tinyml-env/lib/python3.7/site-packages/tflite_runtime/interpreter.py\", line 572, in set_tensor\n    self._interpreter.SetTensor(tensor_index, value)\nValueError: Cannot set tensor: Got value of type FLOAT32 but expected type UINT8 for input 175, name: normalized_input_image_tensor ."
      },
      "session_id": "phi4_9e98_tpusg_batch",
      "metadata": {
        "num_run": 15
      },
      "tags": [
        "ablation",
        "benchmark",
        "phi4:latest",
        "tpu_sketch_generator"
      ],
      "latency": 112.957,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-22-17-31-562061_chatcmpl-9c0c2b06-dab7-4a7f-8d92-2cbf9fac45cd",
          "traceId": "2dc2cdca",
          "type": "GENERATION",
          "name": "2dc2_tpusg_gen_attempt#1",
          "startTime": "2025-12-10T20:17:31.562000+00:00",
          "endTime": "2025-12-10T20:17:46.243000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 14681.0,
          "totalTokens": 1080,
          "costDetails": {},
          "environment": "default",
          "promptTokens": 273,
          "completionTokens": 807,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-22-17-54-448645_chatcmpl-4740bc84-936a-49cf-985d-c1bb4fa20107",
          "traceId": "2dc2cdca",
          "type": "GENERATION",
          "name": "2dc2_tpusg_gen_attempt#2",
          "startTime": "2025-12-10T20:17:54.448000+00:00",
          "endTime": "2025-12-10T20:18:09.113000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 14665.0,
          "totalTokens": 1082,
          "costDetails": {},
          "environment": "default",
          "promptTokens": 273,
          "completionTokens": 809,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-22-18-17-238485_chatcmpl-b81b2b44-610e-4c70-b8d3-e0cbb670bee6",
          "traceId": "2dc2cdca",
          "type": "GENERATION",
          "name": "2dc2_tpusg_gen_attempt#3",
          "startTime": "2025-12-10T20:18:17.238000+00:00",
          "endTime": "2025-12-10T20:18:33.816000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 16578.0,
          "totalTokens": 1187,
          "costDetails": {},
          "environment": "default",
          "promptTokens": 273,
          "completionTokens": 914,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-22-18-42-045250_chatcmpl-a9562e87-ae99-4bb3-b027-e72dea16c914",
          "traceId": "2dc2cdca",
          "type": "GENERATION",
          "name": "2dc2_tpusg_gen_attempt#4",
          "startTime": "2025-12-10T20:18:42.045000+00:00",
          "endTime": "2025-12-10T20:18:55.266000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 13221.0,
          "totalTokens": 1003,
          "costDetails": {},
          "environment": "default",
          "promptTokens": 273,
          "completionTokens": 730,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-22-18-59-287708_chatcmpl-55fd81ff-13d0-4a1a-a4ef-c831a2c068fd",
          "traceId": "2dc2cdca",
          "type": "GENERATION",
          "name": "2dc2_tpusg_gen_attempt#5",
          "startTime": "2025-12-10T20:18:59.287000+00:00",
          "endTime": "2025-12-10T20:19:16.286000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 16999.0,
          "totalTokens": 1210,
          "costDetails": {},
          "environment": "default",
          "promptTokens": 273,
          "completionTokens": 937,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "4b4d5dc2-999a-4391-b7b8-ce4423d6c9bb",
          "traceId": "2dc2cdca",
          "type": "SPAN",
          "name": "error_2d_tpusg_failure_signal_tpu_sketch_generator",
          "startTime": "2025-12-10T20:19:24.519000+00:00",
          "level": "ERROR",
          "statusMessage": "Failed: Max retries reached with error. Last error: Traceback (most recent call last):\n  File \"script_2a2e3282_1765397956.py\", line 114, in <module>\n    main()\n  File \"script_2a2e3282_1765397956.py\", line 94, in main\n    interpreter.set_tensor(interpreter.get_input_details()[0]['index'], input_data)\n  File \"/home/mendel/tinyml_autopilot/tinyml-env/lib/python3.7/site-packages/tflite_runtime/interpreter.py\", line 572, in set_tensor\n    self._interpreter.SetTensor(tensor_index, value)\nValueError: Cannot set tensor: Got value of type FLOAT32 but expected type UINT8 for input 175, name: normalized_input_image_tensor .",
          "calculatedTotalCost": 0.0,
          "totalTokens": 0,
          "costDetails": {},
          "environment": "default",
          "promptTokens": 0,
          "completionTokens": 0,
          "endTime": null,
          "model": null,
          "modelParameters": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null,
          "latency": null
        }
      ],
      "createdAt": "2025-12-10T20:17:32.080Z",
      "updatedAt": "2025-12-10T20:19:29.798Z",
      "environment": "default"
    },
    {
      "id": "33661b32",
      "timestamp": "2025-12-10T20:15:03.578000+00:00",
      "name": "3366_tpu_sketch_generator",
      "input": null,
      "output": {
        "status": "failed",
        "last_code": "import cv2\nimport numpy as np\nimport tensorflow as tf\nfrom google.protobuf import text_format\nfrom object_detection.utils import label_map_util\nfrom object_detection.metrics import coco_evaluation\n\n# Configuration parameters\nmodel_path  = \"/home/mendel/tinyml_autopilot/models/edgetpu_detect.tflite\"\nlabel_path  = \"/home/mendel/tinyml_autopilot/models/labelmap.txt\"\ninput_path  = \"/home/mendel/tinyml_autopilot/data//sheeps.mp4\"\noutput_path  = \"/home/mendel/tinyml_autopilot/results/sheeps_detections.mp4\"\nconfidence_threshold  = 0.5\n\n# Phase 1: Setup - Load the TFLite interpreter for TPU\ninterpreter = tf.lite.Interpreter(\n    model_path=model_path,\n    experimental_delegates=[\n        tf.lite.experimental.load_delegate('/usr/lib/aarch64-linux-gnu/libedgetpu.so.1.0')\n    ]\n)\ninterpreter.allocate_tensors()\n\n# Get input and output tensors.\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\n\ninput_shape = input_details[0]['shape']\n\n# Phase 2: Preprocessing - Load labels\ncategory_index = label_map_util.create_category_index_from_labelmap(label_path, use_display_name=True)\n\n# Helper function to load video frames\ndef load_video_frames(video_path):\n    cap = cv2.VideoCapture(video_path)\n    frames = []\n    while True:\n        ret, frame = cap.read()\n        if not ret:\n            break\n        frames.append(frame)\n    cap.release()\n    return frames\n\n# Phase 3: Inference - Process and run inference\ndef preprocess_frame(frame):\n    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n    input_data = cv2.resize(frame_rgb, (input_shape[1], input_shape[2]))\n    input_data = np.expand_dims(input_data, axis=0)\n    return input_data\n\ndef run_inference(interpreter, input_data):\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n    interpreter.invoke()\n    boxes = interpreter.get_tensor(output_details[0]['index'])[0]\n    classes = interpreter.get_tensor(output_details[1]['index'])[0]\n    scores = interpreter.get_tensor(output_details[2]['index'])[0]\n    return boxes, classes, scores\n\ndef filter_detections(boxes, classes, scores, threshold):\n    valid_indices = np.where(scores >= threshold)[0]\n    filtered_boxes = boxes[valid_indices]\n    filtered_classes = classes[valid_indices].astype(np.int32)\n    filtered_scores = scores[valid_indices]\n    return filtered_boxes, filtered_classes, filtered_scores\n\n# Phase 4: Output handling - Draw detection boxes with labels and output to specified path\ndef draw_detections(frame, boxes, classes, scores):\n    for i in range(len(scores)):\n        if scores[i] < confidence_threshold:\n            continue\n        box = tuple(boxes[i].tolist())\n        class_id = int(classes[i])\n        display_str = f'{category_index[class_id][\"name\"]}: {int(100 * scores[i])}%'\n        \n        # Draw bounding box and label on the frame\n        cv2.rectangle(frame, (box[1], box[0]), (box[3], box[2]), (10, 255, 0), 2)\n        cv2.putText(frame, display_str, (box[1], box[0] - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)\n\ndef compute_mAP(ground_truths, detections):\n    # Placeholder for mAP computation logic\n    pass\n\n# Main processing loop\nframes = load_video_frames(input_path)\noutput_frames = []\n\nfor frame in frames:\n    input_data = preprocess_frame(frame)\n    boxes, classes, scores = run_inference(interpreter, input_data)\n    filtered_boxes, filtered_classes, filtered_scores = filter_detections(boxes, classes, scores, confidence_threshold)\n    draw_detections(frame, filtered_boxes, filtered_classes, filtered_scores)\n    output_frames.append(frame)\n\n# Save the video with detections\nfourcc = cv2.VideoWriter_fourcc(*'mp4v')\nout = cv2.VideoWriter(output_path, fourcc, 20.0, (frames[0].shape[1], frames[0].shape[0]))\n\nfor frame in output_frames:\n    out.write(frame)\n\nout.release()\n\n# Compute mAP (placeholder logic)\ncompute_mAP(None, None)  # Replace with actual ground truth and detection data",
        "last_error": "Max retries reached with error. Last error: Traceback (most recent call last):\n  File \"script_66831fe4_1765397817.py\", line 3, in <module>\n    import tensorflow as tf\nModuleNotFoundError: No module named 'tensorflow'."
      },
      "session_id": "phi4_9e98_tpusg_batch",
      "metadata": {
        "num_run": 14
      },
      "tags": [
        "ablation",
        "benchmark",
        "phi4:latest",
        "tpu_sketch_generator"
      ],
      "latency": 122.145,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-22-15-03-579469_chatcmpl-59f09495-c713-433d-913d-c939a679d84b",
          "traceId": "33661b32",
          "type": "GENERATION",
          "name": "3366_tpusg_gen_attempt#1",
          "startTime": "2025-12-10T20:15:03.579000+00:00",
          "endTime": "2025-12-10T20:15:18.919000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 15340.0,
          "totalTokens": 1115,
          "costDetails": {},
          "environment": "default",
          "promptTokens": 273,
          "completionTokens": 842,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-22-15-26-628117_chatcmpl-d844a864-f942-4a88-b1b7-1395d6a3c6be",
          "traceId": "33661b32",
          "type": "GENERATION",
          "name": "3366_tpusg_gen_attempt#2",
          "startTime": "2025-12-10T20:15:26.628000+00:00",
          "endTime": "2025-12-10T20:15:42.032000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 15404.0,
          "totalTokens": 1123,
          "costDetails": {},
          "environment": "default",
          "promptTokens": 273,
          "completionTokens": 850,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-22-15-49-905533_chatcmpl-7bf69017-a97a-4624-9f5a-ee0df4ef8430",
          "traceId": "33661b32",
          "type": "GENERATION",
          "name": "3366_tpusg_gen_attempt#3",
          "startTime": "2025-12-10T20:15:49.905000+00:00",
          "endTime": "2025-12-10T20:16:06.222000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 16317.0,
          "totalTokens": 1173,
          "costDetails": {},
          "environment": "default",
          "promptTokens": 273,
          "completionTokens": 900,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-22-16-14-047689_chatcmpl-4925c911-30a6-42c9-93b2-3c494b782b87",
          "traceId": "33661b32",
          "type": "GENERATION",
          "name": "3366_tpusg_gen_attempt#4",
          "startTime": "2025-12-10T20:16:14.047000+00:00",
          "endTime": "2025-12-10T20:16:30.946000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 16899.0,
          "totalTokens": 1204,
          "costDetails": {},
          "environment": "default",
          "promptTokens": 273,
          "completionTokens": 931,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-22-16-39-998026_chatcmpl-717912a9-4e0e-474a-af82-34b02b4d3f81",
          "traceId": "33661b32",
          "type": "GENERATION",
          "name": "3366_tpusg_gen_attempt#5",
          "startTime": "2025-12-10T20:16:39.998000+00:00",
          "endTime": "2025-12-10T20:16:57.905000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 17907.0,
          "totalTokens": 1259,
          "costDetails": {},
          "environment": "default",
          "promptTokens": 273,
          "completionTokens": 986,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "367386cc-9cbb-4aa0-931e-2b295705067c",
          "traceId": "33661b32",
          "type": "SPAN",
          "name": "error_33_tpusg_failure_signal_tpu_sketch_generator",
          "startTime": "2025-12-10T20:17:05.724000+00:00",
          "level": "ERROR",
          "statusMessage": "Failed: Max retries reached with error. Last error: Traceback (most recent call last):\n  File \"script_66831fe4_1765397817.py\", line 3, in <module>\n    import tensorflow as tf\nModuleNotFoundError: No module named 'tensorflow'.",
          "calculatedTotalCost": 0.0,
          "totalTokens": 0,
          "costDetails": {},
          "environment": "default",
          "promptTokens": 0,
          "completionTokens": 0,
          "endTime": null,
          "model": null,
          "modelParameters": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null,
          "latency": null
        }
      ],
      "createdAt": "2025-12-10T20:15:04.096Z",
      "updatedAt": "2025-12-10T20:17:11.290Z",
      "environment": "default"
    },
    {
      "id": "be5aa2df",
      "timestamp": "2025-12-10T20:10:41.617000+00:00",
      "name": "be5a_tpu_sketch_generator",
      "input": null,
      "output": {
        "status": "success",
        "sketch": "import cv2\nimport numpy as np\nfrom tflite_runtime.interpreter import Interpreter\nfrom tflite_runtime.interpreter import load_delegate\n\n# Configuration parameters\nmodel_path  = \"/home/mendel/tinyml_autopilot/models/edgetpu_detect.tflite\"\nlabel_path  = \"/home/mendel/tinyml_autopilot/models/labelmap.txt\"\ninput_path  = \"/home/mendel/tinyml_autopilot/data//sheeps.mp4\"\noutput_path  = \"/home/mendel/tinyml_autopilot/results/sheeps_detections.mp4\"\nconfidence_threshold  = 0.5\n\n# Load labels\nwith open(label_path, 'r') as f:\n    labels = [line.strip() for line in f.readlines()]\n\n# Phase 1: Setup - Load the TFLite interpreter for TPU\ninterpreter = Interpreter(\n    model_path=model_path,\n    experimental_delegates=[load_delegate('/usr/lib/aarch64-linux-gnu/libedgetpu.so.1.0')]\n)\ninterpreter.allocate_tensors()\n\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\n\n# Phase 2: Preprocessing - Read input video\ncap = cv2.VideoCapture(input_path)\nfourcc = cv2.VideoWriter_fourcc(*'mp4v')\nout = cv2.VideoWriter(output_path, fourcc, 30.0, (int(cap.get(3)), int(cap.get(4))))\n\ndef preprocess_frame(frame):\n    input_shape = input_details[0]['shape']\n    frame_resized = cv2.resize(frame, (input_shape[1], input_shape[2]))\n    input_data = np.expand_dims(frame_resized, axis=0)\n    return input_data\n\n# Phase 3: Inference\ndef run_inference(input_data):\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n    interpreter.invoke()\n    boxes = interpreter.get_tensor(output_details[0]['index'])[0] # Bounding box coordinates of detected objects\n    classes = interpreter.get_tensor(output_details[1]['index'])[0] # Class index of detected objects\n    scores = interpreter.get_tensor(output_details[2]['index'])[0] # Confidence of detected objects\n\n    return boxes, classes, scores\n\n# Phase 4: Output handling - Compute mAP, draw detection boxes with labels, and output to specified path\ndef compute_ap():\n    # Placeholder function for computing mean Average Precision (mAP)\n    # Implement this based on your specific requirements\n    pass\n\nwhile cap.isOpened():\n    ret, frame = cap.read()\n    if not ret:\n        break\n    \n    input_data = preprocess_frame(frame)\n    boxes, classes, scores = run_inference(input_data)\n\n    for i in range(len(scores)):\n        if scores[i] > confidence_threshold:\n            ymin, xmin, ymax, xmax = boxes[i]\n            (left, right, top, bottom) = (xmin * frame.shape[1], xmax * frame.shape[1],\n                                          ymin * frame.shape[0], ymax * frame.shape[0])\n            \n            cv2.rectangle(frame, (int(left), int(top)), (int(right), int(bottom)),\n                          (10, 255, 0), 2)\n\n            label = f'{labels[int(classes[i])]}: {int(scores[i]*100)}%'\n            label_size, base_line = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.7, 2)\n            top = max(top, label_size[1])\n            cv2.rectangle(frame, (int(left), int(top - label_size[1])), \n                          (int(left + label_size[0]), int(top + base_line)), \n                          (255, 255, 255), cv2.FILLED)\n            cv2.putText(frame, label, (int(left), int(top)), \n                        cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 0), 2)\n\n    out.write(frame)\n\ncap.release()\nout.release()\ncv2.destroyAllWindows()\n\ncompute_ap()  # Call this function with appropriate implementation"
      },
      "session_id": "phi4_9e98_tpusg_batch",
      "metadata": {
        "num_run": 13
      },
      "tags": [
        "ablation",
        "benchmark",
        "phi4:latest",
        "tpu_sketch_generator"
      ],
      "latency": 185.13,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-22-10-41-618538_chatcmpl-43a128d2-e9fa-49c9-8498-de9bb4a0e0d3",
          "traceId": "be5aa2df",
          "type": "GENERATION",
          "name": "be5a_tpusg_gen_attempt#1",
          "startTime": "2025-12-10T20:10:41.618000+00:00",
          "endTime": "2025-12-10T20:12:32.964000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 111346.0,
          "totalTokens": 1069,
          "costDetails": {},
          "environment": "default",
          "promptTokens": 273,
          "completionTokens": 796,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-22-12-41-279725_chatcmpl-036c7bb9-61df-49f2-aa29-b20e7229bab1",
          "traceId": "be5aa2df",
          "type": "GENERATION",
          "name": "be5a_tpusg_gen_attempt#2",
          "startTime": "2025-12-10T20:12:41.279000+00:00",
          "endTime": "2025-12-10T20:12:59.750000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 18471.0,
          "totalTokens": 1289,
          "costDetails": {},
          "environment": "default",
          "promptTokens": 273,
          "completionTokens": 1016,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-22-13-07-488125_chatcmpl-b9cc456a-9c1a-470d-b28d-4c7c3885fab2",
          "traceId": "be5aa2df",
          "type": "GENERATION",
          "name": "be5a_tpusg_gen_attempt#3",
          "startTime": "2025-12-10T20:13:07.488000+00:00",
          "endTime": "2025-12-10T20:13:23.963000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 16475.0,
          "totalTokens": 1182,
          "costDetails": {},
          "environment": "default",
          "promptTokens": 273,
          "completionTokens": 909,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-22-13-31-862490_chatcmpl-12050b69-016d-4b03-b674-1e71c8143f1a",
          "traceId": "be5aa2df",
          "type": "GENERATION",
          "name": "be5a_tpusg_gen_attempt#4",
          "startTime": "2025-12-10T20:13:31.862000+00:00",
          "endTime": "2025-12-10T20:13:46.748000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 14886.0,
          "totalTokens": 1094,
          "costDetails": {},
          "environment": "default",
          "promptTokens": 273,
          "completionTokens": 821,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        }
      ],
      "createdAt": "2025-12-10T20:10:42.136Z",
      "updatedAt": "2025-12-10T20:14:44.957Z",
      "environment": "default"
    },
    {
      "id": "01e1853b",
      "timestamp": "2025-12-10T20:10:15.658000+00:00",
      "name": "01e1_tpu_sketch_generator",
      "input": null,
      "output": {
        "status": "failed",
        "last_code": "",
        "last_error": "[FATAL]: CUDA error detected: litellm.APIConnectionError: OllamaException - {\"error\":\"llama runner process has terminated: CUDA error\"}"
      },
      "session_id": "phi4_9e98_tpusg_batch",
      "metadata": {
        "num_run": 12
      },
      "tags": [
        "ablation",
        "benchmark",
        "phi4:latest",
        "tpu_sketch_generator"
      ],
      "latency": 0.0,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "f3dc88cb-9687-4c49-b4cd-03d0a3a76014",
          "traceId": "01e1853b",
          "type": "SPAN",
          "name": "error_01_tpusg_failure_signal_tpu_sketch_generator",
          "startTime": "2025-12-10T20:10:16.171000+00:00",
          "level": "ERROR",
          "statusMessage": "Failed: [FATAL]: CUDA error detected: litellm.APIConnectionError: OllamaException - {\"error\":\"llama runner process has terminated: CUDA error\"}",
          "calculatedTotalCost": 0.0,
          "totalTokens": 0,
          "costDetails": {},
          "environment": "default",
          "promptTokens": 0,
          "completionTokens": 0,
          "endTime": null,
          "model": null,
          "modelParameters": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null,
          "latency": null
        }
      ],
      "createdAt": "2025-12-10T20:10:16.693Z",
      "updatedAt": "2025-12-10T20:10:21.714Z",
      "environment": "default"
    },
    {
      "id": "e23c5a83",
      "timestamp": "2025-12-10T20:09:49.748000+00:00",
      "name": "e23c_tpu_sketch_generator",
      "input": null,
      "output": {
        "status": "failed",
        "last_code": "",
        "last_error": "[FATAL]: CUDA error detected: litellm.APIConnectionError: OllamaException - {\"error\":\"llama runner process has terminated: CUDA error\"}"
      },
      "session_id": "phi4_9e98_tpusg_batch",
      "metadata": {
        "num_run": 11
      },
      "tags": [
        "ablation",
        "benchmark",
        "phi4:latest",
        "tpu_sketch_generator"
      ],
      "latency": 0.0,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "0bdde9f3-1a05-4a8b-b099-88bfee66343b",
          "traceId": "e23c5a83",
          "type": "SPAN",
          "name": "error_e2_tpusg_failure_signal_tpu_sketch_generator",
          "startTime": "2025-12-10T20:09:50.270000+00:00",
          "level": "ERROR",
          "statusMessage": "Failed: [FATAL]: CUDA error detected: litellm.APIConnectionError: OllamaException - {\"error\":\"llama runner process has terminated: CUDA error\"}",
          "calculatedTotalCost": 0.0,
          "totalTokens": 0,
          "costDetails": {},
          "environment": "default",
          "promptTokens": 0,
          "completionTokens": 0,
          "endTime": null,
          "model": null,
          "modelParameters": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null,
          "latency": null
        }
      ],
      "createdAt": "2025-12-10T20:09:50.785Z",
      "updatedAt": "2025-12-10T20:09:55.821Z",
      "environment": "default"
    },
    {
      "id": "78d88875",
      "timestamp": "2025-12-10T20:09:22.846000+00:00",
      "name": "78d8_tpu_sketch_generator",
      "input": null,
      "output": {
        "status": "failed",
        "last_code": "",
        "last_error": "[FATAL]: CUDA error detected: litellm.APIConnectionError: OllamaException - {\"error\":\"llama runner process has terminated: CUDA error\"}"
      },
      "session_id": "phi4_9e98_tpusg_batch",
      "metadata": {
        "num_run": 10
      },
      "tags": [
        "ablation",
        "benchmark",
        "phi4:latest",
        "tpu_sketch_generator"
      ],
      "latency": 0.0,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "52607c1b-677a-4ba0-ba86-0c73f58e8b6a",
          "traceId": "78d88875",
          "type": "SPAN",
          "name": "error_78_tpusg_failure_signal_tpu_sketch_generator",
          "startTime": "2025-12-10T20:09:23.398000+00:00",
          "level": "ERROR",
          "statusMessage": "Failed: [FATAL]: CUDA error detected: litellm.APIConnectionError: OllamaException - {\"error\":\"llama runner process has terminated: CUDA error\"}",
          "calculatedTotalCost": 0.0,
          "totalTokens": 0,
          "costDetails": {},
          "environment": "default",
          "promptTokens": 0,
          "completionTokens": 0,
          "endTime": null,
          "model": null,
          "modelParameters": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null,
          "latency": null
        }
      ],
      "createdAt": "2025-12-10T20:09:23.364Z",
      "updatedAt": "2025-12-10T20:09:28.917Z",
      "environment": "default"
    },
    {
      "id": "dfb59888",
      "timestamp": "2025-12-10T20:08:56.929000+00:00",
      "name": "dfb5_tpu_sketch_generator",
      "input": null,
      "output": {
        "status": "failed",
        "last_code": "",
        "last_error": "[FATAL]: CUDA error detected: litellm.APIConnectionError: OllamaException - {\"error\":\"llama runner process has terminated: CUDA error: all CUDA-capable devices are busy or unavailable\\ntime=2025-12-10T22:08:57.439+02:00 level=INFO source=runner.go:991 msg=\\\"Server listening on 127.0.0.1:43541\\\"\\n  current device: 0, in function ggml_backend_cuda_device_get_memory at //ml/backend/ggml/ggml/src/ggml-cuda/ggml-cuda.cu:2898\\n  cudaMemGetInfo(free, total)\\n//ml/backend/ggml/ggml/src/ggml-cuda/ggml-cuda.cu:73: CUDA error\"}"
      },
      "session_id": "phi4_9e98_tpusg_batch",
      "metadata": {
        "num_run": 9
      },
      "tags": [
        "ablation",
        "benchmark",
        "phi4:latest",
        "tpu_sketch_generator"
      ],
      "latency": 0.0,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "6027941e-c825-4e76-b221-0439497344f9",
          "traceId": "dfb59888",
          "type": "SPAN",
          "name": "error_df_tpusg_failure_signal_tpu_sketch_generator",
          "startTime": "2025-12-10T20:08:57.625000+00:00",
          "level": "ERROR",
          "statusMessage": "Failed: [FATAL]: CUDA error detected: litellm.APIConnectionError: OllamaException - {\"error\":\"llama runner process has terminated: CUDA error: all CUDA-capable devices are busy or unavailable\\ntime=2025-12-10T22:08:57.439+02:00 level=INFO source=runner.go:991 msg=\\\"Server listening on 127.0.0.1:43541\\\"\\n  current device: 0, in function ggml_backend_cuda_device_get_memory at //ml/backend/ggml/ggml/src/ggml-cuda/ggml-cuda.cu:2898\\n  cudaMemGetInfo(free, total)\\n//ml/backend/ggml/ggml/src/ggml-cuda/ggml-cuda.cu:73: CUDA error\"}",
          "calculatedTotalCost": 0.0,
          "totalTokens": 0,
          "costDetails": {},
          "environment": "default",
          "promptTokens": 0,
          "completionTokens": 0,
          "endTime": null,
          "model": null,
          "modelParameters": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null,
          "latency": null
        }
      ],
      "createdAt": "2025-12-10T20:08:57.447Z",
      "updatedAt": "2025-12-10T20:09:03.021Z",
      "environment": "default"
    },
    {
      "id": "fe6bc145",
      "timestamp": "2025-12-10T20:08:30.021000+00:00",
      "name": "fe6b_tpu_sketch_generator",
      "input": null,
      "output": {
        "status": "failed",
        "last_code": "",
        "last_error": "[FATAL]: CUDA error detected: litellm.APIConnectionError: OllamaException - {\"error\":\"llama runner process has terminated: CUDA error\"}"
      },
      "session_id": "phi4_9e98_tpusg_batch",
      "metadata": {
        "num_run": 8
      },
      "tags": [
        "ablation",
        "benchmark",
        "phi4:latest",
        "tpu_sketch_generator"
      ],
      "latency": 0.0,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "411143d5-815c-4ecd-8114-615a00f55324",
          "traceId": "fe6bc145",
          "type": "SPAN",
          "name": "error_fe_tpusg_failure_signal_tpu_sketch_generator",
          "startTime": "2025-12-10T20:08:30.529000+00:00",
          "level": "ERROR",
          "statusMessage": "Failed: [FATAL]: CUDA error detected: litellm.APIConnectionError: OllamaException - {\"error\":\"llama runner process has terminated: CUDA error\"}",
          "calculatedTotalCost": 0.0,
          "totalTokens": 0,
          "costDetails": {},
          "environment": "default",
          "promptTokens": 0,
          "completionTokens": 0,
          "endTime": null,
          "model": null,
          "modelParameters": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null,
          "latency": null
        }
      ],
      "createdAt": "2025-12-10T20:08:30.540Z",
      "updatedAt": "2025-12-10T20:08:36.126Z",
      "environment": "default"
    },
    {
      "id": "969884de",
      "timestamp": "2025-12-10T20:08:04.131000+00:00",
      "name": "9698_tpu_sketch_generator",
      "input": null,
      "output": {
        "status": "failed",
        "last_code": "",
        "last_error": "[FATAL]: CUDA error detected: litellm.APIConnectionError: OllamaException - {\"error\":\"llama runner process has terminated: CUDA error\"}"
      },
      "session_id": "phi4_9e98_tpusg_batch",
      "metadata": {
        "num_run": 7
      },
      "tags": [
        "ablation",
        "benchmark",
        "phi4:latest",
        "tpu_sketch_generator"
      ],
      "latency": 0.0,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "d59bfe5e-98e1-456e-9f06-4b1f214e0e3e",
          "traceId": "969884de",
          "type": "SPAN",
          "name": "error_96_tpusg_failure_signal_tpu_sketch_generator",
          "startTime": "2025-12-10T20:08:04.659000+00:00",
          "level": "ERROR",
          "statusMessage": "Failed: [FATAL]: CUDA error detected: litellm.APIConnectionError: OllamaException - {\"error\":\"llama runner process has terminated: CUDA error\"}",
          "calculatedTotalCost": 0.0,
          "totalTokens": 0,
          "costDetails": {},
          "environment": "default",
          "promptTokens": 0,
          "completionTokens": 0,
          "endTime": null,
          "model": null,
          "modelParameters": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null,
          "latency": null
        }
      ],
      "createdAt": "2025-12-10T20:08:04.650Z",
      "updatedAt": "2025-12-10T20:08:10.230Z",
      "environment": "default"
    },
    {
      "id": "5fd8dfd2",
      "timestamp": "2025-12-10T20:07:38.195000+00:00",
      "name": "5fd8_tpu_sketch_generator",
      "input": null,
      "output": {
        "status": "failed",
        "last_code": "",
        "last_error": "[FATAL]: CUDA error detected: litellm.APIConnectionError: OllamaException - {\"error\":\"llama runner process has terminated: CUDA error\"}"
      },
      "session_id": "phi4_9e98_tpusg_batch",
      "metadata": {
        "num_run": 6
      },
      "tags": [
        "ablation",
        "benchmark",
        "phi4:latest",
        "tpu_sketch_generator"
      ],
      "latency": 0.0,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "f82cffb7-1b5c-4d08-8c24-e867a6b99826",
          "traceId": "5fd8dfd2",
          "type": "SPAN",
          "name": "error_5f_tpusg_failure_signal_tpu_sketch_generator",
          "startTime": "2025-12-10T20:07:38.727000+00:00",
          "level": "ERROR",
          "statusMessage": "Failed: [FATAL]: CUDA error detected: litellm.APIConnectionError: OllamaException - {\"error\":\"llama runner process has terminated: CUDA error\"}",
          "calculatedTotalCost": 0.0,
          "totalTokens": 0,
          "costDetails": {},
          "environment": "default",
          "promptTokens": 0,
          "completionTokens": 0,
          "endTime": null,
          "model": null,
          "modelParameters": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null,
          "latency": null
        }
      ],
      "createdAt": "2025-12-10T20:07:38.713Z",
      "updatedAt": "2025-12-10T20:07:44.333Z",
      "environment": "default"
    },
    {
      "id": "1dcdad5b",
      "timestamp": "2025-12-10T20:07:12.264000+00:00",
      "name": "1dcd_tpu_sketch_generator",
      "input": null,
      "output": {
        "status": "failed",
        "last_code": "",
        "last_error": "[FATAL]: CUDA error detected: litellm.APIConnectionError: OllamaException - {\"error\":\"llama runner process has terminated: CUDA error\"}"
      },
      "session_id": "phi4_9e98_tpusg_batch",
      "metadata": {
        "num_run": 5
      },
      "tags": [
        "ablation",
        "benchmark",
        "phi4:latest",
        "tpu_sketch_generator"
      ],
      "latency": 0.0,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "08eaf1b8-1673-413c-a49d-307a746c8e4e",
          "traceId": "1dcdad5b",
          "type": "SPAN",
          "name": "error_1d_tpusg_failure_signal_tpu_sketch_generator",
          "startTime": "2025-12-10T20:07:12.806000+00:00",
          "level": "ERROR",
          "statusMessage": "Failed: [FATAL]: CUDA error detected: litellm.APIConnectionError: OllamaException - {\"error\":\"llama runner process has terminated: CUDA error\"}",
          "calculatedTotalCost": 0.0,
          "totalTokens": 0,
          "costDetails": {},
          "environment": "default",
          "promptTokens": 0,
          "completionTokens": 0,
          "endTime": null,
          "model": null,
          "modelParameters": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null,
          "latency": null
        }
      ],
      "createdAt": "2025-12-10T20:07:12.780Z",
      "updatedAt": "2025-12-10T20:07:18.341Z",
      "environment": "default"
    },
    {
      "id": "887c7d50",
      "timestamp": "2025-12-10T20:06:46.329000+00:00",
      "name": "887c_tpu_sketch_generator",
      "input": null,
      "output": {
        "status": "failed",
        "last_code": "",
        "last_error": "[FATAL]: CUDA error detected: litellm.APIConnectionError: OllamaException - {\"error\":\"llama runner process has terminated: CUDA error\"}"
      },
      "session_id": "phi4_9e98_tpusg_batch",
      "metadata": {
        "num_run": 4
      },
      "tags": [
        "ablation",
        "benchmark",
        "phi4:latest",
        "tpu_sketch_generator"
      ],
      "latency": 0.0,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "bdc3dd3e-9551-46a7-aaa2-fef77e63fbb2",
          "traceId": "887c7d50",
          "type": "SPAN",
          "name": "error_88_tpusg_failure_signal_tpu_sketch_generator",
          "startTime": "2025-12-10T20:06:46.838000+00:00",
          "level": "ERROR",
          "statusMessage": "Failed: [FATAL]: CUDA error detected: litellm.APIConnectionError: OllamaException - {\"error\":\"llama runner process has terminated: CUDA error\"}",
          "calculatedTotalCost": 0.0,
          "totalTokens": 0,
          "costDetails": {},
          "environment": "default",
          "promptTokens": 0,
          "completionTokens": 0,
          "endTime": null,
          "model": null,
          "modelParameters": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null,
          "latency": null
        }
      ],
      "createdAt": "2025-12-10T20:06:46.847Z",
      "updatedAt": "2025-12-10T20:06:52.447Z",
      "environment": "default"
    },
    {
      "id": "7a7d5b84",
      "timestamp": "2025-12-10T20:06:19.388000+00:00",
      "name": "7a7d_tpu_sketch_generator",
      "input": null,
      "output": {
        "status": "failed",
        "last_code": "",
        "last_error": "[FATAL]: CUDA error detected: litellm.APIConnectionError: OllamaException - {\"error\":\"llama runner process has terminated: CUDA error\"}"
      },
      "session_id": "phi4_9e98_tpusg_batch",
      "metadata": {
        "num_run": 3
      },
      "tags": [
        "ablation",
        "benchmark",
        "phi4:latest",
        "tpu_sketch_generator"
      ],
      "latency": 0.0,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "2acaf916-7388-42ca-90cc-12edc8d05ce4",
          "traceId": "7a7d5b84",
          "type": "SPAN",
          "name": "error_7a_tpusg_failure_signal_tpu_sketch_generator",
          "startTime": "2025-12-10T20:06:19.904000+00:00",
          "level": "ERROR",
          "statusMessage": "Failed: [FATAL]: CUDA error detected: litellm.APIConnectionError: OllamaException - {\"error\":\"llama runner process has terminated: CUDA error\"}",
          "calculatedTotalCost": 0.0,
          "totalTokens": 0,
          "costDetails": {},
          "environment": "default",
          "promptTokens": 0,
          "completionTokens": 0,
          "endTime": null,
          "model": null,
          "modelParameters": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null,
          "latency": null
        }
      ],
      "createdAt": "2025-12-10T20:06:19.906Z",
      "updatedAt": "2025-12-10T20:06:25.443Z",
      "environment": "default"
    },
    {
      "id": "95e27817",
      "timestamp": "2025-12-10T20:05:53.389000+00:00",
      "name": "95e2_tpu_sketch_generator",
      "input": null,
      "output": {
        "status": "failed",
        "last_code": "",
        "last_error": "[FATAL]: CUDA error detected: litellm.APIConnectionError: OllamaException - {\"error\":\"llama runner process has terminated: CUDA error: all CUDA-capable devices are busy or unavailable\\n  current device: 0, in function ggml_backend_cuda_device_get_memory at //ml/backend/ggml/ggml/src/ggml-cuda/ggml-cuda.cu:2898\\n  cudaMemGetInfo(free, total)\\n//ml/backend/ggml/ggml/src/ggml-cuda/ggml-cuda.cu:73: CUDA error\"}"
      },
      "session_id": "phi4_9e98_tpusg_batch",
      "metadata": {
        "num_run": 2
      },
      "tags": [
        "ablation",
        "benchmark",
        "phi4:latest",
        "tpu_sketch_generator"
      ],
      "latency": 0.0,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "1c627a0a-7421-458d-97d1-c0e33b72d906",
          "traceId": "95e27817",
          "type": "SPAN",
          "name": "error_95_tpusg_failure_signal_tpu_sketch_generator",
          "startTime": "2025-12-10T20:05:53.899000+00:00",
          "level": "ERROR",
          "statusMessage": "Failed: [FATAL]: CUDA error detected: litellm.APIConnectionError: OllamaException - {\"error\":\"llama runner process has terminated: CUDA error: all CUDA-capable devices are busy or unavailable\\n  current device: 0, in function ggml_backend_cuda_device_get_memory at //ml/backend/ggml/ggml/src/ggml-cuda/ggml-cuda.cu:2898\\n  cudaMemGetInfo(free, total)\\n//ml/backend/ggml/ggml/src/ggml-cuda/ggml-cuda.cu:73: CUDA error\"}",
          "calculatedTotalCost": 0.0,
          "totalTokens": 0,
          "costDetails": {},
          "environment": "default",
          "promptTokens": 0,
          "completionTokens": 0,
          "endTime": null,
          "model": null,
          "modelParameters": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null,
          "latency": null
        }
      ],
      "createdAt": "2025-12-10T20:05:53.907Z",
      "updatedAt": "2025-12-10T20:05:59.448Z",
      "environment": "default"
    },
    {
      "id": "1b120398",
      "timestamp": "2025-12-10T20:05:22.434000+00:00",
      "name": "1b12_tpu_sketch_generator",
      "input": null,
      "output": {
        "status": "failed",
        "last_code": "",
        "last_error": "[FATAL]: CUDA error detected: litellm.APIConnectionError: OllamaException - {\"error\":\"llama runner process has terminated: CUDA error: all CUDA-capable devices are busy or unavailable\\n  current device: 0, in function ggml_backend_cuda_device_get_memory at //ml/backend/ggml/ggml/src/ggml-cuda/ggml-cuda.cu:2898\\n  cudaMemGetInfo(free, total)\\n//ml/backend/ggml/ggml/src/ggml-cuda/ggml-cuda.cu:73: CUDA error\"}"
      },
      "session_id": "phi4_9e98_tpusg_batch",
      "metadata": {
        "num_run": 1
      },
      "tags": [
        "ablation",
        "benchmark",
        "phi4:latest",
        "tpu_sketch_generator"
      ],
      "latency": 0.0,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "b5ff933b-9a03-405c-bed9-8f344f22eff0",
          "traceId": "1b120398",
          "type": "SPAN",
          "name": "error_1b_tpusg_failure_signal_tpu_sketch_generator",
          "startTime": "2025-12-10T20:05:26.531000+00:00",
          "level": "ERROR",
          "statusMessage": "Failed: [FATAL]: CUDA error detected: litellm.APIConnectionError: OllamaException - {\"error\":\"llama runner process has terminated: CUDA error: all CUDA-capable devices are busy or unavailable\\n  current device: 0, in function ggml_backend_cuda_device_get_memory at //ml/backend/ggml/ggml/src/ggml-cuda/ggml-cuda.cu:2898\\n  cudaMemGetInfo(free, total)\\n//ml/backend/ggml/ggml/src/ggml-cuda/ggml-cuda.cu:73: CUDA error\"}",
          "calculatedTotalCost": 0.0,
          "totalTokens": 0,
          "costDetails": {},
          "environment": "default",
          "promptTokens": 0,
          "completionTokens": 0,
          "endTime": null,
          "model": null,
          "modelParameters": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null,
          "latency": null
        }
      ],
      "createdAt": "2025-12-10T20:05:22.951Z",
      "updatedAt": "2025-12-10T20:05:32.046Z",
      "environment": "default"
    }
  ],
  "meta": {
    "total_items": 30
  }
}
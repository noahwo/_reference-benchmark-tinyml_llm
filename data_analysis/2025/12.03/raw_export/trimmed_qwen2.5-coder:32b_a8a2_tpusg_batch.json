{
  "data": [
    {
      "id": "4e0cde11",
      "timestamp": "2025-12-11T01:13:33.582000+00:00",
      "name": "4e0c_tpu_sketch_generator",
      "input": null,
      "output": {
        "status": "success",
        "sketch": "import cv2\nimport numpy as np\nfrom PIL import Image\nfrom pycoral.adapters import common, detect\nfrom pycoral.utils.dataset import read_label_file\nfrom pycoral.utils.edgetpu import make_interpreter\n\n# Configuration parameters\nmodel_path = '/home/mendel/tinyml_autopilot/models/edgetpu_detect.tflite'\nlabel_path = '/home/mendel/tinyml_autopilot/models/labelmap.txt'\ninput_path = '/home/mendel/tinyml_autopilot/data/sheeps.mp4'\noutput_path = '/home/mendel/tinyml_autopilot/results/sheeps_detections.mp4'\nconfidence_threshold = 0.5\n\n# Setup: Load the TFLite interpreter for TPU\ninterpreter = make_interpreter(model_path)\ninterpreter.allocate_tensors()\n\n# Load labels\nlabels = read_label_file(label_path)\n\n# Read input video\ncap = cv2.VideoCapture(input_path)\nif not cap.isOpened():\n    raise IOError(\"Cannot open video file\")\n\n# Get video properties\nframe_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\nframe_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\nfps = int(cap.get(cv2.CAP_PROP_FPS))\n\n# Define the codec and create VideoWriter object\nfourcc = cv2.VideoWriter_fourcc(*'mp4v')\nout = cv2.VideoWriter(output_path, fourcc, fps, (frame_width, frame_height))\n\ndef draw_objects(frame, objs, labels):\n    for obj in objs:\n        bbox = obj.bbox\n        label = labels.get(obj.id, 'Unknown')\n        score = obj.score\n        if score >= confidence_threshold:\n            cv2.rectangle(frame, (bbox.xmin, bbox.ymin), (bbox.xmax, bbox.ymax), (0, 255, 0), 2)\n            text = f'{label}: {score:.2f}'\n            cv2.putText(frame, text, (bbox.xmin, bbox.ymin - 10),\n                        cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n\n# Process video frame by frame\nwhile cap.isOpened():\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    # Preprocessing: Convert frame to RGB and resize to expected input size\n    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n    img = Image.fromarray(rgb_frame).resize(common.input_size(interpreter), Image.ANTIALIAS)\n\n    # Run inference\n    common.set_input(interpreter, img)\n    interpreter.invoke()\n    objs = detect.get_objects(interpreter, confidence_threshold)[:5]\n\n    # Draw detection boxes and labels\n    draw_objects(frame, objs, labels)\n\n    # Write the processed frame to output video file\n    out.write(frame)\n\n# Release resources\ncap.release()\nout.release()\ncv2.destroyAllWindows()"
      },
      "session_id": "qwen2.5-coder:32b_a8a2_tpusg_batch",
      "metadata": {
        "num_run": 30
      },
      "tags": [
        "ablation",
        "benchmark",
        "qwen2.5-coder:32b",
        "tpu_sketch_generator"
      ],
      "latency": 90.554,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-03-13-33-583743_chatcmpl-c02b4dc7-9c17-4401-8dc7-7e4422ea66ad",
          "traceId": "4e0cde11",
          "type": "GENERATION",
          "name": "4e0c_tpusg_gen_attempt#1",
          "startTime": "2025-12-11T01:13:33.583000+00:00",
          "endTime": "2025-12-11T01:13:54.860000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 21277.0,
          "completionTokens": 575,
          "environment": "default",
          "totalTokens": 886,
          "promptTokens": 311,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-03-14-03-269083_chatcmpl-66728c90-02ba-4809-a51b-e295fe0321ad",
          "traceId": "4e0cde11",
          "type": "GENERATION",
          "name": "4e0c_tpusg_gen_attempt#2",
          "startTime": "2025-12-11T01:14:03.269000+00:00",
          "endTime": "2025-12-11T01:14:33.637000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 30368.0,
          "completionTokens": 822,
          "environment": "default",
          "totalTokens": 1133,
          "promptTokens": 311,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-03-14-41-659150_chatcmpl-0f558dfe-f7ec-438a-9cb2-0d87e1a1a907",
          "traceId": "4e0cde11",
          "type": "GENERATION",
          "name": "4e0c_tpusg_gen_attempt#3",
          "startTime": "2025-12-11T01:14:41.659000+00:00",
          "endTime": "2025-12-11T01:15:04.137000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 22478.0,
          "completionTokens": 610,
          "environment": "default",
          "totalTokens": 921,
          "promptTokens": 311,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        }
      ],
      "createdAt": "2025-12-11T01:13:34.109Z",
      "updatedAt": "2025-12-11T01:16:05.838Z",
      "environment": "default"
    },
    {
      "id": "75810ee0",
      "timestamp": "2025-12-11T01:10:09.805000+00:00",
      "name": "7581_tpu_sketch_generator",
      "input": null,
      "output": {
        "status": "failed",
        "last_code": "import os\nimport cv2\nimport numpy as np\nfrom PIL import Image\nfrom pycoral.adapters.common import input_size\nfrom pycoral.adapters.detect import get_objects\nfrom pycoral.utils.dataset import read_label_file\nfrom pycoral.utils.edgetpu import make_interpreter\n\n# Configuration parameters\nmodel_path = '/home/mendel/tinyml_autopilot/models/edgetpu_detect.tflite'\nlabel_path = '/home/mendel/tinyml_autopilot/models/labelmap.txt'\ninput_path = '/home/mendel/tinyml_autopilot/data/sheeps.mp4'\noutput_path = '/home/mendel/tinyml_autopilot/results/sheeps_detections.mp4'\nconfidence_threshold = 0.5\n\n# Load the TFLite interpreter for TPU\ninterpreter = make_interpreter(model_path, device=':0')\ninterpreter.allocate_tensors()\nlabels = read_label_file(label_path)\n\n# Read the input video from the given path\ncap = cv2.VideoCapture(input_path)\nwidth = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\nheight = int(cap.get(cv2.CAP_PROP_HEIGHT))\nfps = cap.get(cv2.CAP_PROP_FPS)\n\n# Define the codec and create VideoWriter object\nfourcc = cv2.VideoWriter_fourcc(*'mp4v')\nout = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n\ndef preprocess_image(image):\n    size = input_size(interpreter)\n    image = Image.fromarray(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n    resized_image = image.resize(size, Image.ANTIALIAS)\n    return np.array(resized_image)\n\nwhile cap.isOpened():\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    # Preprocess the input\n    preprocessed_frame = preprocess_image(frame.copy())\n\n    # Run inference\n    input_tensor = interpreter.tensor(interpreter.get_input_details()[0]['index'])\n    input_tensor[:, :] = preprocessed_frame\n    interpreter.invoke()\n\n    # Get detection results\n    detected_objects = get_objects(interpreter, confidence_threshold)\n\n    # Draw detection boxes and labels on the frame\n    for obj in detected_objects:\n        bbox = obj.bbox\n        label = f'{labels.get(obj.id, obj.id)}: {obj.score:.2f}'\n        x0, y0 = int(bbox.xmin * width), int(bbox.ymin * height)\n        x1, y1 = int(bbox.xmax * width), int(bbox.ymax * height)\n        cv2.rectangle(frame, (x0, y0), (x1, y1), (0, 255, 0), 2)\n        cv2.putText(frame, label, (x0, y0 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n\n    # Write the frame with detections to the output video\n    out.write(frame)\n\n# Release resources\ncap.release()\nout.release()\ncv2.destroyAllWindows()",
        "last_error": "Max retries reached with error. Last error: Traceback (most recent call last):\n  File \"script_ddbfe603_1765415579.py\", line 25, in <module>\n    height = int(cap.get(cv2.CAP_PROP_HEIGHT))\nAttributeError: module 'cv2' has no attribute 'CAP_PROP_HEIGHT'."
      },
      "session_id": "qwen2.5-coder:32b_a8a2_tpusg_batch",
      "metadata": {
        "num_run": 29
      },
      "tags": [
        "ablation",
        "benchmark",
        "qwen2.5-coder:32b",
        "tpu_sketch_generator"
      ],
      "latency": 178.018,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-03-10-09-806969_chatcmpl-359f14c3-d2f8-4f70-ba1e-54df1219261a",
          "traceId": "75810ee0",
          "type": "GENERATION",
          "name": "7581_tpusg_gen_attempt#1",
          "startTime": "2025-12-11T01:10:09.806000+00:00",
          "endTime": "2025-12-11T01:10:34.051000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 24245.0,
          "completionTokens": 655,
          "environment": "default",
          "totalTokens": 966,
          "promptTokens": 311,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-03-10-42-850776_chatcmpl-5ec6042c-8b30-4715-b990-85b3de2eb7ff",
          "traceId": "75810ee0",
          "type": "GENERATION",
          "name": "7581_tpusg_gen_attempt#2",
          "startTime": "2025-12-11T01:10:42.850000+00:00",
          "endTime": "2025-12-11T01:11:17.383000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 34533.0,
          "completionTokens": 934,
          "environment": "default",
          "totalTokens": 1245,
          "promptTokens": 311,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-03-11-25-444774_chatcmpl-73ca1ac6-614e-4d16-8ea7-55ec18b33ae8",
          "traceId": "75810ee0",
          "type": "GENERATION",
          "name": "7581_tpusg_gen_attempt#3",
          "startTime": "2025-12-11T01:11:25.444000+00:00",
          "endTime": "2025-12-11T01:11:54.904000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 29460.0,
          "completionTokens": 798,
          "environment": "default",
          "totalTokens": 1109,
          "promptTokens": 311,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-03-12-02-558377_chatcmpl-09128239-06c1-41ce-b061-2dcbbfc6384c",
          "traceId": "75810ee0",
          "type": "GENERATION",
          "name": "7581_tpusg_gen_attempt#4",
          "startTime": "2025-12-11T01:12:02.558000+00:00",
          "endTime": "2025-12-11T01:12:27.082000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 24524.0,
          "completionTokens": 665,
          "environment": "default",
          "totalTokens": 976,
          "promptTokens": 311,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-03-12-35-903426_chatcmpl-6259bf8f-dd88-48e9-8ffb-ab0297d14286",
          "traceId": "75810ee0",
          "type": "GENERATION",
          "name": "7581_tpusg_gen_attempt#5",
          "startTime": "2025-12-11T01:12:35.903000+00:00",
          "endTime": "2025-12-11T01:12:59.408000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 23505.0,
          "completionTokens": 637,
          "environment": "default",
          "totalTokens": 948,
          "promptTokens": 311,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "e574a278-c8b0-4a5e-a726-8726081b1299",
          "traceId": "75810ee0",
          "type": "SPAN",
          "name": "error_75_tpusg_failure_signal_tpu_sketch_generator",
          "startTime": "2025-12-11T01:13:07.824000+00:00",
          "level": "ERROR",
          "statusMessage": "Failed: Max retries reached with error. Last error: Traceback (most recent call last):\n  File \"script_ddbfe603_1765415579.py\", line 25, in <module>\n    height = int(cap.get(cv2.CAP_PROP_HEIGHT))\nAttributeError: module 'cv2' has no attribute 'CAP_PROP_HEIGHT'.",
          "calculatedTotalCost": 0.0,
          "completionTokens": 0,
          "environment": "default",
          "totalTokens": 0,
          "promptTokens": 0,
          "costDetails": {},
          "endTime": null,
          "model": null,
          "modelParameters": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null,
          "latency": null
        }
      ],
      "createdAt": "2025-12-11T01:10:10.324Z",
      "updatedAt": "2025-12-11T01:13:13.033Z",
      "environment": "default"
    },
    {
      "id": "1cb44fb0",
      "timestamp": "2025-12-11T01:08:20.711000+00:00",
      "name": "1cb4_tpu_sketch_generator",
      "input": null,
      "output": {
        "status": "success",
        "sketch": "import os\nimport numpy as np\nimport cv2\nfrom tflite_runtime.interpreter import Interpreter\nfrom pycoral.utils.edgetpu import make_interpreter\n\n# Configuration parameters\nmodel_path = '/home/mendel/tinyml_autopilot/models/edgetpu_detect.tflite'\nlabel_path = '/home/mendel/tinyml_autopilot/models/labelmap.txt'\ninput_path = '/home/mendel/tinyml_autopilot/data/sheeps.mp4'\noutput_path = '/home/mendel/tinyml_autopilot/results/sheeps_detections.mp4'\nconfidence_threshold = 0.5\n\n# Load labels\ndef load_labels(filename):\n    with open(filename, 'r', encoding='utf-8') as f:\n        return {i: line.strip() for i, line in enumerate(f)}\n\nlabels = load_labels(label_path)\n\n# Initialize interpreter and allocate tensors\ninterpreter = make_interpreter(model_path, device=':0')\ninterpreter.allocate_tensors()\n\n# Get input and output details\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\nheight, width = input_details[0]['shape'][1:3]\n\n# Preprocessing function\ndef preprocess_image(image):\n    image_resized = cv2.resize(image, (width, height))\n    image_rgb = cv2.cvtColor(image_resized, cv2.COLOR_BGR2RGB)\n    input_data = np.expand_dims(image_rgb, axis=0).astype(np.uint8)\n    return input_data\n\n# Function to draw bounding boxes\ndef draw_boxes(frame, detections, labels):\n    for i in range(len(detections['detection_scores'])):\n        score = float(detections['detection_scores'][i])\n        if score > confidence_threshold:\n            ymin = int(max(1, (detections['detection_boxes'][i][0] * frame.shape[0])))\n            xmin = int(max(1, (detections['detection_boxes'][i][1] * frame.shape[1])))\n            ymax = int(min(frame.shape[0], (detections['detection_boxes'][i][2] * frame.shape[0])))\n            xmax = int(min(frame.shape[1], (detections['detection_boxes'][i][3] * frame.shape[1])))\n\n            label_id = int(detections['detection_classes'][i])\n            label_text = labels[label_id]\n            display_text = f'{label_text}: {score:.2f}'\n\n            cv2.rectangle(frame, (xmin, ymin), (xmax, ymax), (0, 255, 0), 2)\n            cv2.putText(frame, display_text, (xmin, ymin - 5),\n                        cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n\n# Read video\ncap = cv2.VideoCapture(input_path)\nfourcc = cv2.VideoWriter_fourcc(*'mp4v')\nout = cv2.VideoWriter(output_path, fourcc, cap.get(cv2.CAP_PROP_FPS),\n                      (int(cap.get(cv2.CAP_PROP_FRAME_WIDTH)), int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))))\n\nwhile cap.isOpened():\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    input_data = preprocess_image(frame)\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n\n    # Run inference\n    interpreter.invoke()\n\n    # Extract results\n    boxes = np.squeeze(interpreter.get_tensor(output_details[0]['index']))\n    classes = np.squeeze(interpreter.get_tensor(output_details[1]['index'])).astype(np.int)\n    scores = np.squeeze(interpreter.get_tensor(output_details[2]['index']))\n\n    detections = {\n        'detection_boxes': boxes,\n        'detection_classes': classes,\n        'detection_scores': scores\n    }\n\n    # Draw bounding boxes\n    draw_boxes(frame, detections, labels)\n\n    # Write the frame with detections to the output video\n    out.write(frame)\n\ncap.release()\nout.release()\ncv2.destroyAllWindows()"
      },
      "session_id": "qwen2.5-coder:32b_a8a2_tpusg_batch",
      "metadata": {
        "num_run": 28
      },
      "tags": [
        "ablation",
        "benchmark",
        "qwen2.5-coder:32b",
        "tpu_sketch_generator"
      ],
      "latency": 31.049,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-03-08-20-712241_chatcmpl-fd9de3c6-fa66-4d28-a5b9-9b38b453a16e",
          "traceId": "1cb44fb0",
          "type": "GENERATION",
          "name": "1cb4_tpusg_gen_attempt#1",
          "startTime": "2025-12-11T01:08:20.712000+00:00",
          "endTime": "2025-12-11T01:08:51.761000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 31049.0,
          "completionTokens": 838,
          "environment": "default",
          "totalTokens": 1149,
          "promptTokens": 311,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        }
      ],
      "createdAt": "2025-12-11T01:08:21.231Z",
      "updatedAt": "2025-12-11T01:09:49.901Z",
      "environment": "default"
    },
    {
      "id": "2d07a956",
      "timestamp": "2025-12-11T01:06:37.746000+00:00",
      "name": "2d07_tpu_sketch_generator",
      "input": null,
      "output": {
        "status": "success",
        "sketch": "import cv2\nimport numpy as np\nfrom tflite_runtime.interpreter import Interpreter\nfrom PIL import ImageDraw, ImageFont, Image\nfrom pycoral.adapters import common, detect\nfrom pycoral.utils.dataset import read_label_file\nfrom pycoral.utils.edgetpu import make_interpreter\n\n# Configuration parameters\nmodel_path = '/home/mendel/tinyml_autopilot/models/edgetpu_detect.tflite'\nlabel_path = '/home/mendel/tinyml_autopilot/models/labelmap.txt'\ninput_path = '/home/mendel/tinyml_autopilot/data/sheeps.mp4'\noutput_path = '/home/mendel/tinyml_autopilot/results/sheeps_detections.mp4'\nconfidence_threshold = 0.5\n\n# Load the TFLite interpreter with TPU\ninterpreter = make_interpreter(model_path)\ninterpreter.allocate_tensors()\n\n# Load labels\nlabels = read_label_file(label_path)\n\n# Initialize video capture and writer\ncap = cv2.VideoCapture(input_path)\nfps = cap.get(cv2.CAP_PROP_FPS)\nwidth  = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\nheight = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\nfourcc = cv2.VideoWriter_fourcc(*'mp4v')\nout = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n\n# Function to draw detection boxes and labels\ndef draw_detection_boxes(image, detections):\n    draw = ImageDraw.Draw(image)\n    font = ImageFont.load_default()\n    for obj in detections:\n        bbox = obj.bbox\n        score = obj.score\n        label = labels.get(obj.id, 'Unknown')\n        if score > confidence_threshold:\n            draw.rectangle([(bbox.xmin, bbox.ymin), (bbox.xmax, bbox.ymax)], outline='green', width=2)\n            text = f'{label}: {score:.2f}'\n            draw.text((bbox.xmin + 5, bbox.ymin - 10), text, font=font, fill='green')\n    return image\n\n# Process video frame by frame\nwhile cap.isOpened():\n    ret, frame = cap.read()\n    if not ret:\n        break\n    \n    # Preprocessing\n    input_tensor = interpreter.tensor(interpreter.get_input_details()[0]['index'])\n    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n    frame_resized = cv2.resize(frame_rgb, (300, 300))\n    input_tensor()[:, :] = np.expand_dims(frame_resized, axis=0)\n\n    # Inference\n    interpreter.invoke()\n    detections = detect.get_objects(interpreter, score_threshold=confidence_threshold)\n\n    # Postprocessing and drawing boxes\n    frame_pil = Image.fromarray(frame_rgb)\n    output_frame = draw_detection_boxes(frame_pil, detections)\n    output_frame_bgr = cv2.cvtColor(np.array(output_frame), cv2.COLOR_RGB2BGR)\n\n    # Write the result to the video file\n    out.write(output_frame_bgr)\n\n# Release resources\ncap.release()\nout.release()\ncv2.destroyAllWindows()"
      },
      "session_id": "qwen2.5-coder:32b_a8a2_tpusg_batch",
      "metadata": {
        "num_run": 27
      },
      "tags": [
        "ablation",
        "benchmark",
        "qwen2.5-coder:32b",
        "tpu_sketch_generator"
      ],
      "latency": 23.87,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-03-06-37-748312_chatcmpl-8324f477-4dbe-476e-b7de-4e6752a4ddb4",
          "traceId": "2d07a956",
          "type": "GENERATION",
          "name": "2d07_tpusg_gen_attempt#1",
          "startTime": "2025-12-11T01:06:37.748000+00:00",
          "endTime": "2025-12-11T01:07:01.618000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 23870.0,
          "completionTokens": 645,
          "environment": "default",
          "totalTokens": 956,
          "promptTokens": 311,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        }
      ],
      "createdAt": "2025-12-11T01:06:38.269Z",
      "updatedAt": "2025-12-11T01:08:00.413Z",
      "environment": "default"
    },
    {
      "id": "01dc9278",
      "timestamp": "2025-12-11T01:03:25.034000+00:00",
      "name": "01dc_tpu_sketch_generator",
      "input": null,
      "output": {
        "status": "failed",
        "last_code": "import os\nimport cv2\nimport numpy as np\nfrom PIL import Image\nfrom pycoral.adapters.common import input_size\nfrom pycoral.adapters.detect import get_objects\nfrom pycoral.utils.dataset import read_label_file\nfrom pycoral.utils.edgetpu import make_interpreter\n\n# Configuration parameters\nmodel_path = '/home/mendel/tinyml_autopilot/models/edgetpu_detect.tflite'\nlabel_path = '/home/mendel/tinyml_autopilot/models/labelmap.txt'\ninput_path = '/home/mendel/tinyml_autopilot/data/sheeps.mp4'\noutput_path = '/home/mendel/tinyml_autopilot/results/sheeps_detections.mp4'\nconfidence_threshold = 0.5\n\n# Load the TFLite interpreter for TPU\ninterpreter = make_interpreter(model_path)\ninterpreter.allocate_tensors()\nlabels = read_label_file(label_path)\n\n# Read input video\ncap = cv2.VideoCapture(input_path)\nif not cap.isOpened():\n    raise IOError(\"Cannot open video file\")\n\n# Get video properties to save output video with the same specifications\nwidth = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\nheight = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\nfps = int(cap.get(cv2.CAP_PROP_FPS))\n\n# Initialize video writer for output\nfourcc = cv2.VideoWriter_fourcc(*'mp4v')\nout = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n\n# Preprocessing and inference pipeline\nwhile cap.isOpened():\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    # Convert OpenCV BGR format to PIL Image RGB\n    img = Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n    resize_img = img.resize((width, height), Image.ANTIALIAS)\n\n    # Preprocess the image and run inference\n    input_tensor = interpreter.tensor(interpreter.get_input_details()[0]['index'])\n    _, scale = common.set_resized_input(interpreter, resize_img.size, lambda size: resize_img.resize(size, Image.ANTIALIAS))\n    interpreter.invoke()\n    \n    # Get detection results\n    objs = get_objects(interpreter, score_threshold=confidence_threshold, image_scale=scale)\n\n    # Draw bounding boxes and labels on the frame\n    for obj in objs:\n        bbox = obj.bbox\n        color = (255, 0, 0)  # Blue color for bounding box\n        cv2.rectangle(frame, (bbox.xmin, bbox.ymin), (bbox.xmax, bbox.ymax), color, 2)\n        \n        label = '%s: %.1f%%' % (labels.get(obj.id, obj.id), obj.score * 100)\n        label_size, base_line = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.5, 2)\n        label_ymin = max(bbox.ymin, label_size[1] + 10)\n        cv2.rectangle(frame, (bbox.xmin, label_ymin - label_size[1] - 10), (bbox.xmin + label_size[0], label_ymin + base_line - 10), color, cv2.FILLED)\n        cv2.putText(frame, label, (bbox.xmin, label_ymin - 7), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2)\n\n    # Write the frame with detections to output video\n    out.write(frame)\n\n# Release resources\ncap.release()\nout.release()\ncv2.destroyAllWindows()",
        "last_error": "Max retries reached with error. Last error: Traceback (most recent call last):\n  File \"script_f1c85e5d_1765415162.py\", line 48, in <module>\n    _, scale = common.set_resized_input(interpreter, resize_img.size, lambda size: resize_img.resize(size, Image.ANTIALIAS))\nNameError: name 'common' is not defined."
      },
      "session_id": "qwen2.5-coder:32b_a8a2_tpusg_batch",
      "metadata": {
        "num_run": 26
      },
      "tags": [
        "ablation",
        "benchmark",
        "qwen2.5-coder:32b",
        "tpu_sketch_generator"
      ],
      "latency": 166.333,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-03-03-25-035716_chatcmpl-25fb5e40-776a-4b27-a50e-70424cc3e75e",
          "traceId": "01dc9278",
          "type": "GENERATION",
          "name": "01dc_tpusg_gen_attempt#1",
          "startTime": "2025-12-11T01:03:25.035000+00:00",
          "endTime": "2025-12-11T01:03:49.372000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 24337.0,
          "completionTokens": 653,
          "environment": "default",
          "totalTokens": 964,
          "promptTokens": 311,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-03-03-56-924880_chatcmpl-66f23a73-0afb-4f9f-b135-9449ba790d02",
          "traceId": "01dc9278",
          "type": "GENERATION",
          "name": "01dc_tpusg_gen_attempt#2",
          "startTime": "2025-12-11T01:03:56.924000+00:00",
          "endTime": "2025-12-11T01:04:19.947000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 23023.0,
          "completionTokens": 624,
          "environment": "default",
          "totalTokens": 935,
          "promptTokens": 311,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-03-04-28-027223_chatcmpl-9c0d69c9-a116-47f0-b3cb-c68d8449738b",
          "traceId": "01dc9278",
          "type": "GENERATION",
          "name": "01dc_tpusg_gen_attempt#3",
          "startTime": "2025-12-11T01:04:28.027000+00:00",
          "endTime": "2025-12-11T01:04:51.964000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 23937.0,
          "completionTokens": 649,
          "environment": "default",
          "totalTokens": 960,
          "promptTokens": 311,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-03-04-59-997545_chatcmpl-afbec0bd-7718-40c0-95fa-03bbe2d96ee3",
          "traceId": "01dc9278",
          "type": "GENERATION",
          "name": "01dc_tpusg_gen_attempt#4",
          "startTime": "2025-12-11T01:04:59.997000+00:00",
          "endTime": "2025-12-11T01:05:21.476000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 21479.0,
          "completionTokens": 583,
          "environment": "default",
          "totalTokens": 894,
          "promptTokens": 311,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-03-05-29-618940_chatcmpl-3fe9156c-45da-43ad-bdcf-7235c8ca9aab",
          "traceId": "01dc9278",
          "type": "GENERATION",
          "name": "01dc_tpusg_gen_attempt#5",
          "startTime": "2025-12-11T01:05:29.618000+00:00",
          "endTime": "2025-12-11T01:06:02.839000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 33221.0,
          "completionTokens": 899,
          "environment": "default",
          "totalTokens": 1210,
          "promptTokens": 311,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "912a1814-6e39-4e69-8cb0-2581fb14cd77",
          "traceId": "01dc9278",
          "type": "SPAN",
          "name": "error_01_tpusg_failure_signal_tpu_sketch_generator",
          "startTime": "2025-12-11T01:06:11.368000+00:00",
          "level": "ERROR",
          "statusMessage": "Failed: Max retries reached with error. Last error: Traceback (most recent call last):\n  File \"script_f1c85e5d_1765415162.py\", line 48, in <module>\n    _, scale = common.set_resized_input(interpreter, resize_img.size, lambda size: resize_img.resize(size, Image.ANTIALIAS))\nNameError: name 'common' is not defined.",
          "calculatedTotalCost": 0.0,
          "completionTokens": 0,
          "environment": "default",
          "totalTokens": 0,
          "promptTokens": 0,
          "costDetails": {},
          "endTime": null,
          "model": null,
          "modelParameters": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null,
          "latency": null
        }
      ],
      "createdAt": "2025-12-11T01:03:25.555Z",
      "updatedAt": "2025-12-11T01:06:16.758Z",
      "environment": "default"
    },
    {
      "id": "99cbcfb7",
      "timestamp": "2025-12-11T01:00:37.983000+00:00",
      "name": "99cb_tpu_sketch_generator",
      "input": null,
      "output": {
        "status": "success",
        "sketch": "import os\nimport numpy as np\nimport cv2\nfrom PIL import Image\nimport tflite_runtime.interpreter as tflite\nfrom pycoral.adapters.common import input_size\nfrom pycoral.adapters.detect import get_objects\nfrom pycoral.utils.dataset import read_label_file\nfrom pycoral.utils.edgetpu import make_interpreter\n\n# Configuration parameters\nmodel_path = '/home/mendel/tinyml_autopilot/models/edgetpu_detect.tflite'\nlabel_path = '/home/mendel/tinyml_autopilot/models/labelmap.txt'\ninput_path = '/home/mendel/tinyml_autopilot/data/sheeps.mp4'\noutput_path = '/home/mendel/tinyml_autopilot/results/sheeps_detections.mp4'\nconfidence_threshold = 0.5\n\n# Load the TFLite interpreter for TPU\ninterpreter = make_interpreter(model_path)\ninterpreter.allocate_tensors()\nlabels = read_label_file(label_path)\n\n# Get model details\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\nheight, width = input_size(interpreter)\n\n# Open video file\ncap = cv2.VideoCapture(input_path)\nfourcc = cv2.VideoWriter_fourcc(*'mp4v')\nout = cv2.VideoWriter(output_path, fourcc, 30.0, (int(cap.get(3)), int(cap.get(4))))\n\ndef draw_objects(frame, objs, labels):\n    for obj in objs:\n        bbox = obj.bbox\n        x0, y0, x1, y1 = bbox.xmin, bbox.ymin, bbox.xmax, bbox.ymax\n        label = f'{labels.get(obj.id, obj.id)} {obj.score:.2f}'\n        cv2.rectangle(frame, (int(x0), int(y0)), (int(x1), int(y1)), (0, 255, 0), 2)\n        cv2.putText(frame, label, (int(x0), int(y0) - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (36,255,12), 2)\n\nwhile cap.isOpened():\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    # Preprocessing\n    img = Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)).resize((width, height))\n    input_data = np.expand_dims(img, axis=0).astype(np.uint8)\n\n    # Inference\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n    interpreter.invoke()\n    objs = get_objects(interpreter, confidence_threshold)\n\n    # Draw detection boxes with labels\n    draw_objects(frame, objs, labels)\n\n    # Output handling\n    out.write(cv2.cvtColor(frame, cv2.COLOR_RGB2BGR))\n\ncap.release()\nout.release()\ncv2.destroyAllWindows()"
      },
      "session_id": "qwen2.5-coder:32b_a8a2_tpusg_batch",
      "metadata": {
        "num_run": 25
      },
      "tags": [
        "ablation",
        "benchmark",
        "qwen2.5-coder:32b",
        "tpu_sketch_generator"
      ],
      "latency": 89.318,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-03-00-37-984920_chatcmpl-f9806e99-2e17-4789-bef4-b4558a15392f",
          "traceId": "99cbcfb7",
          "type": "GENERATION",
          "name": "99cb_tpusg_gen_attempt#1",
          "startTime": "2025-12-11T01:00:37.984000+00:00",
          "endTime": "2025-12-11T01:01:03.396000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 25412.0,
          "completionTokens": 687,
          "environment": "default",
          "totalTokens": 998,
          "promptTokens": 311,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-03-01-11-315820_chatcmpl-bc28febf-765a-45b0-88b9-1bc510e43872",
          "traceId": "99cbcfb7",
          "type": "GENERATION",
          "name": "99cb_tpusg_gen_attempt#2",
          "startTime": "2025-12-11T01:01:11.315000+00:00",
          "endTime": "2025-12-11T01:01:36.784000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 25469.0,
          "completionTokens": 690,
          "environment": "default",
          "totalTokens": 1001,
          "promptTokens": 311,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-03-01-45-231556_chatcmpl-d57e42e7-fb04-4e92-8367-36f83f2d1288",
          "traceId": "99cbcfb7",
          "type": "GENERATION",
          "name": "99cb_tpusg_gen_attempt#3",
          "startTime": "2025-12-11T01:01:45.231000+00:00",
          "endTime": "2025-12-11T01:02:07.302000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 22071.0,
          "completionTokens": 599,
          "environment": "default",
          "totalTokens": 910,
          "promptTokens": 311,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        }
      ],
      "createdAt": "2025-12-11T01:00:38.503Z",
      "updatedAt": "2025-12-11T01:03:05.358Z",
      "environment": "default"
    },
    {
      "id": "aef76af2",
      "timestamp": "2025-12-11T00:57:09.967000+00:00",
      "name": "aef7_tpu_sketch_generator",
      "input": null,
      "output": {
        "status": "success",
        "sketch": "import cv2\nimport numpy as np\nfrom PIL import Image\nfrom pycoral.adapters.common import input_size\nfrom pycoral.adapters.detect import get_objects\nfrom pycoral.utils.dataset import read_label_file\nfrom pycoral.utils.edgetpu import make_interpreter\n\n# Configuration parameters\nmodel_path = '/home/mendel/tinyml_autopilot/models/edgetpu_detect.tflite'\nlabel_path = '/home/mendel/tinyml_autopilot/models/labelmap.txt'\ninput_path = '/home/mendel/tinyml_autopilot/data/sheeps.mp4'\noutput_path = '/home/mendel/tinyml_autopilot/results/sheeps_detections.mp4'\nconfidence_threshold = 0.5\n\n# Load the TFLite interpreter with Edge TPU support\ninterpreter = make_interpreter(model_path)\ninterpreter.allocate_tensors()\nlabels = read_label_file(label_path)\n\n# Preprocessing function to prepare image for inference\ndef preprocess_image(image):\n    size = input_size(interpreter)\n    resized_image = Image.fromarray(cv2.cvtColor(image, cv2.COLOR_BGR2RGB)).resize(size, Image.ANTIALIAS)\n    return np.array(resized_image), size\n\n# Function to draw detection boxes and labels on the image\ndef draw_boxes(frame, objs, scale_x, scale_y):\n    for obj in objs:\n        bbox = obj.bbox\n        if obj.score > confidence_threshold:\n            start_point = (int(bbox.xmin * scale_x), int(bbox.ymin * scale_y))\n            end_point = (int(bbox.xmax * scale_x), int(bbox.ymax * scale_y))\n            cv2.rectangle(frame, start_point, end_point, (0, 255, 0), 2)\n            label = f'{labels.get(obj.id, obj.id)}: {obj.score:.2f}'\n            cv2.putText(frame, label, (start_point[0], start_point[1] - 10),\n                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n\n# Read video from the specified input path\ncap = cv2.VideoCapture(input_path)\nif not cap.isOpened():\n    raise SystemExit('ERROR: Unable to open input video file')\n\n# Get video properties\nframe_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\nframe_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\nfps = cap.get(cv2.CAP_PROP_FPS)\n\n# Initialize video writer for output video\nfourcc = cv2.VideoWriter_fourcc(*'mp4v')\nout = cv2.VideoWriter(output_path, fourcc, fps, (frame_width, frame_height))\n\n# Process each frame in the video\nwhile True:\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    # Preprocess image for inference\n    preprocessed_image, size = preprocess_image(frame)\n    scale_x, scale_y = frame_width / size[0], frame_height / size[1]\n\n    # Run inference\n    interpreter.set_tensor(interpreter.get_input_details()[0]['index'], [preprocessed_image])\n    interpreter.invoke()\n\n    # Get detection results and draw boxes on the frame\n    objs = get_objects(interpreter, confidence_threshold)\n    draw_boxes(frame, objs, scale_x, scale_y)\n\n    # Write processed frame to output video\n    out.write(frame)\n\n# Release resources\ncap.release()\nout.release()\ncv2.destroyAllWindows()"
      },
      "session_id": "qwen2.5-coder:32b_a8a2_tpusg_batch",
      "metadata": {
        "num_run": 24
      },
      "tags": [
        "ablation",
        "benchmark",
        "qwen2.5-coder:32b",
        "tpu_sketch_generator"
      ],
      "latency": 125.633,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-02-57-09-968527_chatcmpl-69909316-6d22-4673-8d51-39cdc04bcf79",
          "traceId": "aef76af2",
          "type": "GENERATION",
          "name": "aef7_tpusg_gen_attempt#1",
          "startTime": "2025-12-11T00:57:09.968000+00:00",
          "endTime": "2025-12-11T00:57:31.566000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 21598.0,
          "completionTokens": 584,
          "environment": "default",
          "totalTokens": 895,
          "promptTokens": 311,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-02-57-40-155290_chatcmpl-aab75f74-1eae-4cd3-b5b5-9103dd1c5e8e",
          "traceId": "aef76af2",
          "type": "GENERATION",
          "name": "aef7_tpusg_gen_attempt#2",
          "startTime": "2025-12-11T00:57:40.155000+00:00",
          "endTime": "2025-12-11T00:58:07.036000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 26881.0,
          "completionTokens": 728,
          "environment": "default",
          "totalTokens": 1039,
          "promptTokens": 311,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-02-58-15-615457_chatcmpl-12ec389e-7171-4afe-9aad-691ce8414130",
          "traceId": "aef76af2",
          "type": "GENERATION",
          "name": "aef7_tpusg_gen_attempt#3",
          "startTime": "2025-12-11T00:58:15.615000+00:00",
          "endTime": "2025-12-11T00:58:38.628000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 23013.0,
          "completionTokens": 624,
          "environment": "default",
          "totalTokens": 935,
          "promptTokens": 311,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-02-58-46-539028_chatcmpl-6aa1288d-579a-4e74-b686-bd56f2c912cf",
          "traceId": "aef76af2",
          "type": "GENERATION",
          "name": "aef7_tpusg_gen_attempt#4",
          "startTime": "2025-12-11T00:58:46.539000+00:00",
          "endTime": "2025-12-11T00:59:15.601000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 29062.0,
          "completionTokens": 787,
          "environment": "default",
          "totalTokens": 1098,
          "promptTokens": 311,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        }
      ],
      "createdAt": "2025-12-11T00:57:10.487Z",
      "updatedAt": "2025-12-11T01:00:17.657Z",
      "environment": "default"
    },
    {
      "id": "ded7490c",
      "timestamp": "2025-12-11T00:53:53.856000+00:00",
      "name": "ded7_tpu_sketch_generator",
      "input": null,
      "output": {
        "status": "failed",
        "last_code": "import os\nimport cv2\nimport numpy as np\nfrom pycoral.adapters import common\nfrom pycoral.adapters import detect\nfrom pycoral.utils.dataset import read_label_file\nfrom pycoral.utils.edgetpu import make_interpreter\n\n# Configuration parameters\nmodel_path = '/home/mendel/tinyml_autopilot/models/edgetpu_detect.tflite'\nlabel_path = '/home/mendel/tinyml_autopilot/models/labelmap.txt'\ninput_path = '/home/mendel/tinyml_autopilot/data/sheeps.mp4'\noutput_path = '/home/mendel/tinyml_autopilot/results/sheeps_detections.mp4'\nconfidence_threshold = 0.5\n\n# Step 1: Setup\ninterpreter = make_interpreter(model_path, device=':0')\ninterpreter.allocate_tensors()\nlabels = read_label_file(label_path)\n\n# Step 2: Preprocessing\ncap = cv2.VideoCapture(input_path)\nif not cap.isOpened():\n    raise IOError(\"Cannot open video\")\n\nframe_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\nframe_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\nfps = cap.get(cv2.CAP_PROP_FPS)\n\nfourcc = cv2.VideoWriter_fourcc(*'mp4v')\nout = cv2.VideoWriter(output_path, fourcc, fps, (frame_width, frame_height))\n\n# Step 3: Inference and Output Handling\nwhile True:\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    # Preprocess the image\n    input_tensor = interpreter.tensor(interpreter.get_input_details()[0]['index'])\n    _, scale = common.set_resized_input(interpreter, frame.size, lambda size: cv2.resize(frame, size))\n\n    # Run inference\n    interpreter.invoke()\n    detections = detect.get_objects(interpreter, confidence_threshold)\n\n    # Draw detection boxes and labels\n    for obj in detections:\n        bbox = obj.bbox.scale(frame_width * scale, frame_height * scale)\n        label = f'{labels[obj.id]}: {obj.score:.2f}'\n        cv2.rectangle(frame, (int(bbox.xmin), int(bbox.ymin)), (int(bbox.xmax), int(bbox.ymax)), (0, 255, 0), 2)\n        cv2.putText(frame, label, (int(bbox.xmin), int(bbox.ymin) - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n\n    # Write the frame to output video\n    out.write(frame)\n\ncap.release()\nout.release()",
        "last_error": "Max retries reached with error. Last error: Traceback (most recent call last):\n  File \"script_2425fe40_1765414596.py\", line 41, in <module>\n    _, scale = common.set_resized_input(interpreter, frame.size, lambda size: cv2.resize(frame, size))\n  File \"/home/mendel/tinyml_autopilot/tinyml-env/lib/python3.7/site-packages/pycoral/adapters/common.py\", line 92, in set_resized_input\n    w, h = size\nTypeError: cannot unpack non-iterable int object."
      },
      "session_id": "qwen2.5-coder:32b_a8a2_tpusg_batch",
      "metadata": {
        "num_run": 23
      },
      "tags": [
        "ablation",
        "benchmark",
        "qwen2.5-coder:32b",
        "tpu_sketch_generator"
      ],
      "latency": 171.014,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-02-53-53-858179_chatcmpl-96849321-6d87-49cd-9b6f-da3f10c19c05",
          "traceId": "ded7490c",
          "type": "GENERATION",
          "name": "ded7_tpusg_gen_attempt#1",
          "startTime": "2025-12-11T00:53:53.858000+00:00",
          "endTime": "2025-12-11T00:54:18.413000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 24555.0,
          "completionTokens": 664,
          "environment": "default",
          "totalTokens": 975,
          "promptTokens": 311,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-02-54-26-659461_chatcmpl-534611a9-3891-49a3-b88e-661cd11fac66",
          "traceId": "ded7490c",
          "type": "GENERATION",
          "name": "ded7_tpusg_gen_attempt#2",
          "startTime": "2025-12-11T00:54:26.659000+00:00",
          "endTime": "2025-12-11T00:54:51.125000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 24466.0,
          "completionTokens": 663,
          "environment": "default",
          "totalTokens": 974,
          "promptTokens": 311,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-02-54-59-046415_chatcmpl-84349278-6404-46ac-a328-b6be0ea83705",
          "traceId": "ded7490c",
          "type": "GENERATION",
          "name": "ded7_tpusg_gen_attempt#3",
          "startTime": "2025-12-11T00:54:59.046000+00:00",
          "endTime": "2025-12-11T00:55:31.909000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 32863.0,
          "completionTokens": 889,
          "environment": "default",
          "totalTokens": 1200,
          "promptTokens": 311,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-02-55-40-015531_chatcmpl-bff46ba0-14be-4e19-965b-cd590f720a59",
          "traceId": "ded7490c",
          "type": "GENERATION",
          "name": "ded7_tpusg_gen_attempt#4",
          "startTime": "2025-12-11T00:55:40.015000+00:00",
          "endTime": "2025-12-11T00:56:06.263000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 26248.0,
          "completionTokens": 711,
          "environment": "default",
          "totalTokens": 1022,
          "promptTokens": 311,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-02-56-13-974213_chatcmpl-f9fcc338-7d30-4e6b-9487-0f259a3e36e6",
          "traceId": "ded7490c",
          "type": "GENERATION",
          "name": "ded7_tpusg_gen_attempt#5",
          "startTime": "2025-12-11T00:56:13.974000+00:00",
          "endTime": "2025-12-11T00:56:36.126000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 22152.0,
          "completionTokens": 601,
          "environment": "default",
          "totalTokens": 912,
          "promptTokens": 311,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "a919f84e-93ac-4d21-a4cd-c3186787ae82",
          "traceId": "ded7490c",
          "type": "SPAN",
          "name": "error_de_tpusg_failure_signal_tpu_sketch_generator",
          "startTime": "2025-12-11T00:56:44.872000+00:00",
          "level": "ERROR",
          "statusMessage": "Failed: Max retries reached with error. Last error: Traceback (most recent call last):\n  File \"script_2425fe40_1765414596.py\", line 41, in <module>\n    _, scale = common.set_resized_input(interpreter, frame.size, lambda size: cv2.resize(frame, size))\n  File \"/home/mendel/tinyml_autopilot/tinyml-env/lib/python3.7/site-packages/pycoral/adapters/common.py\", line 92, in set_resized_input\n    w, h = size\nTypeError: cannot unpack non-iterable int object.",
          "calculatedTotalCost": 0.0,
          "completionTokens": 0,
          "environment": "default",
          "totalTokens": 0,
          "promptTokens": 0,
          "costDetails": {},
          "endTime": null,
          "model": null,
          "modelParameters": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null,
          "latency": null
        }
      ],
      "createdAt": "2025-12-11T00:53:54.377Z",
      "updatedAt": "2025-12-11T00:56:50.117Z",
      "environment": "default"
    },
    {
      "id": "f5364ed4",
      "timestamp": "2025-12-11T00:50:38.375000+00:00",
      "name": "f536_tpu_sketch_generator",
      "input": null,
      "output": {
        "status": "failed",
        "last_code": "import os\nimport cv2\nimport numpy as np\nfrom PIL import Image\nfrom pycoral.adapters.common import input_size\nfrom pycoral.adapters.detect import get_objects\nfrom pycoral.utils.dataset import read_label_file\nfrom pycoral.utils.edgetpu import make_interpreter\n\n# Configuration parameters\nmodel_path = '/home/mendel/tinyml_autopilot/models/edgetpu_detect.tflite'\nlabel_path = '/home/mendel/tinyml_autopilot/models/labelmap.txt'\ninput_path = '/home/mendel/tinyml_autopilot/data/sheeps.mp4'\noutput_path = '/home/mendel/tinyml_autopilot/results/sheeps_detections.mp4'\nconfidence_threshold = 0.5\n\n# Setup: Load the TFLite interpreter for TPU\ninterpreter = make_interpreter(model_path, device=':0')\ninterpreter.allocate_tensors()\n\n# Load all labels from the provided label map\nlabels = read_label_file(label_path)\n\n# Preprocessing function to resize and normalize input image\ndef preprocess_image(image):\n    resized_img = Image.fromarray(cv2.cvtColor(image, cv2.COLOR_BGR2RGB)).resize(input_size(interpreter), Image.ANTIALIAS)\n    return np.array(resized_img).astype(np.uint8)\n\n# Function to draw detection boxes with labels on the frame\ndef draw_detections(frame, objs):\n    for obj in objs:\n        if obj.score >= confidence_threshold:\n            bbox = obj.bbox\n            cv2.rectangle(frame, (bbox.xmin, bbox.ymin), (bbox.xmax, bbox.ymax), (0, 255, 0), 2)\n            label = f'{labels.get(obj.id, obj.id)}: {obj.score:.2f}'\n            cv2.putText(frame, label, (bbox.xmin, bbox.ymin - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n\n# Read input video and prepare output video writer\ncap = cv2.VideoCapture(input_path)\nwidth = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\nheight = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\nfps = cap.get(cv2.CAP_PROP_FPS)\nfourcc = cv2.VideoWriter_fourcc(*'mp4v')\nout = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n\n# Process and run inference for each frame\nwhile cap.isOpened():\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    # Preprocess the image\n    input_tensor = preprocess_image(frame)\n    interpreter.set_input(input_tensor)\n\n    # Run inference\n    interpreter.invoke()\n\n    # Get detection results\n    objs = get_objects(interpreter, confidence_threshold)\n\n    # Draw detections on the frame\n    draw_detections(frame, objs)\n\n    # Write the output frame\n    out.write(frame)\n\n# Release resources\ncap.release()\nout.release()\ncv2.destroyAllWindows()",
        "last_error": "Max retries reached with error. Last error: Traceback (most recent call last):\n  File \"script_f8a7d3fb_1765414399.py\", line 54, in <module>\n    interpreter.set_input(input_tensor)\nAttributeError: 'Interpreter' object has no attribute 'set_input'."
      },
      "session_id": "qwen2.5-coder:32b_a8a2_tpusg_batch",
      "metadata": {
        "num_run": 22
      },
      "tags": [
        "ablation",
        "benchmark",
        "qwen2.5-coder:32b",
        "tpu_sketch_generator"
      ],
      "latency": 169.866,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-02-50-38-376573_chatcmpl-de28798d-688c-4c23-bf7a-f4de189684a0",
          "traceId": "f5364ed4",
          "type": "GENERATION",
          "name": "f536_tpusg_gen_attempt#1",
          "startTime": "2025-12-11T00:50:38.376000+00:00",
          "endTime": "2025-12-11T00:51:06.884000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 28508.0,
          "completionTokens": 771,
          "environment": "default",
          "totalTokens": 1082,
          "promptTokens": 311,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-02-51-15-142292_chatcmpl-cc6da240-98c3-4d69-a320-8f47943d242f",
          "traceId": "f5364ed4",
          "type": "GENERATION",
          "name": "f536_tpusg_gen_attempt#2",
          "startTime": "2025-12-11T00:51:15.142000+00:00",
          "endTime": "2025-12-11T00:51:40.820000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 25678.0,
          "completionTokens": 696,
          "environment": "default",
          "totalTokens": 1007,
          "promptTokens": 311,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-02-51-48-822344_chatcmpl-c64db00d-121c-4e2b-9fff-b3d91b232c54",
          "traceId": "f5364ed4",
          "type": "GENERATION",
          "name": "f536_tpusg_gen_attempt#3",
          "startTime": "2025-12-11T00:51:48.822000+00:00",
          "endTime": "2025-12-11T00:52:16.091000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 27269.0,
          "completionTokens": 739,
          "environment": "default",
          "totalTokens": 1050,
          "promptTokens": 311,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-02-52-23-900880_chatcmpl-09146ccc-07a4-4264-8d41-9d44571e33be",
          "traceId": "f5364ed4",
          "type": "GENERATION",
          "name": "f536_tpusg_gen_attempt#4",
          "startTime": "2025-12-11T00:52:23.900000+00:00",
          "endTime": "2025-12-11T00:52:47.716000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 23816.0,
          "completionTokens": 646,
          "environment": "default",
          "totalTokens": 957,
          "promptTokens": 311,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-02-52-56-567103_chatcmpl-d1e862cf-d4c7-436f-8125-3e3b74f67ace",
          "traceId": "f5364ed4",
          "type": "GENERATION",
          "name": "f536_tpusg_gen_attempt#5",
          "startTime": "2025-12-11T00:52:56.567000+00:00",
          "endTime": "2025-12-11T00:53:19.615000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 23048.0,
          "completionTokens": 625,
          "environment": "default",
          "totalTokens": 936,
          "promptTokens": 311,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "2be18aec-e06a-46dc-b807-ca135056b8be",
          "traceId": "f5364ed4",
          "type": "SPAN",
          "name": "error_f5_tpusg_failure_signal_tpu_sketch_generator",
          "startTime": "2025-12-11T00:53:28.242000+00:00",
          "level": "ERROR",
          "statusMessage": "Failed: Max retries reached with error. Last error: Traceback (most recent call last):\n  File \"script_f8a7d3fb_1765414399.py\", line 54, in <module>\n    interpreter.set_input(input_tensor)\nAttributeError: 'Interpreter' object has no attribute 'set_input'.",
          "calculatedTotalCost": 0.0,
          "completionTokens": 0,
          "environment": "default",
          "totalTokens": 0,
          "promptTokens": 0,
          "costDetails": {},
          "endTime": null,
          "model": null,
          "modelParameters": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null,
          "latency": null
        }
      ],
      "createdAt": "2025-12-11T00:50:38.896Z",
      "updatedAt": "2025-12-11T00:53:33.596Z",
      "environment": "default"
    },
    {
      "id": "76b4c874",
      "timestamp": "2025-12-11T00:47:18.472000+00:00",
      "name": "76b4_tpu_sketch_generator",
      "input": null,
      "output": {
        "status": "failed",
        "last_code": "import os\nimport numpy as np\nimport cv2\nfrom PIL import Image\nfrom pycoral.utils.edgetpu import make_interpreter\nfrom pycoral.adapters import common, detect\n\n# Configuration parameters\nmodel_path = '/home/mendel/tinyml_autopilot/models/edgetpu_detect.tflite'\nlabel_path = '/home/mendel/tinyml_autopilot/models/labelmap.txt'\ninput_path = '/home/mendel/tinyml_autopilot/data/sheeps.mp4'\noutput_path = '/home/mendel/tinyml_autopilot/results/sheeps_detections.mp4'\nconfidence_threshold = 0.5\n\n# Load labels\ndef load_labels(label_path):\n    with open(label_path, 'r', encoding='utf-8') as f:\n        lines = f.readlines()\n    return {int(line.split(' ', maxsplit=1)[0]): line.strip() for line in lines if line}\n\nlabels = load_labels(label_path)\n\n# Load TFLite interpreter for TPU\ninterpreter = make_interpreter(model_path)\ninterpreter.allocate_tensors()\n\n# Read video from the input path\ncap = cv2.VideoCapture(input_path)\nif not cap.isOpened():\n    raise IOError(\"Cannot open video\")\n\n# Get video properties to set up output video\nframe_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\nframe_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\nfps = cap.get(cv2.CAP_PROP_FPS)\n\n# Define the codec and create VideoWriter object\nfourcc = cv2.VideoWriter_fourcc(*'mp4v')\nout = cv2.VideoWriter(output_path, fourcc, fps, (frame_width, frame_height))\n\ndef draw_detection_boxes(image, detections, labels):\n    for obj in detections:\n        bbox = obj.bbox\n        label = labels.get(obj.id, 'Unknown')\n        score = obj.score\n        if score >= confidence_threshold:\n            x0, y0, x1, y1 = int(bbox.xmin), int(bbox.ymin), int(bbox.xmax), int(bbox.ymax)\n            cv2.rectangle(image, (x0, y0), (x1, y1), (0, 255, 0), 2)\n            label_text = f'{label}: {score:.2f}'\n            label_size, _ = cv2.getTextSize(label_text, cv2.FONT_HERSHEY_SIMPLEX, 0.7, 1)\n            cv2.rectangle(image, (x0, y0 - label_size[1] - 5), (x0 + label_size[0], y0 - 5), (0, 255, 0), -1)\n            cv2.putText(image, label_text, (x0, y0 - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 0), 1)\n\n# Process each frame\nwhile cap.isOpened():\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    # Convert the frame to RGB and resize for inference\n    img = Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n    resized_img = img.resize((300, 300), Image.ANTIALIAS)\n\n    # Preprocess image\n    input_details = interpreter.get_input_details()\n    input_scale = input_details[0]['quantization'][0]\n    input_zero_point = input_details[0]['quantization'][1]\n    if np.issubdtype(input_details[0]['dtype'], np.integer):\n        img_array = np.array(resized_img, dtype=np.uint8)\n        img_array = (img_array - input_zero_point) / input_scale\n    else:\n        img_array = np.array(resized_img).astype(np.float32)\n\n    input_tensor = common.input_details(interpreter)[0]['index']\n    interpreter.set_tensor(input_tensor, np.expand_dims(img_array, axis=0))\n\n    # Run inference\n    interpreter.invoke()\n\n    # Extract results\n    detections = detect.get_objects(interpreter, confidence_threshold)\n\n    # Draw detection boxes on the frame\n    draw_detection_boxes(frame, detections, labels)\n\n    # Write the processed frame to the output video\n    out.write(frame)\n\n# Release resources\ncap.release()\nout.release()\ncv2.destroyAllWindows()",
        "last_error": "Max retries reached with error. Last error: Traceback (most recent call last):\n  File \"script_adf87749_1765414202.py\", line 21, in <module>\n    labels = load_labels(label_path)\n  File \"script_adf87749_1765414202.py\", line 19, in load_labels\n    return {int(line.split(' ', maxsplit=1)[0]): line.strip() for line in lines if line}\n  File \"script_adf87749_1765414202.py\", line 19, in <dictcomp>\n    return {int(line.split(' ', maxsplit=1)[0]): line.strip() for line in lines if line}\nValueError: invalid literal for int() with base 10: 'person\\n'."
      },
      "session_id": "qwen2.5-coder:32b_a8a2_tpusg_batch",
      "metadata": {
        "num_run": 21
      },
      "tags": [
        "ablation",
        "benchmark",
        "qwen2.5-coder:32b",
        "tpu_sketch_generator"
      ],
      "latency": 172.154,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-02-47-18-474090_chatcmpl-93d0ca9b-9613-40d5-b9db-b66b1c11ce67",
          "traceId": "76b4c874",
          "type": "GENERATION",
          "name": "76b4_tpusg_gen_attempt#1",
          "startTime": "2025-12-11T00:47:18.474000+00:00",
          "endTime": "2025-12-11T00:47:46.552000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 28078.0,
          "completionTokens": 759,
          "environment": "default",
          "totalTokens": 1070,
          "promptTokens": 311,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-02-47-54-426727_chatcmpl-dd260ebe-803c-4da6-bb2e-7e7078d2d534",
          "traceId": "76b4c874",
          "type": "GENERATION",
          "name": "76b4_tpusg_gen_attempt#2",
          "startTime": "2025-12-11T00:47:54.426000+00:00",
          "endTime": "2025-12-11T00:48:16.883000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 22457.0,
          "completionTokens": 609,
          "environment": "default",
          "totalTokens": 920,
          "promptTokens": 311,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-02-48-25-016659_chatcmpl-9ea9d950-13c7-4031-ab3b-3b02603ca513",
          "traceId": "76b4c874",
          "type": "GENERATION",
          "name": "76b4_tpusg_gen_attempt#3",
          "startTime": "2025-12-11T00:48:25.016000+00:00",
          "endTime": "2025-12-11T00:48:47.010000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 21994.0,
          "completionTokens": 597,
          "environment": "default",
          "totalTokens": 908,
          "promptTokens": 311,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-02-48-55-122994_chatcmpl-70b85be7-07e7-44f5-9fb5-8d356e7258d9",
          "traceId": "76b4c874",
          "type": "GENERATION",
          "name": "76b4_tpusg_gen_attempt#4",
          "startTime": "2025-12-11T00:48:55.122000+00:00",
          "endTime": "2025-12-11T00:49:19.621000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 24499.0,
          "completionTokens": 664,
          "environment": "default",
          "totalTokens": 975,
          "promptTokens": 311,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-02-49-27-646484_chatcmpl-1adabe09-1875-4983-b503-09bf4b264a9c",
          "traceId": "76b4c874",
          "type": "GENERATION",
          "name": "76b4_tpusg_gen_attempt#5",
          "startTime": "2025-12-11T00:49:27.646000+00:00",
          "endTime": "2025-12-11T00:50:02.694000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 35048.0,
          "completionTokens": 948,
          "environment": "default",
          "totalTokens": 1259,
          "promptTokens": 311,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "f9339223-64bc-4d18-9942-bcaea8c1a1bd",
          "traceId": "76b4c874",
          "type": "SPAN",
          "name": "error_76_tpusg_failure_signal_tpu_sketch_generator",
          "startTime": "2025-12-11T00:50:10.628000+00:00",
          "level": "ERROR",
          "statusMessage": "Failed: Max retries reached with error. Last error: Traceback (most recent call last):\n  File \"script_adf87749_1765414202.py\", line 21, in <module>\n    labels = load_labels(label_path)\n  File \"script_adf87749_1765414202.py\", line 19, in load_labels\n    return {int(line.split(' ', maxsplit=1)[0]): line.strip() for line in lines if line}\n  File \"script_adf87749_1765414202.py\", line 19, in <dictcomp>\n    return {int(line.split(' ', maxsplit=1)[0]): line.strip() for line in lines if line}\nValueError: invalid literal for int() with base 10: 'person\\n'.",
          "calculatedTotalCost": 0.0,
          "completionTokens": 0,
          "environment": "default",
          "totalTokens": 0,
          "promptTokens": 0,
          "costDetails": {},
          "endTime": null,
          "model": null,
          "modelParameters": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null,
          "latency": null
        }
      ],
      "createdAt": "2025-12-11T00:47:18.991Z",
      "updatedAt": "2025-12-11T00:50:16.177Z",
      "environment": "default"
    },
    {
      "id": "4d208cb6",
      "timestamp": "2025-12-11T00:43:48.496000+00:00",
      "name": "4d20_tpu_sketch_generator",
      "input": null,
      "output": {
        "status": "success",
        "sketch": "import os\nimport cv2\nimport numpy as np\nfrom PIL import Image\nfrom pycoral.adapters.common import input_size\nfrom pycoral.adapters.detect import get_objects\nfrom pycoral.utils.dataset import read_label_file\nfrom pycoral.utils.edgetpu import make_interpreter\n\n# Configuration parameters\nmodel_path = '/home/mendel/tinyml_autopilot/models/edgetpu_detect.tflite'\nlabel_path = '/home/mendel/tinyml_autopilot/models/labelmap.txt'\ninput_path = '/home/mendel/tinyml_autopilot/data/sheeps.mp4'\noutput_path = '/home/mendel/tinyml_autopilot/results/sheeps_detections.mp4'\nconfidence_threshold = 0.5\n\n# Phase 1: Setup\ninterpreter = make_interpreter(model_path, device=':0')\ninterpreter.allocate_tensors()\nlabels = read_label_file(label_path)\n_, height, width, _ = interpreter.get_input_details()[0]['shape']\n\n# Phase 2: Preprocessing and Inference\ncap = cv2.VideoCapture(input_path)\nfourcc = cv2.VideoWriter_fourcc(*'mp4v')\nout = cv2.VideoWriter(output_path, fourcc, cap.get(cv2.CAP_PROP_FPS), (int(cap.get(3)), int(cap.get(4))))\n\nwhile cap.isOpened():\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    # Resize and normalize the image\n    img = Image.fromarray(frame).convert('RGB').resize((width, height), Image.ANTIALIAS)\n    input_tensor = np.array(img)\n    input_details = interpreter.get_input_details()[0]['index']\n    interpreter.set_tensor(input_details, np.expand_dims(input_tensor, axis=0))\n\n    # Run inference\n    interpreter.invoke()\n    objs = get_objects(interpreter, score_threshold=confidence_threshold)\n\n    # Phase 4: Output handling - Draw detection boxes with labels\n    for obj in objs:\n        bbox = obj.bbox\n        x1, y1 = int(bbox.xmin * width), int(bbox.ymin * height)\n        x2, y2 = int(bbox.xmax * width), int(bbox.ymax * height)\n        cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n        label = labels.get(obj.id, obj.id)\n        score = float(obj.score)\n        text = f'{label}: {score:.2f}'\n        cv2.putText(frame, text, (x1, y1 - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n\n    out.write(frame)\n\ncap.release()\nout.release()"
      },
      "session_id": "qwen2.5-coder:32b_a8a2_tpusg_batch",
      "metadata": {
        "num_run": 20
      },
      "tags": [
        "ablation",
        "benchmark",
        "qwen2.5-coder:32b",
        "tpu_sketch_generator"
      ],
      "latency": 129.015,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-02-43-48-496999_chatcmpl-039476b2-9639-42f5-bfb3-9c22f3832032",
          "traceId": "4d208cb6",
          "type": "GENERATION",
          "name": "4d20_tpusg_gen_attempt#1",
          "startTime": "2025-12-11T00:43:48.496000+00:00",
          "endTime": "2025-12-11T00:44:14.476000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 25980.0,
          "completionTokens": 651,
          "environment": "default",
          "totalTokens": 962,
          "promptTokens": 311,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-02-44-22-545875_chatcmpl-a293d93b-469f-4f4c-81ab-8cdb4d53cec4",
          "traceId": "4d208cb6",
          "type": "GENERATION",
          "name": "4d20_tpusg_gen_attempt#2",
          "startTime": "2025-12-11T00:44:22.545000+00:00",
          "endTime": "2025-12-11T00:44:53.352000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 30807.0,
          "completionTokens": 834,
          "environment": "default",
          "totalTokens": 1145,
          "promptTokens": 311,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-02-45-01-983058_chatcmpl-288fe2ee-649f-4ac6-a30c-99f3e7ded91f",
          "traceId": "4d208cb6",
          "type": "GENERATION",
          "name": "4d20_tpusg_gen_attempt#3",
          "startTime": "2025-12-11T00:45:01.983000+00:00",
          "endTime": "2025-12-11T00:45:25.547000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 23564.0,
          "completionTokens": 639,
          "environment": "default",
          "totalTokens": 950,
          "promptTokens": 311,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-02-45-33-759748_chatcmpl-84cedb2d-d21e-4530-94aa-2640c696bec0",
          "traceId": "4d208cb6",
          "type": "GENERATION",
          "name": "4d20_tpusg_gen_attempt#4",
          "startTime": "2025-12-11T00:45:33.759000+00:00",
          "endTime": "2025-12-11T00:45:57.511000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 23752.0,
          "completionTokens": 644,
          "environment": "default",
          "totalTokens": 955,
          "promptTokens": 311,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        }
      ],
      "createdAt": "2025-12-11T00:43:49.027Z",
      "updatedAt": "2025-12-11T00:46:58.870Z",
      "environment": "default"
    },
    {
      "id": "9f1c8442",
      "timestamp": "2025-12-11T00:41:05.527000+00:00",
      "name": "9f1c_tpu_sketch_generator",
      "input": null,
      "output": {
        "status": "success",
        "sketch": "import os\nimport cv2\nimport numpy as np\nfrom PIL import Image\nimport tflite_runtime.interpreter as tflite\nfrom pycoral.adapters import common, detect\nfrom pycoral.utils.dataset import read_label_file\n\n# Configuration parameters\nmodel_path = '/home/mendel/tinyml_autopilot/models/edgetpu_detect.tflite'\nlabel_path = '/home/mendel/tinyml_autopilot/models/labelmap.txt'\ninput_path = '/home/mendel/tinyml_autopilot/data/sheeps.mp4'\noutput_path = '/home/mendel/tinyml_autopilot/results/sheeps_detections.mp4'\nconfidence_threshold = 0.5\n\n# Load the TFLite interpreter for TPU\ninterpreter = tflite.Interpreter(model_path=model_path, experimental_delegates=[tflite.load_delegate('/usr/lib/aarch64-linux-gnu/libedgetpu.so.1.0')])\ninterpreter.allocate_tensors()\n\n# Get model details\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\nheight = input_details[0]['shape'][1]\nwidth = input_details[0]['shape'][2]\n\n# Load labels\nlabels = read_label_file(label_path)\n\n# Open the video file for reading\ncap = cv2.VideoCapture(input_path)\nif not cap.isOpened():\n    raise IOError(\"Cannot open video file\")\n\n# Define the codec and create VideoWriter object\nfourcc = cv2.VideoWriter_fourcc(*'mp4v')\nout = cv2.VideoWriter(output_path, fourcc, 30.0, (int(cap.get(3)), int(cap.get(4))))\n\ndef draw_detection_boxes(image, detections):\n    for obj in detections:\n        bbox = obj.bbox\n        score = obj.score\n        label = labels[obj.id]\n        if score > confidence_threshold:\n            # Draw bounding box\n            cv2.rectangle(image, (bbox.xmin, bbox.ymin), (bbox.xmax, bbox.ymax), (0, 255, 0), 2)\n            # Draw label and score\n            label_text = f'{label}: {score:.2f}'\n            cv2.putText(image, label_text, (bbox.xmin, bbox.ymin - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n\n# Process video frame by frame\nwhile cap.isOpened():\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    # Preprocessing: Resize and normalize image\n    img = Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n    resized_img = img.resize((width, height), Image.ANTIALIAS)\n    input_data = np.array(resized_img)\n\n    # Run inference\n    common.set_input(interpreter, input_data)\n    interpreter.invoke()\n    detections = detect.get_objects(interpreter, confidence_threshold)\n\n    # Draw detection boxes on the frame\n    draw_detection_boxes(frame, detections)\n\n    # Write the result to output video file\n    out.write(frame)\n\n# Release everything when job is finished\ncap.release()\nout.release()\ncv2.destroyAllWindows()"
      },
      "session_id": "qwen2.5-coder:32b_a8a2_tpusg_batch",
      "metadata": {
        "num_run": 19
      },
      "tags": [
        "ablation",
        "benchmark",
        "qwen2.5-coder:32b",
        "tpu_sketch_generator"
      ],
      "latency": 29.345,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-02-41-05-528525_chatcmpl-56bd9202-2a3d-404a-9cae-04ab2f20361b",
          "traceId": "9f1c8442",
          "type": "GENERATION",
          "name": "9f1c_tpusg_gen_attempt#1",
          "startTime": "2025-12-11T00:41:05.528000+00:00",
          "endTime": "2025-12-11T00:41:34.873000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 29345.0,
          "completionTokens": 664,
          "environment": "default",
          "totalTokens": 975,
          "promptTokens": 311,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        }
      ],
      "createdAt": "2025-12-11T00:41:06.048Z",
      "updatedAt": "2025-12-11T00:43:30.309Z",
      "environment": "default"
    },
    {
      "id": "5f9c5fbd",
      "timestamp": "2025-12-11T00:38:47.557000+00:00",
      "name": "5f9c_tpu_sketch_generator",
      "input": null,
      "output": {
        "status": "success",
        "sketch": "import os\nimport numpy as np\nimport cv2\nfrom PIL import Image\nfrom pycoral.adapters.common import input_size\nfrom pycoral.adapters.detect import get_objects\nfrom pycoral.utils.dataset import read_label_file\nfrom pycoral.utils.edgetpu import make_interpreter\n\n# Configuration parameters\nmodel_path = '/home/mendel/tinyml_autopilot/models/edgetpu_detect.tflite'\nlabel_path = '/home/mendel/tinyml_autopilot/models/labelmap.txt'\ninput_path = '/home/mendel/tinyml_autopilot/data/sheeps.mp4'\noutput_path = '/home/mendel/tinyml_autopilot/results/sheeps_detections.mp4'\nconfidence_threshold = 0.5\n\n# Load TFLite interpreter with Edge TPU\ninterpreter = make_interpreter(model_path, device=':0')\ninterpreter.allocate_tensors()\n\n# Read labels from label map file\nlabels = read_label_file(label_path)\n\n# Get input size for the model\ninput_size_w, input_size_h = input_size(interpreter)\n\n# Open video file\ncap = cv2.VideoCapture(input_path)\nif not cap.isOpened():\n    raise SystemExit('Could not open video')\n\n# Define codec and create VideoWriter object\nfourcc = cv2.VideoWriter_fourcc(*'mp4v')\nfps = int(cap.get(cv2.CAP_PROP_FPS))\nwidth = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\nheight = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\nout = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n\n# Process video frame by frame\nwhile cap.isOpened():\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    # Preprocessing: resize and convert to RGB\n    im_pil = Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)).resize((input_size_w, input_size_h))\n    scale_factor_x = width / input_size_w\n    scale_factor_y = height / input_size_h\n\n    # Run inference\n    interpreter.set_tensor(interpreter.get_input_details()[0]['index'], np.array(im_pil).reshape(1, input_size_h, input_size_w, 3))\n    interpreter.invoke()\n\n    # Get detection results and filter based on confidence threshold\n    objects = get_objects(interpreter, confidence_threshold)\n    for obj in objects:\n        bbox = obj.bbox.scale(scale_factor_x, scale_factor_y)\n        start_point = (int(bbox.xmin), int(bbox.ymin))\n        end_point = (int(bbox.xmax), int(bbox.ymax))\n        label_text = f'{labels.get(obj.id, \"Unknown\")}: {obj.score:0.2f}'\n\n        # Draw bounding box and label\n        cv2.rectangle(frame, start_point, end_point, (0, 255, 0), 2)\n        cv2.putText(frame, label_text, (start_point[0], start_point[1] - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n\n    # Write the frame to output video\n    out.write(frame)\n\n# Release resources\ncap.release()\nout.release()\ncv2.destroyAllWindows()"
      },
      "session_id": "qwen2.5-coder:32b_a8a2_tpusg_batch",
      "metadata": {
        "num_run": 18
      },
      "tags": [
        "ablation",
        "benchmark",
        "qwen2.5-coder:32b",
        "tpu_sketch_generator"
      ],
      "latency": 60.448,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-02-38-47-558581_chatcmpl-69ad6b91-ce14-42fd-a41f-e432ba347905",
          "traceId": "5f9c5fbd",
          "type": "GENERATION",
          "name": "5f9c_tpusg_gen_attempt#1",
          "startTime": "2025-12-11T00:38:47.558000+00:00",
          "endTime": "2025-12-11T00:39:12.536000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 24978.0,
          "completionTokens": 675,
          "environment": "default",
          "totalTokens": 986,
          "promptTokens": 311,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-02-39-20-689884_chatcmpl-b3ae753a-3992-4659-99bd-4903fab4c46b",
          "traceId": "5f9c5fbd",
          "type": "GENERATION",
          "name": "5f9c_tpusg_gen_attempt#2",
          "startTime": "2025-12-11T00:39:20.689000+00:00",
          "endTime": "2025-12-11T00:39:48.006000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 27317.0,
          "completionTokens": 740,
          "environment": "default",
          "totalTokens": 1051,
          "promptTokens": 311,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        }
      ],
      "createdAt": "2025-12-11T00:38:48.076Z",
      "updatedAt": "2025-12-11T00:40:46.221Z",
      "environment": "default"
    },
    {
      "id": "930130e9",
      "timestamp": "2025-12-11T00:37:04.356000+00:00",
      "name": "9301_tpu_sketch_generator",
      "input": null,
      "output": {
        "status": "success",
        "sketch": "import os\nimport cv2\nimport numpy as np\nfrom PIL import Image\nfrom pycoral.adapters import common\nfrom pycoral.adapters.detect import get_objects\nfrom pycoral.utils.dataset import read_label_file\nfrom pycoral.utils.edgetpu import make_interpreter\n\n# Configuration parameters\nmodel_path = '/home/mendel/tinyml_autopilot/models/edgetpu_detect.tflite'\nlabel_path = '/home/mendel/tinyml_autopilot/models/labelmap.txt'\ninput_path = '/home/mendel/tinyml_autopilot/data/sheeps.mp4'\noutput_path = '/home/mendel/tinyml_autopilot/results/sheeps_detections.mp4'\nconfidence_threshold = 0.5\n\n# Load the TFLite interpreter with TPU support\ninterpreter = make_interpreter(model_path)\ninterpreter.allocate_tensors()\n\n# Read labels\nlabels = read_label_file(label_path)\n\n# Initialize video capture and writer\ncap = cv2.VideoCapture(input_path)\nfps = cap.get(cv2.CAP_PROP_FPS)\nwidth = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\nheight = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n\nfourcc = cv2.VideoWriter_fourcc(*'mp4v')\nout = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n\ndef draw_detection_boxes(frame, detections):\n    for obj in detections:\n        if obj.score >= confidence_threshold:\n            bbox = obj.bbox\n            start_point = (int(bbox.xmin * width), int(bbox.ymin * height))\n            end_point = (int(bbox.xmax * width), int(bbox.ymax * height))\n            cv2.rectangle(frame, start_point, end_point, (0, 255, 0), 2)\n            label = f'{labels.get(obj.id, \"Unknown\")}: {obj.score:.2f}'\n            cv2.putText(frame, label, (start_point[0], start_point[1] - 10),\n                        cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n\nwhile cap.isOpened():\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    # Preprocess the image\n    img = Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n    resized_img = img.resize((300, 300), Image.ANTIALIAS)\n\n    # Run inference\n    common.set_input(interpreter, resized_img)\n    interpreter.invoke()\n    detections = get_objects(interpreter, confidence_threshold)[:]\n\n    # Draw detection boxes\n    draw_detection_boxes(frame, detections)\n\n    # Write the frame to the output video file\n    out.write(frame)\n\n# Release resources\ncap.release()\nout.release()\ncv2.destroyAllWindows()"
      },
      "session_id": "qwen2.5-coder:32b_a8a2_tpusg_batch",
      "metadata": {
        "num_run": 17
      },
      "tags": [
        "ablation",
        "benchmark",
        "qwen2.5-coder:32b",
        "tpu_sketch_generator"
      ],
      "latency": 21.76,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-02-37-04-358089_chatcmpl-28fe40b1-3969-43bd-afab-c329877ea012",
          "traceId": "930130e9",
          "type": "GENERATION",
          "name": "9301_tpusg_gen_attempt#1",
          "startTime": "2025-12-11T00:37:04.358000+00:00",
          "endTime": "2025-12-11T00:37:26.118000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 21760.0,
          "completionTokens": 589,
          "environment": "default",
          "totalTokens": 900,
          "promptTokens": 311,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        }
      ],
      "createdAt": "2025-12-11T00:37:04.876Z",
      "updatedAt": "2025-12-11T00:38:27.606Z",
      "environment": "default"
    },
    {
      "id": "613745c0",
      "timestamp": "2025-12-11T00:34:05.314000+00:00",
      "name": "6137_tpu_sketch_generator",
      "input": null,
      "output": {
        "status": "failed",
        "last_code": "import numpy as np\nimport cv2\nfrom PIL import Image\nfrom pycoral.adapters.common import input_size\nfrom pycoral.adapters.detect import get_objects\nfrom pycoral.utils.dataset import read_label_file\nfrom pycoral.utils.edgetpu import make_interpreter\n\n# Configuration parameters\nmodel_path = '/home/mendel/tinyml_autopilot/models/edgetpu_detect.tflite'\nlabel_path = '/home/mendel/tinyml_autopilot/models/labelmap.txt'\ninput_path = '/home/mendel/tinyml_autopilot/data/sheeps.mp4'\noutput_path = '/home/mendel/tinyml_autopilot/results/sheeps_detections.mp4'\nconfidence_threshold = 0.5\n\n# Load TFLite interpreter with TPU support\ninterpreter = make_interpreter(model_path)\ninterpreter.allocate_tensors()\n\n# Read labels\nlabels = read_label_file(label_path)\n\n# Open input video file\ncap = cv2.VideoCapture(input_path)\n\nif not cap.isOpened():\n    raise IOError(\"Cannot open video file\")\n\n# Get video properties\nwidth = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\nheight = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\nfps = cap.get(cv2.CAP_PROP_FPS)\n\n# Define the codec and create VideoWriter object\nfourcc = cv2.VideoWriter_fourcc(*'mp4v')\nout = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n\nwhile cap.isOpened():\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    # Preprocessing: Convert the frame to a tensor\n    image = Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n    resized_image = image.resize(input_size(interpreter), Image.ANTIALIAS)\n    input_tensor = np.array(resized_image)\n\n    # Inference: Run the model on the TPU\n    interpreter.set_input(0, input_tensor.flatten())\n    interpreter.invoke()\n\n    # Post-processing: Draw detection boxes and labels\n    detected_objects = get_objects(interpreter, confidence_threshold)[:10]\n    for obj in detected_objects:\n        box = obj.bbox\n        label = f'{labels.get(obj.id, obj.id)} {obj.score:.2f}'\n        x0, y0 = int(box.xmin * width), int(box.ymin * height)\n        x1, y1 = int(box.xmax * width), int(box.ymax * height)\n\n        cv2.rectangle(frame, (x0, y0), (x1, y1), (0, 255, 0), 2)\n        cv2.putText(frame, label, (x0, y0 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n\n    # Write the frame with detections to the output file\n    out.write(frame)\n\n# Release resources\ncap.release()\nout.release()\ncv2.destroyAllWindows()",
        "last_error": "Max retries reached with error. Last error: Traceback (most recent call last):\n  File \"script_359c8ab1_1765413390.py\", line 49, in <module>\n    interpreter.set_input(0, input_tensor.flatten())\nAttributeError: 'Interpreter' object has no attribute 'set_input'."
      },
      "session_id": "qwen2.5-coder:32b_a8a2_tpusg_batch",
      "metadata": {
        "num_run": 16
      },
      "tags": [
        "ablation",
        "benchmark",
        "qwen2.5-coder:32b",
        "tpu_sketch_generator"
      ],
      "latency": 154.301,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-02-34-05-315347_chatcmpl-40383bb5-473c-44d8-8e8c-19e5779e0978",
          "traceId": "613745c0",
          "type": "GENERATION",
          "name": "6137_tpusg_gen_attempt#1",
          "startTime": "2025-12-11T00:34:05.315000+00:00",
          "endTime": "2025-12-11T00:34:25.220000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 19905.0,
          "completionTokens": 538,
          "environment": "default",
          "totalTokens": 849,
          "promptTokens": 311,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-02-34-33-446510_chatcmpl-ca087909-e21b-4a86-a817-7127c9e254f1",
          "traceId": "613745c0",
          "type": "GENERATION",
          "name": "6137_tpusg_gen_attempt#2",
          "startTime": "2025-12-11T00:34:33.446000+00:00",
          "endTime": "2025-12-11T00:34:55.854000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 22408.0,
          "completionTokens": 608,
          "environment": "default",
          "totalTokens": 919,
          "promptTokens": 311,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-02-35-04-510209_chatcmpl-78719745-129a-4f3d-bad4-90e2bb86db5a",
          "traceId": "613745c0",
          "type": "GENERATION",
          "name": "6137_tpusg_gen_attempt#3",
          "startTime": "2025-12-11T00:35:04.510000+00:00",
          "endTime": "2025-12-11T00:35:27.472000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 22962.0,
          "completionTokens": 623,
          "environment": "default",
          "totalTokens": 934,
          "promptTokens": 311,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-02-35-36-203396_chatcmpl-e4a45e77-7ffc-46d4-917d-bb70a01fc15f",
          "traceId": "613745c0",
          "type": "GENERATION",
          "name": "6137_tpusg_gen_attempt#4",
          "startTime": "2025-12-11T00:35:36.203000+00:00",
          "endTime": "2025-12-11T00:35:59.878000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 23675.0,
          "completionTokens": 642,
          "environment": "default",
          "totalTokens": 953,
          "promptTokens": 311,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-02-36-07-781495_chatcmpl-5b78f8dc-3772-4e1e-ba1a-99f0065f4dec",
          "traceId": "613745c0",
          "type": "GENERATION",
          "name": "6137_tpusg_gen_attempt#5",
          "startTime": "2025-12-11T00:36:07.781000+00:00",
          "endTime": "2025-12-11T00:36:30.849000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 23068.0,
          "completionTokens": 626,
          "environment": "default",
          "totalTokens": 937,
          "promptTokens": 311,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "970c969f-e857-4dd3-9488-ac0c77a43b48",
          "traceId": "613745c0",
          "type": "SPAN",
          "name": "error_61_tpusg_failure_signal_tpu_sketch_generator",
          "startTime": "2025-12-11T00:36:39.616000+00:00",
          "level": "ERROR",
          "statusMessage": "Failed: Max retries reached with error. Last error: Traceback (most recent call last):\n  File \"script_359c8ab1_1765413390.py\", line 49, in <module>\n    interpreter.set_input(0, input_tensor.flatten())\nAttributeError: 'Interpreter' object has no attribute 'set_input'.",
          "calculatedTotalCost": 0.0,
          "completionTokens": 0,
          "environment": "default",
          "totalTokens": 0,
          "promptTokens": 0,
          "costDetails": {},
          "endTime": null,
          "model": null,
          "modelParameters": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null,
          "latency": null
        }
      ],
      "createdAt": "2025-12-11T00:34:05.833Z",
      "updatedAt": "2025-12-11T00:36:45.037Z",
      "environment": "default"
    },
    {
      "id": "8cc080d6",
      "timestamp": "2025-12-11T00:30:39.321000+00:00",
      "name": "8cc0_tpu_sketch_generator",
      "input": null,
      "output": {
        "status": "success",
        "sketch": "import cv2\nimport numpy as np\nfrom PIL import Image\nfrom pycoral.adapters.common import input_size\nfrom pycoral.adapters.detect import get_objects\nfrom pycoral.utils.dataset import read_label_file\nfrom pycoral.utils.edgetpu import make_interpreter\n\n# Configuration parameters\nmodel_path = '/home/mendel/tinyml_autopilot/models/edgetpu_detect.tflite'\nlabel_path = '/home/mendel/tinyml_autopilot/models/labelmap.txt'\ninput_path = '/home/mendel/tinyml_autopilot/data/sheeps.mp4'\noutput_path = '/home/mendel/tinyml_autopilot/results/sheeps_detections.mp4'\nconfidence_threshold = 0.5\n\n# Load TFLite model and allocate tensors\ninterpreter = make_interpreter(model_path, device=':0')\ninterpreter.allocate_tensors()\n\n# Get input and output details\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\n\n# Read labels\nlabels = read_label_file(label_path)\n\n# Open video file\ncap = cv2.VideoCapture(input_path)\nif not cap.isOpened():\n    raise RuntimeError(\"Error opening video stream or file\")\n\n# Get video properties\nframe_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\nframe_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\nfps = cap.get(cv2.CAP_PROP_FPS)\n\n# Define codec and create VideoWriter object\nfourcc = cv2.VideoWriter_fourcc(*'mp4v')\nout = cv2.VideoWriter(output_path, fourcc, fps, (frame_width, frame_height))\n\ndef draw_objects(frame, objs, labels):\n    for obj in objs:\n        bbox = obj.bbox\n        class_id = int(obj.id)\n        score = float(obj.score)\n        if score >= confidence_threshold:\n            label = f'{labels.get(class_id, \"Unknown\")}: {score:.2f}'\n            cv2.rectangle(frame, (bbox.xmin, bbox.ymin), (bbox.xmax, bbox.ymax), (0, 255, 0), 2)\n            cv2.putText(frame, label, (bbox.xmin, bbox.ymin - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (36,255,12), 2)\n\nwhile cap.isOpened():\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    # Preprocess frame\n    img = Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)).convert('RGB')\n    resized_img = img.resize(input_size(interpreter), Image.ANTIALIAS)\n    input_tensor = np.array(resized_img)\n\n    # Set model input\n    interpreter.set_tensor(input_details[0]['index'], np.expand_dims(input_tensor, axis=0))\n\n    # Run inference\n    interpreter.invoke()\n\n    # Get detection results\n    objs = get_objects(interpreter, confidence_threshold)[:5]\n\n    # Draw bounding boxes and labels on the frame\n    draw_objects(frame, objs, labels)\n\n    # Write the frame with detections to the output file\n    out.write(frame)\n\n# Release everything when job is finished\ncap.release()\nout.release()\ncv2.destroyAllWindows()"
      },
      "session_id": "qwen2.5-coder:32b_a8a2_tpusg_batch",
      "metadata": {
        "num_run": 15
      },
      "tags": [
        "ablation",
        "benchmark",
        "qwen2.5-coder:32b",
        "tpu_sketch_generator"
      ],
      "latency": 124.519,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-02-30-39-323237_chatcmpl-f84adc20-9ca4-49d3-b23a-5e80655ae355",
          "traceId": "8cc080d6",
          "type": "GENERATION",
          "name": "8cc0_tpusg_gen_attempt#1",
          "startTime": "2025-12-11T00:30:39.323000+00:00",
          "endTime": "2025-12-11T00:31:03.085000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 23762.0,
          "completionTokens": 643,
          "environment": "default",
          "totalTokens": 954,
          "promptTokens": 311,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-02-31-11-337504_chatcmpl-fd3c45ac-9409-4212-b7c4-68c226b42282",
          "traceId": "8cc080d6",
          "type": "GENERATION",
          "name": "8cc0_tpusg_gen_attempt#2",
          "startTime": "2025-12-11T00:31:11.337000+00:00",
          "endTime": "2025-12-11T00:31:33.497000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 22160.0,
          "completionTokens": 601,
          "environment": "default",
          "totalTokens": 912,
          "promptTokens": 311,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-02-31-42-157153_chatcmpl-3bb74c79-a61c-4324-a4fa-2fab4fe37c72",
          "traceId": "8cc080d6",
          "type": "GENERATION",
          "name": "8cc0_tpusg_gen_attempt#3",
          "startTime": "2025-12-11T00:31:42.157000+00:00",
          "endTime": "2025-12-11T00:32:10.242000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 28085.0,
          "completionTokens": 761,
          "environment": "default",
          "totalTokens": 1072,
          "promptTokens": 311,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-02-32-18-987618_chatcmpl-459aa847-a300-4319-8d42-4c6eea103f4a",
          "traceId": "8cc080d6",
          "type": "GENERATION",
          "name": "8cc0_tpusg_gen_attempt#4",
          "startTime": "2025-12-11T00:32:18.987000+00:00",
          "endTime": "2025-12-11T00:32:43.842000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 24855.0,
          "completionTokens": 674,
          "environment": "default",
          "totalTokens": 985,
          "promptTokens": 311,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        }
      ],
      "createdAt": "2025-12-11T00:30:39.840Z",
      "updatedAt": "2025-12-11T00:33:46.087Z",
      "environment": "default"
    },
    {
      "id": "a4ed7900",
      "timestamp": "2025-12-11T00:27:22.624000+00:00",
      "name": "a4ed_tpu_sketch_generator",
      "input": null,
      "output": {
        "status": "failed",
        "last_code": "import cv2\nimport numpy as np\nfrom PIL import Image\nfrom pycoral.utils.edgetpu import make_interpreter\nfrom pycoral.adapters.common import input_size, set_input\nfrom pycoral.adapters.detect import get_objects\n\n# Configuration parameters\nmodel_path = '/home/mendel/tinyml_autopilot/models/edgetpu_detect.tflite'\nlabel_path = '/home/mendel/tinyml_autopilot/models/labelmap.txt'\ninput_path = '/home/mendel/tinyml_autopilot/data/sheeps.mp4'\noutput_path = '/home/mendel/tinyml_autopilot/results/sheeps_detections.mp4'\nconfidence_threshold = 0.5\n\n# Load labels\ndef load_labels(label_path):\n    with open(label_path, 'r', encoding='utf-8') as f:\n        lines = f.readlines()\n    return {int(line.split(maxsplit=1)[0]): line.split(maxsplit=1)[1].strip() for line in lines}\n\nlabels = load_labels(label_path)\n\n# Setup TFLite interpreter for TPU\ninterpreter = make_interpreter(model_path, device=':0')\ninterpreter.allocate_tensors()\n\n# Read input video\ncap = cv2.VideoCapture(input_path)\nif not cap.isOpened():\n    raise RuntimeError(\"Error opening video file\")\n\n# Prepare output video writer\nframe_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\nframe_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\nfps = cap.get(cv2.CAP_PROP_FPS)\nfourcc = cv2.VideoWriter_fourcc(*'mp4v')\nout = cv2.VideoWriter(output_path, fourcc, fps, (frame_width, frame_height))\n\n# Process video frames\nwhile True:\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    # Preprocessing\n    img = Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n    resized_img = img.resize(input_size(interpreter), Image.ANTIALIAS)\n    set_input(interpreter, resized_img)\n\n    # Inference\n    interpreter.invoke()\n    detections = get_objects(interpreter, score_threshold=confidence_threshold)\n\n    # Draw detection boxes with labels\n    for obj in detections:\n        bbox = obj.bbox\n        x0, y0, x1, y1 = int(bbox.xmin * frame_width), int(bbox.ymin * frame_height), int(bbox.xmax * frame_width), int(bbox.ymax * frame_height)\n        cv2.rectangle(frame, (x0, y0), (x1, y1), (0, 255, 0), 2)\n        label = f\"{labels[obj.id]}: {obj.score:.2f}\"\n        cv2.putText(frame, label, (x0, y0 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n\n    # Write the frame with detections to output video\n    out.write(frame)\n\n# Release resources\ncap.release()\nout.release()\ncv2.destroyAllWindows()",
        "last_error": "Max retries reached with error. Last error: Traceback (most recent call last):\n  File \"script_1d9b8b53_1765413004.py\", line 21, in <module>\n    labels = load_labels(label_path)\n  File \"script_1d9b8b53_1765413004.py\", line 19, in load_labels\n    return {int(line.split(maxsplit=1)[0]): line.split(maxsplit=1)[1].strip() for line in lines}\n  File \"script_1d9b8b53_1765413004.py\", line 19, in <dictcomp>\n    return {int(line.split(maxsplit=1)[0]): line.split(maxsplit=1)[1].strip() for line in lines}\nIndexError: list index out of range."
      },
      "session_id": "qwen2.5-coder:32b_a8a2_tpusg_batch",
      "metadata": {
        "num_run": 14
      },
      "tags": [
        "ablation",
        "benchmark",
        "qwen2.5-coder:32b",
        "tpu_sketch_generator"
      ],
      "latency": 170.229,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-02-27-22-625533_chatcmpl-753ce4d0-5b12-4c28-920e-61b0fe35f79a",
          "traceId": "a4ed7900",
          "type": "GENERATION",
          "name": "a4ed_tpusg_gen_attempt#1",
          "startTime": "2025-12-11T00:27:22.625000+00:00",
          "endTime": "2025-12-11T00:27:48.986000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 26361.0,
          "completionTokens": 712,
          "environment": "default",
          "totalTokens": 1023,
          "promptTokens": 311,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-02-27-57-019474_chatcmpl-84723c24-d182-45c6-aa1a-823f3ff035ed",
          "traceId": "a4ed7900",
          "type": "GENERATION",
          "name": "a4ed_tpusg_gen_attempt#2",
          "startTime": "2025-12-11T00:27:57.019000+00:00",
          "endTime": "2025-12-11T00:28:20.103000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 23084.0,
          "completionTokens": 626,
          "environment": "default",
          "totalTokens": 937,
          "promptTokens": 311,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-02-28-28-634835_chatcmpl-d7e92d71-c338-4259-9ed1-a04c6bcc4a34",
          "traceId": "a4ed7900",
          "type": "GENERATION",
          "name": "a4ed_tpusg_gen_attempt#3",
          "startTime": "2025-12-11T00:28:28.634000+00:00",
          "endTime": "2025-12-11T00:28:54.948000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 26314.0,
          "completionTokens": 713,
          "environment": "default",
          "totalTokens": 1024,
          "promptTokens": 311,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-02-29-02-647226_chatcmpl-8490ed6f-987f-4f35-8981-0139060fa42f",
          "traceId": "a4ed7900",
          "type": "GENERATION",
          "name": "a4ed_tpusg_gen_attempt#4",
          "startTime": "2025-12-11T00:29:02.647000+00:00",
          "endTime": "2025-12-11T00:29:30.852000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 28205.0,
          "completionTokens": 764,
          "environment": "default",
          "totalTokens": 1075,
          "promptTokens": 311,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-02-29-38-927500_chatcmpl-e6ffa2af-046b-4cc8-b82a-eb1558ba2be7",
          "traceId": "a4ed7900",
          "type": "GENERATION",
          "name": "a4ed_tpusg_gen_attempt#5",
          "startTime": "2025-12-11T00:29:38.927000+00:00",
          "endTime": "2025-12-11T00:30:04.672000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 25745.0,
          "completionTokens": 698,
          "environment": "default",
          "totalTokens": 1009,
          "promptTokens": 311,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "25709e26-7e99-43a8-98ed-f56a542c70b1",
          "traceId": "a4ed7900",
          "type": "SPAN",
          "name": "error_a4_tpusg_failure_signal_tpu_sketch_generator",
          "startTime": "2025-12-11T00:30:12.854000+00:00",
          "level": "ERROR",
          "statusMessage": "Failed: Max retries reached with error. Last error: Traceback (most recent call last):\n  File \"script_1d9b8b53_1765413004.py\", line 21, in <module>\n    labels = load_labels(label_path)\n  File \"script_1d9b8b53_1765413004.py\", line 19, in load_labels\n    return {int(line.split(maxsplit=1)[0]): line.split(maxsplit=1)[1].strip() for line in lines}\n  File \"script_1d9b8b53_1765413004.py\", line 19, in <dictcomp>\n    return {int(line.split(maxsplit=1)[0]): line.split(maxsplit=1)[1].strip() for line in lines}\nIndexError: list index out of range.",
          "calculatedTotalCost": 0.0,
          "completionTokens": 0,
          "environment": "default",
          "totalTokens": 0,
          "promptTokens": 0,
          "costDetails": {},
          "endTime": null,
          "model": null,
          "modelParameters": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null,
          "latency": null
        }
      ],
      "createdAt": "2025-12-11T00:27:23.144Z",
      "updatedAt": "2025-12-11T00:30:18.335Z",
      "environment": "default"
    },
    {
      "id": "bfca5f7b",
      "timestamp": "2025-12-11T00:25:04.708000+00:00",
      "name": "bfca_tpu_sketch_generator",
      "input": null,
      "output": {
        "status": "success",
        "sketch": "import cv2\nimport numpy as np\nfrom PIL import Image\nimport tflite_runtime.interpreter as tflite\nfrom pycoral.adapters.common import input_size, set_input\nfrom pycoral.adapters.detect import get_objects\nfrom pycoral.utils.edgetpu import make_interpreter\n\n# Configuration parameters\nmodel_path = '/home/mendel/tinyml_autopilot/models/edgetpu_detect.tflite'\nlabel_path = '/home/mendel/tinyml_autopilot/models/labelmap.txt'\ninput_path = '/home/mendel/tinyml_autopilot/data/sheeps.mp4'\noutput_path = '/home/mendel/tinyml_autopilot/results/sheeps_detections.mp4'\nconfidence_threshold = 0.5\n\n# Load labels\ndef load_labels(filename):\n    with open(filename, 'r', encoding='utf-8') as f:\n        return {i: line.strip() for i, line in enumerate(f.readlines())}\n\nlabels = load_labels(label_path)\n\n# Initialize interpreter\ninterpreter = make_interpreter(model_path)\ninterpreter.allocate_tensors()\n\n# Read input video\ncap = cv2.VideoCapture(input_path)\nwidth = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\nheight = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\nfps = cap.get(cv2.CAP_PROP_FPS)\n\n# Define output video codec and create VideoWriter object\nfourcc = cv2.VideoWriter_fourcc(*'mp4v')\nout = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n\n# Process frames\nwhile cap.isOpened():\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    # Preprocessing\n    img = Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n    resized_img = img.resize(input_size(interpreter), Image.ANTIALIAS)\n    set_input(interpreter, resized_img)\n\n    # Inference\n    interpreter.invoke()\n    objs = get_objects(interpreter, confidence_threshold)\n\n    # Draw detection boxes with labels\n    for obj in objs:\n        bbox = obj.bbox\n        x0, y0, x1, y1 = int(bbox.xmin * width), int(bbox.ymin * height), int(bbox.xmax * width), int(bbox.ymax * height)\n        cv2.rectangle(frame, (x0, y0), (x1, y1), (0, 255, 0), 2)\n        label = f'{labels.get(obj.id, \"Unknown\")}: {obj.score:.2f}'\n        cv2.putText(frame, label, (x0, y0 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (36, 255, 12), 2)\n\n    # Write the frame to output video\n    out.write(frame)\n\n# Release everything when done\ncap.release()\nout.release()\ncv2.destroyAllWindows()"
      },
      "session_id": "qwen2.5-coder:32b_a8a2_tpusg_batch",
      "metadata": {
        "num_run": 13
      },
      "tags": [
        "ablation",
        "benchmark",
        "qwen2.5-coder:32b",
        "tpu_sketch_generator"
      ],
      "latency": 57.069,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-02-25-04-709788_chatcmpl-e73c0f83-2fc2-40f2-818d-81d6b1dc9d12",
          "traceId": "bfca5f7b",
          "type": "GENERATION",
          "name": "bfca_tpusg_gen_attempt#1",
          "startTime": "2025-12-11T00:25:04.709000+00:00",
          "endTime": "2025-12-11T00:25:30.402000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 25693.0,
          "completionTokens": 694,
          "environment": "default",
          "totalTokens": 1005,
          "promptTokens": 311,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-02-25-39-223662_chatcmpl-3684e37f-ea14-4c43-bf31-84d74aef6902",
          "traceId": "bfca5f7b",
          "type": "GENERATION",
          "name": "bfca_tpusg_gen_attempt#2",
          "startTime": "2025-12-11T00:25:39.223000+00:00",
          "endTime": "2025-12-11T00:26:01.778000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 22555.0,
          "completionTokens": 612,
          "environment": "default",
          "totalTokens": 923,
          "promptTokens": 311,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        }
      ],
      "createdAt": "2025-12-11T00:25:05.230Z",
      "updatedAt": "2025-12-11T00:27:03.619Z",
      "environment": "default"
    },
    {
      "id": "d3899014",
      "timestamp": "2025-12-11T00:21:40.670000+00:00",
      "name": "d389_tpu_sketch_generator",
      "input": null,
      "output": {
        "status": "failed",
        "last_code": "import os\nimport cv2\nimport numpy as np\nfrom PIL import Image\nfrom tflite_runtime.interpreter import Interpreter\nfrom tflite_runtime.interpreter import load_delegate\n\n# Configuration parameters\nmodel_path = '/home/mendel/tinyml_autopilot/models/edgetpu_detect.tflite'\nlabel_path = '/home/mendel/tinyml_autopilot/models/labelmap.txt'\ninput_path = '/home/mendel/tinyml_autopilot/data/sheeps.mp4'\noutput_path = '/home/mendel/tinyml_autopilot/results/sheeps_detections.mp4'\nconfidence_threshold = 0.5\n\n# Load labels\ndef load_labels(label_path):\n    with open(label_path, 'r', encoding='utf-8') as f:\n        lines = f.readlines()\n    labels = {}\n    for row_number, content in enumerate(lines):\n        pair = re.split(r'[:\\s]+', content.strip(), maxsplit=1)\n        if len(pair) == 2:\n            labels[int(pair[0])] = pair[1].strip()\n    return labels\n\nlabels = load_labels(label_path)\n\n# Load TFLite model and allocate tensors\ninterpreter = Interpreter(\n    model_path=model_path,\n    experimental_delegates=[load_delegate('/usr/lib/aarch64-linux-gnu/libedgetpu.so.1.0')]\n)\ninterpreter.allocate_tensors()\n\n# Get input and output details\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\n\n# Read video file\ncap = cv2.VideoCapture(input_path)\nwidth = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\nheight = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\nfps = cap.get(cv2.CAP_PROP_FPS)\n\n# Define the codec and create VideoWriter object\nfourcc = cv2.VideoWriter_fourcc(*'mp4v')\nout = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n\ndef preprocess_image(image):\n    image = image.resize((input_details[0]['shape'][1], input_details[0]['shape'][2]))\n    image = np.array(image)\n    image = image.astype(np.float32) / 255.0\n    return image\n\n# Process video frame by frame\nwhile cap.isOpened():\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    # Preprocess the frame\n    input_image = preprocess_image(Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)))\n    input_data = np.expand_dims(input_image, axis=0)\n\n    # Run inference\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n    interpreter.invoke()\n\n    # Extract results\n    boxes = interpreter.get_tensor(output_details[0]['index'])\n    classes = interpreter.get_tensor(output_details[1]['index'])\n    scores = interpreter.get_tensor(output_details[2]['index'])\n    num_detections = int(interpreter.get_tensor(output_details[3]['index']))\n\n    # Draw detection boxes and labels on the frame\n    for i in range(num_detections):\n        if scores[0][i] > confidence_threshold:\n            ymin, xmin, ymax, xmax = boxes[0][i]\n            (left, right, top, bottom) = (xmin * width, xmax * width,\n                                          ymin * height, ymax * height)\n            cv2.rectangle(frame, (int(left), int(top)), (int(right), int(bottom)), (0, 255, 0), 2)\n\n            label = labels[int(classes[0][i])]\n            confidence = scores[0][i]\n            text = f'{label}: {confidence:.2f}'\n            cv2.putText(frame, text, (int(left), int(top) - 10),\n                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n\n    # Write the frame with detection to the output file\n    out.write(frame)\n\n# Release everything when done\ncap.release()\nout.release()\ncv2.destroyAllWindows()",
        "last_error": "Max retries reached with error. Last error: Traceback (most recent call last):\n  File \"script_09c08dcd_1765412670.py\", line 26, in <module>\n    labels = load_labels(label_path)\n  File \"script_09c08dcd_1765412670.py\", line 21, in load_labels\n    pair = re.split(r'[:\\s]+', content.strip(), maxsplit=1)\nNameError: name 're' is not defined."
      },
      "session_id": "qwen2.5-coder:32b_a8a2_tpusg_batch",
      "metadata": {
        "num_run": 12
      },
      "tags": [
        "ablation",
        "benchmark",
        "qwen2.5-coder:32b",
        "tpu_sketch_generator"
      ],
      "latency": 178.166,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-02-21-40-671304_chatcmpl-aaeeddc4-63dc-4477-a69e-bbdaf7fbc4f1",
          "traceId": "d3899014",
          "type": "GENERATION",
          "name": "d389_tpusg_gen_attempt#1",
          "startTime": "2025-12-11T00:21:40.671000+00:00",
          "endTime": "2025-12-11T00:22:06.169000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 25498.0,
          "completionTokens": 690,
          "environment": "default",
          "totalTokens": 1001,
          "promptTokens": 311,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-02-22-14-316501_chatcmpl-4b8a48fa-4c80-4309-8406-d0ca5891ed9f",
          "traceId": "d3899014",
          "type": "GENERATION",
          "name": "d389_tpusg_gen_attempt#2",
          "startTime": "2025-12-11T00:22:14.316000+00:00",
          "endTime": "2025-12-11T00:22:43.019000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 28703.0,
          "completionTokens": 778,
          "environment": "default",
          "totalTokens": 1089,
          "promptTokens": 311,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-02-22-51-175864_chatcmpl-39955451-6398-476f-b363-556883774328",
          "traceId": "d3899014",
          "type": "GENERATION",
          "name": "d389_tpusg_gen_attempt#3",
          "startTime": "2025-12-11T00:22:51.175000+00:00",
          "endTime": "2025-12-11T00:23:17.748000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 26573.0,
          "completionTokens": 720,
          "environment": "default",
          "totalTokens": 1031,
          "promptTokens": 311,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-02-23-26-513259_chatcmpl-7e86f17c-97af-409e-b3c0-88afa4288d44",
          "traceId": "d3899014",
          "type": "GENERATION",
          "name": "d389_tpusg_gen_attempt#4",
          "startTime": "2025-12-11T00:23:26.513000+00:00",
          "endTime": "2025-12-11T00:23:51.862000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 25349.0,
          "completionTokens": 687,
          "environment": "default",
          "totalTokens": 998,
          "promptTokens": 311,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-02-23-59-704858_chatcmpl-5a051785-7694-494f-918c-5ac43465e259",
          "traceId": "d3899014",
          "type": "GENERATION",
          "name": "d389_tpusg_gen_attempt#5",
          "startTime": "2025-12-11T00:23:59.704000+00:00",
          "endTime": "2025-12-11T00:24:30.834000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 31130.0,
          "completionTokens": 843,
          "environment": "default",
          "totalTokens": 1154,
          "promptTokens": 311,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "aba308ae-a79b-4577-8957-b5482ade793f",
          "traceId": "d3899014",
          "type": "SPAN",
          "name": "error_d3_tpusg_failure_signal_tpu_sketch_generator",
          "startTime": "2025-12-11T00:24:38.837000+00:00",
          "level": "ERROR",
          "statusMessage": "Failed: Max retries reached with error. Last error: Traceback (most recent call last):\n  File \"script_09c08dcd_1765412670.py\", line 26, in <module>\n    labels = load_labels(label_path)\n  File \"script_09c08dcd_1765412670.py\", line 21, in load_labels\n    pair = re.split(r'[:\\s]+', content.strip(), maxsplit=1)\nNameError: name 're' is not defined.",
          "calculatedTotalCost": 0.0,
          "completionTokens": 0,
          "environment": "default",
          "totalTokens": 0,
          "promptTokens": 0,
          "costDetails": {},
          "endTime": null,
          "model": null,
          "modelParameters": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null,
          "latency": null
        }
      ],
      "createdAt": "2025-12-11T00:21:41.187Z",
      "updatedAt": "2025-12-11T00:24:44.427Z",
      "environment": "default"
    },
    {
      "id": "5bfb0f01",
      "timestamp": "2025-12-11T00:18:17.745000+00:00",
      "name": "5bfb_tpu_sketch_generator",
      "input": null,
      "output": {
        "status": "failed",
        "last_code": "import os\nimport numpy as np\nimport cv2\nfrom PIL import Image\nfrom pycoral.adapters.common import input_size\nfrom pycoral.adapters.detect import get_objects\nfrom pycoral.utils.dataset import read_label_file\nfrom pycoral.utils.edgetpu import make_interpreter\n\n# Configuration parameters\nmodel_path = '/home/mendel/tinyml_autopilot/models/edgetpu_detect.tflite'\nlabel_path = '/home/mendel/tinyml_autopilot/models/labelmap.txt'\ninput_path = '/home/mendel/tinyml_autopilot/data/sheeps.mp4'\noutput_path = '/home/mendel/tinyml_autopilot/results/sheeps_detections.mp4'\nconfidence_threshold = 0.5\n\n# Load the interpreter for TPU\ninterpreter = make_interpreter(model_path)\ninterpreter.allocate_tensors()\n\n# Read labels\nlabels = read_label_file(label_path)\n\n# Get input size\n_, height, width, _ = interpreter.get_input_details()[0]['shape']\n\n# Open video file\ncap = cv2.VideoCapture(input_path)\nif not cap.isOpened():\n    raise IOError(\"Cannot open video\")\n\n# Define the codec and create VideoWriter object\nfourcc = cv2.VideoWriter_fourcc(*'mp4v')\nout = cv2.VideoWriter(output_path, fourcc, 30.0, (int(cap.get(3)), int(cap.get(4))))\n\nwhile cap.isOpened():\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    # Preprocess the image\n    img = Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)).resize((width, height), Image.ANTIALIAS)\n    scale = detect.set_input(interpreter, img)\n\n    # Run inference\n    interpreter.invoke()\n\n    # Get detection results\n    objs = get_objects(interpreter, confidence_threshold, scale)\n\n    # Draw detection boxes with labels\n    for obj in objs:\n        bbox = obj.bbox\n        cv2.rectangle(frame, (int(bbox.xmin), int(bbox.ymin)), (int(bbox.xmax), int(bbox.ymax)), (0, 255, 0), 2)\n        label = '%s: %.1f%%' % (labels.get(obj.id, obj.id), obj.score * 100)\n        cv2.putText(frame, label, (int(bbox.xmin), int(bbox.ymin) - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n\n    # Write the frame to the output file\n    out.write(frame)\n\n# Release everything when job is finished\ncap.release()\nout.release()\ncv2.destroyAllWindows()",
        "last_error": "Max retries reached with error. Last error: Traceback (most recent call last):\n  File \"script_fb3ad676_1765412466.py\", line 43, in <module>\n    scale = detect.set_input(interpreter, img)\nNameError: name 'detect' is not defined."
      },
      "session_id": "qwen2.5-coder:32b_a8a2_tpusg_batch",
      "metadata": {
        "num_run": 11
      },
      "tags": [
        "ablation",
        "benchmark",
        "qwen2.5-coder:32b",
        "tpu_sketch_generator"
      ],
      "latency": 177.596,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-02-18-17-746974_chatcmpl-f73afddf-46d3-455e-ab5b-b1476aa2a5d1",
          "traceId": "5bfb0f01",
          "type": "GENERATION",
          "name": "5bfb_tpusg_gen_attempt#1",
          "startTime": "2025-12-11T00:18:17.746000+00:00",
          "endTime": "2025-12-11T00:18:54.588000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 36842.0,
          "completionTokens": 993,
          "environment": "default",
          "totalTokens": 1304,
          "promptTokens": 311,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-02-19-03-196371_chatcmpl-f624cf0a-412f-456c-b196-b606e76f91b7",
          "traceId": "5bfb0f01",
          "type": "GENERATION",
          "name": "5bfb_tpusg_gen_attempt#2",
          "startTime": "2025-12-11T00:19:03.196000+00:00",
          "endTime": "2025-12-11T00:19:26.982000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 23786.0,
          "completionTokens": 645,
          "environment": "default",
          "totalTokens": 956,
          "promptTokens": 311,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-02-19-35-022125_chatcmpl-9eecc61b-d432-413e-b5b8-9927c9c574c2",
          "traceId": "5bfb0f01",
          "type": "GENERATION",
          "name": "5bfb_tpusg_gen_attempt#3",
          "startTime": "2025-12-11T00:19:35.022000+00:00",
          "endTime": "2025-12-11T00:19:57.958000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 22936.0,
          "completionTokens": 622,
          "environment": "default",
          "totalTokens": 933,
          "promptTokens": 311,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-02-20-06-067453_chatcmpl-367f231e-680b-417d-a364-f6301f1a2dc6",
          "traceId": "5bfb0f01",
          "type": "GENERATION",
          "name": "5bfb_tpusg_gen_attempt#4",
          "startTime": "2025-12-11T00:20:06.067000+00:00",
          "endTime": "2025-12-11T00:20:33.442000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 27375.0,
          "completionTokens": 741,
          "environment": "default",
          "totalTokens": 1052,
          "promptTokens": 311,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-02-20-41-717855_chatcmpl-e6e7902d-e96a-4e6c-b078-702399e5536e",
          "traceId": "5bfb0f01",
          "type": "GENERATION",
          "name": "5bfb_tpusg_gen_attempt#5",
          "startTime": "2025-12-11T00:20:41.717000+00:00",
          "endTime": "2025-12-11T00:21:06.518000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 24801.0,
          "completionTokens": 672,
          "environment": "default",
          "totalTokens": 983,
          "promptTokens": 311,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "a5e99ca6-52c6-4ce7-9d0a-d6bec4496b2b",
          "traceId": "5bfb0f01",
          "type": "SPAN",
          "name": "error_5b_tpusg_failure_signal_tpu_sketch_generator",
          "startTime": "2025-12-11T00:21:15.342000+00:00",
          "level": "ERROR",
          "statusMessage": "Failed: Max retries reached with error. Last error: Traceback (most recent call last):\n  File \"script_fb3ad676_1765412466.py\", line 43, in <module>\n    scale = detect.set_input(interpreter, img)\nNameError: name 'detect' is not defined.",
          "calculatedTotalCost": 0.0,
          "completionTokens": 0,
          "environment": "default",
          "totalTokens": 0,
          "promptTokens": 0,
          "costDetails": {},
          "endTime": null,
          "model": null,
          "modelParameters": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null,
          "latency": null
        }
      ],
      "createdAt": "2025-12-11T00:18:18.263Z",
      "updatedAt": "2025-12-11T00:21:20.487Z",
      "environment": "default"
    },
    {
      "id": "32fd1eba",
      "timestamp": "2025-12-11T00:15:55.731000+00:00",
      "name": "32fd_tpu_sketch_generator",
      "input": null,
      "output": {
        "status": "success",
        "sketch": "import cv2\nimport numpy as np\nfrom PIL import Image\nfrom pycoral.adapters.common import input_size\nfrom pycoral.adapters.detect import get_objects\nfrom pycoral.utils.dataset import read_label_file\nfrom pycoral.utils.edgetpu import make_interpreter\n\n# Configuration parameters\nmodel_path = '/home/mendel/tinyml_autopilot/models/edgetpu_detect.tflite'\nlabel_path = '/home/mendel/tinyml_autopilot/models/labelmap.txt'\ninput_path = '/home/mendel/tinyml_autopilot/data/sheeps.mp4'\noutput_path = '/home/mendel/tinyml_autopilot/results/sheeps_detections.mp4'\nconfidence_threshold = 0.5\n\n# Phase 1: Setup\ninterpreter = make_interpreter(model_path, device=':0')\ninterpreter.allocate_tensors()\nlabels = read_label_file(label_path)\n\n# Get model details\ninference_size = input_size(interpreter)\ninput_tensor_index = interpreter.get_input_details()[0]['index']\n\n# Load video\ncap = cv2.VideoCapture(input_path)\nfps = cap.get(cv2.CAP_PROP_FPS)\nwidth = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\nheight = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n\n# Define codec and create VideoWriter object\nfourcc = cv2.VideoWriter_fourcc(*'mp4v')\nout = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n\ndef draw_objects(frame, objs, labels, inference_size):\n    scale_x = frame.shape[1] / inference_size[0]\n    scale_y = frame.shape[0] / inference_size[1]\n\n    for obj in objs:\n        if obj.score >= confidence_threshold:\n            bbox = obj.bbox\n            start_point = (int(bbox.xmin * scale_x), int(bbox.ymin * scale_y))\n            end_point = (int(bbox.xmax * scale_x), int(bbox.ymax * scale_y))\n            cv2.rectangle(frame, start_point, end_point, (0, 255, 0), 2)\n            label_str = f\"{labels.get(obj.id, obj.id)}: {obj.score:.2f}\"\n            text_size, _ = cv2.getTextSize(label_str, cv2.FONT_HERSHEY_SIMPLEX, 0.6, 1)\n            text_x = start_point[0]\n            text_y = start_point[1] - 5 if start_point[1] > text_size[1] else start_point[1] + text_size[1] + 5\n            cv2.rectangle(frame, (text_x, text_y - text_size[1]), (text_x + text_size[0], text_y), (0, 255, 0), -1)\n            cv2.putText(frame, label_str, (text_x, text_y), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 0, 0), 1)\n\n# Process video frame by frame\nwhile cap.isOpened():\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    # Preprocess image\n    img = Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n    img = img.resize(inference_size)\n    input_tensor = np.array(img)\n\n    # Run inference\n    interpreter.set_tensor(input_tensor_index, np.expand_dims(input_tensor, axis=0))\n    interpreter.invoke()\n    objs = get_objects(interpreter, confidence_threshold)[:5]\n\n    # Draw results on frame\n    draw_objects(frame, objs, labels, inference_size)\n\n    # Write the result to output video file\n    out.write(frame)\n\n# Release everything when job is finished\ncap.release()\nout.release()\ncv2.destroyAllWindows()"
      },
      "session_id": "qwen2.5-coder:32b_a8a2_tpusg_batch",
      "metadata": {
        "num_run": 10
      },
      "tags": [
        "ablation",
        "benchmark",
        "qwen2.5-coder:32b",
        "tpu_sketch_generator"
      ],
      "latency": 64.119,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-02-15-55-732563_chatcmpl-ff3f3deb-4642-48d9-87c4-16176a3e051a",
          "traceId": "32fd1eba",
          "type": "GENERATION",
          "name": "32fd_tpusg_gen_attempt#1",
          "startTime": "2025-12-11T00:15:55.732000+00:00",
          "endTime": "2025-12-11T00:16:22.829000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 27097.0,
          "completionTokens": 729,
          "environment": "default",
          "totalTokens": 1040,
          "promptTokens": 311,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-02-16-30-923610_chatcmpl-a0596d9f-6ed1-4a3d-a2e2-03a900c39267",
          "traceId": "32fd1eba",
          "type": "GENERATION",
          "name": "32fd_tpusg_gen_attempt#2",
          "startTime": "2025-12-11T00:16:30.923000+00:00",
          "endTime": "2025-12-11T00:16:59.851000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 28928.0,
          "completionTokens": 784,
          "environment": "default",
          "totalTokens": 1095,
          "promptTokens": 311,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        }
      ],
      "createdAt": "2025-12-11T00:15:56.249Z",
      "updatedAt": "2025-12-11T00:17:57.447Z",
      "environment": "default"
    },
    {
      "id": "6b60a3ea",
      "timestamp": "2025-12-11T00:13:32.704000+00:00",
      "name": "6b60_tpu_sketch_generator",
      "input": null,
      "output": {
        "status": "success",
        "sketch": "import numpy as np\nimport cv2\nfrom PIL import Image\nfrom tflite_runtime.interpreter import Interpreter\nfrom pycoral.utils.edgetpu import make_interpreter\n\n# Configuration parameters\nmodel_path = '/home/mendel/tinyml_autopilot/models/edgetpu_detect.tflite'\nlabel_path = '/home/mendel/tinyml_autopilot/models/labelmap.txt'\ninput_path = '/home/mendel/tinyml_autopilot/data/sheeps.mp4'\noutput_path = '/home/mendel/tinyml_autopilot/results/sheeps_detections.mp4'\nconfidence_threshold = 0.5\n\n# Load labels\ndef load_labels(filename):\n    with open(filename, 'r') as f:\n        return {index: line.strip() for index, line in enumerate(f.readlines())}\n\nlabels = load_labels(label_path)\n\n# Setup interpreter\ninterpreter = make_interpreter(model_path)\ninterpreter.allocate_tensors()\n\n# Get input and output details\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\n\n# Read video file\ncap = cv2.VideoCapture(input_path)\nfourcc = cv2.VideoWriter_fourcc(*'mp4v')\nfps = cap.get(cv2.CAP_PROP_FPS)\nwidth = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\nheight = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\nout = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n\ndef preprocess(image):\n    image_resized = Image.fromarray(cv2.cvtColor(image, cv2.COLOR_BGR2RGB)).resize((input_details[0]['shape'][2], input_details[0]['shape'][1]), Image.ANTIALIAS)\n    return np.array(image_resized).astype(np.uint8)\n\ndef draw_detection_boxes(frame, boxes, classes, scores):\n    for (box, cls, score) in zip(boxes, classes, scores):\n        if score > confidence_threshold:\n            ymin, xmin, ymax, xmax = box\n            im_width, im_height = frame.shape[1], frame.shape[0]\n            (left, right, top, bottom) = (xmin * im_width, xmax * im_width, ymin * im_height, ymax * im_height)\n            cv2.rectangle(frame, (int(left), int(top)), (int(right), int(bottom)), (0, 255, 0), 2)\n            label = f'{labels[int(cls)]}: {score:.2f}'\n            cv2.putText(frame, label, (int(left), int(top) - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n\n# Inference and output handling\nwhile cap.isOpened():\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    preprocessed_image = preprocess(frame)\n    interpreter.set_tensor(input_details[0]['index'], np.expand_dims(preprocessed_image, axis=0))\n    interpreter.invoke()\n\n    boxes = interpreter.get_tensor(output_details[0]['index'])[0]\n    classes = interpreter.get_tensor(output_details[1]['index'])[0]\n    scores = interpreter.get_tensor(output_details[2]['index'])[0]\n\n    draw_detection_boxes(frame, boxes, classes, scores)\n    out.write(frame)\n\ncap.release()\nout.release()\ncv2.destroyAllWindows()"
      },
      "session_id": "qwen2.5-coder:32b_a8a2_tpusg_batch",
      "metadata": {
        "num_run": 9
      },
      "tags": [
        "ablation",
        "benchmark",
        "qwen2.5-coder:32b",
        "tpu_sketch_generator"
      ],
      "latency": 61.471,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-02-13-32-705498_chatcmpl-67c54554-5099-4880-a6dd-90c8d5dde3b9",
          "traceId": "6b60a3ea",
          "type": "GENERATION",
          "name": "6b60_tpusg_gen_attempt#1",
          "startTime": "2025-12-11T00:13:32.705000+00:00",
          "endTime": "2025-12-11T00:13:58.257000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 25552.0,
          "completionTokens": 690,
          "environment": "default",
          "totalTokens": 1001,
          "promptTokens": 311,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-02-14-06-421324_chatcmpl-d46e319a-834c-4629-9141-4c5ae46178c3",
          "traceId": "6b60a3ea",
          "type": "GENERATION",
          "name": "6b60_tpusg_gen_attempt#2",
          "startTime": "2025-12-11T00:14:06.421000+00:00",
          "endTime": "2025-12-11T00:14:34.176000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 27755.0,
          "completionTokens": 752,
          "environment": "default",
          "totalTokens": 1063,
          "promptTokens": 311,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        }
      ],
      "createdAt": "2025-12-11T00:13:33.223Z",
      "updatedAt": "2025-12-11T00:15:45.875Z",
      "environment": "default"
    },
    {
      "id": "b5265b33",
      "timestamp": "2025-12-11T00:11:05.752000+00:00",
      "name": "b526_tpu_sketch_generator",
      "input": null,
      "output": {
        "status": "success",
        "sketch": "import os\nimport cv2\nimport numpy as np\nfrom PIL import Image\nfrom pycoral.utils.edgetpu import make_interpreter\nfrom pycoral.adapters import common, detect\n\n# Configuration parameters\nmodel_path = '/home/mendel/tinyml_autopilot/models/edgetpu_detect.tflite'\nlabel_path = '/home/mendel/tinyml_autopilot/models/labelmap.txt'\ninput_path = '/home/mendel/tinyml_autopilot/data/sheeps.mp4'\noutput_path = '/home/mendel/tinyml_autopilot/results/sheeps_detections.mp4'\nconfidence_threshold = 0.5\n\n# Load labels\ndef load_labels(label_path):\n    with open(label_path, 'r', encoding='utf-8') as f:\n        return {i: line.strip() for i, line in enumerate(f.readlines())}\n\nlabels = load_labels(label_path)\n\n# Setup interpreter\ninterpreter = make_interpreter(model_path)\ninterpreter.allocate_tensors()\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\n\n# Preprocessing function\ndef preprocess_image(image):\n    image = Image.fromarray(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n    resized_image = image.resize((300, 300), Image.ANTIALIAS)\n    input_data = np.array(resized_image).reshape((1, 300, 300, 3)).astype(np.uint8)\n    return input_data\n\n# Function to draw boxes\ndef draw_boxes(image, detections, labels):\n    for obj in detections:\n        if obj.score > confidence_threshold:\n            bbox = obj.bbox\n            start_point = (int(bbox.xmin * image.shape[1]), int(bbox.ymin * image.shape[0]))\n            end_point = (int(bbox.xmax * image.shape[1]), int(bbox.ymax * image.shape[0]))\n            label = f\"{labels[int(obj.id)]}: {obj.score:.2f}\"\n            cv2.rectangle(image, start_point, end_point, (0, 255, 0), 2)\n            cv2.putText(image, label, (start_point[0], start_point[1] - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n    return image\n\n# Main pipeline\ncap = cv2.VideoCapture(input_path)\nfourcc = cv2.VideoWriter_fourcc(*'mp4v')\nout = None\nframe_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\nframe_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\nfps = cap.get(cv2.CAP_PROP_FPS)\n\nwhile cap.isOpened():\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    if out is None:\n        out = cv2.VideoWriter(output_path, fourcc, fps, (frame_width, frame_height))\n\n    input_data = preprocess_image(frame)\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n    interpreter.invoke()\n\n    detections = detect.get_objects(interpreter, confidence_threshold)\n    output_frame = draw_boxes(frame.copy(), detections, labels)\n\n    out.write(output_frame)\n\ncap.release()\nout.release()\ncv2.destroyAllWindows()"
      },
      "session_id": "qwen2.5-coder:32b_a8a2_tpusg_batch",
      "metadata": {
        "num_run": 8
      },
      "tags": [
        "ablation",
        "benchmark",
        "qwen2.5-coder:32b",
        "tpu_sketch_generator"
      ],
      "latency": 66.001,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-02-11-05-753102_chatcmpl-633af13d-f828-473a-bae3-4c8f35025e99",
          "traceId": "b5265b33",
          "type": "GENERATION",
          "name": "b526_tpusg_gen_attempt#1",
          "startTime": "2025-12-11T00:11:05.753000+00:00",
          "endTime": "2025-12-11T00:11:38.437000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 32684.0,
          "completionTokens": 759,
          "environment": "default",
          "totalTokens": 1070,
          "promptTokens": 311,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-02-11-46-599372_chatcmpl-d6e36fdd-1de6-4026-ab79-b18b7464ca24",
          "traceId": "b5265b33",
          "type": "GENERATION",
          "name": "b526_tpusg_gen_attempt#2",
          "startTime": "2025-12-11T00:11:46.599000+00:00",
          "endTime": "2025-12-11T00:12:11.754000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 25155.0,
          "completionTokens": 682,
          "environment": "default",
          "totalTokens": 993,
          "promptTokens": 311,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        }
      ],
      "createdAt": "2025-12-11T00:11:09.968Z",
      "updatedAt": "2025-12-11T00:13:22.962Z",
      "environment": "default"
    },
    {
      "id": "2afb690c",
      "timestamp": "2025-12-11T00:07:29.718000+00:00",
      "name": "2afb_tpu_sketch_generator",
      "input": null,
      "output": {
        "status": "failed",
        "last_code": "import os\nimport cv2\nimport numpy as np\nfrom PIL import Image\nfrom pycoral.adapters.common import input_size\nfrom pycoral.adapters.detect import get_objects\nfrom pycoral.utils.dataset import read_label_file\nfrom pycoral.utils.edgetpu import make_interpreter\n\n# Configuration parameters\nmodel_path = '/home/mendel/tinyml_autopilot/models/edgetpu_detect.tflite'\nlabel_path = '/home/mendel/tinyml_autopilot/models/labelmap.txt'\ninput_path = '/home/mendel/tinyml_autopilot/data/sheeps.mp4'\noutput_path = '/home/mendel/tinyml_autopilot/results/sheeps_detections.mp4'\nconfidence_threshold = 0.5\n\n# Setup\ninterpreter = make_interpreter(model_path, device=':0')\ninterpreter.allocate_tensors()\nlabels = read_label_file(label_path)\n\n# Preprocessing function\ndef preprocess_image(image):\n    width, height = input_size(interpreter)\n    image = Image.fromarray(cv2.cvtColor(image, cv2.COLOR_BGR2RGB)).resize((width, height))\n    return np.array(image), (width, height)\n\n# Inference and post-processing function\ndef run_inference(image, interpreter):\n    _, scale = preprocess_image(image)\n    set_input(interpreter, image.tobytes())\n    interpreter.invoke()\n    return get_objects(interpreter, confidence_threshold), scale\n\n# Drawing function\ndef draw_detection_boxes(image, objs, labels, scale):\n    for obj in objs:\n        bbox = obj.bbox\n        x0, y0 = int(bbox.xmin * scale[0]), int(bbox.ymin * scale[1])\n        x1, y1 = int(bbox.xmax * scale[0]), int(bbox.ymax * scale[1])\n        percent = int(100 * obj.score)\n        label = '{}% {}'.format(percent, labels.get(obj.id, obj.id))\n        cv2.rectangle(image, (x0, y0), (x1, y1), (0, 255, 0), 2)\n        cv2.putText(image, label, (x0, y0 - 5),\n                    cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n\n# Main pipeline\ncap = cv2.VideoCapture(input_path)\nwidth = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\nheight = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\nfps = cap.get(cv2.CAP_PROP_FPS)\n\nfourcc = cv2.VideoWriter_fourcc(*'mp4v')\nout = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n\nwhile cap.isOpened():\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    objs, scale = run_inference(frame, interpreter)\n    draw_detection_boxes(frame, objs, labels, scale)\n\n    out.write(frame)\n\ncap.release()\nout.release()\ncv2.destroyAllWindows()",
        "last_error": "Max retries reached with error. Last error: Traceback (most recent call last):\n  File \"script_ce64dd5c_1765411831.py\", line 61, in <module>\n    objs, scale = run_inference(frame, interpreter)\n  File \"script_ce64dd5c_1765411831.py\", line 31, in run_inference\n    set_input(interpreter, image.tobytes())\nNameError: name 'set_input' is not defined."
      },
      "session_id": "qwen2.5-coder:32b_a8a2_tpusg_batch",
      "metadata": {
        "num_run": 7
      },
      "tags": [
        "ablation",
        "benchmark",
        "qwen2.5-coder:32b",
        "tpu_sketch_generator"
      ],
      "latency": 190.23,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-02-07-29-719607_chatcmpl-660ed3f7-5e88-453d-ad8c-b525eb28258e",
          "traceId": "2afb690c",
          "type": "GENERATION",
          "name": "2afb_tpusg_gen_attempt#1",
          "startTime": "2025-12-11T00:07:29.719000+00:00",
          "endTime": "2025-12-11T00:07:50.717000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 20998.0,
          "completionTokens": 567,
          "environment": "default",
          "totalTokens": 878,
          "promptTokens": 311,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-02-07-59-132526_chatcmpl-ef654508-da0b-4086-ac1f-22bd179c9394",
          "traceId": "2afb690c",
          "type": "GENERATION",
          "name": "2afb_tpusg_gen_attempt#2",
          "startTime": "2025-12-11T00:07:59.132000+00:00",
          "endTime": "2025-12-11T00:08:22.246000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 23114.0,
          "completionTokens": 627,
          "environment": "default",
          "totalTokens": 938,
          "promptTokens": 311,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-02-08-30-408425_chatcmpl-100cac95-c399-4fcc-ad1d-d3bcdb3f8838",
          "traceId": "2afb690c",
          "type": "GENERATION",
          "name": "2afb_tpusg_gen_attempt#3",
          "startTime": "2025-12-11T00:08:30.408000+00:00",
          "endTime": "2025-12-11T00:09:03.830000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 33422.0,
          "completionTokens": 904,
          "environment": "default",
          "totalTokens": 1215,
          "promptTokens": 311,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-02-09-11-767734_chatcmpl-f210046b-eaec-492f-82a2-7f9cf5888324",
          "traceId": "2afb690c",
          "type": "GENERATION",
          "name": "2afb_tpusg_gen_attempt#4",
          "startTime": "2025-12-11T00:09:11.767000+00:00",
          "endTime": "2025-12-11T00:09:34.082000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 22315.0,
          "completionTokens": 605,
          "environment": "default",
          "totalTokens": 916,
          "promptTokens": 311,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-02-09-42-506304_chatcmpl-ba1081c5-5980-4ee7-8f7f-4483578adfcd",
          "traceId": "2afb690c",
          "type": "GENERATION",
          "name": "2afb_tpusg_gen_attempt#5",
          "startTime": "2025-12-11T00:09:42.506000+00:00",
          "endTime": "2025-12-11T00:10:31.016000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 48510.0,
          "completionTokens": 1305,
          "environment": "default",
          "totalTokens": 1616,
          "promptTokens": 311,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "ab7dd68a-88e4-43b5-8da0-be27550e95cb",
          "traceId": "2afb690c",
          "type": "SPAN",
          "name": "error_2a_tpusg_failure_signal_tpu_sketch_generator",
          "startTime": "2025-12-11T00:10:39.949000+00:00",
          "level": "ERROR",
          "statusMessage": "Failed: Max retries reached with error. Last error: Traceback (most recent call last):\n  File \"script_ce64dd5c_1765411831.py\", line 61, in <module>\n    objs, scale = run_inference(frame, interpreter)\n  File \"script_ce64dd5c_1765411831.py\", line 31, in run_inference\n    set_input(interpreter, image.tobytes())\nNameError: name 'set_input' is not defined.",
          "calculatedTotalCost": 0.0,
          "completionTokens": 0,
          "environment": "default",
          "totalTokens": 0,
          "promptTokens": 0,
          "costDetails": {},
          "endTime": null,
          "model": null,
          "modelParameters": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null,
          "latency": null
        }
      ],
      "createdAt": "2025-12-11T00:07:30.236Z",
      "updatedAt": "2025-12-11T00:10:55.627Z",
      "environment": "default"
    },
    {
      "id": "7928941f",
      "timestamp": "2025-12-11T00:03:25.588000+00:00",
      "name": "7928_tpu_sketch_generator",
      "input": null,
      "output": {
        "status": "success",
        "sketch": "import os\nimport cv2\nimport numpy as np\nfrom PIL import Image\nfrom pycoral.utils.edgetpu import make_interpreter\nfrom pycoral.adapters.common import input_size, set_input\nfrom pycoral.adapters.detect import get_objects\n\n# Configuration parameters\nmodel_path = '/home/mendel/tinyml_autopilot/models/edgetpu_detect.tflite'\nlabel_path = '/home/mendel/tinyml_autopilot/models/labelmap.txt'\ninput_path = '/home/mendel/tinyml_autopilot/data/sheeps.mp4'\noutput_path = '/home/mendel/tinyml_autopilot/results/sheeps_detections.mp4'\nconfidence_threshold = 0.5\n\n# Load labels\ndef load_labels(label_path):\n    with open(label_path, 'r', encoding='utf-8') as f:\n        return {i: line.strip() for i, line in enumerate(f.readlines())}\n\nlabels = load_labels(label_path)\n\n# Setup TFLite interpreter with TPU\ninterpreter = make_interpreter(model_path)\ninterpreter.allocate_tensors()\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\n\n# Preprocessing function\ndef preprocess_image(image):\n    image = Image.fromarray(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n    resized_image = image.resize(input_size(interpreter), Image.ANTIALIAS)\n    return np.array(resized_image)\n\n# Function to draw bounding boxes and labels on the frame\ndef draw_detection(frame, objs, labels, confidence_threshold):\n    for obj in objs:\n        if obj.score >= confidence_threshold:\n            bbox = obj.bbox\n            label = f\"{labels[obj.id]}: {obj.score:.2f}\"\n            cv2.rectangle(frame, (bbox.xmin, bbox.ymin), (bbox.xmax, bbox.ymax), (0, 255, 0), 2)\n            cv2.putText(frame, label, (bbox.xmin, bbox.ymin - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n\n# Read input video and process frames\ncap = cv2.VideoCapture(input_path)\nif not cap.isOpened():\n    raise IOError(\"Cannot open video file\")\n\nframe_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\nframe_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\nfps = cap.get(cv2.CAP_PROP_FPS)\n\nfourcc = cv2.VideoWriter_fourcc(*'mp4v')\nout = cv2.VideoWriter(output_path, fourcc, fps, (frame_width, frame_height))\n\nwhile True:\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    preprocessed_image = preprocess_image(frame)\n    set_input(interpreter, preprocessed_image)\n    interpreter.invoke()\n\n    objs = get_objects(interpreter, score_threshold=confidence_threshold, image_scale=(1.0, 1.0))\n    draw_detection(frame, objs, labels, confidence_threshold)\n\n    out.write(frame)\n\ncap.release()\nout.release()\ncv2.destroyAllWindows()"
      },
      "session_id": "qwen2.5-coder:32b_a8a2_tpusg_batch",
      "metadata": {
        "num_run": 6
      },
      "tags": [
        "ablation",
        "benchmark",
        "qwen2.5-coder:32b",
        "tpu_sketch_generator"
      ],
      "latency": 161.971,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-02-03-25-589412_chatcmpl-34aa7ae9-a352-44fc-915e-d2727323e8a2",
          "traceId": "7928941f",
          "type": "GENERATION",
          "name": "7928_tpusg_gen_attempt#1",
          "startTime": "2025-12-11T00:03:25.589000+00:00",
          "endTime": "2025-12-11T00:03:48.146000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 22557.0,
          "completionTokens": 610,
          "environment": "default",
          "totalTokens": 921,
          "promptTokens": 311,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-02-03-56-664267_chatcmpl-4771b73e-2169-4301-b032-96750469cd28",
          "traceId": "7928941f",
          "type": "GENERATION",
          "name": "7928_tpusg_gen_attempt#2",
          "startTime": "2025-12-11T00:03:56.664000+00:00",
          "endTime": "2025-12-11T00:04:19.619000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 22955.0,
          "completionTokens": 622,
          "environment": "default",
          "totalTokens": 933,
          "promptTokens": 311,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-02-04-27-733000_chatcmpl-f037457f-ab41-4f0d-ba9c-a9820000fd1c",
          "traceId": "7928941f",
          "type": "GENERATION",
          "name": "7928_tpusg_gen_attempt#3",
          "startTime": "2025-12-11T00:04:27.733000+00:00",
          "endTime": "2025-12-11T00:04:57.837000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 30104.0,
          "completionTokens": 815,
          "environment": "default",
          "totalTokens": 1126,
          "promptTokens": 311,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-02-05-06-193501_chatcmpl-99eb4aea-20b1-4fe5-b33c-f4d929f9617d",
          "traceId": "7928941f",
          "type": "GENERATION",
          "name": "7928_tpusg_gen_attempt#4",
          "startTime": "2025-12-11T00:05:06.193000+00:00",
          "endTime": "2025-12-11T00:05:33.557000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 27364.0,
          "completionTokens": 742,
          "environment": "default",
          "totalTokens": 1053,
          "promptTokens": 311,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-02-05-41-768496_chatcmpl-d25605a5-ddb8-46ed-9d83-19b0775d4b20",
          "traceId": "7928941f",
          "type": "GENERATION",
          "name": "7928_tpusg_gen_attempt#5",
          "startTime": "2025-12-11T00:05:41.768000+00:00",
          "endTime": "2025-12-11T00:06:07.560000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 25792.0,
          "completionTokens": 699,
          "environment": "default",
          "totalTokens": 1010,
          "promptTokens": 311,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        }
      ],
      "createdAt": "2025-12-11T00:03:26.107Z",
      "updatedAt": "2025-12-11T00:07:19.848Z",
      "environment": "default"
    },
    {
      "id": "4b2654a3",
      "timestamp": "2025-12-11T00:00:01.562000+00:00",
      "name": "4b26_tpu_sketch_generator",
      "input": null,
      "output": {
        "status": "success",
        "sketch": "import cv2\nimport numpy as np\nfrom PIL import Image\nfrom pycoral.adapters import common, detect\nfrom pycoral.utils.dataset import read_label_file\nfrom pycoral.utils.edgetpu import make_interpreter\n\n# Configuration parameters\nmodel_path = '/home/mendel/tinyml_autopilot/models/edgetpu_detect.tflite'\nlabel_path = '/home/mendel/tinyml_autopilot/models/labelmap.txt'\ninput_path = '/home/mendel/tinyml_autopilot/data/sheeps.mp4'\noutput_path = '/home/mendel/tinyml_autopilot/results/sheeps_detections.mp4'\nconfidence_threshold = 0.5\n\n# Load TFLite interpreter for TPU\ninterpreter = make_interpreter(model_path)\ninterpreter.allocate_tensors()\nlabels = read_label_file(label_path)\n\n# Preprocessing function\ndef preprocess_image(image):\n    image = Image.fromarray(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n    resized_image = image.resize(common.input_size(interpreter), Image.ANTIALIAS)\n    return np.array(resized_image)\n\n# Inference function\ndef run_inference(input_tensor):\n    common.set_input(interpreter, input_tensor)\n    interpreter.invoke()\n    return detect.get_objects(interpreter, confidence_threshold)\n\n# Function to draw detection boxes and labels on the frame\ndef draw_detections(frame, detections):\n    height, width, _ = frame.shape\n    for obj in detections:\n        bbox = obj.bbox\n        x0, y0 = int(bbox.xmin * width), int(bbox.ymin * height)\n        x1, y1 = int(bbox.xmax * width), int(bbox.ymax * height)\n        percent = int(100 * obj.score)\n        label = '{}% {}'.format(percent, labels.get(obj.id, obj.id))\n        \n        cv2.rectangle(frame, (x0, y0), (x1, y1), (0, 255, 0), 2)\n        cv2.putText(frame, label, (x0, y0 - 5), cv2.FONT_HERSHEY_SIMPLEX,\n                    0.5, (0, 255, 0), 1)\n\n# Read input video\ncap = cv2.VideoCapture(input_path)\nif not cap.isOpened():\n    raise IOError(\"Error opening video stream or file\")\n\n# Define the codec and create VideoWriter object\nfourcc = cv2.VideoWriter_fourcc(*'mp4v')\nout = cv2.VideoWriter(output_path, fourcc, 30.0, (int(cap.get(3)), int(cap.get(4))))\n\nwhile cap.isOpened():\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    # Preprocess the frame\n    input_tensor = preprocess_image(frame)\n\n    # Run inference\n    detections = run_inference(input_tensor)\n\n    # Draw detection boxes and labels\n    draw_detections(frame, detections)\n\n    # Write the processed frame to the output video file\n    out.write(frame)\n\n# Release everything when job is finished\ncap.release()\nout.release()\ncv2.destroyAllWindows()"
      },
      "session_id": "qwen2.5-coder:32b_a8a2_tpusg_batch",
      "metadata": {
        "num_run": 5
      },
      "tags": [
        "ablation",
        "benchmark",
        "qwen2.5-coder:32b",
        "tpu_sketch_generator"
      ],
      "latency": 122.874,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-02-00-01-563870_chatcmpl-b5400084-e7bd-4953-87ee-36561d1a6895",
          "traceId": "4b2654a3",
          "type": "GENERATION",
          "name": "4b26_tpusg_gen_attempt#1",
          "startTime": "2025-12-11T00:00:01.563000+00:00",
          "endTime": "2025-12-11T00:00:27.502000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 25939.0,
          "completionTokens": 701,
          "environment": "default",
          "totalTokens": 1012,
          "promptTokens": 311,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-02-00-35-602828_chatcmpl-35147eaa-be1d-414c-8ef2-119edea822f1",
          "traceId": "4b2654a3",
          "type": "GENERATION",
          "name": "4b26_tpusg_gen_attempt#2",
          "startTime": "2025-12-11T00:00:35.602000+00:00",
          "endTime": "2025-12-11T00:00:57.900000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 22298.0,
          "completionTokens": 605,
          "environment": "default",
          "totalTokens": 916,
          "promptTokens": 311,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-02-01-05-871906_chatcmpl-d89c212b-b2ee-40fa-b789-fdbf4c29ab6d",
          "traceId": "4b2654a3",
          "type": "GENERATION",
          "name": "4b26_tpusg_gen_attempt#3",
          "startTime": "2025-12-11T00:01:05.871000+00:00",
          "endTime": "2025-12-11T00:01:29.309000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 23438.0,
          "completionTokens": 636,
          "environment": "default",
          "totalTokens": 947,
          "promptTokens": 311,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-02-01-37-897628_chatcmpl-81748af3-2263-4df1-b5a3-634550500a3a",
          "traceId": "4b2654a3",
          "type": "GENERATION",
          "name": "4b26_tpusg_gen_attempt#4",
          "startTime": "2025-12-11T00:01:37.897000+00:00",
          "endTime": "2025-12-11T00:02:04.437000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 26540.0,
          "completionTokens": 719,
          "environment": "default",
          "totalTokens": 1030,
          "promptTokens": 311,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        }
      ],
      "createdAt": "2025-12-11T00:00:02.085Z",
      "updatedAt": "2025-12-11T00:03:15.770Z",
      "environment": "default"
    },
    {
      "id": "cca4be2d",
      "timestamp": "2025-12-10T23:57:38.632000+00:00",
      "name": "cca4_tpu_sketch_generator",
      "input": null,
      "output": {
        "status": "success",
        "sketch": "import numpy as np\nimport cv2\nfrom PIL import Image\nfrom pycoral.utils.edgetpu import make_interpreter\nfrom pycoral.adapters import common, detect\n\n# Configuration parameters\nmodel_path = '/home/mendel/tinyml_autopilot/models/edgetpu_detect.tflite'\nlabel_path = '/home/mendel/tinyml_autopilot/models/labelmap.txt'\ninput_path = '/home/mendel/tinyml_autopilot/data/sheeps.mp4'\noutput_path = '/home/mendel/tinyml_autopilot/results/sheeps_detections.mp4'\nconfidence_threshold = 0.5\n\n# Load labels\ndef load_labels(label_path):\n    with open(label_path, 'r', encoding='utf-8') as f:\n        return {i: line.strip() for i, line in enumerate(f.readlines())}\n\n# Setup interpreter\ninterpreter = make_interpreter(model_path)\ninterpreter.allocate_tensors()\n_, height, width, _ = interpreter.get_input_details()[0]['shape']\n\n# Load labels\nlabels = load_labels(label_path)\n\n# Read video\ncap = cv2.VideoCapture(input_path)\nfourcc = cv2.VideoWriter_fourcc(*'mp4v')\nout = cv2.VideoWriter(output_path, fourcc, cap.get(cv2.CAP_PROP_FPS), (int(cap.get(3)), int(cap.get(4))))\n\ndef draw_objects(frame, objs, labels, confidence_threshold):\n    for obj in objs:\n        if obj.score > confidence_threshold:\n            bbox = obj.bbox\n            label = labels.get(obj.id, 'Unknown')\n            text = f'{label}: {obj.score:.2f}'\n            color = (0, 255, 0)\n            cv2.rectangle(frame, (bbox.xmin, bbox.ymin), (bbox.xmax, bbox.ymax), color, 2)\n            cv2.putText(frame, text, (bbox.xmin, bbox.ymin - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n\nwhile cap.isOpened():\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    # Preprocessing\n    image = Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)).resize((width, height), Image.ANTIALIAS)\n    input_tensor = np.array(image)\n\n    # Inference\n    common.set_input(interpreter, input_tensor)\n    interpreter.invoke()\n    objs = detect.get_objects(interpreter, score_threshold=confidence_threshold, image_scale=(1.0, 1.0))\n\n    # Draw detections\n    draw_objects(frame, objs, labels, confidence_threshold)\n\n    # Output handling\n    out.write(cv2.cvtColor(frame, cv2.COLOR_RGB2BGR))\n\ncap.release()\nout.release()\ncv2.destroyAllWindows()"
      },
      "session_id": "qwen2.5-coder:32b_a8a2_tpusg_batch",
      "metadata": {
        "num_run": 4
      },
      "tags": [
        "ablation",
        "benchmark",
        "qwen2.5-coder:32b",
        "tpu_sketch_generator"
      ],
      "latency": 60.927,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-01-57-38-634311_chatcmpl-18bb549c-533a-4bab-8ed7-86b0660dd298",
          "traceId": "cca4be2d",
          "type": "GENERATION",
          "name": "cca4_tpusg_gen_attempt#1",
          "startTime": "2025-12-10T23:57:38.634000+00:00",
          "endTime": "2025-12-10T23:58:09.525000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 30891.0,
          "completionTokens": 835,
          "environment": "default",
          "totalTokens": 1146,
          "promptTokens": 311,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-01-58-18-026348_chatcmpl-dad44309-8071-4e4d-a6e7-b82947cf126e",
          "traceId": "cca4be2d",
          "type": "GENERATION",
          "name": "cca4_tpusg_gen_attempt#2",
          "startTime": "2025-12-10T23:58:18.026000+00:00",
          "endTime": "2025-12-10T23:58:39.561000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 21535.0,
          "completionTokens": 584,
          "environment": "default",
          "totalTokens": 895,
          "promptTokens": 311,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        }
      ],
      "createdAt": "2025-12-10T23:57:39.151Z",
      "updatedAt": "2025-12-10T23:59:52.014Z",
      "environment": "default"
    },
    {
      "id": "06874eba",
      "timestamp": "2025-12-10T23:53:36.592000+00:00",
      "name": "0687_tpu_sketch_generator",
      "input": null,
      "output": {
        "status": "failed",
        "last_code": "import cv2\nimport numpy as np\nfrom PIL import Image\nfrom pycoral.utils.edgetpu import make_interpreter\nfrom pycoral.adapters.common import input_size\nfrom pycoral.adapters.detect import get_objects\n\n# Configuration parameters\nmodel_path = '/home/mendel/tinyml_autopilot/models/edgetpu_detect.tflite'\nlabel_path = '/home/mendel/tinyml_autopilot/models/labelmap.txt'\ninput_path = '/home/mendel/tinyml_autopilot/data/sheeps.mp4'\noutput_path = '/home/mendel/tinyml_autopilot/results/sheeps_detections.mp4'\nconfidence_threshold = 0.5\n\n# Load labels\ndef load_labels(filename):\n    with open(filename, 'r', encoding='utf-8') as f:\n        return {int(line.split(maxsplit=1)[0]): line.split(maxsplit=1)[1].strip() for line in f}\n\nlabels = load_labels(label_path)\n\n# Setup TFLite interpreter\ninterpreter = make_interpreter(model_path)\ninterpreter.allocate_tensors()\n_, height, width, _ = input_size(interpreter)\n\n# Preprocessing function\ndef preprocess(image):\n    image = cv2.resize(image, (width, height))\n    image = Image.fromarray(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n    return np.array(image).astype(np.uint8)\n\n# Function to draw detection boxes and labels\ndef draw_detections(frame, detections):\n    for obj in detections:\n        if obj.score >= confidence_threshold:\n            bbox = obj.bbox\n            class_id = int(obj.id)\n            label = labels.get(class_id, 'Unknown')\n            cv2.rectangle(frame, (bbox.xmin, bbox.ymin), (bbox.xmax, bbox.ymax), (0, 255, 0), 2)\n            cv2.putText(frame, f'{label}: {obj.score:.2f}', (bbox.xmin, bbox.ymin - 10),\n                        cv2.FONT_HERSHEY_SIMPLEX, 0.9, (36, 255, 12), 2)\n\n# Read input video\ncap = cv2.VideoCapture(input_path)\nfourcc = cv2.VideoWriter_fourcc(*'mp4v')\nout = cv2.VideoWriter(output_path, fourcc, cap.get(cv2.CAP_PROP_FPS), (int(cap.get(3)), int(cap.get(4))))\n\nwhile cap.isOpened():\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    preprocessed_image = preprocess(frame)\n    interpreter.set_tensor(interpreter.get_input_details()[0]['index'], [preprocessed_image])\n    interpreter.invoke()\n\n    detections = get_objects(interpreter, confidence_threshold)\n\n    draw_detections(frame, detections)\n    out.write(frame)\n\ncap.release()\nout.release()\ncv2.destroyAllWindows()",
        "last_error": "Max retries reached with error. Last error: Traceback (most recent call last):\n  File \"script_9b121c87_1765411024.py\", line 20, in <module>\n    labels = load_labels(label_path)\n  File \"script_9b121c87_1765411024.py\", line 18, in load_labels\n    return {int(line.split(maxsplit=1)[0]): line.split(maxsplit=1)[1].strip() for line in f}\n  File \"script_9b121c87_1765411024.py\", line 18, in <dictcomp>\n    return {int(line.split(maxsplit=1)[0]): line.split(maxsplit=1)[1].strip() for line in f}\nIndexError: list index out of range."
      },
      "session_id": "qwen2.5-coder:32b_a8a2_tpusg_batch",
      "metadata": {
        "num_run": 3
      },
      "tags": [
        "ablation",
        "benchmark",
        "qwen2.5-coder:32b",
        "tpu_sketch_generator"
      ],
      "latency": 216.091,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-01-53-36-593814_chatcmpl-60fdf708-29b8-4bf6-8b03-63fd8ce3a6bb",
          "traceId": "06874eba",
          "type": "GENERATION",
          "name": "0687_tpusg_gen_attempt#1",
          "startTime": "2025-12-10T23:53:36.593000+00:00",
          "endTime": "2025-12-10T23:54:29.631000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 53038.0,
          "completionTokens": 1420,
          "environment": "default",
          "totalTokens": 1731,
          "promptTokens": 311,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-01-54-38-209381_chatcmpl-0447f538-3b86-4c30-ab83-d32585608f3e",
          "traceId": "06874eba",
          "type": "GENERATION",
          "name": "0687_tpusg_gen_attempt#2",
          "startTime": "2025-12-10T23:54:38.209000+00:00",
          "endTime": "2025-12-10T23:55:25.510000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 47301.0,
          "completionTokens": 1272,
          "environment": "default",
          "totalTokens": 1583,
          "promptTokens": 311,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-01-55-34-089652_chatcmpl-5f701561-8724-440d-9d10-09c09d5c6f62",
          "traceId": "06874eba",
          "type": "GENERATION",
          "name": "0687_tpusg_gen_attempt#3",
          "startTime": "2025-12-10T23:55:34.089000+00:00",
          "endTime": "2025-12-10T23:56:00.184000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 26095.0,
          "completionTokens": 707,
          "environment": "default",
          "totalTokens": 1018,
          "promptTokens": 311,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-01-56-08-592536_chatcmpl-889fe541-2103-4d1d-980f-fdd686473c82",
          "traceId": "06874eba",
          "type": "GENERATION",
          "name": "0687_tpusg_gen_attempt#4",
          "startTime": "2025-12-10T23:56:08.592000+00:00",
          "endTime": "2025-12-10T23:56:34.535000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 25943.0,
          "completionTokens": 703,
          "environment": "default",
          "totalTokens": 1014,
          "promptTokens": 311,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-01-56-42-671419_chatcmpl-aa335e34-538a-47a0-b900-65893c7ca1a6",
          "traceId": "06874eba",
          "type": "GENERATION",
          "name": "0687_tpusg_gen_attempt#5",
          "startTime": "2025-12-10T23:56:42.671000+00:00",
          "endTime": "2025-12-10T23:57:04.558000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 21887.0,
          "completionTokens": 593,
          "environment": "default",
          "totalTokens": 904,
          "promptTokens": 311,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "d68120b8-3b7b-4a21-96c6-e1428d99d044",
          "traceId": "06874eba",
          "type": "SPAN",
          "name": "error_06_tpusg_failure_signal_tpu_sketch_generator",
          "startTime": "2025-12-10T23:57:12.684000+00:00",
          "level": "ERROR",
          "statusMessage": "Failed: Max retries reached with error. Last error: Traceback (most recent call last):\n  File \"script_9b121c87_1765411024.py\", line 20, in <module>\n    labels = load_labels(label_path)\n  File \"script_9b121c87_1765411024.py\", line 18, in load_labels\n    return {int(line.split(maxsplit=1)[0]): line.split(maxsplit=1)[1].strip() for line in f}\n  File \"script_9b121c87_1765411024.py\", line 18, in <dictcomp>\n    return {int(line.split(maxsplit=1)[0]): line.split(maxsplit=1)[1].strip() for line in f}\nIndexError: list index out of range.",
          "calculatedTotalCost": 0.0,
          "completionTokens": 0,
          "environment": "default",
          "totalTokens": 0,
          "promptTokens": 0,
          "costDetails": {},
          "endTime": null,
          "model": null,
          "modelParameters": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null,
          "latency": null
        }
      ],
      "createdAt": "2025-12-10T23:53:37.109Z",
      "updatedAt": "2025-12-10T23:57:27.895Z",
      "environment": "default"
    },
    {
      "id": "ff70460e",
      "timestamp": "2025-12-10T23:51:46.609000+00:00",
      "name": "ff70_tpu_sketch_generator",
      "input": null,
      "output": {
        "status": "success",
        "sketch": "import os\nimport cv2\nimport numpy as np\nfrom PIL import Image\nfrom pycoral.adapters.common import input_size\nfrom pycoral.adapters.detect import get_objects\nfrom pycoral.utils.dataset import read_label_file\nfrom pycoral.utils.edgetpu import make_interpreter\n\n# Configuration parameters\nmodel_path = '/home/mendel/tinyml_autopilot/models/edgetpu_detect.tflite'\nlabel_path = '/home/mendel/tinyml_autopilot/models/labelmap.txt'\ninput_path = '/home/mendel/tinyml_autopilot/data/sheeps.mp4'\noutput_path = '/home/mendel/tinyml_autopilot/results/sheeps_detections.mp4'\nconfidence_threshold = 0.5\n\n# Step 1: Setup - Load the TFLite interpreter for TPU\ninterpreter = make_interpreter(model_path, device=':0')\ninterpreter.allocate_tensors()\nlabels = read_label_file(label_path)\n\n# Get model details\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\nheight, width = input_size(interpreter)\n\n# Step 2: Preprocessing - Read the input video and prepare frames for inference\ncap = cv2.VideoCapture(input_path)\nfourcc = cv2.VideoWriter_fourcc(*'mp4v')\nout = cv2.VideoWriter(output_path, fourcc, cap.get(cv2.CAP_PROP_FPS), (int(cap.get(3)), int(cap.get(4))))\n\nwhile cap.isOpened():\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    # Resize and normalize the image\n    img = Image.fromarray(frame).convert('RGB').resize((width, height), Image.ANTIALIAS)\n    input_tensor = np.array(img).reshape((1, width, height, 3))\n    \n    # Step 3: Inference - Run object detection on the frame\n    interpreter.set_tensor(input_details[0]['index'], input_tensor.astype(np.uint8))\n    interpreter.invoke()\n    objs = get_objects(interpreter, score_threshold=confidence_threshold)\n\n    # Step 4: Output Handling - Draw detection boxes and labels on the frame\n    for obj in objs:\n        bbox = obj.bbox\n        label = labels.get(obj.id, 'Unknown')\n        color = (255, 0, 0)  # Blue color for bounding box\n\n        # Scale the bounding box to match the original image size\n        scale_x = frame.shape[1] / width\n        scale_y = frame.shape[0] / height\n        bbox = (bbox.xmin * scale_x, bbox.ymin * scale_y, bbox.xmax * scale_x, bbox.ymax * scale_y)\n\n        # Draw bounding box and label\n        cv2.rectangle(frame, (int(bbox[0]), int(bbox[1])), (int(bbox[2]), int(bbox[3])), color, 2)\n        cv2.putText(frame, f'{label}: {obj.score:.2f}', (int(bbox[0]), int(bbox[1]) - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n\n    # Write the frame with detections to the output video\n    out.write(frame)\n\n# Release resources\ncap.release()\nout.release()\ncv2.destroyAllWindows()"
      },
      "session_id": "qwen2.5-coder:32b_a8a2_tpusg_batch",
      "metadata": {
        "num_run": 2
      },
      "tags": [
        "ablation",
        "benchmark",
        "qwen2.5-coder:32b",
        "tpu_sketch_generator"
      ],
      "latency": 27.902,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-01-51-46-610851_chatcmpl-af62df65-5923-43a4-9c92-ebd0e5dc4876",
          "traceId": "ff70460e",
          "type": "GENERATION",
          "name": "ff70_tpusg_gen_attempt#1",
          "startTime": "2025-12-10T23:51:46.610000+00:00",
          "endTime": "2025-12-10T23:52:14.512000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 27902.0,
          "completionTokens": 753,
          "environment": "default",
          "totalTokens": 1064,
          "promptTokens": 311,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        }
      ],
      "createdAt": "2025-12-10T23:51:47.126Z",
      "updatedAt": "2025-12-10T23:53:26.800Z",
      "environment": "default"
    },
    {
      "id": "fa27dfb0",
      "timestamp": "2025-12-10T23:49:26.979000+00:00",
      "name": "fa27_tpu_sketch_generator",
      "input": null,
      "output": {
        "status": "success",
        "sketch": "import cv2\nimport numpy as np\nfrom PIL import Image\nfrom pycoral.adapters.common import input_size\nfrom pycoral.adapters.detect import get_objects\nfrom pycoral.utils.dataset import read_label_file\nfrom pycoral.utils.edgetpu import make_interpreter\n\n# Configuration parameters\nmodel_path = '/home/mendel/tinyml_autopilot/models/edgetpu_detect.tflite'\nlabel_path = '/home/mendel/tinyml_autopilot/models/labelmap.txt'\ninput_path = '/home/mendel/tinyml_autopilot/data/sheeps.mp4'\noutput_path = '/home/mendel/tinyml_autopilot/results/sheeps_detections.mp4'\nconfidence_threshold = 0.5\n\n# Setup\ninterpreter = make_interpreter(model_path, device=':0')\ninterpreter.allocate_tensors()\nlabels = read_label_file(label_path)\n\n# Preprocessing\ncap = cv2.VideoCapture(input_path)\nwidth = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\nheight = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\nfps = cap.get(cv2.CAP_PROP_FPS)\n\nfourcc = cv2.VideoWriter_fourcc(*'mp4v')\nout = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n\ndef preprocess(image):\n    image = Image.fromarray(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n    resized_image = image.resize(input_size(interpreter), Image.ANTIALIAS)\n    return np.array(resized_image)\n\n# Inference and Output Handling\nwhile cap.isOpened():\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    preprocessed_frame = preprocess(frame)\n    interpreter.set_tensor(interpreter.get_input_details()[0]['index'], [preprocessed_frame.astype(np.uint8)])\n    interpreter.invoke()\n\n    detected_objects = get_objects(interpreter, score_threshold=confidence_threshold, image_scale=(width / 320.0, height / 320.0))\n    \n    for obj in detected_objects:\n        bbox = obj.bbox\n        cv2.rectangle(frame, (int(bbox.xmin), int(bbox.ymin)), (int(bbox.xmax), int(bbox.ymax)), (0, 255, 0), 2)\n        label = f'{labels.get(obj.id, \"Unknown\")}: {obj.score:.2f}'\n        cv2.putText(frame, label, (int(bbox.xmin), int(bbox.ymin) - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n\n    out.write(frame)\n\ncap.release()\nout.release()\ncv2.destroyAllWindows()"
      },
      "session_id": "qwen2.5-coder:32b_a8a2_tpusg_batch",
      "metadata": {
        "num_run": 1
      },
      "tags": [
        "ablation",
        "benchmark",
        "qwen2.5-coder:32b",
        "tpu_sketch_generator"
      ],
      "latency": 57.835,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-01-49-26-980953_chatcmpl-ad7a56ec-d833-4453-8e02-c86e742875f6",
          "traceId": "fa27dfb0",
          "type": "GENERATION",
          "name": "fa27_tpusg_gen_attempt#1",
          "startTime": "2025-12-10T23:49:26.980000+00:00",
          "endTime": "2025-12-10T23:49:53.644000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 26664.0,
          "completionTokens": 702,
          "environment": "default",
          "totalTokens": 1013,
          "promptTokens": 311,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-01-50-02-204701_chatcmpl-9c964e24-81ea-47f7-bbf1-bcc36890a5e5",
          "traceId": "fa27dfb0",
          "type": "GENERATION",
          "name": "fa27_tpusg_gen_attempt#2",
          "startTime": "2025-12-10T23:50:02.204000+00:00",
          "endTime": "2025-12-10T23:50:24.815000+00:00",
          "model": "qwen2.5-coder:32b",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 22611.0,
          "completionTokens": 613,
          "environment": "default",
          "totalTokens": 924,
          "promptTokens": 311,
          "costDetails": {},
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        }
      ],
      "createdAt": "2025-12-10T23:49:27.500Z",
      "updatedAt": "2025-12-10T23:51:37.204Z",
      "environment": "default"
    }
  ],
  "meta": {
    "total_items": 30
  }
}
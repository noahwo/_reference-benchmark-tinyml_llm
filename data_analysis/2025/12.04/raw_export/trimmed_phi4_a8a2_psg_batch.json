{
  "data": [
    {
      "id": "5facdb24",
      "timestamp": "2025-12-11T06:25:00.333000+00:00",
      "name": "5fac_py_sketch_generator",
      "input": null,
      "output": {
        "status": "success",
        "sketch": "import cv2\nimport numpy as np\nimport tensorflow as tf\nfrom sklearn.metrics import average_precision_score\n\n# Configuration parameters\nmodel_path = 'models/ssd-mobilenet_v1/detect.tflite'\nlabel_path = 'models/ssd-mobilenet_v1/labelmap.txt'\ninput_path = 'data/object_detection/sheeps.mp4'\noutput_path = 'results/object_detection/test_results/sheeps_detections.mp4'\nconfidence_threshold = 0.5\n\n# Phase 1: Setup\ndef load_labels(label_file):\n    with open(label_file, 'r') as f:\n        labels = [line.strip() for line in f.readlines()]\n    return labels\n\ndef create_interpreter(model_path):\n    interpreter = tf.lite.Interpreter(model_path=model_path)\n    interpreter.allocate_tensors()\n    return interpreter\n\ninterpreter = create_interpreter(model_path)\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\n\n# Get input shape\n_, height, width, _ = input_details[0]['shape']\n\nlabels = load_labels(label_path)\n\n# Phase 2: Preprocessing\ndef preprocess_frame(frame):\n    frame_resized = cv2.resize(frame, (width, height))\n    input_data = np.expand_dims(frame_resized, axis=0)\n    return input_data\n\n# Phase 3: Inference\ndef run_inference(interpreter, frame):\n    interpreter.set_tensor(input_details[0]['index'], frame)\n    interpreter.invoke()\n    \n    boxes = interpreter.get_tensor(output_details[0]['index'])[0]  # Bounding box coordinates of detected objects\n    classes = interpreter.get_tensor(output_details[1]['index'])[0]  # Class index of detected objects\n    scores = interpreter.get_tensor(output_details[2]['index'])[0]  # Confidence of detected objects\n    \n    return boxes, classes, scores\n\ndef compute_map(ground_truths, predictions):\n    # Assuming ground_truths and predictions are lists of bounding box coordinates and labels for each frame\n    all_ap_scores = []\n    for gt_boxes, pred_boxes, pred_labels in zip(ground_truths, predictions['boxes'], predictions['labels']):\n        ap_score = average_precision_score(gt_boxes[:, -1], pred_boxes[:, -1])\n        all_ap_scores.append(ap_score)\n    \n    mean_ap = np.mean(all_ap_scores) if all_ap_scores else 0.0\n    return mean_ap\n\n# Phase 4: Output Handling\ndef draw_detections(frame, boxes, classes, scores, labels):\n    for i in range(len(scores)):\n        if scores[i] > confidence_threshold:\n            ymin, xmin, ymax, xmax = boxes[i]\n            (left, right, top, bottom) = (xmin * frame.shape[1], xmax * frame.shape[1],\n                                          ymin * frame.shape[0], ymax * frame.shape[0])\n            \n            cv2.rectangle(frame, (int(left), int(top)), (int(right), int(bottom)), (10, 255, 0), 2)\n            label = f\"{labels[int(classes[i])]}: {int(scores[i] * 100)}%\"\n            cv2.putText(frame, label, (int(left), int(top) - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2)\n\ndef main():\n    # Open video files\n    cap = cv2.VideoCapture(input_path)\n    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n    out = cv2.VideoWriter(output_path, fourcc, 30.0, (int(cap.get(3)), int(cap.get(4))))\n\n    detections = {'boxes': [], 'labels': []}\n    \n    while cap.isOpened():\n        ret, frame = cap.read()\n        if not ret:\n            break\n\n        # Preprocess\n        input_data = preprocess_frame(frame)\n\n        # Inference\n        boxes, classes, scores = run_inference(interpreter, input_data)\n\n        # Draw detections\n        draw_detections(frame, boxes, classes, scores, labels)\n        \n        # Store predictions for mAP computation (dummy ground truth for demonstration)\n        detections['boxes'].append(boxes[scores > confidence_threshold])\n        detections['labels'].append([int(classes[i]) for i in range(len(scores)) if scores[i] > confidence_threshold])\n\n        out.write(frame)\n\n    cap.release()\n    out.release()\n\n    # Compute mAP (dummy ground truth for demonstration)\n    mean_ap = compute_map([], detections)  # Replace [] with actual ground truths\n    print(f\"Mean Average Precision: {mean_ap}\")\n\nif __name__ == \"__main__\":\n    main()"
      },
      "session_id": "phi4_a8a2_psg_batch",
      "metadata": {
        "num_run": 30
      },
      "tags": [
        "ablation",
        "benchmark",
        "phi4:latest",
        "py_sketch_generator"
      ],
      "latency": 56.08,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-08-25-00-334372_chatcmpl-ea997ae4-7b01-4eef-9031-13b09cf4a025",
          "traceId": "5facdb24",
          "type": "GENERATION",
          "name": "5fac_psg_gen_attempt#1",
          "startTime": "2025-12-11T06:25:00.334000+00:00",
          "endTime": "2025-12-11T06:25:20.758000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 20424.0,
          "promptTokens": 245,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 1116,
          "totalTokens": 1361,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-08-25-23-756540_chatcmpl-5f4cd00e-7b96-48e1-90c5-979f233fcd55",
          "traceId": "5facdb24",
          "type": "GENERATION",
          "name": "5fac_psg_gen_attempt#2",
          "startTime": "2025-12-11T06:25:23.756000+00:00",
          "endTime": "2025-12-11T06:25:38.698000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 14942.0,
          "promptTokens": 245,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 823,
          "totalTokens": 1068,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-08-25-38-852421_chatcmpl-532917bf-8b0c-4ab3-b033-bb36a169a078",
          "traceId": "5facdb24",
          "type": "GENERATION",
          "name": "5fac_psg_gen_attempt#3",
          "startTime": "2025-12-11T06:25:38.852000+00:00",
          "endTime": "2025-12-11T06:25:56.414000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 17562.0,
          "promptTokens": 245,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 965,
          "totalTokens": 1210,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        }
      ],
      "createdAt": "2025-12-11T06:25:00.851Z",
      "updatedAt": "2025-12-11T06:26:10.497Z",
      "environment": "default"
    },
    {
      "id": "1dace6ca",
      "timestamp": "2025-12-11T06:22:59.382000+00:00",
      "name": "1dac_py_sketch_generator",
      "input": null,
      "output": {
        "status": "failed",
        "last_code": "import cv2\nimport numpy as np\nimport tensorflow as tf\n\n# Configuration parameters\nmodel_path = 'models/ssd-mobilenet_v1/detect.tflite'\nlabel_path = 'models/ssd-mobilenet_v1/labelmap.txt'\ninput_path = 'data/object_detection/sheeps.mp4'\noutput_path = 'results/object_detection/test_results/sheeps_detections.mp4'\nconfidence_threshold = 0.5\n\n# Setup\ndef load_labels(label_file):\n    with open(label_file, 'r') as file:\n        return [line.strip() for line in file.readlines()]\n\nlabels = load_labels(label_path)\ninterpreter = tf.lite.Interpreter(model_path=model_path)\ninterpreter.allocate_tensors()\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\n\n# Preprocessing\ndef preprocess_frame(frame):\n    input_shape = input_details[0]['shape']\n    frame_resized = cv2.resize(frame, (input_shape[1], input_shape[2]))\n    input_data = np.expand_dims(frame_resized, axis=0).astype(np.float32)\n    return input_data\n\n# Inference\ndef run_inference(input_data):\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n    interpreter.invoke()\n    boxes = interpreter.get_tensor(output_details[0]['index'])[0]\n    classes = interpreter.get_tensor(output_details[1]['index'])[0].astype(np.int64)\n    scores = interpreter.get_tensor(output_details[2]['index'])[0]\n    return boxes, classes, scores\n\n# Output handling\ndef draw_detections(frame, boxes, classes, scores):\n    for i in range(len(scores)):\n        if scores[i] > confidence_threshold:\n            ymin, xmin, ymax, xmax = boxes[i]\n            (left, right, top, bottom) = (xmin * frame.shape[1], xmax * frame.shape[1],\n                                          ymin * frame.shape[0], ymax * frame.shape[0])\n            cv2.rectangle(frame, (int(left), int(top)), (int(right), int(bottom)),\n                          color=(0, 255, 0), thickness=2)\n            label = f'{labels[classes[i]]}: {int(scores[i] * 100)}%'\n            cv2.putText(frame, label, (int(left), int(top) - 10),\n                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n    return frame\n\ndef compute_map():\n    # Placeholder for mAP computation logic\n    pass\n\n# Main processing loop\ncap = cv2.VideoCapture(input_path)\nfourcc = cv2.VideoWriter_fourcc(*'mp4v')\nout = cv2.VideoWriter(output_path, fourcc, 20.0, (int(cap.get(3)), int(cap.get(4))))\n\nwhile cap.isOpened():\n    ret, frame = cap.read()\n    if not ret:\n        break\n    \n    input_data = preprocess_frame(frame)\n    boxes, classes, scores = run_inference(input_data)\n    output_frame = draw_detections(frame, boxes, classes, scores)\n    \n    out.write(output_frame)\n\ncap.release()\nout.release()\n\ncompute_map()  # Call the mAP computation function if needed",
        "last_error": "Max retries reached with failure. Last error from execution: 2025-12-11 08:24:31.703786: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n2025-12-11 08:24:31.707454: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n2025-12-11 08:24:31.719138: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2025-12-11 08:24:31.738095: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2025-12-11 08:24:31.743651: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n2025-12-11 08:24:31.757294: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\nTo enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n2025-12-11 08:24:32.594978: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\nINFO: Created TensorFlow Lite XNNPACK delegate for CPU.\nTraceback (most recent call last):\n  File \"/home/wuguangh/Projects/03.12/tinyml-autopilot-pm.03.12.2025/results/object_detection/sketches/tmp_20251211082431_psg_phi4:latest/tmp_20251211082431_psg_phi4:latest.py\", line 68, in <module>\n    boxes, classes, scores = run_inference(input_data)\n  File \"/home/wuguangh/Projects/03.12/tinyml-autopilot-pm.03.12.2025/results/object_detection/sketches/tmp_20251211082431_psg_phi4:latest/tmp_20251211082431_psg_phi4:latest.py\", line 32, in run_inference\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n  File \"/home/wuguangh/.conda/envs/tinyml/lib/python3.10/site-packages/tensorflow/lite/python/interpreter.py\", line 732, in set_tensor\n    self._interpreter.SetTensor(tensor_index, value)\nValueError: Cannot set tensor: Got value of type FLOAT32 but expected type UINT8 for input 175, name: normalized_input_image_tensor \n"
      },
      "session_id": "phi4_a8a2_psg_batch",
      "metadata": {
        "num_run": 29
      },
      "tags": [
        "ablation",
        "benchmark",
        "phi4:latest",
        "py_sketch_generator"
      ],
      "latency": 95.075,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-08-22-59-383707_chatcmpl-83a0d36b-c5d1-44d8-9745-e3d7559a0c9d",
          "traceId": "1dace6ca",
          "type": "GENERATION",
          "name": "1dac_psg_gen_attempt#1",
          "startTime": "2025-12-11T06:22:59.383000+00:00",
          "endTime": "2025-12-11T06:23:17.004000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 17621.0,
          "promptTokens": 245,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 963,
          "totalTokens": 1208,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-08-23-20-237059_chatcmpl-601e1b97-d5c2-4dbb-96e3-5dcc2079cf99",
          "traceId": "1dace6ca",
          "type": "GENERATION",
          "name": "1dac_psg_gen_attempt#2",
          "startTime": "2025-12-11T06:23:20.237000+00:00",
          "endTime": "2025-12-11T06:23:37.379000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 17142.0,
          "promptTokens": 245,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 942,
          "totalTokens": 1187,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-08-23-40-371796_chatcmpl-18a2f2c5-0cd7-4fdd-b634-2c9553043b42",
          "traceId": "1dace6ca",
          "type": "GENERATION",
          "name": "1dac_psg_gen_attempt#3",
          "startTime": "2025-12-11T06:23:40.371000+00:00",
          "endTime": "2025-12-11T06:23:57.681000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 17310.0,
          "promptTokens": 245,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 951,
          "totalTokens": 1196,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-08-24-01-080801_chatcmpl-b2f113ff-1778-4964-bb1a-b19b19275ce4",
          "traceId": "1dace6ca",
          "type": "GENERATION",
          "name": "1dac_psg_gen_attempt#4",
          "startTime": "2025-12-11T06:24:01.080000+00:00",
          "endTime": "2025-12-11T06:24:16.199000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 15119.0,
          "promptTokens": 245,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 833,
          "totalTokens": 1078,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-08-24-19-226560_chatcmpl-ccc93d19-c147-449c-b77c-7c49355c7471",
          "traceId": "1dace6ca",
          "type": "GENERATION",
          "name": "1dac_psg_gen_attempt#5",
          "startTime": "2025-12-11T06:24:19.226000+00:00",
          "endTime": "2025-12-11T06:24:31.366000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 12140.0,
          "promptTokens": 245,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 669,
          "totalTokens": 914,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "bafa165c-ed69-4e41-8d35-da3bfbaad053",
          "traceId": "1dace6ca",
          "type": "SPAN",
          "name": "error_1d_psg_failure_signal_py_sketch_generator",
          "startTime": "2025-12-11T06:24:34.458000+00:00",
          "level": "ERROR",
          "statusMessage": "Failed. Last error: Max retries reached with failure. Last error from execution: 2025-12-11 08:24:31.703786: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n2025-12-11 08:24:31.707454: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n2025-12-11 08:24:31.719138: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2025-12-11 08:24:31.738095: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2025-12-11 08:24:31.743651: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n2025-12-11 08:24:31.757294: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\nTo enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n2025-12-11 08:24:32.594978: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\nINFO: Created TensorFlow Lite XNNPACK delegate for CPU.\nTraceback (most recent call last):\n  File \"/home/wuguangh/Projects/03.12/tinyml-autopilot-pm.03.12.2025/results/object_detection/sketches/tmp_20251211082431_psg_phi4:latest/tmp_20251211082431_psg_phi4:latest.py\", line 68, in <module>\n    boxes, classes, scores = run_inference(input_data)\n  File \"/home/wuguangh/Projects/03.12/tinyml-autopilot-pm.03.12.2025/results/object_detection/sketches/tmp_20251211082431_psg_phi4:latest/tmp_20251211082431_psg_phi4:latest.py\", line 32, in run_inference\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n  File \"/home/wuguangh/.conda/envs/tinyml/lib/python3.10/site-packages/tensorflow/lite/python/interpreter.py\", line 732, in set_tensor\n    self._interpreter.SetTensor(tensor_index, value)\nValueError: Cannot set tensor: Got value of type FLOAT32 but expected type UINT8 for input 175, name: normalized_input_image_tensor \n",
          "calculatedTotalCost": 0.0,
          "promptTokens": 0,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 0,
          "totalTokens": 0,
          "endTime": null,
          "model": null,
          "modelParameters": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null,
          "latency": null
        }
      ],
      "createdAt": "2025-12-11T06:22:59.899Z",
      "updatedAt": "2025-12-11T06:24:40.075Z",
      "environment": "default"
    },
    {
      "id": "523d360f",
      "timestamp": "2025-12-11T06:21:10.453000+00:00",
      "name": "523d_py_sketch_generator",
      "input": null,
      "output": {
        "status": "failed",
        "last_code": "import cv2\nimport numpy as np\nimport tflite_runtime.interpreter as tflite\nfrom pycocotools.coco import COCO\nfrom pycocotools.cocoeval import COCOeval\n\ndef load_labels(label_path):\n    with open(label_path, 'r') as file:\n        labels = [line.strip() for line in file.readlines()]\n    return labels\n\ndef set_input_tensor(interpreter, image):\n    tensor_index = interpreter.get_input_details()[0]['index']\n    input_shape = interpreter.get_input_details()[0]['shape']\n    image = cv2.resize(image, (input_shape[1], input_shape[2]))\n    input_data = np.expand_dims(image, axis=0)\n    interpreter.set_tensor(tensor_index, input_data)\n\ndef get_output(interpreter):\n    boxes = interpreter.get_tensor(interpreter.get_output_details()[0]['index'])[0]\n    classes = interpreter.get_tensor(interpreter.get_output_details()[1]['index'])[0]\n    scores = interpreter.get_tensor(interpreter.get_output_details()[2]['index'])[0]\n    count = int(interpreter.get_tensor(interpreter.get_output_details()[3]['index'])[0])\n    return boxes, classes, scores, count\n\ndef load_labels_and_coco(label_path):\n    labels = load_labels(label_path)\n    coco = COCO(label_path.replace('labelmap.txt', 'instances_val2017.json'))\n    categories = {cat['id']: cat['name'] for cat in coco.loadCats(coco.getCatIds())}\n    return labels, categories\n\ndef draw_detections(image, boxes, classes, scores, labels, confidence_threshold):\n    height, width, _ = image.shape\n    for i in range(len(scores)):\n        if scores[i] > confidence_threshold:\n            class_id = int(classes[i])\n            box = tuple(boxes[i].tolist())\n            ymin, xmin, ymax, xmax = box\n            (left, right, top, bottom) = (xmin * width, xmax * width,\n                                          ymin * height, ymax * height)\n            cv2.rectangle(image, (int(left), int(top)), (int(right), int(bottom)), (10, 255, 0), 2)\n            label = f\"{labels[class_id]}: {int(scores[i] * 100)}%\"\n            cv2.putText(image, label, (int(left), int(top) - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (10, 255, 0), 2)\n\ndef main():\n    model_path = 'models/ssd-mobilenet_v1/detect.tflite'\n    label_path = 'models/ssd-mobilenet_v1/labelmap.txt'\n    input_path = 'data/object_detection/sheeps.mp4'\n    output_path = 'results/object_detection/test_results/sheeps_detections.mp4'\n    confidence_threshold = 0.5\n\n    # 1. Setup\n    interpreter = tflite.Interpreter(model_path=model_path)\n    interpreter.allocate_tensors()\n    labels, categories = load_labels_and_coco(label_path)\n\n    # 2. Preprocessing\n    cap = cv2.VideoCapture(input_path)\n    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n    out = cv2.VideoWriter(output_path, fourcc, 20.0, (int(cap.get(3)), int(cap.get(4))))\n\n    while cap.isOpened():\n        ret, frame = cap.read()\n        if not ret:\n            break\n\n        # 3. Inference\n        set_input_tensor(interpreter, frame)\n        interpreter.invoke()\n        boxes, classes, scores, count = get_output(interpreter)\n\n        # 4. Output handling\n        draw_detections(frame, boxes, classes, scores, labels, confidence_threshold)\n        out.write(frame)\n\n    cap.release()\n    out.release()\n\nif __name__ == '__main__':\n    main()",
        "last_error": "Max retries reached with failure. Last error from execution: Traceback (most recent call last):\n  File \"/home/wuguangh/Projects/03.12/tinyml-autopilot-pm.03.12.2025/results/object_detection/sketches/tmp_20251211082233_psg_phi4:latest/tmp_20251211082233_psg_phi4:latest.py\", line 4, in <module>\n    from pycocotools.coco import COCO\nModuleNotFoundError: No module named 'pycocotools'\n"
      },
      "session_id": "phi4_a8a2_psg_batch",
      "metadata": {
        "num_run": 28
      },
      "tags": [
        "ablation",
        "benchmark",
        "phi4:latest",
        "py_sketch_generator"
      ],
      "latency": 83.199,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-08-21-10-454742_chatcmpl-28fc079e-ca00-4e30-8289-85227ad8e529",
          "traceId": "523d360f",
          "type": "GENERATION",
          "name": "523d_psg_gen_attempt#1",
          "startTime": "2025-12-11T06:21:10.454000+00:00",
          "endTime": "2025-12-11T06:21:25.263000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 14809.0,
          "promptTokens": 245,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 811,
          "totalTokens": 1056,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-08-21-28-215646_chatcmpl-ce4f1c5a-588d-4b21-bac1-557476a0c405",
          "traceId": "523d360f",
          "type": "GENERATION",
          "name": "523d_psg_gen_attempt#2",
          "startTime": "2025-12-11T06:21:28.215000+00:00",
          "endTime": "2025-12-11T06:21:41.392000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 13177.0,
          "promptTokens": 245,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 726,
          "totalTokens": 971,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-08-21-44-377222_chatcmpl-e0318af0-06c9-4ecb-84b4-cfb067c0dfc8",
          "traceId": "523d360f",
          "type": "GENERATION",
          "name": "523d_psg_gen_attempt#3",
          "startTime": "2025-12-11T06:21:44.377000+00:00",
          "endTime": "2025-12-11T06:21:59.699000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 15322.0,
          "promptTokens": 245,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 843,
          "totalTokens": 1088,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-08-22-02-726401_chatcmpl-d4c7b62e-2f18-4780-a18c-7ee104bd8035",
          "traceId": "523d360f",
          "type": "GENERATION",
          "name": "523d_psg_gen_attempt#4",
          "startTime": "2025-12-11T06:22:02.726000+00:00",
          "endTime": "2025-12-11T06:22:16.130000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 13404.0,
          "promptTokens": 245,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 739,
          "totalTokens": 984,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-08-22-16-706012_chatcmpl-919dffca-46ff-487d-bb55-0e78e191dfd1",
          "traceId": "523d360f",
          "type": "GENERATION",
          "name": "523d_psg_gen_attempt#5",
          "startTime": "2025-12-11T06:22:16.706000+00:00",
          "endTime": "2025-12-11T06:22:33.518000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 16812.0,
          "promptTokens": 245,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 924,
          "totalTokens": 1169,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "474a5c8b-1f5f-4223-abab-b10c2161660f",
          "traceId": "523d360f",
          "type": "SPAN",
          "name": "error_52_psg_failure_signal_py_sketch_generator",
          "startTime": "2025-12-11T06:22:33.653000+00:00",
          "level": "ERROR",
          "statusMessage": "Failed. Last error: Max retries reached with failure. Last error from execution: Traceback (most recent call last):\n  File \"/home/wuguangh/Projects/03.12/tinyml-autopilot-pm.03.12.2025/results/object_detection/sketches/tmp_20251211082233_psg_phi4:latest/tmp_20251211082233_psg_phi4:latest.py\", line 4, in <module>\n    from pycocotools.coco import COCO\nModuleNotFoundError: No module named 'pycocotools'\n",
          "calculatedTotalCost": 0.0,
          "promptTokens": 0,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 0,
          "totalTokens": 0,
          "endTime": null,
          "model": null,
          "modelParameters": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null,
          "latency": null
        }
      ],
      "createdAt": "2025-12-11T06:21:10.972Z",
      "updatedAt": "2025-12-11T06:22:39.051Z",
      "environment": "default"
    },
    {
      "id": "5da73b99",
      "timestamp": "2025-12-11T06:20:20.516000+00:00",
      "name": "5da7_py_sketch_generator",
      "input": null,
      "output": {
        "status": "success",
        "sketch": "import cv2\nimport numpy as np\nimport tensorflow as tf\nfrom collections import defaultdict\n\n# Configuration parameters\nmodel_path = 'models/ssd-mobilenet_v1/detect.tflite'\nlabel_path = 'models/ssd-mobilenet_v1/labelmap.txt'\ninput_path = 'data/object_detection/sheeps.mp4'\noutput_path = 'results/object_detection/test_results/sheeps_detections.mp4'\nconfidence_threshold = 0.5\n\n# Phase 1: Setup\ndef load_labels(label_file):\n    with open(label_file, 'r') as file:\n        return {i: line.strip() for i, line in enumerate(file.readlines())}\n\nlabels = load_labels(label_path)\ninterpreter = tf.lite.Interpreter(model_path=model_path)\ninterpreter.allocate_tensors()\n\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\n\n# Phase 2: Preprocessing\ndef preprocess_frame(frame):\n    input_shape = input_details[0]['shape']\n    frame_resized = cv2.resize(frame, (input_shape[1], input_shape[2]))\n    input_data = np.expand_dims(frame_resized, axis=0)\n    return input_data\n\n# Phase 3: Inference\ndef run_inference(input_data):\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n    interpreter.invoke()\n    boxes = interpreter.get_tensor(output_details[0]['index'])[0] # Bounding box coordinates of detected objects\n    classes = interpreter.get_tensor(output_details[1]['index'])[0] # Class index of detected objects\n    scores = interpreter.get_tensor(output_details[2]['index'])[0] # Confidence of detected objects\n    return boxes, classes, scores\n\n# Phase 4: Output Handling\ndef compute_map(predictions, ground_truths):\n    # Placeholder for mAP computation logic\n    return 0.0\n\ndef draw_boxes(frame, boxes, classes, scores, labels):\n    for i in range(len(scores)):\n        if scores[i] > confidence_threshold:\n            ymin, xmin, ymax, xmax = boxes[i]\n            (left, right, top, bottom) = (xmin * frame.shape[1], xmax * frame.shape[1],\n                                          ymin * frame.shape[0], ymax * frame.shape[0])\n            cv2.rectangle(frame, (int(left), int(top)), (int(right), int(bottom)), (0, 255, 0), 2)\n            label = f'{labels[int(classes[i])]}: {scores[i]:.2f}'\n            cv2.putText(frame, label, (int(left), int(top) - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n\ndef process_video(input_path, output_path):\n    cap = cv2.VideoCapture(input_path)\n    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n    out = cv2.VideoWriter(output_path, fourcc, 20.0, (int(cap.get(3)), int(cap.get(4))))\n\n    all_detections = defaultdict(list)\n\n    while cap.isOpened():\n        ret, frame = cap.read()\n        if not ret:\n            break\n\n        input_data = preprocess_frame(frame)\n        boxes, classes, scores = run_inference(input_data)\n        \n        draw_boxes(frame, boxes, classes, scores, labels)\n        \n        # Collect detections for mAP computation\n        all_detections['boxes'].append(boxes)\n        all_detections['classes'].append(classes)\n        all_detections['scores'].append(scores)\n\n        out.write(frame)\n\n    cap.release()\n    out.release()\n\n    # Compute and print mean Average Precision (mAP)\n    mAP = compute_map(all_detections, {})  # Ground truths would be needed here\n    print(f\"Mean Average Precision: {mAP:.2f}\")\n\nprocess_video(input_path, output_path)"
      },
      "session_id": "phi4_a8a2_psg_batch",
      "metadata": {
        "num_run": 27
      },
      "tags": [
        "ablation",
        "benchmark",
        "phi4:latest",
        "py_sketch_generator"
      ],
      "latency": 14.715,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-08-20-20-517213_chatcmpl-9b105163-59fe-49b1-b60a-0ce6fddf838c",
          "traceId": "5da73b99",
          "type": "GENERATION",
          "name": "5da7_psg_gen_attempt#1",
          "startTime": "2025-12-11T06:20:20.517000+00:00",
          "endTime": "2025-12-11T06:20:35.232000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 14715.0,
          "promptTokens": 245,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 806,
          "totalTokens": 1051,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        }
      ],
      "createdAt": "2025-12-11T06:20:21.042Z",
      "updatedAt": "2025-12-11T06:20:50.154Z",
      "environment": "default"
    },
    {
      "id": "ce357043",
      "timestamp": "2025-12-11T06:18:19.516000+00:00",
      "name": "ce35_py_sketch_generator",
      "input": null,
      "output": {
        "status": "success",
        "sketch": "import cv2\nfrom tflite_runtime.interpreter import Interpreter\nimport numpy as np\n\n# Configuration parameters\nmodel_path = 'models/ssd-mobilenet_v1/detect.tflite'\nlabel_path = 'models/ssd-mobilenet_v1/labelmap.txt'\ninput_path = 'data/object_detection/sheeps.mp4'\noutput_path = 'results/object_detection/test_results/sheeps_detections.mp4'\nconfidence_threshold = 0.5\n\n# Phase 1: Setup\ndef load_labels(label_file):\n    with open(label_file, 'r') as file:\n        return [line.strip() for line in file.readlines()]\n\ndef load_interpreter(model_path):\n    interpreter = Interpreter(model_path=model_path)\n    interpreter.allocate_tensors()\n    return interpreter\n\nlabels = load_labels(label_path)\ninterpreter = load_interpreter(model_path)\n\n# Phase 2: Preprocessing\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\n\nheight, width = input_details[0]['shape'][1], input_details[0]['shape'][2]\n\ndef preprocess_frame(frame):\n    frame_resized = cv2.resize(frame, (width, height))\n    input_data = np.expand_dims(frame_resized, axis=0)\n    return input_data\n\n# Phase 3: Inference\ndef run_inference(interpreter, frame):\n    input_data = preprocess_frame(frame)\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n\n    interpreter.invoke()\n\n    boxes = interpreter.get_tensor(output_details[0]['index'])[0]\n    classes = interpreter.get_tensor(output_details[1]['index'])[0]\n    scores = interpreter.get_tensor(output_details[2]['index'])[0]\n\n    return boxes, classes, scores\n\n# Phase 4: Output Handling\ndef draw_boxes(frame, boxes, classes, scores, labels):\n    for i in range(len(scores)):\n        if scores[i] > confidence_threshold:\n            ymin, xmin, ymax, xmax = boxes[i]\n            (left, right, top, bottom) = (xmin * frame.shape[1], xmax * frame.shape[1],\n                                          ymin * frame.shape[0], ymax * frame.shape[0])\n            cv2.rectangle(frame, (int(left), int(top)), (int(right), int(bottom)), (10, 255, 0), 2)\n\n            class_id = int(classes[i])\n            label = f'{labels[class_id]}: {scores[i]:.2f}'\n            cv2.putText(frame, label, (int(left), int(top) - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (10, 255, 0), 2)\n\ndef compute_mAP():\n    # Placeholder for mAP computation logic\n    pass\n\n# Video processing pipeline\ncap = cv2.VideoCapture(input_path)\nfourcc = cv2.VideoWriter_fourcc(*'mp4v')\nout = cv2.VideoWriter(output_path, fourcc, 20.0, (int(cap.get(3)), int(cap.get(4))))\n\nwhile cap.isOpened():\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    boxes, classes, scores = run_inference(interpreter, frame)\n    draw_boxes(frame, boxes, classes, scores, labels)\n\n    out.write(frame)\n\ncap.release()\nout.release()\n\ncompute_mAP()  # Call mAP computation after processing all frames"
      },
      "session_id": "phi4_a8a2_psg_batch",
      "metadata": {
        "num_run": 26
      },
      "tags": [
        "ablation",
        "benchmark",
        "phi4:latest",
        "py_sketch_generator"
      ],
      "latency": 60.873,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-08-18-19-517380_chatcmpl-017e54db-9569-4b45-9b2c-7bd824b226e1",
          "traceId": "ce357043",
          "type": "GENERATION",
          "name": "ce35_psg_gen_attempt#1",
          "startTime": "2025-12-11T06:18:19.517000+00:00",
          "endTime": "2025-12-11T06:18:33.626000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 14109.0,
          "promptTokens": 245,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 773,
          "totalTokens": 1018,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-08-18-36-700576_chatcmpl-e5be2b56-fb2f-45a7-b90f-47e704c4964a",
          "traceId": "ce357043",
          "type": "GENERATION",
          "name": "ce35_psg_gen_attempt#2",
          "startTime": "2025-12-11T06:18:36.700000+00:00",
          "endTime": "2025-12-11T06:18:52.689000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 15989.0,
          "promptTokens": 245,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 879,
          "totalTokens": 1124,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-08-18-52-845372_chatcmpl-bdc311c7-7961-434e-ba79-b2840b4bcaed",
          "traceId": "ce357043",
          "type": "GENERATION",
          "name": "ce35_psg_gen_attempt#3",
          "startTime": "2025-12-11T06:18:52.845000+00:00",
          "endTime": "2025-12-11T06:19:07.507000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 14662.0,
          "promptTokens": 245,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 807,
          "totalTokens": 1052,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-08-19-07-657002_chatcmpl-12362184-f369-409c-a388-08c1999f957e",
          "traceId": "ce357043",
          "type": "GENERATION",
          "name": "ce35_psg_gen_attempt#4",
          "startTime": "2025-12-11T06:19:07.657000+00:00",
          "endTime": "2025-12-11T06:19:20.390000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 12733.0,
          "promptTokens": 245,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 702,
          "totalTokens": 947,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        }
      ],
      "createdAt": "2025-12-11T06:18:20.033Z",
      "updatedAt": "2025-12-11T06:20:00.781Z",
      "environment": "default"
    },
    {
      "id": "1fedc910",
      "timestamp": "2025-12-11T06:16:32.496000+00:00",
      "name": "1fed_py_sketch_generator",
      "input": null,
      "output": {
        "status": "failed",
        "last_code": "import cv2\nimport numpy as np\nimport tensorflow as tf\n\n# Configuration parameters\nmodel_path = 'models/ssd-mobilenet_v1/detect.tflite'\nlabel_path = 'models/ssd-mobilenet_v1/labelmap.txt'\ninput_path = 'data/object_detection/sheeps.mp4'\noutput_path = 'results/object_detection/test_results/sheeps_detections.mp4'\nconfidence_threshold = 0.5\n\n# Load TFLite model and allocate tensors\ninterpreter = tf.lite.Interpreter(model_path=model_path)\ninterpreter.allocate_tensors()\n\n# Get input and output details\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\nheight, width, channel = input_details[0]['shape'][1:4]\n\n# Load labels\nwith open(label_path, 'r') as file:\n    labels = [line.strip() for line in file.readlines()]\n\ndef preprocess_frame(frame):\n    frame_resized = cv2.resize(frame, (width, height))\n    input_data = np.expand_dims(frame_resized, axis=0).astype(np.float32)\n    return input_data\n\ndef draw_boxes(frame, boxes, classes, scores, labels):\n    for i in range(len(scores)):\n        if scores[i] > confidence_threshold:\n            ymin, xmin, ymax, xmax = boxes[i]\n            (left, right, top, bottom) = (xmin * frame.shape[1], xmax * frame.shape[1],\n                                          ymin * frame.shape[0], ymax * frame.shape[0])\n            cv2.rectangle(frame, (int(left), int(top)), (int(right), int(bottom)), (10, 255, 0), 2)\n            label = f\"{labels[int(classes[i])]}: {scores[i]:.2f}\"\n            cv2.putText(frame, label, (int(left), int(top) - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (10, 255, 0), 2)\n\ndef compute_map(detections, ground_truths):\n    # Dummy function to represent mAP computation\n    return \"mAP: Computed value\"\n\n# Open video file and prepare output writer\ncap = cv2.VideoCapture(input_path)\nfourcc = cv2.VideoWriter_fourcc(*'mp4v')\nout = cv2.VideoWriter(output_path, fourcc, 20.0, (int(cap.get(3)), int(cap.get(4))))\n\nwhile cap.isOpened():\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    # Preprocessing\n    input_data = preprocess_frame(frame)\n\n    # Inference\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n    interpreter.invoke()\n\n    boxes = interpreter.get_tensor(output_details[0]['index'])[0]\n    classes = interpreter.get_tensor(output_details[1]['index'])[0]\n    scores = interpreter.get_tensor(output_details[2]['index'])[0]\n\n    # Output handling\n    draw_boxes(frame, boxes, classes, scores, labels)\n    \n    out.write(frame)\n\ncap.release()\nout.release()\n\n# Compute mAP (this is a placeholder for actual computation)\nprint(compute_map(None, None))",
        "last_error": "Max retries reached with failure. Last error from execution: 2025-12-11 08:17:51.826619: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n2025-12-11 08:17:51.830019: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n2025-12-11 08:17:51.841728: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2025-12-11 08:17:51.859914: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2025-12-11 08:17:51.865423: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n2025-12-11 08:17:51.878644: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\nTo enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n2025-12-11 08:17:52.656449: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\nINFO: Created TensorFlow Lite XNNPACK delegate for CPU.\nTraceback (most recent call last):\n  File \"/home/wuguangh/Projects/03.12/tinyml-autopilot-pm.03.12.2025/results/object_detection/sketches/tmp_20251211081751_psg_phi4:latest/tmp_20251211081751_psg_phi4:latest.py\", line 58, in <module>\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n  File \"/home/wuguangh/.conda/envs/tinyml/lib/python3.10/site-packages/tensorflow/lite/python/interpreter.py\", line 732, in set_tensor\n    self._interpreter.SetTensor(tensor_index, value)\nValueError: Cannot set tensor: Got value of type FLOAT32 but expected type UINT8 for input 175, name: normalized_input_image_tensor \n"
      },
      "session_id": "phi4_a8a2_psg_batch",
      "metadata": {
        "num_run": 25
      },
      "tags": [
        "ablation",
        "benchmark",
        "phi4:latest",
        "py_sketch_generator"
      ],
      "latency": 82.0,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-08-16-32-498434_chatcmpl-c728a804-44c5-44fd-9014-e7fc181e40ef",
          "traceId": "1fedc910",
          "type": "GENERATION",
          "name": "1fed_psg_gen_attempt#1",
          "startTime": "2025-12-11T06:16:32.498000+00:00",
          "endTime": "2025-12-11T06:16:48.512000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 16014.0,
          "promptTokens": 245,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 875,
          "totalTokens": 1120,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-08-16-49-231608_chatcmpl-486dd566-366f-47e4-b0fe-99730c809cdb",
          "traceId": "1fedc910",
          "type": "GENERATION",
          "name": "1fed_psg_gen_attempt#2",
          "startTime": "2025-12-11T06:16:49.231000+00:00",
          "endTime": "2025-12-11T06:17:03.602000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 14371.0,
          "promptTokens": 245,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 792,
          "totalTokens": 1037,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-08-17-03-758614_chatcmpl-68b370f8-3b5e-4d00-8ad1-1d23c94f9e55",
          "traceId": "1fedc910",
          "type": "GENERATION",
          "name": "1fed_psg_gen_attempt#3",
          "startTime": "2025-12-11T06:17:03.758000+00:00",
          "endTime": "2025-12-11T06:17:20.232000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 16474.0,
          "promptTokens": 245,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 906,
          "totalTokens": 1151,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-08-17-20-943396_chatcmpl-edcdc99c-c278-462f-8bba-5efd340c4b64",
          "traceId": "1fedc910",
          "type": "GENERATION",
          "name": "1fed_psg_gen_attempt#4",
          "startTime": "2025-12-11T06:17:20.943000+00:00",
          "endTime": "2025-12-11T06:17:36.562000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 15619.0,
          "promptTokens": 245,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 859,
          "totalTokens": 1104,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-08-17-39-539367_chatcmpl-2a608f7e-7a68-4019-a9bb-e97a4fbb7c9f",
          "traceId": "1fedc910",
          "type": "GENERATION",
          "name": "1fed_psg_gen_attempt#5",
          "startTime": "2025-12-11T06:17:39.539000+00:00",
          "endTime": "2025-12-11T06:17:51.506000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 11967.0,
          "promptTokens": 245,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 659,
          "totalTokens": 904,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "f2af778c-4ec7-495b-8ee2-af952f19ce9f",
          "traceId": "1fedc910",
          "type": "SPAN",
          "name": "error_1f_psg_failure_signal_py_sketch_generator",
          "startTime": "2025-12-11T06:17:54.498000+00:00",
          "level": "ERROR",
          "statusMessage": "Failed. Last error: Max retries reached with failure. Last error from execution: 2025-12-11 08:17:51.826619: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n2025-12-11 08:17:51.830019: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n2025-12-11 08:17:51.841728: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2025-12-11 08:17:51.859914: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2025-12-11 08:17:51.865423: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n2025-12-11 08:17:51.878644: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\nTo enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n2025-12-11 08:17:52.656449: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\nINFO: Created TensorFlow Lite XNNPACK delegate for CPU.\nTraceback (most recent call last):\n  File \"/home/wuguangh/Projects/03.12/tinyml-autopilot-pm.03.12.2025/results/object_detection/sketches/tmp_20251211081751_psg_phi4:latest/tmp_20251211081751_psg_phi4:latest.py\", line 58, in <module>\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n  File \"/home/wuguangh/.conda/envs/tinyml/lib/python3.10/site-packages/tensorflow/lite/python/interpreter.py\", line 732, in set_tensor\n    self._interpreter.SetTensor(tensor_index, value)\nValueError: Cannot set tensor: Got value of type FLOAT32 but expected type UINT8 for input 175, name: normalized_input_image_tensor \n",
          "calculatedTotalCost": 0.0,
          "promptTokens": 0,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 0,
          "totalTokens": 0,
          "endTime": null,
          "model": null,
          "modelParameters": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null,
          "latency": null
        }
      ],
      "createdAt": "2025-12-11T06:16:33.018Z",
      "updatedAt": "2025-12-11T06:17:59.737Z",
      "environment": "default"
    },
    {
      "id": "0950b00a",
      "timestamp": "2025-12-11T06:15:10.865000+00:00",
      "name": "0950_py_sketch_generator",
      "input": null,
      "output": {
        "status": "success",
        "sketch": "import cv2\nimport numpy as np\nimport tensorflow as tf\nfrom tflite_runtime.interpreter import Interpreter\n\ndef load_labels(label_path):\n    with open(label_path, 'r', encoding='utf-8') as f:\n        return {i: line.strip() for i, line in enumerate(f.readlines())}\n\ndef set_input_tensor(interpreter, image):\n    tensor_index = interpreter.get_input_details()[0]['index']\n    input_shape = interpreter.get_input_details()[0]['shape']\n    input_tensor = np.expand_dims(image, axis=0)\n    interpreter.set_tensor(tensor_index, input_tensor)\n\ndef get_output(interpreter, score_threshold):\n    boxes = interpreter.get_tensor(interpreter.get_output_details()[0]['index'])[0] # Bounding box coordinates of detected objects\n    classes = interpreter.get_tensor(interpreter.get_output_details()[1]['index'])[0] # Class index of detected objects\n    scores = interpreter.get_tensor(interpreter.get_output_details()[2]['index'])[0] # Confidence of detected objects\n\n    results = []\n    for i in range(len(scores)):\n        if scores[i] >= score_threshold:\n            result = {\n                'bounding_box': boxes[i],\n                'class_id': classes[i],\n                'score': scores[i]\n            }\n            results.append(result)\n    return results\n\ndef draw_boxes(frame, results, labels):\n    height, width, _ = frame.shape\n    for obj in results:\n        ymin, xmin, ymax, xmax = tuple(obj['bounding_box'])\n        xmin = int(xmin * width)\n        xmax = int(xmax * width)\n        ymin = int(ymin * height)\n        ymax = int(ymax * height)\n\n        cv2.rectangle(frame, (xmin, ymin), (xmax, ymax), (10, 255, 0), 2)\n        \n        label = f'{labels[int(obj[\"class_id\"])]}: {int(obj[\"score\"] * 100)}%'\n        labelSize, baseLine = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.7, 2)\n        label_ymin = max(ymin, labelSize[1] + 10)\n        \n        cv2.rectangle(frame, (xmin, label_ymin - labelSize[1] - 10), \n                      (xmin + labelSize[0], label_ymin + baseLine - 10), \n                      (255, 255, 255), cv2.FILLED)\n        cv2.putText(frame, label, (xmin, label_ymin - 7), \n                    cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 0), 2)\n\ndef main():\n    model_path = 'models/ssd-mobilenet_v1/detect.tflite'\n    label_path = 'models/ssd-mobilenet_v1/labelmap.txt'\n    input_path = 'data/object_detection/sheeps.mp4'\n    output_path = 'results/object_detection/test_results/sheeps_detections.mp4'\n    confidence_threshold = 0.5\n\n    # Load the TFLite model and allocate tensors\n    interpreter = Interpreter(model_path=model_path)\n    interpreter.allocate_tensors()\n\n    input_details = interpreter.get_input_details()\n    output_details = interpreter.get_output_details()\n\n    labels = load_labels(label_path)\n\n    # Open video file\n    cap = cv2.VideoCapture(input_path)\n    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n    fps = int(cap.get(cv2.CAP_PROP_FPS))\n\n    # Define the codec and create VideoWriter object\n    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n    out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n\n    while cap.isOpened():\n        ret, frame = cap.read()\n        if not ret:\n            break\n\n        # Preprocess the image\n        input_size = input_details[0]['shape'][1:3]\n        img = cv2.resize(frame, (input_size[1], input_size[0]))\n        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n        set_input_tensor(interpreter, img)\n\n        # Run inference\n        interpreter.invoke()\n        results = get_output(interpreter, confidence_threshold)\n\n        # Draw boxes on the frame\n        draw_boxes(frame, results, labels)\n\n        # Write the frame with detections\n        out.write(frame)\n\n    cap.release()\n    out.release()\n\nif __name__ == '__main__':\n    main()"
      },
      "session_id": "phi4_a8a2_psg_batch",
      "metadata": {
        "num_run": 24
      },
      "tags": [
        "ablation",
        "benchmark",
        "phi4:latest",
        "py_sketch_generator"
      ],
      "latency": 17.237,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-08-15-10-866458_chatcmpl-478b7c9d-8589-44fc-a9dd-13f370ef89f8",
          "traceId": "0950b00a",
          "type": "GENERATION",
          "name": "0950_psg_gen_attempt#1",
          "startTime": "2025-12-11T06:15:10.866000+00:00",
          "endTime": "2025-12-11T06:15:28.103000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 17237.0,
          "promptTokens": 245,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 945,
          "totalTokens": 1190,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        }
      ],
      "createdAt": "2025-12-11T06:15:11.383Z",
      "updatedAt": "2025-12-11T06:16:11.544Z",
      "environment": "default"
    },
    {
      "id": "aba7e146",
      "timestamp": "2025-12-11T06:13:18.890000+00:00",
      "name": "aba7_py_sketch_generator",
      "input": null,
      "output": {
        "status": "failed",
        "last_code": "import cv2\nfrom tflite_runtime.interpreter import Interpreter\nimport numpy as np\n\n# Configuration parameters\nmodel_path = 'models/ssd-mobilenet_v1/detect.tflite'\nlabel_path = 'models/ssd-mobilenet_v1/labelmap.txt'\ninput_path = 'data/object_detection/sheeps.mp4'\noutput_path = 'results/object_detection/test_results/sheeps_detections.mp4'\nconfidence_threshold = 0.5\n\n# Phase 1: Setup\ndef load_labels(label_path):\n    with open(label_path, 'r') as file:\n        labels = [line.strip() for line in file.readlines()]\n    return labels\n\ndef load_tflite_model(model_path):\n    interpreter = Interpreter(model_path=model_path)\n    interpreter.allocate_tensors()\n    return interpreter\n\nlabels = load_labels(label_path)\ninterpreter = load_tflite_model(model_path)\n\n# Phase 2: Preprocessing\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\n\ndef preprocess_frame(frame, input_shape):\n    frame_resized = cv2.resize(frame, (input_shape[1], input_shape[0]))\n    frame_normalized = frame_resized / 255.0\n    return np.expand_dims(frame_normalized, axis=0).astype(np.float32)\n\n# Phase 3: Inference\ndef run_inference(interpreter, frame):\n    interpreter.set_tensor(input_details[0]['index'], frame)\n    interpreter.invoke()\n    \n    boxes = interpreter.get_tensor(output_details[0]['index'])[0]\n    classes = interpreter.get_tensor(output_details[1]['index'])[0].astype(np.int64)\n    scores = interpreter.get_tensor(output_details[2]['index'])[0]\n\n    return boxes, classes, scores\n\n# Phase 4: Output handling\ndef draw_detections(frame, boxes, classes, scores, labels):\n    height, width, _ = frame.shape\n    for i in range(len(scores)):\n        if scores[i] > confidence_threshold:\n            ymin, xmin, ymax, xmax = boxes[i]\n            (left, right, top, bottom) = (xmin * width, xmax * width,\n                                          ymin * height, ymax * height)\n            \n            object_name = labels[classes[i]]\n            label = f\"{object_name}: {int(scores[i] * 100)}%\"\n            \n            cv2.rectangle(frame, (int(left), int(top)), (int(right), int(bottom)), (10, 255, 0), 2)\n            cv2.putText(frame, label, (int(left), int(top - 5)), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (10, 255, 0), 2)\n\ndef main():\n    cap = cv2.VideoCapture(input_path)\n    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n    out = cv2.VideoWriter(output_path, fourcc, 20.0, (int(cap.get(3)), int(cap.get(4))))\n\n    while cap.isOpened():\n        ret, frame = cap.read()\n        if not ret:\n            break\n        \n        input_shape = input_details[0]['shape'][1:3]\n        preprocessed_frame = preprocess_frame(frame, input_shape)\n        \n        boxes, classes, scores = run_inference(interpreter, preprocessed_frame)\n        draw_detections(frame, boxes, classes, scores, labels)\n        \n        out.write(frame)\n\n    cap.release()\n    out.release()\n\nif __name__ == '__main__':\n    main()",
        "last_error": "Max retries reached with failure. Last error from execution: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\nTraceback (most recent call last):\n  File \"/home/wuguangh/Projects/03.12/tinyml-autopilot-pm.03.12.2025/results/object_detection/sketches/tmp_20251211081444_psg_phi4:latest/tmp_20251211081444_psg_phi4:latest.py\", line 83, in <module>\n    main()\n  File \"/home/wuguangh/Projects/03.12/tinyml-autopilot-pm.03.12.2025/results/object_detection/sketches/tmp_20251211081444_psg_phi4:latest/tmp_20251211081444_psg_phi4:latest.py\", line 74, in main\n    boxes, classes, scores = run_inference(interpreter, preprocessed_frame)\n  File \"/home/wuguangh/Projects/03.12/tinyml-autopilot-pm.03.12.2025/results/object_detection/sketches/tmp_20251211081444_psg_phi4:latest/tmp_20251211081444_psg_phi4:latest.py\", line 37, in run_inference\n    interpreter.set_tensor(input_details[0]['index'], frame)\n  File \"/home/wuguangh/.conda/envs/tinyml/lib/python3.10/site-packages/tflite_runtime/interpreter.py\", line 720, in set_tensor\n    self._interpreter.SetTensor(tensor_index, value)\nValueError: Cannot set tensor: Got value of type FLOAT32 but expected type UINT8 for input 175, name: normalized_input_image_tensor \n"
      },
      "session_id": "phi4_a8a2_psg_batch",
      "metadata": {
        "num_run": 23
      },
      "tags": [
        "ablation",
        "benchmark",
        "phi4:latest",
        "py_sketch_generator"
      ],
      "latency": 85.452,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-08-13-18-891535_chatcmpl-830af951-daf2-4825-a618-5782b573f923",
          "traceId": "aba7e146",
          "type": "GENERATION",
          "name": "aba7_psg_gen_attempt#1",
          "startTime": "2025-12-11T06:13:18.891000+00:00",
          "endTime": "2025-12-11T06:13:34.485000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 15594.0,
          "promptTokens": 245,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 844,
          "totalTokens": 1089,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-08-13-39-874983_chatcmpl-fcb8dad1-6d44-4ed5-8bd2-5ccb464928fb",
          "traceId": "aba7e146",
          "type": "GENERATION",
          "name": "aba7_psg_gen_attempt#2",
          "startTime": "2025-12-11T06:13:39.874000+00:00",
          "endTime": "2025-12-11T06:13:56.537000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 16663.0,
          "promptTokens": 245,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 916,
          "totalTokens": 1161,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-08-13-56-662358_chatcmpl-1baa08d4-e264-4e38-ba4e-38597da74529",
          "traceId": "aba7e146",
          "type": "GENERATION",
          "name": "aba7_psg_gen_attempt#3",
          "startTime": "2025-12-11T06:13:56.662000+00:00",
          "endTime": "2025-12-11T06:14:13.635000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 16973.0,
          "promptTokens": 245,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 934,
          "totalTokens": 1179,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-08-14-13-769351_chatcmpl-515d7dd9-d954-4fc4-8ea8-06f3f725286d",
          "traceId": "aba7e146",
          "type": "GENERATION",
          "name": "aba7_psg_gen_attempt#4",
          "startTime": "2025-12-11T06:14:13.769000+00:00",
          "endTime": "2025-12-11T06:14:28.091000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 14322.0,
          "promptTokens": 245,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 789,
          "totalTokens": 1034,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-08-14-31-099372_chatcmpl-8605eb6c-e354-4885-9db0-f8e91972fcdd",
          "traceId": "aba7e146",
          "type": "GENERATION",
          "name": "aba7_psg_gen_attempt#5",
          "startTime": "2025-12-11T06:14:31.099000+00:00",
          "endTime": "2025-12-11T06:14:44.192000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 13093.0,
          "promptTokens": 245,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 721,
          "totalTokens": 966,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "2c054efd-e139-4d79-9bce-b722e744230d",
          "traceId": "aba7e146",
          "type": "SPAN",
          "name": "error_ab_psg_failure_signal_py_sketch_generator",
          "startTime": "2025-12-11T06:14:44.343000+00:00",
          "level": "ERROR",
          "statusMessage": "Failed. Last error: Max retries reached with failure. Last error from execution: INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\nTraceback (most recent call last):\n  File \"/home/wuguangh/Projects/03.12/tinyml-autopilot-pm.03.12.2025/results/object_detection/sketches/tmp_20251211081444_psg_phi4:latest/tmp_20251211081444_psg_phi4:latest.py\", line 83, in <module>\n    main()\n  File \"/home/wuguangh/Projects/03.12/tinyml-autopilot-pm.03.12.2025/results/object_detection/sketches/tmp_20251211081444_psg_phi4:latest/tmp_20251211081444_psg_phi4:latest.py\", line 74, in main\n    boxes, classes, scores = run_inference(interpreter, preprocessed_frame)\n  File \"/home/wuguangh/Projects/03.12/tinyml-autopilot-pm.03.12.2025/results/object_detection/sketches/tmp_20251211081444_psg_phi4:latest/tmp_20251211081444_psg_phi4:latest.py\", line 37, in run_inference\n    interpreter.set_tensor(input_details[0]['index'], frame)\n  File \"/home/wuguangh/.conda/envs/tinyml/lib/python3.10/site-packages/tflite_runtime/interpreter.py\", line 720, in set_tensor\n    self._interpreter.SetTensor(tensor_index, value)\nValueError: Cannot set tensor: Got value of type FLOAT32 but expected type UINT8 for input 175, name: normalized_input_image_tensor \n",
          "calculatedTotalCost": 0.0,
          "promptTokens": 0,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 0,
          "totalTokens": 0,
          "endTime": null,
          "model": null,
          "modelParameters": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null,
          "latency": null
        }
      ],
      "createdAt": "2025-12-11T06:13:19.407Z",
      "updatedAt": "2025-12-11T06:14:49.554Z",
      "environment": "default"
    },
    {
      "id": "485729a1",
      "timestamp": "2025-12-11T06:11:25.933000+00:00",
      "name": "4857_py_sketch_generator",
      "input": null,
      "output": {
        "status": "success",
        "sketch": "import cv2\nfrom tflite_runtime.interpreter import Interpreter\nimport numpy as np\n\n# Configuration parameters\nmodel_path = 'models/ssd-mobilenet_v1/detect.tflite'\nlabel_path = 'models/ssd-mobilenet_v1/labelmap.txt'\ninput_path = 'data/object_detection/sheeps.mp4'\noutput_path = 'results/object_detection/test_results/sheeps_detections.mp4'\nconfidence_threshold = 0.5\n\n# Phase 1: Setup\ndef load_labels(label_path):\n    with open(label_path, 'r') as f:\n        return [line.strip() for line in f.readlines()]\n\ndef set_input_tensor(interpreter, image):\n    tensor_index = interpreter.get_input_details()[0]['index']\n    input_shape = interpreter.get_input_details()[0]['shape']\n    image = cv2.resize(image, (input_shape[1], input_shape[2]))\n    image = np.expand_dims(image, axis=0)\n    interpreter.set_tensor(tensor_index, image)\n\ndef get_output(interpreter, score_threshold):\n    boxes = interpreter.get_tensor(interpreter.get_output_details()[0]['index'])[0] # Bounding box coordinates of detected objects\n    classes = interpreter.get_tensor(interpreter.get_output_details()[1]['index'])[0] # Class index of detected objects\n    scores = interpreter.get_tensor(interpreter.get_output_details()[2]['index'])[0] # Confidence of detected objects\n\n    results = []\n    for i in range(len(scores)):\n        if scores[i] >= score_threshold:\n            result = {\n                'bounding_box': boxes[i],\n                'class_id': classes[i],\n                'score': scores[i]\n            }\n            results.append(result)\n    return results\n\ndef load_tflite_model(model_path):\n    interpreter = Interpreter(model_path=model_path, num_threads=2)\n    interpreter.allocate_tensors()\n    return interpreter\n\n# Phase 2: Preprocessing\nlabels = load_labels(label_path)\n\n# Phase 3: Inference\ninterpreter = load_tflite_model(model_path)\ncap = cv2.VideoCapture(input_path)\nfourcc = cv2.VideoWriter_fourcc(*'mp4v')\nout = cv2.VideoWriter(output_path, fourcc, 20.0, (int(cap.get(3)), int(cap.get(4))))\n\nwhile cap.isOpened():\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    set_input_tensor(interpreter, frame)\n    interpreter.invoke()\n\n    results = get_output(interpreter, confidence_threshold)\n\n    for obj in results:\n        ymin, xmin, ymax, xmax = obj['bounding_box']\n        (left, right, top, bottom) = (xmin * frame.shape[1], xmax * frame.shape[1],\n                                      ymin * frame.shape[0], ymax * frame.shape[0])\n        \n        cv2.rectangle(frame, (int(left), int(top)), (int(right), int(bottom)), (10, 255, 0), 2)\n        label = f\"{labels[int(obj['class_id'])]}: {round(obj['score'] * 100)}%\"\n        label_size, base_line = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.7, 2)\n        top = max(top, label_size[1])\n        cv2.rectangle(frame, (int(left), int(top - round(1.5*label_size[1]))),\n                      (int(left + round(1.5*label_size[0])), int(top + base_line)),\n                      (255, 255, 255), cv2.FILLED)\n        cv2.putText(frame, label, (int(left), int(top + base_line)), cv2.FONT_HERSHEY_SIMPLEX,\n                    0.7, (0, 0, 0), 2)\n\n    out.write(frame)\n\ncap.release()\nout.release()\n\n# Phase 4: Output handling\nprint(\"Processing completed and output saved to:\", output_path)"
      },
      "session_id": "phi4_a8a2_psg_batch",
      "metadata": {
        "num_run": 22
      },
      "tags": [
        "ablation",
        "benchmark",
        "phi4:latest",
        "py_sketch_generator"
      ],
      "latency": 62.17,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-08-11-25-934870_chatcmpl-120c7c79-046e-4407-a6fe-82694da8b826",
          "traceId": "485729a1",
          "type": "GENERATION",
          "name": "4857_psg_gen_attempt#1",
          "startTime": "2025-12-11T06:11:25.934000+00:00",
          "endTime": "2025-12-11T06:11:38.511000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 12577.0,
          "promptTokens": 245,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 688,
          "totalTokens": 933,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-08-11-38-657823_chatcmpl-52bb7a5c-982f-471e-9d98-e488acb2d90c",
          "traceId": "485729a1",
          "type": "GENERATION",
          "name": "4857_psg_gen_attempt#2",
          "startTime": "2025-12-11T06:11:38.657000+00:00",
          "endTime": "2025-12-11T06:11:54.615000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 15958.0,
          "promptTokens": 245,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 878,
          "totalTokens": 1123,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-08-11-57-590874_chatcmpl-aaefc81c-e546-475a-b787-81e999fbd921",
          "traceId": "485729a1",
          "type": "GENERATION",
          "name": "4857_psg_gen_attempt#3",
          "startTime": "2025-12-11T06:11:57.590000+00:00",
          "endTime": "2025-12-11T06:12:10.295000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 12705.0,
          "promptTokens": 245,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 700,
          "totalTokens": 945,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-08-12-13-321975_chatcmpl-38bc4d92-e40d-4763-8574-da7b4e34c6d4",
          "traceId": "485729a1",
          "type": "GENERATION",
          "name": "4857_psg_gen_attempt#4",
          "startTime": "2025-12-11T06:12:13.321000+00:00",
          "endTime": "2025-12-11T06:12:28.104000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 14783.0,
          "promptTokens": 245,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 814,
          "totalTokens": 1059,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        }
      ],
      "createdAt": "2025-12-11T06:11:26.450Z",
      "updatedAt": "2025-12-11T06:12:58.636Z",
      "environment": "default"
    },
    {
      "id": "ff5cb5e7",
      "timestamp": "2025-12-11T06:09:26.500000+00:00",
      "name": "ff5c_py_sketch_generator",
      "input": null,
      "output": {
        "status": "success",
        "sketch": "import cv2\nfrom tflite_runtime.interpreter import Interpreter\nimport numpy as np\n\n# Configuration parameters\nmodel_path = 'models/ssd-mobilenet_v1/detect.tflite'\nlabel_path = 'models/ssd-mobilenet_v1/labelmap.txt'\ninput_path = 'data/object_detection/sheeps.mp4'\noutput_path = 'results/object_detection/test_results/sheeps_detections.mp4'\nconfidence_threshold = 0.5\n\n# Phase 1: Setup\ndef load_labels(label_file):\n    with open(label_file, 'r') as file:\n        return [line.strip() for line in file.readlines()]\n\ndef create_interpreter(model_path):\n    interpreter = Interpreter(model_path=model_path)\n    interpreter.allocate_tensors()\n    return interpreter\n\nlabels = load_labels(label_path)\ninterpreter = create_interpreter(model_path)\n\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\n\n# Phase 2: Preprocessing\ndef preprocess_frame(frame, input_shape):\n    frame_resized = cv2.resize(frame, (input_shape[1], input_shape[0]))\n    input_data = np.expand_dims(frame_resized, axis=0)\n    return input_data\n\n# Phase 3: Inference\ndef set_input_tensor(interpreter, input_data):\n    tensor_index = interpreter.get_input_details()[0]['index']\n    interpreter.set_tensor(tensor_index, input_data)\n\ndef get_output(interpreter):\n    boxes = interpreter.get_tensor(output_details[0]['index'])[0]\n    classes = interpreter.get_tensor(output_details[1]['index'])[0]\n    scores = interpreter.get_tensor(output_details[2]['index'])[0]\n    return boxes, classes, scores\n\n# Phase 4: Output Handling\ndef draw_detections(frame, boxes, classes, scores, labels, threshold):\n    height, width, _ = frame.shape\n    for i in range(len(scores)):\n        if scores[i] >= threshold:\n            ymin, xmin, ymax, xmax = boxes[i]\n            left, right, top, bottom = int(xmin * width), int(xmax * width), int(ymin * height), int(ymax * height)\n            cv2.rectangle(frame, (left, top), (right, bottom), (10, 255, 0), 2)\n            class_id = int(classes[i])\n            label = f\"{labels[class_id]}: {int(scores[i] * 100)}%\"\n            cv2.putText(frame, label, (left, top - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)\n\ndef compute_map(ground_truths, predictions):\n    # Placeholder for mAP computation logic\n    return 0.0\n\n# Main processing loop\ncap = cv2.VideoCapture(input_path)\nwidth = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\nheight = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\nfps = cap.get(cv2.CAP_PROP_FPS)\noutput_size = (round(width * 720 / height), 720)\nfourcc = cv2.VideoWriter_fourcc(*'mp4v')\nout = cv2.VideoWriter(output_path, fourcc, fps, output_size)\n\nwhile cap.isOpened():\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    input_data = preprocess_frame(frame, input_details[0]['shape'][1:3])\n    set_input_tensor(interpreter, input_data)\n    interpreter.invoke()\n\n    boxes, classes, scores = get_output(interpreter)\n    draw_detections(frame, boxes, classes, scores, labels, confidence_threshold)\n\n    out.write(cv2.resize(frame, output_size))\n\ncap.release()\nout.release()\n\n# Placeholder for mAP computation\nground_truths = []  # This would be loaded from a dataset\npredictions = []  # This would be collected during inference\nmap_score = compute_map(ground_truths, predictions)\nprint(f\"Mean Average Precision (mAP): {map_score}\")"
      },
      "session_id": "phi4_a8a2_psg_batch",
      "metadata": {
        "num_run": 21
      },
      "tags": [
        "ablation",
        "benchmark",
        "phi4:latest",
        "py_sketch_generator"
      ],
      "latency": 61.789,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-08-09-26-501340_chatcmpl-9749fb56-086c-44a2-a692-042166789b1f",
          "traceId": "ff5cb5e7",
          "type": "GENERATION",
          "name": "ff5c_psg_gen_attempt#1",
          "startTime": "2025-12-11T06:09:26.501000+00:00",
          "endTime": "2025-12-11T06:09:42.333000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 15832.0,
          "promptTokens": 245,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 866,
          "totalTokens": 1111,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-08-09-45-357604_chatcmpl-fd8a8fb8-6ea3-450a-bf9b-d44c415b058a",
          "traceId": "ff5cb5e7",
          "type": "GENERATION",
          "name": "ff5c_psg_gen_attempt#2",
          "startTime": "2025-12-11T06:09:45.357000+00:00",
          "endTime": "2025-12-11T06:10:00.548000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 15191.0,
          "promptTokens": 245,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 836,
          "totalTokens": 1081,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-08-10-00-671611_chatcmpl-90862fea-2945-4888-9345-55486cda7540",
          "traceId": "ff5cb5e7",
          "type": "GENERATION",
          "name": "ff5c_psg_gen_attempt#3",
          "startTime": "2025-12-11T06:10:00.671000+00:00",
          "endTime": "2025-12-11T06:10:13.135000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 12464.0,
          "promptTokens": 245,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 687,
          "totalTokens": 932,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-08-10-13-281000_chatcmpl-f91791b7-b98e-49fd-adb2-0931ff0a2579",
          "traceId": "ff5cb5e7",
          "type": "GENERATION",
          "name": "ff5c_psg_gen_attempt#4",
          "startTime": "2025-12-11T06:10:13.281000+00:00",
          "endTime": "2025-12-11T06:10:28.290000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 15009.0,
          "promptTokens": 245,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 826,
          "totalTokens": 1071,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        }
      ],
      "createdAt": "2025-12-11T06:09:27.018Z",
      "updatedAt": "2025-12-11T06:11:05.737Z",
      "environment": "default"
    },
    {
      "id": "c6475f38",
      "timestamp": "2025-12-11T06:08:38.423000+00:00",
      "name": "c647_py_sketch_generator",
      "input": null,
      "output": {
        "status": "success",
        "sketch": "import cv2\nimport numpy as np\nimport tensorflow as tf\n\n# Configuration parameters\nmodel_path = 'models/ssd-mobilenet_v1/detect.tflite'\nlabel_path = 'models/ssd-mobilenet_v1/labelmap.txt'\ninput_path = 'data/object_detection/sheeps.mp4'\noutput_path = 'results/object_detection/test_results/sheeps_detections.mp4'\nconfidence_threshold = 0.5\n\n# Phase 1: Setup\ninterpreter = tf.lite.Interpreter(model_path=model_path)\ninterpreter.allocate_tensors()\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\n\n# Read labels from label map\nwith open(label_path, 'r') as f:\n    labels = [line.strip() for line in f.readlines()]\n\n# Phase 2: Preprocessing\ndef preprocess_frame(frame):\n    input_shape = input_details[0]['shape']\n    frame_resized = cv2.resize(frame, (input_shape[1], input_shape[2]))\n    input_data = np.expand_dims(frame_resized, axis=0)\n    return input_data\n\n# Phase 3: Inference\ndef run_inference(input_data):\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n    interpreter.invoke()\n    \n    boxes = interpreter.get_tensor(output_details[0]['index'])[0]\n    classes = interpreter.get_tensor(output_details[1]['index'])[0]\n    scores = interpreter.get_tensor(output_details[2]['index'])[0]\n\n    return boxes, classes, scores\n\n# Phase 4: Output handling\ndef draw_boxes(frame, boxes, classes, scores):\n    for i in range(len(scores)):\n        if scores[i] > confidence_threshold:\n            ymin, xmin, ymax, xmax = boxes[i]\n            (left, right, top, bottom) = (xmin * frame.shape[1], xmax * frame.shape[1],\n                                          ymin * frame.shape[0], ymax * frame.shape[0])\n            left, right, top, bottom = int(left), int(right), int(top), int(bottom)\n            \n            cv2.rectangle(frame, (left, top), (right, bottom), (10, 255, 0), 2)\n            \n            label = f'{labels[int(classes[i])]}: {int(scores[i] * 100)}%'\n            cv2.putText(frame, label, (left, top - 5), cv2.FONT_HERSHEY_SIMPLEX,\n                        0.7, (10, 255, 0), 2)\n\n# Open video files\ncap = cv2.VideoCapture(input_path)\noutput_video = cv2.VideoWriter(output_path, cv2.VideoWriter_fourcc(*'mp4v'), \n                               int(cap.get(cv2.CAP_PROP_FPS)), \n                               (int(cap.get(cv2.CAP_PROP_FRAME_WIDTH)),\n                                int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))))\n\nwhile cap.isOpened():\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    # Preprocess and run inference\n    input_data = preprocess_frame(frame)\n    boxes, classes, scores = run_inference(input_data)\n\n    # Draw detection boxes with labels\n    draw_boxes(frame, boxes, classes, scores)\n\n    # Write the frame with detections to output video\n    output_video.write(frame)\n\ncap.release()\noutput_video.release()\n\n# Note: mAP computation is not included as it requires ground truth annotations and a more complex setup."
      },
      "session_id": "phi4_a8a2_psg_batch",
      "metadata": {
        "num_run": 20
      },
      "tags": [
        "ablation",
        "benchmark",
        "phi4:latest",
        "py_sketch_generator"
      ],
      "latency": 14.469,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-08-08-38-423821_chatcmpl-d69dcbed-7d5c-4245-8279-9806363dc310",
          "traceId": "c6475f38",
          "type": "GENERATION",
          "name": "c647_psg_gen_attempt#1",
          "startTime": "2025-12-11T06:08:38.423000+00:00",
          "endTime": "2025-12-11T06:08:52.892000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 14469.0,
          "promptTokens": 245,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 789,
          "totalTokens": 1034,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        }
      ],
      "createdAt": "2025-12-11T06:08:38.939Z",
      "updatedAt": "2025-12-11T06:09:06.596Z",
      "environment": "default"
    },
    {
      "id": "936b7d7f",
      "timestamp": "2025-12-11T06:06:50.454000+00:00",
      "name": "936b_py_sketch_generator",
      "input": null,
      "output": {
        "status": "success",
        "sketch": "import cv2\nimport numpy as np\nfrom tflite_runtime.interpreter import Interpreter\n\n# Configuration parameters\nmodel_path = 'models/ssd-mobilenet_v1/detect.tflite'\nlabel_path = 'models/ssd-mobilenet_v1/labelmap.txt'\ninput_path = 'data/object_detection/sheeps.mp4'\noutput_path = 'results/object_detection/test_results/sheeps_detections.mp4'\nconfidence_threshold = 0.5\n\n# Setup phase\ndef load_labels(label_file):\n    with open(label_file, 'r') as f:\n        return [line.strip() for line in f.readlines()]\n\ndef load_tflite_model(model_path):\n    interpreter = Interpreter(model_path=model_path)\n    interpreter.allocate_tensors()\n    return interpreter\n\nlabels = load_labels(label_path)\ninterpreter = load_tflite_model(model_path)\n\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\n\nheight, width = input_details[0]['shape'][1], input_details[0]['shape'][2]\nfloating_model = (input_details[0]['dtype'] == np.float32)\n\n# Preprocessing phase\ndef preprocess_frame(frame):\n    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n    frame_resized = cv2.resize(frame_rgb, (width, height))\n    input_data = np.expand_dims(frame_resized, axis=0)\n    if floating_model:\n        input_data = (np.float32(input_data) - 127.5) / 127.5\n    return input_data\n\n# Inference phase\ndef run_inference(interpreter, frame):\n    interpreter.set_tensor(input_details[0]['index'], frame)\n    interpreter.invoke()\n    \n    boxes = interpreter.get_tensor(output_details[0]['index'])[0]\n    classes = interpreter.get_tensor(output_details[1]['index'])[0]\n    scores = interpreter.get_tensor(output_details[2]['index'])[0]\n\n    return boxes, classes, scores\n\n# Output handling phase\ndef draw_detections(frame, boxes, classes, scores):\n    for i in range(len(scores)):\n        if scores[i] >= confidence_threshold:\n            ymin, xmin, ymax, xmax = boxes[i]\n            (left, right, top, bottom) = (xmin * frame.shape[1], xmax * frame.shape[1],\n                                          ymin * frame.shape[0], ymax * frame.shape[0])\n            \n            left, right, top, bottom = int(left), int(right), int(top), int(bottom)\n            cv2.rectangle(frame, (left, top), (right, bottom), (10, 255, 0), 2)\n\n            label = f'{labels[int(classes[i])]}: {int(scores[i]*100)}%'\n            label_size, base_line = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.7, 2)\n            \n            top = max(top, label_size[1])\n            cv2.rectangle(frame, (left, top - round(1.5*label_size[1])), \n                          (left + round(1.5*label_size[0]), top + base_line), \n                          (255, 255, 255), cv2.FILLED)\n            \n            cv2.putText(frame, label, (left, top), cv2.FONT_HERSHEY_SIMPLEX, 0.7, \n                        (0, 0, 0), 2)\n\ndef compute_mAP(ground_truth_boxes, pred_boxes):\n    # Placeholder for mAP computation logic\n    # This function would require ground truth data and prediction boxes to calculate mAP.\n    pass\n\n# Video processing\ncap = cv2.VideoCapture(input_path)\noutput_writer = None\n\nwhile cap.isOpened():\n    ret, frame = cap.read()\n    if not ret:\n        break\n    \n    input_data = preprocess_frame(frame)\n    boxes, classes, scores = run_inference(interpreter, input_data)\n    \n    draw_detections(frame, boxes, classes, scores)\n\n    if output_writer is None:\n        fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n        output_writer = cv2.VideoWriter(output_path, fourcc, 30.0, (frame.shape[1], frame.shape[0]))\n\n    output_writer.write(frame)\n\ncap.release()\noutput_writer.release()\n\n# Note: mAP computation is not fully implemented here due to lack of ground truth data."
      },
      "session_id": "phi4_a8a2_psg_batch",
      "metadata": {
        "num_run": 19
      },
      "tags": [
        "ablation",
        "benchmark",
        "phi4:latest",
        "py_sketch_generator"
      ],
      "latency": 50.929,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-08-06-50-455687_chatcmpl-81ea2ec3-e848-4cd8-bc9a-cac575e8cbbf",
          "traceId": "936b7d7f",
          "type": "GENERATION",
          "name": "936b_psg_gen_attempt#1",
          "startTime": "2025-12-11T06:06:50.455000+00:00",
          "endTime": "2025-12-11T06:07:03.675000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 13220.0,
          "promptTokens": 245,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 724,
          "totalTokens": 969,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-08-07-06-731408_chatcmpl-dc90a4cd-c8c0-435b-adb9-67d9860706ab",
          "traceId": "936b7d7f",
          "type": "GENERATION",
          "name": "936b_psg_gen_attempt#2",
          "startTime": "2025-12-11T06:07:06.731000+00:00",
          "endTime": "2025-12-11T06:07:24.225000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 17494.0,
          "promptTokens": 245,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 960,
          "totalTokens": 1205,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-08-07-24-937812_chatcmpl-a21a83d5-e748-47bf-b413-5144eeb7a0f5",
          "traceId": "936b7d7f",
          "type": "GENERATION",
          "name": "936b_psg_gen_attempt#3",
          "startTime": "2025-12-11T06:07:24.937000+00:00",
          "endTime": "2025-12-11T06:07:41.384000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 16447.0,
          "promptTokens": 245,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 905,
          "totalTokens": 1150,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        }
      ],
      "createdAt": "2025-12-11T06:06:50.969Z",
      "updatedAt": "2025-12-11T06:08:18.732Z",
      "environment": "default"
    },
    {
      "id": "e3c73f43",
      "timestamp": "2025-12-11T06:05:20.461000+00:00",
      "name": "e3c7_py_sketch_generator",
      "input": null,
      "output": {
        "status": "success",
        "sketch": "import cv2\nimport numpy as np\nfrom tflite_runtime.interpreter import Interpreter\n\ndef load_labels(label_path):\n    with open(label_path, 'r') as file:\n        labels = [line.strip() for line in file.readlines()]\n    return labels\n\ndef set_input_tensor(interpreter, image):\n    tensor_index = interpreter.get_input_details()[0]['index']\n    input_tensor = interpreter.tensor(tensor_index)()[0]\n    input_tensor[:, :] = image\n\ndef get_output_boxes(interpreter, confidence_threshold):\n    boxes = []\n    classes = []\n    scores = []\n\n    for i in range(len(interpreter.get_output_details())):\n        output_detail = interpreter.get_output_details()[i]\n        output_data = np.squeeze(interpreter.get_tensor(output_detail['index']))\n\n        if 'detection_boxes' in output_detail['name']:\n            boxes.extend(output_data)\n        elif 'detection_classes' in output_detail['name']:\n            classes.extend(output_data.astype(np.int64))\n        elif 'detection_scores' in output_detail['name']:\n            scores.extend(output_data)\n\n    results = []\n    for i, box in enumerate(boxes):\n        if scores[i] >= confidence_threshold:\n            ymin, xmin, ymax, xmax = box\n            class_id = classes[i]\n            score = scores[i]\n            results.append((class_id, score, (xmin, ymin, xmax - xmin, ymax - ymin)))\n    return results\n\ndef draw_detections(image, detections, labels):\n    for detection in detections:\n        class_id, score, bbox = detection\n        left, top, width, height = bbox\n        right = left + width\n        bottom = top + height\n\n        # Scale bounding box to image dimensions\n        im_width, im_height = image.shape[1], image.shape[0]\n        left = int(left * im_width)\n        right = int(right * im_width)\n        top = int(top * im_height)\n        bottom = int(bottom * im_height)\n\n        # Draw rectangle and label on the image\n        cv2.rectangle(image, (left, top), (right, bottom), color=(0, 255, 0), thickness=2)\n        text = f'{labels[class_id]}: {score:.2f}'\n        cv2.putText(image, text, (left, top - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 1)\n\ndef process_video(input_path, output_path, interpreter, labels, confidence_threshold):\n    cap = cv2.VideoCapture(input_path)\n    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n    fps = cap.get(cv2.CAP_PROP_FPS)\n\n    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n    out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n\n    while cap.isOpened():\n        ret, frame = cap.read()\n        if not ret:\n            break\n\n        # Preprocess the image\n        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n        input_image = cv2.resize(frame_rgb, (300, 300))\n        input_image = np.expand_dims(input_image, axis=0)\n\n        # Run inference\n        set_input_tensor(interpreter, input_image)\n        interpreter.invoke()\n\n        detections = get_output_boxes(interpreter, confidence_threshold)\n\n        # Draw detections on the frame\n        draw_detections(frame, detections, labels)\n\n        out.write(frame)\n\n    cap.release()\n    out.release()\n\ndef main():\n    model_path = 'models/ssd-mobilenet_v1/detect.tflite'\n    label_path = 'models/ssd-mobilenet_v1/labelmap.txt'\n    input_path = 'data/object_detection/sheeps.mp4'\n    output_path = 'results/object_detection/test_results/sheeps_detections.mp4'\n    confidence_threshold = 0.5\n\n    # Load labels\n    labels = load_labels(label_path)\n\n    # Setup the TFLite interpreter\n    interpreter = Interpreter(model_path=model_path)\n    interpreter.allocate_tensors()\n\n    # Process video and draw detections\n    process_video(input_path, output_path, interpreter, labels, confidence_threshold)\n\nif __name__ == '__main__':\n    main()"
      },
      "session_id": "phi4_a8a2_psg_batch",
      "metadata": {
        "num_run": 18
      },
      "tags": [
        "ablation",
        "benchmark",
        "phi4:latest",
        "py_sketch_generator"
      ],
      "latency": 32.626,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-08-05-20-463005_chatcmpl-c92e47ea-2df8-4a09-9def-70449f655d27",
          "traceId": "e3c73f43",
          "type": "GENERATION",
          "name": "e3c7_psg_gen_attempt#1",
          "startTime": "2025-12-11T06:05:20.463000+00:00",
          "endTime": "2025-12-11T06:05:33.758000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 13295.0,
          "promptTokens": 245,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 729,
          "totalTokens": 974,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-08-05-36-812083_chatcmpl-a67dbc49-b32a-49d1-891a-b09c0011ae71",
          "traceId": "e3c73f43",
          "type": "GENERATION",
          "name": "e3c7_psg_gen_attempt#2",
          "startTime": "2025-12-11T06:05:36.812000+00:00",
          "endTime": "2025-12-11T06:05:53.089000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 16277.0,
          "promptTokens": 245,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 896,
          "totalTokens": 1141,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        }
      ],
      "createdAt": "2025-12-11T06:05:20.976Z",
      "updatedAt": "2025-12-11T06:06:30.138Z",
      "environment": "default"
    },
    {
      "id": "7cf5549f",
      "timestamp": "2025-12-11T06:03:24.502000+00:00",
      "name": "7cf5_py_sketch_generator",
      "input": null,
      "output": {
        "status": "failed",
        "last_code": "import cv2\nimport numpy as np\nimport tensorflow as tf\n\n# Configuration parameters\nmodel_path = 'models/ssd-mobilenet_v1/detect.tflite'\nlabel_path = 'models/ssd-mobilenet_v1/labelmap.txt'\ninput_path = 'data/object_detection/sheeps.mp4'\noutput_path = 'results/object_detection/test_results/sheeps_detections.mp4'\nconfidence_threshold = 0.5\n\n# Phase 1: Setup\ndef load_labels(label_file):\n    with open(label_file, 'r') as file:\n        labels = [line.strip() for line in file.readlines()]\n    return labels\n\ndef load_interpreter(model_path):\n    interpreter = tf.lite.Interpreter(model_path=model_path)\n    interpreter.allocate_tensors()\n    return interpreter\n\ninterpreter = load_interpreter(model_path)\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\nlabels = load_labels(label_path)\n\n# Phase 2: Preprocessing\ndef preprocess_frame(frame, input_shape):\n    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n    frame_resized = cv2.resize(frame_rgb, (input_shape[1], input_shape[0]))\n    input_data = np.expand_dims(frame_resized, axis=0).astype(np.float32)\n    return input_data\n\n# Phase 3: Inference\ndef run_inference(interpreter, input_data):\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n    interpreter.invoke()\n    boxes = interpreter.get_tensor(output_details[0]['index'])[0]\n    classes = interpreter.get_tensor(output_details[1]['index'])[0].astype(np.int32)\n    scores = interpreter.get_tensor(output_details[2]['index'])[0]\n    return boxes, classes, scores\n\n# Phase 4: Output Handling\ndef draw_boxes(frame, boxes, classes, scores, labels, confidence_threshold):\n    height, width, _ = frame.shape\n    for i in range(len(scores)):\n        if scores[i] >= confidence_threshold:\n            ymin, xmin, ymax, xmax = boxes[i]\n            (left, right, top, bottom) = (xmin * width, xmax * width,\n                                          ymin * height, ymax * height)\n            cv2.rectangle(frame, (int(left), int(top)), (int(right), int(bottom)),\n                          (0, 255, 0), 2)\n            label = f\"{labels[classes[i]]}: {int(scores[i] * 100)}%\"\n            cv2.putText(frame, label, (int(left), int(top - 10)),\n                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 1)\n\n# Main processing loop\ndef process_video(input_path, output_path, interpreter, labels):\n    cap = cv2.VideoCapture(input_path)\n    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n    out = cv2.VideoWriter(output_path, fourcc, 20.0, (int(cap.get(3)), int(cap.get(4))))\n\n    while cap.isOpened():\n        ret, frame = cap.read()\n        if not ret:\n            break\n\n        input_data = preprocess_frame(frame, input_details[0]['shape'][1:3])\n        boxes, classes, scores = run_inference(interpreter, input_data)\n        draw_boxes(frame, boxes, classes, scores, labels, confidence_threshold)\n\n        out.write(frame)\n\n    cap.release()\n    out.release()\n\nprocess_video(input_path, output_path, interpreter, labels)",
        "last_error": "Max retries reached with failure. Last error from execution: 2025-12-11 08:04:52.398275: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n2025-12-11 08:04:52.401641: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n2025-12-11 08:04:52.412991: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2025-12-11 08:04:52.431462: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2025-12-11 08:04:52.437352: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n2025-12-11 08:04:52.450559: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\nTo enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n2025-12-11 08:04:53.238798: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\nINFO: Created TensorFlow Lite XNNPACK delegate for CPU.\nTraceback (most recent call last):\n  File \"/home/wuguangh/Projects/03.12/tinyml-autopilot-pm.03.12.2025/results/object_detection/sketches/tmp_20251211080452_psg_phi4:latest/tmp_20251211080452_psg_phi4:latest.py\", line 78, in <module>\n    process_video(input_path, output_path, interpreter, labels)\n  File \"/home/wuguangh/Projects/03.12/tinyml-autopilot-pm.03.12.2025/results/object_detection/sketches/tmp_20251211080452_psg_phi4:latest/tmp_20251211080452_psg_phi4:latest.py\", line 70, in process_video\n    boxes, classes, scores = run_inference(interpreter, input_data)\n  File \"/home/wuguangh/Projects/03.12/tinyml-autopilot-pm.03.12.2025/results/object_detection/sketches/tmp_20251211080452_psg_phi4:latest/tmp_20251211080452_psg_phi4:latest.py\", line 37, in run_inference\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n  File \"/home/wuguangh/.conda/envs/tinyml/lib/python3.10/site-packages/tensorflow/lite/python/interpreter.py\", line 732, in set_tensor\n    self._interpreter.SetTensor(tensor_index, value)\nValueError: Cannot set tensor: Got value of type FLOAT32 but expected type UINT8 for input 175, name: normalized_input_image_tensor \n"
      },
      "session_id": "phi4_a8a2_psg_batch",
      "metadata": {
        "num_run": 17
      },
      "tags": [
        "ablation",
        "benchmark",
        "phi4:latest",
        "py_sketch_generator"
      ],
      "latency": 90.581,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-08-03-24-503195_chatcmpl-945912f9-f43b-47cf-850c-18a4ce9a5c49",
          "traceId": "7cf5549f",
          "type": "GENERATION",
          "name": "7cf5_psg_gen_attempt#1",
          "startTime": "2025-12-11T06:03:24.503000+00:00",
          "endTime": "2025-12-11T06:03:41.188000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 16685.0,
          "promptTokens": 245,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 913,
          "totalTokens": 1158,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-08-03-44-153652_chatcmpl-06311fd2-caaf-482a-ac54-6d9e57202e06",
          "traceId": "7cf5549f",
          "type": "GENERATION",
          "name": "7cf5_psg_gen_attempt#2",
          "startTime": "2025-12-11T06:03:44.153000+00:00",
          "endTime": "2025-12-11T06:04:01.004000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 16851.0,
          "promptTokens": 245,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 927,
          "totalTokens": 1172,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-08-04-01-160436_chatcmpl-9cddf9ab-e2e6-4012-809c-ef34c1365864",
          "traceId": "7cf5549f",
          "type": "GENERATION",
          "name": "7cf5_psg_gen_attempt#3",
          "startTime": "2025-12-11T06:04:01.160000+00:00",
          "endTime": "2025-12-11T06:04:18.796000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 17636.0,
          "promptTokens": 245,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 969,
          "totalTokens": 1214,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-08-04-21-819946_chatcmpl-d10ce3bc-79f3-428d-9313-1f17bf619d52",
          "traceId": "7cf5549f",
          "type": "GENERATION",
          "name": "7cf5_psg_gen_attempt#4",
          "startTime": "2025-12-11T06:04:21.819000+00:00",
          "endTime": "2025-12-11T06:04:37.590000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 15771.0,
          "promptTokens": 245,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 867,
          "totalTokens": 1112,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-08-04-37-720414_chatcmpl-9de7bffa-4a45-4ae6-b88e-eae35ddc0f6a",
          "traceId": "7cf5549f",
          "type": "GENERATION",
          "name": "7cf5_psg_gen_attempt#5",
          "startTime": "2025-12-11T06:04:37.720000+00:00",
          "endTime": "2025-12-11T06:04:52.076000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 14356.0,
          "promptTokens": 245,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 790,
          "totalTokens": 1035,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "26d834bb-b2b8-46d5-8cf1-d0319a199dbd",
          "traceId": "7cf5549f",
          "type": "SPAN",
          "name": "error_7c_psg_failure_signal_py_sketch_generator",
          "startTime": "2025-12-11T06:04:55.084000+00:00",
          "level": "ERROR",
          "statusMessage": "Failed. Last error: Max retries reached with failure. Last error from execution: 2025-12-11 08:04:52.398275: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n2025-12-11 08:04:52.401641: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n2025-12-11 08:04:52.412991: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2025-12-11 08:04:52.431462: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2025-12-11 08:04:52.437352: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n2025-12-11 08:04:52.450559: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\nTo enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n2025-12-11 08:04:53.238798: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\nINFO: Created TensorFlow Lite XNNPACK delegate for CPU.\nTraceback (most recent call last):\n  File \"/home/wuguangh/Projects/03.12/tinyml-autopilot-pm.03.12.2025/results/object_detection/sketches/tmp_20251211080452_psg_phi4:latest/tmp_20251211080452_psg_phi4:latest.py\", line 78, in <module>\n    process_video(input_path, output_path, interpreter, labels)\n  File \"/home/wuguangh/Projects/03.12/tinyml-autopilot-pm.03.12.2025/results/object_detection/sketches/tmp_20251211080452_psg_phi4:latest/tmp_20251211080452_psg_phi4:latest.py\", line 70, in process_video\n    boxes, classes, scores = run_inference(interpreter, input_data)\n  File \"/home/wuguangh/Projects/03.12/tinyml-autopilot-pm.03.12.2025/results/object_detection/sketches/tmp_20251211080452_psg_phi4:latest/tmp_20251211080452_psg_phi4:latest.py\", line 37, in run_inference\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n  File \"/home/wuguangh/.conda/envs/tinyml/lib/python3.10/site-packages/tensorflow/lite/python/interpreter.py\", line 732, in set_tensor\n    self._interpreter.SetTensor(tensor_index, value)\nValueError: Cannot set tensor: Got value of type FLOAT32 but expected type UINT8 for input 175, name: normalized_input_image_tensor \n",
          "calculatedTotalCost": 0.0,
          "promptTokens": 0,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 0,
          "totalTokens": 0,
          "endTime": null,
          "model": null,
          "modelParameters": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null,
          "latency": null
        }
      ],
      "createdAt": "2025-12-11T06:03:25.016Z",
      "updatedAt": "2025-12-11T06:05:00.706Z",
      "environment": "default"
    },
    {
      "id": "042086fa",
      "timestamp": "2025-12-11T06:01:25.461000+00:00",
      "name": "0420_py_sketch_generator",
      "input": null,
      "output": {
        "status": "success",
        "sketch": "import cv2\nfrom tflite_runtime.interpreter import Interpreter\nimport numpy as np\n\n# Configuration parameters\nmodel_path = 'models/ssd-mobilenet_v1/detect.tflite'\nlabel_path = 'models/ssd-mobilenet_v1/labelmap.txt'\ninput_path = 'data/object_detection/sheeps.mp4'\noutput_path = 'results/object_detection/test_results/sheeps_detections.mp4'\nconfidence_threshold = 0.5\n\n# Phase 1: Setup\ndef load_labels(label_file):\n    with open(label_file, 'r') as file:\n        labels = [line.strip() for line in file.readlines()]\n    return labels\n\nlabels = load_labels(label_path)\n\ninterpreter = Interpreter(model_path=model_path)\ninterpreter.allocate_tensors()\n\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\n\nheight = input_details[0]['shape'][1]\nwidth = input_details[0]['shape'][2]\n\n# Phase 2: Preprocessing\ndef preprocess_frame(frame, width, height):\n    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n    frame_resized = cv2.resize(frame_rgb, (width, height))\n    input_data = np.expand_dims(frame_resized, axis=0)\n    return input_data\n\n# Phase 3: Inference\ndef run_inference(interpreter, input_data):\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n    interpreter.invoke()\n    boxes = interpreter.get_tensor(output_details[0]['index'])[0] # Bounding box coordinates of detected objects\n    classes = interpreter.get_tensor(output_details[1]['index'])[0] # Class index of detected objects\n    scores = interpreter.get_tensor(output_details[2]['index'])[0] # Confidence of detected objects\n    return boxes, classes, scores\n\n# Phase 4: Output handling\ndef compute_map(boxes, classes, scores):\n    # Simplified mAP computation for demonstration purposes\n    # Normally, you would use a library or more detailed logic to calculate mAP\n    true_positives = 0\n    total_detections = len(scores)\n    \n    for i in range(total_detections):\n        if scores[i] >= confidence_threshold:\n            true_positives += 1\n    \n    precision = true_positives / total_detections if total_detections > 0 else 0\n    recall = true_positives / total_detections if total_detections > 0 else 0\n    f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n    \n    return {\"precision\": precision, \"recall\": recall, \"f1_score\": f1_score}\n\ndef draw_boxes(frame, boxes, classes, scores, labels):\n    for i in range(len(scores)):\n        if scores[i] >= confidence_threshold:\n            ymin, xmin, ymax, xmax = boxes[i]\n            (left, right, top, bottom) = (xmin * frame.shape[1], xmax * frame.shape[1],\n                                          ymin * frame.shape[0], ymax * frame.shape[0])\n            cv2.rectangle(frame, (int(left), int(top)), (int(right), int(bottom)), (10, 255, 0), 2)\n            label = f\"{labels[int(classes[i])]}: {int(scores[i] * 100)}%\"\n            cv2.putText(frame, label, (int(left), int(top) - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (10, 255, 0), 2)\n    return frame\n\n# Video processing\ncap = cv2.VideoCapture(input_path)\nfourcc = cv2.VideoWriter_fourcc(*'mp4v')\nout = cv2.VideoWriter(output_path, fourcc, cap.get(cv2.CAP_PROP_FPS),\n                      (int(cap.get(cv2.CAP_PROP_FRAME_WIDTH)), int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))))\n\nwhile cap.isOpened():\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    input_data = preprocess_frame(frame, width, height)\n    boxes, classes, scores = run_inference(interpreter, input_data)\n\n    frame_with_boxes = draw_boxes(frame, boxes, classes, scores, labels)\n\n    out.write(frame_with_boxes)\n\n    # Compute mAP (for demonstration purposes, typically done over a dataset)\n    metrics = compute_map(boxes, classes, scores)\n    print(f\"Frame Metrics: Precision={metrics['precision']:.2f}, Recall={metrics['recall']:.2f}, F1-Score={metrics['f1_score']:.2f}\")\n\ncap.release()\nout.release()\n\nprint(\"Processing complete. Output saved to:\", output_path)"
      },
      "session_id": "phi4_a8a2_psg_batch",
      "metadata": {
        "num_run": 16
      },
      "tags": [
        "ablation",
        "benchmark",
        "phi4:latest",
        "py_sketch_generator"
      ],
      "latency": 58.592,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-08-01-25-462377_chatcmpl-ac8e2251-fc4a-486d-96a4-6e3773dae33f",
          "traceId": "042086fa",
          "type": "GENERATION",
          "name": "0420_psg_gen_attempt#1",
          "startTime": "2025-12-11T06:01:25.462000+00:00",
          "endTime": "2025-12-11T06:01:42.177000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 16715.0,
          "promptTokens": 245,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 915,
          "totalTokens": 1160,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-08-01-42-308540_chatcmpl-7d32beed-f328-47b2-9dc0-d2904490bc90",
          "traceId": "042086fa",
          "type": "GENERATION",
          "name": "0420_psg_gen_attempt#2",
          "startTime": "2025-12-11T06:01:42.308000+00:00",
          "endTime": "2025-12-11T06:02:03.075000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 20767.0,
          "promptTokens": 245,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 1138,
          "totalTokens": 1383,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-08-02-06-153866_chatcmpl-9ba0b2eb-3da1-48f4-8f71-7df9c61ace79",
          "traceId": "042086fa",
          "type": "GENERATION",
          "name": "0420_psg_gen_attempt#3",
          "startTime": "2025-12-11T06:02:06.153000+00:00",
          "endTime": "2025-12-11T06:02:24.054000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 17901.0,
          "promptTokens": 245,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 983,
          "totalTokens": 1228,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        }
      ],
      "createdAt": "2025-12-11T06:01:25.976Z",
      "updatedAt": "2025-12-11T06:03:04.786Z",
      "environment": "default"
    },
    {
      "id": "1e24202c",
      "timestamp": "2025-12-11T05:59:03.481000+00:00",
      "name": "1e24_py_sketch_generator",
      "input": null,
      "output": {
        "status": "success",
        "sketch": "import cv2\nimport numpy as np\nfrom tflite_runtime.interpreter import Interpreter\n\n# Configuration parameters\nmodel_path = 'models/ssd-mobilenet_v1/detect.tflite'\nlabel_path = 'models/ssd-mobilenet_v1/labelmap.txt'\ninput_path = 'data/object_detection/sheeps.mp4'\noutput_path = 'results/object_detection/test_results/sheeps_detections.mp4'\nconfidence_threshold = 0.5\n\ndef load_labels(label_file):\n    with open(label_file, 'r') as file:\n        return {i: line.strip() for i, line in enumerate(file.readlines())}\n\ndef set_input_tensor(interpreter, image):\n    tensor_index = interpreter.get_input_details()[0]['index']\n    input_shape = interpreter.get_input_details()[0]['shape']\n    input_image = cv2.resize(image, (input_shape[1], input_shape[2]))\n    input_image = np.expand_dims(input_image, axis=0)\n    interpreter.set_tensor(tensor_index, input_image)\n\ndef get_output(interpreter):\n    boxes = interpreter.get_tensor(interpreter.get_output_details()[0]['index'])[0]\n    classes = interpreter.get_tensor(interpreter.get_output_details()[1]['index'])[0].astype(np.int64)\n    scores = interpreter.get_tensor(interpreter.get_output_details()[2]['index'])[0]\n    return boxes, classes, scores\n\ndef draw_detections(image, detections, labels):\n    for i in range(len(detections)):\n        if detections[i][4] > confidence_threshold:\n            ymin, xmin, ymax, xmax = detections[i][:4]\n            (left, right, top, bottom) = (xmin * image.shape[1], xmax * image.shape[1],\n                                          ymin * image.shape[0], ymax * image.shape[0])\n            cv2.rectangle(image, (int(left), int(top)), (int(right), int(bottom)), (10, 255, 0), 2)\n            label = f\"{labels[detections[i][5]]}: {detections[i][4]:.2f}\"\n            cv2.putText(image, label, (int(left), int(top) - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 1)\n\ndef compute_map(detections):\n    # Placeholder for mAP computation logic\n    return \"mAP: Not implemented\"\n\n# Setup phase\ninterpreter = Interpreter(model_path=model_path)\ninterpreter.allocate_tensors()\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\n\nlabels = load_labels(label_path)\n\n# Preprocessing and inference phase\ncap = cv2.VideoCapture(input_path)\nfourcc = cv2.VideoWriter_fourcc(*'mp4v')\nout = cv2.VideoWriter(output_path, fourcc, 20.0, (int(cap.get(3)), int(cap.get(4))))\n\nwhile cap.isOpened():\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    set_input_tensor(interpreter, frame)\n    interpreter.invoke()\n\n    boxes, classes, scores = get_output(interpreter)\n\n    detections = np.array([list(box) + [score] + [cls] for box, score, cls in zip(boxes, scores, classes)])\n    draw_detections(frame, detections, labels)\n\n    out.write(frame)\n\ncap.release()\nout.release()\n\n# Output handling phase\nmap_result = compute_map(detections)\nprint(map_result)"
      },
      "session_id": "phi4_a8a2_psg_batch",
      "metadata": {
        "num_run": 15
      },
      "tags": [
        "ablation",
        "benchmark",
        "phi4:latest",
        "py_sketch_generator"
      ],
      "latency": 85.027,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-07-59-03-482910_chatcmpl-f56beea5-35f4-4923-a0ee-f3461eeb1dd3",
          "traceId": "1e24202c",
          "type": "GENERATION",
          "name": "1e24_psg_gen_attempt#1",
          "startTime": "2025-12-11T05:59:03.482000+00:00",
          "endTime": "2025-12-11T05:59:21.636000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 18154.0,
          "promptTokens": 245,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 993,
          "totalTokens": 1238,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-07-59-22-357652_chatcmpl-c3dca23b-a0fa-4767-aac5-6827323313ed",
          "traceId": "1e24202c",
          "type": "GENERATION",
          "name": "1e24_psg_gen_attempt#2",
          "startTime": "2025-12-11T05:59:22.357000+00:00",
          "endTime": "2025-12-11T05:59:37.582000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 15225.0,
          "promptTokens": 245,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 838,
          "totalTokens": 1083,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-07-59-40-911074_chatcmpl-f490970f-921d-4315-8160-c98e9b46a9cc",
          "traceId": "1e24202c",
          "type": "GENERATION",
          "name": "1e24_psg_gen_attempt#3",
          "startTime": "2025-12-11T05:59:40.911000+00:00",
          "endTime": "2025-12-11T05:59:57.881000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 16970.0,
          "promptTokens": 245,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 932,
          "totalTokens": 1177,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-08-00-00-901632_chatcmpl-ab6c6f3d-10b6-4268-b410-aa9d1d5ec665",
          "traceId": "1e24202c",
          "type": "GENERATION",
          "name": "1e24_psg_gen_attempt#4",
          "startTime": "2025-12-11T06:00:00.901000+00:00",
          "endTime": "2025-12-11T06:00:15.421000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 14520.0,
          "promptTokens": 245,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 799,
          "totalTokens": 1044,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-08-00-15-580436_chatcmpl-274c36e9-17b1-4692-b3ce-511c50431cd8",
          "traceId": "1e24202c",
          "type": "GENERATION",
          "name": "1e24_psg_gen_attempt#5",
          "startTime": "2025-12-11T06:00:15.580000+00:00",
          "endTime": "2025-12-11T06:00:28.509000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 12929.0,
          "promptTokens": 245,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 712,
          "totalTokens": 957,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        }
      ],
      "createdAt": "2025-12-11T05:59:03.999Z",
      "updatedAt": "2025-12-11T06:01:05.651Z",
      "environment": "default"
    },
    {
      "id": "20d50369",
      "timestamp": "2025-12-11T05:57:53.518000+00:00",
      "name": "20d5_py_sketch_generator",
      "input": null,
      "output": {
        "status": "success",
        "sketch": "import cv2\nimport numpy as np\nfrom tflite_runtime.interpreter import Interpreter\n\n# Configuration parameters\nmodel_path = 'models/ssd-mobilenet_v1/detect.tflite'\nlabel_path = 'models/ssd-mobilenet_v1/labelmap.txt'\ninput_path = 'data/object_detection/sheeps.mp4'\noutput_path = 'results/object_detection/test_results/sheeps_detections.mp4'\nconfidence_threshold = 0.5\n\n# Load labels\nwith open(label_path, 'r') as f:\n    labels = [line.strip() for line in f.readlines()]\n\n# Initialize TFLite interpreter\ninterpreter = Interpreter(model_path=model_path)\ninterpreter.allocate_tensors()\n\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\n\ninput_shape = input_details[0]['shape']\nheight, width, channels = input_shape[1], input_shape[2], input_shape[3]\n\n# 2. Preprocessing\ndef preprocess(frame):\n    frame_resized = cv2.resize(frame, (width, height))\n    input_data = np.expand_dims(frame_resized, axis=0)\n    return input_data\n\n# 3. Inference\ndef run_inference(input_data):\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n    interpreter.invoke()\n    \n    boxes = interpreter.get_tensor(output_details[0]['index'])[0]\n    classes = interpreter.get_tensor(output_details[1]['index'])[0]\n    scores = interpreter.get_tensor(output_details[2]['index'])[0]\n    \n    return boxes, classes, scores\n\n# 4. Output handling\ndef draw_detections(frame, boxes, classes, scores):\n    for i in range(len(scores)):\n        if scores[i] > confidence_threshold:\n            ymin, xmin, ymax, xmax = boxes[i]\n            (left, right, top, bottom) = (xmin * frame.shape[1], xmax * frame.shape[1],\n                                          ymin * frame.shape[0], ymax * frame.shape[0])\n            \n            cv2.rectangle(frame, (int(left), int(top)), (int(right), int(bottom)), (10, 255, 0), 2)\n            \n            label = f\"{labels[int(classes[i])]}: {int(scores[i]*100)}%\"\n            cv2.putText(frame, label, (int(left), int(top-5)), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n\n# Video processing\ncap = cv2.VideoCapture(input_path)\nfourcc = cv2.VideoWriter_fourcc(*'mp4v')\nout = cv2.VideoWriter(output_path, fourcc, 20.0, (int(cap.get(3)), int(cap.get(4))))\n\nwhile cap.isOpened():\n    ret, frame = cap.read()\n    if not ret:\n        break\n    \n    input_data = preprocess(frame)\n    boxes, classes, scores = run_inference(input_data)\n    \n    draw_detections(frame, boxes, classes, scores)\n    \n    out.write(frame)\n\ncap.release()\nout.release()\n\nprint(\"Processing complete. Output saved to:\", output_path)"
      },
      "session_id": "phi4_a8a2_psg_batch",
      "metadata": {
        "num_run": 14
      },
      "tags": [
        "ablation",
        "benchmark",
        "phi4:latest",
        "py_sketch_generator"
      ],
      "latency": 13.024,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-07-57-53-518646_chatcmpl-cd4b7651-1f98-4aa1-a572-5fddabe79cda",
          "traceId": "20d50369",
          "type": "GENERATION",
          "name": "20d5_psg_gen_attempt#1",
          "startTime": "2025-12-11T05:57:53.518000+00:00",
          "endTime": "2025-12-11T05:58:06.542000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 13024.0,
          "promptTokens": 245,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 706,
          "totalTokens": 951,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        }
      ],
      "createdAt": "2025-12-11T05:57:54.033Z",
      "updatedAt": "2025-12-11T05:58:43.732Z",
      "environment": "default"
    },
    {
      "id": "0e02a3b7",
      "timestamp": "2025-12-11T05:55:41.502000+00:00",
      "name": "0e02_py_sketch_generator",
      "input": null,
      "output": {
        "status": "failed",
        "last_code": "import cv2\nimport numpy as np\nimport tensorflow as tf\n\n# Configuration parameters\nmodel_path = 'models/ssd-mobilenet_v1/detect.tflite'\nlabel_path = 'models/ssd-mobilenet_v1/labelmap.txt'\ninput_path = 'data/object_detection/sheeps.mp4'\noutput_path = 'results/object_detection/test_results/sheeps_detections.mp4'\nconfidence_threshold = 0.5\n\n# Phase 1: Setup\ndef load_labels(label_file):\n    with open(label_file, 'r') as f:\n        return {i: line.strip() for i, line in enumerate(f.readlines())}\n\ndef create_interpreter(model_path):\n    interpreter = tf.lite.Interpreter(model_path=model_path)\n    interpreter.allocate_tensors()\n    return interpreter\n\n# Phase 2: Preprocessing\ndef preprocess_frame(frame, input_size):\n    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n    frame_resized = cv2.resize(frame_rgb, (input_size[1], input_size[0]))\n    input_tensor = np.expand_dims(frame_resized, axis=0).astype(np.float32)\n    return input_tensor\n\n# Phase 3: Inference\ndef run_inference(interpreter, input_tensor):\n    input_details = interpreter.get_input_details()\n    output_details = interpreter.get_output_details()\n\n    interpreter.set_tensor(input_details[0]['index'], input_tensor)\n\n    interpreter.invoke()\n\n    boxes = interpreter.get_tensor(output_details[0]['index'])[0]\n    classes = interpreter.get_tensor(output_details[1]['index'])[0]\n    scores = interpreter.get_tensor(output_details[2]['index'])[0]\n\n    return boxes, classes, scores\n\n# Phase 4: Output handling\ndef draw_detections(frame, boxes, classes, scores, labels, threshold):\n    for i in range(len(scores)):\n        if scores[i] > threshold:\n            ymin, xmin, ymax, xmax = boxes[i]\n            (left, right, top, bottom) = (xmin * frame.shape[1], xmax * frame.shape[1],\n                                          ymin * frame.shape[0], ymax * frame.shape[0])\n            cv2.rectangle(frame, (int(left), int(top)), (int(right), int(bottom)),\n                          (10, 255, 0), 2)\n            label = f'{labels[int(classes[i])]}: {int(scores[i]*100)}%'\n            cv2.putText(frame, label, (int(left), int(top) - 15),\n                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (10, 255, 0), 2)\n\ndef compute_map(predictions, ground_truths):\n    # Placeholder for mAP computation logic\n    pass\n\n# Main execution pipeline\nlabels = load_labels(label_path)\ninterpreter = create_interpreter(model_path)\ninput_details = interpreter.get_input_details()\noutput_size = input_details[0]['shape'][1:3]\n\ncap = cv2.VideoCapture(input_path)\nfourcc = cv2.VideoWriter_fourcc(*'mp4v')\nout = cv2.VideoWriter(output_path, fourcc, 20.0, (int(cap.get(3)), int(cap.get(4))))\n\nwhile cap.isOpened():\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    input_tensor = preprocess_frame(frame, output_size)\n    boxes, classes, scores = run_inference(interpreter, input_tensor)\n    draw_detections(frame, boxes, classes, scores, labels, confidence_threshold)\n\n    out.write(frame)\n\ncap.release()\nout.release()\ncv2.destroyAllWindows()\n\n# Compute mAP (placeholder for actual computation logic)\n# predictions and ground_truths would need to be defined based on your dataset\n# compute_map(predictions, ground_truths)",
        "last_error": "Max retries reached with failure. Last error from execution: 2025-12-11 07:57:25.149148: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n2025-12-11 07:57:25.152623: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n2025-12-11 07:57:25.164043: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2025-12-11 07:57:25.182357: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2025-12-11 07:57:25.188071: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n2025-12-11 07:57:25.201600: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\nTo enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n2025-12-11 07:57:25.997166: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\nINFO: Created TensorFlow Lite XNNPACK delegate for CPU.\nTraceback (most recent call last):\n  File \"/home/wuguangh/Projects/03.12/tinyml-autopilot-pm.03.12.2025/results/object_detection/sketches/tmp_20251211075724_psg_phi4:latest/tmp_20251211075724_psg_phi4:latest.py\", line 77, in <module>\n    boxes, classes, scores = run_inference(interpreter, input_tensor)\n  File \"/home/wuguangh/Projects/03.12/tinyml-autopilot-pm.03.12.2025/results/object_detection/sketches/tmp_20251211075724_psg_phi4:latest/tmp_20251211075724_psg_phi4:latest.py\", line 34, in run_inference\n    interpreter.set_tensor(input_details[0]['index'], input_tensor)\n  File \"/home/wuguangh/.conda/envs/tinyml/lib/python3.10/site-packages/tensorflow/lite/python/interpreter.py\", line 732, in set_tensor\n    self._interpreter.SetTensor(tensor_index, value)\nValueError: Cannot set tensor: Got value of type FLOAT32 but expected type UINT8 for input 175, name: normalized_input_image_tensor \n"
      },
      "session_id": "phi4_a8a2_psg_batch",
      "metadata": {
        "num_run": 13
      },
      "tags": [
        "ablation",
        "benchmark",
        "phi4:latest",
        "py_sketch_generator"
      ],
      "latency": 106.425,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-07-55-41-504147_chatcmpl-11d3adf5-63fc-49ed-a596-269530f6bc67",
          "traceId": "0e02a3b7",
          "type": "GENERATION",
          "name": "0e02_psg_gen_attempt#1",
          "startTime": "2025-12-11T05:55:41.504000+00:00",
          "endTime": "2025-12-11T05:55:56.737000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 15233.0,
          "promptTokens": 245,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 834,
          "totalTokens": 1079,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-07-56-05-621340_chatcmpl-eb83d087-954a-4f54-9e04-d3ad04da589a",
          "traceId": "0e02a3b7",
          "type": "GENERATION",
          "name": "0e02_psg_gen_attempt#2",
          "startTime": "2025-12-11T05:56:05.621000+00:00",
          "endTime": "2025-12-11T05:56:23.622000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 18001.0,
          "promptTokens": 245,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 988,
          "totalTokens": 1233,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-07-56-26-672443_chatcmpl-62f690f6-5d2a-4033-b775-6800acc74a21",
          "traceId": "0e02a3b7",
          "type": "GENERATION",
          "name": "0e02_psg_gen_attempt#3",
          "startTime": "2025-12-11T05:56:26.672000+00:00",
          "endTime": "2025-12-11T05:56:51.386000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 24714.0,
          "promptTokens": 245,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 1349,
          "totalTokens": 1594,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-07-56-52-107765_chatcmpl-fa0b457b-2585-4d25-955b-9e3350abd8e9",
          "traceId": "0e02a3b7",
          "type": "GENERATION",
          "name": "0e02_psg_gen_attempt#4",
          "startTime": "2025-12-11T05:56:52.107000+00:00",
          "endTime": "2025-12-11T05:57:07.661000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 15554.0,
          "promptTokens": 245,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 856,
          "totalTokens": 1101,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-07-57-10-719499_chatcmpl-b0b97e14-8b0b-4d55-bdb1-f76ad6b4a32f",
          "traceId": "0e02a3b7",
          "type": "GENERATION",
          "name": "0e02_psg_gen_attempt#5",
          "startTime": "2025-12-11T05:57:10.719000+00:00",
          "endTime": "2025-12-11T05:57:24.828000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 14109.0,
          "promptTokens": 245,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 776,
          "totalTokens": 1021,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "647000e7-f215-4777-8358-60d58e237505",
          "traceId": "0e02a3b7",
          "type": "SPAN",
          "name": "error_0e_psg_failure_signal_py_sketch_generator",
          "startTime": "2025-12-11T05:57:27.929000+00:00",
          "level": "ERROR",
          "statusMessage": "Failed. Last error: Max retries reached with failure. Last error from execution: 2025-12-11 07:57:25.149148: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n2025-12-11 07:57:25.152623: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n2025-12-11 07:57:25.164043: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2025-12-11 07:57:25.182357: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2025-12-11 07:57:25.188071: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n2025-12-11 07:57:25.201600: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\nTo enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n2025-12-11 07:57:25.997166: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\nINFO: Created TensorFlow Lite XNNPACK delegate for CPU.\nTraceback (most recent call last):\n  File \"/home/wuguangh/Projects/03.12/tinyml-autopilot-pm.03.12.2025/results/object_detection/sketches/tmp_20251211075724_psg_phi4:latest/tmp_20251211075724_psg_phi4:latest.py\", line 77, in <module>\n    boxes, classes, scores = run_inference(interpreter, input_tensor)\n  File \"/home/wuguangh/Projects/03.12/tinyml-autopilot-pm.03.12.2025/results/object_detection/sketches/tmp_20251211075724_psg_phi4:latest/tmp_20251211075724_psg_phi4:latest.py\", line 34, in run_inference\n    interpreter.set_tensor(input_details[0]['index'], input_tensor)\n  File \"/home/wuguangh/.conda/envs/tinyml/lib/python3.10/site-packages/tensorflow/lite/python/interpreter.py\", line 732, in set_tensor\n    self._interpreter.SetTensor(tensor_index, value)\nValueError: Cannot set tensor: Got value of type FLOAT32 but expected type UINT8 for input 175, name: normalized_input_image_tensor \n",
          "calculatedTotalCost": 0.0,
          "promptTokens": 0,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 0,
          "totalTokens": 0,
          "endTime": null,
          "model": null,
          "modelParameters": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null,
          "latency": null
        }
      ],
      "createdAt": "2025-12-11T05:55:42.019Z",
      "updatedAt": "2025-12-11T05:57:33.178Z",
      "environment": "default"
    },
    {
      "id": "55f3a15b",
      "timestamp": "2025-12-11T05:53:44.468000+00:00",
      "name": "55f3_py_sketch_generator",
      "input": null,
      "output": {
        "status": "success",
        "sketch": "import cv2\nimport numpy as np\nimport tensorflow as tf\n\n# Configuration parameters\nmodel_path = 'models/ssd-mobilenet_v1/detect.tflite'\nlabel_path = 'models/ssd-mobilenet_v1/labelmap.txt'\ninput_path = 'data/object_detection/sheeps.mp4'\noutput_path = 'results/object_detection/test_results/sheeps_detections.mp4'\nconfidence_threshold = 0.5\n\n# Setup phase\ndef setup():\n    # Load TFLite model and allocate tensors.\n    interpreter = tf.lite.Interpreter(model_path=model_path)\n    interpreter.allocate_tensors()\n\n    # Get input and output tensors.\n    input_details = interpreter.get_input_details()\n    output_details = interpreter.get_output_details()\n\n    # Read labels from label map\n    with open(label_path, 'r') as f:\n        labels = [line.strip() for line in f.readlines()]\n\n    return interpreter, input_details, output_details, labels\n\n# Preprocessing phase\ndef preprocess_frame(frame, input_details):\n    # Resize and normalize the image to fit model requirements.\n    frame_resized = cv2.resize(frame, (input_details[0]['shape'][2], input_details[0]['shape'][1]))\n    frame_normalized = frame_resized / 255.0\n    return np.expand_dims(frame_normalized, axis=0).astype(input_details[0]['dtype'])\n\n# Inference phase\ndef run_inference(interpreter, preprocessed_frame):\n    # Set the tensor to point to the input data to be inferred\n    interpreter.set_tensor(interpreter.get_input_details()[0]['index'], preprocessed_frame)\n\n    # Run inference and get the result\n    interpreter.invoke()\n\n    # Retrieve detection results\n    boxes = interpreter.get_tensor(interpreter.get_output_details()[0]['index'])[0]  # Bounding box coordinates of detected objects\n    classes = interpreter.get_tensor(interpreter.get_output_details()[1]['index'])[0]  # Class index of detected objects\n    scores = interpreter.get_tensor(interpreter.get_output_details()[2]['index'])[0]  # Confidence of detected objects\n\n    return boxes, classes, scores\n\n# Output handling phase\ndef draw_detections(frame, boxes, classes, scores, labels, confidence_threshold):\n    for i in range(len(scores)):\n        if scores[i] >= confidence_threshold:\n            ymin, xmin, ymax, xmax = boxes[i]\n            (left, right, top, bottom) = (xmin * frame.shape[1], xmax * frame.shape[1],\n                                          ymin * frame.shape[0], ymax * frame.shape[0])\n            cv2.rectangle(frame, (int(left), int(top)), (int(right), int(bottom)), (10, 255, 0), 2)\n\n            # Draw label\n            label = f\"{labels[int(classes[i])]}: {int(scores[i]*100)}%\"\n            cv2.putText(frame, label, (int(left), int(top)-10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2)\n\n    return frame\n\ndef main():\n    interpreter, input_details, output_details, labels = setup()\n\n    # Video capture\n    cap = cv2.VideoCapture(input_path)\n    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n    out = cv2.VideoWriter(output_path, fourcc, 20.0, (int(cap.get(3)), int(cap.get(4))))\n\n    while cap.isOpened():\n        ret, frame = cap.read()\n        if not ret:\n            break\n\n        preprocessed_frame = preprocess_frame(frame, input_details)\n        boxes, classes, scores = run_inference(interpreter, preprocessed_frame)\n        frame_with_detections = draw_detections(frame, boxes, classes, scores, labels, confidence_threshold)\n\n        out.write(frame_with_detections)\n\n    cap.release()\n    out.release()\n\nif __name__ == '__main__':\n    main()"
      },
      "session_id": "phi4_a8a2_psg_batch",
      "metadata": {
        "num_run": 12
      },
      "tags": [
        "ablation",
        "benchmark",
        "phi4:latest",
        "py_sketch_generator"
      ],
      "latency": 82.849,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-07-53-44-469431_chatcmpl-79dca957-5ec5-4b06-a92d-69ebc90f8e33",
          "traceId": "55f3a15b",
          "type": "GENERATION",
          "name": "55f3_psg_gen_attempt#1",
          "startTime": "2025-12-11T05:53:44.469000+00:00",
          "endTime": "2025-12-11T05:54:04.572000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 20103.0,
          "promptTokens": 245,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 1097,
          "totalTokens": 1342,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-07-54-04-705766_chatcmpl-de179186-7b57-47ce-a099-0b9a44bea85b",
          "traceId": "55f3a15b",
          "type": "GENERATION",
          "name": "55f3_psg_gen_attempt#2",
          "startTime": "2025-12-11T05:54:04.705000+00:00",
          "endTime": "2025-12-11T05:54:20.947000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 16242.0,
          "promptTokens": 245,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 893,
          "totalTokens": 1138,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-07-54-21-114594_chatcmpl-4e9929f0-ba5e-4783-8cf7-933ef16e26d6",
          "traceId": "55f3a15b",
          "type": "GENERATION",
          "name": "55f3_psg_gen_attempt#3",
          "startTime": "2025-12-11T05:54:21.114000+00:00",
          "endTime": "2025-12-11T05:54:36.493000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 15379.0,
          "promptTokens": 245,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 846,
          "totalTokens": 1091,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-07-54-36-667440_chatcmpl-da1e11ca-d431-49d2-9b1a-f846f129ef02",
          "traceId": "55f3a15b",
          "type": "GENERATION",
          "name": "55f3_psg_gen_attempt#4",
          "startTime": "2025-12-11T05:54:36.667000+00:00",
          "endTime": "2025-12-11T05:54:52.360000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 15693.0,
          "promptTokens": 245,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 863,
          "totalTokens": 1108,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-07-54-52-492659_chatcmpl-6360a2b7-167f-47a6-aa6c-8b23c993b0f4",
          "traceId": "55f3a15b",
          "type": "GENERATION",
          "name": "55f3_psg_gen_attempt#5",
          "startTime": "2025-12-11T05:54:52.492000+00:00",
          "endTime": "2025-12-11T05:55:07.318000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 14826.0,
          "promptTokens": 245,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 816,
          "totalTokens": 1061,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        }
      ],
      "createdAt": "2025-12-11T05:53:44.983Z",
      "updatedAt": "2025-12-11T05:55:21.191Z",
      "environment": "default"
    },
    {
      "id": "6057e666",
      "timestamp": "2025-12-11T05:51:53.371000+00:00",
      "name": "6057_py_sketch_generator",
      "input": null,
      "output": {
        "status": "failed",
        "last_code": "import cv2\nfrom tflite_runtime.interpreter import Interpreter\nimport numpy as np\n\n# Configuration parameters\nmodel_path = 'models/ssd-mobilenet_v1/detect.tflite'\nlabel_path = 'models/ssd-mobilenet_v1/labelmap.txt'\ninput_path = 'data/object_detection/sheeps.mp4'\noutput_path = 'results/object_detection/test_results/sheeps_detections.mp4'\nconfidence_threshold = 0.5\n\n# Phase 1: Setup\ndef load_labels(path):\n    with open(path, 'r') as file:\n        return {i.strip(): line.strip() for i, line in enumerate(file.readlines())}\n\ndef create_interpreter(model_path):\n    interpreter = Interpreter(model_path=model_path)\n    interpreter.allocate_tensors()\n    return interpreter\n\n# Phase 2: Preprocessing\ndef preprocess_frame(frame, input_size):\n    frame_resized = cv2.resize(frame, (input_size[1], input_size[0]))\n    input_data = np.expand_dims(frame_resized, axis=0).astype(np.float32)\n    return input_data\n\n# Phase 3: Inference\ndef run_inference(interpreter, input_data):\n    interpreter.set_tensor(interpreter.get_input_details()[0]['index'], input_data)\n    interpreter.invoke()\n    boxes = interpreter.get_tensor(interpreter.get_output_details()[0]['index'])[0] # Bounding box coordinates of detected objects\n    classes = interpreter.get_tensor(interpreter.get_output_details()[1]['index'])[0] # Class index of detected objects\n    scores = interpreter.get_tensor(interpreter.get_output_details()[2]['index'])[0] # Confidence of detected objects\n    return boxes, classes, scores\n\n# Phase 4: Output Handling\ndef draw_detections(frame, boxes, classes, scores, labels, input_size, confidence_threshold):\n    height, width, _ = frame.shape\n    for i in range(len(scores)):\n        if scores[i] >= confidence_threshold:\n            ymin, xmin, ymax, xmax = boxes[i]\n            (left, right, top, bottom) = (xmin * width, xmax * width, ymin * height, ymax * height)\n            object_name = labels[int(classes[i])]\n            label = f\"{object_name}: {int(scores[i]*100)}%\"\n            cv2.rectangle(frame, (int(left), int(top)), (int(right), int(bottom)), (10, 255, 0), 2)\n            label_size, base_line = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.7, 2)\n            top = max(top, label_size[1])\n            cv2.rectangle(frame, (int(left), int(top - label_size[1])), (int(left + label_size[0]), int(top + base_line)), (255, 255, 255), cv2.FILLED)\n            cv2.putText(frame, label, (int(left), int(top)), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 0), 2)\n\ndef compute_map():\n    # Placeholder for mAP computation logic\n    pass\n\n# Main execution pipeline\ndef main():\n    labels = load_labels(label_path)\n    interpreter = create_interpreter(model_path)\n    input_details = interpreter.get_input_details()\n    output_details = interpreter.get_output_details()\n    input_size = input_details[0]['shape'][1:3]\n\n    cap = cv2.VideoCapture(input_path)\n    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n    out = cv2.VideoWriter(output_path, fourcc, 20.0, (int(cap.get(3)), int(cap.get(4))))\n\n    while cap.isOpened():\n        ret, frame = cap.read()\n        if not ret:\n            break\n\n        input_data = preprocess_frame(frame, input_size)\n        boxes, classes, scores = run_inference(interpreter, input_data)\n        draw_detections(frame, boxes, classes, scores, labels, input_size, confidence_threshold)\n\n        out.write(frame)\n\n    compute_map()\n\n    cap.release()\n    out.release()\n    cv2.destroyAllWindows()\n\nif __name__ == \"__main__\":\n    main()",
        "last_error": "Max retries reached with failure. Last error from execution: Traceback (most recent call last):\n  File \"/home/wuguangh/Projects/03.12/tinyml-autopilot-pm.03.12.2025/results/object_detection/sketches/tmp_20251211075318_psg_phi4:latest/tmp_20251211075318_psg_phi4:latest.py\", line 86, in <module>\n    main()\n  File \"/home/wuguangh/Projects/03.12/tinyml-autopilot-pm.03.12.2025/results/object_detection/sketches/tmp_20251211075318_psg_phi4:latest/tmp_20251211075318_psg_phi4:latest.py\", line 58, in main\n    labels = load_labels(label_path)\n  File \"/home/wuguangh/Projects/03.12/tinyml-autopilot-pm.03.12.2025/results/object_detection/sketches/tmp_20251211075318_psg_phi4:latest/tmp_20251211075318_psg_phi4:latest.py\", line 15, in load_labels\n    return {i.strip(): line.strip() for i, line in enumerate(file.readlines())}\n  File \"/home/wuguangh/Projects/03.12/tinyml-autopilot-pm.03.12.2025/results/object_detection/sketches/tmp_20251211075318_psg_phi4:latest/tmp_20251211075318_psg_phi4:latest.py\", line 15, in <dictcomp>\n    return {i.strip(): line.strip() for i, line in enumerate(file.readlines())}\nAttributeError: 'int' object has no attribute 'strip'\n"
      },
      "session_id": "phi4_a8a2_psg_batch",
      "metadata": {
        "num_run": 11
      },
      "tags": [
        "ablation",
        "benchmark",
        "phi4:latest",
        "py_sketch_generator"
      ],
      "latency": 85.147,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-07-51-53-372127_chatcmpl-5fed20e8-9f4a-4811-8e17-4866729d0c76",
          "traceId": "6057e666",
          "type": "GENERATION",
          "name": "6057_psg_gen_attempt#1",
          "startTime": "2025-12-11T05:51:53.372000+00:00",
          "endTime": "2025-12-11T05:52:10.647000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 17275.0,
          "promptTokens": 245,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 945,
          "totalTokens": 1190,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-07-52-10-777220_chatcmpl-c5bff12c-15f7-4fd9-9ce8-88d4f8d11fc5",
          "traceId": "6057e666",
          "type": "GENERATION",
          "name": "6057_psg_gen_attempt#2",
          "startTime": "2025-12-11T05:52:10.777000+00:00",
          "endTime": "2025-12-11T05:52:26.084000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 15307.0,
          "promptTokens": 245,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 842,
          "totalTokens": 1087,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-07-52-29-619147_chatcmpl-0838b184-5b70-4df6-8374-2391e67a7f86",
          "traceId": "6057e666",
          "type": "GENERATION",
          "name": "6057_psg_gen_attempt#3",
          "startTime": "2025-12-11T05:52:29.619000+00:00",
          "endTime": "2025-12-11T05:52:44.329000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 14710.0,
          "promptTokens": 245,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 809,
          "totalTokens": 1054,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-07-52-47-684274_chatcmpl-cdc5f85a-c5f6-4549-bc4e-7a8be2227e75",
          "traceId": "6057e666",
          "type": "GENERATION",
          "name": "6057_psg_gen_attempt#4",
          "startTime": "2025-12-11T05:52:47.684000+00:00",
          "endTime": "2025-12-11T05:53:02.587000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 14903.0,
          "promptTokens": 245,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 821,
          "totalTokens": 1066,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-07-53-02-721439_chatcmpl-d1cfba9b-c2bc-4aae-b558-e307c84cf44f",
          "traceId": "6057e666",
          "type": "GENERATION",
          "name": "6057_psg_gen_attempt#5",
          "startTime": "2025-12-11T05:53:02.721000+00:00",
          "endTime": "2025-12-11T05:53:18.385000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 15664.0,
          "promptTokens": 245,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 862,
          "totalTokens": 1107,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "1ea26b7b-2b2b-4477-894f-49aa6a818de0",
          "traceId": "6057e666",
          "type": "SPAN",
          "name": "error_60_psg_failure_signal_py_sketch_generator",
          "startTime": "2025-12-11T05:53:18.519000+00:00",
          "level": "ERROR",
          "statusMessage": "Failed. Last error: Max retries reached with failure. Last error from execution: Traceback (most recent call last):\n  File \"/home/wuguangh/Projects/03.12/tinyml-autopilot-pm.03.12.2025/results/object_detection/sketches/tmp_20251211075318_psg_phi4:latest/tmp_20251211075318_psg_phi4:latest.py\", line 86, in <module>\n    main()\n  File \"/home/wuguangh/Projects/03.12/tinyml-autopilot-pm.03.12.2025/results/object_detection/sketches/tmp_20251211075318_psg_phi4:latest/tmp_20251211075318_psg_phi4:latest.py\", line 58, in main\n    labels = load_labels(label_path)\n  File \"/home/wuguangh/Projects/03.12/tinyml-autopilot-pm.03.12.2025/results/object_detection/sketches/tmp_20251211075318_psg_phi4:latest/tmp_20251211075318_psg_phi4:latest.py\", line 15, in load_labels\n    return {i.strip(): line.strip() for i, line in enumerate(file.readlines())}\n  File \"/home/wuguangh/Projects/03.12/tinyml-autopilot-pm.03.12.2025/results/object_detection/sketches/tmp_20251211075318_psg_phi4:latest/tmp_20251211075318_psg_phi4:latest.py\", line 15, in <dictcomp>\n    return {i.strip(): line.strip() for i, line in enumerate(file.readlines())}\nAttributeError: 'int' object has no attribute 'strip'\n",
          "calculatedTotalCost": 0.0,
          "promptTokens": 0,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 0,
          "totalTokens": 0,
          "endTime": null,
          "model": null,
          "modelParameters": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null,
          "latency": null
        }
      ],
      "createdAt": "2025-12-11T05:51:53.887Z",
      "updatedAt": "2025-12-11T05:53:23.985Z",
      "environment": "default"
    },
    {
      "id": "93dd20ef",
      "timestamp": "2025-12-11T05:50:06.265000+00:00",
      "name": "93dd_py_sketch_generator",
      "input": null,
      "output": {
        "status": "failed",
        "last_code": "import cv2\nimport numpy as np\nimport tensorflow as tf\n\n# Configuration parameters\nmodel_path = 'models/ssd-mobilenet_v1/detect.tflite'\nlabel_path = 'models/ssd-mobilenet_v1/labelmap.txt'\ninput_path = 'data/object_detection/sheeps.mp4'\noutput_path = 'results/object_detection/test_results/sheeps_detections.mp4'\nconfidence_threshold = 0.5\n\n# Phase 1: Setup\ndef load_labels(label_file):\n    with open(label_file, 'r', encoding='utf-8') as file:\n        return [line.strip() for line in file.readlines()]\n\ndef load_interpreter(model_path):\n    interpreter = tf.lite.Interpreter(model_path=model_path)\n    interpreter.allocate_tensors()\n    return interpreter\n\n# Phase 2: Preprocessing\ndef preprocess_frame(frame, input_size):\n    frame_resized = cv2.resize(frame, input_size)\n    input_data = np.expand_dims(frame_resized, axis=0).astype(np.float32)\n    return input_data\n\n# Phase 3: Inference\ndef run_inference(interpreter, input_data):\n    input_details = interpreter.get_input_details()\n    output_details = interpreter.get_output_details()\n\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n\n    interpreter.invoke()\n\n    boxes = interpreter.get_tensor(output_details[0]['index'])[0]  # Bounding box coordinates of detected objects\n    classes = interpreter.get_tensor(output_details[1]['index'])[0]  # Class index of detected objects\n    scores = interpreter.get_tensor(output_details[2]['index'])[0]  # Confidence of detected objects\n\n    return boxes, classes, scores\n\n# Phase 4: Output handling\ndef draw_detections(frame, boxes, classes, scores, labels):\n    for i in range(len(scores)):\n        if scores[i] > confidence_threshold:\n            ymin, xmin, ymax, xmax = boxes[i]\n            (left, right, top, bottom) = (xmin * frame.shape[1], xmax * frame.shape[1],\n                                          ymin * frame.shape[0], ymax * frame.shape[0])\n            cv2.rectangle(frame, (int(left), int(top)), (int(right), int(bottom)), (10, 255, 0), 2)\n            label = f'{labels[int(classes[i])]}: {int(scores[i]*100)}%'\n            cv2.putText(frame, label, (int(left), int(top)-10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)\n\ndef compute_map(ground_truths, predictions):\n    # Placeholder for mAP computation logic\n    pass\n\n# Main execution\nif __name__ == '__main__':\n    labels = load_labels(label_path)\n    interpreter = load_interpreter(model_path)\n    input_details = interpreter.get_input_details()\n    input_size = tuple(input_details[0]['shape'][1:3])\n\n    cap = cv2.VideoCapture(input_path)\n    out = None\n\n    while cap.isOpened():\n        ret, frame = cap.read()\n        if not ret:\n            break\n        \n        input_data = preprocess_frame(frame, input_size)\n\n        boxes, classes, scores = run_inference(interpreter, input_data)\n\n        draw_detections(frame, boxes, classes, scores, labels)\n\n        if out is None:\n            fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n            out = cv2.VideoWriter(output_path, fourcc, 20.0, (frame.shape[1], frame.shape[0]))\n\n        out.write(frame)\n\n    cap.release()\n    if out is not None:\n        out.release()\n\n    # Placeholder for mAP computation\n    compute_map([], [])",
        "last_error": "Max retries reached with failure. Last error from execution: 2025-12-11 07:51:24.331797: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n2025-12-11 07:51:24.335393: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n2025-12-11 07:51:24.346940: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2025-12-11 07:51:24.365622: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2025-12-11 07:51:24.371273: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n2025-12-11 07:51:24.385327: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\nTo enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n2025-12-11 07:51:25.219229: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\nINFO: Created TensorFlow Lite XNNPACK delegate for CPU.\nTraceback (most recent call last):\n  File \"/home/wuguangh/Projects/03.12/tinyml-autopilot-pm.03.12.2025/results/object_detection/sketches/tmp_20251211075124_psg_phi4:latest/tmp_20251211075124_psg_phi4:latest.py\", line 75, in <module>\n    boxes, classes, scores = run_inference(interpreter, input_data)\n  File \"/home/wuguangh/Projects/03.12/tinyml-autopilot-pm.03.12.2025/results/object_detection/sketches/tmp_20251211075124_psg_phi4:latest/tmp_20251211075124_psg_phi4:latest.py\", line 33, in run_inference\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n  File \"/home/wuguangh/.conda/envs/tinyml/lib/python3.10/site-packages/tensorflow/lite/python/interpreter.py\", line 732, in set_tensor\n    self._interpreter.SetTensor(tensor_index, value)\nValueError: Cannot set tensor: Got value of type FLOAT32 but expected type UINT8 for input 175, name: normalized_input_image_tensor \n"
      },
      "session_id": "phi4_a8a2_psg_batch",
      "metadata": {
        "num_run": 10
      },
      "tags": [
        "ablation",
        "benchmark",
        "phi4:latest",
        "py_sketch_generator"
      ],
      "latency": 81.07,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-07-50-06-266933_chatcmpl-24366c1b-c89a-4822-8105-70eb75fb22b8",
          "traceId": "93dd20ef",
          "type": "GENERATION",
          "name": "93dd_psg_gen_attempt#1",
          "startTime": "2025-12-11T05:50:06.266000+00:00",
          "endTime": "2025-12-11T05:50:19.266000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 13000.0,
          "promptTokens": 245,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 713,
          "totalTokens": 958,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-07-50-19-436792_chatcmpl-13b5ed3e-38f8-4261-aa9b-c32890ac18d6",
          "traceId": "93dd20ef",
          "type": "GENERATION",
          "name": "93dd_psg_gen_attempt#2",
          "startTime": "2025-12-11T05:50:19.436000+00:00",
          "endTime": "2025-12-11T05:50:33.567000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 14131.0,
          "promptTokens": 245,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 778,
          "totalTokens": 1023,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-07-50-33-700133_chatcmpl-dc7fdea6-9024-4f04-a336-575514edcf04",
          "traceId": "93dd20ef",
          "type": "GENERATION",
          "name": "93dd_psg_gen_attempt#3",
          "startTime": "2025-12-11T05:50:33.700000+00:00",
          "endTime": "2025-12-11T05:50:47.010000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 13310.0,
          "promptTokens": 245,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 733,
          "totalTokens": 978,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-07-50-50-444540_chatcmpl-c7d03c85-b8d8-4a89-bc9c-f261ed98c743",
          "traceId": "93dd20ef",
          "type": "GENERATION",
          "name": "93dd_psg_gen_attempt#4",
          "startTime": "2025-12-11T05:50:50.444000+00:00",
          "endTime": "2025-12-11T05:51:05.406000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 14962.0,
          "promptTokens": 245,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 824,
          "totalTokens": 1069,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-07-51-08-788281_chatcmpl-89fe3b54-83bf-4e98-a82b-f3673e1d1779",
          "traceId": "93dd20ef",
          "type": "GENERATION",
          "name": "93dd_psg_gen_attempt#5",
          "startTime": "2025-12-11T05:51:08.788000+00:00",
          "endTime": "2025-12-11T05:51:24.003000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 15215.0,
          "promptTokens": 245,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 837,
          "totalTokens": 1082,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "fd32a20d-201b-42cc-9ab4-c0508f591f28",
          "traceId": "93dd20ef",
          "type": "SPAN",
          "name": "error_93_psg_failure_signal_py_sketch_generator",
          "startTime": "2025-12-11T05:51:27.336000+00:00",
          "level": "ERROR",
          "statusMessage": "Failed. Last error: Max retries reached with failure. Last error from execution: 2025-12-11 07:51:24.331797: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n2025-12-11 07:51:24.335393: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n2025-12-11 07:51:24.346940: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2025-12-11 07:51:24.365622: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2025-12-11 07:51:24.371273: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n2025-12-11 07:51:24.385327: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\nTo enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n2025-12-11 07:51:25.219229: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\nINFO: Created TensorFlow Lite XNNPACK delegate for CPU.\nTraceback (most recent call last):\n  File \"/home/wuguangh/Projects/03.12/tinyml-autopilot-pm.03.12.2025/results/object_detection/sketches/tmp_20251211075124_psg_phi4:latest/tmp_20251211075124_psg_phi4:latest.py\", line 75, in <module>\n    boxes, classes, scores = run_inference(interpreter, input_data)\n  File \"/home/wuguangh/Projects/03.12/tinyml-autopilot-pm.03.12.2025/results/object_detection/sketches/tmp_20251211075124_psg_phi4:latest/tmp_20251211075124_psg_phi4:latest.py\", line 33, in run_inference\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n  File \"/home/wuguangh/.conda/envs/tinyml/lib/python3.10/site-packages/tensorflow/lite/python/interpreter.py\", line 732, in set_tensor\n    self._interpreter.SetTensor(tensor_index, value)\nValueError: Cannot set tensor: Got value of type FLOAT32 but expected type UINT8 for input 175, name: normalized_input_image_tensor \n",
          "calculatedTotalCost": 0.0,
          "promptTokens": 0,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 0,
          "totalTokens": 0,
          "endTime": null,
          "model": null,
          "modelParameters": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null,
          "latency": null
        }
      ],
      "createdAt": "2025-12-11T05:50:06.780Z",
      "updatedAt": "2025-12-11T05:51:32.960Z",
      "environment": "default"
    },
    {
      "id": "7ec2d68e",
      "timestamp": "2025-12-11T05:48:04.027000+00:00",
      "name": "7ec2_py_sketch_generator",
      "input": null,
      "output": {
        "status": "failed",
        "last_code": "import cv2\nimport numpy as np\nimport tensorflow as tf\nfrom sklearn.metrics import average_precision_score\n\ndef load_labels(label_path):\n    with open(label_path, 'r') as file:\n        labels = [line.strip() for line in file.readlines()]\n    return labels\n\ndef load_model(model_path):\n    interpreter = tf.lite.Interpreter(model_path=model_path)\n    interpreter.allocate_tensors()\n    input_details = interpreter.get_input_details()\n    output_details = interpreter.get_output_details()\n    return interpreter, input_details, output_details\n\ndef preprocess_frame(frame, input_size):\n    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n    frame_resized = cv2.resize(frame_rgb, (input_size[1], input_size[0]))\n    frame_normalized = frame_resized / 255.0\n    return np.expand_dims(frame_normalized, axis=0).astype(np.float32)\n\ndef draw_boxes(frame, boxes, classes, scores, labels, confidence_threshold):\n    for i in range(len(scores)):\n        if scores[i] >= confidence_threshold:\n            ymin, xmin, ymax, xmax = boxes[i]\n            (left, right, top, bottom) = (xmin * frame.shape[1], xmax * frame.shape[1],\n                                          ymin * frame.shape[0], ymax * frame.shape[0])\n            cv2.rectangle(frame, (int(left), int(top)), (int(right), int(bottom)), (0, 255, 0), 2)\n            label = f'{labels[int(classes[i])]}: {int(scores[i] * 100)}%'\n            cv2.putText(frame, label, (int(left), int(top - 10)), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 1)\n\ndef compute_map(ground_truths, predictions, labels):\n    all_aps = []\n    for i, label in enumerate(labels):\n        y_true = [int(gt[i] == label) for gt in ground_truths]\n        y_scores = [pred[i] for pred in predictions if len(pred) > i]\n        if y_true and y_scores:\n            ap = average_precision_score(y_true, y_scores)\n            all_aps.append(ap)\n    return np.mean(all_aps) if all_aps else 0.0\n\ndef main():\n    model_path = 'models/ssd-mobilenet_v1/detect.tflite'\n    label_path = 'models/ssd-mobilenet_v1/labelmap.txt'\n    input_path = 'data/object_detection/sheeps.mp4'\n    output_path = 'results/object_detection/test_results/sheeps_detections.mp4'\n    confidence_threshold = 0.5\n\n    labels = load_labels(label_path)\n    interpreter, input_details, output_details = load_model(model_path)\n\n    cap = cv2.VideoCapture(input_path)\n    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n    out = cv2.VideoWriter(output_path, fourcc, 20.0, (int(cap.get(3)), int(cap.get(4))))\n\n    input_size = input_details[0]['shape'][1:3]\n    ground_truths = []  # This would be populated with actual ground truth data\n    predictions = []\n\n    while cap.isOpened():\n        ret, frame = cap.read()\n        if not ret:\n            break\n\n        processed_frame = preprocess_frame(frame, input_size)\n        interpreter.set_tensor(input_details[0]['index'], processed_frame)\n        interpreter.invoke()\n\n        boxes = interpreter.get_tensor(output_details[0]['index'])[0]  # Bounding box coordinates\n        classes = interpreter.get_tensor(output_details[1]['index'])[0]  # Class index\n        scores = interpreter.get_tensor(output_details[2]['index'])[0]  # Confidence score\n\n        draw_boxes(frame, boxes, classes, scores, labels, confidence_threshold)\n\n        out.write(frame)\n\n        predictions.append(scores)\n        ground_truths.append(classes)  # This should be actual ground truth data for mAP calculation\n\n    cap.release()\n    out.release()\n\n    mean_average_precision = compute_map(ground_truths, predictions, labels)\n    print(f\"Mean Average Precision: {mean_average_precision}\")\n\nif __name__ == \"__main__\":\n    main()",
        "last_error": "Max retries reached with failure. Last error from execution: 2025-12-11 07:49:36.845826: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n2025-12-11 07:49:36.849424: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n2025-12-11 07:49:36.860997: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2025-12-11 07:49:36.879584: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2025-12-11 07:49:36.885277: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n2025-12-11 07:49:36.899296: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\nTo enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n2025-12-11 07:49:37.723864: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\nINFO: Created TensorFlow Lite XNNPACK delegate for CPU.\nTraceback (most recent call last):\n  File \"/home/wuguangh/Projects/03.12/tinyml-autopilot-pm.03.12.2025/results/object_detection/sketches/tmp_20251211074936_psg_phi4:latest/tmp_20251211074936_psg_phi4:latest.py\", line 89, in <module>\n    main()\n  File \"/home/wuguangh/Projects/03.12/tinyml-autopilot-pm.03.12.2025/results/object_detection/sketches/tmp_20251211074936_psg_phi4:latest/tmp_20251211074936_psg_phi4:latest.py\", line 68, in main\n    interpreter.set_tensor(input_details[0]['index'], processed_frame)\n  File \"/home/wuguangh/.conda/envs/tinyml/lib/python3.10/site-packages/tensorflow/lite/python/interpreter.py\", line 732, in set_tensor\n    self._interpreter.SetTensor(tensor_index, value)\nValueError: Cannot set tensor: Got value of type FLOAT32 but expected type UINT8 for input 175, name: normalized_input_image_tensor \n"
      },
      "session_id": "phi4_a8a2_psg_batch",
      "metadata": {
        "num_run": 9
      },
      "tags": [
        "ablation",
        "benchmark",
        "phi4:latest",
        "py_sketch_generator"
      ],
      "latency": 96.284,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-07-48-04-029323_chatcmpl-241b7cb0-625a-4569-8095-6c1ba8a59ad2",
          "traceId": "7ec2d68e",
          "type": "GENERATION",
          "name": "7ec2_psg_gen_attempt#1",
          "startTime": "2025-12-11T05:48:04.029000+00:00",
          "endTime": "2025-12-11T05:48:20.431000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 16402.0,
          "promptTokens": 245,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 898,
          "totalTokens": 1143,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-07-48-23-935588_chatcmpl-1c785d0c-594c-44c7-9688-ec83f4ae79eb",
          "traceId": "7ec2d68e",
          "type": "GENERATION",
          "name": "7ec2_psg_gen_attempt#2",
          "startTime": "2025-12-11T05:48:23.935000+00:00",
          "endTime": "2025-12-11T05:48:39.531000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 15596.0,
          "promptTokens": 245,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 858,
          "totalTokens": 1103,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-07-48-43-015657_chatcmpl-9b7ccd70-5c3b-4903-aed3-fdb60090571a",
          "traceId": "7ec2d68e",
          "type": "GENERATION",
          "name": "7ec2_psg_gen_attempt#3",
          "startTime": "2025-12-11T05:48:43.015000+00:00",
          "endTime": "2025-12-11T05:48:56.700000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 13685.0,
          "promptTokens": 245,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 753,
          "totalTokens": 998,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-07-49-00-357653_chatcmpl-491d8e21-02b1-44f2-8a2d-2a0e13cbea76",
          "traceId": "7ec2d68e",
          "type": "GENERATION",
          "name": "7ec2_psg_gen_attempt#4",
          "startTime": "2025-12-11T05:49:00.357000+00:00",
          "endTime": "2025-12-11T05:49:15.872000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 15515.0,
          "promptTokens": 245,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 853,
          "totalTokens": 1098,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-07-49-19-225303_chatcmpl-f2613708-7200-4da5-8574-deb4fa645e48",
          "traceId": "7ec2d68e",
          "type": "GENERATION",
          "name": "7ec2_psg_gen_attempt#5",
          "startTime": "2025-12-11T05:49:19.225000+00:00",
          "endTime": "2025-12-11T05:49:36.503000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 17278.0,
          "promptTokens": 245,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 949,
          "totalTokens": 1194,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "bf3ad85b-edd8-4e80-911e-ce396685ef91",
          "traceId": "7ec2d68e",
          "type": "SPAN",
          "name": "error_7e_psg_failure_signal_py_sketch_generator",
          "startTime": "2025-12-11T05:49:40.313000+00:00",
          "level": "ERROR",
          "statusMessage": "Failed. Last error: Max retries reached with failure. Last error from execution: 2025-12-11 07:49:36.845826: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n2025-12-11 07:49:36.849424: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n2025-12-11 07:49:36.860997: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2025-12-11 07:49:36.879584: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2025-12-11 07:49:36.885277: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n2025-12-11 07:49:36.899296: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\nTo enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n2025-12-11 07:49:37.723864: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\nINFO: Created TensorFlow Lite XNNPACK delegate for CPU.\nTraceback (most recent call last):\n  File \"/home/wuguangh/Projects/03.12/tinyml-autopilot-pm.03.12.2025/results/object_detection/sketches/tmp_20251211074936_psg_phi4:latest/tmp_20251211074936_psg_phi4:latest.py\", line 89, in <module>\n    main()\n  File \"/home/wuguangh/Projects/03.12/tinyml-autopilot-pm.03.12.2025/results/object_detection/sketches/tmp_20251211074936_psg_phi4:latest/tmp_20251211074936_psg_phi4:latest.py\", line 68, in main\n    interpreter.set_tensor(input_details[0]['index'], processed_frame)\n  File \"/home/wuguangh/.conda/envs/tinyml/lib/python3.10/site-packages/tensorflow/lite/python/interpreter.py\", line 732, in set_tensor\n    self._interpreter.SetTensor(tensor_index, value)\nValueError: Cannot set tensor: Got value of type FLOAT32 but expected type UINT8 for input 175, name: normalized_input_image_tensor \n",
          "calculatedTotalCost": 0.0,
          "promptTokens": 0,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 0,
          "totalTokens": 0,
          "endTime": null,
          "model": null,
          "modelParameters": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null,
          "latency": null
        }
      ],
      "createdAt": "2025-12-11T05:48:04.543Z",
      "updatedAt": "2025-12-11T05:49:45.672Z",
      "environment": "default"
    },
    {
      "id": "df02c19b",
      "timestamp": "2025-12-11T05:46:14.705000+00:00",
      "name": "df02_py_sketch_generator",
      "input": null,
      "output": {
        "status": "failed",
        "last_code": "import cv2\nimport numpy as np\nimport tensorflow as tf\n\n# Configuration parameters\nmodel_path = 'models/ssd-mobilenet_v1/detect.tflite'\nlabel_path = 'models/ssd-mobilenet_v1/labelmap.txt'\ninput_path = 'data/object_detection/sheeps.mp4'\noutput_path = 'results/object_detection/test_results/sheeps_detections.mp4'\nconfidence_threshold = 0.5\n\n# Setup\ndef load_labels(label_path):\n    with open(label_path, 'r') as file:\n        labels = [line.strip() for line in file.readlines()]\n    return labels\n\ndef load_interpreter(model_path):\n    interpreter = tf.lite.Interpreter(model_path=model_path)\n    interpreter.allocate_tensors()\n    input_details = interpreter.get_input_details()\n    output_details = interpreter.get_output_details()\n    return interpreter, input_details, output_details\n\n# Preprocessing\ndef preprocess_frame(frame, input_size):\n    frame_resized = cv2.resize(frame, (input_size[1], input_size[0]))\n    input_data = np.expand_dims(frame_resized, axis=0)\n    return input_data\n\n# Inference\ndef run_inference(interpreter, input_data):\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n    interpreter.invoke()\n    boxes = interpreter.get_tensor(output_details[0]['index'])[0]\n    classes = interpreter.get_tensor(output_details[1]['index'])[0]\n    scores = interpreter.get_tensor(output_details[2]['index'])[0]\n    return boxes, classes, scores\n\n# Output handling\ndef draw_boxes(frame, boxes, classes, scores, labels):\n    for i in range(len(scores)):\n        if scores[i] > confidence_threshold:\n            ymin, xmin, ymax, xmax = boxes[i]\n            (left, right, top, bottom) = (xmin * frame.shape[1], xmax * frame.shape[1],\n                                          ymin * frame.shape[0], ymax * frame.shape[0])\n            cv2.rectangle(frame, (int(left), int(top)), (int(right), int(bottom)), (255, 0, 0), 2)\n            label = f\"{labels[int(classes[i])]}: {scores[i]:.2f}\"\n            cv2.putText(frame, label, (int(left), int(top) - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 1)\n\ndef main():\n    labels = load_labels(label_path)\n    interpreter, input_details, output_details = load_interpreter(model_path)\n    \n    cap = cv2.VideoCapture(input_path)\n    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n    out = cv2.VideoWriter(output_path, fourcc, 20.0, (int(cap.get(3)), int(cap.get(4))))\n    \n    while cap.isOpened():\n        ret, frame = cap.read()\n        if not ret:\n            break\n        \n        input_data = preprocess_frame(frame, input_details[0]['shape'][1:3])\n        boxes, classes, scores = run_inference(interpreter, input_data)\n        \n        draw_boxes(frame, boxes, classes, scores, labels)\n        \n        out.write(frame)\n    \n    cap.release()\n    out.release()\n\nif __name__ == \"__main__\":\n    main()",
        "last_error": "Max retries reached with failure. Last error from execution: 2025-12-11 07:47:35.101495: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n2025-12-11 07:47:35.105017: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n2025-12-11 07:47:35.116674: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2025-12-11 07:47:35.135398: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2025-12-11 07:47:35.141082: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n2025-12-11 07:47:35.154558: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\nTo enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n2025-12-11 07:47:35.987773: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\nINFO: Created TensorFlow Lite XNNPACK delegate for CPU.\nTraceback (most recent call last):\n  File \"/home/wuguangh/Projects/03.12/tinyml-autopilot-pm.03.12.2025/results/object_detection/sketches/tmp_20251211074734_psg_phi4:latest/tmp_20251211074734_psg_phi4:latest.py\", line 75, in <module>\n    main()\n  File \"/home/wuguangh/Projects/03.12/tinyml-autopilot-pm.03.12.2025/results/object_detection/sketches/tmp_20251211074734_psg_phi4:latest/tmp_20251211074734_psg_phi4:latest.py\", line 65, in main\n    boxes, classes, scores = run_inference(interpreter, input_data)\n  File \"/home/wuguangh/Projects/03.12/tinyml-autopilot-pm.03.12.2025/results/object_detection/sketches/tmp_20251211074734_psg_phi4:latest/tmp_20251211074734_psg_phi4:latest.py\", line 33, in run_inference\n    interpreter.set_tensor(input_details[0]['index'], input_data)\nNameError: name 'input_details' is not defined. Did you mean: 'input_data'?\n"
      },
      "session_id": "phi4_a8a2_psg_batch",
      "metadata": {
        "num_run": 8
      },
      "tags": [
        "ablation",
        "benchmark",
        "phi4:latest",
        "py_sketch_generator"
      ],
      "latency": 83.146,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-07-46-14-707078_chatcmpl-b38cf044-1df4-4986-896b-5761a7ae7a7d",
          "traceId": "df02c19b",
          "type": "GENERATION",
          "name": "df02_psg_gen_attempt#1",
          "startTime": "2025-12-11T05:46:14.707000+00:00",
          "endTime": "2025-12-11T05:46:31.087000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 16380.0,
          "promptTokens": 245,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 897,
          "totalTokens": 1142,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-07-46-31-435534_chatcmpl-a16fc46f-437b-4e65-8ab3-78d47f6e4a87",
          "traceId": "df02c19b",
          "type": "GENERATION",
          "name": "df02_psg_gen_attempt#2",
          "startTime": "2025-12-11T05:46:31.435000+00:00",
          "endTime": "2025-12-11T05:46:48.411000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 16976.0,
          "promptTokens": 245,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 933,
          "totalTokens": 1178,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-07-46-48-753177_chatcmpl-66dbeaed-14eb-4c50-abc2-2efd234168f7",
          "traceId": "df02c19b",
          "type": "GENERATION",
          "name": "df02_psg_gen_attempt#3",
          "startTime": "2025-12-11T05:46:48.753000+00:00",
          "endTime": "2025-12-11T05:47:01.965000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 13212.0,
          "promptTokens": 245,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 728,
          "totalTokens": 973,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-07-47-04-938713_chatcmpl-007d1510-59d6-4a45-9ae2-05015bb04316",
          "traceId": "df02c19b",
          "type": "GENERATION",
          "name": "df02_psg_gen_attempt#4",
          "startTime": "2025-12-11T05:47:04.938000+00:00",
          "endTime": "2025-12-11T05:47:20.864000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 15926.0,
          "promptTokens": 245,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 875,
          "totalTokens": 1120,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-07-47-21-037511_chatcmpl-e454ebe8-3135-4002-9367-be5339526bae",
          "traceId": "df02c19b",
          "type": "GENERATION",
          "name": "df02_psg_gen_attempt#5",
          "startTime": "2025-12-11T05:47:21.037000+00:00",
          "endTime": "2025-12-11T05:47:34.762000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 13725.0,
          "promptTokens": 245,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 756,
          "totalTokens": 1001,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "18b69012-af48-4b00-8569-f76b03855a3c",
          "traceId": "df02c19b",
          "type": "SPAN",
          "name": "error_df_psg_failure_signal_py_sketch_generator",
          "startTime": "2025-12-11T05:47:37.853000+00:00",
          "level": "ERROR",
          "statusMessage": "Failed. Last error: Max retries reached with failure. Last error from execution: 2025-12-11 07:47:35.101495: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n2025-12-11 07:47:35.105017: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n2025-12-11 07:47:35.116674: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2025-12-11 07:47:35.135398: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2025-12-11 07:47:35.141082: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n2025-12-11 07:47:35.154558: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\nTo enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n2025-12-11 07:47:35.987773: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\nINFO: Created TensorFlow Lite XNNPACK delegate for CPU.\nTraceback (most recent call last):\n  File \"/home/wuguangh/Projects/03.12/tinyml-autopilot-pm.03.12.2025/results/object_detection/sketches/tmp_20251211074734_psg_phi4:latest/tmp_20251211074734_psg_phi4:latest.py\", line 75, in <module>\n    main()\n  File \"/home/wuguangh/Projects/03.12/tinyml-autopilot-pm.03.12.2025/results/object_detection/sketches/tmp_20251211074734_psg_phi4:latest/tmp_20251211074734_psg_phi4:latest.py\", line 65, in main\n    boxes, classes, scores = run_inference(interpreter, input_data)\n  File \"/home/wuguangh/Projects/03.12/tinyml-autopilot-pm.03.12.2025/results/object_detection/sketches/tmp_20251211074734_psg_phi4:latest/tmp_20251211074734_psg_phi4:latest.py\", line 33, in run_inference\n    interpreter.set_tensor(input_details[0]['index'], input_data)\nNameError: name 'input_details' is not defined. Did you mean: 'input_data'?\n",
          "calculatedTotalCost": 0.0,
          "promptTokens": 0,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 0,
          "totalTokens": 0,
          "endTime": null,
          "model": null,
          "modelParameters": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null,
          "latency": null
        }
      ],
      "createdAt": "2025-12-11T05:46:15.223Z",
      "updatedAt": "2025-12-11T05:47:43.421Z",
      "environment": "default"
    },
    {
      "id": "3defce52",
      "timestamp": "2025-12-11T05:44:09.737000+00:00",
      "name": "3def_py_sketch_generator",
      "input": null,
      "output": {
        "status": "success",
        "sketch": "import cv2\nfrom tflite_runtime.interpreter import Interpreter\nimport numpy as np\n\n# Configuration parameters\nmodel_path = 'models/ssd-mobilenet_v1/detect.tflite'\nlabel_path = 'models/ssd-mobilenet_v1/labelmap.txt'\ninput_path = 'data/object_detection/sheeps.mp4'\noutput_path = 'results/object_detection/test_results/sheeps_detections.mp4'\nconfidence_threshold = 0.5\n\n# Phase 1: Setup\ndef load_labels(path):\n    with open(path, 'r', encoding='utf-8') as f:\n        return {i: line.strip() for i, line in enumerate(f.readlines())}\n\nlabels = load_labels(label_path)\n\ninterpreter = Interpreter(model_path=model_path)\ninterpreter.allocate_tensors()\n\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\n\ninput_shape = input_details[0]['shape']\nheight, width = input_shape[1], input_shape[2]\n\n# Phase 2: Preprocessing\ndef preprocess_frame(frame):\n    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n    frame_resized = cv2.resize(frame_rgb, (width, height))\n    input_data = np.expand_dims(frame_resized, axis=0)\n    return input_data\n\n# Phase 3: Inference\ndef run_inference(frame):\n    interpreter.set_tensor(input_details[0]['index'], frame)\n    interpreter.invoke()\n\n    boxes = interpreter.get_tensor(output_details[0]['index'])[0]\n    classes = interpreter.get_tensor(output_details[1]['index'])[0]\n    scores = interpreter.get_tensor(output_details[2]['index'])[0]\n\n    results = []\n    for i in range(len(scores)):\n        if scores[i] >= confidence_threshold:\n            ymin, xmin, ymax, xmax = boxes[i]\n            (left, right, top, bottom) = (xmin * frame.shape[1], xmax * frame.shape[1],\n                                          ymin * frame.shape[0], ymax * frame.shape[0])\n            results.append((int(left), int(right), int(top), int(bottom),\n                            scores[i], labels[int(classes[i])]))\n    return results\n\n# Phase 4: Output Handling\ndef draw_boxes(frame, results):\n    for (left, right, top, bottom, score, label) in results:\n        cv2.rectangle(frame, (left, top), (right, bottom), (0, 255, 0), 2)\n        text = f\"{label}: {score:.2f}\"\n        cv2.putText(frame, text, (left, top - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 1)\n\ndef compute_map(results):\n    # Placeholder for mAP computation logic\n    return \"mAP computation not implemented\"\n\n# Main processing loop\ncap = cv2.VideoCapture(input_path)\nfourcc = cv2.VideoWriter_fourcc(*'mp4v')\nout = cv2.VideoWriter(output_path, fourcc, 20.0, (int(cap.get(3)), int(cap.get(4))))\n\nwhile cap.isOpened():\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    input_data = preprocess_frame(frame)\n    results = run_inference(input_data)\n\n    draw_boxes(frame, results)\n    map_score = compute_map(results)  # Placeholder for mAP calculation\n    print(f\"mAP: {map_score}\")\n\n    out.write(frame)\n\ncap.release()\nout.release()\n\nprint(\"Processing complete. Output saved to:\", output_path)"
      },
      "session_id": "phi4_a8a2_psg_batch",
      "metadata": {
        "num_run": 7
      },
      "tags": [
        "ablation",
        "benchmark",
        "phi4:latest",
        "py_sketch_generator"
      ],
      "latency": 65.343,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-07-44-09-738320_chatcmpl-d8e6ebde-fda5-43b6-8e5d-cb4b0ebdf288",
          "traceId": "3defce52",
          "type": "GENERATION",
          "name": "3def_psg_gen_attempt#1",
          "startTime": "2025-12-11T05:44:09.738000+00:00",
          "endTime": "2025-12-11T05:44:25.771000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 16033.0,
          "promptTokens": 245,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 877,
          "totalTokens": 1122,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-07-44-25-898350_chatcmpl-1cbf0f26-2d4f-4cfd-83e7-c8ef9a47064a",
          "traceId": "3defce52",
          "type": "GENERATION",
          "name": "3def_psg_gen_attempt#2",
          "startTime": "2025-12-11T05:44:25.898000+00:00",
          "endTime": "2025-12-11T05:44:42.907000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 17009.0,
          "promptTokens": 245,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 935,
          "totalTokens": 1180,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-07-44-46-130611_chatcmpl-4108418e-32d4-4ad2-a7bf-7a4a335fe11d",
          "traceId": "3defce52",
          "type": "GENERATION",
          "name": "3def_psg_gen_attempt#3",
          "startTime": "2025-12-11T05:44:46.130000+00:00",
          "endTime": "2025-12-11T05:45:00.549000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 14419.0,
          "promptTokens": 245,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 793,
          "totalTokens": 1038,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-07-45-00-685348_chatcmpl-fc844e5b-6d03-4c18-a1e9-37b4aaa8157b",
          "traceId": "3defce52",
          "type": "GENERATION",
          "name": "3def_psg_gen_attempt#4",
          "startTime": "2025-12-11T05:45:00.685000+00:00",
          "endTime": "2025-12-11T05:45:15.081000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 14396.0,
          "promptTokens": 245,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 792,
          "totalTokens": 1037,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        }
      ],
      "createdAt": "2025-12-11T05:44:10.254Z",
      "updatedAt": "2025-12-11T05:45:54.923Z",
      "environment": "default"
    },
    {
      "id": "034efb08",
      "timestamp": "2025-12-11T05:42:04.435000+00:00",
      "name": "034e_py_sketch_generator",
      "input": null,
      "output": {
        "status": "success",
        "sketch": "import cv2\nfrom tflite_runtime.interpreter import Interpreter\nimport numpy as np\nimport time\n\n# Configuration parameters\nmodel_path = 'models/ssd-mobilenet_v1/detect.tflite'\nlabel_path = 'models/ssd-mobilenet_v1/labelmap.txt'\ninput_path = 'data/object_detection/sheeps.mp4'\noutput_path = 'results/object_detection/test_results/sheeps_detections.mp4'\nconfidence_threshold = 0.5\n\n# Phase 1: Setup\ndef load_labels(label_file):\n    with open(label_file, 'r') as file:\n        return [line.strip() for line in file.readlines()]\n\ndef load_interpreter(model_path):\n    interpreter = Interpreter(model_path=model_path)\n    interpreter.allocate_tensors()\n    return interpreter\n\nlabels = load_labels(label_path)\ninterpreter = load_interpreter(model_path)\n\n# Get input and output details\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\n\ninput_shape = input_details[0]['shape']\nheight, width, channel = input_shape[1], input_shape[2], input_shape[3]\n\ndef set_input_tensor(interpreter, image):\n    tensor_index = input_details[0]['index']\n    input_tensor = interpreter.tensor(tensor_index)()[0]\n    input_tensor[:, :] = image\n\ndef get_output(interpreter):\n    boxes = interpreter.get_tensor(output_details[0]['index'])[0]  # Bounding box coordinates of detected objects\n    classes = interpreter.get_tensor(output_details[1]['index'])[0]  # Class index of detected objects\n    scores = interpreter.get_tensor(output_details[2]['index'])[0]  # Confidence of detected objects\n    return boxes, classes, scores\n\n# Phase 2: Preprocessing\ndef preprocess_frame(frame):\n    frame_resized = cv2.resize(frame, (width, height))\n    input_data = np.expand_dims(frame_resized, axis=0)\n    input_data = (np.float32(input_data) - 127.5) / 127.5\n    return input_data\n\n# Phase 3: Inference\ndef detect_objects(interpreter, image):\n    set_input_tensor(interpreter, image)\n    interpreter.invoke()\n    boxes, classes, scores = get_output(interpreter)\n    \n    results = []\n    for i in range(len(scores)):\n        if scores[i] >= confidence_threshold:\n            ymin, xmin, ymax, xmax = boxes[i]\n            (left, right, top, bottom) = (xmin * width, xmax * width, ymin * height, ymax * height)\n            \n            result = {\n                'bounding_box': [int(left), int(top), int(right), int(bottom)],\n                'class_id': classes[i],\n                'score': scores[i]\n            }\n            results.append(result)\n    return results\n\n# Phase 4: Output Handling\ndef draw_detections(frame, detections):\n    for detection in detections:\n        bbox = detection['bounding_box']\n        class_id = detection['class_id']\n        score = detection['score']\n\n        left, top, right, bottom = bbox\n        cv2.rectangle(frame, (left, top), (right, bottom), (0, 255, 0), 2)\n        \n        label = f'{labels[int(class_id)]}: {int(score * 100)}%'\n        cv2.putText(frame, label, (left, top - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n\n# Main pipeline\ndef main():\n    cap = cv2.VideoCapture(input_path)\n    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n    out = cv2.VideoWriter(output_path, fourcc, 30.0, (int(cap.get(3)), int(cap.get(4))))\n    \n    while cap.isOpened():\n        ret, frame = cap.read()\n        \n        if not ret:\n            break\n        \n        input_data = preprocess_frame(frame)\n        detections = detect_objects(interpreter, input_data[0])\n        draw_detections(frame, detections)\n\n        out.write(frame)\n        \n    cap.release()\n    out.release()\n\nif __name__ == '__main__':\n    main()"
      },
      "session_id": "phi4_a8a2_psg_batch",
      "metadata": {
        "num_run": 6
      },
      "tags": [
        "ablation",
        "benchmark",
        "phi4:latest",
        "py_sketch_generator"
      ],
      "latency": 65.785,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-07-42-04-436912_chatcmpl-ff1fd604-f4d5-4f13-bc0c-e5e080db1819",
          "traceId": "034efb08",
          "type": "GENERATION",
          "name": "034e_psg_gen_attempt#1",
          "startTime": "2025-12-11T05:42:04.436000+00:00",
          "endTime": "2025-12-11T05:42:20.514000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 16078.0,
          "promptTokens": 245,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 880,
          "totalTokens": 1125,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-07-42-20-665876_chatcmpl-93493fb8-f4e3-4466-b327-4fb169a1ef7e",
          "traceId": "034efb08",
          "type": "GENERATION",
          "name": "034e_psg_gen_attempt#2",
          "startTime": "2025-12-11T05:42:20.665000+00:00",
          "endTime": "2025-12-11T05:42:34.031000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 13366.0,
          "promptTokens": 245,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 736,
          "totalTokens": 981,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-07-42-37-053941_chatcmpl-e616126a-58f5-40b9-9080-4186bc1b1b6d",
          "traceId": "034efb08",
          "type": "GENERATION",
          "name": "034e_psg_gen_attempt#3",
          "startTime": "2025-12-11T05:42:37.053000+00:00",
          "endTime": "2025-12-11T05:42:51.470000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 14417.0,
          "promptTokens": 245,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 793,
          "totalTokens": 1038,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-07-42-54-451265_chatcmpl-cf5eed68-3d03-49ec-a896-8a086cc1f772",
          "traceId": "034efb08",
          "type": "GENERATION",
          "name": "034e_psg_gen_attempt#4",
          "startTime": "2025-12-11T05:42:54.451000+00:00",
          "endTime": "2025-12-11T05:43:10.221000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 15770.0,
          "promptTokens": 245,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 868,
          "totalTokens": 1113,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        }
      ],
      "createdAt": "2025-12-11T05:42:04.952Z",
      "updatedAt": "2025-12-11T05:43:49.161Z",
      "environment": "default"
    },
    {
      "id": "cbdff797",
      "timestamp": "2025-12-11T05:40:13.468000+00:00",
      "name": "cbdf_py_sketch_generator",
      "input": null,
      "output": {
        "status": "failed",
        "last_code": "import cv2\nimport numpy as np\nimport tensorflow as tf\n\n# Configuration parameters\nmodel_path = 'models/ssd-mobilenet_v1/detect.tflite'\nlabel_path = 'models/ssd-mobilenet_v1/labelmap.txt'\ninput_path = 'data/object_detection/sheeps.mp4'\noutput_path = 'results/object_detection/test_results/sheeps_detections.mp4'\nconfidence_threshold = 0.5\n\n# Phase 1: Setup\ndef load_labels(label_file):\n    with open(label_file, 'r') as file:\n        return [line.strip() for line in file.readlines()]\n\ndef load_interpreter(model_path):\n    interpreter = tf.lite.Interpreter(model_path=model_path)\n    interpreter.allocate_tensors()\n    return interpreter\n\n# Phase 2: Preprocessing\ndef preprocess_frame(frame, input_size):\n    frame_resized = cv2.resize(frame, (input_size[1], input_size[0]))\n    input_data = np.expand_dims(frame_resized, axis=0).astype(np.float32)\n    return input_data\n\n# Phase 3: Inference\ndef run_inference(interpreter, input_data):\n    input_details = interpreter.get_input_details()\n    output_details = interpreter.get_output_details()\n\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n\n    interpreter.invoke()\n\n    boxes = interpreter.get_tensor(output_details[0]['index'])[0]\n    classes = interpreter.get_tensor(output_details[1]['index'])[0]\n    scores = interpreter.get_tensor(output_details[2]['index'])[0]\n\n    return boxes, classes, scores\n\n# Phase 4: Output Handling\ndef draw_detections(frame, boxes, classes, scores, labels):\n    height, width, _ = frame.shape\n    for i in range(len(scores)):\n        if scores[i] > confidence_threshold:\n            ymin, xmin, ymax, xmax = boxes[i]\n            (left, right, top, bottom) = (xmin * width, xmax * width,\n                                          ymin * height, ymax * height)\n            cv2.rectangle(frame, (int(left), int(top)), (int(right), int(bottom)), (0, 255, 0), 2)\n\n            label = f\"{labels[int(classes[i])]}: {scores[i]:.2f}\"\n            cv2.putText(frame, label, (int(left), int(top - 5)), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n\ndef compute_mAP(boxes, classes, scores):\n    # Placeholder for mAP computation logic\n    return \"mAP calculation not implemented\"\n\n# Main execution pipeline\nif __name__ == \"__main__\":\n    labels = load_labels(label_path)\n    interpreter = load_interpreter(model_path)\n    \n    input_details = interpreter.get_input_details()\n    input_size = input_details[0]['shape'][1:3]\n    \n    cap = cv2.VideoCapture(input_path)\n    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n    out = cv2.VideoWriter(output_path, fourcc, 30.0, (int(cap.get(3)), int(cap.get(4))))\n\n    while cap.isOpened():\n        ret, frame = cap.read()\n        if not ret:\n            break\n        \n        input_data = preprocess_frame(frame, input_size)\n        boxes, classes, scores = run_inference(interpreter, input_data)\n        \n        draw_detections(frame, boxes, classes, scores, labels)\n        out.write(frame)\n\n    mAP_result = compute_mAP(boxes, classes, scores)\n    print(f\"mAP Result: {mAP_result}\")\n\n    cap.release()\n    out.release()\n    cv2.destroyAllWindows()",
        "last_error": "Max retries reached with failure. Last error from execution: 2025-12-11 07:41:36.554509: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n2025-12-11 07:41:36.557905: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n2025-12-11 07:41:36.569320: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2025-12-11 07:41:36.587551: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2025-12-11 07:41:36.592970: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n2025-12-11 07:41:36.606433: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\nTo enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n2025-12-11 07:41:37.396267: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\nINFO: Created TensorFlow Lite XNNPACK delegate for CPU.\nTraceback (most recent call last):\n  File \"/home/wuguangh/Projects/03.12/tinyml-autopilot-pm.03.12.2025/results/object_detection/sketches/tmp_20251211074136_psg_phi4:latest/tmp_20251211074136_psg_phi4:latest.py\", line 78, in <module>\n    boxes, classes, scores = run_inference(interpreter, input_data)\n  File \"/home/wuguangh/Projects/03.12/tinyml-autopilot-pm.03.12.2025/results/object_detection/sketches/tmp_20251211074136_psg_phi4:latest/tmp_20251211074136_psg_phi4:latest.py\", line 33, in run_inference\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n  File \"/home/wuguangh/.conda/envs/tinyml/lib/python3.10/site-packages/tensorflow/lite/python/interpreter.py\", line 732, in set_tensor\n    self._interpreter.SetTensor(tensor_index, value)\nValueError: Cannot set tensor: Got value of type FLOAT32 but expected type UINT8 for input 175, name: normalized_input_image_tensor \n"
      },
      "session_id": "phi4_a8a2_psg_batch",
      "metadata": {
        "num_run": 5
      },
      "tags": [
        "ablation",
        "benchmark",
        "phi4:latest",
        "py_sketch_generator"
      ],
      "latency": 85.765,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-07-40-13-469272_chatcmpl-341e2cdc-0be7-4d37-b3c5-d3805982949e",
          "traceId": "cbdff797",
          "type": "GENERATION",
          "name": "cbdf_psg_gen_attempt#1",
          "startTime": "2025-12-11T05:40:13.469000+00:00",
          "endTime": "2025-12-11T05:40:30.123000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 16654.0,
          "promptTokens": 245,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 911,
          "totalTokens": 1156,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-07-40-30-253120_chatcmpl-8537825a-b8c1-4400-8bfa-2bfbd8803e9b",
          "traceId": "cbdff797",
          "type": "GENERATION",
          "name": "cbdf_psg_gen_attempt#2",
          "startTime": "2025-12-11T05:40:30.253000+00:00",
          "endTime": "2025-12-11T05:40:43.639000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 13386.0,
          "promptTokens": 245,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 738,
          "totalTokens": 983,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-07-40-46-677248_chatcmpl-5c51bd52-e936-4011-81fd-1203fb870fb3",
          "traceId": "cbdff797",
          "type": "GENERATION",
          "name": "cbdf_psg_gen_attempt#3",
          "startTime": "2025-12-11T05:40:46.677000+00:00",
          "endTime": "2025-12-11T05:41:02.246000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 15569.0,
          "promptTokens": 245,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 856,
          "totalTokens": 1101,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-07-41-05-284365_chatcmpl-e5a73204-317a-4f3b-a450-cf9dda41469d",
          "traceId": "cbdff797",
          "type": "GENERATION",
          "name": "cbdf_psg_gen_attempt#4",
          "startTime": "2025-12-11T05:41:05.284000+00:00",
          "endTime": "2025-12-11T05:41:19.299000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 14015.0,
          "promptTokens": 245,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 772,
          "totalTokens": 1017,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-07-41-22-317218_chatcmpl-cb119aff-0fa3-49fe-a310-5ef8ef413621",
          "traceId": "cbdff797",
          "type": "GENERATION",
          "name": "cbdf_psg_gen_attempt#5",
          "startTime": "2025-12-11T05:41:22.317000+00:00",
          "endTime": "2025-12-11T05:41:36.222000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 13905.0,
          "promptTokens": 245,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 766,
          "totalTokens": 1011,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "e31ccf1b-ad58-4266-b571-583349e49992",
          "traceId": "cbdff797",
          "type": "SPAN",
          "name": "error_cb_psg_failure_signal_py_sketch_generator",
          "startTime": "2025-12-11T05:41:39.234000+00:00",
          "level": "ERROR",
          "statusMessage": "Failed. Last error: Max retries reached with failure. Last error from execution: 2025-12-11 07:41:36.554509: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n2025-12-11 07:41:36.557905: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n2025-12-11 07:41:36.569320: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2025-12-11 07:41:36.587551: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2025-12-11 07:41:36.592970: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n2025-12-11 07:41:36.606433: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\nTo enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n2025-12-11 07:41:37.396267: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\nINFO: Created TensorFlow Lite XNNPACK delegate for CPU.\nTraceback (most recent call last):\n  File \"/home/wuguangh/Projects/03.12/tinyml-autopilot-pm.03.12.2025/results/object_detection/sketches/tmp_20251211074136_psg_phi4:latest/tmp_20251211074136_psg_phi4:latest.py\", line 78, in <module>\n    boxes, classes, scores = run_inference(interpreter, input_data)\n  File \"/home/wuguangh/Projects/03.12/tinyml-autopilot-pm.03.12.2025/results/object_detection/sketches/tmp_20251211074136_psg_phi4:latest/tmp_20251211074136_psg_phi4:latest.py\", line 33, in run_inference\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n  File \"/home/wuguangh/.conda/envs/tinyml/lib/python3.10/site-packages/tensorflow/lite/python/interpreter.py\", line 732, in set_tensor\n    self._interpreter.SetTensor(tensor_index, value)\nValueError: Cannot set tensor: Got value of type FLOAT32 but expected type UINT8 for input 175, name: normalized_input_image_tensor \n",
          "calculatedTotalCost": 0.0,
          "promptTokens": 0,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 0,
          "totalTokens": 0,
          "endTime": null,
          "model": null,
          "modelParameters": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null,
          "latency": null
        }
      ],
      "createdAt": "2025-12-11T05:40:13.986Z",
      "updatedAt": "2025-12-11T05:41:44.609Z",
      "environment": "default"
    },
    {
      "id": "16b3a5ea",
      "timestamp": "2025-12-11T05:38:11.467000+00:00",
      "name": "16b3_py_sketch_generator",
      "input": null,
      "output": {
        "status": "failed",
        "last_code": "import cv2\nimport numpy as np\nimport tensorflow as tf\n\n# Configuration parameters\nmodel_path = 'models/ssd-mobilenet_v1/detect.tflite'\nlabel_path = 'models/ssd-mobilenet_v1/labelmap.txt'\ninput_path = 'data/object_detection/sheeps.mp4'\noutput_path = 'results/object_detection/test_results/sheeps_detections.mp4'\nconfidence_threshold = 0.5\n\n# Setup\ndef load_labels(label_file):\n    with open(label_file, 'r') as file:\n        labels = [line.strip() for line in file.readlines()]\n    return labels\n\ndef load_tflite_model(model_path):\n    interpreter = tf.lite.Interpreter(model_path=model_path)\n    interpreter.allocate_tensors()\n    input_details = interpreter.get_input_details()\n    output_details = interpreter.get_output_details()\n    return interpreter, input_details, output_details\n\n# Preprocessing\ndef preprocess_frame(frame, input_size):\n    frame_resized = cv2.resize(frame, (input_size[1], input_size[0]))\n    input_data = np.expand_dims(frame_resized, axis=0).astype(np.float32)\n    return input_data\n\n# Inference\ndef run_inference(interpreter, input_data):\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n    interpreter.invoke()\n    boxes = interpreter.get_tensor(output_details[0]['index'])[0]\n    classes = interpreter.get_tensor(output_details[1]['index'])[0]\n    scores = interpreter.get_tensor(output_details[2]['index'])[0]\n    return boxes, classes, scores\n\n# Output handling\ndef draw_detections(frame, boxes, classes, scores, labels, confidence_threshold):\n    height, width, _ = frame.shape\n    for i in range(len(scores)):\n        if scores[i] > confidence_threshold:\n            ymin, xmin, ymax, xmax = boxes[i]\n            (left, right, top, bottom) = (xmin * width, xmax * width,\n                                          ymin * height, ymax * height)\n            cv2.rectangle(frame, (int(left), int(top)), (int(right), int(bottom)),\n                          color=(0, 255, 0), thickness=2)\n            label = f'{labels[int(classes[i])]}: {scores[i]:.2f}'\n            cv2.putText(frame, label, (int(left), int(top - 10)),\n                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 1)\n\ndef compute_map(boxes, classes, scores, labels):\n    # Placeholder for mAP computation logic\n    return \"mAP: N/A\"\n\n# Main function\ndef main():\n    labels = load_labels(label_path)\n    interpreter, input_details, output_details = load_tflite_model(model_path)\n    \n    cap = cv2.VideoCapture(input_path)\n    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n    out = cv2.VideoWriter(output_path, fourcc, 20.0, (int(cap.get(3)), int(cap.get(4))))\n    \n    while cap.isOpened():\n        ret, frame = cap.read()\n        if not ret:\n            break\n        \n        input_data = preprocess_frame(frame, input_details[0]['shape'][1:3])\n        boxes, classes, scores = run_inference(interpreter, input_data)\n        \n        draw_detections(frame, boxes, classes, scores, labels, confidence_threshold)\n        \n        mAP = compute_map(boxes, classes, scores, labels)\n        cv2.putText(frame, mAP, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2)\n        \n        out.write(frame)\n    \n    cap.release()\n    out.release()\n\nif __name__ == '__main__':\n    main()",
        "last_error": "Max retries reached with failure. Last error from execution: 2025-12-11 07:39:45.414346: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n2025-12-11 07:39:45.417780: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n2025-12-11 07:39:45.429119: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2025-12-11 07:39:45.447336: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2025-12-11 07:39:45.452959: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n2025-12-11 07:39:45.466087: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\nTo enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n2025-12-11 07:39:46.251206: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\nINFO: Created TensorFlow Lite XNNPACK delegate for CPU.\nTraceback (most recent call last):\n  File \"/home/wuguangh/Projects/03.12/tinyml-autopilot-pm.03.12.2025/results/object_detection/sketches/tmp_20251211073945_psg_phi4:latest/tmp_20251211073945_psg_phi4:latest.py\", line 86, in <module>\n    main()\n  File \"/home/wuguangh/Projects/03.12/tinyml-autopilot-pm.03.12.2025/results/object_detection/sketches/tmp_20251211073945_psg_phi4:latest/tmp_20251211073945_psg_phi4:latest.py\", line 73, in main\n    boxes, classes, scores = run_inference(interpreter, input_data)\n  File \"/home/wuguangh/Projects/03.12/tinyml-autopilot-pm.03.12.2025/results/object_detection/sketches/tmp_20251211073945_psg_phi4:latest/tmp_20251211073945_psg_phi4:latest.py\", line 33, in run_inference\n    interpreter.set_tensor(input_details[0]['index'], input_data)\nNameError: name 'input_details' is not defined. Did you mean: 'input_data'?\n"
      },
      "session_id": "phi4_a8a2_psg_batch",
      "metadata": {
        "num_run": 4
      },
      "tags": [
        "ablation",
        "benchmark",
        "phi4:latest",
        "py_sketch_generator"
      ],
      "latency": 96.607,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-07-38-11-468289_chatcmpl-50f92698-8b1a-4729-a178-55e294b29609",
          "traceId": "16b3a5ea",
          "type": "GENERATION",
          "name": "16b3_psg_gen_attempt#1",
          "startTime": "2025-12-11T05:38:11.468000+00:00",
          "endTime": "2025-12-11T05:38:27.032000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 15564.0,
          "promptTokens": 245,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 850,
          "totalTokens": 1095,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-07-38-30-401802_chatcmpl-fd1fdbc7-7d5e-47f4-a6f0-6883a6b5bdd6",
          "traceId": "16b3a5ea",
          "type": "GENERATION",
          "name": "16b3_psg_gen_attempt#2",
          "startTime": "2025-12-11T05:38:30.401000+00:00",
          "endTime": "2025-12-11T05:38:50.877000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 20476.0,
          "promptTokens": 245,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 1123,
          "totalTokens": 1368,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-07-38-55-095414_chatcmpl-4a8808a2-1348-47b3-9cb0-f1e7b6b4504e",
          "traceId": "16b3a5ea",
          "type": "GENERATION",
          "name": "16b3_psg_gen_attempt#3",
          "startTime": "2025-12-11T05:38:55.095000+00:00",
          "endTime": "2025-12-11T05:39:11.446000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 16351.0,
          "promptTokens": 245,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 898,
          "totalTokens": 1143,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-07-39-11-594331_chatcmpl-e90f2c35-f63c-44fe-89a6-0eae2196caa0",
          "traceId": "16b3a5ea",
          "type": "GENERATION",
          "name": "16b3_psg_gen_attempt#4",
          "startTime": "2025-12-11T05:39:11.594000+00:00",
          "endTime": "2025-12-11T05:39:26.756000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 15162.0,
          "promptTokens": 245,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 834,
          "totalTokens": 1079,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-07-39-30-668838_chatcmpl-ac1a52c8-5f39-4116-b285-4fbb48ce7325",
          "traceId": "16b3a5ea",
          "type": "GENERATION",
          "name": "16b3_psg_gen_attempt#5",
          "startTime": "2025-12-11T05:39:30.668000+00:00",
          "endTime": "2025-12-11T05:39:45.094000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 14426.0,
          "promptTokens": 245,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 793,
          "totalTokens": 1038,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "cc45efc6-8a20-4554-ae04-b64b34e0f65b",
          "traceId": "16b3a5ea",
          "type": "SPAN",
          "name": "error_16_psg_failure_signal_py_sketch_generator",
          "startTime": "2025-12-11T05:39:48.075000+00:00",
          "level": "ERROR",
          "statusMessage": "Failed. Last error: Max retries reached with failure. Last error from execution: 2025-12-11 07:39:45.414346: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n2025-12-11 07:39:45.417780: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n2025-12-11 07:39:45.429119: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2025-12-11 07:39:45.447336: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2025-12-11 07:39:45.452959: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n2025-12-11 07:39:45.466087: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\nTo enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n2025-12-11 07:39:46.251206: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\nINFO: Created TensorFlow Lite XNNPACK delegate for CPU.\nTraceback (most recent call last):\n  File \"/home/wuguangh/Projects/03.12/tinyml-autopilot-pm.03.12.2025/results/object_detection/sketches/tmp_20251211073945_psg_phi4:latest/tmp_20251211073945_psg_phi4:latest.py\", line 86, in <module>\n    main()\n  File \"/home/wuguangh/Projects/03.12/tinyml-autopilot-pm.03.12.2025/results/object_detection/sketches/tmp_20251211073945_psg_phi4:latest/tmp_20251211073945_psg_phi4:latest.py\", line 73, in main\n    boxes, classes, scores = run_inference(interpreter, input_data)\n  File \"/home/wuguangh/Projects/03.12/tinyml-autopilot-pm.03.12.2025/results/object_detection/sketches/tmp_20251211073945_psg_phi4:latest/tmp_20251211073945_psg_phi4:latest.py\", line 33, in run_inference\n    interpreter.set_tensor(input_details[0]['index'], input_data)\nNameError: name 'input_details' is not defined. Did you mean: 'input_data'?\n",
          "calculatedTotalCost": 0.0,
          "promptTokens": 0,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 0,
          "totalTokens": 0,
          "endTime": null,
          "model": null,
          "modelParameters": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null,
          "latency": null
        }
      ],
      "createdAt": "2025-12-11T05:38:11.983Z",
      "updatedAt": "2025-12-11T05:39:53.701Z",
      "environment": "default"
    },
    {
      "id": "c0ebf0d6",
      "timestamp": "2025-12-11T05:36:14.086000+00:00",
      "name": "c0eb_py_sketch_generator",
      "input": null,
      "output": {
        "status": "failed",
        "last_code": "import cv2\nimport numpy as np\nimport tensorflow as tf\n\n# Configuration parameters\nmodel_path = 'models/ssd-mobilenet_v1/detect.tflite'\nlabel_path = 'models/ssd-mobilenet_v1/labelmap.txt'\ninput_path = 'data/object_detection/sheeps.mp4'\noutput_path = 'results/object_detection/test_results/sheeps_detections.mp4'\nconfidence_threshold = 0.5\n\n# Setup phase\ndef load_labels(label_file):\n    with open(label_file, 'r') as file:\n        labels = [line.strip() for line in file.readlines()]\n    return labels\n\ndef load_interpreter(model_path):\n    interpreter = tf.lite.Interpreter(model_path=model_path)\n    interpreter.allocate_tensors()\n    return interpreter\n\n# Preprocessing phase\ndef preprocess_frame(frame, input_size):\n    frame_resized = cv2.resize(frame, (input_size[1], input_size[0]))\n    input_data = np.expand_dims(frame_resized, axis=0).astype(np.float32)\n    return input_data\n\n# Inference phase\ndef run_inference(interpreter, input_data):\n    input_details = interpreter.get_input_details()\n    output_details = interpreter.get_output_details()\n\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n\n    interpreter.invoke()\n\n    boxes = interpreter.get_tensor(output_details[0]['index'])[0] # Bounding box coordinates\n    classes = interpreter.get_tensor(output_details[1]['index'])[0] # Class index\n    scores = interpreter.get_tensor(output_details[2]['index'])[0] # Confidence\n\n    return boxes, classes, scores\n\n# Output handling phase\ndef draw_boxes(frame, boxes, classes, scores, labels, threshold):\n    for i in range(len(scores)):\n        if scores[i] >= threshold:\n            ymin, xmin, ymax, xmax = boxes[i]\n            (left, right, top, bottom) = (xmin * frame.shape[1], xmax * frame.shape[1],\n                                          ymin * frame.shape[0], ymax * frame.shape[0])\n            \n            cv2.rectangle(frame, (int(left), int(top)), (int(right), int(bottom)), (10, 255, 0), 2)\n            \n            label = f\"{labels[int(classes[i])]}: {int(scores[i] * 100)}%\"\n            cv2.putText(frame, label, (int(left), int(top - 5)), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (10, 255, 0), 2)\n\ndef main():\n    labels = load_labels(label_path)\n    interpreter = load_interpreter(model_path)\n    \n    input_details = interpreter.get_input_details()\n    input_shape = input_details[0]['shape'][1:3]\n    \n    cap = cv2.VideoCapture(input_path)\n    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n    out = cv2.VideoWriter(output_path, fourcc, 20.0, (int(cap.get(3)), int(cap.get(4))))\n    \n    while cap.isOpened():\n        ret, frame = cap.read()\n        if not ret:\n            break\n        \n        input_data = preprocess_frame(frame, input_shape)\n        boxes, classes, scores = run_inference(interpreter, input_data)\n        \n        draw_boxes(frame, boxes, classes, scores, labels, confidence_threshold)\n        \n        out.write(frame)\n    \n    cap.release()\n    out.release()\n\nif __name__ == \"__main__\":\n    main()",
        "last_error": "Max retries reached with failure. Last error from execution: 2025-12-11 07:37:42.777079: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n2025-12-11 07:37:42.780458: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n2025-12-11 07:37:42.791742: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2025-12-11 07:37:42.809829: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2025-12-11 07:37:42.815305: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n2025-12-11 07:37:42.829676: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\nTo enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n2025-12-11 07:37:43.614623: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\nINFO: Created TensorFlow Lite XNNPACK delegate for CPU.\nTraceback (most recent call last):\n  File \"/home/wuguangh/Projects/03.12/tinyml-autopilot-pm.03.12.2025/results/object_detection/sketches/tmp_20251211073742_psg_phi4:latest/tmp_20251211073742_psg_phi4:latest.py\", line 84, in <module>\n    main()\n  File \"/home/wuguangh/Projects/03.12/tinyml-autopilot-pm.03.12.2025/results/object_detection/sketches/tmp_20251211073742_psg_phi4:latest/tmp_20251211073742_psg_phi4:latest.py\", line 74, in main\n    boxes, classes, scores = run_inference(interpreter, input_data)\n  File \"/home/wuguangh/Projects/03.12/tinyml-autopilot-pm.03.12.2025/results/object_detection/sketches/tmp_20251211073742_psg_phi4:latest/tmp_20251211073742_psg_phi4:latest.py\", line 34, in run_inference\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n  File \"/home/wuguangh/.conda/envs/tinyml/lib/python3.10/site-packages/tensorflow/lite/python/interpreter.py\", line 732, in set_tensor\n    self._interpreter.SetTensor(tensor_index, value)\nValueError: Cannot set tensor: Got value of type FLOAT32 but expected type UINT8 for input 175, name: normalized_input_image_tensor \n"
      },
      "session_id": "phi4_a8a2_psg_batch",
      "metadata": {
        "num_run": 3
      },
      "tags": [
        "ablation",
        "benchmark",
        "phi4:latest",
        "py_sketch_generator"
      ],
      "latency": 91.329,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-07-36-14-088425_chatcmpl-68f8fa88-513c-4a6e-a441-aa8a3bc1bf4b",
          "traceId": "c0ebf0d6",
          "type": "GENERATION",
          "name": "c0eb_psg_gen_attempt#1",
          "startTime": "2025-12-11T05:36:14.088000+00:00",
          "endTime": "2025-12-11T05:36:29.320000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 15232.0,
          "promptTokens": 245,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 833,
          "totalTokens": 1078,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-07-36-34-727916_chatcmpl-c194ad4d-9c33-447a-8c8e-04937ca1696e",
          "traceId": "c0ebf0d6",
          "type": "GENERATION",
          "name": "c0eb_psg_gen_attempt#2",
          "startTime": "2025-12-11T05:36:34.727000+00:00",
          "endTime": "2025-12-11T05:36:49.390000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 14663.0,
          "promptTokens": 245,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 807,
          "totalTokens": 1052,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-07-36-50-373289_chatcmpl-618e8f6b-b0a2-4fe6-8af6-dce6928a619e",
          "traceId": "c0ebf0d6",
          "type": "GENERATION",
          "name": "c0eb_psg_gen_attempt#3",
          "startTime": "2025-12-11T05:36:50.373000+00:00",
          "endTime": "2025-12-11T05:37:05.448000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 15075.0,
          "promptTokens": 245,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 829,
          "totalTokens": 1074,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-07-37-12-264064_chatcmpl-c048f64f-aae7-493d-9c03-be32f38175e2",
          "traceId": "c0ebf0d6",
          "type": "GENERATION",
          "name": "c0eb_psg_gen_attempt#4",
          "startTime": "2025-12-11T05:37:12.264000+00:00",
          "endTime": "2025-12-11T05:37:29.200000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 16936.0,
          "promptTokens": 245,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 931,
          "totalTokens": 1176,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-07-37-29-353315_chatcmpl-7e0addd9-a9ce-4874-86e1-62e650838e91",
          "traceId": "c0ebf0d6",
          "type": "GENERATION",
          "name": "c0eb_psg_gen_attempt#5",
          "startTime": "2025-12-11T05:37:29.353000+00:00",
          "endTime": "2025-12-11T05:37:42.458000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 13105.0,
          "promptTokens": 245,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 722,
          "totalTokens": 967,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "a0d21f6c-b077-4f2c-b416-91d30495d4ab",
          "traceId": "c0ebf0d6",
          "type": "SPAN",
          "name": "error_c0_psg_failure_signal_py_sketch_generator",
          "startTime": "2025-12-11T05:37:45.417000+00:00",
          "level": "ERROR",
          "statusMessage": "Failed. Last error: Max retries reached with failure. Last error from execution: 2025-12-11 07:37:42.777079: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n2025-12-11 07:37:42.780458: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n2025-12-11 07:37:42.791742: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2025-12-11 07:37:42.809829: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2025-12-11 07:37:42.815305: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n2025-12-11 07:37:42.829676: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\nTo enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n2025-12-11 07:37:43.614623: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\nINFO: Created TensorFlow Lite XNNPACK delegate for CPU.\nTraceback (most recent call last):\n  File \"/home/wuguangh/Projects/03.12/tinyml-autopilot-pm.03.12.2025/results/object_detection/sketches/tmp_20251211073742_psg_phi4:latest/tmp_20251211073742_psg_phi4:latest.py\", line 84, in <module>\n    main()\n  File \"/home/wuguangh/Projects/03.12/tinyml-autopilot-pm.03.12.2025/results/object_detection/sketches/tmp_20251211073742_psg_phi4:latest/tmp_20251211073742_psg_phi4:latest.py\", line 74, in main\n    boxes, classes, scores = run_inference(interpreter, input_data)\n  File \"/home/wuguangh/Projects/03.12/tinyml-autopilot-pm.03.12.2025/results/object_detection/sketches/tmp_20251211073742_psg_phi4:latest/tmp_20251211073742_psg_phi4:latest.py\", line 34, in run_inference\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n  File \"/home/wuguangh/.conda/envs/tinyml/lib/python3.10/site-packages/tensorflow/lite/python/interpreter.py\", line 732, in set_tensor\n    self._interpreter.SetTensor(tensor_index, value)\nValueError: Cannot set tensor: Got value of type FLOAT32 but expected type UINT8 for input 175, name: normalized_input_image_tensor \n",
          "calculatedTotalCost": 0.0,
          "promptTokens": 0,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 0,
          "totalTokens": 0,
          "endTime": null,
          "model": null,
          "modelParameters": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null,
          "latency": null
        }
      ],
      "createdAt": "2025-12-11T05:36:14.603Z",
      "updatedAt": "2025-12-11T05:37:50.754Z",
      "environment": "default"
    },
    {
      "id": "bf958909",
      "timestamp": "2025-12-11T05:34:33.858000+00:00",
      "name": "bf95_py_sketch_generator",
      "input": null,
      "output": {
        "status": "success",
        "sketch": "import cv2\nimport numpy as np\nfrom tflite_runtime.interpreter import Interpreter\n\n# Configuration parameters\nmodel_path = 'models/ssd-mobilenet_v1/detect.tflite'\nlabel_path = 'models/ssd-mobilenet_v1/labelmap.txt'\ninput_path = 'data/object_detection/sheeps.mp4'\noutput_path = 'results/object_detection/test_results/sheeps_detections.mp4'\nconfidence_threshold = 0.5\n\n# Phase 1: Setup\ndef load_labels(label_file):\n    with open(label_file, 'r') as file:\n        return {i: line.strip() for i, line in enumerate(file.readlines())}\n\ndef set_input_tensor(interpreter, image):\n    tensor_index = interpreter.get_input_details()[0]['index']\n    input_shape = interpreter.get_input_details()[0]['shape']\n    image = cv2.resize(image, (input_shape[1], input_shape[2]))\n    image = np.expand_dims(image, axis=0)\n    interpreter.set_tensor(tensor_index, image)\n\ndef get_output(interpreter):\n    boxes = interpreter.get_tensor(interpreter.get_output_details()[0]['index'])[0] # Bounding box coordinates of detected objects\n    classes = interpreter.get_tensor(interpreter.get_output_details()[1]['index'])[0] # Class index of detected objects\n    scores = interpreter.get_tensor(interpreter.get_output_details()[2]['index'])[0] # Confidence of detected objects\n    return boxes, classes, scores\n\n# Phase 2: Preprocessing\ndef load_labels(label_file):\n    with open(label_file, 'r') as file:\n        labels = {i: line.strip() for i, line in enumerate(file.readlines())}\n    return labels\n\n# Phase 3: Inference\ndef main():\n    interpreter = Interpreter(model_path=model_path)\n    interpreter.allocate_tensors()\n\n    input_details = interpreter.get_input_details()\n    output_details = interpreter.get_output_details()\n\n    cap = cv2.VideoCapture(input_path)\n    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n    out = cv2.VideoWriter(output_path, fourcc, 30.0, (int(cap.get(3)), int(cap.get(4))))\n\n    labels = load_labels(label_path)\n\n    while cap.isOpened():\n        ret, frame = cap.read()\n        if not ret:\n            break\n\n        set_input_tensor(interpreter, frame)\n        interpreter.invoke()\n\n        boxes, classes, scores = get_output(interpreter)\n\n        for i in range(len(scores)):\n            if scores[i] >= confidence_threshold:\n                ymin, xmin, ymax, xmax = boxes[i]\n                (left, right, top, bottom) = (xmin * cap.get(3), xmax * cap.get(3),\n                                              ymin * cap.get(4), ymax * cap.get(4))\n                class_id = int(classes[i])\n                label = labels.get(class_id, 'Unknown')\n\n                cv2.rectangle(frame, (int(left), int(top)), (int(right), int(bottom)), (10, 255, 0), 2)\n                text = f'{label}: {int(scores[i] * 100)}%'\n                cv2.putText(frame, text, (int(left), int(top) - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (10, 255, 0), 1)\n\n        out.write(frame)\n\n    cap.release()\n    out.release()\n\nif __name__ == '__main__':\n    main()"
      },
      "session_id": "phi4_a8a2_psg_batch",
      "metadata": {
        "num_run": 2
      },
      "tags": [
        "ablation",
        "benchmark",
        "phi4:latest",
        "py_sketch_generator"
      ],
      "latency": 28.837,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-07-34-33-860639_chatcmpl-dddf13db-eac6-45fb-8704-3d4cc1ac0d8e",
          "traceId": "bf958909",
          "type": "GENERATION",
          "name": "bf95_psg_gen_attempt#1",
          "startTime": "2025-12-11T05:34:33.860000+00:00",
          "endTime": "2025-12-11T05:34:48.548000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 14688.0,
          "promptTokens": 245,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 803,
          "totalTokens": 1048,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-07-34-48-702569_chatcmpl-e5d22976-4ad1-47ea-a3e8-d10eefe877ca",
          "traceId": "bf958909",
          "type": "GENERATION",
          "name": "bf95_psg_gen_attempt#2",
          "startTime": "2025-12-11T05:34:48.702000+00:00",
          "endTime": "2025-12-11T05:35:02.697000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 13995.0,
          "promptTokens": 245,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 770,
          "totalTokens": 1015,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        }
      ],
      "createdAt": "2025-12-11T05:34:34.383Z",
      "updatedAt": "2025-12-11T05:35:54.125Z",
      "environment": "default"
    },
    {
      "id": "d23d32c1",
      "timestamp": "2025-12-11T05:33:46.553000+00:00",
      "name": "d23d_py_sketch_generator",
      "input": null,
      "output": {
        "status": "success",
        "sketch": "import cv2\nimport numpy as np\nimport tensorflow as tf\n\n# Configuration parameters\nmodel_path = 'models/ssd-mobilenet_v1/detect.tflite'\nlabel_path = 'models/ssd-mobilenet_v1/labelmap.txt'\ninput_path = 'data/object_detection/sheeps.mp4'\noutput_path = 'results/object_detection/test_results/sheeps_detections.mp4'\nconfidence_threshold = 0.5\n\n# Load labels from label map file\ndef load_labels(label_file):\n    with open(label_file, 'r', encoding='utf-8') as f:\n        return {i: line.strip() for i, line in enumerate(f.readlines())}\n\nlabels = load_labels(label_path)\n\n# Setup phase\ninterpreter = tf.lite.Interpreter(model_path=model_path)\ninterpreter.allocate_tensors()\n\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\n\ninput_shape = input_details[0]['shape']\nheight, width, channels = input_shape[1], input_shape[2], input_shape[3]\n\n# Preprocessing phase\ndef preprocess_frame(frame):\n    frame_resized = cv2.resize(frame, (width, height))\n    input_data = np.expand_dims(frame_resized, axis=0)\n    return input_data\n\n# Inference phase\ndef run_inference(input_data):\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n    interpreter.invoke()\n\n    boxes = interpreter.get_tensor(output_details[0]['index'])[0]\n    classes = interpreter.get_tensor(output_details[1]['index'])[0]\n    scores = interpreter.get_tensor(output_details[2]['index'])[0]\n\n    return boxes, classes, scores\n\n# Output handling phase\ndef draw_boxes(frame, boxes, classes, scores):\n    for i in range(len(scores)):\n        if scores[i] > confidence_threshold:\n            ymin, xmin, ymax, xmax = boxes[i]\n            (left, right, top, bottom) = (xmin * frame.shape[1], xmax * frame.shape[1],\n                                          ymin * frame.shape[0], ymax * frame.shape[0])\n            class_id = int(classes[i])\n            label = f\"{labels.get(class_id, 'Unknown')} {int(scores[i]*100)}%\"\n            \n            cv2.rectangle(frame, (int(left), int(top)), (int(right), int(bottom)), (10, 255, 0), 2)\n            cv2.putText(frame, label, (int(left), int(top) - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (10, 255, 0), 2)\n\ndef main():\n    cap = cv2.VideoCapture(input_path)\n    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n    out = cv2.VideoWriter(output_path, fourcc, 30.0, (int(cap.get(3)), int(cap.get(4))))\n\n    while cap.isOpened():\n        ret, frame = cap.read()\n        if not ret:\n            break\n\n        input_data = preprocess_frame(frame)\n        boxes, classes, scores = run_inference(input_data)\n        draw_boxes(frame, boxes, classes, scores)\n\n        out.write(frame)\n\n    cap.release()\n    out.release()\n\nif __name__ == '__main__':\n    main()"
      },
      "session_id": "phi4_a8a2_psg_batch",
      "metadata": {
        "num_run": 1
      },
      "tags": [
        "ablation",
        "benchmark",
        "phi4:latest",
        "py_sketch_generator"
      ],
      "latency": 12.572,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-07-33-46-554781_chatcmpl-b2b0d4e0-1c4a-4c6f-ae0d-44e077bef68c",
          "traceId": "d23d32c1",
          "type": "GENERATION",
          "name": "d23d_psg_gen_attempt#1",
          "startTime": "2025-12-11T05:33:46.554000+00:00",
          "endTime": "2025-12-11T05:33:59.126000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 12572.0,
          "promptTokens": 245,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 676,
          "totalTokens": 921,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        }
      ],
      "createdAt": "2025-12-11T05:33:47.069Z",
      "updatedAt": "2025-12-11T05:34:12.753Z",
      "environment": "default"
    }
  ],
  "meta": {
    "total_items": 30
  }
}
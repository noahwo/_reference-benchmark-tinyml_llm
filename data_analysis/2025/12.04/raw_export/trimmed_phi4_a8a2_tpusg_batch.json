{
  "data": [
    {
      "id": "96430a12",
      "timestamp": "2025-12-11T05:31:21.258000+00:00",
      "name": "9643_tpu_sketch_generator",
      "input": null,
      "output": {
        "status": "failed",
        "last_code": "import cv2\nimport numpy as np\nfrom tflite_runtime.interpreter import Interpreter\nfrom PIL import Image, ImageDraw, ImageFont\n\ndef load_labels(label_path):\n    with open(label_path, 'r', encoding='utf-8') as file:\n        lines = file.readlines()\n    return {int(line.split(' ')[0]): line.strip().split(' ', 1)[1] for line in lines}\n\ndef set_input_tensor(interpreter, image):\n    tensor_index = interpreter.get_input_details()[0]['index']\n    input_shape = interpreter.get_input_details()[0]['shape']\n    image = cv2.resize(image, (input_shape[1], input_shape[2]))\n    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n    input_data = np.expand_dims(image, axis=0).astype(np.float32)\n    interpreter.set_tensor(tensor_index, input_data)\n\ndef get_output(interpreter):\n    boxes = interpreter.get_tensor(interpreter.get_output_details()[0]['index'])[0]  # Bounding box coordinates\n    classes = interpreter.get_tensor(interpreter.get_output_details()[1]['index'])[0]  # Class index\n    scores = interpreter.get_tensor(interpreter.get_output_details()[2]['index'])[0]  # Confidence\n    count = int(interpreter.get_tensor(interpreter.get_output_details()[3]['index'])[0])  # Number of objects detected\n    return boxes, classes, scores, count\n\ndef draw_boxes(image, boxes, class_ids, scores, labels):\n    for i in range(len(scores)):\n        if scores[i] > confidence_threshold:\n            ymin, xmin, ymax, xmax = boxes[i]\n            (left, right, top, bottom) = (xmin * image.shape[1], xmax * image.shape[1],\n                                          ymin * image.shape[0], ymax * image.shape[0])\n            left, right, top, bottom = int(left), int(right), int(top), int(bottom)\n            \n            cv2.rectangle(image, (left, top), (right, bottom), color=(0, 255, 0), thickness=2)\n\n            label = '%s: %d%%' % (labels[int(class_ids[i])], int(scores[i] * 100))\n            cv2.putText(image, label, (left, top - 10), cv2.FONT_HERSHEY_SIMPLEX,\n                        0.5, (0, 255, 0), 1)\n    return image\n\ndef compute_map(ground_truths, predictions):\n    # Placeholder function for mAP calculation\n    # Implement the actual mAP computation based on ground truths and predictions\n    pass\n\nmodel_path = '/home/mendel/tinyml_autopilot/models/edgetpu_detect.tflite'\nlabel_path = '/home/mendel/tinyml_autopilot/models/labelmap.txt'\ninput_path = '/home/mendel/tinyml_autopilot/data/sheeps.mp4'\noutput_path = '/home/mendel/tinyml_autopilot/results/sheeps_detections.mp4'\nconfidence_threshold = 0.5\n\n# Phase 1: Setup\ninterpreter = Interpreter(model_path=model_path, experimental_delegates=[load_delegate('/usr/lib/aarch64-linux-gnu/libedgetpu.so.1.0')])\ninterpreter.allocate_tensors()\n\n# Load labels\nlabels = load_labels(label_path)\n\n# Phase 2: Preprocessing and Reading Input\ncap = cv2.VideoCapture(input_path)\nfourcc = cv2.VideoWriter_fourcc(*'mp4v')\nout = cv2.VideoWriter(output_path, fourcc, 20.0, (int(cap.get(3)), int(cap.get(4))))\n\nwhile cap.isOpened():\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    # Phase 3: Inference\n    set_input_tensor(interpreter, frame)\n    interpreter.invoke()\n    boxes, class_ids, scores, count = get_output(interpreter)\n\n    # Phase 4: Output Handling\n    annotated_frame = draw_boxes(frame, boxes, class_ids, scores, labels)\n    out.write(annotated_frame)\n\ncap.release()\nout.release()\n\n# Placeholder for mAP computation\n# compute_map(ground_truths, predictions)  # Implement this with actual data",
        "last_error": "Max retries reached with error. Last error: Traceback (most recent call last):\n  File \"script_19718fe4_1765431212.py\", line 53, in <module>\n    interpreter = Interpreter(model_path=model_path, experimental_delegates=[load_delegate('/usr/lib/aarch64-linux-gnu/libedgetpu.so.1.0')])\nNameError: name 'load_delegate' is not defined."
      },
      "session_id": "phi4_a8a2_tpusg_batch",
      "metadata": {
        "num_run": 30
      },
      "tags": [
        "ablation",
        "benchmark",
        "phi4:latest",
        "tpu_sketch_generator"
      ],
      "latency": 139.183,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-07-31-21-260119_chatcmpl-f02101bc-434a-4f88-8351-30972a7f7dbf",
          "traceId": "96430a12",
          "type": "GENERATION",
          "name": "9643_tpusg_gen_attempt#1",
          "startTime": "2025-12-11T05:31:21.260000+00:00",
          "endTime": "2025-12-11T05:31:36.168000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 14908.0,
          "promptTokens": 291,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 816,
          "totalTokens": 1107,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-07-31-43-975537_chatcmpl-a365bb2f-8812-4ac4-9688-310c53ce07dc",
          "traceId": "96430a12",
          "type": "GENERATION",
          "name": "9643_tpusg_gen_attempt#2",
          "startTime": "2025-12-11T05:31:43.975000+00:00",
          "endTime": "2025-12-11T05:32:16.391000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 32416.0,
          "promptTokens": 291,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 1749,
          "totalTokens": 2040,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-07-32-24-944550_chatcmpl-eb917457-3a88-496c-aec0-c8753e5bae12",
          "traceId": "96430a12",
          "type": "GENERATION",
          "name": "9643_tpusg_gen_attempt#3",
          "startTime": "2025-12-11T05:32:24.944000+00:00",
          "endTime": "2025-12-11T05:32:39.558000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 14614.0,
          "promptTokens": 291,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 803,
          "totalTokens": 1094,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-07-32-47-673089_chatcmpl-26c57716-a55b-4c68-a623-f74db3a2d2cd",
          "traceId": "96430a12",
          "type": "GENERATION",
          "name": "9643_tpusg_gen_attempt#4",
          "startTime": "2025-12-11T05:32:47.673000+00:00",
          "endTime": "2025-12-11T05:33:06.931000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 19258.0,
          "promptTokens": 291,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 1053,
          "totalTokens": 1344,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-07-33-15-326593_chatcmpl-56999205-e2a1-43f7-8f2d-38035226a226",
          "traceId": "96430a12",
          "type": "GENERATION",
          "name": "9643_tpusg_gen_attempt#5",
          "startTime": "2025-12-11T05:33:15.326000+00:00",
          "endTime": "2025-12-11T05:33:32.364000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 17038.0,
          "promptTokens": 291,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 934,
          "totalTokens": 1225,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "2915455c-bd22-4915-bac9-9566ad0b72cb",
          "traceId": "96430a12",
          "type": "SPAN",
          "name": "error_96_tpusg_failure_signal_tpu_sketch_generator",
          "startTime": "2025-12-11T05:33:40.443000+00:00",
          "level": "ERROR",
          "statusMessage": "Failed: Max retries reached with error. Last error: Traceback (most recent call last):\n  File \"script_19718fe4_1765431212.py\", line 53, in <module>\n    interpreter = Interpreter(model_path=model_path, experimental_delegates=[load_delegate('/usr/lib/aarch64-linux-gnu/libedgetpu.so.1.0')])\nNameError: name 'load_delegate' is not defined.",
          "calculatedTotalCost": 0.0,
          "promptTokens": 0,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 0,
          "totalTokens": 0,
          "endTime": null,
          "model": null,
          "modelParameters": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null,
          "latency": null
        }
      ],
      "createdAt": "2025-12-11T05:31:21.773Z",
      "updatedAt": "2025-12-11T05:33:46.067Z",
      "environment": "default"
    },
    {
      "id": "d1094318",
      "timestamp": "2025-12-11T05:28:52.289000+00:00",
      "name": "d109_tpu_sketch_generator",
      "input": null,
      "output": {
        "status": "failed",
        "last_code": "import cv2\nimport numpy as np\nfrom tflite_runtime.interpreter import Interpreter\nfrom tflite_runtime.interpreter import load_delegate\nfrom google Coral's TPU library\n\n# Constants\nMODEL_PATH = '/home/mendel/tinyml_autopilot/models/edgetpu_detect.tflite'\nLABEL_PATH = '/home/mendel/tinyml_autopilot/models/labelmap.txt'\nINPUT_PATH = '/home/mendel/tinyml_autopilot/data/sheeps.mp4'\nOUTPUT_PATH = '/home/mendel/tinyml_autopilot/results/sheeps_detections.mp4'\nCONFIDENCE_THRESHOLD = 0.5\n\n# Load labels\ndef load_labels(path):\n    with open(path, 'r') as f:\n        lines = f.readlines()\n    return [line.strip() for line in lines]\n\n# Setup TFLite interpreter for Coral TPU\ndef setup_interpreter():\n    return Interpreter(\n        model_path=MODEL_PATH,\n        experimental_delegates=[load_delegate('/usr/lib/aarch64-linux-gnu/libedgetpu.so.1.0')]\n    )\n\n# Preprocess the input frame\ndef preprocess_frame(frame, input_size):\n    image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n    image = cv2.resize(image, input_size)\n    image = np.expand_dims(image, axis=0).astype(np.float32)\n    return image\n\n# Perform inference and process results\ndef run_inference(interpreter, frame):\n    input_details = interpreter.get_input_details()\n    output_details = interpreter.get_output_details()\n\n    # Set input tensor\n    interpreter.set_tensor(input_details[0]['index'], frame)\n\n    # Run inference\n    interpreter.invoke()\n\n    # Extract detection results\n    boxes = interpreter.get_tensor(output_details[0]['index'])[0]  # Bounding box coordinates of detected objects\n    classes = interpreter.get_tensor(output_details[1]['index'])[0]  # Class index of detected objects\n    scores = interpreter.get_tensor(output_details[2]['index'])[0]  # Confidence of detected objects\n\n    return boxes, classes, scores\n\n# Draw detection results on the frame\ndef draw_detections(frame, boxes, classes, scores, labels):\n    height, width, _ = frame.shape\n    for i in range(len(scores)):\n        if scores[i] >= CONFIDENCE_THRESHOLD:\n            ymin, xmin, ymax, xmax = boxes[i]\n            (left, right, top, bottom) = (xmin * width, xmax * width,\n                                          ymin * height, ymax * height)\n            object_name = labels[int(classes[i])]\n            label = f'{object_name}: {int(scores[i] * 100)}%'\n            color = (0, 255, 0)\n\n            # Draw rectangle\n            cv2.rectangle(frame, (int(left), int(top)), (int(right), int(bottom)), color, 2)\n            \n            # Draw label background\n            label_size, base_line = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.7, 2)\n            top = max(top, label_size[1])\n            cv2.rectangle(frame, (int(left), int(top - round(1.5 * label_size[1]))),\n                          (int(left + round(1.5 * label_size[0])), int(top + base_line)),\n                          color, cv2.FILLED)\n            \n            # Draw text\n            cv2.putText(frame, label, (int(left), int(top)), cv2.FONT_HERSHEY_SIMPLEX,\n                        0.7, (255, 255, 255), 2)\n\n# Compute mAP (simplified version for demonstration purposes)\ndef compute_map(boxes, classes, scores, labels):\n    # This is a placeholder function to represent the computation of mean Average Precision.\n    # In practice, you would need ground truth data and compare detections with it.\n    detected_objects = set()\n    total_true_positives = 0\n    for i in range(len(scores)):\n        if scores[i] >= CONFIDENCE_THRESHOLD:\n            detected_objects.add((classes[i], boxes[i]))\n    \n    # For simplicity, assume each detection is a true positive\n    total_true_positives = len(detected_objects)\n    mAP = total_true_positives / (len(classes) + 1e-6)  # Avoid division by zero\n    \n    return mAP\n\n# Main pipeline\ndef main():\n    labels = load_labels(LABEL_PATH)\n    \n    interpreter = setup_interpreter()\n    input_details = interpreter.get_input_details()\n    output_details = interpreter.get_output_details()\n\n    _, height, width, _ = input_details[0]['shape']\n    cap = cv2.VideoCapture(INPUT_PATH)\n    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n    out = cv2.VideoWriter(OUTPUT_PATH, fourcc, 20.0, (width, height))\n\n    while cap.isOpened():\n        ret, frame = cap.read()\n        if not ret:\n            break\n\n        # Preprocess\n        input_image = preprocess_frame(frame, (width, height))\n        \n        # Inference\n        boxes, classes, scores = run_inference(interpreter, input_image)\n        \n        # Draw detections\n        draw_detections(frame, boxes, classes, scores, labels)\n\n        # Output frame\n        out.write(frame)\n\n    # Compute mAP for the entire video (simplified)\n    all_boxes = []\n    all_classes = []\n    all_scores = []\n    \n    cap.set(cv2.CAP_PROP_POS_FRAMES, 0)  # Reset video to start\n\n    while cap.isOpened():\n        ret, frame = cap.read()\n        if not ret:\n            break\n        \n        input_image = preprocess_frame(frame, (width, height))\n        boxes, classes, scores = run_inference(interpreter, input_image)\n        \n        all_boxes.extend(boxes)\n        all_classes.extend(classes)\n        all_scores.extend(scores)\n\n    mAP = compute_map(all_boxes, all_classes, all_scores, labels)\n    print(f\"Mean Average Precision (mAP): {mAP}\")\n\n    cap.release()\n    out.release()\n    cv2.destroyAllWindows()\n\nif __name__ == '__main__':\n    main()",
        "last_error": "Max retries reached with error. Last error:   File \"script_2a957a45_1765431053.py\", line 5\n    from google Coral's TPU library\n                    ^\nSyntaxError: invalid syntax."
      },
      "session_id": "phi4_a8a2_tpusg_batch",
      "metadata": {
        "num_run": 29
      },
      "tags": [
        "ablation",
        "benchmark",
        "phi4:latest",
        "tpu_sketch_generator"
      ],
      "latency": 124.797,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-07-28-52-290965_chatcmpl-89fa090d-dd17-4a81-91a4-9497736531d6",
          "traceId": "d1094318",
          "type": "GENERATION",
          "name": "d109_tpusg_gen_attempt#1",
          "startTime": "2025-12-11T05:28:52.290000+00:00",
          "endTime": "2025-12-11T05:29:07.192000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 14902.0,
          "promptTokens": 291,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 815,
          "totalTokens": 1106,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-07-29-15-334236_chatcmpl-9d69cf4d-e5e8-4290-a04e-1466aee3742f",
          "traceId": "d1094318",
          "type": "GENERATION",
          "name": "d109_tpusg_gen_attempt#2",
          "startTime": "2025-12-11T05:29:15.334000+00:00",
          "endTime": "2025-12-11T05:29:29.809000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 14475.0,
          "promptTokens": 291,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 795,
          "totalTokens": 1086,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-07-29-38-200143_chatcmpl-84552849-ee97-4f29-8e5b-ee5f4d5cdb81",
          "traceId": "d1094318",
          "type": "GENERATION",
          "name": "d109_tpusg_gen_attempt#3",
          "startTime": "2025-12-11T05:29:38.200000+00:00",
          "endTime": "2025-12-11T05:29:55.440000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 17240.0,
          "promptTokens": 291,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 945,
          "totalTokens": 1236,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-07-30-03-688614_chatcmpl-321162d7-f577-4fd3-9d4d-36ebf0b3cd8d",
          "traceId": "d1094318",
          "type": "GENERATION",
          "name": "d109_tpusg_gen_attempt#4",
          "startTime": "2025-12-11T05:30:03.688000+00:00",
          "endTime": "2025-12-11T05:30:21.325000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 17637.0,
          "promptTokens": 291,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 967,
          "totalTokens": 1258,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-07-30-29-564401_chatcmpl-78aedd30-7d2b-4534-ab2f-7ea04c4937f3",
          "traceId": "d1094318",
          "type": "GENERATION",
          "name": "d109_tpusg_gen_attempt#5",
          "startTime": "2025-12-11T05:30:29.564000+00:00",
          "endTime": "2025-12-11T05:30:53.064000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 23500.0,
          "promptTokens": 291,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 1280,
          "totalTokens": 1571,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "7ac5f361-5a47-4203-99ef-2e6f595058da",
          "traceId": "d1094318",
          "type": "SPAN",
          "name": "error_d1_tpusg_failure_signal_tpu_sketch_generator",
          "startTime": "2025-12-11T05:30:57.087000+00:00",
          "level": "ERROR",
          "statusMessage": "Failed: Max retries reached with error. Last error:   File \"script_2a957a45_1765431053.py\", line 5\n    from google Coral's TPU library\n                    ^\nSyntaxError: invalid syntax.",
          "calculatedTotalCost": 0.0,
          "promptTokens": 0,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 0,
          "totalTokens": 0,
          "endTime": null,
          "model": null,
          "modelParameters": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null,
          "latency": null
        }
      ],
      "createdAt": "2025-12-11T05:28:52.805Z",
      "updatedAt": "2025-12-11T05:31:02.475Z",
      "environment": "default"
    },
    {
      "id": "74ca4e3d",
      "timestamp": "2025-12-11T05:26:18.321000+00:00",
      "name": "74ca_tpu_sketch_generator",
      "input": null,
      "output": {
        "status": "failed",
        "last_code": "import cv2\nimport numpy as np\nfrom tflite_runtime.interpreter import Interpreter\nfrom google.protobuf.json_format import ParseDict\nfrom object_detection.protos.string_int_label_map_pb2 import StringIntLabelMap\nfrom object_detection.utils import visualization_utils as vis_util\n\n# Configuration parameters\nmodel_path = '/home/mendel/tinyml_autopilot/models/edgetpu_detect.tflite'\nlabel_path = '/home/mendel/tinyml_autopilot/models/labelmap.txt'\ninput_path = '/home/mendel/tinyml_autopilot/data/sheeps.mp4'\noutput_path = '/home/mendel/tinyml_autopilot/results/sheeps_detections.mp4'\nconfidence_threshold = 0.5\n\n# Load the TFLite interpreter for TPU\ndef load_interpreter(model_path):\n    # Set up the Coral specific libraries location and load the EdgeTPU delegator.\n    import os\n    os.environ['LIBEDGETPU_LIB_PATH'] = '/usr/lib/aarch64-linux-gnu'\n    \n    # Load the TFLite model with the EdgeTPU delegate\n    from tflite_runtime.interpreter import load_delegate\n    interpreter = Interpreter(\n        model_path=model_path,\n        experimental_delegates=[load_delegate('libedgetpu.so.1.0')]\n    )\n    interpreter.allocate_tensors()\n    return interpreter\n\n# Read and parse labels\ndef load_labels(label_path):\n    with open(label_path, 'r') as f:\n        label_map = StringIntLabelMap()\n        ParseDict({line.split(maxsplit=1)[0]: {'id': int(line.split()[0])} for line in f.read().strip().split('\\n')}, label_map)\n    \n    categories = [{'id': item.id, 'name': item.name} for item in label_map.item]\n    return {category['id']: category['name'] for category in categories}\n\n# Preprocessing: Resize and normalize the image\ndef preprocess_frame(frame, input_size):\n    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n    frame_resized = cv2.resize(frame_rgb, (input_size[1], input_size[0]))\n    input_data = np.expand_dims(frame_resized, axis=0).astype(np.float32)\n    return input_data\n\n# Run inference and process output\ndef run_inference(interpreter, input_data):\n    input_details = interpreter.get_input_details()\n    output_details = interpreter.get_output_details()\n\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n    interpreter.invoke()\n\n    boxes = interpreter.get_tensor(output_details[0]['index'])[0]  # Bounding box coordinates of detected objects\n    classes = interpreter.get_tensor(output_details[1]['index'])[0]  # Class index of detected objects\n    scores = interpreter.get_tensor(output_details[2]['index'])[0]  # Confidence of detected objects\n\n    return boxes, classes, scores\n\n# Compute mean Average Precision (mAP) - Placeholder function for demonstration\ndef compute_map(ground_truths, predictions):\n    # This is a placeholder. In practice, you would implement the mAP calculation.\n    print(\"Computing mAP...\")\n\n# Draw detection boxes with labels\ndef draw_detections(frame, boxes, classes, scores, labels, threshold):\n    input_height, input_width, _ = frame.shape\n    vis_util.visualize_boxes_and_labels_on_image_array(\n        frame,\n        np.array([boxes]).astype(int),\n        [np.argmax(cls) for cls in classes if scores[np.argmax(cls)] > threshold],\n        [scores[np.argmax(cls)] for cls in classes if scores[np.argmax(cls)] > threshold],\n        labels,\n        use_normalized_coordinates=True,\n        line_thickness=8\n    )\n    return frame\n\n# Main processing pipeline\ndef main():\n    interpreter = load_interpreter(model_path)\n    input_details = interpreter.get_input_details()\n    output_details = interpreter.get_output_details()\n    input_size = (input_details[0]['shape'][1], input_details[0]['shape'][2])\n\n    labels = load_labels(label_path)\n\n    # Open video file\n    cap = cv2.VideoCapture(input_path)\n    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n    out = cv2.VideoWriter(output_path, fourcc, 20.0, (int(cap.get(3)), int(cap.get(4))))\n\n    while cap.isOpened():\n        ret, frame = cap.read()\n        if not ret:\n            break\n\n        input_data = preprocess_frame(frame, input_size)\n        boxes, classes, scores = run_inference(interpreter, input_data)\n        \n        # Draw detections on the frame\n        frame_with_detections = draw_detections(\n            frame,\n            boxes,\n            classes,\n            scores,\n            labels,\n            confidence_threshold\n        )\n\n        out.write(frame_with_detections)\n\n    compute_map([], [])  # Placeholder for mAP computation\n\n    cap.release()\n    out.release()\n\nif __name__ == '__main__':\n    main()",
        "last_error": "Max retries reached with error. Last error: Traceback (most recent call last):\n  File \"script_e81c6840_1765430898.py\", line 5, in <module>\n    from object_detection.protos.string_int_label_map_pb2 import StringIntLabelMap\nModuleNotFoundError: No module named 'object_detection'."
      },
      "session_id": "phi4_a8a2_tpusg_batch",
      "metadata": {
        "num_run": 28
      },
      "tags": [
        "ablation",
        "benchmark",
        "phi4:latest",
        "tpu_sketch_generator"
      ],
      "latency": 128.044,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-07-26-18-322505_chatcmpl-96471e1d-0767-4935-a708-ab0b4944899b",
          "traceId": "74ca4e3d",
          "type": "GENERATION",
          "name": "74ca_tpusg_gen_attempt#1",
          "startTime": "2025-12-11T05:26:18.322000+00:00",
          "endTime": "2025-12-11T05:26:35.198000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 16876.0,
          "promptTokens": 291,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 922,
          "totalTokens": 1213,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-07-26-43-844783_chatcmpl-cf384742-0df8-41e8-9a41-1383b0fc84a2",
          "traceId": "74ca4e3d",
          "type": "GENERATION",
          "name": "74ca_tpusg_gen_attempt#2",
          "startTime": "2025-12-11T05:26:43.844000+00:00",
          "endTime": "2025-12-11T05:26:59.738000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 15894.0,
          "promptTokens": 291,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 872,
          "totalTokens": 1163,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-07-27-08-234030_chatcmpl-eea70b39-76bc-4a31-b93d-85015a565447",
          "traceId": "74ca4e3d",
          "type": "GENERATION",
          "name": "74ca_tpusg_gen_attempt#3",
          "startTime": "2025-12-11T05:27:08.234000+00:00",
          "endTime": "2025-12-11T05:27:27.827000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 19593.0,
          "promptTokens": 291,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 1073,
          "totalTokens": 1364,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-07-27-35-810851_chatcmpl-43197961-4312-47b3-a327-b2bb75a2aa21",
          "traceId": "74ca4e3d",
          "type": "GENERATION",
          "name": "74ca_tpusg_gen_attempt#4",
          "startTime": "2025-12-11T05:27:35.810000+00:00",
          "endTime": "2025-12-11T05:27:49.997000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 14187.0,
          "promptTokens": 291,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 779,
          "totalTokens": 1070,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-07-27-58-099819_chatcmpl-19fd8b0e-a97b-431c-9331-035c5d18015d",
          "traceId": "74ca4e3d",
          "type": "GENERATION",
          "name": "74ca_tpusg_gen_attempt#5",
          "startTime": "2025-12-11T05:27:58.099000+00:00",
          "endTime": "2025-12-11T05:28:18.087000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 19988.0,
          "promptTokens": 291,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 1092,
          "totalTokens": 1383,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "cb26cff0-496b-43f6-89b7-b15c7d3e26a3",
          "traceId": "74ca4e3d",
          "type": "SPAN",
          "name": "error_74_tpusg_failure_signal_tpu_sketch_generator",
          "startTime": "2025-12-11T05:28:26.366000+00:00",
          "level": "ERROR",
          "statusMessage": "Failed: Max retries reached with error. Last error: Traceback (most recent call last):\n  File \"script_e81c6840_1765430898.py\", line 5, in <module>\n    from object_detection.protos.string_int_label_map_pb2 import StringIntLabelMap\nModuleNotFoundError: No module named 'object_detection'.",
          "calculatedTotalCost": 0.0,
          "promptTokens": 0,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 0,
          "totalTokens": 0,
          "endTime": null,
          "model": null,
          "modelParameters": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null,
          "latency": null
        }
      ],
      "createdAt": "2025-12-11T05:26:18.838Z",
      "updatedAt": "2025-12-11T05:28:31.520Z",
      "environment": "default"
    },
    {
      "id": "d172633c",
      "timestamp": "2025-12-11T05:23:59.317000+00:00",
      "name": "d172_tpu_sketch_generator",
      "input": null,
      "output": {
        "status": "failed",
        "last_code": "import cv2\nimport numpy as np\nimport tensorflow as tf\nfrom tflite_runtime.interpreter import Interpreter\n\n# Configuration parameters\nmodel_path = '/home/mendel/tinyml_autopilot/models/edgetpu_detect.tflite'\nlabel_path = '/home/mendel/tinyml_autopilot/models/labelmap.txt'\ninput_path = '/home/mendel/tinyml_autopilot/data/sheeps.mp4'\noutput_path = '/home/mendel/tinyml_autopilot/results/sheeps_detections.mp4'\nconfidence_threshold = 0.5\n\n# Phase 1: Setup\ndef load_labels(label_file):\n    with open(label_file, 'r') as file:\n        return [line.strip() for line in file.readlines()]\n\ndef load_interpreter(model_path):\n    interpreter = Interpreter(\n        model_path=model_path,\n        experimental_delegates=[tf.lite.experimental.load_delegate('/usr/lib/aarch64-linux-gnu/libedgetpu.so.1.0')]\n    )\n    interpreter.allocate_tensors()\n    return interpreter\n\ninterpreter = load_interpreter(model_path)\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\n\nlabels = load_labels(label_path)\n\n# Phase 2: Preprocessing\ndef preprocess_frame(frame, input_size):\n    frame_resized = cv2.resize(frame, (input_size[1], input_size[0]))\n    frame_normalized = frame_resized / 255.0\n    return np.expand_dims(frame_normalized, axis=0).astype(np.float32)\n\n# Phase 3: Inference\ndef run_inference(interpreter, frame):\n    interpreter.set_tensor(input_details[0]['index'], preprocess_frame(frame, input_details[0]['shape'][1:3]))\n    interpreter.invoke()\n    \n    boxes = interpreter.get_tensor(output_details[0]['index'])[0]  # Bounding box coordinates of detected objects\n    classes = interpreter.get_tensor(output_details[1]['index'])[0]  # Class index of detected objects\n    scores = interpreter.get_tensor(output_details[2]['index'])[0]   # Confidence of detected objects\n    \n    return boxes, classes, scores\n\n# Phase 4: Output handling\ndef draw_detections(frame, boxes, classes, scores):\n    height, width, _ = frame.shape\n    for i in range(len(scores)):\n        if scores[i] >= confidence_threshold:\n            ymin, xmin, ymax, xmax = boxes[i]\n            (left, right, top, bottom) = (xmin * width, xmax * width,\n                                          ymin * height, ymax * height)\n            left, right, top, bottom = int(left), int(right), int(top), int(bottom)\n\n            cv2.rectangle(frame, (left, top), (right, bottom),\n                          color=(0, 255, 0), thickness=2)\n            text = f'{labels[int(classes[i])]}: {int(scores[i] * 100)}%'\n            cv2.putText(frame, text, (left, top - 10), cv2.FONT_HERSHEY_SIMPLEX,\n                        0.5, (0, 255, 0), 2)\n\ndef main():\n    cap = cv2.VideoCapture(input_path)\n    out = None\n\n    while cap.isOpened():\n        ret, frame = cap.read()\n        if not ret:\n            break\n\n        boxes, classes, scores = run_inference(interpreter, frame)\n        draw_detections(frame, boxes, classes, scores)\n\n        if out is None:\n            fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n            out = cv2.VideoWriter(output_path, fourcc, 30.0, (frame.shape[1], frame.shape[0]))\n\n        out.write(frame)\n\n    cap.release()\n    if out is not None:\n        out.release()\n\nif __name__ == '__main__':\n    main()",
        "last_error": "Max retries reached with error. Last error: Traceback (most recent call last):\n  File \"script_424e9f3c_1765430745.py\", line 3, in <module>\n    import tensorflow as tf\nModuleNotFoundError: No module named 'tensorflow'."
      },
      "session_id": "phi4_a8a2_tpusg_batch",
      "metadata": {
        "num_run": 27
      },
      "tags": [
        "ablation",
        "benchmark",
        "phi4:latest",
        "tpu_sketch_generator"
      ],
      "latency": 113.491,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-07-23-59-317905_chatcmpl-02483aca-1ed4-40ea-bbfd-4539d527f173",
          "traceId": "d172633c",
          "type": "GENERATION",
          "name": "d172_tpusg_gen_attempt#1",
          "startTime": "2025-12-11T05:23:59.317000+00:00",
          "endTime": "2025-12-11T05:24:15.078000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 15761.0,
          "promptTokens": 291,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 861,
          "totalTokens": 1152,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-07-24-23-102587_chatcmpl-8a7186a0-bb4b-4ce4-90b2-eecaddc046d0",
          "traceId": "d172633c",
          "type": "GENERATION",
          "name": "d172_tpusg_gen_attempt#2",
          "startTime": "2025-12-11T05:24:23.102000+00:00",
          "endTime": "2025-12-11T05:24:36.511000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 13409.0,
          "promptTokens": 291,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 737,
          "totalTokens": 1028,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-07-24-44-735480_chatcmpl-c372f8de-bc5b-4166-82b2-f56fb082fb83",
          "traceId": "d172633c",
          "type": "GENERATION",
          "name": "d172_tpusg_gen_attempt#3",
          "startTime": "2025-12-11T05:24:44.735000+00:00",
          "endTime": "2025-12-11T05:24:59.589000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 14854.0,
          "promptTokens": 291,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 816,
          "totalTokens": 1107,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-07-25-07-318725_chatcmpl-8023a84f-d07f-4cdf-ac6c-4dc0da51298a",
          "traceId": "d172633c",
          "type": "GENERATION",
          "name": "d172_tpusg_gen_attempt#4",
          "startTime": "2025-12-11T05:25:07.318000+00:00",
          "endTime": "2025-12-11T05:25:22.561000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 15243.0,
          "promptTokens": 291,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 837,
          "totalTokens": 1128,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-07-25-30-661505_chatcmpl-919070a7-ca8a-49ad-bd12-0f89af9e3ad6",
          "traceId": "d172633c",
          "type": "GENERATION",
          "name": "d172_tpusg_gen_attempt#5",
          "startTime": "2025-12-11T05:25:30.661000+00:00",
          "endTime": "2025-12-11T05:25:45.087000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 14426.0,
          "promptTokens": 291,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 793,
          "totalTokens": 1084,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "1c8afc86-fa49-4492-81fa-096921e12360",
          "traceId": "d172633c",
          "type": "SPAN",
          "name": "error_d1_tpusg_failure_signal_tpu_sketch_generator",
          "startTime": "2025-12-11T05:25:52.808000+00:00",
          "level": "ERROR",
          "statusMessage": "Failed: Max retries reached with error. Last error: Traceback (most recent call last):\n  File \"script_424e9f3c_1765430745.py\", line 3, in <module>\n    import tensorflow as tf\nModuleNotFoundError: No module named 'tensorflow'.",
          "calculatedTotalCost": 0.0,
          "promptTokens": 0,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 0,
          "totalTokens": 0,
          "endTime": null,
          "model": null,
          "modelParameters": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null,
          "latency": null
        }
      ],
      "createdAt": "2025-12-11T05:23:59.832Z",
      "updatedAt": "2025-12-11T05:25:58.057Z",
      "environment": "default"
    },
    {
      "id": "55e15597",
      "timestamp": "2025-12-11T05:21:35.280000+00:00",
      "name": "55e1_tpu_sketch_generator",
      "input": null,
      "output": {
        "status": "failed",
        "last_code": "import cv2\nimport numpy as np\nfrom tflite_runtime.interpreter import Interpreter\nfrom tflite_runtime.load_delegate import load_delegate\n\n# Configuration parameters\nmodel_path = '/home/mendel/tinyml_autopilot/models/edgetpu_detect.tflite'\nlabel_path = '/home/mendel/tinyml_autopilot/models/labelmap.txt'\ninput_path = '/home/mendel/tinyml_autopilot/data/sheeps.mp4'\noutput_path = '/home/mendel/tinyml_autopilot/results/sheeps_detections.mp4'\nconfidence_threshold = 0.5\n\n# Setup: Load the interpreter for TPU\ninterpreter = Interpreter(\n    model_path=model_path,\n    experimental_delegates=[load_delegate('/usr/lib/aarch64-linux-gnu/libedgetpu.so.1.0')]\n)\ninterpreter.allocate_tensors()\n\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\n\n# Read labels from the label map file\nwith open(label_path, 'r') as f:\n    labels = [line.strip() for line in f.readlines()]\n\ndef preprocess_frame(frame):\n    input_shape = input_details[0]['shape']\n    frame_resized = cv2.resize(frame, (input_shape[1], input_shape[2]))\n    input_data = np.expand_dims(frame_resized, axis=0).astype(np.float32)\n    return input_data\n\ndef postprocess(output_data, frame):\n    num_detections = int(output_data[0][0])\n    detections = output_data[0]\n    \n    for i in range(num_detections):\n        score = detections[1 + 5 * i]\n        if score < confidence_threshold:\n            continue\n        \n        ymin, xmin, ymax, xmax = detections[3 + 5 * i:7 + 5 * i] * np.array([frame.shape[0], frame.shape[1], frame.shape[0], frame.shape[1]])\n        (left, right, top, bottom) = (xmin * frame.shape[1], xmax * frame.shape[1], ymin * frame.shape[0], ymax * frame.shape[0])\n        \n        class_id = int(detections[2 + 5 * i])\n        label = f\"{labels[class_id]}: {score:.2f}\"\n        \n        cv2.rectangle(frame, (int(left), int(top)), (int(right), int(bottom)), (0, 255, 0), 2)\n        cv2.putText(frame, label, (int(left), int(top) - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 1)\n\ndef compute_map(detections):\n    # Placeholder for mAP computation logic\n    pass\n\n# Open video input and output files\ncap = cv2.VideoCapture(input_path)\nfourcc = cv2.VideoWriter_fourcc(*'mp4v')\nout = cv2.VideoWriter(output_path, fourcc, 20.0, (int(cap.get(3)), int(cap.get(4))))\n\ndetection_results = []\n\nwhile cap.isOpened():\n    ret, frame = cap.read()\n    if not ret:\n        break\n    \n    # Preprocessing\n    input_data = preprocess_frame(frame)\n    \n    # Inference\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n    interpreter.invoke()\n    output_data = [interpreter.get_tensor(output_detail['index']) for output_detail in output_details]\n    \n    # Postprocessing\n    postprocess(output_data, frame)\n    \n    # Collect detection results for mAP computation (if necessary)\n    detection_results.append(output_data)\n    \n    # Output handling: Write the processed frame to the output video file\n    out.write(frame)\n\n# Compute mean Average Precision (mAP) if needed\ncompute_map(detection_results)\n\ncap.release()\nout.release()\n\ncv2.destroyAllWindows()",
        "last_error": "Max retries reached with error. Last error: Traceback (most recent call last):\n  File \"script_ae719691_1765430606.py\", line 4, in <module>\n    from tflite_runtime.load_delegate import load_delegate\nModuleNotFoundError: No module named 'tflite_runtime.load_delegate'."
      },
      "session_id": "phi4_a8a2_tpusg_batch",
      "metadata": {
        "num_run": 26
      },
      "tags": [
        "ablation",
        "benchmark",
        "phi4:latest",
        "tpu_sketch_generator"
      ],
      "latency": 118.914,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-07-21-35-282517_chatcmpl-322eedcb-d115-4164-b1f7-dd96e0c23524",
          "traceId": "55e15597",
          "type": "GENERATION",
          "name": "55e1_tpusg_gen_attempt#1",
          "startTime": "2025-12-11T05:21:35.282000+00:00",
          "endTime": "2025-12-11T05:21:49.385000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 14103.0,
          "promptTokens": 291,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 760,
          "totalTokens": 1051,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-07-21-57-543210_chatcmpl-1cb5f3bd-33a8-4ad0-ab0c-9a7712170d17",
          "traceId": "55e15597",
          "type": "GENERATION",
          "name": "55e1_tpusg_gen_attempt#2",
          "startTime": "2025-12-11T05:21:57.543000+00:00",
          "endTime": "2025-12-11T05:22:13.056000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 15513.0,
          "promptTokens": 291,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 852,
          "totalTokens": 1143,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-07-22-20-808532_chatcmpl-3ac30a8a-5943-49ee-afb7-d3f470ffa509",
          "traceId": "55e15597",
          "type": "GENERATION",
          "name": "55e1_tpusg_gen_attempt#3",
          "startTime": "2025-12-11T05:22:20.808000+00:00",
          "endTime": "2025-12-11T05:22:40.208000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 19400.0,
          "promptTokens": 291,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 1062,
          "totalTokens": 1353,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-07-22-48-460470_chatcmpl-88c08d3b-b1ee-474f-8f9a-561ad0690dd6",
          "traceId": "55e15597",
          "type": "GENERATION",
          "name": "55e1_tpusg_gen_attempt#4",
          "startTime": "2025-12-11T05:22:48.460000+00:00",
          "endTime": "2025-12-11T05:23:04.029000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 15569.0,
          "promptTokens": 291,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 856,
          "totalTokens": 1147,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-07-23-11-834466_chatcmpl-1972f58f-7a94-4542-8015-df45a439865f",
          "traceId": "55e15597",
          "type": "GENERATION",
          "name": "55e1_tpusg_gen_attempt#5",
          "startTime": "2025-12-11T05:23:11.834000+00:00",
          "endTime": "2025-12-11T05:23:26.271000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 14437.0,
          "promptTokens": 291,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 794,
          "totalTokens": 1085,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "6352d04c-b20e-43f4-9df7-9c58d14c5e0e",
          "traceId": "55e15597",
          "type": "SPAN",
          "name": "error_55_tpusg_failure_signal_tpu_sketch_generator",
          "startTime": "2025-12-11T05:23:34.196000+00:00",
          "level": "ERROR",
          "statusMessage": "Failed: Max retries reached with error. Last error: Traceback (most recent call last):\n  File \"script_ae719691_1765430606.py\", line 4, in <module>\n    from tflite_runtime.load_delegate import load_delegate\nModuleNotFoundError: No module named 'tflite_runtime.load_delegate'.",
          "calculatedTotalCost": 0.0,
          "promptTokens": 0,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 0,
          "totalTokens": 0,
          "endTime": null,
          "model": null,
          "modelParameters": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null,
          "latency": null
        }
      ],
      "createdAt": "2025-12-11T05:21:35.796Z",
      "updatedAt": "2025-12-11T05:23:39.461Z",
      "environment": "default"
    },
    {
      "id": "c24aef25",
      "timestamp": "2025-12-11T05:19:05.385000+00:00",
      "name": "c24a_tpu_sketch_generator",
      "input": null,
      "output": {
        "status": "failed",
        "last_code": "import cv2\nimport numpy as np\nfrom tflite_runtime.interpreter import Interpreter\nfrom edgetpu.basic.edgetpu_utils import MakeEdgeTpuList, AddEdgeTpu\n\n# Configuration parameters\nmodel_path = '/home/mendel/tinyml_autopilot/models/edgetpu_detect.tflite'\nlabel_path = '/home/mendel/tinyml_autopilot/models/labelmap.txt'\ninput_path = '/home/mendel/tinyml_autopilot/data/sheeps.mp4'\noutput_path = '/home/mendel/tinyml_autopilot/results/sheeps_detections.mp4'\nconfidence_threshold = 0.5\n\n# Phase 1: Setup\ndef load_interpreter(model_path):\n    interpreter = Interpreter(\n        model_path=model_path,\n        experimental_delegates=[AddEdgeTpu(MakeEdgeTpuList())]\n    )\n    interpreter.allocate_tensors()\n    return interpreter\n\ninterpreter = load_interpreter(model_path)\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\n\n# Phase 2: Preprocessing\ndef load_labels(label_path):\n    with open(label_path, 'r') as f:\n        labels = {i: line.strip() for i, line in enumerate(f.readlines())}\n    return labels\n\nlabels = load_labels(label_path)\n\ndef preprocess_frame(frame, input_shape):\n    frame_resized = cv2.resize(frame, (input_shape[1], input_shape[0]))\n    input_data = np.expand_dims(frame_resized, axis=0)\n    return input_data\n\n# Phase 3: Inference\ndef run_inference(interpreter, input_data):\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n    interpreter.invoke()\n    boxes = interpreter.get_tensor(output_details[0]['index'])[0] # Bounding box coordinates of detected objects\n    classes = interpreter.get_tensor(output_details[1]['index'])[0] # Class index of detected objects\n    scores = interpreter.get_tensor(output_details[2]['index'])[0] # Confidence of detected objects\n    return boxes, classes, scores\n\n# Phase 4: Output handling\ndef draw_boxes(frame, boxes, classes, scores, labels, confidence_threshold):\n    for i in range(len(scores)):\n        if scores[i] >= confidence_threshold:\n            ymin, xmin, ymax, xmax = boxes[i]\n            (left, right, top, bottom) = (xmin * frame.shape[1], xmax * frame.shape[1],\n                                          ymin * frame.shape[0], ymax * frame.shape[0])\n            cv2.rectangle(frame, (int(left), int(top)), (int(right), int(bottom)), (10, 255, 0), 2)\n            label = f'{labels[int(classes[i])]}: {int(scores[i]*100)}%'\n            cv2.putText(frame, label, (int(left), int(top) - 10),\n                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)\n\ndef compute_mAP(boxes, classes, scores):\n    # This is a placeholder for mAP computation logic.\n    # In practice, you would compare the predictions against ground truth annotations.\n    return \"mAP computation not implemented\"\n\n# Main processing loop\ncap = cv2.VideoCapture(input_path)\nfourcc = cv2.VideoWriter_fourcc(*'mp4v')\nout = cv2.VideoWriter(output_path, fourcc, 20.0, (int(cap.get(3)), int(cap.get(4))))\n\nwhile cap.isOpened():\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    input_data = preprocess_frame(frame, input_details[0]['shape'][1:3])\n    boxes, classes, scores = run_inference(interpreter, input_data)\n    \n    draw_boxes(frame, boxes, classes, scores, labels, confidence_threshold)\n\n    out.write(frame)\n\ncap.release()\nout.release()\n\n# Compute mAP (placeholder call)\nmAP_result = compute_mAP(None, None, None)  # Replace with actual data for real computation\nprint(f\"Mean Average Precision: {mAP_result}\")",
        "last_error": "Max retries reached with error. Last error: Traceback (most recent call last):\n  File \"script_229274ec_1765430460.py\", line 4, in <module>\n    from edgetpu.basic.edgetpu_utils import MakeEdgeTpuList, AddEdgeTpu\nImportError: cannot import name 'MakeEdgeTpuList' from 'edgetpu.basic.edgetpu_utils' (/home/mendel/.local/lib/python3.7/site-packages/edgetpu/basic/edgetpu_utils.py)."
      },
      "session_id": "phi4_a8a2_tpusg_batch",
      "metadata": {
        "num_run": 25
      },
      "tags": [
        "ablation",
        "benchmark",
        "phi4:latest",
        "tpu_sketch_generator"
      ],
      "latency": 123.29,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-07-19-05-386379_chatcmpl-006dbf5f-6abf-4b88-8101-80c15a55e9c2",
          "traceId": "c24aef25",
          "type": "GENERATION",
          "name": "c24a_tpusg_gen_attempt#1",
          "startTime": "2025-12-11T05:19:05.386000+00:00",
          "endTime": "2025-12-11T05:19:20.722000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 15336.0,
          "promptTokens": 291,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 838,
          "totalTokens": 1129,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-07-19-28-477737_chatcmpl-a435cf1e-854a-46bf-88ee-f91fb7879695",
          "traceId": "c24aef25",
          "type": "GENERATION",
          "name": "c24a_tpusg_gen_attempt#2",
          "startTime": "2025-12-11T05:19:28.477000+00:00",
          "endTime": "2025-12-11T05:19:45.002000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 16525.0,
          "promptTokens": 291,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 907,
          "totalTokens": 1198,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-07-19-53-503954_chatcmpl-857d91d9-aa5f-40e6-a9f2-2d5c87c88e54",
          "traceId": "c24aef25",
          "type": "GENERATION",
          "name": "c24a_tpusg_gen_attempt#3",
          "startTime": "2025-12-11T05:19:53.503000+00:00",
          "endTime": "2025-12-11T05:20:10.410000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 16907.0,
          "promptTokens": 291,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 927,
          "totalTokens": 1218,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-07-20-18-572389_chatcmpl-be1024c4-f089-48f5-ba2d-c116c31f9ef1",
          "traceId": "c24aef25",
          "type": "GENERATION",
          "name": "c24a_tpusg_gen_attempt#4",
          "startTime": "2025-12-11T05:20:18.572000+00:00",
          "endTime": "2025-12-11T05:20:36.127000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 17555.0,
          "promptTokens": 291,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 962,
          "totalTokens": 1253,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-07-20-43-939201_chatcmpl-e23f6967-05b2-4c7e-9802-035dc5c58ded",
          "traceId": "c24aef25",
          "type": "GENERATION",
          "name": "c24a_tpusg_gen_attempt#5",
          "startTime": "2025-12-11T05:20:43.939000+00:00",
          "endTime": "2025-12-11T05:21:00.890000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 16951.0,
          "promptTokens": 291,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 930,
          "totalTokens": 1221,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "d24d1ebe-b578-4193-89f4-d375a58f0e71",
          "traceId": "c24aef25",
          "type": "SPAN",
          "name": "error_c2_tpusg_failure_signal_tpu_sketch_generator",
          "startTime": "2025-12-11T05:21:08.676000+00:00",
          "level": "ERROR",
          "statusMessage": "Failed: Max retries reached with error. Last error: Traceback (most recent call last):\n  File \"script_229274ec_1765430460.py\", line 4, in <module>\n    from edgetpu.basic.edgetpu_utils import MakeEdgeTpuList, AddEdgeTpu\nImportError: cannot import name 'MakeEdgeTpuList' from 'edgetpu.basic.edgetpu_utils' (/home/mendel/.local/lib/python3.7/site-packages/edgetpu/basic/edgetpu_utils.py).",
          "calculatedTotalCost": 0.0,
          "promptTokens": 0,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 0,
          "totalTokens": 0,
          "endTime": null,
          "model": null,
          "modelParameters": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null,
          "latency": null
        }
      ],
      "createdAt": "2025-12-11T05:19:05.900Z",
      "updatedAt": "2025-12-11T05:21:14.121Z",
      "environment": "default"
    },
    {
      "id": "80128fdc",
      "timestamp": "2025-12-11T05:16:38.415000+00:00",
      "name": "8012_tpu_sketch_generator",
      "input": null,
      "output": {
        "status": "failed",
        "last_code": "import cv2\nimport numpy as np\nfrom tflite_runtime.interpreter import Interpreter\nfrom tflite_runtime.interpreter import load_delegate\nfrom tqdm import tqdm\n\n# Configuration parameters\nmodel_path = '/home/mendel/tinyml_autopilot/models/edgetpu_detect.tflite'\nlabel_path = '/home/mendel/tinyml_autopilot/models/labelmap.txt'\ninput_path = '/home/mendel/tinyml_autopilot/data/sheeps.mp4'\noutput_path = '/home/mendel/tinyml_autopilot/results/sheeps_detections.mp4'\nconfidence_threshold = 0.5\n\n# Phase 1: Setup\ndef load_labels(path):\n    with open(path, 'r', encoding='utf-8') as f:\n        lines = f.readlines()\n        labels = {}\n        for row_number, content in enumerate(lines):\n            pair = content.strip().split(maxsplit=1)\n            if len(pair) == 2 and pair[0].strip().isdigit():\n                labels[int(pair[0])] = pair[1].strip()\n    return labels\n\ndef load_interpreter(model_path):\n    interpreter = Interpreter(\n        model_path=model_path,\n        experimental_delegates=[load_delegate('/usr/lib/aarch64-linux-gnu/libedgetpu.so.1.0')]\n    )\n    interpreter.allocate_tensors()\n    return interpreter\n\n# Phase 2: Preprocessing\ndef set_input_tensor(interpreter, image):\n    tensor_index = interpreter.get_input_details()[0]['index']\n    input_shape = interpreter.get_input_details()[tensor_index]['shape']\n\n    # Resize the image to match the model's expected size\n    image = cv2.resize(image, (input_shape[1], input_shape[2]))\n    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n    \n    input_tensor = np.expand_dims(image, axis=0).astype(np.float32)\n    interpreter.set_tensor(tensor_index, input_tensor)\n\n# Phase 3: Inference\ndef get_output(interpreter):\n    boxes = interpreter.get_tensor(interpreter.get_output_details()[0]['index'])[0] # Bounding box coordinates of detected objects\n    classes = interpreter.get_tensor(interpreter.get_output_details()[1]['index'])[0] # Class index of detected objects\n    scores = interpreter.get_tensor(interpreter.get_output_details()[2]['index'])[0] # Confidence of detected objects\n    count = int(interpreter.get_tensor(interpreter.get_output_details()[3]['index'])[0]) # Number of objects detected\n    return boxes, classes, scores, count\n\n# Phase 4: Output handling\ndef draw_box_with_label(img, box, label, score):\n    ymin, xmin, ymax, xmax = box\n    (left, right, top, bottom) = (xmin * img.shape[1], xmax * img.shape[1],\n                                  ymin * img.shape[0], ymax * img.shape[0])\n    \n    cv2.rectangle(img, (int(left), int(top)), (int(right), int(bottom)), color=(10, 255, 0), thickness=3)\n    label_str = '{}: {}%'.format(label, int(score * 100))\n    cv2.putText(img, label_str, (int(left), int(top) - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)\n\ndef main():\n    labels = load_labels(label_path)\n    interpreter = load_interpreter(model_path)\n    \n    # Open video input\n    cap = cv2.VideoCapture(input_path)\n    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n    fps = int(cap.get(cv2.CAP_PROP_FPS))\n\n    # Prepare video writer\n    out = cv2.VideoWriter(output_path, cv2.VideoWriter_fourcc(*'mp4v'), fps, (width, height))\n    \n    while cap.isOpened():\n        ret, frame = cap.read()\n        if not ret:\n            break\n\n        set_input_tensor(interpreter, frame)\n        interpreter.invoke()\n        boxes, classes, scores, count = get_output(interpreter)\n\n        for i in range(count):\n            if scores[i] >= confidence_threshold:\n                ymin, xmin, ymax, xmax = boxes[i]\n                class_id = int(classes[i])\n                label = labels.get(class_id, 'N/A')\n                \n                draw_box_with_label(frame, (ymin, xmin, ymax, xmax), label, scores[i])\n\n        out.write(frame)\n\n    cap.release()\n    out.release()\n\nif __name__ == '__main__':\n    main()",
        "last_error": "Max retries reached with error. Last error: Traceback (most recent call last):\n  File \"script_75b052d8_1765430311.py\", line 5, in <module>\n    from tqdm import tqdm\nModuleNotFoundError: No module named 'tqdm'."
      },
      "session_id": "phi4_a8a2_tpusg_batch",
      "metadata": {
        "num_run": 24
      },
      "tags": [
        "ablation",
        "benchmark",
        "phi4:latest",
        "tpu_sketch_generator"
      ],
      "latency": 121.37,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-07-16-38-417343_chatcmpl-3ace3ea5-c736-434a-84c3-53924e30c213",
          "traceId": "80128fdc",
          "type": "GENERATION",
          "name": "8012_tpusg_gen_attempt#1",
          "startTime": "2025-12-11T05:16:38.417000+00:00",
          "endTime": "2025-12-11T05:16:54.289000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 15872.0,
          "promptTokens": 291,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 865,
          "totalTokens": 1156,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-07-17-02-579127_chatcmpl-16e994f8-5a61-47d8-bf0b-f4fedd9384bb",
          "traceId": "80128fdc",
          "type": "GENERATION",
          "name": "8012_tpusg_gen_attempt#2",
          "startTime": "2025-12-11T05:17:02.579000+00:00",
          "endTime": "2025-12-11T05:17:16.016000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 13437.0,
          "promptTokens": 291,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 739,
          "totalTokens": 1030,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-07-17-23-714334_chatcmpl-9b5b28cf-a5a8-4c81-a770-fe44135f092c",
          "traceId": "80128fdc",
          "type": "GENERATION",
          "name": "8012_tpusg_gen_attempt#3",
          "startTime": "2025-12-11T05:17:23.714000+00:00",
          "endTime": "2025-12-11T05:17:40.981000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 17267.0,
          "promptTokens": 291,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 948,
          "totalTokens": 1239,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-07-17-49-216928_chatcmpl-bc2a07b3-130d-4ad9-a7f8-df4d767f959a",
          "traceId": "80128fdc",
          "type": "GENERATION",
          "name": "8012_tpusg_gen_attempt#4",
          "startTime": "2025-12-11T05:17:49.216000+00:00",
          "endTime": "2025-12-11T05:18:05.989000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 16773.0,
          "promptTokens": 291,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 920,
          "totalTokens": 1211,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-07-18-14-261533_chatcmpl-191921aa-cad1-4d62-a5e0-9ab199fc0b43",
          "traceId": "80128fdc",
          "type": "GENERATION",
          "name": "8012_tpusg_gen_attempt#5",
          "startTime": "2025-12-11T05:18:14.261000+00:00",
          "endTime": "2025-12-11T05:18:31.729000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 17468.0,
          "promptTokens": 291,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 958,
          "totalTokens": 1249,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "93a4440f-9780-4dc9-8592-73ac4fdf7946",
          "traceId": "80128fdc",
          "type": "SPAN",
          "name": "error_80_tpusg_failure_signal_tpu_sketch_generator",
          "startTime": "2025-12-11T05:18:39.787000+00:00",
          "level": "ERROR",
          "statusMessage": "Failed: Max retries reached with error. Last error: Traceback (most recent call last):\n  File \"script_75b052d8_1765430311.py\", line 5, in <module>\n    from tqdm import tqdm\nModuleNotFoundError: No module named 'tqdm'.",
          "calculatedTotalCost": 0.0,
          "promptTokens": 0,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 0,
          "totalTokens": 0,
          "endTime": null,
          "model": null,
          "modelParameters": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null,
          "latency": null
        }
      ],
      "createdAt": "2025-12-11T05:16:38.932Z",
      "updatedAt": "2025-12-11T05:18:45.179Z",
      "environment": "default"
    },
    {
      "id": "dfe0f2c5",
      "timestamp": "2025-12-11T05:13:50.420000+00:00",
      "name": "dfe0_tpu_sketch_generator",
      "input": null,
      "output": {
        "status": "success",
        "sketch": "import cv2\nimport numpy as np\nfrom tflite_runtime.interpreter import Interpreter\nfrom tflite_runtime.interpreter import load_delegate\n\ndef load_labels(label_path):\n    with open(label_path, 'r') as file:\n        labels = [line.strip() for line in file.readlines()]\n    return labels\n\ndef set_input_tensor(interpreter, image):\n    tensor_index = interpreter.get_input_details()[0]['index']\n    input_shape = interpreter.get_input_details()[0]['shape']\n    image = cv2.resize(image, (input_shape[1], input_shape[2]))\n    image = np.expand_dims(image, axis=0)\n    interpreter.set_tensor(tensor_index, image)\n\ndef get_output(interpreter):\n    boxes = interpreter.get_tensor(\n        interpreter.get_output_details()[0]['index'])[0]\n    classes = interpreter.get_tensor(\n        interpreter.get_output_details()[1]['index'])[0]\n    scores = interpreter.get_tensor(\n        interpreter.get_output_details()[2]['index'])[0]\n    count = int(interpreter.get_tensor(\n        interpreter.get_output_details()[3]['index'])[0])\n    return boxes, classes, scores, count\n\ndef draw_detections(image, boxes, classes, scores, labels, confidence_threshold):\n    for i in range(len(scores)):\n        if scores[i] >= confidence_threshold:\n            ymin, xmin, ymax, xmax = boxes[i]\n            (left, right, top, bottom) = (xmin * image.shape[1], xmax * image.shape[1],\n                                          ymin * image.shape[0], ymax * image.shape[0])\n            cv2.rectangle(image, (int(left), int(top)), (int(right), int(bottom)), (10, 255, 0), 2)\n            label = f'{labels[int(classes[i])]}: {int(scores[i]*100)}%'\n            labelSize, baseLine = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.7, 2)\n            top = max(top, labelSize[1])\n            cv2.rectangle(image, (int(left), int(top - round(1.5*labelSize[1]))),\n                          (int(left + round(1.5*labelSize[0])), int(top + baseLine)),\n                          (255, 255, 255), cv2.FILLED)\n            cv2.putText(image, label, (int(left), int(top)), cv2.FONT_HERSHEY_SIMPLEX,\n                        0.7, (0, 0, 0), 2)\n    return image\n\ndef main():\n    model_path = '/home/mendel/tinyml_autopilot/models/edgetpu_detect.tflite'\n    label_path = '/home/mendel/tinyml_autopilot/models/labelmap.txt'\n    input_path = '/home/mendel/tinyml_autopilot/data/sheeps.mp4'\n    output_path = '/home/mendel/tinyml_autopilot/results/sheeps_detections.mp4'\n    confidence_threshold = 0.5\n\n    # Load labels\n    labels = load_labels(label_path)\n\n    # Setup TFLite interpreter with Coral Edge TPU delegate\n    interpreter = Interpreter(\n        model_path=model_path,\n        experimental_delegates=[load_delegate('/usr/lib/aarch64-linux-gnu/libedgetpu.so.1.0')]\n    )\n    interpreter.allocate_tensors()\n    \n    # Open video file and prepare output writer\n    cap = cv2.VideoCapture(input_path)\n    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n    out = cv2.VideoWriter(output_path, fourcc, 20.0, (int(cap.get(3)), int(cap.get(4))))\n\n    while cap.isOpened():\n        ret, frame = cap.read()\n        if not ret:\n            break\n\n        # Preprocessing\n        set_input_tensor(interpreter, frame)\n\n        # Inference\n        interpreter.invoke()\n\n        # Get output and process it\n        boxes, classes, scores, count = get_output(interpreter)\n        frame = draw_detections(frame, boxes, classes, scores, labels, confidence_threshold)\n\n        # Write the frame with detections to the output video file\n        out.write(frame)\n\n    cap.release()\n    out.release()\n\nif __name__ == '__main__':\n    main()"
      },
      "session_id": "phi4_a8a2_tpusg_batch",
      "metadata": {
        "num_run": 23
      },
      "tags": [
        "ablation",
        "benchmark",
        "phi4:latest",
        "tpu_sketch_generator"
      ],
      "latency": 89.893,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-07-13-50-421648_chatcmpl-fc9cc1ed-893a-4eee-82cb-5265f83f610c",
          "traceId": "dfe0f2c5",
          "type": "GENERATION",
          "name": "dfe0_tpusg_gen_attempt#1",
          "startTime": "2025-12-11T05:13:50.421000+00:00",
          "endTime": "2025-12-11T05:14:05.253000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 14832.0,
          "promptTokens": 291,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 811,
          "totalTokens": 1102,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-07-14-13-014792_chatcmpl-f37c5caa-404f-406f-9027-747e72e4ec3d",
          "traceId": "dfe0f2c5",
          "type": "GENERATION",
          "name": "dfe0_tpusg_gen_attempt#2",
          "startTime": "2025-12-11T05:14:13.014000+00:00",
          "endTime": "2025-12-11T05:14:32.578000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 19564.0,
          "promptTokens": 291,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 1070,
          "totalTokens": 1361,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-07-14-40-572172_chatcmpl-96a71dc9-35d8-43fb-84af-b7f6fde4e71f",
          "traceId": "dfe0f2c5",
          "type": "GENERATION",
          "name": "dfe0_tpusg_gen_attempt#3",
          "startTime": "2025-12-11T05:14:40.572000+00:00",
          "endTime": "2025-12-11T05:14:55.861000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 15289.0,
          "promptTokens": 291,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 840,
          "totalTokens": 1131,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-07-15-04-279859_chatcmpl-37dd1fc5-8986-45ee-9e35-52a4b6812f62",
          "traceId": "dfe0f2c5",
          "type": "GENERATION",
          "name": "dfe0_tpusg_gen_attempt#4",
          "startTime": "2025-12-11T05:15:04.279000+00:00",
          "endTime": "2025-12-11T05:15:20.314000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 16035.0,
          "promptTokens": 291,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 881,
          "totalTokens": 1172,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        }
      ],
      "createdAt": "2025-12-11T05:13:50.936Z",
      "updatedAt": "2025-12-11T05:16:18.753Z",
      "environment": "default"
    },
    {
      "id": "0bdd4865",
      "timestamp": "2025-12-11T05:11:51.505000+00:00",
      "name": "0bdd_tpu_sketch_generator",
      "input": null,
      "output": {
        "status": "success",
        "sketch": "import cv2\nimport numpy as np\nimport tflite_runtime.interpreter as tflite\nfrom tflite_runtime.interpreter import load_delegate\n\n# Configuration parameters\nmodel_path = '/home/mendel/tinyml_autopilot/models/edgetpu_detect.tflite'\nlabel_path = '/home/mendel/tinyml_autopilot/models/labelmap.txt'\ninput_path = '/home/mendel/tinyml_autopilot/data/sheeps.mp4'\noutput_path = '/home/mendel/tinyml_autopilot/results/sheeps_detections.mp4'\nconfidence_threshold = 0.5\n\n# Load labels from label map file\nwith open(label_path, 'r') as f:\n    labels = [line.strip() for line in f.readlines()]\n\n# Setup: Load the TFLite interpreter with Edge TPU delegate\ninterpreter = tflite.Interpreter(\n    model_path=model_path,\n    experimental_delegates=[load_delegate('/usr/lib/aarch64-linux-gnu/libedgetpu.so.1.0')]\n)\n\n# Allocate tensors and get input details\ninterpreter.allocate_tensors()\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\n\n# Preprocessing: Read video input\ncap = cv2.VideoCapture(input_path)\nframe_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\nframe_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\nfps = cap.get(cv2.CAP_PROP_FPS)\n\n# Define the codec and create VideoWriter object\nfourcc = cv2.VideoWriter_fourcc(*'mp4v')\nout = cv2.VideoWriter(output_path, fourcc, fps, (frame_width, frame_height))\n\ndef preprocess_frame(frame):\n    # Resize frame to model's input size\n    input_size = input_details[0]['shape'][1:3]\n    frame_resized = cv2.resize(frame, (input_size[1], input_size[0]))\n    return np.expand_dims(frame_resized, axis=0)\n\ndef draw_detections(frame, detections):\n    for detection in detections:\n        ymin, xmin, ymax, xmax = detection['bbox']\n        class_id = int(detection['class_id'])\n        score = float(detection['score'])\n\n        # Convert normalized coordinates to pixel values\n        (left, right, top, bottom) = (xmin * frame.shape[1], xmax * frame.shape[1],\n                                      ymin * frame.shape[0], ymax * frame.shape[0])\n\n        left, right, top, bottom = int(left), int(right), int(top), int(bottom)\n\n        # Draw rectangle and label\n        cv2.rectangle(frame, (left, top), (right, bottom), (0, 255, 0), 2)\n        text = f'{labels[class_id]}: {score:.2f}'\n        cv2.putText(frame, text, (left, top - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n\ndef postprocess(output_data):\n    # Parse the output data to extract detections\n    boxes = np.squeeze(output_data[0])\n    classes = np.squeeze(output_data[1])\n    scores = np.squeeze(output_data[2])\n\n    detections = []\n    for i in range(len(scores)):\n        if scores[i] >= confidence_threshold:\n            detection = {\n                'bbox': [\n                    boxes[i][0],  # ymin\n                    boxes[i][1],  # xmin\n                    boxes[i][2],  # ymax\n                    boxes[i][3]   # xmax\n                ],\n                'class_id': int(classes[i]),\n                'score': scores[i]\n            }\n            detections.append(detection)\n    return detections\n\nwhile cap.isOpened():\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    # Preprocessing: Prepare the input tensor\n    preprocessed_frame = preprocess_frame(frame)\n    interpreter.set_tensor(input_details[0]['index'], preprocessed_frame)\n\n    # Inference\n    interpreter.invoke()\n\n    # Postprocessing: Get output data and draw detections\n    boxes = interpreter.get_tensor(output_details[0]['index'])\n    classes = interpreter.get_tensor(output_details[1]['index'])\n    scores = interpreter.get_tensor(output_details[2]['index'])\n\n    detections = postprocess([boxes, classes, scores])\n    draw_detections(frame, detections)\n\n    # Output handling: Write frame to output video\n    out.write(frame)\n\n# Release resources\ncap.release()\nout.release()\ncv2.destroyAllWindows()"
      },
      "session_id": "phi4_a8a2_tpusg_batch",
      "metadata": {
        "num_run": 22
      },
      "tags": [
        "ablation",
        "benchmark",
        "phi4:latest",
        "tpu_sketch_generator"
      ],
      "latency": 40.419,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-07-11-51-506607_chatcmpl-5a5b903e-1e83-4411-96e4-319fc0cc6610",
          "traceId": "0bdd4865",
          "type": "GENERATION",
          "name": "0bdd_tpusg_gen_attempt#1",
          "startTime": "2025-12-11T05:11:51.506000+00:00",
          "endTime": "2025-12-11T05:12:06.043000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 14537.0,
          "promptTokens": 291,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 795,
          "totalTokens": 1086,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-07-12-13-859655_chatcmpl-d1f8b07e-5f68-4003-b762-f5a857b5e32f",
          "traceId": "0bdd4865",
          "type": "GENERATION",
          "name": "0bdd_tpusg_gen_attempt#2",
          "startTime": "2025-12-11T05:12:13.859000+00:00",
          "endTime": "2025-12-11T05:12:31.925000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 18066.0,
          "promptTokens": 291,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 990,
          "totalTokens": 1281,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        }
      ],
      "createdAt": "2025-12-11T05:11:52.021Z",
      "updatedAt": "2025-12-11T05:13:30.232Z",
      "environment": "default"
    },
    {
      "id": "c6ffe159",
      "timestamp": "2025-12-11T05:09:15.499000+00:00",
      "name": "c6ff_tpu_sketch_generator",
      "input": null,
      "output": {
        "status": "failed",
        "last_code": "import cv2\nimport numpy as np\nimport tflite_runtime.interpreter as tflite\nfrom PIL import Image\nfrom google.protobuf import text_format\nfrom object_detection.utils import label_map_util\nfrom object_detection.utils import visualization_utils as vis_util\n\n# Configuration parameters\nmodel_path = '/home/mendel/tinyml_autopilot/models/edgetpu_detect.tflite'\nlabel_path = '/home/mendel/tinyml_autopilot/models/labelmap.txt'\ninput_path = '/home/mendel/tinyml_autopilot/data/sheeps.mp4'\noutput_path = '/home/mendel/tinyml_autopilot/results/sheeps_detections.mp4'\nconfidence_threshold = 0.5\n\n# Phase 1: Setup\ndef load_interpreter():\n    # Load TFLite model and allocate tensors.\n    interpreter = tflite.Interpreter(\n        model_path=model_path,\n        experimental_delegates=[tflite.load_delegate('/usr/lib/aarch64-linux-gnu/libedgetpu.so.1.0')]\n    )\n    interpreter.allocate_tensors()\n    return interpreter\n\n# Phase 2: Preprocessing\ndef load_labels(label_file):\n    with open(label_file, 'r') as file:\n        labels = [line.strip() for line in file.readlines()]\n    return labels\n\ndef preprocess_frame(frame, input_size):\n    frame_resized = cv2.resize(frame, (input_size[1], input_size[0]))\n    frame_rgb = cv2.cvtColor(frame_resized, cv2.COLOR_BGR2RGB)\n    return np.expand_dims(frame_rgb, axis=0)\n\n# Phase 3: Inference\ndef run_inference(interpreter, frame):\n    input_details = interpreter.get_input_details()\n    output_details = interpreter.get_output_details()\n\n    input_shape = input_details[0]['shape']\n    interpreter.set_tensor(input_details[0]['index'], frame)\n    interpreter.invoke()\n\n    boxes = interpreter.get_tensor(output_details[0]['index'])[0]\n    classes = interpreter.get_tensor(output_details[1]['index'])[0]\n    scores = interpreter.get_tensor(output_details[2]['index'])[0]\n\n    return boxes, classes, scores\n\n# Phase 4: Output Handling\ndef draw_boxes(frame, boxes, classes, scores, labels):\n    height, width, _ = frame.shape\n    for i in range(len(scores)):\n        if scores[i] >= confidence_threshold:\n            ymin, xmin, ymax, xmax = boxes[i]\n            (left, right, top, bottom) = (xmin * width, xmax * width,\n                                          ymin * height, ymax * height)\n            object_name = labels[int(classes[i])]\n            vis_util.draw_bounding_box_on_image_array(\n                frame,\n                int(left),\n                int(top),\n                int(right),\n                int(bottom),\n                color='red',\n                thickness=4,\n                display_str_list=[object_name],\n                use_normalized_coordinates=True\n            )\n    return frame\n\ndef main():\n    # Setup\n    interpreter = load_interpreter()\n    input_details = interpreter.get_input_details()\n    input_size = input_details[0]['shape'][1:3]\n    labels = load_labels(label_path)\n\n    # Video processing\n    cap = cv2.VideoCapture(input_path)\n    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n    out = cv2.VideoWriter(output_path, fourcc, 20.0, (int(cap.get(3)), int(cap.get(4))))\n\n    while cap.isOpened():\n        ret, frame = cap.read()\n        if not ret:\n            break\n\n        # Preprocess\n        preprocessed_frame = preprocess_frame(frame, input_size)\n\n        # Inference\n        boxes, classes, scores = run_inference(interpreter, preprocessed_frame)\n\n        # Draw boxes and labels on the frame\n        output_frame = draw_boxes(frame.copy(), boxes, classes, scores, labels)\n\n        # Write the frame with detections to output video\n        out.write(output_frame)\n\n    cap.release()\n    out.release()\n\nif __name__ == '__main__':\n    main()",
        "last_error": "Max retries reached with error. Last error: Traceback (most recent call last):\n  File \"script_7decee0d_1765429877.py\", line 6, in <module>\n    from object_detection.utils import label_map_util\nModuleNotFoundError: No module named 'object_detection'."
      },
      "session_id": "phi4_a8a2_tpusg_batch",
      "metadata": {
        "num_run": 21
      },
      "tags": [
        "ablation",
        "benchmark",
        "phi4:latest",
        "tpu_sketch_generator"
      ],
      "latency": 130.091,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-07-09-15-501038_chatcmpl-9db5c924-63ea-4fde-9984-bda69a254e99",
          "traceId": "c6ffe159",
          "type": "GENERATION",
          "name": "c6ff_tpusg_gen_attempt#1",
          "startTime": "2025-12-11T05:09:15.501000+00:00",
          "endTime": "2025-12-11T05:09:29.333000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 13832.0,
          "promptTokens": 291,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 757,
          "totalTokens": 1048,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-07-09-37-618372_chatcmpl-5f98c35a-d0e0-48ea-836a-a68b0e690738",
          "traceId": "c6ffe159",
          "type": "GENERATION",
          "name": "c6ff_tpusg_gen_attempt#2",
          "startTime": "2025-12-11T05:09:37.618000+00:00",
          "endTime": "2025-12-11T05:09:53.854000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 16236.0,
          "promptTokens": 291,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 891,
          "totalTokens": 1182,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-07-10-02-017512_chatcmpl-89decae2-40c8-407b-b5f7-d7e5e72c5e87",
          "traceId": "c6ffe159",
          "type": "GENERATION",
          "name": "c6ff_tpusg_gen_attempt#3",
          "startTime": "2025-12-11T05:10:02.017000+00:00",
          "endTime": "2025-12-11T05:10:29.294000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 27277.0,
          "promptTokens": 291,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 1482,
          "totalTokens": 1773,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-07-10-37-803075_chatcmpl-3e11c803-e610-46ae-9425-569bbc279f13",
          "traceId": "c6ffe159",
          "type": "GENERATION",
          "name": "c6ff_tpusg_gen_attempt#4",
          "startTime": "2025-12-11T05:10:37.803000+00:00",
          "endTime": "2025-12-11T05:10:52.632000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 14829.0,
          "promptTokens": 291,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 815,
          "totalTokens": 1106,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-07-11-01-043099_chatcmpl-507677cc-64c6-45da-8b30-9e25a609b1fd",
          "traceId": "c6ffe159",
          "type": "GENERATION",
          "name": "c6ff_tpusg_gen_attempt#5",
          "startTime": "2025-12-11T05:11:01.043000+00:00",
          "endTime": "2025-12-11T05:11:17.359000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 16316.0,
          "promptTokens": 291,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 896,
          "totalTokens": 1187,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "3109e39c-6f8a-4554-8d44-11613ae076ff",
          "traceId": "c6ffe159",
          "type": "SPAN",
          "name": "error_c6_tpusg_failure_signal_tpu_sketch_generator",
          "startTime": "2025-12-11T05:11:25.592000+00:00",
          "level": "ERROR",
          "statusMessage": "Failed: Max retries reached with error. Last error: Traceback (most recent call last):\n  File \"script_7decee0d_1765429877.py\", line 6, in <module>\n    from object_detection.utils import label_map_util\nModuleNotFoundError: No module named 'object_detection'.",
          "calculatedTotalCost": 0.0,
          "promptTokens": 0,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 0,
          "totalTokens": 0,
          "endTime": null,
          "model": null,
          "modelParameters": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null,
          "latency": null
        }
      ],
      "createdAt": "2025-12-11T05:09:16.016Z",
      "updatedAt": "2025-12-11T05:11:30.697Z",
      "environment": "default"
    },
    {
      "id": "851d2c7f",
      "timestamp": "2025-12-11T05:06:57.538000+00:00",
      "name": "851d_tpu_sketch_generator",
      "input": null,
      "output": {
        "status": "failed",
        "last_code": "import cv2\nimport numpy as np\nimport edgetpu.detection.engine\nfrom tflite_runtime.interpreter import Interpreter\n\n# Configuration parameters\nmodel_path = '/home/mendel/tinyml_autopilot/models/edgetpu_detect.tflite'\nlabel_path = '/home/mendel/tinyml_autopilot/models/labelmap.txt'\ninput_path = '/home/mendel/tinyml_autopilot/data/sheeps.mp4'\noutput_path = '/home/mendel/tinyml_autopilot/results/sheeps_detections.mp4'\nconfidence_threshold = 0.5\n\n# Phase 1: Setup\ndef load_labels(label_path):\n    with open(label_path, 'r', encoding='utf-8') as f:\n        lines = f.readlines()\n    return [line.strip() for line in lines]\n\nlabels = load_labels(label_path)\ndetection_engine = edgetpu.detection.engine.DetectionEngine(model_path)\n\n# Phase 2: Preprocessing\ndef preprocess_frame(frame):\n    input_tensor = detection_engine.get_input_tensor()\n    height, width, channel = input_tensor.shape\n    frame_resized = cv2.resize(frame, (width, height))\n    frame_rgb = cv2.cvtColor(frame_resized, cv2.COLOR_BGR2RGB)\n    return np.expand_dims(frame_rgb, axis=0)\n\n# Phase 3: Inference and output handling\ndef postprocess_and_draw_boxes(detections, frame):\n    for detection in detections:\n        if detection.score < confidence_threshold:\n            continue\n        ymin, xmin, ymax, xmax = detection.bounding_box.flatten().tolist()\n        left, right, top, bottom = int(xmin * frame.shape[1]), int(xmax * frame.shape[1]), int(ymin * frame.shape[0]), int(ymax * frame.shape[0])\n        \n        cv2.rectangle(frame, (left, top), (right, bottom), (0, 255, 0), 2)\n        \n        label = f\"{labels[detection.label_id]}: {int(detection.score * 100)}%\"\n        cv2.putText(frame, label, (left, top - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n\ndef process_video(input_path, output_path):\n    cap = cv2.VideoCapture(input_path)\n    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n    out = None\n\n    while cap.isOpened():\n        ret, frame = cap.read()\n        if not ret:\n            break\n        \n        processed_frame = preprocess_frame(frame)\n        \n        detections = detection_engine.detect_with_input_tensor(processed_frame, threshold=confidence_threshold, keep_aspect_ratio=True, relative_coord=False, top_k=10)\n        \n        postprocess_and_draw_boxes(detections, frame)\n\n        if out is None:\n            height, width = frame.shape[:2]\n            out = cv2.VideoWriter(output_path, fourcc, 30.0, (width, height))\n\n        out.write(frame)\n\n    cap.release()\n    if out is not None:\n        out.release()\n\n# Run the pipeline\nprocess_video(input_path, output_path)",
        "last_error": "Max retries reached with error. Last error: Traceback (most recent call last):\n  File \"script_aa552595_1765429722.py\", line 70, in <module>\n    process_video(input_path, output_path)\n  File \"script_aa552595_1765429722.py\", line 53, in process_video\n    processed_frame = preprocess_frame(frame)\n  File \"script_aa552595_1765429722.py\", line 24, in preprocess_frame\n    input_tensor = detection_engine.get_input_tensor()\nAttributeError: 'DetectionEngine' object has no attribute 'get_input_tensor'."
      },
      "session_id": "phi4_a8a2_tpusg_batch",
      "metadata": {
        "num_run": 20
      },
      "tags": [
        "ablation",
        "benchmark",
        "phi4:latest",
        "tpu_sketch_generator"
      ],
      "latency": 113.954,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-07-06-57-539648_chatcmpl-34aa0be1-66bc-4e3b-81c2-6968200060a6",
          "traceId": "851d2c7f",
          "type": "GENERATION",
          "name": "851d_tpusg_gen_attempt#1",
          "startTime": "2025-12-11T05:06:57.539000+00:00",
          "endTime": "2025-12-11T05:07:11.926000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 14387.0,
          "promptTokens": 291,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 785,
          "totalTokens": 1076,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-07-07-20-146335_chatcmpl-5aa24a55-2105-412a-8f39-238b8ba183b9",
          "traceId": "851d2c7f",
          "type": "GENERATION",
          "name": "851d_tpusg_gen_attempt#2",
          "startTime": "2025-12-11T05:07:20.146000+00:00",
          "endTime": "2025-12-11T05:07:38.071000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 17925.0,
          "promptTokens": 291,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 982,
          "totalTokens": 1273,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-07-07-45-800371_chatcmpl-9f584be0-18e8-4e7a-9404-2969388571f7",
          "traceId": "851d2c7f",
          "type": "GENERATION",
          "name": "851d_tpusg_gen_attempt#3",
          "startTime": "2025-12-11T05:07:45.800000+00:00",
          "endTime": "2025-12-11T05:08:01.142000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 15342.0,
          "promptTokens": 291,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 843,
          "totalTokens": 1134,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-07-08-09-099110_chatcmpl-d1e44c80-b0a2-4587-910f-a6ba934c5e84",
          "traceId": "851d2c7f",
          "type": "GENERATION",
          "name": "851d_tpusg_gen_attempt#4",
          "startTime": "2025-12-11T05:08:09.099000+00:00",
          "endTime": "2025-12-11T05:08:23.048000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 13949.0,
          "promptTokens": 291,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 766,
          "totalTokens": 1057,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-07-08-31-078190_chatcmpl-7ba9af82-a54d-484e-b99d-77362e1f7117",
          "traceId": "851d2c7f",
          "type": "GENERATION",
          "name": "851d_tpusg_gen_attempt#5",
          "startTime": "2025-12-11T05:08:31.078000+00:00",
          "endTime": "2025-12-11T05:08:42.990000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 11912.0,
          "promptTokens": 291,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 655,
          "totalTokens": 946,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "6da07623-df31-4944-bad8-98a78e4385b5",
          "traceId": "851d2c7f",
          "type": "SPAN",
          "name": "error_85_tpusg_failure_signal_tpu_sketch_generator",
          "startTime": "2025-12-11T05:08:51.493000+00:00",
          "level": "ERROR",
          "statusMessage": "Failed: Max retries reached with error. Last error: Traceback (most recent call last):\n  File \"script_aa552595_1765429722.py\", line 70, in <module>\n    process_video(input_path, output_path)\n  File \"script_aa552595_1765429722.py\", line 53, in process_video\n    processed_frame = preprocess_frame(frame)\n  File \"script_aa552595_1765429722.py\", line 24, in preprocess_frame\n    input_tensor = detection_engine.get_input_tensor()\nAttributeError: 'DetectionEngine' object has no attribute 'get_input_tensor'.",
          "calculatedTotalCost": 0.0,
          "promptTokens": 0,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 0,
          "totalTokens": 0,
          "endTime": null,
          "model": null,
          "modelParameters": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null,
          "latency": null
        }
      ],
      "createdAt": "2025-12-11T05:06:58.055Z",
      "updatedAt": "2025-12-11T05:08:56.739Z",
      "environment": "default"
    },
    {
      "id": "dbbc3a80",
      "timestamp": "2025-12-11T05:04:10.352000+00:00",
      "name": "dbbc_tpu_sketch_generator",
      "input": null,
      "output": {
        "status": "success",
        "sketch": "import cv2\nimport numpy as np\nfrom tflite_runtime.interpreter import Interpreter\nfrom tflite_runtime.interpreter import load_delegate\nimport time\n\n# Configuration parameters\nmodel_path = '/home/mendel/tinyml_autopilot/models/edgetpu_detect.tflite'\nlabel_path = '/home/mendel/tinyml_autopilot/models/labelmap.txt'\ninput_path = '/home/mendel/tinyml_autopilot/data/sheeps.mp4'\noutput_path = '/home/mendel/tinyml_autopilot/results/sheeps_detections.mp4'\nconfidence_threshold = 0.5\n\n# Load label map\ndef load_labels(path):\n    with open(path, 'r', encoding='utf-8') as f:\n        return {i: line.strip() for i, line in enumerate(f.readlines())}\n\nlabels = load_labels(label_path)\n\n# Setup TFLite interpreter on Coral Dev Board with TPU\ninterpreter = Interpreter(\n    model_path=model_path,\n    experimental_delegates=[load_delegate('/usr/lib/aarch64-linux-gnu/libedgetpu.so.1.0')]\n)\ninterpreter.allocate_tensors()\n\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\n\n# Get input size and create video capture object\nheight, width, _ = input_details[0]['shape'][1:]\ncap = cv2.VideoCapture(input_path)\nfps = cap.get(cv2.CAP_PROP_FPS)\nwidth_vid, height_vid = int(cap.get(3)), int(cap.get(4))\nout = cv2.VideoWriter(output_path, cv2.VideoWriter_fourcc(*'mp4v'), fps, (width_vid, height_vid))\n\n# Helper function to compute mAP\ndef compute_map(predictions, ground_truths):\n    # Placeholder for mAP computation logic; implement as needed.\n    return 0.0\n\n# Main loop: read input, process, run inference, and draw boxes with labels\nmap_accumulator = []\nwhile cap.isOpened():\n    ret, frame = cap.read()\n    if not ret:\n        break\n    \n    # Preprocessing: Resize and normalize the image\n    resized_frame = cv2.resize(frame, (width, height))\n    input_data = np.expand_dims(resized_frame, axis=0).astype(np.uint8)\n    \n    interpreter.set_tensor(input_details[0]['index'], input_data)\n\n    # Inference\n    start_time = time.time()\n    interpreter.invoke()\n    inference_time = time.time() - start_time\n\n    # Extract output data\n    boxes = interpreter.get_tensor(output_details[0]['index'])[0]  # Bounding box coordinates of detected objects\n    classes = interpreter.get_tensor(output_details[1]['index'])[0]  # Class index of detected objects\n    scores = interpreter.get_tensor(output_details[2]['index'])[0]  # Confidence of detected objects\n\n    # Post-processing: Filter out low confidence detections and draw boxes\n    frame_height, frame_width, _ = frame.shape\n    for i in range(len(scores)):\n        if scores[i] >= confidence_threshold:\n            ymin, xmin, ymax, xmax = boxes[i]\n            (left, right, top, bottom) = (xmin * frame_width, xmax * frame_width,\n                                          ymin * frame_height, ymax * frame_height)\n            \n            # Draw bounding box and label on the image\n            cv2.rectangle(frame, (int(left), int(top)), (int(right), int(bottom)), (10, 255, 0), 2)\n            object_name = labels[int(classes[i])]\n            label = f'{object_name}: {scores[i]:.2f}'\n            label_size, base_line = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.5, 1)\n            top = max(top, label_size[1])\n            cv2.rectangle(frame, (int(left), int(top - round(1.5 * label_size[1]))),\n                          (int(left + label_size[0]), int(top + base_line)), (255, 255, 255), cv2.FILLED)\n            cv2.putText(frame, label, (int(left), int(top)), cv2.FONT_HERSHEY_SIMPLEX,\n                        0.75, (0, 0, 0), 1)\n\n    # Compute mAP for current frame if needed\n    # map_accumulator.append(compute_map(...))  # Implement actual logic\n\n    # Write the processed frame to output video\n    out.write(frame)\n    \n# Release resources\ncap.release()\nout.release()\n\n# Optionally compute average mAP over all frames\n# print(f'Average mAP: {sum(map_accumulator) / len(map_accumulator)}')"
      },
      "session_id": "phi4_a8a2_tpusg_batch",
      "metadata": {
        "num_run": 19
      },
      "tags": [
        "ablation",
        "benchmark",
        "phi4:latest",
        "tpu_sketch_generator"
      ],
      "latency": 88.971,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-07-04-10-353869_chatcmpl-9c6be899-e36d-464c-8016-6f7e44b79c13",
          "traceId": "dbbc3a80",
          "type": "GENERATION",
          "name": "dbbc_tpusg_gen_attempt#1",
          "startTime": "2025-12-11T05:04:10.353000+00:00",
          "endTime": "2025-12-11T05:04:24.769000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 14416.0,
          "promptTokens": 291,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 788,
          "totalTokens": 1079,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-07-04-33-035414_chatcmpl-3f5000bd-a67c-4e43-be4b-08b7ac21f48f",
          "traceId": "dbbc3a80",
          "type": "GENERATION",
          "name": "dbbc_tpusg_gen_attempt#2",
          "startTime": "2025-12-11T05:04:33.035000+00:00",
          "endTime": "2025-12-11T05:04:51.603000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 18568.0,
          "promptTokens": 291,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 1016,
          "totalTokens": 1307,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-07-04-59-327840_chatcmpl-4c3196bd-755d-4341-a593-44390125e01e",
          "traceId": "dbbc3a80",
          "type": "GENERATION",
          "name": "dbbc_tpusg_gen_attempt#3",
          "startTime": "2025-12-11T05:04:59.327000+00:00",
          "endTime": "2025-12-11T05:05:13.389000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 14062.0,
          "promptTokens": 291,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 773,
          "totalTokens": 1064,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-07-05-21-664435_chatcmpl-55ef2f8a-7874-4b9b-a3df-17f1eef44cd5",
          "traceId": "dbbc3a80",
          "type": "GENERATION",
          "name": "dbbc_tpusg_gen_attempt#4",
          "startTime": "2025-12-11T05:05:21.664000+00:00",
          "endTime": "2025-12-11T05:05:39.324000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 17660.0,
          "promptTokens": 291,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 967,
          "totalTokens": 1258,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        }
      ],
      "createdAt": "2025-12-11T05:04:10.871Z",
      "updatedAt": "2025-12-11T05:06:37.626Z",
      "environment": "default"
    },
    {
      "id": "bba48971",
      "timestamp": "2025-12-11T05:01:37.332000+00:00",
      "name": "bba4_tpu_sketch_generator",
      "input": null,
      "output": {
        "status": "failed",
        "last_code": "import cv2\nimport numpy as np\nfrom tflite_runtime.interpreter import Interpreter\nfrom tflite_runtime.load_delegate import load_delegate\n\n# Configuration parameters\nmodel_path = '/home/mendel/tinyml_autopilot/models/edgetpu_detect.tflite'\nlabel_path = '/home/mendel/tinyml_autopilot/models/labelmap.txt'\ninput_path = '/home/mendel/tinyml_autopilot/data/sheeps.mp4'\noutput_path = '/home/mendel/tinyml_autopilot/results/sheeps_detections.mp4'\nconfidence_threshold = 0.5\n\ndef load_labels(label_file):\n    with open(label_file, 'r') as file:\n        labels = {i: line.strip() for i, line in enumerate(file.readlines())}\n    return labels\n\ndef load_interpreter(model_path):\n    interpreter = Interpreter(\n        model_path=model_path,\n        experimental_delegates=[load_delegate('/usr/lib/aarch64-linux-gnu/libedgetpu.so.1.0')]\n    )\n    interpreter.allocate_tensors()\n    return interpreter\n\ndef preprocess_frame(frame, input_size):\n    frame_resized = cv2.resize(frame, input_size)\n    input_data = np.expand_dims(frame_resized, axis=0).astype(np.float32)\n    return input_data\n\ndef run_inference(interpreter, input_data):\n    input_details = interpreter.get_input_details()\n    output_details = interpreter.get_output_details()\n\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n\n    interpreter.invoke()\n\n    boxes = interpreter.get_tensor(output_details[0]['index'])[0]\n    classes = interpreter.get_tensor(output_details[1]['index'])[0].astype(np.int64)\n    scores = interpreter.get_tensor(output_details[2]['index'])[0]\n\n    return boxes, classes, scores\n\ndef draw_detections(frame, boxes, classes, scores, labels, input_size):\n    height, width, _ = frame.shape\n    scale_h, scale_w = input_size[0] / height, input_size[1] / width\n\n    for i in range(len(scores)):\n        if scores[i] >= confidence_threshold:\n            ymin, xmin, ymax, xmax = boxes[i]\n            (left, right, top, bottom) = (xmin * scale_w, xmax * scale_w,\n                                          ymin * scale_h, ymax * scale_h)\n            cv2.rectangle(frame, (int(left), int(top)), (int(right), int(bottom)),\n                          (0, 255, 0), 2)\n\n            label = f'{labels[classes[i]]}: {int(scores[i] * 100)}%'\n            label_size, base_line = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.7, 2)\n            top = max(top, label_size[1])\n            cv2.rectangle(frame, (int(left), int(top - round(1.5 * label_size[1]))),\n                          (int(left + label_size[0]), int(top + base_line)),\n                          (255, 255, 255), cv2.FILLED)\n            cv2.putText(frame, label, (int(left), int(top)), cv2.FONT_HERSHEY_SIMPLEX,\n                        0.7, (0, 0, 0), 2)\n\ndef main():\n    labels = load_labels(label_path)\n    interpreter = load_interpreter(model_path)\n\n    input_details = interpreter.get_input_details()\n    input_size = input_details[0]['shape'][1:3]\n\n    cap = cv2.VideoCapture(input_path)\n    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n    out = cv2.VideoWriter(output_path, fourcc, 20.0, (int(cap.get(3)), int(cap.get(4))))\n\n    while cap.isOpened():\n        ret, frame = cap.read()\n        if not ret:\n            break\n\n        input_data = preprocess_frame(frame, input_size)\n        boxes, classes, scores = run_inference(interpreter, input_data)\n        draw_detections(frame, boxes, classes, scores, labels, input_size)\n\n        out.write(frame)\n\n    cap.release()\n    out.release()\n\nif __name__ == '__main__':\n    main()",
        "last_error": "Max retries reached with error. Last error: Traceback (most recent call last):\n  File \"script_6aba7971_1765429416.py\", line 4, in <module>\n    from tflite_runtime.load_delegate import load_delegate\nModuleNotFoundError: No module named 'tflite_runtime.load_delegate'."
      },
      "session_id": "phi4_a8a2_tpusg_batch",
      "metadata": {
        "num_run": 18
      },
      "tags": [
        "ablation",
        "benchmark",
        "phi4:latest",
        "tpu_sketch_generator"
      ],
      "latency": 127.148,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-07-01-37-335252_chatcmpl-e8c23616-4f80-4f17-bbee-4e3d96e71741",
          "traceId": "bba48971",
          "type": "GENERATION",
          "name": "bba4_tpusg_gen_attempt#1",
          "startTime": "2025-12-11T05:01:37.335000+00:00",
          "endTime": "2025-12-11T05:01:56.889000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 19554.0,
          "promptTokens": 291,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 1065,
          "totalTokens": 1356,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-07-02-05-313879_chatcmpl-7e47f912-d243-4c9a-873e-c5a02630d991",
          "traceId": "bba48971",
          "type": "GENERATION",
          "name": "bba4_tpusg_gen_attempt#2",
          "startTime": "2025-12-11T05:02:05.313000+00:00",
          "endTime": "2025-12-11T05:02:19.191000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 13878.0,
          "promptTokens": 291,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 763,
          "totalTokens": 1054,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-07-02-26-906431_chatcmpl-c7149181-df83-48f0-bbf3-0efaa08030ba",
          "traceId": "bba48971",
          "type": "GENERATION",
          "name": "bba4_tpusg_gen_attempt#3",
          "startTime": "2025-12-11T05:02:26.906000+00:00",
          "endTime": "2025-12-11T05:02:45.597000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 18691.0,
          "promptTokens": 291,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 1023,
          "totalTokens": 1314,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-07-02-53-330822_chatcmpl-5c5f66de-6b66-463d-a24d-46e378a7b567",
          "traceId": "bba48971",
          "type": "GENERATION",
          "name": "bba4_tpusg_gen_attempt#4",
          "startTime": "2025-12-11T05:02:53.330000+00:00",
          "endTime": "2025-12-11T05:03:13.035000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 19705.0,
          "promptTokens": 291,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 1077,
          "totalTokens": 1368,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-07-03-20-976611_chatcmpl-3fa3bb74-abc2-4aec-9a83-f78a94ad6c99",
          "traceId": "bba48971",
          "type": "GENERATION",
          "name": "bba4_tpusg_gen_attempt#5",
          "startTime": "2025-12-11T05:03:20.976000+00:00",
          "endTime": "2025-12-11T05:03:36.717000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 15741.0,
          "promptTokens": 291,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 865,
          "totalTokens": 1156,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "c81418a3-dd57-42fb-b488-2b89c2d30618",
          "traceId": "bba48971",
          "type": "SPAN",
          "name": "error_bb_tpusg_failure_signal_tpu_sketch_generator",
          "startTime": "2025-12-11T05:03:44.483000+00:00",
          "level": "ERROR",
          "statusMessage": "Failed: Max retries reached with error. Last error: Traceback (most recent call last):\n  File \"script_6aba7971_1765429416.py\", line 4, in <module>\n    from tflite_runtime.load_delegate import load_delegate\nModuleNotFoundError: No module named 'tflite_runtime.load_delegate'.",
          "calculatedTotalCost": 0.0,
          "promptTokens": 0,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 0,
          "totalTokens": 0,
          "endTime": null,
          "model": null,
          "modelParameters": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null,
          "latency": null
        }
      ],
      "createdAt": "2025-12-11T05:01:37.851Z",
      "updatedAt": "2025-12-11T05:03:50.020Z",
      "environment": "default"
    },
    {
      "id": "a5eb54fd",
      "timestamp": "2025-12-11T04:59:10.864000+00:00",
      "name": "a5eb_tpu_sketch_generator",
      "input": null,
      "output": {
        "status": "failed",
        "last_code": "import cv2\nimport numpy as np\nimport tflite_runtime.interpreter as tflite\nfrom pycoral.adapters import common\nfrom pycoral.adapters import detect\nfrom pycoral.utils.edgetpu import make_interpreter\n\ndef load_labels(label_path):\n    with open(label_path, 'r') as f:\n        return [line.strip() for line in f.readlines()]\n\ndef compute_iou(box1, box2):\n    x_left = max(box1[0], box2[0])\n    y_top = max(box1[1], box2[1])\n    x_right = min(box1[2], box2[2])\n    y_bottom = min(box1[3], box2[3])\n\n    if x_right < x_left or y_bottom < y_top:\n        return 0.0\n\n    intersection_area = (x_right - x_left) * (y_bottom - y_top)\n    box1_area = (box1[2] - box1[0]) * (box1[3] - box1[1])\n    box2_area = (box2[2] - box2[0]) * (box2[3] - box2[1])\n\n    iou = intersection_area / float(box1_area + box2_area - intersection_area)\n    return iou\n\ndef compute_ap(precisions, recalls):\n    precisions = np.concatenate(([0.], precisions, [0.]))\n    recalls = np.concatenate(([0.], recalls, [1.]))\n\n    for i in range(len(precisions) - 2, -1, -1):\n        precisions[i] = max(precisions[i], precisions[i + 1])\n\n    indices = np.where(recalls[1:] != recalls[:-1])[0]\n    ap = np.sum((recalls[indices + 1] - recalls[indices]) * precisions[indices + 1])\n    return ap\n\ndef process_detections(detections, labels, confidence_threshold):\n    valid_detections = []\n    for detection in detections:\n        if detection.score >= confidence_threshold:\n            valid_detections.append({\n                'label': labels[detection.index],\n                'score': detection.score,\n                'bounding_box': (detection.left, detection.top, detection.right, detection.bottom)\n            })\n    return valid_detections\n\ndef draw_boxes(frame, detections):\n    for det in detections:\n        bbox = det['bounding_box']\n        cv2.rectangle(frame, (int(bbox[0]), int(bbox[1])), (int(bbox[2]), int(bbox[3])),\n                      (0, 255, 0), 2)\n        label = f\"{det['label']}: {det['score']:.2f}\"\n        cv2.putText(frame, label, (int(bbox[0]), int(bbox[1] - 10)), cv2.FONT_HERSHEY_SIMPLEX,\n                    0.5, (0, 255, 0), 2)\n\ndef main():\n    model_path = '/home/mendel/tinyml_autopilot/models/edgetpu_detect.tflite'\n    label_path = '/home/mendel/tinyml_autopilot/models/labelmap.txt'\n    input_path = '/home/mendel/tinyml_autopilot/data/sheeps.mp4'\n    output_path = '/home/mendel/tinyml_autopilot/results/sheeps_detections.mp4'\n    confidence_threshold = 0.5\n\n    # Setup\n    interpreter = make_interpreter(model_path, device_path='/usr/lib/aarch64-linux-gnu/libedgetpu.so.1.0')\n    interpreter.allocate_tensors()\n    \n    labels = load_labels(label_path)\n    video_input = cv2.VideoCapture(input_path)\n    width = int(video_input.get(cv2.CAP_PROP_FRAME_WIDTH))\n    height = int(video_input.get(cv2.CAP_PROP_FRAME_HEIGHT))\n    fps = int(video_input.get(cv2.CAP_PROP_FPS))\n    codec = cv2.VideoWriter_fourcc(*'mp4v')\n    video_output = cv2.VideoWriter(output_path, codec, fps, (width, height))\n\n    # Inference loop\n    while True:\n        ret, frame = video_input.read()\n        if not ret:\n            break\n\n        input_tensor = common.set_input(interpreter, frame)\n        interpreter.invoke()\n\n        detections = detect.get_detections(interpreter, threshold=confidence_threshold)\n\n        valid_detections = process_detections(detections, labels, confidence_threshold)\n        draw_boxes(frame, valid_detections)\n\n        video_output.write(frame)\n\n    # Cleanup\n    video_input.release()\n    video_output.release()\n\nif __name__ == \"__main__\":\n    main()",
        "last_error": "Max retries reached with error. Last error: Traceback (most recent call last):\n  File \"script_6ab95f30_1765429261.py\", line 99, in <module>\n    main()\n  File \"script_6ab95f30_1765429261.py\", line 67, in main\n    interpreter = make_interpreter(model_path, device_path='/usr/lib/aarch64-linux-gnu/libedgetpu.so.1.0')\nTypeError: make_interpreter() got an unexpected keyword argument 'device_path'."
      },
      "session_id": "phi4_a8a2_tpusg_batch",
      "metadata": {
        "num_run": 17
      },
      "tags": [
        "ablation",
        "benchmark",
        "phi4:latest",
        "tpu_sketch_generator"
      ],
      "latency": 119.216,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-06-59-10-865551_chatcmpl-c4d034f6-71a9-43b7-9ed6-b20f00ccfa35",
          "traceId": "a5eb54fd",
          "type": "GENERATION",
          "name": "a5eb_tpusg_gen_attempt#1",
          "startTime": "2025-12-11T04:59:10.865000+00:00",
          "endTime": "2025-12-11T04:59:28.026000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 17161.0,
          "promptTokens": 291,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 936,
          "totalTokens": 1227,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-06-59-36-512280_chatcmpl-861f9261-816f-4863-802d-57199943bd85",
          "traceId": "a5eb54fd",
          "type": "GENERATION",
          "name": "a5eb_tpusg_gen_attempt#2",
          "startTime": "2025-12-11T04:59:36.512000+00:00",
          "endTime": "2025-12-11T04:59:50.810000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 14298.0,
          "promptTokens": 291,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 784,
          "totalTokens": 1075,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-06-59-58-633404_chatcmpl-e9396453-e13d-4b73-96ad-78512e416fce",
          "traceId": "a5eb54fd",
          "type": "GENERATION",
          "name": "a5eb_tpusg_gen_attempt#3",
          "startTime": "2025-12-11T04:59:58.633000+00:00",
          "endTime": "2025-12-11T05:00:13.609000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 14976.0,
          "promptTokens": 291,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 822,
          "totalTokens": 1113,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-07-00-22-126839_chatcmpl-0193759c-cb71-4c80-a8b7-b3d50b0e1506",
          "traceId": "a5eb54fd",
          "type": "GENERATION",
          "name": "a5eb_tpusg_gen_attempt#4",
          "startTime": "2025-12-11T05:00:22.126000+00:00",
          "endTime": "2025-12-11T05:00:36.516000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 14390.0,
          "promptTokens": 291,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 790,
          "totalTokens": 1081,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-07-00-44-335355_chatcmpl-3ac6c424-2fe6-449b-8892-d0d69484d2fb",
          "traceId": "a5eb54fd",
          "type": "GENERATION",
          "name": "a5eb_tpusg_gen_attempt#5",
          "startTime": "2025-12-11T05:00:44.335000+00:00",
          "endTime": "2025-12-11T05:01:01.941000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 17606.0,
          "promptTokens": 291,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 967,
          "totalTokens": 1258,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "770d89e4-d54a-4eb4-9cc6-3958ecfb29c5",
          "traceId": "a5eb54fd",
          "type": "SPAN",
          "name": "error_a5_tpusg_failure_signal_tpu_sketch_generator",
          "startTime": "2025-12-11T05:01:10.081000+00:00",
          "level": "ERROR",
          "statusMessage": "Failed: Max retries reached with error. Last error: Traceback (most recent call last):\n  File \"script_6ab95f30_1765429261.py\", line 99, in <module>\n    main()\n  File \"script_6ab95f30_1765429261.py\", line 67, in main\n    interpreter = make_interpreter(model_path, device_path='/usr/lib/aarch64-linux-gnu/libedgetpu.so.1.0')\nTypeError: make_interpreter() got an unexpected keyword argument 'device_path'.",
          "calculatedTotalCost": 0.0,
          "promptTokens": 0,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 0,
          "totalTokens": 0,
          "endTime": null,
          "model": null,
          "modelParameters": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null,
          "latency": null
        }
      ],
      "createdAt": "2025-12-11T04:59:11.384Z",
      "updatedAt": "2025-12-11T05:01:15.557Z",
      "environment": "default"
    },
    {
      "id": "f721c6f5",
      "timestamp": "2025-12-11T04:56:24.475000+00:00",
      "name": "f721_tpu_sketch_generator",
      "input": null,
      "output": {
        "status": "success",
        "sketch": "import cv2\nimport numpy as np\nfrom tflite_runtime.interpreter import load_delegate\nfrom tflite_runtime.interpreter import Interpreter\n\ndef load_labels(label_path):\n    with open(label_path, 'r') as file:\n        return [line.strip() for line in file.readlines()]\n\ndef set_input_tensor(interpreter, image):\n    tensor_index = interpreter.get_input_details()[0]['index']\n    input_shape = interpreter.get_input_details()[0]['shape']\n    input_data = cv2.resize(image, (input_shape[1], input_shape[2]))\n    input_data = np.expand_dims(input_data, axis=0)\n    interpreter.set_tensor(tensor_index, input_data)\n\ndef get_output(interpreter):\n    boxes = interpreter.get_tensor(interpreter.get_output_details()[0]['index'])[0]\n    classes = interpreter.get_tensor(interpreter.get_output_details()[1]['index'])[0]\n    scores = interpreter.get_tensor(interpreter.get_output_details()[2]['index'])[0]\n    count = int(interpreter.get_tensor(interpreter.get_output_details()[3]['index'])[0])\n    return boxes, classes, scores, count\n\ndef draw_detections(image, labels, boxes, classes, scores, threshold):\n    for i in range(len(scores)):\n        if scores[i] >= threshold:\n            ymin, xmin, ymax, xmax = boxes[i]\n            (left, right, top, bottom) = (xmin * image.shape[1], xmax * image.shape[1],\n                                          ymin * image.shape[0], ymax * image.shape[0])\n            cv2.rectangle(image, (int(left), int(top)), (int(right), int(bottom)), (10, 255, 0), 2)\n            label = f\"{labels[int(classes[i])]}: {scores[i]:.2f}\"\n            cv2.putText(image, label, (int(left), int(top) - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (10, 255, 0), 2)\n\ndef main():\n    model_path = '/home/mendel/tinyml_autopilot/models/edgetpu_detect.tflite'\n    label_path = '/home/mendel/tinyml_autopilot/models/labelmap.txt'\n    input_path = '/home/mendel/tinyml_autopilot/data/sheeps.mp4'\n    output_path = '/home/mendel/tinyml_autopilot/results/sheeps_detections.mp4'\n    confidence_threshold = 0.5\n\n    # Load labels\n    labels = load_labels(label_path)\n\n    # Setup TFLite interpreter for Coral Edge TPU\n    interpreter = Interpreter(\n        model_path=model_path,\n        experimental_delegates=[load_delegate('/usr/lib/aarch64-linux-gnu/libedgetpu.so.1.0')]\n    )\n    interpreter.allocate_tensors()\n\n    # Open video input and output streams\n    cap = cv2.VideoCapture(input_path)\n    if not cap.isOpened():\n        print(\"Error: Could not open video.\")\n        return\n\n    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n    out = cv2.VideoWriter(output_path, fourcc, 30.0, (int(cap.get(3)), int(cap.get(4))))\n\n    while cap.isOpened():\n        ret, frame = cap.read()\n        if not ret:\n            break\n\n        # Preprocess and run inference\n        set_input_tensor(interpreter, frame)\n        interpreter.invoke()\n        boxes, classes, scores, count = get_output(interpreter)\n\n        # Draw detection results on the frame\n        draw_detections(frame, labels, boxes, classes, scores, confidence_threshold)\n\n        # Write the frame with detections to output video\n        out.write(frame)\n\n    cap.release()\n    out.release()\n\nif __name__ == '__main__':\n    main()"
      },
      "session_id": "phi4_a8a2_tpusg_batch",
      "metadata": {
        "num_run": 16
      },
      "tags": [
        "ablation",
        "benchmark",
        "phi4:latest",
        "tpu_sketch_generator"
      ],
      "latency": 88.074,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-06-56-24-476295_chatcmpl-f0b83e51-d9dc-4245-800d-e20fc5caaca0",
          "traceId": "f721c6f5",
          "type": "GENERATION",
          "name": "f721_tpusg_gen_attempt#1",
          "startTime": "2025-12-11T04:56:24.476000+00:00",
          "endTime": "2025-12-11T04:56:42.104000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 17628.0,
          "promptTokens": 291,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 963,
          "totalTokens": 1254,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-06-56-50-271009_chatcmpl-b58f2e3a-4bfe-4447-9d0a-e16e72eb5010",
          "traceId": "f721c6f5",
          "type": "GENERATION",
          "name": "f721_tpusg_gen_attempt#2",
          "startTime": "2025-12-11T04:56:50.271000+00:00",
          "endTime": "2025-12-11T04:57:07.017000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 16746.0,
          "promptTokens": 291,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 918,
          "totalTokens": 1209,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-06-57-14-867003_chatcmpl-857990b4-73b8-41dd-8eec-9a10010d7165",
          "traceId": "f721c6f5",
          "type": "GENERATION",
          "name": "f721_tpusg_gen_attempt#3",
          "startTime": "2025-12-11T04:57:14.867000+00:00",
          "endTime": "2025-12-11T04:57:30.207000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 15340.0,
          "promptTokens": 291,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 842,
          "totalTokens": 1133,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-06-57-38-283684_chatcmpl-4146070b-b85a-4a0b-aa4d-900a1d6270a0",
          "traceId": "f721c6f5",
          "type": "GENERATION",
          "name": "f721_tpusg_gen_attempt#4",
          "startTime": "2025-12-11T04:57:38.283000+00:00",
          "endTime": "2025-12-11T04:57:52.550000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 14267.0,
          "promptTokens": 291,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 784,
          "totalTokens": 1075,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        }
      ],
      "createdAt": "2025-12-11T04:56:24.995Z",
      "updatedAt": "2025-12-11T04:58:50.731Z",
      "environment": "default"
    },
    {
      "id": "bdbb9fea",
      "timestamp": "2025-12-11T04:54:04.518000+00:00",
      "name": "bdbb_tpu_sketch_generator",
      "input": null,
      "output": {
        "status": "failed",
        "last_code": "import cv2\nimport numpy as np\nfrom tflite_runtime.interpreter import Interpreter\nfrom edgetpu.basic.edgetpu_utils import MakeEdgeTpuSubgraphInterpreter\n\n# Configuration parameters\nmodel_path = '/home/mendel/tinyml_autopilot/models/edgetpu_detect.tflite'\nlabel_path = '/home/mendel/tinyml_autopilot/models/labelmap.txt'\ninput_path = '/home/mendel/tinyml_autopilot/data/sheeps.mp4'\noutput_path = '/home/mendel/tinyml_autopilot/results/sheeps_detections.mp4'\nconfidence_threshold = 0.5\n\n# Setup phase: Load the TFLite interpreter for TPU\ndef load_interpreter(model_path):\n    return MakeEdgeTpuSubgraphInterpreter(model_path)\n\ninterpreter = load_interpreter(model_path)\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\n\n# Preprocessing function to prepare input frames\ndef preprocess_frame(frame, target_size):\n    frame_resized = cv2.resize(frame, (target_size[1], target_size[0]))\n    input_data = np.expand_dims(frame_resized, axis=0).astype(np.float32)\n    return input_data\n\n# Inference phase: Process and run inference\ndef run_inference(interpreter, input_data):\n    interpreter.allocate_tensors()\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n    interpreter.invoke()\n    boxes = interpreter.get_tensor(output_details[0]['index'])[0]\n    classes = interpreter.get_tensor(output_details[1]['index'])[0].astype(np.int32)\n    scores = interpreter.get_tensor(output_details[2]['index'])[0]\n    return boxes, classes, scores\n\n# Load labels\ndef load_labels(label_path):\n    with open(label_path, 'r') as file:\n        lines = file.readlines()\n    return [line.strip() for line in lines]\n\nlabels = load_labels(label_path)\n\n# Initialize video capture and writer\ncap = cv2.VideoCapture(input_path)\nframe_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\nframe_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\noutput_writer = cv2.VideoWriter(output_path, cv2.VideoWriter_fourcc(*'mp4v'), 30, (frame_width, frame_height))\n\n# Main processing loop\nwhile cap.isOpened():\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    input_data = preprocess_frame(frame, input_details[0]['shape'][1:3])\n    boxes, classes, scores = run_inference(interpreter, input_data)\n\n    for i in range(len(scores)):\n        if scores[i] >= confidence_threshold:\n            ymin, xmin, ymax, xmax = boxes[i]\n            (left, right, top, bottom) = (xmin * frame_width, xmax * frame_width,\n                                          ymin * frame_height, ymax * frame_height)\n            cv2.rectangle(frame, (int(left), int(top)), (int(right), int(bottom)),\n                          (0, 255, 0), 2)\n            label = f'{labels[classes[i]]}: {scores[i]:.2f}'\n            cv2.putText(frame, label, (int(left), int(top) - 10),\n                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n\n    output_writer.write(frame)\n\ncap.release()\noutput_writer.release()\n\n# Compute mAP and other metrics if necessary\n# Note: Full mAP computation is complex and typically requires a separate evaluation phase with ground truth annotations.",
        "last_error": "Max retries reached with error. Last error: Traceback (most recent call last):\n  File \"script_2554dc3c_1765428951.py\", line 4, in <module>\n    from edgetpu.basic.edgetpu_utils import MakeEdgeTpuSubgraphInterpreter\nImportError: cannot import name 'MakeEdgeTpuSubgraphInterpreter' from 'edgetpu.basic.edgetpu_utils' (/home/mendel/.local/lib/python3.7/site-packages/edgetpu/basic/edgetpu_utils.py)."
      },
      "session_id": "phi4_a8a2_tpusg_batch",
      "metadata": {
        "num_run": 15
      },
      "tags": [
        "ablation",
        "benchmark",
        "phi4:latest",
        "tpu_sketch_generator"
      ],
      "latency": 115.007,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-06-54-04-519217_chatcmpl-edfae389-5b2c-4e95-9a99-ed92e54bc2af",
          "traceId": "bdbb9fea",
          "type": "GENERATION",
          "name": "bdbb_tpusg_gen_attempt#1",
          "startTime": "2025-12-11T04:54:04.519000+00:00",
          "endTime": "2025-12-11T04:54:18.546000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 14027.0,
          "promptTokens": 291,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 767,
          "totalTokens": 1058,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-06-54-26-728984_chatcmpl-1e21f299-0a87-4fa3-830f-a5eff994e237",
          "traceId": "bdbb9fea",
          "type": "GENERATION",
          "name": "bdbb_tpusg_gen_attempt#2",
          "startTime": "2025-12-11T04:54:26.728000+00:00",
          "endTime": "2025-12-11T04:54:43.708000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 16980.0,
          "promptTokens": 291,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 931,
          "totalTokens": 1222,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-06-54-51-949490_chatcmpl-00f06887-2dc9-4652-9765-725a1ff7d572",
          "traceId": "bdbb9fea",
          "type": "GENERATION",
          "name": "bdbb_tpusg_gen_attempt#3",
          "startTime": "2025-12-11T04:54:51.949000+00:00",
          "endTime": "2025-12-11T04:55:07+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 15051.0,
          "promptTokens": 291,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 826,
          "totalTokens": 1117,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-06-55-15-344494_chatcmpl-f750624f-f1c8-4588-aecb-7d635b5b5e18",
          "traceId": "bdbb9fea",
          "type": "GENERATION",
          "name": "bdbb_tpusg_gen_attempt#4",
          "startTime": "2025-12-11T04:55:15.344000+00:00",
          "endTime": "2025-12-11T04:55:29.802000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 14458.0,
          "promptTokens": 291,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 794,
          "totalTokens": 1085,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-06-55-38-309459_chatcmpl-77f05905-569f-4297-a1b3-d37a8efb88c5",
          "traceId": "bdbb9fea",
          "type": "GENERATION",
          "name": "bdbb_tpusg_gen_attempt#5",
          "startTime": "2025-12-11T04:55:38.309000+00:00",
          "endTime": "2025-12-11T04:55:51.792000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 13483.0,
          "promptTokens": 291,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 741,
          "totalTokens": 1032,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "bcd15088-b654-4a1e-835c-d82d991c7c8b",
          "traceId": "bdbb9fea",
          "type": "SPAN",
          "name": "error_bd_tpusg_failure_signal_tpu_sketch_generator",
          "startTime": "2025-12-11T04:55:59.526000+00:00",
          "level": "ERROR",
          "statusMessage": "Failed: Max retries reached with error. Last error: Traceback (most recent call last):\n  File \"script_2554dc3c_1765428951.py\", line 4, in <module>\n    from edgetpu.basic.edgetpu_utils import MakeEdgeTpuSubgraphInterpreter\nImportError: cannot import name 'MakeEdgeTpuSubgraphInterpreter' from 'edgetpu.basic.edgetpu_utils' (/home/mendel/.local/lib/python3.7/site-packages/edgetpu/basic/edgetpu_utils.py).",
          "calculatedTotalCost": 0.0,
          "promptTokens": 0,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 0,
          "totalTokens": 0,
          "endTime": null,
          "model": null,
          "modelParameters": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null,
          "latency": null
        }
      ],
      "createdAt": "2025-12-11T04:54:05.039Z",
      "updatedAt": "2025-12-11T04:56:04.729Z",
      "environment": "default"
    },
    {
      "id": "a8511294",
      "timestamp": "2025-12-11T04:51:14.526000+00:00",
      "name": "a851_tpu_sketch_generator",
      "input": null,
      "output": {
        "status": "success",
        "sketch": "import cv2\nimport numpy as np\nfrom tflite_runtime.interpreter import Interpreter\nfrom tflite_runtime.interpreter import load_delegate\n\n# Configuration parameters\nmodel_path = '/home/mendel/tinyml_autopilot/models/edgetpu_detect.tflite'\nlabel_path = '/home/mendel/tinyml_autopilot/models/labelmap.txt'\ninput_path = '/home/mendel/tinyml_autopilot/data/sheeps.mp4'\noutput_path = '/home/mendel/tinyml_autopilot/results/sheeps_detections.mp4'\nconfidence_threshold = 0.5\n\n# Setup: Load the TFLite interpreter for TPU\ndef load_interpreter():\n    return Interpreter(\n        model_path=model_path,\n        experimental_delegates=[load_delegate('/usr/lib/aarch64-linux-gnu/libedgetpu.so.1.0')]\n    )\n\n# Preprocessing: Read input and prepare labels\ndef preprocess_input(input_path, label_path):\n    # Load labels\n    with open(label_path, 'r') as f:\n        labels = [line.strip() for line in f.readlines()]\n\n    # Open video file\n    cap = cv2.VideoCapture(input_path)\n    if not cap.isOpened():\n        raise IOError(f\"Cannot open video file {input_path}\")\n\n    return cap, labels\n\n# Inference: Run detection on each frame\ndef run_inference(interpreter, frame):\n    input_details = interpreter.get_input_details()\n    output_details = interpreter.get_output_details()\n\n    # Preprocess the image\n    input_shape = input_details[0]['shape']\n    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n    frame_resized = cv2.resize(frame_rgb, (input_shape[1], input_shape[2]))\n    input_data = np.expand_dims(frame_resized, axis=0)\n\n    # Set the tensor\n    interpreter.set_tensor(input_details[0]['index'], input_data)\n\n    # Run inference\n    interpreter.invoke()\n\n    # Get output details\n    boxes = interpreter.get_tensor(output_details[0]['index'])[0]  # Bounding box coordinates of detected objects\n    classes = interpreter.get_tensor(output_details[1]['index'])[0]  # Class index of detected objects\n    scores = interpreter.get_tensor(output_details[2]['index'])[0]  # Confidence of detected objects\n\n    return boxes, classes, scores\n\n# Output handling: Draw detection boxes and save to output video\ndef draw_detections(frame, boxes, classes, scores, labels):\n    for i in range(len(scores)):\n        if scores[i] > confidence_threshold:\n            ymin, xmin, ymax, xmax = boxes[i]\n            (left, right, top, bottom) = (xmin * frame.shape[1], xmax * frame.shape[1],\n                                          ymin * frame.shape[0], ymax * frame.shape[0])\n            cv2.rectangle(frame, (int(left), int(top)), (int(right), int(bottom)), (0, 255, 0), 2)\n            label = f\"{labels[int(classes[i])]}: {int(scores[i]*100)}%\"\n            cv2.putText(frame, label, (int(left), int(top)-10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 1)\n\n# Main pipeline\ndef main():\n    interpreter = load_interpreter()\n    interpreter.allocate_tensors()\n\n    cap, labels = preprocess_input(input_path, label_path)\n    \n    # Get video properties\n    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n    fps = int(cap.get(cv2.CAP_PROP_FPS))\n\n    # Define the codec and create VideoWriter object\n    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n    out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n\n    while cap.isOpened():\n        ret, frame = cap.read()\n        if not ret:\n            break\n\n        boxes, classes, scores = run_inference(interpreter, frame)\n        draw_detections(frame, boxes, classes, scores, labels)\n\n        out.write(frame)  # Write the frame with detections to output video\n\n    cap.release()\n    out.release()\n\nif __name__ == \"__main__\":\n    main()"
      },
      "session_id": "phi4_a8a2_tpusg_batch",
      "metadata": {
        "num_run": 14
      },
      "tags": [
        "ablation",
        "benchmark",
        "phi4:latest",
        "tpu_sketch_generator"
      ],
      "latency": 92.236,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-06-51-14-527946_chatcmpl-4809ee23-1e81-485b-b559-c1ae09ccc7a7",
          "traceId": "a8511294",
          "type": "GENERATION",
          "name": "a851_tpusg_gen_attempt#1",
          "startTime": "2025-12-11T04:51:14.527000+00:00",
          "endTime": "2025-12-11T04:51:34.040000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 19513.0,
          "promptTokens": 291,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 1063,
          "totalTokens": 1354,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-06-51-42-547424_chatcmpl-654c8f4f-21a1-410c-b6bf-dfd0a635f102",
          "traceId": "a8511294",
          "type": "GENERATION",
          "name": "a851_tpusg_gen_attempt#2",
          "startTime": "2025-12-11T04:51:42.547000+00:00",
          "endTime": "2025-12-11T04:51:56.558000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 14011.0,
          "promptTokens": 291,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 769,
          "totalTokens": 1060,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-06-52-04-473509_chatcmpl-f3b51ffd-ffdf-4977-a7b5-8a853dc9739d",
          "traceId": "a8511294",
          "type": "GENERATION",
          "name": "a851_tpusg_gen_attempt#3",
          "startTime": "2025-12-11T04:52:04.473000+00:00",
          "endTime": "2025-12-11T04:52:22.626000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 18153.0,
          "promptTokens": 291,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 994,
          "totalTokens": 1285,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-06-52-30-362915_chatcmpl-56db396c-47c1-4bfe-8687-0d2dc282b4e0",
          "traceId": "a8511294",
          "type": "GENERATION",
          "name": "a851_tpusg_gen_attempt#4",
          "startTime": "2025-12-11T04:52:30.362000+00:00",
          "endTime": "2025-12-11T04:52:46.763000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 16401.0,
          "promptTokens": 291,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 899,
          "totalTokens": 1190,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        }
      ],
      "createdAt": "2025-12-11T04:51:15.048Z",
      "updatedAt": "2025-12-11T04:53:44.306Z",
      "environment": "default"
    },
    {
      "id": "b489de44",
      "timestamp": "2025-12-11T04:48:47.586000+00:00",
      "name": "b489_tpu_sketch_generator",
      "input": null,
      "output": {
        "status": "failed",
        "last_code": "import cv2\nimport numpy as np\nfrom tflite_runtime.interpreter import Interpreter\nfrom PIL import ImageDraw\n\n# Configuration parameters\nmodel_path = '/home/mendel/tinyml_autopilot/models/edgetpu_detect.tflite'\nlabel_path = '/home/mendel/tinyml_autopilot/models/labelmap.txt'\ninput_path = '/home/mendel/tinyml_autopilot/data/sheeps.mp4'\noutput_path = '/home/mendel/tinyml_autopilot/results/sheeps_detections.mp4'\nconfidence_threshold = 0.5\n\n# Load labels\nwith open(label_path, 'r') as f:\n    labels = [line.strip() for line in f.readlines()]\n\ndef load_interpreter(model_path):\n    # Setup TPU interpreter\n    from tflite_runtime.interpreter import load_delegate\n    interpreter = Interpreter(\n        model_path=model_path,\n        experimental_delegates=[load_delegate('/usr/lib/aarch64-linux-gnu/libedgetpu.so.1.0')]\n    )\n    interpreter.allocate_tensors()\n    return interpreter\n\ndef preprocess_frame(frame, input_size):\n    # Resize and normalize the frame\n    frame_resized = cv2.resize(frame, (input_size[1], input_size[0]))\n    input_data = np.expand_dims(frame_resized, axis=0).astype(np.float32)\n    input_data = input_data / 255.0\n    return input_data\n\ndef run_inference(interpreter, input_data):\n    # Run inference on the preprocessed frame\n    interpreter.set_tensor(interpreter.get_input_details()[0]['index'], input_data)\n    interpreter.invoke()\n    \n    # Extract output data\n    boxes = interpreter.get_tensor(interpreter.get_output_details()[0]['index'])[0]\n    classes = interpreter.get_tensor(interpreter.get_output_details()[1]['index'])[0].astype(np.int64)\n    scores = interpreter.get_tensor(interpreter.get_output_details()[2]['index'])[0]\n\n    return boxes, classes, scores\n\ndef draw_detections(frame, boxes, classes, scores, labels):\n    # Draw detection results on the frame\n    height, width, _ = frame.shape\n    for i in range(len(scores)):\n        if scores[i] >= confidence_threshold:\n            ymin, xmin, ymax, xmax = boxes[i]\n            (left, right, top, bottom) = (xmin * width, xmax * width,\n                                          ymin * height, ymax * height)\n            label = f\"{labels[classes[i]]}: {int(scores[i]*100)}%\"\n            cv2.rectangle(frame, (int(left), int(top)), (int(right), int(bottom)), (0, 255, 0), 2)\n            cv2.putText(frame, label, (int(left), int(top-10)), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n\ndef compute_mAP(ground_truths, predictions):\n    # Placeholder for mAP computation logic\n    # Implement this function based on your specific requirements and data format.\n    pass\n\n# Main pipeline\ninterpreter = load_interpreter(model_path)\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\ninput_size = input_details[0]['shape'][1:3]\n\ncap = cv2.VideoCapture(input_path)\nfourcc = cv2.VideoWriter_fourcc(*'mp4v')\nout = cv2.VideoWriter(output_path, fourcc, 20.0, (int(cap.get(3)), int(cap.get(4))))\n\nwhile cap.isOpened():\n    ret, frame = cap.read()\n    if not ret:\n        break\n    \n    # Preprocessing\n    input_data = preprocess_frame(frame, input_size)\n    \n    # Inference\n    boxes, classes, scores = run_inference(interpreter, input_data)\n    \n    # Output handling\n    draw_detections(frame, boxes, classes, scores, labels)\n    out.write(frame)\n\ncap.release()\nout.release()\n\n# Compute mAP (you need to implement this part based on your ground truth data and logic)\n# compute_mAP(ground_truths, predictions)",
        "last_error": "Max retries reached with error. Last error: Traceback (most recent call last):\n  File \"script_3faf8f48_1765428641.py\", line 82, in <module>\n    boxes, classes, scores = run_inference(interpreter, input_data)\n  File \"script_3faf8f48_1765428641.py\", line 36, in run_inference\n    interpreter.set_tensor(interpreter.get_input_details()[0]['index'], input_data)\n  File \"/home/mendel/tinyml_autopilot/tinyml-env/lib/python3.7/site-packages/tflite_runtime/interpreter.py\", line 572, in set_tensor\n    self._interpreter.SetTensor(tensor_index, value)\nValueError: Cannot set tensor: Got value of type FLOAT32 but expected type UINT8 for input 175, name: normalized_input_image_tensor ."
      },
      "session_id": "phi4_a8a2_tpusg_batch",
      "metadata": {
        "num_run": 13
      },
      "tags": [
        "ablation",
        "benchmark",
        "phi4:latest",
        "tpu_sketch_generator"
      ],
      "latency": 121.598,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-06-48-47-588118_chatcmpl-18894f3c-f39b-4205-9eca-cd03cd16879d",
          "traceId": "b489de44",
          "type": "GENERATION",
          "name": "b489_tpusg_gen_attempt#1",
          "startTime": "2025-12-11T04:48:47.588000+00:00",
          "endTime": "2025-12-11T04:49:01.984000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 14396.0,
          "promptTokens": 291,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 783,
          "totalTokens": 1074,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-06-49-10-108707_chatcmpl-8d5a4153-e200-4c62-a4dc-9cbbd258d706",
          "traceId": "b489de44",
          "type": "GENERATION",
          "name": "b489_tpusg_gen_attempt#2",
          "startTime": "2025-12-11T04:49:10.108000+00:00",
          "endTime": "2025-12-11T04:49:28.422000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 18314.0,
          "promptTokens": 291,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 1002,
          "totalTokens": 1293,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-06-49-36-318712_chatcmpl-b6f54ca6-343a-4048-80e8-2f300a4d1576",
          "traceId": "b489de44",
          "type": "GENERATION",
          "name": "b489_tpusg_gen_attempt#3",
          "startTime": "2025-12-11T04:49:36.318000+00:00",
          "endTime": "2025-12-11T04:49:54.160000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 17842.0,
          "promptTokens": 291,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 977,
          "totalTokens": 1268,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-06-50-02-455086_chatcmpl-a4afd376-498f-49f2-a2d3-f45322906ac1",
          "traceId": "b489de44",
          "type": "GENERATION",
          "name": "b489_tpusg_gen_attempt#4",
          "startTime": "2025-12-11T04:50:02.455000+00:00",
          "endTime": "2025-12-11T04:50:16.508000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 14053.0,
          "promptTokens": 291,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 771,
          "totalTokens": 1062,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-06-50-24-215247_chatcmpl-f4f7fc15-a039-49a4-9775-b6dab8c230fa",
          "traceId": "b489de44",
          "type": "GENERATION",
          "name": "b489_tpusg_gen_attempt#5",
          "startTime": "2025-12-11T04:50:24.215000+00:00",
          "endTime": "2025-12-11T04:50:41.002000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 16787.0,
          "promptTokens": 291,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 920,
          "totalTokens": 1211,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "76a3f965-e230-4ef4-8f12-760bcd8eab51",
          "traceId": "b489de44",
          "type": "SPAN",
          "name": "error_b4_tpusg_failure_signal_tpu_sketch_generator",
          "startTime": "2025-12-11T04:50:49.186000+00:00",
          "level": "ERROR",
          "statusMessage": "Failed: Max retries reached with error. Last error: Traceback (most recent call last):\n  File \"script_3faf8f48_1765428641.py\", line 82, in <module>\n    boxes, classes, scores = run_inference(interpreter, input_data)\n  File \"script_3faf8f48_1765428641.py\", line 36, in run_inference\n    interpreter.set_tensor(interpreter.get_input_details()[0]['index'], input_data)\n  File \"/home/mendel/tinyml_autopilot/tinyml-env/lib/python3.7/site-packages/tflite_runtime/interpreter.py\", line 572, in set_tensor\n    self._interpreter.SetTensor(tensor_index, value)\nValueError: Cannot set tensor: Got value of type FLOAT32 but expected type UINT8 for input 175, name: normalized_input_image_tensor .",
          "calculatedTotalCost": 0.0,
          "promptTokens": 0,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 0,
          "totalTokens": 0,
          "endTime": null,
          "model": null,
          "modelParameters": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null,
          "latency": null
        }
      ],
      "createdAt": "2025-12-11T04:48:48.107Z",
      "updatedAt": "2025-12-11T04:50:54.802Z",
      "environment": "default"
    },
    {
      "id": "d01e27d1",
      "timestamp": "2025-12-11T04:44:58.510000+00:00",
      "name": "d01e_tpu_sketch_generator",
      "input": null,
      "output": {
        "status": "success",
        "sketch": "import cv2\nimport numpy as np\nfrom tflite_runtime.interpreter import Interpreter\nfrom tflite_runtime.interpreter import load_delegate\nimport time\n\n# Configuration parameters\nmodel_path = '/home/mendel/tinyml_autopilot/models/edgetpu_detect.tflite'\nlabel_path = '/home/mendel/tinyml_autopilot/models/labelmap.txt'\ninput_path = '/home/mendel/tinyml_autopilot/data/sheeps.mp4'\noutput_path = '/home/mendel/tinyml_autopilot/results/sheeps_detections.mp4'\nconfidence_threshold = 0.5\n\n# Load labels\ndef load_labels(label_file):\n    with open(label_file, 'r', encoding='utf-8') as f:\n        lines = f.readlines()\n    return {i: line.strip() for i, line in enumerate(lines)}\n\nlabels = load_labels(label_path)\n\n# Phase 1: Setup\ninterpreter = Interpreter(\n    model_path=model_path,\n    experimental_delegates=[load_delegate('/usr/lib/aarch64-linux-gnu/libedgetpu.so.1.0')]\n)\ninterpreter.allocate_tensors()\n\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\n\ninput_shape = input_details[0]['shape']\nheight, width, channels = input_shape[1], input_shape[2], input_shape[3]\n\n# Phase 2: Preprocessing\ndef preprocess_frame(frame):\n    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n    frame_resized = cv2.resize(frame_rgb, (width, height))\n    return np.expand_dims(frame_resized, axis=0)\n\n# Phase 3: Inference\ndef run_inference(interpreter, image):\n    interpreter.set_tensor(input_details[0]['index'], image)\n    interpreter.invoke()\n    \n    boxes = interpreter.get_tensor(output_details[0]['index'])[0] # Bounding box coordinates of detected objects\n    classes = interpreter.get_tensor(output_details[1]['index'])[0] # Class index of detected objects\n    scores = interpreter.get_tensor(output_details[2]['index'])[0] # Confidence of detected objects\n    \n    return boxes, classes, scores\n\n# Phase 4: Output Handling\ndef draw_boxes(frame, boxes, classes, scores):\n    for i in range(len(scores)):\n        if scores[i] >= confidence_threshold:\n            ymin, xmin, ymax, xmax = boxes[i]\n            (left, right, top, bottom) = (xmin * frame.shape[1], xmax * frame.shape[1],\n                                          ymin * frame.shape[0], ymax * frame.shape[0])\n            \n            cv2.rectangle(frame, (int(left), int(top)), (int(right), int(bottom)),\n                          color=(0, 255, 0), thickness=2)\n            \n            label = f\"{labels[int(classes[i])]}: {int(scores[i] * 100)}%\"\n            cv2.putText(frame, label, (int(left), int(top - 10)), \n                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n\ndef main():\n    cap = cv2.VideoCapture(input_path)\n    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n    out = cv2.VideoWriter(output_path, fourcc, 20.0, (int(cap.get(3)), int(cap.get(4))))\n    \n    while cap.isOpened():\n        ret, frame = cap.read()\n        if not ret:\n            break\n        \n        start_time = time.time()\n        \n        # Preprocess\n        preprocessed_frame = preprocess_frame(frame)\n        \n        # Inference\n        boxes, classes, scores = run_inference(interpreter, preprocessed_frame)\n        \n        # Draw detection results on frame\n        draw_boxes(frame, boxes, classes, scores)\n        \n        out.write(frame)\n        print(f\"Inference time: {time.time() - start_time:.2f}s\")\n    \n    cap.release()\n    out.release()\n\nif __name__ == \"__main__\":\n    main()"
      },
      "session_id": "phi4_a8a2_tpusg_batch",
      "metadata": {
        "num_run": 12
      },
      "tags": [
        "ablation",
        "benchmark",
        "phi4:latest",
        "tpu_sketch_generator"
      ],
      "latency": 151.657,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "time-06-44-58-511266_chatcmpl-bb3cdaeb-2b1a-4a66-a8f4-17d060d11808",
          "traceId": "d01e27d1",
          "type": "GENERATION",
          "name": "d01e_tpusg_gen_attempt#1",
          "startTime": "2025-12-11T04:44:58.511000+00:00",
          "endTime": "2025-12-11T04:46:46.030000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 107519.0,
          "promptTokens": 291,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 780,
          "totalTokens": 1071,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-06-46-53-909061_chatcmpl-01a15f6b-f188-4d5f-a297-e17b23f9bdaa",
          "traceId": "d01e27d1",
          "type": "GENERATION",
          "name": "d01e_tpusg_gen_attempt#2",
          "startTime": "2025-12-11T04:46:53.909000+00:00",
          "endTime": "2025-12-11T04:47:06.612000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 12703.0,
          "promptTokens": 291,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 697,
          "totalTokens": 988,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        },
        {
          "id": "time-06-47-14-959351_chatcmpl-9b488f3a-31aa-4779-8e47-53a0cf0db24f",
          "traceId": "d01e27d1",
          "type": "GENERATION",
          "name": "d01e_tpusg_gen_attempt#3",
          "startTime": "2025-12-11T04:47:14.959000+00:00",
          "endTime": "2025-12-11T04:47:30.168000+00:00",
          "model": "phi4:latest",
          "modelParameters": {},
          "level": "DEFAULT",
          "calculatedTotalCost": 0.0,
          "latency": 15209.0,
          "promptTokens": 291,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 835,
          "totalTokens": 1126,
          "statusMessage": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null
        }
      ],
      "createdAt": "2025-12-11T04:44:59.032Z",
      "updatedAt": "2025-12-11T04:48:28.259Z",
      "environment": "default"
    },
    {
      "id": "c8135084",
      "timestamp": "2025-12-11T04:44:31.567000+00:00",
      "name": "c813_tpu_sketch_generator",
      "input": null,
      "output": {
        "status": "failed",
        "last_code": "",
        "last_error": "[FATAL]: CUDA error detected: litellm.APIConnectionError: OllamaException - {\"error\":\"llama runner process has terminated: CUDA error: all CUDA-capable devices are busy or unavailable\\n  current device: 0, in function ggml_backend_cuda_device_get_memory at //ml/backend/ggml/ggml/src/ggml-cuda/ggml-cuda.cu:2898\\n  cudaMemGetInfo(free, total)\\n//ml/backend/ggml/ggml/src/ggml-cuda/ggml-cuda.cu:73: CUDA error\"}"
      },
      "session_id": "phi4_a8a2_tpusg_batch",
      "metadata": {
        "num_run": 11
      },
      "tags": [
        "ablation",
        "benchmark",
        "phi4:latest",
        "tpu_sketch_generator"
      ],
      "latency": 0.0,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "114f0258-304f-4a9c-8079-23aae6471452",
          "traceId": "c8135084",
          "type": "SPAN",
          "name": "error_c8_tpusg_failure_signal_tpu_sketch_generator",
          "startTime": "2025-12-11T04:44:32.436000+00:00",
          "level": "ERROR",
          "statusMessage": "Failed: [FATAL]: CUDA error detected: litellm.APIConnectionError: OllamaException - {\"error\":\"llama runner process has terminated: CUDA error: all CUDA-capable devices are busy or unavailable\\n  current device: 0, in function ggml_backend_cuda_device_get_memory at //ml/backend/ggml/ggml/src/ggml-cuda/ggml-cuda.cu:2898\\n  cudaMemGetInfo(free, total)\\n//ml/backend/ggml/ggml/src/ggml-cuda/ggml-cuda.cu:73: CUDA error\"}",
          "calculatedTotalCost": 0.0,
          "promptTokens": 0,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 0,
          "totalTokens": 0,
          "endTime": null,
          "model": null,
          "modelParameters": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null,
          "latency": null
        }
      ],
      "createdAt": "2025-12-11T04:44:32.610Z",
      "updatedAt": "2025-12-11T04:44:37.635Z",
      "environment": "default"
    },
    {
      "id": "9cae3bed",
      "timestamp": "2025-12-11T04:44:05.627000+00:00",
      "name": "9cae_tpu_sketch_generator",
      "input": null,
      "output": {
        "status": "failed",
        "last_code": "",
        "last_error": "[FATAL]: CUDA error detected: litellm.APIConnectionError: OllamaException - {\"error\":\"llama runner process has terminated: CUDA error\"}"
      },
      "session_id": "phi4_a8a2_tpusg_batch",
      "metadata": {
        "num_run": 10
      },
      "tags": [
        "ablation",
        "benchmark",
        "phi4:latest",
        "tpu_sketch_generator"
      ],
      "latency": 0.0,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "8da96109-bd03-477c-b0cd-c3eda90276db",
          "traceId": "9cae3bed",
          "type": "SPAN",
          "name": "error_9c_tpusg_failure_signal_tpu_sketch_generator",
          "startTime": "2025-12-11T04:44:06.159000+00:00",
          "level": "ERROR",
          "statusMessage": "Failed: [FATAL]: CUDA error detected: litellm.APIConnectionError: OllamaException - {\"error\":\"llama runner process has terminated: CUDA error\"}",
          "calculatedTotalCost": 0.0,
          "promptTokens": 0,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 0,
          "totalTokens": 0,
          "endTime": null,
          "model": null,
          "modelParameters": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null,
          "latency": null
        }
      ],
      "createdAt": "2025-12-11T04:44:06.670Z",
      "updatedAt": "2025-12-11T04:44:11.739Z",
      "environment": "default"
    },
    {
      "id": "40c058e8",
      "timestamp": "2025-12-11T04:43:38.657000+00:00",
      "name": "40c0_tpu_sketch_generator",
      "input": null,
      "output": {
        "status": "failed",
        "last_code": "",
        "last_error": "[FATAL]: CUDA error detected: litellm.APIConnectionError: OllamaException - {\"error\":\"llama runner process has terminated: CUDA error: all CUDA-capable devices are busy or unavailable\\n  current device: 0, in function ggml_backend_cuda_device_get_memory at //ml/backend/ggml/ggml/src/ggml-cuda/ggml-cuda.cu:2898\\n  cudaMemGetInfo(free, total)\\n//ml/backend/ggml/ggml/src/ggml-cuda/ggml-cuda.cu:73: CUDA error\"}"
      },
      "session_id": "phi4_a8a2_tpusg_batch",
      "metadata": {
        "num_run": 9
      },
      "tags": [
        "ablation",
        "benchmark",
        "phi4:latest",
        "tpu_sketch_generator"
      ],
      "latency": 0.0,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "b9dca094-af98-43ab-b9c4-4161c5e109c9",
          "traceId": "40c058e8",
          "type": "SPAN",
          "name": "error_40_tpusg_failure_signal_tpu_sketch_generator",
          "startTime": "2025-12-11T04:43:39.175000+00:00",
          "level": "ERROR",
          "statusMessage": "Failed: [FATAL]: CUDA error detected: litellm.APIConnectionError: OllamaException - {\"error\":\"llama runner process has terminated: CUDA error: all CUDA-capable devices are busy or unavailable\\n  current device: 0, in function ggml_backend_cuda_device_get_memory at //ml/backend/ggml/ggml/src/ggml-cuda/ggml-cuda.cu:2898\\n  cudaMemGetInfo(free, total)\\n//ml/backend/ggml/ggml/src/ggml-cuda/ggml-cuda.cu:73: CUDA error\"}",
          "calculatedTotalCost": 0.0,
          "promptTokens": 0,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 0,
          "totalTokens": 0,
          "endTime": null,
          "model": null,
          "modelParameters": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null,
          "latency": null
        }
      ],
      "createdAt": "2025-12-11T04:43:39.701Z",
      "updatedAt": "2025-12-11T04:43:44.734Z",
      "environment": "default"
    },
    {
      "id": "fd48609d",
      "timestamp": "2025-12-11T04:43:12.735000+00:00",
      "name": "fd48_tpu_sketch_generator",
      "input": null,
      "output": {
        "status": "failed",
        "last_code": "",
        "last_error": "[FATAL]: CUDA error detected: litellm.APIConnectionError: OllamaException - {\"error\":\"llama runner process has terminated: CUDA error: all CUDA-capable devices are busy or unavailable\\n  current device: 0, in function ggml_backend_cuda_device_get_memory at //ml/backend/ggml/ggml/src/ggml-cuda/ggml-cuda.cu:2898\\n  cudaMemGetInfo(free, total)\\n//ml/backend/ggml/ggml/src/ggml-cuda/ggml-cuda.cu:73: CUDA error\"}"
      },
      "session_id": "phi4_a8a2_tpusg_batch",
      "metadata": {
        "num_run": 8
      },
      "tags": [
        "ablation",
        "benchmark",
        "phi4:latest",
        "tpu_sketch_generator"
      ],
      "latency": 0.0,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "d8383881-da85-4d42-9781-5435aac46f24",
          "traceId": "fd48609d",
          "type": "SPAN",
          "name": "error_fd_tpusg_failure_signal_tpu_sketch_generator",
          "startTime": "2025-12-11T04:43:13.288000+00:00",
          "level": "ERROR",
          "statusMessage": "Failed: [FATAL]: CUDA error detected: litellm.APIConnectionError: OllamaException - {\"error\":\"llama runner process has terminated: CUDA error: all CUDA-capable devices are busy or unavailable\\n  current device: 0, in function ggml_backend_cuda_device_get_memory at //ml/backend/ggml/ggml/src/ggml-cuda/ggml-cuda.cu:2898\\n  cudaMemGetInfo(free, total)\\n//ml/backend/ggml/ggml/src/ggml-cuda/ggml-cuda.cu:73: CUDA error\"}",
          "calculatedTotalCost": 0.0,
          "promptTokens": 0,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 0,
          "totalTokens": 0,
          "endTime": null,
          "model": null,
          "modelParameters": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null,
          "latency": null
        }
      ],
      "createdAt": "2025-12-11T04:43:13.774Z",
      "updatedAt": "2025-12-11T04:43:18.839Z",
      "environment": "default"
    },
    {
      "id": "7a51a196",
      "timestamp": "2025-12-11T04:42:45.829000+00:00",
      "name": "7a51_tpu_sketch_generator",
      "input": null,
      "output": {
        "status": "failed",
        "last_code": "",
        "last_error": "[FATAL]: CUDA error detected: litellm.APIConnectionError: OllamaException - {\"error\":\"llama runner process has terminated: CUDA error\"}"
      },
      "session_id": "phi4_a8a2_tpusg_batch",
      "metadata": {
        "num_run": 7
      },
      "tags": [
        "ablation",
        "benchmark",
        "phi4:latest",
        "tpu_sketch_generator"
      ],
      "latency": 0.0,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "a9ca4bd7-c441-4a67-aa5c-99d19da1a449",
          "traceId": "7a51a196",
          "type": "SPAN",
          "name": "error_7a_tpusg_failure_signal_tpu_sketch_generator",
          "startTime": "2025-12-11T04:42:46.359000+00:00",
          "level": "ERROR",
          "statusMessage": "Failed: [FATAL]: CUDA error detected: litellm.APIConnectionError: OllamaException - {\"error\":\"llama runner process has terminated: CUDA error\"}",
          "calculatedTotalCost": 0.0,
          "promptTokens": 0,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 0,
          "totalTokens": 0,
          "endTime": null,
          "model": null,
          "modelParameters": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null,
          "latency": null
        }
      ],
      "createdAt": "2025-12-11T04:42:46.350Z",
      "updatedAt": "2025-12-11T04:42:51.946Z",
      "environment": "default"
    },
    {
      "id": "9a17c0eb",
      "timestamp": "2025-12-11T04:42:18.908000+00:00",
      "name": "9a17_tpu_sketch_generator",
      "input": null,
      "output": {
        "status": "failed",
        "last_code": "",
        "last_error": "[FATAL]: CUDA error detected: litellm.APIConnectionError: OllamaException - {\"error\":\"llama runner process has terminated: CUDA error\"}"
      },
      "session_id": "phi4_a8a2_tpusg_batch",
      "metadata": {
        "num_run": 6
      },
      "tags": [
        "ablation",
        "benchmark",
        "phi4:latest",
        "tpu_sketch_generator"
      ],
      "latency": 0.0,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "f87bd154-d8ae-4e20-ad96-0dd2ef6507df",
          "traceId": "9a17c0eb",
          "type": "SPAN",
          "name": "error_9a_tpusg_failure_signal_tpu_sketch_generator",
          "startTime": "2025-12-11T04:42:19.429000+00:00",
          "level": "ERROR",
          "statusMessage": "Failed: [FATAL]: CUDA error detected: litellm.APIConnectionError: OllamaException - {\"error\":\"llama runner process has terminated: CUDA error\"}",
          "calculatedTotalCost": 0.0,
          "promptTokens": 0,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 0,
          "totalTokens": 0,
          "endTime": null,
          "model": null,
          "modelParameters": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null,
          "latency": null
        }
      ],
      "createdAt": "2025-12-11T04:42:19.431Z",
      "updatedAt": "2025-12-11T04:42:25.044Z",
      "environment": "default"
    },
    {
      "id": "0d046272",
      "timestamp": "2025-12-11T04:41:52.954000+00:00",
      "name": "0d04_tpu_sketch_generator",
      "input": null,
      "output": {
        "status": "failed",
        "last_code": "",
        "last_error": "[FATAL]: CUDA error detected: litellm.APIConnectionError: OllamaException - {\"error\":\"llama runner process has terminated: CUDA error\"}"
      },
      "session_id": "phi4_a8a2_tpusg_batch",
      "metadata": {
        "num_run": 5
      },
      "tags": [
        "ablation",
        "benchmark",
        "phi4:latest",
        "tpu_sketch_generator"
      ],
      "latency": 0.0,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "454f6c73-e32c-4ade-a131-0f8ad4ccb30f",
          "traceId": "0d046272",
          "type": "SPAN",
          "name": "error_0d_tpusg_failure_signal_tpu_sketch_generator",
          "startTime": "2025-12-11T04:41:53.473000+00:00",
          "level": "ERROR",
          "statusMessage": "Failed: [FATAL]: CUDA error detected: litellm.APIConnectionError: OllamaException - {\"error\":\"llama runner process has terminated: CUDA error\"}",
          "calculatedTotalCost": 0.0,
          "promptTokens": 0,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 0,
          "totalTokens": 0,
          "endTime": null,
          "model": null,
          "modelParameters": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null,
          "latency": null
        }
      ],
      "createdAt": "2025-12-11T04:41:53.475Z",
      "updatedAt": "2025-12-11T04:41:59.048Z",
      "environment": "default"
    },
    {
      "id": "3dc6e438",
      "timestamp": "2025-12-11T04:41:26.053000+00:00",
      "name": "3dc6_tpu_sketch_generator",
      "input": null,
      "output": {
        "status": "failed",
        "last_code": "",
        "last_error": "[FATAL]: CUDA error detected: litellm.APIConnectionError: OllamaException - {\"error\":\"llama runner process has terminated: CUDA error\"}"
      },
      "session_id": "phi4_a8a2_tpusg_batch",
      "metadata": {
        "num_run": 4
      },
      "tags": [
        "ablation",
        "benchmark",
        "phi4:latest",
        "tpu_sketch_generator"
      ],
      "latency": 0.0,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "abe70fef-7fbe-4dba-89de-7d33b755e8a8",
          "traceId": "3dc6e438",
          "type": "SPAN",
          "name": "error_3d_tpusg_failure_signal_tpu_sketch_generator",
          "startTime": "2025-12-11T04:41:26.580000+00:00",
          "level": "ERROR",
          "statusMessage": "Failed: [FATAL]: CUDA error detected: litellm.APIConnectionError: OllamaException - {\"error\":\"llama runner process has terminated: CUDA error\"}",
          "calculatedTotalCost": 0.0,
          "promptTokens": 0,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 0,
          "totalTokens": 0,
          "endTime": null,
          "model": null,
          "modelParameters": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null,
          "latency": null
        }
      ],
      "createdAt": "2025-12-11T04:41:26.574Z",
      "updatedAt": "2025-12-11T04:41:32.151Z",
      "environment": "default"
    },
    {
      "id": "aef94961",
      "timestamp": "2025-12-11T04:40:59.049000+00:00",
      "name": "aef9_tpu_sketch_generator",
      "input": null,
      "output": {
        "status": "failed",
        "last_code": "",
        "last_error": "[FATAL]: CUDA error detected: litellm.APIConnectionError: OllamaException - {\"error\":\"llama runner process has terminated: CUDA error\"}"
      },
      "session_id": "phi4_a8a2_tpusg_batch",
      "metadata": {
        "num_run": 3
      },
      "tags": [
        "ablation",
        "benchmark",
        "phi4:latest",
        "tpu_sketch_generator"
      ],
      "latency": 0.0,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "383d4278-c43b-49b7-a3ac-59161f7fa900",
          "traceId": "aef94961",
          "type": "SPAN",
          "name": "error_ae_tpusg_failure_signal_tpu_sketch_generator",
          "startTime": "2025-12-11T04:40:59.611000+00:00",
          "level": "ERROR",
          "statusMessage": "Failed: [FATAL]: CUDA error detected: litellm.APIConnectionError: OllamaException - {\"error\":\"llama runner process has terminated: CUDA error\"}",
          "calculatedTotalCost": 0.0,
          "promptTokens": 0,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 0,
          "totalTokens": 0,
          "endTime": null,
          "model": null,
          "modelParameters": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null,
          "latency": null
        }
      ],
      "createdAt": "2025-12-11T04:40:59.570Z",
      "updatedAt": "2025-12-11T04:41:05.152Z",
      "environment": "default"
    },
    {
      "id": "41068ab0",
      "timestamp": "2025-12-11T04:40:33.102000+00:00",
      "name": "4106_tpu_sketch_generator",
      "input": null,
      "output": {
        "status": "failed",
        "last_code": "",
        "last_error": "[FATAL]: CUDA error detected: litellm.APIConnectionError: OllamaException - {\"error\":\"llama runner process has terminated: CUDA error\"}"
      },
      "session_id": "phi4_a8a2_tpusg_batch",
      "metadata": {
        "num_run": 2
      },
      "tags": [
        "ablation",
        "benchmark",
        "phi4:latest",
        "tpu_sketch_generator"
      ],
      "latency": 0.0,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "8cfc1183-d864-458d-b5f1-09f75748d417",
          "traceId": "41068ab0",
          "type": "SPAN",
          "name": "error_41_tpusg_failure_signal_tpu_sketch_generator",
          "startTime": "2025-12-11T04:40:33.637000+00:00",
          "level": "ERROR",
          "statusMessage": "Failed: [FATAL]: CUDA error detected: litellm.APIConnectionError: OllamaException - {\"error\":\"llama runner process has terminated: CUDA error\"}",
          "calculatedTotalCost": 0.0,
          "promptTokens": 0,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 0,
          "totalTokens": 0,
          "endTime": null,
          "model": null,
          "modelParameters": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null,
          "latency": null
        }
      ],
      "createdAt": "2025-12-11T04:40:33.623Z",
      "updatedAt": "2025-12-11T04:40:39.258Z",
      "environment": "default"
    },
    {
      "id": "1c2488d8",
      "timestamp": "2025-12-11T04:40:05.165000+00:00",
      "name": "1c24_tpu_sketch_generator",
      "input": null,
      "output": {
        "status": "failed",
        "last_code": "",
        "last_error": "[FATAL]: CUDA error detected: litellm.APIConnectionError: OllamaException - {\"error\":\"llama runner process has terminated: CUDA error\"}"
      },
      "session_id": "phi4_a8a2_tpusg_batch",
      "metadata": {
        "num_run": 1
      },
      "tags": [
        "ablation",
        "benchmark",
        "phi4:latest",
        "tpu_sketch_generator"
      ],
      "latency": 0.0,
      "total_cost": 0.0,
      "observations": [
        {
          "id": "0a409cfb-0f0e-483b-bc74-fb3716558101",
          "traceId": "1c2488d8",
          "type": "SPAN",
          "name": "error_1c_tpusg_failure_signal_tpu_sketch_generator",
          "startTime": "2025-12-11T04:40:08.089000+00:00",
          "level": "ERROR",
          "statusMessage": "Failed: [FATAL]: CUDA error detected: litellm.APIConnectionError: OllamaException - {\"error\":\"llama runner process has terminated: CUDA error\"}",
          "calculatedTotalCost": 0.0,
          "promptTokens": 0,
          "environment": "default",
          "costDetails": {},
          "completionTokens": 0,
          "totalTokens": 0,
          "endTime": null,
          "model": null,
          "modelParameters": null,
          "calculatedInputCost": null,
          "calculatedOutputCost": null,
          "latency": null
        }
      ],
      "createdAt": "2025-12-11T04:40:05.684Z",
      "updatedAt": "2025-12-11T04:40:13.266Z",
      "environment": "default"
    }
  ],
  "meta": {
    "total_items": 30
  }
}